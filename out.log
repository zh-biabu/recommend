nohup: ignoring input
2025-12-26 20:37:35 - GraphTrainer - INFO - Starting training...
2025-12-26 20:37:35 - GraphTrainer - INFO - 模型: MMGCN_rec
2025-12-26 20:37:35 - GraphTrainer - INFO - 总参数量: 2,696,448
2025-12-26 20:37:35 - GraphTrainer - INFO - 可训练参数量: 2,696,448
2025-12-26 20:37:35 - GraphTrainer - INFO - ============================================================
2025-12-26 20:37:35 - GraphTrainer - INFO - 开始第 1/1000 轮训练
2025-12-26 20:37:35 - GraphTrainer - INFO - ============================================================
Using GPU: NVIDIA GeForce RTX 3090
============================================================
Graph-based Recommendation System
============================================================
Dataset: baby
Device: cuda
Model: MMGCN_rec
Embedding dim: 64
Epochs: 1000
============================================================
Loading data...
Initializing full dataset from ../autodl-tmp/data/ori_data/baby
Loading interaction data from ../autodl-tmp/data/ori_data/baby
Loading features from ../autodl-tmp/data/ori_data/baby
Building user-item interaction index...
Dataset Statistics:
  num_users: 19445
  num_items: 7050
  num_interactions: 160792
  sparsity: 0.9988270827520429
  user_features: []
  item_features_dimensions: {'image_feat': 4096, 'text_feat': 384}
  user_feature_dimensions: {}
  train_ratio: 0.737294143987263
  val_ratio: 0.12786083884770386
  test_ratio: 0.13484501716503308
Full dataset initialized: 160792 interactions, 19445 users, 7050 items
Splitting dataset into train/val/test...
Initializing subset dataset (mode: train) with 118551 interactions
Initializing subset dataset (mode: val) with 20559 interactions
Initializing subset dataset (mode: test) with 21682 interactions
Split results - Train: 118551 interactions, Val: 20559, Test: 21682
Data loaders created - Train batches: 58, Val batches: 11, Test batches: 11
Data loaded: 19445 users, 7050 items
User features: []
Item features: ['image_feat', 'text_feat']
Building graph and model...
Extracting training interactions for graph construction...
Extracted 118551 positive interactions for graph construction
⚠️  Important: Graph constructed using only training data to prevent data leakage
MMGCN_rec(
  (model): Net_rec(
    (v_gcn): GCN(
      (MLP): Linear(in_features=4096, out_features=512, bias=True)
      (conv_embed_1): BaseModel(512, 512)
      (linear_layer1): Linear(in_features=512, out_features=64, bias=True)
      (g_layer1): Linear(in_features=576, out_features=64, bias=True)
      (conv_embed_2): BaseModel(64, 64)
      (linear_layer2): Linear(in_features=64, out_features=64, bias=True)
      (g_layer2): Linear(in_features=128, out_features=64, bias=True)
      (conv_embed_3): BaseModel(64, 64)
      (linear_layer3): Linear(in_features=64, out_features=64, bias=True)
      (g_layer3): Linear(in_features=128, out_features=64, bias=True)
    )
    (t_gcn): GCN(
      (conv_embed_1): BaseModel(384, 384)
      (linear_layer1): Linear(in_features=384, out_features=64, bias=True)
      (g_layer1): Linear(in_features=448, out_features=64, bias=True)
      (conv_embed_2): BaseModel(64, 64)
      (linear_layer2): Linear(in_features=64, out_features=64, bias=True)
      (g_layer2): Linear(in_features=128, out_features=64, bias=True)
      (conv_embed_3): BaseModel(64, 64)
      (linear_layer3): Linear(in_features=64, out_features=64, bias=True)
      (g_layer3): Linear(in_features=128, out_features=64, bias=True)
    )
  )
)
Model parameters: 2,696,448
init trainer,verifier,tester
2025-12-26 20:37:46 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:37:46 - GraphTrainer - INFO -   precision@5: 0.004094
2025-12-26 20:37:46 - GraphTrainer - INFO -   recall@5: 0.019674
2025-12-26 20:37:46 - GraphTrainer - INFO -   hit_rate@5: 0.020468
2025-12-26 20:37:46 - GraphTrainer - INFO -   ndcg@5: 0.012806
2025-12-26 20:37:46 - GraphTrainer - INFO -   map@5: 0.010420
2025-12-26 20:37:46 - GraphTrainer - INFO -   mrr@5: 0.010813
2025-12-26 20:37:46 - GraphTrainer - INFO -   precision@10: 0.002993
2025-12-26 20:37:46 - GraphTrainer - INFO -   recall@10: 0.028614
2025-12-26 20:37:46 - GraphTrainer - INFO -   hit_rate@10: 0.029931
2025-12-26 20:37:46 - GraphTrainer - INFO -   ndcg@10: 0.015725
2025-12-26 20:37:46 - GraphTrainer - INFO -   map@10: 0.011608
2025-12-26 20:37:46 - GraphTrainer - INFO -   mrr@10: 0.012072
2025-12-26 20:37:46 - GraphTrainer - INFO -   precision@20: 0.002538
2025-12-26 20:37:46 - GraphTrainer - INFO -   recall@20: 0.048448
2025-12-26 20:37:46 - GraphTrainer - INFO -   hit_rate@20: 0.050450
2025-12-26 20:37:46 - GraphTrainer - INFO -   ndcg@20: 0.020707
2025-12-26 20:37:46 - GraphTrainer - INFO -   map@20: 0.012926
2025-12-26 20:37:46 - GraphTrainer - INFO -   mrr@20: 0.013429
2025-12-26 20:37:46 - GraphTrainer - INFO - 第 1 轮训练完成
2025-12-26 20:37:46 - GraphTrainer - INFO - train_loss: 3.247402
2025-12-26 20:37:46 - GraphTrainer - INFO - precision@5: 0.004094
2025-12-26 20:37:46 - GraphTrainer - INFO - recall@5: 0.019674
2025-12-26 20:37:46 - GraphTrainer - INFO - hit_rate@5: 0.020468
2025-12-26 20:37:46 - GraphTrainer - INFO - ndcg@5: 0.012806
2025-12-26 20:37:46 - GraphTrainer - INFO - map@5: 0.010420
2025-12-26 20:37:46 - GraphTrainer - INFO - mrr@5: 0.010813
2025-12-26 20:37:46 - GraphTrainer - INFO - precision@10: 0.002993
2025-12-26 20:37:46 - GraphTrainer - INFO - recall@10: 0.028614
2025-12-26 20:37:46 - GraphTrainer - INFO - hit_rate@10: 0.029931
2025-12-26 20:37:46 - GraphTrainer - INFO - ndcg@10: 0.015725
2025-12-26 20:37:46 - GraphTrainer - INFO - map@10: 0.011608
2025-12-26 20:37:46 - GraphTrainer - INFO - mrr@10: 0.012072
2025-12-26 20:37:46 - GraphTrainer - INFO - precision@20: 0.002538
2025-12-26 20:37:46 - GraphTrainer - INFO - recall@20: 0.048448
2025-12-26 20:37:46 - GraphTrainer - INFO - hit_rate@20: 0.050450
2025-12-26 20:37:46 - GraphTrainer - INFO - ndcg@20: 0.020707
2025-12-26 20:37:46 - GraphTrainer - INFO - map@20: 0.012926
2025-12-26 20:37:46 - GraphTrainer - INFO - mrr@20: 0.013429
2025-12-26 20:37:46 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:37:46 - GraphTrainer - INFO - ============================================================
2025-12-26 20:37:46 - GraphTrainer - INFO - 开始第 2/1000 轮训练
2025-12-26 20:37:46 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(3.7377, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(3.7374, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(3.7371, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(3.7366, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(3.7358, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(3.7347, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(3.7332, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(3.7311, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(3.7277, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(3.7224, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(3.7186, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(3.7089, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(3.6980, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(3.6859, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(3.6651, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(3.6372, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(3.6023, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(3.5461, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(3.4805, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(3.3807, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(3.3328, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(3.1960, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(3.0638, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(3.0375, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(2.9800, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(2.9890, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(3.0065, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(3.0236, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(2.9754, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(2.9421, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(2.9798, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(2.9187, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(2.9399, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(2.9592, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(2.9458, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(2.9251, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(2.9914, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(2.8721, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(3.0614, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(3.1761, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(2.9069, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(3.0357, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(3.1458, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(3.0499, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(2.8694, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(3.1556, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(3.2432, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(3.1567, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(2.9978, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(2.9464, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(2.9744, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(3.1022, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(3.1141, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(2.9992, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(2.8992, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(2.9618, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(2.9834, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(3.0348, device='cuda:0', grad_fn=<AddBackward0>)
The 1 training average loss: 3.2474021706087837
2025-12-26 20:37:57 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:37:57 - GraphTrainer - INFO -   precision@5: 0.003867
2025-12-26 20:37:57 - GraphTrainer - INFO -   recall@5: 0.018488
2025-12-26 20:37:57 - GraphTrainer - INFO -   hit_rate@5: 0.019337
2025-12-26 20:37:57 - GraphTrainer - INFO -   ndcg@5: 0.012170
2025-12-26 20:37:57 - GraphTrainer - INFO -   map@5: 0.009947
2025-12-26 20:37:57 - GraphTrainer - INFO -   mrr@5: 0.010377
2025-12-26 20:37:57 - GraphTrainer - INFO -   precision@10: 0.003060
2025-12-26 20:37:57 - GraphTrainer - INFO -   recall@10: 0.029095
2025-12-26 20:37:57 - GraphTrainer - INFO -   hit_rate@10: 0.030599
2025-12-26 20:37:57 - GraphTrainer - INFO -   ndcg@10: 0.015620
2025-12-26 20:37:57 - GraphTrainer - INFO -   map@10: 0.011340
2025-12-26 20:37:57 - GraphTrainer - INFO -   mrr@10: 0.011856
2025-12-26 20:37:57 - GraphTrainer - INFO -   precision@20: 0.002466
2025-12-26 20:37:57 - GraphTrainer - INFO -   recall@20: 0.047017
2025-12-26 20:37:57 - GraphTrainer - INFO -   hit_rate@20: 0.049113
2025-12-26 20:37:57 - GraphTrainer - INFO -   ndcg@20: 0.020157
2025-12-26 20:37:57 - GraphTrainer - INFO -   map@20: 0.012559
2025-12-26 20:37:57 - GraphTrainer - INFO -   mrr@20: 0.013116
2025-12-26 20:37:57 - GraphTrainer - INFO - 第 2 轮训练完成
2025-12-26 20:37:57 - GraphTrainer - INFO - train_loss: 2.842992
2025-12-26 20:37:57 - GraphTrainer - INFO - precision@5: 0.003867
2025-12-26 20:37:57 - GraphTrainer - INFO - recall@5: 0.018488
2025-12-26 20:37:57 - GraphTrainer - INFO - hit_rate@5: 0.019337
2025-12-26 20:37:57 - GraphTrainer - INFO - ndcg@5: 0.012170
2025-12-26 20:37:57 - GraphTrainer - INFO - map@5: 0.009947
2025-12-26 20:37:57 - GraphTrainer - INFO - mrr@5: 0.010377
2025-12-26 20:37:57 - GraphTrainer - INFO - precision@10: 0.003060
2025-12-26 20:37:57 - GraphTrainer - INFO - recall@10: 0.029095
2025-12-26 20:37:57 - GraphTrainer - INFO - hit_rate@10: 0.030599
2025-12-26 20:37:57 - GraphTrainer - INFO - ndcg@10: 0.015620
2025-12-26 20:37:57 - GraphTrainer - INFO - map@10: 0.011340
2025-12-26 20:37:57 - GraphTrainer - INFO - mrr@10: 0.011856
2025-12-26 20:37:57 - GraphTrainer - INFO - precision@20: 0.002466
2025-12-26 20:37:57 - GraphTrainer - INFO - recall@20: 0.047017
2025-12-26 20:37:57 - GraphTrainer - INFO - hit_rate@20: 0.049113
2025-12-26 20:37:57 - GraphTrainer - INFO - ndcg@20: 0.020157
2025-12-26 20:37:57 - GraphTrainer - INFO - map@20: 0.012559
2025-12-26 20:37:57 - GraphTrainer - INFO - mrr@20: 0.013116
2025-12-26 20:37:57 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:37:57 - GraphTrainer - INFO - ============================================================
2025-12-26 20:37:57 - GraphTrainer - INFO - 开始第 3/1000 轮训练
2025-12-26 20:37:57 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(2.9696, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(2.8712, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(2.9170, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(2.9016, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(2.8550, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(2.9401, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(2.8126, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(2.8628, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(2.8727, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(2.8824, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(2.8539, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(2.9041, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(2.9125, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(2.8053, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(2.8810, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(2.8394, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(2.8423, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(2.8815, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(2.8599, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(2.8191, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(2.8888, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(2.8635, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(2.8638, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(2.8106, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(2.8166, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(2.8450, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(2.8293, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(2.8391, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(2.8284, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(2.7997, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(2.7842, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(2.7878, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(2.7640, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(2.8777, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(2.7943, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(2.8165, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(2.7699, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(2.8451, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(2.7925, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(2.7765, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(2.8586, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(2.8240, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(2.7957, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(2.8340, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(2.8161, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(2.8491, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(2.8287, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(2.7990, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(2.8313, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(2.8349, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(2.8561, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(2.8822, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(2.8289, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(2.8578, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(2.8083, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(2.8087, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(2.8549, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(2.8480, device='cuda:0', grad_fn=<AddBackward0>)
The 2 training average loss: 2.842991833029122
2025-12-26 20:38:09 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:38:09 - GraphTrainer - INFO -   precision@5: 0.003898
2025-12-26 20:38:09 - GraphTrainer - INFO -   recall@5: 0.018827
2025-12-26 20:38:09 - GraphTrainer - INFO -   hit_rate@5: 0.019491
2025-12-26 20:38:09 - GraphTrainer - INFO -   ndcg@5: 0.012039
2025-12-26 20:38:09 - GraphTrainer - INFO -   map@5: 0.009719
2025-12-26 20:38:09 - GraphTrainer - INFO -   mrr@5: 0.010007
2025-12-26 20:38:09 - GraphTrainer - INFO -   precision@10: 0.003235
2025-12-26 20:38:09 - GraphTrainer - INFO -   recall@10: 0.030915
2025-12-26 20:38:09 - GraphTrainer - INFO -   hit_rate@10: 0.032348
2025-12-26 20:38:09 - GraphTrainer - INFO -   ndcg@10: 0.015928
2025-12-26 20:38:09 - GraphTrainer - INFO -   map@10: 0.011265
2025-12-26 20:38:09 - GraphTrainer - INFO -   mrr@10: 0.011645
2025-12-26 20:38:09 - GraphTrainer - INFO -   precision@20: 0.002633
2025-12-26 20:38:09 - GraphTrainer - INFO -   recall@20: 0.050161
2025-12-26 20:38:09 - GraphTrainer - INFO -   hit_rate@20: 0.052558
2025-12-26 20:38:09 - GraphTrainer - INFO -   ndcg@20: 0.020808
2025-12-26 20:38:09 - GraphTrainer - INFO -   map@20: 0.012570
2025-12-26 20:38:09 - GraphTrainer - INFO -   mrr@20: 0.013015
2025-12-26 20:38:09 - GraphTrainer - INFO - 第 3 轮训练完成
2025-12-26 20:38:09 - GraphTrainer - INFO - train_loss: 2.758068
2025-12-26 20:38:09 - GraphTrainer - INFO - precision@5: 0.003898
2025-12-26 20:38:09 - GraphTrainer - INFO - recall@5: 0.018827
2025-12-26 20:38:09 - GraphTrainer - INFO - hit_rate@5: 0.019491
2025-12-26 20:38:09 - GraphTrainer - INFO - ndcg@5: 0.012039
2025-12-26 20:38:09 - GraphTrainer - INFO - map@5: 0.009719
2025-12-26 20:38:09 - GraphTrainer - INFO - mrr@5: 0.010007
2025-12-26 20:38:09 - GraphTrainer - INFO - precision@10: 0.003235
2025-12-26 20:38:09 - GraphTrainer - INFO - recall@10: 0.030915
2025-12-26 20:38:09 - GraphTrainer - INFO - hit_rate@10: 0.032348
2025-12-26 20:38:09 - GraphTrainer - INFO - ndcg@10: 0.015928
2025-12-26 20:38:09 - GraphTrainer - INFO - map@10: 0.011265
2025-12-26 20:38:09 - GraphTrainer - INFO - mrr@10: 0.011645
2025-12-26 20:38:09 - GraphTrainer - INFO - precision@20: 0.002633
2025-12-26 20:38:09 - GraphTrainer - INFO - recall@20: 0.050161
2025-12-26 20:38:09 - GraphTrainer - INFO - hit_rate@20: 0.052558
2025-12-26 20:38:09 - GraphTrainer - INFO - ndcg@20: 0.020808
2025-12-26 20:38:09 - GraphTrainer - INFO - map@20: 0.012570
2025-12-26 20:38:09 - GraphTrainer - INFO - mrr@20: 0.013015
2025-12-26 20:38:09 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:38:09 - GraphTrainer - INFO - ============================================================
2025-12-26 20:38:09 - GraphTrainer - INFO - 开始第 4/1000 轮训练
2025-12-26 20:38:09 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(2.8055, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(2.8247, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(2.7406, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(2.8425, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(2.7427, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(2.7899, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(2.8074, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(2.8136, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(2.7957, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(2.7498, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(2.7884, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(2.7609, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(2.7854, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(2.7915, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(2.8223, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(2.7746, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(2.7749, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(2.8520, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(2.7789, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(2.8017, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(2.8152, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(2.8138, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(2.7746, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(2.7986, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(2.7720, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(2.7759, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(2.7543, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(2.7867, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(2.7473, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(2.7412, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(2.6886, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(2.7744, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(2.7153, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(2.6925, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(2.7705, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(2.7757, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(2.8072, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(2.7595, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(2.7502, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(2.7068, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(2.7420, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(2.7647, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(2.7854, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(2.7433, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(2.6792, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(2.7370, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(2.7380, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(2.7693, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(2.7521, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(2.8198, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(2.6260, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(2.7446, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(2.6634, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(2.6708, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(2.6806, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(2.6775, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(2.6976, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(2.6129, device='cuda:0', grad_fn=<AddBackward0>)
The 3 training average loss: 2.7580675256663354
2025-12-26 20:38:20 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:38:20 - GraphTrainer - INFO -   precision@5: 0.004443
2025-12-26 20:38:20 - GraphTrainer - INFO -   recall@5: 0.021350
2025-12-26 20:38:20 - GraphTrainer - INFO -   hit_rate@5: 0.022217
2025-12-26 20:38:20 - GraphTrainer - INFO -   ndcg@5: 0.013812
2025-12-26 20:38:20 - GraphTrainer - INFO -   map@5: 0.011188
2025-12-26 20:38:20 - GraphTrainer - INFO -   mrr@5: 0.011630
2025-12-26 20:38:20 - GraphTrainer - INFO -   precision@10: 0.003682
2025-12-26 20:38:20 - GraphTrainer - INFO -   recall@10: 0.034803
2025-12-26 20:38:20 - GraphTrainer - INFO -   hit_rate@10: 0.036719
2025-12-26 20:38:20 - GraphTrainer - INFO -   ndcg@10: 0.018169
2025-12-26 20:38:20 - GraphTrainer - INFO -   map@10: 0.012923
2025-12-26 20:38:20 - GraphTrainer - INFO -   mrr@10: 0.013501
2025-12-26 20:38:20 - GraphTrainer - INFO -   precision@20: 0.002870
2025-12-26 20:38:20 - GraphTrainer - INFO -   recall@20: 0.054498
2025-12-26 20:38:20 - GraphTrainer - INFO -   hit_rate@20: 0.057136
2025-12-26 20:38:20 - GraphTrainer - INFO -   ndcg@20: 0.023145
2025-12-26 20:38:20 - GraphTrainer - INFO -   map@20: 0.014255
2025-12-26 20:38:20 - GraphTrainer - INFO -   mrr@20: 0.014881
2025-12-26 20:38:20 - GraphTrainer - INFO - 第 4 轮训练完成
2025-12-26 20:38:20 - GraphTrainer - INFO - train_loss: 2.586317
2025-12-26 20:38:20 - GraphTrainer - INFO - precision@5: 0.004443
2025-12-26 20:38:20 - GraphTrainer - INFO - recall@5: 0.021350
2025-12-26 20:38:20 - GraphTrainer - INFO - hit_rate@5: 0.022217
2025-12-26 20:38:20 - GraphTrainer - INFO - ndcg@5: 0.013812
2025-12-26 20:38:20 - GraphTrainer - INFO - map@5: 0.011188
2025-12-26 20:38:20 - GraphTrainer - INFO - mrr@5: 0.011630
2025-12-26 20:38:20 - GraphTrainer - INFO - precision@10: 0.003682
2025-12-26 20:38:20 - GraphTrainer - INFO - recall@10: 0.034803
2025-12-26 20:38:20 - GraphTrainer - INFO - hit_rate@10: 0.036719
2025-12-26 20:38:20 - GraphTrainer - INFO - ndcg@10: 0.018169
2025-12-26 20:38:20 - GraphTrainer - INFO - map@10: 0.012923
2025-12-26 20:38:20 - GraphTrainer - INFO - mrr@10: 0.013501
2025-12-26 20:38:20 - GraphTrainer - INFO - precision@20: 0.002870
2025-12-26 20:38:20 - GraphTrainer - INFO - recall@20: 0.054498
2025-12-26 20:38:20 - GraphTrainer - INFO - hit_rate@20: 0.057136
2025-12-26 20:38:20 - GraphTrainer - INFO - ndcg@20: 0.023145
2025-12-26 20:38:20 - GraphTrainer - INFO - map@20: 0.014255
2025-12-26 20:38:20 - GraphTrainer - INFO - mrr@20: 0.014881
2025-12-26 20:38:20 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:38:20 - GraphTrainer - INFO - ============================================================
2025-12-26 20:38:20 - GraphTrainer - INFO - 开始第 5/1000 轮训练
2025-12-26 20:38:20 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(2.6446, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(2.5840, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(2.6191, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(2.6253, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(2.6475, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(2.6274, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(2.6499, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(2.6864, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(2.5133, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(2.6944, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(2.6685, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(2.6505, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(2.6063, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(2.6318, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(2.5983, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(2.5842, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(2.5949, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(2.5961, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(2.5961, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(2.6335, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(2.5758, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(2.6139, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(2.5891, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(2.6383, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(2.6131, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(2.6354, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(2.5750, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(2.6418, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(2.5697, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(2.6704, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(2.6149, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(2.5956, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(2.5938, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(2.6137, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(2.6422, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(2.5657, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(2.5399, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(2.5876, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(2.5486, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(2.5656, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(2.5572, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(2.6302, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(2.5351, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(2.5537, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(2.5293, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(2.5021, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(2.5594, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(2.4967, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(2.5280, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(2.4466, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(2.5224, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(2.5256, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(2.5520, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(2.5403, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(2.5669, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(2.5118, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(2.4935, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(2.5135, device='cuda:0', grad_fn=<AddBackward0>)
The 4 training average loss: 2.586316733524717
2025-12-26 20:38:31 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:38:31 - GraphTrainer - INFO -   precision@5: 0.004114
2025-12-26 20:38:31 - GraphTrainer - INFO -   recall@5: 0.019545
2025-12-26 20:38:31 - GraphTrainer - INFO -   hit_rate@5: 0.020571
2025-12-26 20:38:31 - GraphTrainer - INFO -   ndcg@5: 0.012645
2025-12-26 20:38:31 - GraphTrainer - INFO -   map@5: 0.010187
2025-12-26 20:38:31 - GraphTrainer - INFO -   mrr@5: 0.010704
2025-12-26 20:38:31 - GraphTrainer - INFO -   precision@10: 0.003343
2025-12-26 20:38:31 - GraphTrainer - INFO -   recall@10: 0.031755
2025-12-26 20:38:31 - GraphTrainer - INFO -   hit_rate@10: 0.033376
2025-12-26 20:38:31 - GraphTrainer - INFO -   ndcg@10: 0.016581
2025-12-26 20:38:31 - GraphTrainer - INFO -   map@10: 0.011767
2025-12-26 20:38:31 - GraphTrainer - INFO -   mrr@10: 0.012359
2025-12-26 20:38:31 - GraphTrainer - INFO -   precision@20: 0.002736
2025-12-26 20:38:31 - GraphTrainer - INFO -   recall@20: 0.051566
2025-12-26 20:38:31 - GraphTrainer - INFO -   hit_rate@20: 0.054410
2025-12-26 20:38:31 - GraphTrainer - INFO -   ndcg@20: 0.021621
2025-12-26 20:38:31 - GraphTrainer - INFO -   map@20: 0.013112
2025-12-26 20:38:31 - GraphTrainer - INFO -   mrr@20: 0.013783
2025-12-26 20:38:31 - GraphTrainer - INFO - 第 5 轮训练完成
2025-12-26 20:38:31 - GraphTrainer - INFO - train_loss: 2.475938
2025-12-26 20:38:31 - GraphTrainer - INFO - precision@5: 0.004114
2025-12-26 20:38:31 - GraphTrainer - INFO - recall@5: 0.019545
2025-12-26 20:38:31 - GraphTrainer - INFO - hit_rate@5: 0.020571
2025-12-26 20:38:31 - GraphTrainer - INFO - ndcg@5: 0.012645
2025-12-26 20:38:31 - GraphTrainer - INFO - map@5: 0.010187
2025-12-26 20:38:31 - GraphTrainer - INFO - mrr@5: 0.010704
2025-12-26 20:38:31 - GraphTrainer - INFO - precision@10: 0.003343
2025-12-26 20:38:31 - GraphTrainer - INFO - recall@10: 0.031755
2025-12-26 20:38:31 - GraphTrainer - INFO - hit_rate@10: 0.033376
2025-12-26 20:38:31 - GraphTrainer - INFO - ndcg@10: 0.016581
2025-12-26 20:38:31 - GraphTrainer - INFO - map@10: 0.011767
2025-12-26 20:38:31 - GraphTrainer - INFO - mrr@10: 0.012359
2025-12-26 20:38:31 - GraphTrainer - INFO - precision@20: 0.002736
2025-12-26 20:38:31 - GraphTrainer - INFO - recall@20: 0.051566
2025-12-26 20:38:31 - GraphTrainer - INFO - hit_rate@20: 0.054410
2025-12-26 20:38:31 - GraphTrainer - INFO - ndcg@20: 0.021621
2025-12-26 20:38:31 - GraphTrainer - INFO - map@20: 0.013112
2025-12-26 20:38:31 - GraphTrainer - INFO - mrr@20: 0.013783
2025-12-26 20:38:31 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:38:31 - GraphTrainer - INFO - ============================================================
2025-12-26 20:38:31 - GraphTrainer - INFO - 开始第 6/1000 轮训练
2025-12-26 20:38:31 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(2.4914, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(2.5227, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(2.4926, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(2.4226, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(2.4773, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(2.4841, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(2.4724, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(2.4628, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(2.4886, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(2.4637, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(2.4174, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(2.5194, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(2.4733, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(2.4775, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(2.4528, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(2.4578, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(2.4812, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(2.4721, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(2.5389, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(2.5028, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(2.4809, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(2.5133, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(2.4778, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(2.4952, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(2.4208, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(2.5066, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(2.5056, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(2.4412, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(2.4930, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(2.5105, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(2.5080, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(2.4975, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(2.4782, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(2.4838, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(2.4782, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(2.5471, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(2.4926, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(2.4469, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(2.4868, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(2.5178, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(2.4365, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(2.4753, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(2.4301, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(2.4814, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(2.4992, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(2.4311, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(2.4867, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(2.5415, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(2.4391, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(2.4215, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(2.4282, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(2.4603, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(2.4474, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(2.4277, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(2.4623, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(2.4748, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(2.4612, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(2.4467, device='cuda:0', grad_fn=<AddBackward0>)
The 5 training average loss: 2.475937983085369
2025-12-26 20:38:42 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:38:42 - GraphTrainer - INFO -   precision@5: 0.004340
2025-12-26 20:38:42 - GraphTrainer - INFO -   recall@5: 0.020701
2025-12-26 20:38:42 - GraphTrainer - INFO -   hit_rate@5: 0.021702
2025-12-26 20:38:42 - GraphTrainer - INFO -   ndcg@5: 0.013625
2025-12-26 20:38:42 - GraphTrainer - INFO -   map@5: 0.011126
2025-12-26 20:38:42 - GraphTrainer - INFO -   mrr@5: 0.011608
2025-12-26 20:38:42 - GraphTrainer - INFO -   precision@10: 0.003682
2025-12-26 20:38:42 - GraphTrainer - INFO -   recall@10: 0.034991
2025-12-26 20:38:42 - GraphTrainer - INFO -   hit_rate@10: 0.036770
2025-12-26 20:38:42 - GraphTrainer - INFO -   ndcg@10: 0.018240
2025-12-26 20:38:42 - GraphTrainer - INFO -   map@10: 0.012976
2025-12-26 20:38:42 - GraphTrainer - INFO -   mrr@10: 0.013569
2025-12-26 20:38:42 - GraphTrainer - INFO -   precision@20: 0.002947
2025-12-26 20:38:42 - GraphTrainer - INFO -   recall@20: 0.055886
2025-12-26 20:38:42 - GraphTrainer - INFO -   hit_rate@20: 0.058781
2025-12-26 20:38:42 - GraphTrainer - INFO -   ndcg@20: 0.023537
2025-12-26 20:38:42 - GraphTrainer - INFO -   map@20: 0.014388
2025-12-26 20:38:42 - GraphTrainer - INFO -   mrr@20: 0.015059
2025-12-26 20:38:42 - GraphTrainer - INFO - 第 6 轮训练完成
2025-12-26 20:38:42 - GraphTrainer - INFO - train_loss: 2.423394
2025-12-26 20:38:42 - GraphTrainer - INFO - precision@5: 0.004340
2025-12-26 20:38:42 - GraphTrainer - INFO - recall@5: 0.020701
2025-12-26 20:38:42 - GraphTrainer - INFO - hit_rate@5: 0.021702
2025-12-26 20:38:42 - GraphTrainer - INFO - ndcg@5: 0.013625
2025-12-26 20:38:42 - GraphTrainer - INFO - map@5: 0.011126
2025-12-26 20:38:42 - GraphTrainer - INFO - mrr@5: 0.011608
2025-12-26 20:38:42 - GraphTrainer - INFO - precision@10: 0.003682
2025-12-26 20:38:42 - GraphTrainer - INFO - recall@10: 0.034991
2025-12-26 20:38:42 - GraphTrainer - INFO - hit_rate@10: 0.036770
2025-12-26 20:38:42 - GraphTrainer - INFO - ndcg@10: 0.018240
2025-12-26 20:38:42 - GraphTrainer - INFO - map@10: 0.012976
2025-12-26 20:38:42 - GraphTrainer - INFO - mrr@10: 0.013569
2025-12-26 20:38:42 - GraphTrainer - INFO - precision@20: 0.002947
2025-12-26 20:38:42 - GraphTrainer - INFO - recall@20: 0.055886
2025-12-26 20:38:42 - GraphTrainer - INFO - hit_rate@20: 0.058781
2025-12-26 20:38:42 - GraphTrainer - INFO - ndcg@20: 0.023537
2025-12-26 20:38:42 - GraphTrainer - INFO - map@20: 0.014388
2025-12-26 20:38:42 - GraphTrainer - INFO - mrr@20: 0.015059
2025-12-26 20:38:42 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:38:42 - GraphTrainer - INFO - ============================================================
2025-12-26 20:38:42 - GraphTrainer - INFO - 开始第 7/1000 轮训练
2025-12-26 20:38:42 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(2.4049, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(2.4416, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(2.4491, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(2.5170, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(2.4543, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(2.4823, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(2.5234, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(2.4512, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(2.5070, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(2.4739, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(2.4922, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(2.4395, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(2.4751, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(2.4295, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(2.4730, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(2.3533, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(2.3640, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(2.4135, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(2.3915, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(2.4412, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(2.4021, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(2.4226, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(2.4031, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(2.4496, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(2.3633, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(2.4019, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(2.4116, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(2.4713, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(2.4055, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(2.4719, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(2.4532, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(2.4172, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(2.4250, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(2.3846, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(2.3563, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(2.4282, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(2.4721, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(2.4536, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(2.4467, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(2.3968, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(2.3897, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(2.4006, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(2.4111, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(2.4007, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(2.4111, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(2.4218, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(2.4103, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(2.4399, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(2.3846, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(2.4461, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(2.4246, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(2.3621, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(2.3732, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(2.3786, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(2.3560, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(2.3565, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(2.3808, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(2.3953, device='cuda:0', grad_fn=<AddBackward0>)
The 6 training average loss: 2.4233943182846596
2025-12-26 20:38:54 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:38:54 - GraphTrainer - INFO -   precision@5: 0.004412
2025-12-26 20:38:54 - GraphTrainer - INFO -   recall@5: 0.020926
2025-12-26 20:38:54 - GraphTrainer - INFO -   hit_rate@5: 0.022062
2025-12-26 20:38:54 - GraphTrainer - INFO -   ndcg@5: 0.013850
2025-12-26 20:38:54 - GraphTrainer - INFO -   map@5: 0.011333
2025-12-26 20:38:54 - GraphTrainer - INFO -   mrr@5: 0.011958
2025-12-26 20:38:54 - GraphTrainer - INFO -   precision@10: 0.003636
2025-12-26 20:38:54 - GraphTrainer - INFO -   recall@10: 0.034510
2025-12-26 20:38:54 - GraphTrainer - INFO -   hit_rate@10: 0.036359
2025-12-26 20:38:54 - GraphTrainer - INFO -   ndcg@10: 0.018262
2025-12-26 20:38:54 - GraphTrainer - INFO -   map@10: 0.013123
2025-12-26 20:38:54 - GraphTrainer - INFO -   mrr@10: 0.013843
2025-12-26 20:38:54 - GraphTrainer - INFO -   precision@20: 0.002942
2025-12-26 20:38:54 - GraphTrainer - INFO -   recall@20: 0.055558
2025-12-26 20:38:54 - GraphTrainer - INFO -   hit_rate@20: 0.058421
2025-12-26 20:38:54 - GraphTrainer - INFO -   ndcg@20: 0.023597
2025-12-26 20:38:54 - GraphTrainer - INFO -   map@20: 0.014547
2025-12-26 20:38:54 - GraphTrainer - INFO -   mrr@20: 0.015322
2025-12-26 20:38:54 - GraphTrainer - INFO - 第 7 轮训练完成
2025-12-26 20:38:54 - GraphTrainer - INFO - train_loss: 2.321399
2025-12-26 20:38:54 - GraphTrainer - INFO - precision@5: 0.004412
2025-12-26 20:38:54 - GraphTrainer - INFO - recall@5: 0.020926
2025-12-26 20:38:54 - GraphTrainer - INFO - hit_rate@5: 0.022062
2025-12-26 20:38:54 - GraphTrainer - INFO - ndcg@5: 0.013850
2025-12-26 20:38:54 - GraphTrainer - INFO - map@5: 0.011333
2025-12-26 20:38:54 - GraphTrainer - INFO - mrr@5: 0.011958
2025-12-26 20:38:54 - GraphTrainer - INFO - precision@10: 0.003636
2025-12-26 20:38:54 - GraphTrainer - INFO - recall@10: 0.034510
2025-12-26 20:38:54 - GraphTrainer - INFO - hit_rate@10: 0.036359
2025-12-26 20:38:54 - GraphTrainer - INFO - ndcg@10: 0.018262
2025-12-26 20:38:54 - GraphTrainer - INFO - map@10: 0.013123
2025-12-26 20:38:54 - GraphTrainer - INFO - mrr@10: 0.013843
2025-12-26 20:38:54 - GraphTrainer - INFO - precision@20: 0.002942
2025-12-26 20:38:54 - GraphTrainer - INFO - recall@20: 0.055558
2025-12-26 20:38:54 - GraphTrainer - INFO - hit_rate@20: 0.058421
2025-12-26 20:38:54 - GraphTrainer - INFO - ndcg@20: 0.023597
2025-12-26 20:38:54 - GraphTrainer - INFO - map@20: 0.014547
2025-12-26 20:38:54 - GraphTrainer - INFO - mrr@20: 0.015322
2025-12-26 20:38:54 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:38:54 - GraphTrainer - INFO - ============================================================
2025-12-26 20:38:54 - GraphTrainer - INFO - 开始第 8/1000 轮训练
2025-12-26 20:38:54 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(2.3549, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(2.4228, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(2.3358, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(2.3917, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(2.2692, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(2.3988, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(2.3113, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(2.3365, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(2.2600, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(2.3249, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(2.3812, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(2.3691, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(2.3978, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(2.3302, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(2.3352, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(2.3030, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(2.3164, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(2.3291, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(2.3139, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(2.2832, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(2.3067, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(2.2598, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(2.2579, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(2.3347, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(2.3229, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(2.2806, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(2.3956, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(2.2754, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(2.2828, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(2.2559, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(2.3118, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(2.3017, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(2.3091, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(2.3609, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(2.2446, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(2.2862, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(2.4038, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(2.3113, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(2.3046, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(2.3358, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(2.3269, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(2.3969, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(2.3537, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(2.3713, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(2.3403, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(2.4316, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(2.3557, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(2.3196, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(2.2817, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(2.2726, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(2.2545, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(2.2809, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(2.2926, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(2.2831, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(2.3395, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(2.2534, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(2.2704, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(2.3092, device='cuda:0', grad_fn=<AddBackward0>)
The 7 training average loss: 2.3213989118049883
2025-12-26 20:39:04 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:39:04 - GraphTrainer - INFO -   precision@5: 0.005153
2025-12-26 20:39:04 - GraphTrainer - INFO -   recall@5: 0.024367
2025-12-26 20:39:04 - GraphTrainer - INFO -   hit_rate@5: 0.025765
2025-12-26 20:39:04 - GraphTrainer - INFO -   ndcg@5: 0.015543
2025-12-26 20:39:04 - GraphTrainer - INFO -   map@5: 0.012421
2025-12-26 20:39:04 - GraphTrainer - INFO -   mrr@5: 0.013146
2025-12-26 20:39:04 - GraphTrainer - INFO -   precision@10: 0.004243
2025-12-26 20:39:04 - GraphTrainer - INFO -   recall@10: 0.040000
2025-12-26 20:39:04 - GraphTrainer - INFO -   hit_rate@10: 0.042325
2025-12-26 20:39:04 - GraphTrainer - INFO -   ndcg@10: 0.020626
2025-12-26 20:39:04 - GraphTrainer - INFO -   map@10: 0.014477
2025-12-26 20:39:04 - GraphTrainer - INFO -   mrr@10: 0.015322
2025-12-26 20:39:04 - GraphTrainer - INFO -   precision@20: 0.003281
2025-12-26 20:39:04 - GraphTrainer - INFO -   recall@20: 0.061821
2025-12-26 20:39:04 - GraphTrainer - INFO -   hit_rate@20: 0.065210
2025-12-26 20:39:04 - GraphTrainer - INFO -   ndcg@20: 0.026160
2025-12-26 20:39:04 - GraphTrainer - INFO -   map@20: 0.015955
2025-12-26 20:39:04 - GraphTrainer - INFO -   mrr@20: 0.016862
2025-12-26 20:39:04 - GraphTrainer - INFO - 第 8 轮训练完成
2025-12-26 20:39:04 - GraphTrainer - INFO - train_loss: 2.252300
2025-12-26 20:39:04 - GraphTrainer - INFO - precision@5: 0.005153
2025-12-26 20:39:04 - GraphTrainer - INFO - recall@5: 0.024367
2025-12-26 20:39:04 - GraphTrainer - INFO - hit_rate@5: 0.025765
2025-12-26 20:39:04 - GraphTrainer - INFO - ndcg@5: 0.015543
2025-12-26 20:39:04 - GraphTrainer - INFO - map@5: 0.012421
2025-12-26 20:39:04 - GraphTrainer - INFO - mrr@5: 0.013146
2025-12-26 20:39:04 - GraphTrainer - INFO - precision@10: 0.004243
2025-12-26 20:39:04 - GraphTrainer - INFO - recall@10: 0.040000
2025-12-26 20:39:04 - GraphTrainer - INFO - hit_rate@10: 0.042325
2025-12-26 20:39:04 - GraphTrainer - INFO - ndcg@10: 0.020626
2025-12-26 20:39:04 - GraphTrainer - INFO - map@10: 0.014477
2025-12-26 20:39:04 - GraphTrainer - INFO - mrr@10: 0.015322
2025-12-26 20:39:04 - GraphTrainer - INFO - precision@20: 0.003281
2025-12-26 20:39:04 - GraphTrainer - INFO - recall@20: 0.061821
2025-12-26 20:39:04 - GraphTrainer - INFO - hit_rate@20: 0.065210
2025-12-26 20:39:04 - GraphTrainer - INFO - ndcg@20: 0.026160
2025-12-26 20:39:04 - GraphTrainer - INFO - map@20: 0.015955
2025-12-26 20:39:04 - GraphTrainer - INFO - mrr@20: 0.016862
2025-12-26 20:39:04 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:39:04 - GraphTrainer - INFO - ============================================================
2025-12-26 20:39:04 - GraphTrainer - INFO - 开始第 9/1000 轮训练
2025-12-26 20:39:04 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(2.3069, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(2.2364, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(2.2644, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(2.2873, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(2.2859, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(2.2221, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(2.2746, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(2.3081, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(2.2766, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(2.3385, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(2.3372, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(2.2064, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(2.2656, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(2.2447, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(2.2613, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(2.2941, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(2.2006, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(2.2644, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(2.3495, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(2.3033, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(2.3659, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(2.3283, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(2.3361, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(2.2518, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(2.2498, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(2.1817, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(2.2057, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(2.2830, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(2.1877, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(2.2618, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(2.2020, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(2.2104, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(2.3156, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(2.2226, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(2.2541, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(2.2748, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(2.2331, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(2.1892, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(2.2670, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(2.2637, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(2.1663, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(2.2588, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(2.2318, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(2.2774, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(2.2754, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(2.2718, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(2.1631, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(2.2382, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(2.1637, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(2.2313, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(2.2697, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(2.2460, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(2.1846, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(2.2242, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(2.2314, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(2.1631, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(2.2621, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(2.1624, device='cuda:0', grad_fn=<AddBackward0>)
The 8 training average loss: 2.2523004638737647
2025-12-26 20:39:15 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:39:15 - GraphTrainer - INFO -   precision@5: 0.005235
2025-12-26 20:39:15 - GraphTrainer - INFO -   recall@5: 0.024662
2025-12-26 20:39:15 - GraphTrainer - INFO -   hit_rate@5: 0.026176
2025-12-26 20:39:15 - GraphTrainer - INFO -   ndcg@5: 0.016109
2025-12-26 20:39:15 - GraphTrainer - INFO -   map@5: 0.013036
2025-12-26 20:39:15 - GraphTrainer - INFO -   mrr@5: 0.013818
2025-12-26 20:39:15 - GraphTrainer - INFO -   precision@10: 0.004212
2025-12-26 20:39:15 - GraphTrainer - INFO -   recall@10: 0.039379
2025-12-26 20:39:15 - GraphTrainer - INFO -   hit_rate@10: 0.041913
2025-12-26 20:39:15 - GraphTrainer - INFO -   ndcg@10: 0.020910
2025-12-26 20:39:15 - GraphTrainer - INFO -   map@10: 0.014974
2025-12-26 20:39:15 - GraphTrainer - INFO -   mrr@10: 0.015886
2025-12-26 20:39:15 - GraphTrainer - INFO -   precision@20: 0.003260
2025-12-26 20:39:15 - GraphTrainer - INFO -   recall@20: 0.061158
2025-12-26 20:39:15 - GraphTrainer - INFO -   hit_rate@20: 0.064747
2025-12-26 20:39:15 - GraphTrainer - INFO -   ndcg@20: 0.026447
2025-12-26 20:39:15 - GraphTrainer - INFO -   map@20: 0.016464
2025-12-26 20:39:15 - GraphTrainer - INFO -   mrr@20: 0.017438
2025-12-26 20:39:15 - GraphTrainer - INFO - 第 9 轮训练完成
2025-12-26 20:39:15 - GraphTrainer - INFO - train_loss: 2.194633
2025-12-26 20:39:15 - GraphTrainer - INFO - precision@5: 0.005235
2025-12-26 20:39:15 - GraphTrainer - INFO - recall@5: 0.024662
2025-12-26 20:39:15 - GraphTrainer - INFO - hit_rate@5: 0.026176
2025-12-26 20:39:15 - GraphTrainer - INFO - ndcg@5: 0.016109
2025-12-26 20:39:15 - GraphTrainer - INFO - map@5: 0.013036
2025-12-26 20:39:15 - GraphTrainer - INFO - mrr@5: 0.013818
2025-12-26 20:39:15 - GraphTrainer - INFO - precision@10: 0.004212
2025-12-26 20:39:15 - GraphTrainer - INFO - recall@10: 0.039379
2025-12-26 20:39:15 - GraphTrainer - INFO - hit_rate@10: 0.041913
2025-12-26 20:39:15 - GraphTrainer - INFO - ndcg@10: 0.020910
2025-12-26 20:39:15 - GraphTrainer - INFO - map@10: 0.014974
2025-12-26 20:39:15 - GraphTrainer - INFO - mrr@10: 0.015886
2025-12-26 20:39:15 - GraphTrainer - INFO - precision@20: 0.003260
2025-12-26 20:39:15 - GraphTrainer - INFO - recall@20: 0.061158
2025-12-26 20:39:15 - GraphTrainer - INFO - hit_rate@20: 0.064747
2025-12-26 20:39:15 - GraphTrainer - INFO - ndcg@20: 0.026447
2025-12-26 20:39:15 - GraphTrainer - INFO - map@20: 0.016464
2025-12-26 20:39:15 - GraphTrainer - INFO - mrr@20: 0.017438
2025-12-26 20:39:15 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:39:15 - GraphTrainer - INFO - ============================================================
2025-12-26 20:39:15 - GraphTrainer - INFO - 开始第 10/1000 轮训练
2025-12-26 20:39:15 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(2.1969, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(2.2009, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(2.1925, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(2.1716, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(2.1720, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(2.2085, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(2.1576, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(2.2953, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(2.2734, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(2.1872, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(2.2807, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(2.2328, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(2.1755, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(2.1977, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(2.2759, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(2.2441, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(2.2382, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(2.3448, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(2.2871, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(2.2987, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(2.2426, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(2.2241, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(2.1879, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(2.1142, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(2.1795, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(2.2080, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(2.2355, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(2.2504, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(2.1813, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(2.2235, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(2.1837, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(2.1680, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(2.2263, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(2.1980, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(2.1294, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(2.1519, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(2.1732, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(2.1956, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(2.0836, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(2.1838, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(2.2689, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(2.1432, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(2.1002, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(2.2165, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(2.1780, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(2.1942, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(2.1722, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(2.1885, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(2.1220, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(2.1685, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(2.1965, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(2.1514, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(2.1380, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(2.1729, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(2.1523, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(2.1636, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(2.1296, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(2.0602, device='cuda:0', grad_fn=<AddBackward0>)
The 9 training average loss: 2.194633414005411
2025-12-26 20:39:25 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:39:25 - GraphTrainer - INFO -   precision@5: 0.004927
2025-12-26 20:39:25 - GraphTrainer - INFO -   recall@5: 0.022944
2025-12-26 20:39:25 - GraphTrainer - INFO -   hit_rate@5: 0.024634
2025-12-26 20:39:25 - GraphTrainer - INFO -   ndcg@5: 0.015451
2025-12-26 20:39:25 - GraphTrainer - INFO -   map@5: 0.012667
2025-12-26 20:39:25 - GraphTrainer - INFO -   mrr@5: 0.013606
2025-12-26 20:39:25 - GraphTrainer - INFO -   precision@10: 0.003996
2025-12-26 20:39:25 - GraphTrainer - INFO -   recall@10: 0.037417
2025-12-26 20:39:25 - GraphTrainer - INFO -   hit_rate@10: 0.039805
2025-12-26 20:39:25 - GraphTrainer - INFO -   ndcg@10: 0.020145
2025-12-26 20:39:25 - GraphTrainer - INFO -   map@10: 0.014571
2025-12-26 20:39:25 - GraphTrainer - INFO -   mrr@10: 0.015598
2025-12-26 20:39:25 - GraphTrainer - INFO -   precision@20: 0.003299
2025-12-26 20:39:25 - GraphTrainer - INFO -   recall@20: 0.061951
2025-12-26 20:39:25 - GraphTrainer - INFO -   hit_rate@20: 0.065518
2025-12-26 20:39:25 - GraphTrainer - INFO -   ndcg@20: 0.026402
2025-12-26 20:39:25 - GraphTrainer - INFO -   map@20: 0.016263
2025-12-26 20:39:25 - GraphTrainer - INFO -   mrr@20: 0.017358
2025-12-26 20:39:25 - GraphTrainer - INFO - 第 10 轮训练完成
2025-12-26 20:39:25 - GraphTrainer - INFO - train_loss: 2.088917
2025-12-26 20:39:25 - GraphTrainer - INFO - precision@5: 0.004927
2025-12-26 20:39:25 - GraphTrainer - INFO - recall@5: 0.022944
2025-12-26 20:39:25 - GraphTrainer - INFO - hit_rate@5: 0.024634
2025-12-26 20:39:25 - GraphTrainer - INFO - ndcg@5: 0.015451
2025-12-26 20:39:25 - GraphTrainer - INFO - map@5: 0.012667
2025-12-26 20:39:25 - GraphTrainer - INFO - mrr@5: 0.013606
2025-12-26 20:39:25 - GraphTrainer - INFO - precision@10: 0.003996
2025-12-26 20:39:25 - GraphTrainer - INFO - recall@10: 0.037417
2025-12-26 20:39:25 - GraphTrainer - INFO - hit_rate@10: 0.039805
2025-12-26 20:39:25 - GraphTrainer - INFO - ndcg@10: 0.020145
2025-12-26 20:39:25 - GraphTrainer - INFO - map@10: 0.014571
2025-12-26 20:39:25 - GraphTrainer - INFO - mrr@10: 0.015598
2025-12-26 20:39:25 - GraphTrainer - INFO - precision@20: 0.003299
2025-12-26 20:39:25 - GraphTrainer - INFO - recall@20: 0.061951
2025-12-26 20:39:25 - GraphTrainer - INFO - hit_rate@20: 0.065518
2025-12-26 20:39:25 - GraphTrainer - INFO - ndcg@20: 0.026402
2025-12-26 20:39:25 - GraphTrainer - INFO - map@20: 0.016263
2025-12-26 20:39:25 - GraphTrainer - INFO - mrr@20: 0.017358
2025-12-26 20:39:25 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:39:25 - GraphTrainer - INFO - 检查点已保存: Epoch 10 -> ./checkpoints/checkpoint_epoch_10.pth
2025-12-26 20:39:25 - GraphTrainer - INFO - ============================================================
2025-12-26 20:39:25 - GraphTrainer - INFO - 开始第 11/1000 轮训练
2025-12-26 20:39:25 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(2.0894, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(2.1530, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(2.0916, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(2.2202, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(2.0727, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(2.1307, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(2.1086, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(2.1432, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(2.1511, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(2.1109, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(2.1417, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(2.0913, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(2.1382, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(2.0380, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(2.2006, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(2.1510, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(2.1022, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(2.1064, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(2.0701, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(2.0694, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(2.1076, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(2.0918, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(2.0892, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(2.0585, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(2.1095, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(2.0413, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(2.0558, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(2.1701, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(2.0671, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(2.1612, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(2.1484, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(2.0595, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(2.0441, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(2.1262, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(2.0625, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(2.0434, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(2.0706, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(2.0636, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(2.1283, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(2.0988, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(2.0089, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(2.0840, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(2.0604, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(2.0019, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(2.0388, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(2.0835, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(2.0684, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(2.0685, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(2.1281, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(2.0433, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(2.0844, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(2.0558, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(2.0851, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(2.0605, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(2.0354, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(2.0431, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(2.0049, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(2.0243, device='cuda:0', grad_fn=<AddBackward0>)
The 10 training average loss: 2.0889167333471366
2025-12-26 20:39:36 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:39:36 - GraphTrainer - INFO -   precision@5: 0.004474
2025-12-26 20:39:36 - GraphTrainer - INFO -   recall@5: 0.020745
2025-12-26 20:39:36 - GraphTrainer - INFO -   hit_rate@5: 0.022319
2025-12-26 20:39:36 - GraphTrainer - INFO -   ndcg@5: 0.013793
2025-12-26 20:39:36 - GraphTrainer - INFO -   map@5: 0.011202
2025-12-26 20:39:36 - GraphTrainer - INFO -   mrr@5: 0.012097
2025-12-26 20:39:36 - GraphTrainer - INFO -   precision@10: 0.003770
2025-12-26 20:39:36 - GraphTrainer - INFO -   recall@10: 0.035390
2025-12-26 20:39:36 - GraphTrainer - INFO -   hit_rate@10: 0.037593
2025-12-26 20:39:36 - GraphTrainer - INFO -   ndcg@10: 0.018526
2025-12-26 20:39:36 - GraphTrainer - INFO -   map@10: 0.013119
2025-12-26 20:39:36 - GraphTrainer - INFO -   mrr@10: 0.014095
2025-12-26 20:39:36 - GraphTrainer - INFO -   precision@20: 0.003124
2025-12-26 20:39:36 - GraphTrainer - INFO -   recall@20: 0.058873
2025-12-26 20:39:36 - GraphTrainer - INFO -   hit_rate@20: 0.062278
2025-12-26 20:39:36 - GraphTrainer - INFO -   ndcg@20: 0.024480
2025-12-26 20:39:36 - GraphTrainer - INFO -   map@20: 0.014711
2025-12-26 20:39:36 - GraphTrainer - INFO -   mrr@20: 0.015765
2025-12-26 20:39:36 - GraphTrainer - INFO - 第 11 轮训练完成
2025-12-26 20:39:36 - GraphTrainer - INFO - train_loss: 1.991126
2025-12-26 20:39:36 - GraphTrainer - INFO - precision@5: 0.004474
2025-12-26 20:39:36 - GraphTrainer - INFO - recall@5: 0.020745
2025-12-26 20:39:36 - GraphTrainer - INFO - hit_rate@5: 0.022319
2025-12-26 20:39:36 - GraphTrainer - INFO - ndcg@5: 0.013793
2025-12-26 20:39:36 - GraphTrainer - INFO - map@5: 0.011202
2025-12-26 20:39:36 - GraphTrainer - INFO - mrr@5: 0.012097
2025-12-26 20:39:36 - GraphTrainer - INFO - precision@10: 0.003770
2025-12-26 20:39:36 - GraphTrainer - INFO - recall@10: 0.035390
2025-12-26 20:39:36 - GraphTrainer - INFO - hit_rate@10: 0.037593
2025-12-26 20:39:36 - GraphTrainer - INFO - ndcg@10: 0.018526
2025-12-26 20:39:36 - GraphTrainer - INFO - map@10: 0.013119
2025-12-26 20:39:36 - GraphTrainer - INFO - mrr@10: 0.014095
2025-12-26 20:39:36 - GraphTrainer - INFO - precision@20: 0.003124
2025-12-26 20:39:36 - GraphTrainer - INFO - recall@20: 0.058873
2025-12-26 20:39:36 - GraphTrainer - INFO - hit_rate@20: 0.062278
2025-12-26 20:39:36 - GraphTrainer - INFO - ndcg@20: 0.024480
2025-12-26 20:39:36 - GraphTrainer - INFO - map@20: 0.014711
2025-12-26 20:39:36 - GraphTrainer - INFO - mrr@20: 0.015765
2025-12-26 20:39:36 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:39:36 - GraphTrainer - INFO - ============================================================
2025-12-26 20:39:36 - GraphTrainer - INFO - 开始第 12/1000 轮训练
2025-12-26 20:39:36 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(2.0357, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(2.0388, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(2.0726, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(1.9983, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(2.0066, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(2.0751, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(1.9988, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(1.9625, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(2.1042, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(1.9816, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(2.0157, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(1.9565, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(2.0368, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(2.0020, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(1.9647, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(2.0033, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(2.0158, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(1.9858, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(2.0207, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(1.9941, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(2.0359, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(2.0202, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(1.9984, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(1.9540, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(2.0573, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(2.0164, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(1.9760, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(1.9767, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(1.9814, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(1.9891, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(1.9762, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(2.0188, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(1.9569, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(1.9986, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(2.0060, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(1.9594, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(1.9571, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(1.9684, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(2.0111, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(1.9386, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(1.9663, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(2.0116, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(1.9827, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(2.0244, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(1.9245, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(1.9808, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(1.9245, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(1.9480, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(1.9576, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(1.9483, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(2.0269, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(1.9963, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(1.9311, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(1.9330, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(1.9506, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(1.9674, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(1.9831, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(1.9620, device='cuda:0', grad_fn=<AddBackward0>)
The 11 training average loss: 1.9911262064144528
2025-12-26 20:39:46 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:39:46 - GraphTrainer - INFO -   precision@5: 0.004762
2025-12-26 20:39:46 - GraphTrainer - INFO -   recall@5: 0.022080
2025-12-26 20:39:46 - GraphTrainer - INFO -   hit_rate@5: 0.023759
2025-12-26 20:39:46 - GraphTrainer - INFO -   ndcg@5: 0.014576
2025-12-26 20:39:46 - GraphTrainer - INFO -   map@5: 0.011828
2025-12-26 20:39:46 - GraphTrainer - INFO -   mrr@5: 0.012645
2025-12-26 20:39:46 - GraphTrainer - INFO -   precision@10: 0.003775
2025-12-26 20:39:46 - GraphTrainer - INFO -   recall@10: 0.035344
2025-12-26 20:39:46 - GraphTrainer - INFO -   hit_rate@10: 0.037593
2025-12-26 20:39:46 - GraphTrainer - INFO -   ndcg@10: 0.018878
2025-12-26 20:39:46 - GraphTrainer - INFO -   map@10: 0.013576
2025-12-26 20:39:46 - GraphTrainer - INFO -   mrr@10: 0.014465
2025-12-26 20:39:46 - GraphTrainer - INFO -   precision@20: 0.003160
2025-12-26 20:39:46 - GraphTrainer - INFO -   recall@20: 0.059122
2025-12-26 20:39:46 - GraphTrainer - INFO -   hit_rate@20: 0.062792
2025-12-26 20:39:46 - GraphTrainer - INFO -   ndcg@20: 0.024900
2025-12-26 20:39:46 - GraphTrainer - INFO -   map@20: 0.015172
2025-12-26 20:39:46 - GraphTrainer - INFO -   mrr@20: 0.016156
2025-12-26 20:39:46 - GraphTrainer - INFO - 第 12 轮训练完成
2025-12-26 20:39:46 - GraphTrainer - INFO - train_loss: 1.914604
2025-12-26 20:39:46 - GraphTrainer - INFO - precision@5: 0.004762
2025-12-26 20:39:46 - GraphTrainer - INFO - recall@5: 0.022080
2025-12-26 20:39:46 - GraphTrainer - INFO - hit_rate@5: 0.023759
2025-12-26 20:39:46 - GraphTrainer - INFO - ndcg@5: 0.014576
2025-12-26 20:39:46 - GraphTrainer - INFO - map@5: 0.011828
2025-12-26 20:39:46 - GraphTrainer - INFO - mrr@5: 0.012645
2025-12-26 20:39:46 - GraphTrainer - INFO - precision@10: 0.003775
2025-12-26 20:39:46 - GraphTrainer - INFO - recall@10: 0.035344
2025-12-26 20:39:46 - GraphTrainer - INFO - hit_rate@10: 0.037593
2025-12-26 20:39:46 - GraphTrainer - INFO - ndcg@10: 0.018878
2025-12-26 20:39:46 - GraphTrainer - INFO - map@10: 0.013576
2025-12-26 20:39:46 - GraphTrainer - INFO - mrr@10: 0.014465
2025-12-26 20:39:46 - GraphTrainer - INFO - precision@20: 0.003160
2025-12-26 20:39:46 - GraphTrainer - INFO - recall@20: 0.059122
2025-12-26 20:39:46 - GraphTrainer - INFO - hit_rate@20: 0.062792
2025-12-26 20:39:46 - GraphTrainer - INFO - ndcg@20: 0.024900
2025-12-26 20:39:46 - GraphTrainer - INFO - map@20: 0.015172
2025-12-26 20:39:46 - GraphTrainer - INFO - mrr@20: 0.016156
2025-12-26 20:39:46 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:39:46 - GraphTrainer - INFO - ============================================================
2025-12-26 20:39:46 - GraphTrainer - INFO - 开始第 13/1000 轮训练
2025-12-26 20:39:46 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(1.9771, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(1.9307, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(1.8744, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(1.9479, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(1.9496, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(1.9547, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(1.9308, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(1.9505, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(1.9391, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(1.9149, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(1.8793, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(1.8563, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(1.9070, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(1.9231, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(1.9395, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(1.8757, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(1.9666, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(1.8944, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(1.9448, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(1.9429, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(1.9184, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(1.8795, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(1.9282, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(1.8983, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(1.8895, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(1.9163, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(1.8952, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(1.8416, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(1.9296, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(1.8773, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(1.8876, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(1.9354, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(1.9966, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(1.8711, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(1.9349, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(1.9495, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(1.9507, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(1.9118, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(1.9094, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(1.8798, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(1.8646, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(1.9232, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(1.9495, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(1.8302, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(1.8457, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(1.8853, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(1.9463, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(1.8907, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(1.9857, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(1.9369, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(1.9316, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(1.9442, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(1.8544, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(1.8884, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(1.9698, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(1.9125, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(1.8747, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(1.9135, device='cuda:0', grad_fn=<AddBackward0>)
The 12 training average loss: 1.914603942427142
2025-12-26 20:39:57 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:39:57 - GraphTrainer - INFO -   precision@5: 0.004659
2025-12-26 20:39:57 - GraphTrainer - INFO -   recall@5: 0.021840
2025-12-26 20:39:57 - GraphTrainer - INFO -   hit_rate@5: 0.023245
2025-12-26 20:39:57 - GraphTrainer - INFO -   ndcg@5: 0.014590
2025-12-26 20:39:57 - GraphTrainer - INFO -   map@5: 0.011955
2025-12-26 20:39:57 - GraphTrainer - INFO -   mrr@5: 0.012694
2025-12-26 20:39:57 - GraphTrainer - INFO -   precision@10: 0.003883
2025-12-26 20:39:57 - GraphTrainer - INFO -   recall@10: 0.036537
2025-12-26 20:39:57 - GraphTrainer - INFO -   hit_rate@10: 0.038776
2025-12-26 20:39:57 - GraphTrainer - INFO -   ndcg@10: 0.019322
2025-12-26 20:39:57 - GraphTrainer - INFO -   map@10: 0.013848
2025-12-26 20:39:57 - GraphTrainer - INFO -   mrr@10: 0.014696
2025-12-26 20:39:57 - GraphTrainer - INFO -   precision@20: 0.003176
2025-12-26 20:39:57 - GraphTrainer - INFO -   recall@20: 0.059870
2025-12-26 20:39:57 - GraphTrainer - INFO -   hit_rate@20: 0.063307
2025-12-26 20:39:57 - GraphTrainer - INFO -   ndcg@20: 0.025261
2025-12-26 20:39:57 - GraphTrainer - INFO -   map@20: 0.015445
2025-12-26 20:39:57 - GraphTrainer - INFO -   mrr@20: 0.016369
2025-12-26 20:39:57 - GraphTrainer - INFO - 第 13 轮训练完成
2025-12-26 20:39:57 - GraphTrainer - INFO - train_loss: 1.875621
2025-12-26 20:39:57 - GraphTrainer - INFO - precision@5: 0.004659
2025-12-26 20:39:57 - GraphTrainer - INFO - recall@5: 0.021840
2025-12-26 20:39:57 - GraphTrainer - INFO - hit_rate@5: 0.023245
2025-12-26 20:39:57 - GraphTrainer - INFO - ndcg@5: 0.014590
2025-12-26 20:39:57 - GraphTrainer - INFO - map@5: 0.011955
2025-12-26 20:39:57 - GraphTrainer - INFO - mrr@5: 0.012694
2025-12-26 20:39:57 - GraphTrainer - INFO - precision@10: 0.003883
2025-12-26 20:39:57 - GraphTrainer - INFO - recall@10: 0.036537
2025-12-26 20:39:57 - GraphTrainer - INFO - hit_rate@10: 0.038776
2025-12-26 20:39:57 - GraphTrainer - INFO - ndcg@10: 0.019322
2025-12-26 20:39:57 - GraphTrainer - INFO - map@10: 0.013848
2025-12-26 20:39:57 - GraphTrainer - INFO - mrr@10: 0.014696
2025-12-26 20:39:57 - GraphTrainer - INFO - precision@20: 0.003176
2025-12-26 20:39:57 - GraphTrainer - INFO - recall@20: 0.059870
2025-12-26 20:39:57 - GraphTrainer - INFO - hit_rate@20: 0.063307
2025-12-26 20:39:57 - GraphTrainer - INFO - ndcg@20: 0.025261
2025-12-26 20:39:57 - GraphTrainer - INFO - map@20: 0.015445
2025-12-26 20:39:57 - GraphTrainer - INFO - mrr@20: 0.016369
2025-12-26 20:39:57 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:39:57 - GraphTrainer - INFO - ============================================================
2025-12-26 20:39:57 - GraphTrainer - INFO - 开始第 14/1000 轮训练
2025-12-26 20:39:57 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(1.8194, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(1.8749, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(1.8828, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(1.9419, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(1.8582, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(1.8442, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(1.8455, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(1.8527, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(1.8734, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(1.9017, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(1.8579, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(1.9108, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(1.8636, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(1.8797, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(1.8998, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(1.8618, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(1.8719, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(1.8679, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(1.9015, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(1.8431, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(1.8027, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(1.8645, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(1.8676, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(1.9200, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(1.8805, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(1.8667, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(1.8825, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(1.9421, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(1.9230, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(1.9095, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(1.8906, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(1.9248, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(1.8254, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(1.8444, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(1.8716, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(1.8652, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(1.8948, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(1.8965, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(1.8695, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(1.9528, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(1.9271, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(1.8541, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(1.8751, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(1.9703, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(1.8833, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(1.8715, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(1.8821, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(1.8644, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(1.8395, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(1.8194, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(1.8937, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(1.8880, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(1.8383, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(1.8675, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(1.8563, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(1.7982, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(1.8677, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(1.8423, device='cuda:0', grad_fn=<AddBackward0>)
The 13 training average loss: 1.8756208563673085
2025-12-26 20:40:07 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:40:07 - GraphTrainer - INFO -   precision@5: 0.005410
2025-12-26 20:40:07 - GraphTrainer - INFO -   recall@5: 0.025506
2025-12-26 20:40:07 - GraphTrainer - INFO -   hit_rate@5: 0.026999
2025-12-26 20:40:07 - GraphTrainer - INFO -   ndcg@5: 0.016378
2025-12-26 20:40:07 - GraphTrainer - INFO -   map@5: 0.013153
2025-12-26 20:40:07 - GraphTrainer - INFO -   mrr@5: 0.013856
2025-12-26 20:40:07 - GraphTrainer - INFO -   precision@10: 0.004346
2025-12-26 20:40:07 - GraphTrainer - INFO -   recall@10: 0.040946
2025-12-26 20:40:07 - GraphTrainer - INFO -   hit_rate@10: 0.043250
2025-12-26 20:40:07 - GraphTrainer - INFO -   ndcg@10: 0.021395
2025-12-26 20:40:07 - GraphTrainer - INFO -   map@10: 0.015185
2025-12-26 20:40:07 - GraphTrainer - INFO -   mrr@10: 0.015994
2025-12-26 20:40:07 - GraphTrainer - INFO -   precision@20: 0.003451
2025-12-26 20:40:07 - GraphTrainer - INFO -   recall@20: 0.065055
2025-12-26 20:40:07 - GraphTrainer - INFO -   hit_rate@20: 0.068552
2025-12-26 20:40:07 - GraphTrainer - INFO -   ndcg@20: 0.027521
2025-12-26 20:40:07 - GraphTrainer - INFO -   map@20: 0.016829
2025-12-26 20:40:07 - GraphTrainer - INFO -   mrr@20: 0.017713
2025-12-26 20:40:07 - GraphTrainer - INFO - 第 14 轮训练完成
2025-12-26 20:40:07 - GraphTrainer - INFO - train_loss: 1.807312
2025-12-26 20:40:07 - GraphTrainer - INFO - precision@5: 0.005410
2025-12-26 20:40:07 - GraphTrainer - INFO - recall@5: 0.025506
2025-12-26 20:40:07 - GraphTrainer - INFO - hit_rate@5: 0.026999
2025-12-26 20:40:07 - GraphTrainer - INFO - ndcg@5: 0.016378
2025-12-26 20:40:07 - GraphTrainer - INFO - map@5: 0.013153
2025-12-26 20:40:07 - GraphTrainer - INFO - mrr@5: 0.013856
2025-12-26 20:40:07 - GraphTrainer - INFO - precision@10: 0.004346
2025-12-26 20:40:07 - GraphTrainer - INFO - recall@10: 0.040946
2025-12-26 20:40:07 - GraphTrainer - INFO - hit_rate@10: 0.043250
2025-12-26 20:40:07 - GraphTrainer - INFO - ndcg@10: 0.021395
2025-12-26 20:40:07 - GraphTrainer - INFO - map@10: 0.015185
2025-12-26 20:40:07 - GraphTrainer - INFO - mrr@10: 0.015994
2025-12-26 20:40:07 - GraphTrainer - INFO - precision@20: 0.003451
2025-12-26 20:40:07 - GraphTrainer - INFO - recall@20: 0.065055
2025-12-26 20:40:07 - GraphTrainer - INFO - hit_rate@20: 0.068552
2025-12-26 20:40:07 - GraphTrainer - INFO - ndcg@20: 0.027521
2025-12-26 20:40:07 - GraphTrainer - INFO - map@20: 0.016829
2025-12-26 20:40:07 - GraphTrainer - INFO - mrr@20: 0.017713
2025-12-26 20:40:07 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:40:07 - GraphTrainer - INFO - ============================================================
2025-12-26 20:40:07 - GraphTrainer - INFO - 开始第 15/1000 轮训练
2025-12-26 20:40:07 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(1.8060, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(1.8138, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(1.8912, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(1.8454, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(1.7873, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(1.7625, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(1.7834, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(1.8114, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(1.8438, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(1.8362, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(1.8624, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(1.7716, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(1.8755, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(1.8779, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(1.7978, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(1.7976, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(1.8329, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(1.8847, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(1.8612, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(1.8142, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(1.7925, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(1.8034, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(1.7601, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(1.8321, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(1.7829, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(1.8513, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(1.8119, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(1.7792, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(1.7772, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(1.8191, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(1.8197, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(1.7418, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(1.8498, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(1.7982, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(1.7488, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(1.8616, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(1.8450, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(1.8216, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(1.8086, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(1.7290, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(1.7919, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(1.7758, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(1.8208, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(1.7942, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(1.7706, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(1.7447, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(1.7669, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(1.8607, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(1.7824, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(1.7558, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(1.7824, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(1.8409, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(1.8210, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(1.8330, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(1.7823, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(1.8309, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(1.7617, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(1.7172, device='cuda:0', grad_fn=<AddBackward0>)
The 14 training average loss: 1.8073121597026955
2025-12-26 20:40:18 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:40:18 - GraphTrainer - INFO -   precision@5: 0.004958
2025-12-26 20:40:18 - GraphTrainer - INFO -   recall@5: 0.023540
2025-12-26 20:40:18 - GraphTrainer - INFO -   hit_rate@5: 0.024788
2025-12-26 20:40:18 - GraphTrainer - INFO -   ndcg@5: 0.015217
2025-12-26 20:40:18 - GraphTrainer - INFO -   map@5: 0.012268
2025-12-26 20:40:18 - GraphTrainer - INFO -   mrr@5: 0.012981
2025-12-26 20:40:18 - GraphTrainer - INFO -   precision@10: 0.003934
2025-12-26 20:40:18 - GraphTrainer - INFO -   recall@10: 0.037082
2025-12-26 20:40:18 - GraphTrainer - INFO -   hit_rate@10: 0.039136
2025-12-26 20:40:18 - GraphTrainer - INFO -   ndcg@10: 0.019628
2025-12-26 20:40:18 - GraphTrainer - INFO -   map@10: 0.014054
2025-12-26 20:40:18 - GraphTrainer - INFO -   mrr@10: 0.014861
2025-12-26 20:40:18 - GraphTrainer - INFO -   precision@20: 0.003178
2025-12-26 20:40:18 - GraphTrainer - INFO -   recall@20: 0.059988
2025-12-26 20:40:18 - GraphTrainer - INFO -   hit_rate@20: 0.063101
2025-12-26 20:40:18 - GraphTrainer - INFO -   ndcg@20: 0.025448
2025-12-26 20:40:18 - GraphTrainer - INFO -   map@20: 0.015617
2025-12-26 20:40:18 - GraphTrainer - INFO -   mrr@20: 0.016491
2025-12-26 20:40:18 - GraphTrainer - INFO - 第 15 轮训练完成
2025-12-26 20:40:18 - GraphTrainer - INFO - train_loss: 1.762653
2025-12-26 20:40:18 - GraphTrainer - INFO - precision@5: 0.004958
2025-12-26 20:40:18 - GraphTrainer - INFO - recall@5: 0.023540
2025-12-26 20:40:18 - GraphTrainer - INFO - hit_rate@5: 0.024788
2025-12-26 20:40:18 - GraphTrainer - INFO - ndcg@5: 0.015217
2025-12-26 20:40:18 - GraphTrainer - INFO - map@5: 0.012268
2025-12-26 20:40:18 - GraphTrainer - INFO - mrr@5: 0.012981
2025-12-26 20:40:18 - GraphTrainer - INFO - precision@10: 0.003934
2025-12-26 20:40:18 - GraphTrainer - INFO - recall@10: 0.037082
2025-12-26 20:40:18 - GraphTrainer - INFO - hit_rate@10: 0.039136
2025-12-26 20:40:18 - GraphTrainer - INFO - ndcg@10: 0.019628
2025-12-26 20:40:18 - GraphTrainer - INFO - map@10: 0.014054
2025-12-26 20:40:18 - GraphTrainer - INFO - mrr@10: 0.014861
2025-12-26 20:40:18 - GraphTrainer - INFO - precision@20: 0.003178
2025-12-26 20:40:18 - GraphTrainer - INFO - recall@20: 0.059988
2025-12-26 20:40:18 - GraphTrainer - INFO - hit_rate@20: 0.063101
2025-12-26 20:40:18 - GraphTrainer - INFO - ndcg@20: 0.025448
2025-12-26 20:40:18 - GraphTrainer - INFO - map@20: 0.015617
2025-12-26 20:40:18 - GraphTrainer - INFO - mrr@20: 0.016491
2025-12-26 20:40:18 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:40:18 - GraphTrainer - INFO - ============================================================
2025-12-26 20:40:18 - GraphTrainer - INFO - 开始第 16/1000 轮训练
2025-12-26 20:40:18 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(1.7436, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(1.7503, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(1.7970, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(1.7994, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(1.7784, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(1.8792, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(1.8192, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(1.6956, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(1.7989, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(1.8401, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(1.7804, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(1.7766, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(1.7373, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(1.7564, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(1.7613, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(1.7542, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(1.7495, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(1.7646, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(1.7925, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(1.6724, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(1.8512, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(1.8848, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(1.7814, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(1.8020, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(1.7524, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(1.7518, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(1.7307, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(1.7672, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(1.7116, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(1.7513, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(1.7438, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(1.7715, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(1.7137, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(1.7901, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(1.7777, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(1.7528, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(1.7255, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(1.6833, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(1.8332, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(1.7394, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(1.7911, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(1.7242, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(1.7421, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(1.8073, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(1.7465, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(1.7111, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(1.7163, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(1.7214, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(1.7847, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(1.7213, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(1.7656, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(1.7341, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(1.8082, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(1.7539, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(1.6921, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(1.7169, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(1.7969, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(1.7376, device='cuda:0', grad_fn=<AddBackward0>)
The 15 training average loss: 1.7626530898028407
2025-12-26 20:40:28 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:40:28 - GraphTrainer - INFO -   precision@5: 0.005451
2025-12-26 20:40:28 - GraphTrainer - INFO -   recall@5: 0.025931
2025-12-26 20:40:28 - GraphTrainer - INFO -   hit_rate@5: 0.027256
2025-12-26 20:40:28 - GraphTrainer - INFO -   ndcg@5: 0.017105
2025-12-26 20:40:28 - GraphTrainer - INFO -   map@5: 0.013993
2025-12-26 20:40:28 - GraphTrainer - INFO -   mrr@5: 0.014653
2025-12-26 20:40:28 - GraphTrainer - INFO -   precision@10: 0.004526
2025-12-26 20:40:28 - GraphTrainer - INFO -   recall@10: 0.042752
2025-12-26 20:40:28 - GraphTrainer - INFO -   hit_rate@10: 0.045102
2025-12-26 20:40:28 - GraphTrainer - INFO -   ndcg@10: 0.022580
2025-12-26 20:40:28 - GraphTrainer - INFO -   map@10: 0.016203
2025-12-26 20:40:28 - GraphTrainer - INFO -   mrr@10: 0.016993
2025-12-26 20:40:28 - GraphTrainer - INFO -   precision@20: 0.003476
2025-12-26 20:40:28 - GraphTrainer - INFO -   recall@20: 0.065742
2025-12-26 20:40:28 - GraphTrainer - INFO -   hit_rate@20: 0.069015
2025-12-26 20:40:28 - GraphTrainer - INFO -   ndcg@20: 0.028423
2025-12-26 20:40:28 - GraphTrainer - INFO -   map@20: 0.017777
2025-12-26 20:40:28 - GraphTrainer - INFO -   mrr@20: 0.018622
2025-12-26 20:40:28 - GraphTrainer - INFO - 第 16 轮训练完成
2025-12-26 20:40:28 - GraphTrainer - INFO - train_loss: 1.711811
2025-12-26 20:40:28 - GraphTrainer - INFO - precision@5: 0.005451
2025-12-26 20:40:28 - GraphTrainer - INFO - recall@5: 0.025931
2025-12-26 20:40:28 - GraphTrainer - INFO - hit_rate@5: 0.027256
2025-12-26 20:40:28 - GraphTrainer - INFO - ndcg@5: 0.017105
2025-12-26 20:40:28 - GraphTrainer - INFO - map@5: 0.013993
2025-12-26 20:40:28 - GraphTrainer - INFO - mrr@5: 0.014653
2025-12-26 20:40:28 - GraphTrainer - INFO - precision@10: 0.004526
2025-12-26 20:40:28 - GraphTrainer - INFO - recall@10: 0.042752
2025-12-26 20:40:28 - GraphTrainer - INFO - hit_rate@10: 0.045102
2025-12-26 20:40:28 - GraphTrainer - INFO - ndcg@10: 0.022580
2025-12-26 20:40:28 - GraphTrainer - INFO - map@10: 0.016203
2025-12-26 20:40:28 - GraphTrainer - INFO - mrr@10: 0.016993
2025-12-26 20:40:28 - GraphTrainer - INFO - precision@20: 0.003476
2025-12-26 20:40:28 - GraphTrainer - INFO - recall@20: 0.065742
2025-12-26 20:40:28 - GraphTrainer - INFO - hit_rate@20: 0.069015
2025-12-26 20:40:28 - GraphTrainer - INFO - ndcg@20: 0.028423
2025-12-26 20:40:28 - GraphTrainer - INFO - map@20: 0.017777
2025-12-26 20:40:28 - GraphTrainer - INFO - mrr@20: 0.018622
2025-12-26 20:40:28 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:40:28 - GraphTrainer - INFO - ============================================================
2025-12-26 20:40:28 - GraphTrainer - INFO - 开始第 17/1000 轮训练
2025-12-26 20:40:28 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(1.7598, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(1.7631, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(1.6970, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(1.6737, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(1.6802, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(1.6888, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(1.7155, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(1.7724, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(1.6904, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(1.7252, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(1.6994, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(1.7443, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(1.7198, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(1.6931, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(1.7172, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(1.7480, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(1.6707, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(1.6464, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(1.7675, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(1.6964, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(1.7035, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(1.6740, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(1.7001, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(1.7588, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(1.6522, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(1.6689, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(1.6850, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(1.7029, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(1.7507, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(1.7278, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(1.7202, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(1.6849, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(1.7220, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(1.6932, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(1.6563, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(1.6979, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(1.6841, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(1.7043, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(1.7024, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(1.6775, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(1.7188, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(1.7620, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(1.6873, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(1.7566, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(1.6810, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(1.6636, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(1.7481, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(1.7019, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(1.7735, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(1.7184, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(1.6739, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(1.6900, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(1.7435, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(1.7222, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(1.8028, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(1.6683, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(1.7526, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(1.7848, device='cuda:0', grad_fn=<AddBackward0>)
The 16 training average loss: 1.7118107080459595
2025-12-26 20:40:39 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:40:39 - GraphTrainer - INFO -   precision@5: 0.004803
2025-12-26 20:40:39 - GraphTrainer - INFO -   recall@5: 0.022804
2025-12-26 20:40:39 - GraphTrainer - INFO -   hit_rate@5: 0.023965
2025-12-26 20:40:39 - GraphTrainer - INFO -   ndcg@5: 0.015088
2025-12-26 20:40:39 - GraphTrainer - INFO -   map@5: 0.012353
2025-12-26 20:40:39 - GraphTrainer - INFO -   mrr@5: 0.013007
2025-12-26 20:40:39 - GraphTrainer - INFO -   precision@10: 0.003878
2025-12-26 20:40:39 - GraphTrainer - INFO -   recall@10: 0.036429
2025-12-26 20:40:39 - GraphTrainer - INFO -   hit_rate@10: 0.038622
2025-12-26 20:40:39 - GraphTrainer - INFO -   ndcg@10: 0.019498
2025-12-26 20:40:39 - GraphTrainer - INFO -   map@10: 0.014108
2025-12-26 20:40:39 - GraphTrainer - INFO -   mrr@10: 0.014888
2025-12-26 20:40:39 - GraphTrainer - INFO -   precision@20: 0.003114
2025-12-26 20:40:39 - GraphTrainer - INFO -   recall@20: 0.057868
2025-12-26 20:40:39 - GraphTrainer - INFO -   hit_rate@20: 0.061661
2025-12-26 20:40:39 - GraphTrainer - INFO -   ndcg@20: 0.024957
2025-12-26 20:40:39 - GraphTrainer - INFO -   map@20: 0.015551
2025-12-26 20:40:39 - GraphTrainer - INFO -   mrr@20: 0.016431
2025-12-26 20:40:39 - GraphTrainer - INFO - 第 17 轮训练完成
2025-12-26 20:40:39 - GraphTrainer - INFO - train_loss: 1.678299
2025-12-26 20:40:39 - GraphTrainer - INFO - precision@5: 0.004803
2025-12-26 20:40:39 - GraphTrainer - INFO - recall@5: 0.022804
2025-12-26 20:40:39 - GraphTrainer - INFO - hit_rate@5: 0.023965
2025-12-26 20:40:39 - GraphTrainer - INFO - ndcg@5: 0.015088
2025-12-26 20:40:39 - GraphTrainer - INFO - map@5: 0.012353
2025-12-26 20:40:39 - GraphTrainer - INFO - mrr@5: 0.013007
2025-12-26 20:40:39 - GraphTrainer - INFO - precision@10: 0.003878
2025-12-26 20:40:39 - GraphTrainer - INFO - recall@10: 0.036429
2025-12-26 20:40:39 - GraphTrainer - INFO - hit_rate@10: 0.038622
2025-12-26 20:40:39 - GraphTrainer - INFO - ndcg@10: 0.019498
2025-12-26 20:40:39 - GraphTrainer - INFO - map@10: 0.014108
2025-12-26 20:40:39 - GraphTrainer - INFO - mrr@10: 0.014888
2025-12-26 20:40:39 - GraphTrainer - INFO - precision@20: 0.003114
2025-12-26 20:40:39 - GraphTrainer - INFO - recall@20: 0.057868
2025-12-26 20:40:39 - GraphTrainer - INFO - hit_rate@20: 0.061661
2025-12-26 20:40:39 - GraphTrainer - INFO - ndcg@20: 0.024957
2025-12-26 20:40:39 - GraphTrainer - INFO - map@20: 0.015551
2025-12-26 20:40:39 - GraphTrainer - INFO - mrr@20: 0.016431
2025-12-26 20:40:39 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:40:39 - GraphTrainer - INFO - ============================================================
2025-12-26 20:40:39 - GraphTrainer - INFO - 开始第 18/1000 轮训练
2025-12-26 20:40:39 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(1.6467, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(1.6429, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(1.6780, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(1.6660, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(1.6835, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(1.6547, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(1.6383, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(1.6472, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(1.6487, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(1.6865, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(1.6835, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(1.6660, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(1.6299, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(1.6458, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(1.6264, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(1.6394, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(1.6557, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(1.6151, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(1.6628, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(1.6952, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(1.6826, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(1.6168, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(1.7604, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(1.6614, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(1.6658, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(1.6995, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(1.6964, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(1.6757, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(1.6964, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(1.7013, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(1.6232, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(1.7114, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(1.7160, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(1.6710, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(1.6999, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(1.6939, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(1.6745, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(1.7173, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(1.6682, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(1.6507, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(1.6994, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(1.6651, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(1.7193, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(1.7329, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(1.6389, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(1.6714, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(1.7018, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(1.7130, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(1.6937, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(1.7026, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(1.6906, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(1.6768, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(1.7103, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(1.6682, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(1.6963, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(1.7808, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(1.6439, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(1.7415, device='cuda:0', grad_fn=<AddBackward0>)
The 17 training average loss: 1.6782991660052333
2025-12-26 20:40:50 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:40:50 - GraphTrainer - INFO -   precision@5: 0.005153
2025-12-26 20:40:50 - GraphTrainer - INFO -   recall@5: 0.024523
2025-12-26 20:40:50 - GraphTrainer - INFO -   hit_rate@5: 0.025765
2025-12-26 20:40:50 - GraphTrainer - INFO -   ndcg@5: 0.016047
2025-12-26 20:40:50 - GraphTrainer - INFO -   map@5: 0.013033
2025-12-26 20:40:50 - GraphTrainer - INFO -   mrr@5: 0.013763
2025-12-26 20:40:50 - GraphTrainer - INFO -   precision@10: 0.004227
2025-12-26 20:40:50 - GraphTrainer - INFO -   recall@10: 0.039837
2025-12-26 20:40:50 - GraphTrainer - INFO -   hit_rate@10: 0.042170
2025-12-26 20:40:50 - GraphTrainer - INFO -   ndcg@10: 0.021053
2025-12-26 20:40:50 - GraphTrainer - INFO -   map@10: 0.015057
2025-12-26 20:40:50 - GraphTrainer - INFO -   mrr@10: 0.015931
2025-12-26 20:40:50 - GraphTrainer - INFO -   precision@20: 0.003224
2025-12-26 20:40:50 - GraphTrainer - INFO -   recall@20: 0.060235
2025-12-26 20:40:50 - GraphTrainer - INFO -   hit_rate@20: 0.063821
2025-12-26 20:40:50 - GraphTrainer - INFO -   ndcg@20: 0.026247
2025-12-26 20:40:50 - GraphTrainer - INFO -   map@20: 0.016439
2025-12-26 20:40:50 - GraphTrainer - INFO -   mrr@20: 0.017387
2025-12-26 20:40:50 - GraphTrainer - INFO - 第 18 轮训练完成
2025-12-26 20:40:50 - GraphTrainer - INFO - train_loss: 1.648455
2025-12-26 20:40:50 - GraphTrainer - INFO - precision@5: 0.005153
2025-12-26 20:40:50 - GraphTrainer - INFO - recall@5: 0.024523
2025-12-26 20:40:50 - GraphTrainer - INFO - hit_rate@5: 0.025765
2025-12-26 20:40:50 - GraphTrainer - INFO - ndcg@5: 0.016047
2025-12-26 20:40:50 - GraphTrainer - INFO - map@5: 0.013033
2025-12-26 20:40:50 - GraphTrainer - INFO - mrr@5: 0.013763
2025-12-26 20:40:50 - GraphTrainer - INFO - precision@10: 0.004227
2025-12-26 20:40:50 - GraphTrainer - INFO - recall@10: 0.039837
2025-12-26 20:40:50 - GraphTrainer - INFO - hit_rate@10: 0.042170
2025-12-26 20:40:50 - GraphTrainer - INFO - ndcg@10: 0.021053
2025-12-26 20:40:50 - GraphTrainer - INFO - map@10: 0.015057
2025-12-26 20:40:50 - GraphTrainer - INFO - mrr@10: 0.015931
2025-12-26 20:40:50 - GraphTrainer - INFO - precision@20: 0.003224
2025-12-26 20:40:50 - GraphTrainer - INFO - recall@20: 0.060235
2025-12-26 20:40:50 - GraphTrainer - INFO - hit_rate@20: 0.063821
2025-12-26 20:40:50 - GraphTrainer - INFO - ndcg@20: 0.026247
2025-12-26 20:40:50 - GraphTrainer - INFO - map@20: 0.016439
2025-12-26 20:40:50 - GraphTrainer - INFO - mrr@20: 0.017387
2025-12-26 20:40:50 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:40:50 - GraphTrainer - INFO - ============================================================
2025-12-26 20:40:50 - GraphTrainer - INFO - 开始第 19/1000 轮训练
2025-12-26 20:40:50 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(1.6913, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(1.6675, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(1.6477, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(1.6456, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(1.6338, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(1.6113, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(1.6408, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(1.6505, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(1.6160, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(1.6034, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(1.6511, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(1.6836, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(1.6152, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(1.6301, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(1.6562, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(1.6365, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(1.6666, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(1.6168, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(1.6848, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(1.6678, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(1.6929, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(1.6140, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(1.6658, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(1.6282, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(1.6694, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(1.6832, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(1.6776, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(1.6937, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(1.6554, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(1.6705, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(1.6718, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(1.6549, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(1.6363, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(1.6470, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(1.6700, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(1.5846, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(1.6561, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(1.7227, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(1.6383, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(1.6182, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(1.7381, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(1.6512, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(1.5914, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(1.6923, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(1.6202, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(1.7031, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(1.6582, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(1.6391, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(1.6756, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(1.5449, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(1.6315, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(1.6071, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(1.6155, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(1.5842, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(1.6320, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(1.6810, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(1.6373, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(1.6401, device='cuda:0', grad_fn=<AddBackward0>)
The 18 training average loss: 1.648455286848134
2025-12-26 20:41:01 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:41:01 - GraphTrainer - INFO -   precision@5: 0.005256
2025-12-26 20:41:01 - GraphTrainer - INFO -   recall@5: 0.024967
2025-12-26 20:41:01 - GraphTrainer - INFO -   hit_rate@5: 0.026279
2025-12-26 20:41:01 - GraphTrainer - INFO -   ndcg@5: 0.016337
2025-12-26 20:41:01 - GraphTrainer - INFO -   map@5: 0.013273
2025-12-26 20:41:01 - GraphTrainer - INFO -   mrr@5: 0.014004
2025-12-26 20:41:01 - GraphTrainer - INFO -   precision@10: 0.004186
2025-12-26 20:41:01 - GraphTrainer - INFO -   recall@10: 0.039690
2025-12-26 20:41:01 - GraphTrainer - INFO -   hit_rate@10: 0.041810
2025-12-26 20:41:01 - GraphTrainer - INFO -   ndcg@10: 0.021085
2025-12-26 20:41:01 - GraphTrainer - INFO -   map@10: 0.015171
2025-12-26 20:41:01 - GraphTrainer - INFO -   mrr@10: 0.016011
2025-12-26 20:41:01 - GraphTrainer - INFO -   precision@20: 0.003397
2025-12-26 20:41:01 - GraphTrainer - INFO -   recall@20: 0.063983
2025-12-26 20:41:01 - GraphTrainer - INFO -   hit_rate@20: 0.067421
2025-12-26 20:41:01 - GraphTrainer - INFO -   ndcg@20: 0.027287
2025-12-26 20:41:01 - GraphTrainer - INFO -   map@20: 0.016842
2025-12-26 20:41:01 - GraphTrainer - INFO -   mrr@20: 0.017764
2025-12-26 20:41:01 - GraphTrainer - INFO - 第 19 轮训练完成
2025-12-26 20:41:01 - GraphTrainer - INFO - train_loss: 1.618228
2025-12-26 20:41:01 - GraphTrainer - INFO - precision@5: 0.005256
2025-12-26 20:41:01 - GraphTrainer - INFO - recall@5: 0.024967
2025-12-26 20:41:01 - GraphTrainer - INFO - hit_rate@5: 0.026279
2025-12-26 20:41:01 - GraphTrainer - INFO - ndcg@5: 0.016337
2025-12-26 20:41:01 - GraphTrainer - INFO - map@5: 0.013273
2025-12-26 20:41:01 - GraphTrainer - INFO - mrr@5: 0.014004
2025-12-26 20:41:01 - GraphTrainer - INFO - precision@10: 0.004186
2025-12-26 20:41:01 - GraphTrainer - INFO - recall@10: 0.039690
2025-12-26 20:41:01 - GraphTrainer - INFO - hit_rate@10: 0.041810
2025-12-26 20:41:01 - GraphTrainer - INFO - ndcg@10: 0.021085
2025-12-26 20:41:01 - GraphTrainer - INFO - map@10: 0.015171
2025-12-26 20:41:01 - GraphTrainer - INFO - mrr@10: 0.016011
2025-12-26 20:41:01 - GraphTrainer - INFO - precision@20: 0.003397
2025-12-26 20:41:01 - GraphTrainer - INFO - recall@20: 0.063983
2025-12-26 20:41:01 - GraphTrainer - INFO - hit_rate@20: 0.067421
2025-12-26 20:41:01 - GraphTrainer - INFO - ndcg@20: 0.027287
2025-12-26 20:41:01 - GraphTrainer - INFO - map@20: 0.016842
2025-12-26 20:41:01 - GraphTrainer - INFO - mrr@20: 0.017764
2025-12-26 20:41:01 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:41:01 - GraphTrainer - INFO - ============================================================
2025-12-26 20:41:01 - GraphTrainer - INFO - 开始第 20/1000 轮训练
2025-12-26 20:41:01 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(1.5732, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(1.5802, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(1.5831, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(1.5992, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(1.5966, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(1.6222, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(1.5620, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(1.6423, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(1.5723, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(1.6127, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(1.5270, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(1.6141, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(1.6281, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(1.6092, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(1.6164, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(1.5858, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(1.6341, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(1.6090, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(1.6585, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(1.5911, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(1.7103, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(1.5617, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(1.6777, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(1.5577, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(1.6148, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(1.5707, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(1.6370, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(1.6098, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(1.6210, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(1.6246, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(1.6072, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(1.6307, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(1.7096, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(1.6321, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(1.6593, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(1.6539, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(1.6037, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(1.6670, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(1.6468, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(1.6964, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(1.6348, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(1.6150, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(1.6095, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(1.6103, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(1.6284, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(1.6705, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(1.5971, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(1.6472, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(1.5633, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(1.6121, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(1.6244, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(1.6048, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(1.6401, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(1.6378, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(1.6230, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(1.5916, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(1.6065, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(1.6316, device='cuda:0', grad_fn=<AddBackward0>)
The 19 training average loss: 1.6182284745676765
2025-12-26 20:41:12 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:41:12 - GraphTrainer - INFO -   precision@5: 0.005040
2025-12-26 20:41:12 - GraphTrainer - INFO -   recall@5: 0.023803
2025-12-26 20:41:12 - GraphTrainer - INFO -   hit_rate@5: 0.025199
2025-12-26 20:41:12 - GraphTrainer - INFO -   ndcg@5: 0.015988
2025-12-26 20:41:12 - GraphTrainer - INFO -   map@5: 0.013168
2025-12-26 20:41:12 - GraphTrainer - INFO -   mrr@5: 0.013924
2025-12-26 20:41:12 - GraphTrainer - INFO -   precision@10: 0.004155
2025-12-26 20:41:12 - GraphTrainer - INFO -   recall@10: 0.039231
2025-12-26 20:41:12 - GraphTrainer - INFO -   hit_rate@10: 0.041347
2025-12-26 20:41:12 - GraphTrainer - INFO -   ndcg@10: 0.020984
2025-12-26 20:41:12 - GraphTrainer - INFO -   map@10: 0.015183
2025-12-26 20:41:12 - GraphTrainer - INFO -   mrr@10: 0.016026
2025-12-26 20:41:12 - GraphTrainer - INFO -   precision@20: 0.003307
2025-12-26 20:41:12 - GraphTrainer - INFO -   recall@20: 0.062186
2025-12-26 20:41:12 - GraphTrainer - INFO -   hit_rate@20: 0.065518
2025-12-26 20:41:12 - GraphTrainer - INFO -   ndcg@20: 0.026856
2025-12-26 20:41:12 - GraphTrainer - INFO -   map@20: 0.016773
2025-12-26 20:41:12 - GraphTrainer - INFO -   mrr@20: 0.017690
2025-12-26 20:41:12 - GraphTrainer - INFO - 第 20 轮训练完成
2025-12-26 20:41:12 - GraphTrainer - INFO - train_loss: 1.588741
2025-12-26 20:41:12 - GraphTrainer - INFO - precision@5: 0.005040
2025-12-26 20:41:12 - GraphTrainer - INFO - recall@5: 0.023803
2025-12-26 20:41:12 - GraphTrainer - INFO - hit_rate@5: 0.025199
2025-12-26 20:41:12 - GraphTrainer - INFO - ndcg@5: 0.015988
2025-12-26 20:41:12 - GraphTrainer - INFO - map@5: 0.013168
2025-12-26 20:41:12 - GraphTrainer - INFO - mrr@5: 0.013924
2025-12-26 20:41:12 - GraphTrainer - INFO - precision@10: 0.004155
2025-12-26 20:41:12 - GraphTrainer - INFO - recall@10: 0.039231
2025-12-26 20:41:12 - GraphTrainer - INFO - hit_rate@10: 0.041347
2025-12-26 20:41:12 - GraphTrainer - INFO - ndcg@10: 0.020984
2025-12-26 20:41:12 - GraphTrainer - INFO - map@10: 0.015183
2025-12-26 20:41:12 - GraphTrainer - INFO - mrr@10: 0.016026
2025-12-26 20:41:12 - GraphTrainer - INFO - precision@20: 0.003307
2025-12-26 20:41:12 - GraphTrainer - INFO - recall@20: 0.062186
2025-12-26 20:41:12 - GraphTrainer - INFO - hit_rate@20: 0.065518
2025-12-26 20:41:12 - GraphTrainer - INFO - ndcg@20: 0.026856
2025-12-26 20:41:12 - GraphTrainer - INFO - map@20: 0.016773
2025-12-26 20:41:12 - GraphTrainer - INFO - mrr@20: 0.017690
2025-12-26 20:41:12 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:41:12 - GraphTrainer - INFO - 检查点已保存: Epoch 20 -> ./checkpoints/checkpoint_epoch_20.pth
2025-12-26 20:41:12 - GraphTrainer - INFO - ============================================================
2025-12-26 20:41:12 - GraphTrainer - INFO - 开始第 21/1000 轮训练
2025-12-26 20:41:12 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(1.5900, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(1.5880, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(1.5199, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(1.5920, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(1.5599, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(1.5590, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(1.5308, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(1.5816, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(1.6030, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(1.4693, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(1.5854, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(1.5886, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(1.6231, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(1.6514, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(1.5684, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(1.6383, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(1.6364, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(1.5553, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(1.6486, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(1.6049, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(1.5942, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(1.5419, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(1.5439, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(1.5283, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(1.6003, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(1.5887, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(1.5699, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(1.6497, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(1.6374, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(1.5704, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(1.6620, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(1.6175, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(1.5557, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(1.5762, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(1.6107, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(1.5609, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(1.5831, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(1.6081, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(1.5239, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(1.5431, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(1.6088, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(1.5974, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(1.6163, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(1.6252, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(1.5949, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(1.5911, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(1.6079, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(1.5802, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(1.5819, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(1.6345, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(1.5954, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(1.5559, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(1.5884, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(1.6061, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(1.6586, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(1.6183, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(1.5504, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(1.5758, device='cuda:0', grad_fn=<AddBackward0>)
The 20 training average loss: 1.5887405111871917
2025-12-26 20:41:23 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:41:23 - GraphTrainer - INFO -   precision@5: 0.004783
2025-12-26 20:41:23 - GraphTrainer - INFO -   recall@5: 0.022647
2025-12-26 20:41:23 - GraphTrainer - INFO -   hit_rate@5: 0.023914
2025-12-26 20:41:23 - GraphTrainer - INFO -   ndcg@5: 0.014993
2025-12-26 20:41:23 - GraphTrainer - INFO -   map@5: 0.012264
2025-12-26 20:41:23 - GraphTrainer - INFO -   mrr@5: 0.012930
2025-12-26 20:41:23 - GraphTrainer - INFO -   precision@10: 0.003996
2025-12-26 20:41:23 - GraphTrainer - INFO -   recall@10: 0.037551
2025-12-26 20:41:23 - GraphTrainer - INFO -   hit_rate@10: 0.039856
2025-12-26 20:41:23 - GraphTrainer - INFO -   ndcg@10: 0.019869
2025-12-26 20:41:23 - GraphTrainer - INFO -   map@10: 0.014240
2025-12-26 20:41:23 - GraphTrainer - INFO -   mrr@10: 0.015041
2025-12-26 20:41:23 - GraphTrainer - INFO -   precision@20: 0.003181
2025-12-26 20:41:23 - GraphTrainer - INFO -   recall@20: 0.059766
2025-12-26 20:41:23 - GraphTrainer - INFO -   hit_rate@20: 0.062792
2025-12-26 20:41:23 - GraphTrainer - INFO -   ndcg@20: 0.025511
2025-12-26 20:41:23 - GraphTrainer - INFO -   map@20: 0.015759
2025-12-26 20:41:23 - GraphTrainer - INFO -   mrr@20: 0.016593
2025-12-26 20:41:23 - GraphTrainer - INFO - 第 21 轮训练完成
2025-12-26 20:41:23 - GraphTrainer - INFO - train_loss: 1.562677
2025-12-26 20:41:23 - GraphTrainer - INFO - precision@5: 0.004783
2025-12-26 20:41:23 - GraphTrainer - INFO - recall@5: 0.022647
2025-12-26 20:41:23 - GraphTrainer - INFO - hit_rate@5: 0.023914
2025-12-26 20:41:23 - GraphTrainer - INFO - ndcg@5: 0.014993
2025-12-26 20:41:23 - GraphTrainer - INFO - map@5: 0.012264
2025-12-26 20:41:23 - GraphTrainer - INFO - mrr@5: 0.012930
2025-12-26 20:41:23 - GraphTrainer - INFO - precision@10: 0.003996
2025-12-26 20:41:23 - GraphTrainer - INFO - recall@10: 0.037551
2025-12-26 20:41:23 - GraphTrainer - INFO - hit_rate@10: 0.039856
2025-12-26 20:41:23 - GraphTrainer - INFO - ndcg@10: 0.019869
2025-12-26 20:41:23 - GraphTrainer - INFO - map@10: 0.014240
2025-12-26 20:41:23 - GraphTrainer - INFO - mrr@10: 0.015041
2025-12-26 20:41:23 - GraphTrainer - INFO - precision@20: 0.003181
2025-12-26 20:41:23 - GraphTrainer - INFO - recall@20: 0.059766
2025-12-26 20:41:23 - GraphTrainer - INFO - hit_rate@20: 0.062792
2025-12-26 20:41:23 - GraphTrainer - INFO - ndcg@20: 0.025511
2025-12-26 20:41:23 - GraphTrainer - INFO - map@20: 0.015759
2025-12-26 20:41:23 - GraphTrainer - INFO - mrr@20: 0.016593
2025-12-26 20:41:23 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:41:23 - GraphTrainer - INFO - ============================================================
2025-12-26 20:41:23 - GraphTrainer - INFO - 开始第 22/1000 轮训练
2025-12-26 20:41:23 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(1.5180, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(1.5707, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(1.5469, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(1.6184, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(1.5389, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(1.5964, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(1.4884, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(1.5290, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(1.5142, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(1.6168, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(1.5682, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(1.5807, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(1.5737, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(1.5676, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(1.5268, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(1.5259, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(1.4829, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(1.5972, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(1.5747, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(1.5826, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(1.5124, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(1.5622, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(1.5288, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(1.5785, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(1.5565, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(1.5606, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(1.5169, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(1.5661, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(1.6022, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(1.5561, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(1.5965, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(1.5764, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(1.5623, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(1.5855, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(1.5084, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(1.5447, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(1.6187, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(1.5462, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(1.5514, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(1.5370, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(1.5332, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(1.5778, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(1.5744, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(1.5815, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(1.5756, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(1.5603, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(1.5641, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(1.5982, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(1.5949, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(1.5871, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(1.6006, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(1.5442, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(1.6078, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(1.5912, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(1.5427, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(1.6048, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(1.5585, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(1.5529, device='cuda:0', grad_fn=<AddBackward0>)
The 21 training average loss: 1.5626774800234828
2025-12-26 20:41:34 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:41:34 - GraphTrainer - INFO -   precision@5: 0.005297
2025-12-26 20:41:34 - GraphTrainer - INFO -   recall@5: 0.025169
2025-12-26 20:41:34 - GraphTrainer - INFO -   hit_rate@5: 0.026485
2025-12-26 20:41:34 - GraphTrainer - INFO -   ndcg@5: 0.016723
2025-12-26 20:41:34 - GraphTrainer - INFO -   map@5: 0.013720
2025-12-26 20:41:34 - GraphTrainer - INFO -   mrr@5: 0.014464
2025-12-26 20:41:34 - GraphTrainer - INFO -   precision@10: 0.004304
2025-12-26 20:41:34 - GraphTrainer - INFO -   recall@10: 0.040508
2025-12-26 20:41:34 - GraphTrainer - INFO -   hit_rate@10: 0.042890
2025-12-26 20:41:34 - GraphTrainer - INFO -   ndcg@10: 0.021707
2025-12-26 20:41:34 - GraphTrainer - INFO -   map@10: 0.015723
2025-12-26 20:41:34 - GraphTrainer - INFO -   mrr@10: 0.016598
2025-12-26 20:41:34 - GraphTrainer - INFO -   precision@20: 0.003420
2025-12-26 20:41:34 - GraphTrainer - INFO -   recall@20: 0.064097
2025-12-26 20:41:34 - GraphTrainer - INFO -   hit_rate@20: 0.067729
2025-12-26 20:41:34 - GraphTrainer - INFO -   ndcg@20: 0.027743
2025-12-26 20:41:34 - GraphTrainer - INFO -   map@20: 0.017353
2025-12-26 20:41:34 - GraphTrainer - INFO -   mrr@20: 0.018306
2025-12-26 20:41:34 - GraphTrainer - INFO - 第 22 轮训练完成
2025-12-26 20:41:34 - GraphTrainer - INFO - train_loss: 1.552588
2025-12-26 20:41:34 - GraphTrainer - INFO - precision@5: 0.005297
2025-12-26 20:41:34 - GraphTrainer - INFO - recall@5: 0.025169
2025-12-26 20:41:34 - GraphTrainer - INFO - hit_rate@5: 0.026485
2025-12-26 20:41:34 - GraphTrainer - INFO - ndcg@5: 0.016723
2025-12-26 20:41:34 - GraphTrainer - INFO - map@5: 0.013720
2025-12-26 20:41:34 - GraphTrainer - INFO - mrr@5: 0.014464
2025-12-26 20:41:34 - GraphTrainer - INFO - precision@10: 0.004304
2025-12-26 20:41:34 - GraphTrainer - INFO - recall@10: 0.040508
2025-12-26 20:41:34 - GraphTrainer - INFO - hit_rate@10: 0.042890
2025-12-26 20:41:34 - GraphTrainer - INFO - ndcg@10: 0.021707
2025-12-26 20:41:34 - GraphTrainer - INFO - map@10: 0.015723
2025-12-26 20:41:34 - GraphTrainer - INFO - mrr@10: 0.016598
2025-12-26 20:41:34 - GraphTrainer - INFO - precision@20: 0.003420
2025-12-26 20:41:34 - GraphTrainer - INFO - recall@20: 0.064097
2025-12-26 20:41:34 - GraphTrainer - INFO - hit_rate@20: 0.067729
2025-12-26 20:41:34 - GraphTrainer - INFO - ndcg@20: 0.027743
2025-12-26 20:41:34 - GraphTrainer - INFO - map@20: 0.017353
2025-12-26 20:41:34 - GraphTrainer - INFO - mrr@20: 0.018306
2025-12-26 20:41:34 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:41:34 - GraphTrainer - INFO - ============================================================
2025-12-26 20:41:34 - GraphTrainer - INFO - 开始第 23/1000 轮训练
2025-12-26 20:41:34 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(1.5639, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(1.5816, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(1.5879, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(1.5269, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(1.5428, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(1.5408, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(1.5370, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(1.5260, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(1.6091, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(1.5213, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(1.5551, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(1.4862, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(1.5805, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(1.5989, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(1.5125, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(1.6179, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(1.5670, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(1.5264, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(1.5083, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(1.5393, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(1.5613, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(1.5568, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(1.5786, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(1.5862, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(1.5456, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(1.5699, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(1.6026, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(1.6098, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(1.5081, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(1.4902, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(1.5271, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(1.5812, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(1.5189, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(1.5611, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(1.5802, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(1.5424, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(1.5222, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(1.4890, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(1.5128, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(1.5803, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(1.5306, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(1.5498, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(1.5605, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(1.5311, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(1.5616, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(1.5176, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(1.5354, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(1.5605, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(1.5212, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(1.5628, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(1.5660, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(1.5639, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(1.5535, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(1.5708, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(1.5361, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(1.6146, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(1.5955, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(1.5648, device='cuda:0', grad_fn=<AddBackward0>)
The 22 training average loss: 1.5525877886805042
2025-12-26 20:41:46 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:41:46 - GraphTrainer - INFO -   precision@5: 0.005030
2025-12-26 20:41:46 - GraphTrainer - INFO -   recall@5: 0.023558
2025-12-26 20:41:46 - GraphTrainer - INFO -   hit_rate@5: 0.025096
2025-12-26 20:41:46 - GraphTrainer - INFO -   ndcg@5: 0.015975
2025-12-26 20:41:46 - GraphTrainer - INFO -   map@5: 0.013203
2025-12-26 20:41:46 - GraphTrainer - INFO -   mrr@5: 0.014003
2025-12-26 20:41:46 - GraphTrainer - INFO -   precision@10: 0.004145
2025-12-26 20:41:46 - GraphTrainer - INFO -   recall@10: 0.039019
2025-12-26 20:41:46 - GraphTrainer - INFO -   hit_rate@10: 0.041245
2025-12-26 20:41:46 - GraphTrainer - INFO -   ndcg@10: 0.020983
2025-12-26 20:41:46 - GraphTrainer - INFO -   map@10: 0.015229
2025-12-26 20:41:46 - GraphTrainer - INFO -   mrr@10: 0.016118
2025-12-26 20:41:46 - GraphTrainer - INFO -   precision@20: 0.003415
2025-12-26 20:41:46 - GraphTrainer - INFO -   recall@20: 0.063966
2025-12-26 20:41:46 - GraphTrainer - INFO -   hit_rate@20: 0.067370
2025-12-26 20:41:46 - GraphTrainer - INFO -   ndcg@20: 0.027345
2025-12-26 20:41:46 - GraphTrainer - INFO -   map@20: 0.016943
2025-12-26 20:41:46 - GraphTrainer - INFO -   mrr@20: 0.017896
2025-12-26 20:41:46 - GraphTrainer - INFO - 第 23 轮训练完成
2025-12-26 20:41:46 - GraphTrainer - INFO - train_loss: 1.526768
2025-12-26 20:41:46 - GraphTrainer - INFO - precision@5: 0.005030
2025-12-26 20:41:46 - GraphTrainer - INFO - recall@5: 0.023558
2025-12-26 20:41:46 - GraphTrainer - INFO - hit_rate@5: 0.025096
2025-12-26 20:41:46 - GraphTrainer - INFO - ndcg@5: 0.015975
2025-12-26 20:41:46 - GraphTrainer - INFO - map@5: 0.013203
2025-12-26 20:41:46 - GraphTrainer - INFO - mrr@5: 0.014003
2025-12-26 20:41:46 - GraphTrainer - INFO - precision@10: 0.004145
2025-12-26 20:41:46 - GraphTrainer - INFO - recall@10: 0.039019
2025-12-26 20:41:46 - GraphTrainer - INFO - hit_rate@10: 0.041245
2025-12-26 20:41:46 - GraphTrainer - INFO - ndcg@10: 0.020983
2025-12-26 20:41:46 - GraphTrainer - INFO - map@10: 0.015229
2025-12-26 20:41:46 - GraphTrainer - INFO - mrr@10: 0.016118
2025-12-26 20:41:46 - GraphTrainer - INFO - precision@20: 0.003415
2025-12-26 20:41:46 - GraphTrainer - INFO - recall@20: 0.063966
2025-12-26 20:41:46 - GraphTrainer - INFO - hit_rate@20: 0.067370
2025-12-26 20:41:46 - GraphTrainer - INFO - ndcg@20: 0.027345
2025-12-26 20:41:46 - GraphTrainer - INFO - map@20: 0.016943
2025-12-26 20:41:46 - GraphTrainer - INFO - mrr@20: 0.017896
2025-12-26 20:41:46 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:41:46 - GraphTrainer - INFO - ============================================================
2025-12-26 20:41:46 - GraphTrainer - INFO - 开始第 24/1000 轮训练
2025-12-26 20:41:46 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(1.5578, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(1.5055, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(1.5361, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(1.5100, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(1.5515, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(1.5243, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(1.4999, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(1.5209, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(1.4916, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(1.5598, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(1.4746, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(1.5000, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(1.5188, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(1.5129, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(1.5511, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(1.4644, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(1.4769, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(1.5005, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(1.5656, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(1.5891, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(1.5421, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(1.5046, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(1.5059, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(1.5123, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(1.5502, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(1.5189, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(1.5037, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(1.4980, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(1.5810, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(1.5731, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(1.5016, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(1.5311, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(1.5138, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(1.5496, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(1.5318, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(1.5219, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(1.5173, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(1.4972, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(1.5655, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(1.4767, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(1.5264, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(1.4983, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(1.5080, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(1.5382, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(1.5436, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(1.5629, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(1.5281, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(1.5372, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(1.5316, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(1.5267, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(1.5213, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(1.5902, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(1.5710, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(1.5070, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(1.5191, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(1.4776, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(1.5874, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(1.5700, device='cuda:0', grad_fn=<AddBackward0>)
The 23 training average loss: 1.5267675169583024
2025-12-26 20:41:56 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:41:56 - GraphTrainer - INFO -   precision@5: 0.005050
2025-12-26 20:41:56 - GraphTrainer - INFO -   recall@5: 0.023816
2025-12-26 20:41:56 - GraphTrainer - INFO -   hit_rate@5: 0.025251
2025-12-26 20:41:56 - GraphTrainer - INFO -   ndcg@5: 0.015738
2025-12-26 20:41:56 - GraphTrainer - INFO -   map@5: 0.012841
2025-12-26 20:41:56 - GraphTrainer - INFO -   mrr@5: 0.013643
2025-12-26 20:41:56 - GraphTrainer - INFO -   precision@10: 0.003975
2025-12-26 20:41:56 - GraphTrainer - INFO -   recall@10: 0.037335
2025-12-26 20:41:56 - GraphTrainer - INFO -   hit_rate@10: 0.039599
2025-12-26 20:41:56 - GraphTrainer - INFO -   ndcg@10: 0.020129
2025-12-26 20:41:56 - GraphTrainer - INFO -   map@10: 0.014606
2025-12-26 20:41:56 - GraphTrainer - INFO -   mrr@10: 0.015517
2025-12-26 20:41:56 - GraphTrainer - INFO -   precision@20: 0.003212
2025-12-26 20:41:56 - GraphTrainer - INFO -   recall@20: 0.060503
2025-12-26 20:41:56 - GraphTrainer - INFO -   hit_rate@20: 0.063821
2025-12-26 20:41:56 - GraphTrainer - INFO -   ndcg@20: 0.026030
2025-12-26 20:41:56 - GraphTrainer - INFO -   map@20: 0.016201
2025-12-26 20:41:56 - GraphTrainer - INFO -   mrr@20: 0.017177
2025-12-26 20:41:56 - GraphTrainer - INFO - 第 24 轮训练完成
2025-12-26 20:41:56 - GraphTrainer - INFO - train_loss: 1.516849
2025-12-26 20:41:56 - GraphTrainer - INFO - precision@5: 0.005050
2025-12-26 20:41:56 - GraphTrainer - INFO - recall@5: 0.023816
2025-12-26 20:41:56 - GraphTrainer - INFO - hit_rate@5: 0.025251
2025-12-26 20:41:56 - GraphTrainer - INFO - ndcg@5: 0.015738
2025-12-26 20:41:56 - GraphTrainer - INFO - map@5: 0.012841
2025-12-26 20:41:56 - GraphTrainer - INFO - mrr@5: 0.013643
2025-12-26 20:41:56 - GraphTrainer - INFO - precision@10: 0.003975
2025-12-26 20:41:56 - GraphTrainer - INFO - recall@10: 0.037335
2025-12-26 20:41:56 - GraphTrainer - INFO - hit_rate@10: 0.039599
2025-12-26 20:41:56 - GraphTrainer - INFO - ndcg@10: 0.020129
2025-12-26 20:41:56 - GraphTrainer - INFO - map@10: 0.014606
2025-12-26 20:41:56 - GraphTrainer - INFO - mrr@10: 0.015517
2025-12-26 20:41:56 - GraphTrainer - INFO - precision@20: 0.003212
2025-12-26 20:41:56 - GraphTrainer - INFO - recall@20: 0.060503
2025-12-26 20:41:56 - GraphTrainer - INFO - hit_rate@20: 0.063821
2025-12-26 20:41:56 - GraphTrainer - INFO - ndcg@20: 0.026030
2025-12-26 20:41:56 - GraphTrainer - INFO - map@20: 0.016201
2025-12-26 20:41:56 - GraphTrainer - INFO - mrr@20: 0.017177
2025-12-26 20:41:56 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:41:56 - GraphTrainer - INFO - ============================================================
2025-12-26 20:41:56 - GraphTrainer - INFO - 开始第 25/1000 轮训练
2025-12-26 20:41:56 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(1.4902, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(1.5073, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(1.4984, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(1.4851, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(1.4831, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(1.5081, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(1.4997, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(1.4766, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(1.5083, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(1.4710, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(1.5010, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(1.5351, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(1.5422, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(1.4325, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(1.4904, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(1.5046, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(1.5038, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(1.5312, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(1.5605, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(1.5500, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(1.5284, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(1.5178, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(1.5873, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(1.6214, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(1.5904, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(1.5392, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(1.5503, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(1.5694, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(1.5906, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(1.5500, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(1.4768, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(1.5070, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(1.5402, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(1.5437, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(1.4258, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(1.5149, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(1.5443, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(1.5515, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(1.4967, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(1.4967, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(1.5023, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(1.4839, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(1.4777, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(1.5005, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(1.5193, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(1.5444, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(1.4732, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(1.4928, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(1.5211, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(1.4991, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(1.5046, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(1.4875, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(1.4986, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(1.5540, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(1.5607, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(1.4769, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(1.5477, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(1.5112, device='cuda:0', grad_fn=<AddBackward0>)
The 24 training average loss: 1.516848975214465
2025-12-26 20:42:07 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:42:07 - GraphTrainer - INFO -   precision@5: 0.005102
2025-12-26 20:42:07 - GraphTrainer - INFO -   recall@5: 0.024174
2025-12-26 20:42:07 - GraphTrainer - INFO -   hit_rate@5: 0.025508
2025-12-26 20:42:07 - GraphTrainer - INFO -   ndcg@5: 0.015462
2025-12-26 20:42:07 - GraphTrainer - INFO -   map@5: 0.012350
2025-12-26 20:42:07 - GraphTrainer - INFO -   mrr@5: 0.013187
2025-12-26 20:42:07 - GraphTrainer - INFO -   precision@10: 0.004166
2025-12-26 20:42:07 - GraphTrainer - INFO -   recall@10: 0.039124
2025-12-26 20:42:07 - GraphTrainer - INFO -   hit_rate@10: 0.041553
2025-12-26 20:42:07 - GraphTrainer - INFO -   ndcg@10: 0.020344
2025-12-26 20:42:07 - GraphTrainer - INFO -   map@10: 0.014323
2025-12-26 20:42:07 - GraphTrainer - INFO -   mrr@10: 0.015303
2025-12-26 20:42:07 - GraphTrainer - INFO -   precision@20: 0.003183
2025-12-26 20:42:07 - GraphTrainer - INFO -   recall@20: 0.059774
2025-12-26 20:42:07 - GraphTrainer - INFO -   hit_rate@20: 0.063307
2025-12-26 20:42:07 - GraphTrainer - INFO -   ndcg@20: 0.025606
2025-12-26 20:42:07 - GraphTrainer - INFO -   map@20: 0.015736
2025-12-26 20:42:07 - GraphTrainer - INFO -   mrr@20: 0.016787
2025-12-26 20:42:07 - GraphTrainer - INFO - 第 25 轮训练完成
2025-12-26 20:42:07 - GraphTrainer - INFO - train_loss: 1.476108
2025-12-26 20:42:07 - GraphTrainer - INFO - precision@5: 0.005102
2025-12-26 20:42:07 - GraphTrainer - INFO - recall@5: 0.024174
2025-12-26 20:42:07 - GraphTrainer - INFO - hit_rate@5: 0.025508
2025-12-26 20:42:07 - GraphTrainer - INFO - ndcg@5: 0.015462
2025-12-26 20:42:07 - GraphTrainer - INFO - map@5: 0.012350
2025-12-26 20:42:07 - GraphTrainer - INFO - mrr@5: 0.013187
2025-12-26 20:42:07 - GraphTrainer - INFO - precision@10: 0.004166
2025-12-26 20:42:07 - GraphTrainer - INFO - recall@10: 0.039124
2025-12-26 20:42:07 - GraphTrainer - INFO - hit_rate@10: 0.041553
2025-12-26 20:42:07 - GraphTrainer - INFO - ndcg@10: 0.020344
2025-12-26 20:42:07 - GraphTrainer - INFO - map@10: 0.014323
2025-12-26 20:42:07 - GraphTrainer - INFO - mrr@10: 0.015303
2025-12-26 20:42:07 - GraphTrainer - INFO - precision@20: 0.003183
2025-12-26 20:42:07 - GraphTrainer - INFO - recall@20: 0.059774
2025-12-26 20:42:07 - GraphTrainer - INFO - hit_rate@20: 0.063307
2025-12-26 20:42:07 - GraphTrainer - INFO - ndcg@20: 0.025606
2025-12-26 20:42:07 - GraphTrainer - INFO - map@20: 0.015736
2025-12-26 20:42:07 - GraphTrainer - INFO - mrr@20: 0.016787
2025-12-26 20:42:07 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:42:07 - GraphTrainer - INFO - ============================================================
2025-12-26 20:42:07 - GraphTrainer - INFO - 开始第 26/1000 轮训练
2025-12-26 20:42:07 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(1.5033, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(1.4146, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(1.4815, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(1.4702, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(1.4717, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(1.4518, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(1.5122, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(1.4764, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(1.4885, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(1.4546, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(1.4680, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(1.4099, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(1.4920, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(1.5237, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(1.5283, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(1.5061, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(1.4984, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(1.4739, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(1.4959, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(1.4675, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(1.4730, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(1.5138, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(1.4281, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(1.5301, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(1.5520, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(1.5142, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(1.4221, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(1.5170, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(1.4756, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(1.4450, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(1.4708, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(1.4218, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(1.4367, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(1.5166, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(1.4300, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(1.4798, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(1.3919, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(1.4506, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(1.4475, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(1.4782, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(1.3990, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(1.4942, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(1.4781, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(1.4320, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(1.5074, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(1.4347, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(1.5202, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(1.5529, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(1.4381, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(1.4972, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(1.4611, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(1.4469, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(1.5143, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(1.5439, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(1.4918, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(1.4349, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(1.5110, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(1.4733, device='cuda:0', grad_fn=<AddBackward0>)
The 25 training average loss: 1.4761083084961464
2025-12-26 20:42:18 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:42:18 - GraphTrainer - INFO -   precision@5: 0.004937
2025-12-26 20:42:18 - GraphTrainer - INFO -   recall@5: 0.023009
2025-12-26 20:42:18 - GraphTrainer - INFO -   hit_rate@5: 0.024685
2025-12-26 20:42:18 - GraphTrainer - INFO -   ndcg@5: 0.015111
2025-12-26 20:42:18 - GraphTrainer - INFO -   map@5: 0.012213
2025-12-26 20:42:18 - GraphTrainer - INFO -   mrr@5: 0.013146
2025-12-26 20:42:18 - GraphTrainer - INFO -   precision@10: 0.004124
2025-12-26 20:42:18 - GraphTrainer - INFO -   recall@10: 0.038599
2025-12-26 20:42:18 - GraphTrainer - INFO -   hit_rate@10: 0.041090
2025-12-26 20:42:18 - GraphTrainer - INFO -   ndcg@10: 0.020132
2025-12-26 20:42:18 - GraphTrainer - INFO -   map@10: 0.014223
2025-12-26 20:42:18 - GraphTrainer - INFO -   mrr@10: 0.015250
2025-12-26 20:42:18 - GraphTrainer - INFO -   precision@20: 0.003219
2025-12-26 20:42:18 - GraphTrainer - INFO -   recall@20: 0.060396
2025-12-26 20:42:18 - GraphTrainer - INFO -   hit_rate@20: 0.063975
2025-12-26 20:42:18 - GraphTrainer - INFO -   ndcg@20: 0.025702
2025-12-26 20:42:18 - GraphTrainer - INFO -   map@20: 0.015735
2025-12-26 20:42:18 - GraphTrainer - INFO -   mrr@20: 0.016828
2025-12-26 20:42:18 - GraphTrainer - INFO - 第 26 轮训练完成
2025-12-26 20:42:18 - GraphTrainer - INFO - train_loss: 1.446516
2025-12-26 20:42:18 - GraphTrainer - INFO - precision@5: 0.004937
2025-12-26 20:42:18 - GraphTrainer - INFO - recall@5: 0.023009
2025-12-26 20:42:18 - GraphTrainer - INFO - hit_rate@5: 0.024685
2025-12-26 20:42:18 - GraphTrainer - INFO - ndcg@5: 0.015111
2025-12-26 20:42:18 - GraphTrainer - INFO - map@5: 0.012213
2025-12-26 20:42:18 - GraphTrainer - INFO - mrr@5: 0.013146
2025-12-26 20:42:18 - GraphTrainer - INFO - precision@10: 0.004124
2025-12-26 20:42:18 - GraphTrainer - INFO - recall@10: 0.038599
2025-12-26 20:42:18 - GraphTrainer - INFO - hit_rate@10: 0.041090
2025-12-26 20:42:18 - GraphTrainer - INFO - ndcg@10: 0.020132
2025-12-26 20:42:18 - GraphTrainer - INFO - map@10: 0.014223
2025-12-26 20:42:18 - GraphTrainer - INFO - mrr@10: 0.015250
2025-12-26 20:42:18 - GraphTrainer - INFO - precision@20: 0.003219
2025-12-26 20:42:18 - GraphTrainer - INFO - recall@20: 0.060396
2025-12-26 20:42:18 - GraphTrainer - INFO - hit_rate@20: 0.063975
2025-12-26 20:42:18 - GraphTrainer - INFO - ndcg@20: 0.025702
2025-12-26 20:42:18 - GraphTrainer - INFO - map@20: 0.015735
2025-12-26 20:42:18 - GraphTrainer - INFO - mrr@20: 0.016828
2025-12-26 20:42:18 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:42:18 - GraphTrainer - INFO - ============================================================
2025-12-26 20:42:18 - GraphTrainer - INFO - 开始第 27/1000 轮训练
2025-12-26 20:42:18 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(1.4284, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(1.4751, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(1.4525, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(1.4754, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(1.4482, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(1.4409, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(1.4749, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(1.4316, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(1.4193, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(1.4390, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(1.4059, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(1.4466, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(1.5176, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(1.4295, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(1.4373, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(1.4175, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(1.4481, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(1.4096, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(1.4281, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(1.4937, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(1.4483, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(1.4546, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(1.4463, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(1.4659, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(1.4955, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(1.4421, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(1.4450, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(1.4626, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(1.4207, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(1.3985, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(1.4142, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(1.4344, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(1.4627, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(1.4328, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(1.4196, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(1.4624, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(1.4910, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(1.4499, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(1.4754, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(1.3814, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(1.4884, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(1.4624, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(1.4517, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(1.4261, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(1.4293, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(1.4446, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(1.4591, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(1.4279, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(1.4384, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(1.4550, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(1.4326, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(1.4291, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(1.4797, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(1.4433, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(1.4430, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(1.4773, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(1.4441, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(1.4434, device='cuda:0', grad_fn=<AddBackward0>)
The 26 training average loss: 1.4465155210988274
2025-12-26 20:42:29 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:42:29 - GraphTrainer - INFO -   precision@5: 0.004937
2025-12-26 20:42:29 - GraphTrainer - INFO -   recall@5: 0.023136
2025-12-26 20:42:29 - GraphTrainer - INFO -   hit_rate@5: 0.024685
2025-12-26 20:42:29 - GraphTrainer - INFO -   ndcg@5: 0.015216
2025-12-26 20:42:29 - GraphTrainer - INFO -   map@5: 0.012343
2025-12-26 20:42:29 - GraphTrainer - INFO -   mrr@5: 0.013146
2025-12-26 20:42:29 - GraphTrainer - INFO -   precision@10: 0.004022
2025-12-26 20:42:29 - GraphTrainer - INFO -   recall@10: 0.037734
2025-12-26 20:42:29 - GraphTrainer - INFO -   hit_rate@10: 0.040062
2025-12-26 20:42:29 - GraphTrainer - INFO -   ndcg@10: 0.019919
2025-12-26 20:42:29 - GraphTrainer - INFO -   map@10: 0.014225
2025-12-26 20:42:29 - GraphTrainer - INFO -   mrr@10: 0.015125
2025-12-26 20:42:29 - GraphTrainer - INFO -   precision@20: 0.003242
2025-12-26 20:42:29 - GraphTrainer - INFO -   recall@20: 0.060800
2025-12-26 20:42:29 - GraphTrainer - INFO -   hit_rate@20: 0.064438
2025-12-26 20:42:29 - GraphTrainer - INFO -   ndcg@20: 0.025799
2025-12-26 20:42:29 - GraphTrainer - INFO -   map@20: 0.015807
2025-12-26 20:42:29 - GraphTrainer - INFO -   mrr@20: 0.016790
2025-12-26 20:42:29 - GraphTrainer - INFO - 第 27 轮训练完成
2025-12-26 20:42:29 - GraphTrainer - INFO - train_loss: 1.424212
2025-12-26 20:42:29 - GraphTrainer - INFO - precision@5: 0.004937
2025-12-26 20:42:29 - GraphTrainer - INFO - recall@5: 0.023136
2025-12-26 20:42:29 - GraphTrainer - INFO - hit_rate@5: 0.024685
2025-12-26 20:42:29 - GraphTrainer - INFO - ndcg@5: 0.015216
2025-12-26 20:42:29 - GraphTrainer - INFO - map@5: 0.012343
2025-12-26 20:42:29 - GraphTrainer - INFO - mrr@5: 0.013146
2025-12-26 20:42:29 - GraphTrainer - INFO - precision@10: 0.004022
2025-12-26 20:42:29 - GraphTrainer - INFO - recall@10: 0.037734
2025-12-26 20:42:29 - GraphTrainer - INFO - hit_rate@10: 0.040062
2025-12-26 20:42:29 - GraphTrainer - INFO - ndcg@10: 0.019919
2025-12-26 20:42:29 - GraphTrainer - INFO - map@10: 0.014225
2025-12-26 20:42:29 - GraphTrainer - INFO - mrr@10: 0.015125
2025-12-26 20:42:29 - GraphTrainer - INFO - precision@20: 0.003242
2025-12-26 20:42:29 - GraphTrainer - INFO - recall@20: 0.060800
2025-12-26 20:42:29 - GraphTrainer - INFO - hit_rate@20: 0.064438
2025-12-26 20:42:29 - GraphTrainer - INFO - ndcg@20: 0.025799
2025-12-26 20:42:29 - GraphTrainer - INFO - map@20: 0.015807
2025-12-26 20:42:29 - GraphTrainer - INFO - mrr@20: 0.016790
2025-12-26 20:42:29 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:42:29 - GraphTrainer - INFO - ============================================================
2025-12-26 20:42:29 - GraphTrainer - INFO - 开始第 28/1000 轮训练
2025-12-26 20:42:29 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(1.4469, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(1.4062, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(1.4327, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(1.4129, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(1.4538, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(1.3910, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(1.3812, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(1.4230, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(1.4159, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(1.3689, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(1.4003, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(1.4438, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(1.3958, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(1.3798, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(1.3504, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(1.3975, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(1.3927, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(1.3736, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(1.4354, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(1.3916, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(1.4245, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(1.4220, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(1.3920, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(1.4393, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(1.4362, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(1.4647, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(1.4150, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(1.4237, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(1.4297, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(1.4647, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(1.4690, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(1.3727, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(1.4618, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(1.4569, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(1.4518, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(1.4373, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(1.4627, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(1.4407, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(1.5064, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(1.4095, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(1.4190, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(1.4056, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(1.4435, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(1.4755, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(1.4640, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(1.4021, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(1.4363, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(1.4169, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(1.4431, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(1.3370, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(1.3878, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(1.4131, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(1.4350, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(1.4493, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(1.4619, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(1.4566, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(1.4355, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(1.4480, device='cuda:0', grad_fn=<AddBackward0>)
The 27 training average loss: 1.4242118000984192
2025-12-26 20:42:40 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:42:40 - GraphTrainer - INFO -   precision@5: 0.004803
2025-12-26 20:42:40 - GraphTrainer - INFO -   recall@5: 0.022532
2025-12-26 20:42:40 - GraphTrainer - INFO -   hit_rate@5: 0.024016
2025-12-26 20:42:40 - GraphTrainer - INFO -   ndcg@5: 0.015307
2025-12-26 20:42:40 - GraphTrainer - INFO -   map@5: 0.012670
2025-12-26 20:42:40 - GraphTrainer - INFO -   mrr@5: 0.013472
2025-12-26 20:42:40 - GraphTrainer - INFO -   precision@10: 0.004011
2025-12-26 20:42:40 - GraphTrainer - INFO -   recall@10: 0.037436
2025-12-26 20:42:40 - GraphTrainer - INFO -   hit_rate@10: 0.039856
2025-12-26 20:42:40 - GraphTrainer - INFO -   ndcg@10: 0.020164
2025-12-26 20:42:40 - GraphTrainer - INFO -   map@10: 0.014637
2025-12-26 20:42:40 - GraphTrainer - INFO -   mrr@10: 0.015559
2025-12-26 20:42:40 - GraphTrainer - INFO -   precision@20: 0.003255
2025-12-26 20:42:40 - GraphTrainer - INFO -   recall@20: 0.060991
2025-12-26 20:42:40 - GraphTrainer - INFO -   hit_rate@20: 0.064592
2025-12-26 20:42:40 - GraphTrainer - INFO -   ndcg@20: 0.026145
2025-12-26 20:42:40 - GraphTrainer - INFO -   map@20: 0.016239
2025-12-26 20:42:40 - GraphTrainer - INFO -   mrr@20: 0.017231
2025-12-26 20:42:40 - GraphTrainer - INFO - 第 28 轮训练完成
2025-12-26 20:42:40 - GraphTrainer - INFO - train_loss: 1.374159
2025-12-26 20:42:40 - GraphTrainer - INFO - precision@5: 0.004803
2025-12-26 20:42:40 - GraphTrainer - INFO - recall@5: 0.022532
2025-12-26 20:42:40 - GraphTrainer - INFO - hit_rate@5: 0.024016
2025-12-26 20:42:40 - GraphTrainer - INFO - ndcg@5: 0.015307
2025-12-26 20:42:40 - GraphTrainer - INFO - map@5: 0.012670
2025-12-26 20:42:40 - GraphTrainer - INFO - mrr@5: 0.013472
2025-12-26 20:42:40 - GraphTrainer - INFO - precision@10: 0.004011
2025-12-26 20:42:40 - GraphTrainer - INFO - recall@10: 0.037436
2025-12-26 20:42:40 - GraphTrainer - INFO - hit_rate@10: 0.039856
2025-12-26 20:42:40 - GraphTrainer - INFO - ndcg@10: 0.020164
2025-12-26 20:42:40 - GraphTrainer - INFO - map@10: 0.014637
2025-12-26 20:42:40 - GraphTrainer - INFO - mrr@10: 0.015559
2025-12-26 20:42:40 - GraphTrainer - INFO - precision@20: 0.003255
2025-12-26 20:42:40 - GraphTrainer - INFO - recall@20: 0.060991
2025-12-26 20:42:40 - GraphTrainer - INFO - hit_rate@20: 0.064592
2025-12-26 20:42:40 - GraphTrainer - INFO - ndcg@20: 0.026145
2025-12-26 20:42:40 - GraphTrainer - INFO - map@20: 0.016239
2025-12-26 20:42:40 - GraphTrainer - INFO - mrr@20: 0.017231
2025-12-26 20:42:40 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:42:40 - GraphTrainer - INFO - ============================================================
2025-12-26 20:42:40 - GraphTrainer - INFO - 开始第 29/1000 轮训练
2025-12-26 20:42:40 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(1.4085, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(1.3724, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(1.3758, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(1.3516, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(1.3686, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(1.3735, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(1.3981, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(1.3637, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(1.4316, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(1.3935, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(1.3420, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(1.3505, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(1.3582, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(1.3787, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(1.3969, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(1.3671, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(1.3743, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(1.2978, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(1.3658, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(1.3749, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(1.4418, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(1.4165, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(1.4256, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(1.3721, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(1.4099, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(1.3688, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(1.4104, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(1.3378, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(1.3397, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(1.3682, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(1.3801, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(1.3453, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(1.3758, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(1.3823, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(1.3118, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(1.3580, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(1.3928, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(1.3668, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(1.3780, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(1.4123, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(1.3480, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(1.4019, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(1.3424, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(1.3829, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(1.3371, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(1.3772, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(1.3666, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(1.3716, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(1.4044, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(1.3872, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(1.3555, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(1.3651, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(1.3417, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(1.4305, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(1.3806, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(1.3143, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(1.3802, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(1.3767, device='cuda:0', grad_fn=<AddBackward0>)
The 28 training average loss: 1.3741587174349819
2025-12-26 20:42:50 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:42:50 - GraphTrainer - INFO -   precision@5: 0.004628
2025-12-26 20:42:50 - GraphTrainer - INFO -   recall@5: 0.021759
2025-12-26 20:42:50 - GraphTrainer - INFO -   hit_rate@5: 0.023142
2025-12-26 20:42:50 - GraphTrainer - INFO -   ndcg@5: 0.014134
2025-12-26 20:42:50 - GraphTrainer - INFO -   map@5: 0.011370
2025-12-26 20:42:50 - GraphTrainer - INFO -   mrr@5: 0.012232
2025-12-26 20:42:50 - GraphTrainer - INFO -   precision@10: 0.003713
2025-12-26 20:42:50 - GraphTrainer - INFO -   recall@10: 0.034892
2025-12-26 20:42:50 - GraphTrainer - INFO -   hit_rate@10: 0.037079
2025-12-26 20:42:50 - GraphTrainer - INFO -   ndcg@10: 0.018397
2025-12-26 20:42:50 - GraphTrainer - INFO -   map@10: 0.013090
2025-12-26 20:42:50 - GraphTrainer - INFO -   mrr@10: 0.014055
2025-12-26 20:42:50 - GraphTrainer - INFO -   precision@20: 0.003114
2025-12-26 20:42:50 - GraphTrainer - INFO -   recall@20: 0.058242
2025-12-26 20:42:50 - GraphTrainer - INFO -   hit_rate@20: 0.061867
2025-12-26 20:42:50 - GraphTrainer - INFO -   ndcg@20: 0.024352
2025-12-26 20:42:50 - GraphTrainer - INFO -   map@20: 0.014687
2025-12-26 20:42:50 - GraphTrainer - INFO -   mrr@20: 0.015740
2025-12-26 20:42:51 - GraphTrainer - INFO - 第 29 轮训练完成
2025-12-26 20:42:51 - GraphTrainer - INFO - train_loss: 1.357672
2025-12-26 20:42:51 - GraphTrainer - INFO - precision@5: 0.004628
2025-12-26 20:42:51 - GraphTrainer - INFO - recall@5: 0.021759
2025-12-26 20:42:51 - GraphTrainer - INFO - hit_rate@5: 0.023142
2025-12-26 20:42:51 - GraphTrainer - INFO - ndcg@5: 0.014134
2025-12-26 20:42:51 - GraphTrainer - INFO - map@5: 0.011370
2025-12-26 20:42:51 - GraphTrainer - INFO - mrr@5: 0.012232
2025-12-26 20:42:51 - GraphTrainer - INFO - precision@10: 0.003713
2025-12-26 20:42:51 - GraphTrainer - INFO - recall@10: 0.034892
2025-12-26 20:42:51 - GraphTrainer - INFO - hit_rate@10: 0.037079
2025-12-26 20:42:51 - GraphTrainer - INFO - ndcg@10: 0.018397
2025-12-26 20:42:51 - GraphTrainer - INFO - map@10: 0.013090
2025-12-26 20:42:51 - GraphTrainer - INFO - mrr@10: 0.014055
2025-12-26 20:42:51 - GraphTrainer - INFO - precision@20: 0.003114
2025-12-26 20:42:51 - GraphTrainer - INFO - recall@20: 0.058242
2025-12-26 20:42:51 - GraphTrainer - INFO - hit_rate@20: 0.061867
2025-12-26 20:42:51 - GraphTrainer - INFO - ndcg@20: 0.024352
2025-12-26 20:42:51 - GraphTrainer - INFO - map@20: 0.014687
2025-12-26 20:42:51 - GraphTrainer - INFO - mrr@20: 0.015740
2025-12-26 20:42:51 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:42:51 - GraphTrainer - INFO - ============================================================
2025-12-26 20:42:51 - GraphTrainer - INFO - 开始第 30/1000 轮训练
2025-12-26 20:42:51 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(1.4420, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(1.3389, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(1.3947, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(1.3623, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(1.3555, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(1.3986, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(1.3693, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(1.3120, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(1.3685, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(1.3730, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(1.3165, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(1.3121, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(1.3334, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(1.3250, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(1.3488, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(1.3356, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(1.2860, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(1.3661, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(1.3167, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(1.2667, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(1.4294, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(1.3607, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(1.3715, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(1.3606, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(1.3446, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(1.4163, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(1.3350, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(1.3253, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(1.3759, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(1.3421, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(1.3620, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(1.3919, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(1.3833, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(1.3600, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(1.3661, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(1.3221, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(1.3632, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(1.3747, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(1.3664, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(1.3937, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(1.3972, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(1.3348, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(1.4016, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(1.3403, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(1.3568, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(1.3441, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(1.2956, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(1.3413, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(1.3171, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(1.3565, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(1.4001, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(1.3479, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(1.3018, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(1.3737, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(1.3376, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(1.4274, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(1.4220, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(1.3831, device='cuda:0', grad_fn=<AddBackward0>)
The 29 training average loss: 1.3576721692907399
2025-12-26 20:43:01 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:43:01 - GraphTrainer - INFO -   precision@5: 0.004433
2025-12-26 20:43:01 - GraphTrainer - INFO -   recall@5: 0.020725
2025-12-26 20:43:01 - GraphTrainer - INFO -   hit_rate@5: 0.022114
2025-12-26 20:43:01 - GraphTrainer - INFO -   ndcg@5: 0.013553
2025-12-26 20:43:01 - GraphTrainer - INFO -   map@5: 0.010955
2025-12-26 20:43:01 - GraphTrainer - INFO -   mrr@5: 0.011747
2025-12-26 20:43:01 - GraphTrainer - INFO -   precision@10: 0.003754
2025-12-26 20:43:01 - GraphTrainer - INFO -   recall@10: 0.035179
2025-12-26 20:43:01 - GraphTrainer - INFO -   hit_rate@10: 0.037388
2025-12-26 20:43:01 - GraphTrainer - INFO -   ndcg@10: 0.018260
2025-12-26 20:43:01 - GraphTrainer - INFO -   map@10: 0.012869
2025-12-26 20:43:01 - GraphTrainer - INFO -   mrr@10: 0.013762
2025-12-26 20:43:01 - GraphTrainer - INFO -   precision@20: 0.003163
2025-12-26 20:43:01 - GraphTrainer - INFO -   recall@20: 0.059438
2025-12-26 20:43:01 - GraphTrainer - INFO -   hit_rate@20: 0.062947
2025-12-26 20:43:01 - GraphTrainer - INFO -   ndcg@20: 0.024440
2025-12-26 20:43:01 - GraphTrainer - INFO -   map@20: 0.014534
2025-12-26 20:43:01 - GraphTrainer - INFO -   mrr@20: 0.015510
2025-12-26 20:43:01 - GraphTrainer - INFO - 第 30 轮训练完成
2025-12-26 20:43:01 - GraphTrainer - INFO - train_loss: 1.341207
2025-12-26 20:43:01 - GraphTrainer - INFO - precision@5: 0.004433
2025-12-26 20:43:01 - GraphTrainer - INFO - recall@5: 0.020725
2025-12-26 20:43:01 - GraphTrainer - INFO - hit_rate@5: 0.022114
2025-12-26 20:43:01 - GraphTrainer - INFO - ndcg@5: 0.013553
2025-12-26 20:43:01 - GraphTrainer - INFO - map@5: 0.010955
2025-12-26 20:43:01 - GraphTrainer - INFO - mrr@5: 0.011747
2025-12-26 20:43:01 - GraphTrainer - INFO - precision@10: 0.003754
2025-12-26 20:43:01 - GraphTrainer - INFO - recall@10: 0.035179
2025-12-26 20:43:01 - GraphTrainer - INFO - hit_rate@10: 0.037388
2025-12-26 20:43:01 - GraphTrainer - INFO - ndcg@10: 0.018260
2025-12-26 20:43:01 - GraphTrainer - INFO - map@10: 0.012869
2025-12-26 20:43:01 - GraphTrainer - INFO - mrr@10: 0.013762
2025-12-26 20:43:01 - GraphTrainer - INFO - precision@20: 0.003163
2025-12-26 20:43:01 - GraphTrainer - INFO - recall@20: 0.059438
2025-12-26 20:43:01 - GraphTrainer - INFO - hit_rate@20: 0.062947
2025-12-26 20:43:01 - GraphTrainer - INFO - ndcg@20: 0.024440
2025-12-26 20:43:01 - GraphTrainer - INFO - map@20: 0.014534
2025-12-26 20:43:01 - GraphTrainer - INFO - mrr@20: 0.015510
2025-12-26 20:43:01 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:43:01 - GraphTrainer - INFO - 检查点已保存: Epoch 30 -> ./checkpoints/checkpoint_epoch_30.pth
2025-12-26 20:43:01 - GraphTrainer - INFO - ============================================================
2025-12-26 20:43:01 - GraphTrainer - INFO - 开始第 31/1000 轮训练
2025-12-26 20:43:01 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(1.2859, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(1.3836, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(1.3640, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(1.3474, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(1.3122, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(1.3147, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(1.2674, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(1.3392, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(1.3378, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(1.3312, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(1.3424, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(1.3161, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(1.3942, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(1.3241, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(1.3001, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(1.3823, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(1.3473, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(1.3072, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(1.3465, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(1.3720, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(1.3207, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(1.3273, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(1.2892, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(1.3190, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(1.3368, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(1.3759, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(1.3506, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(1.3408, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(1.3649, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(1.3385, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(1.3511, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(1.3235, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(1.3596, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(1.3445, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(1.3581, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(1.3512, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(1.3754, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(1.3939, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(1.3112, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(1.3395, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(1.3352, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(1.3273, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(1.3172, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(1.3870, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(1.3308, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(1.3262, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(1.3848, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(1.3915, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(1.3832, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(1.3158, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(1.3205, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(1.3527, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(1.3569, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(1.3266, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(1.3681, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(1.3376, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(1.3093, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(1.3321, device='cuda:0', grad_fn=<AddBackward0>)
The 30 training average loss: 1.3412071980279068
2025-12-26 20:43:12 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:43:12 - GraphTrainer - INFO -   precision@5: 0.004526
2025-12-26 20:43:12 - GraphTrainer - INFO -   recall@5: 0.021106
2025-12-26 20:43:12 - GraphTrainer - INFO -   hit_rate@5: 0.022576
2025-12-26 20:43:12 - GraphTrainer - INFO -   ndcg@5: 0.013845
2025-12-26 20:43:12 - GraphTrainer - INFO -   map@5: 0.011217
2025-12-26 20:43:12 - GraphTrainer - INFO -   mrr@5: 0.012019
2025-12-26 20:43:12 - GraphTrainer - INFO -   precision@10: 0.003811
2025-12-26 20:43:12 - GraphTrainer - INFO -   recall@10: 0.035798
2025-12-26 20:43:12 - GraphTrainer - INFO -   hit_rate@10: 0.037953
2025-12-26 20:43:12 - GraphTrainer - INFO -   ndcg@10: 0.018597
2025-12-26 20:43:12 - GraphTrainer - INFO -   map@10: 0.013139
2025-12-26 20:43:12 - GraphTrainer - INFO -   mrr@10: 0.014027
2025-12-26 20:43:12 - GraphTrainer - INFO -   precision@20: 0.003068
2025-12-26 20:43:12 - GraphTrainer - INFO -   recall@20: 0.057691
2025-12-26 20:43:12 - GraphTrainer - INFO -   hit_rate@20: 0.061044
2025-12-26 20:43:12 - GraphTrainer - INFO -   ndcg@20: 0.024179
2025-12-26 20:43:12 - GraphTrainer - INFO -   map@20: 0.014644
2025-12-26 20:43:12 - GraphTrainer - INFO -   mrr@20: 0.015610
2025-12-26 20:43:12 - GraphTrainer - INFO - 第 31 轮训练完成
2025-12-26 20:43:12 - GraphTrainer - INFO - train_loss: 1.331550
2025-12-26 20:43:12 - GraphTrainer - INFO - precision@5: 0.004526
2025-12-26 20:43:12 - GraphTrainer - INFO - recall@5: 0.021106
2025-12-26 20:43:12 - GraphTrainer - INFO - hit_rate@5: 0.022576
2025-12-26 20:43:12 - GraphTrainer - INFO - ndcg@5: 0.013845
2025-12-26 20:43:12 - GraphTrainer - INFO - map@5: 0.011217
2025-12-26 20:43:12 - GraphTrainer - INFO - mrr@5: 0.012019
2025-12-26 20:43:12 - GraphTrainer - INFO - precision@10: 0.003811
2025-12-26 20:43:12 - GraphTrainer - INFO - recall@10: 0.035798
2025-12-26 20:43:12 - GraphTrainer - INFO - hit_rate@10: 0.037953
2025-12-26 20:43:12 - GraphTrainer - INFO - ndcg@10: 0.018597
2025-12-26 20:43:12 - GraphTrainer - INFO - map@10: 0.013139
2025-12-26 20:43:12 - GraphTrainer - INFO - mrr@10: 0.014027
2025-12-26 20:43:12 - GraphTrainer - INFO - precision@20: 0.003068
2025-12-26 20:43:12 - GraphTrainer - INFO - recall@20: 0.057691
2025-12-26 20:43:12 - GraphTrainer - INFO - hit_rate@20: 0.061044
2025-12-26 20:43:12 - GraphTrainer - INFO - ndcg@20: 0.024179
2025-12-26 20:43:12 - GraphTrainer - INFO - map@20: 0.014644
2025-12-26 20:43:12 - GraphTrainer - INFO - mrr@20: 0.015610
2025-12-26 20:43:12 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:43:12 - GraphTrainer - INFO - ============================================================
2025-12-26 20:43:12 - GraphTrainer - INFO - 开始第 32/1000 轮训练
2025-12-26 20:43:12 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(1.3067, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(1.3106, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(1.3396, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(1.3224, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(1.2970, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(1.2848, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(1.3740, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(1.3269, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(1.3652, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(1.3668, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(1.3601, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(1.3688, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(1.3294, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(1.3331, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(1.3243, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(1.3141, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(1.3360, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(1.3604, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(1.3322, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(1.3417, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(1.3866, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(1.3277, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(1.3475, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(1.3086, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(1.3680, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(1.3780, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(1.3124, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(1.3410, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(1.3467, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(1.3207, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(1.3702, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(1.3473, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(1.3300, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(1.3357, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(1.3396, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(1.3545, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(1.3361, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(1.3193, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(1.3089, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(1.2922, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(1.3003, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(1.2988, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(1.3257, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(1.3907, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(1.2935, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(1.3390, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(1.3271, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(1.2973, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(1.3052, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(1.3019, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(1.3220, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(1.3052, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(1.3607, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(1.3240, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(1.3304, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(1.3334, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(1.3321, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(1.2778, device='cuda:0', grad_fn=<AddBackward0>)
The 31 training average loss: 1.3315503494492893
2025-12-26 20:43:23 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:43:23 - GraphTrainer - INFO -   precision@5: 0.004454
2025-12-26 20:43:23 - GraphTrainer - INFO -   recall@5: 0.020836
2025-12-26 20:43:23 - GraphTrainer - INFO -   hit_rate@5: 0.022217
2025-12-26 20:43:23 - GraphTrainer - INFO -   ndcg@5: 0.013461
2025-12-26 20:43:23 - GraphTrainer - INFO -   map@5: 0.010820
2025-12-26 20:43:23 - GraphTrainer - INFO -   mrr@5: 0.011493
2025-12-26 20:43:23 - GraphTrainer - INFO -   precision@10: 0.003744
2025-12-26 20:43:23 - GraphTrainer - INFO -   recall@10: 0.035094
2025-12-26 20:43:23 - GraphTrainer - INFO -   hit_rate@10: 0.037388
2025-12-26 20:43:23 - GraphTrainer - INFO -   ndcg@10: 0.018085
2025-12-26 20:43:23 - GraphTrainer - INFO -   map@10: 0.012684
2025-12-26 20:43:23 - GraphTrainer - INFO -   mrr@10: 0.013480
2025-12-26 20:43:23 - GraphTrainer - INFO -   precision@20: 0.003078
2025-12-26 20:43:23 - GraphTrainer - INFO -   recall@20: 0.058191
2025-12-26 20:43:23 - GraphTrainer - INFO -   hit_rate@20: 0.061198
2025-12-26 20:43:23 - GraphTrainer - INFO -   ndcg@20: 0.023944
2025-12-26 20:43:23 - GraphTrainer - INFO -   map@20: 0.014265
2025-12-26 20:43:23 - GraphTrainer - INFO -   mrr@20: 0.015104
2025-12-26 20:43:23 - GraphTrainer - INFO - 第 32 轮训练完成
2025-12-26 20:43:23 - GraphTrainer - INFO - train_loss: 1.307253
2025-12-26 20:43:23 - GraphTrainer - INFO - precision@5: 0.004454
2025-12-26 20:43:23 - GraphTrainer - INFO - recall@5: 0.020836
2025-12-26 20:43:23 - GraphTrainer - INFO - hit_rate@5: 0.022217
2025-12-26 20:43:23 - GraphTrainer - INFO - ndcg@5: 0.013461
2025-12-26 20:43:23 - GraphTrainer - INFO - map@5: 0.010820
2025-12-26 20:43:23 - GraphTrainer - INFO - mrr@5: 0.011493
2025-12-26 20:43:23 - GraphTrainer - INFO - precision@10: 0.003744
2025-12-26 20:43:23 - GraphTrainer - INFO - recall@10: 0.035094
2025-12-26 20:43:23 - GraphTrainer - INFO - hit_rate@10: 0.037388
2025-12-26 20:43:23 - GraphTrainer - INFO - ndcg@10: 0.018085
2025-12-26 20:43:23 - GraphTrainer - INFO - map@10: 0.012684
2025-12-26 20:43:23 - GraphTrainer - INFO - mrr@10: 0.013480
2025-12-26 20:43:23 - GraphTrainer - INFO - precision@20: 0.003078
2025-12-26 20:43:23 - GraphTrainer - INFO - recall@20: 0.058191
2025-12-26 20:43:23 - GraphTrainer - INFO - hit_rate@20: 0.061198
2025-12-26 20:43:23 - GraphTrainer - INFO - ndcg@20: 0.023944
2025-12-26 20:43:23 - GraphTrainer - INFO - map@20: 0.014265
2025-12-26 20:43:23 - GraphTrainer - INFO - mrr@20: 0.015104
2025-12-26 20:43:23 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:43:23 - GraphTrainer - INFO - ============================================================
2025-12-26 20:43:23 - GraphTrainer - INFO - 开始第 33/1000 轮训练
2025-12-26 20:43:23 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(1.3261, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(1.2660, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(1.2914, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(1.2558, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(1.1858, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(1.2972, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(1.2970, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(1.3175, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(1.2755, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(1.2856, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(1.3918, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(1.3133, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(1.3343, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(1.2588, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(1.2688, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(1.2614, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(1.2901, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(1.2746, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(1.3414, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(1.3008, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(1.3003, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(1.3344, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(1.2796, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(1.3677, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(1.3311, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(1.3260, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(1.2846, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(1.3216, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(1.3042, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(1.3778, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(1.3406, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(1.3243, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(1.3127, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(1.3329, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(1.2888, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(1.2928, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(1.3258, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(1.3493, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(1.3128, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(1.2970, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(1.2825, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(1.3218, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(1.3672, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(1.2599, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(1.2912, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(1.3103, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(1.3370, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(1.2980, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(1.3425, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(1.3042, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(1.2924, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(1.3172, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(1.3250, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(1.3075, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(1.2918, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(1.2973, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(1.3020, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(1.3354, device='cuda:0', grad_fn=<AddBackward0>)
The 32 training average loss: 1.3072528818558002
2025-12-26 20:43:33 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:43:33 - GraphTrainer - INFO -   precision@5: 0.004824
2025-12-26 20:43:33 - GraphTrainer - INFO -   recall@5: 0.022628
2025-12-26 20:43:33 - GraphTrainer - INFO -   hit_rate@5: 0.024119
2025-12-26 20:43:33 - GraphTrainer - INFO -   ndcg@5: 0.014703
2025-12-26 20:43:33 - GraphTrainer - INFO -   map@5: 0.011852
2025-12-26 20:43:33 - GraphTrainer - INFO -   mrr@5: 0.012626
2025-12-26 20:43:33 - GraphTrainer - INFO -   precision@10: 0.003893
2025-12-26 20:43:33 - GraphTrainer - INFO -   recall@10: 0.036485
2025-12-26 20:43:33 - GraphTrainer - INFO -   hit_rate@10: 0.038776
2025-12-26 20:43:33 - GraphTrainer - INFO -   ndcg@10: 0.019206
2025-12-26 20:43:33 - GraphTrainer - INFO -   map@10: 0.013675
2025-12-26 20:43:33 - GraphTrainer - INFO -   mrr@10: 0.014545
2025-12-26 20:43:33 - GraphTrainer - INFO -   precision@20: 0.003230
2025-12-26 20:43:33 - GraphTrainer - INFO -   recall@20: 0.060648
2025-12-26 20:43:33 - GraphTrainer - INFO -   hit_rate@20: 0.064078
2025-12-26 20:43:33 - GraphTrainer - INFO -   ndcg@20: 0.025302
2025-12-26 20:43:33 - GraphTrainer - INFO -   map@20: 0.015290
2025-12-26 20:43:33 - GraphTrainer - INFO -   mrr@20: 0.016228
2025-12-26 20:43:33 - GraphTrainer - INFO - 第 33 轮训练完成
2025-12-26 20:43:33 - GraphTrainer - INFO - train_loss: 1.297830
2025-12-26 20:43:33 - GraphTrainer - INFO - precision@5: 0.004824
2025-12-26 20:43:33 - GraphTrainer - INFO - recall@5: 0.022628
2025-12-26 20:43:33 - GraphTrainer - INFO - hit_rate@5: 0.024119
2025-12-26 20:43:33 - GraphTrainer - INFO - ndcg@5: 0.014703
2025-12-26 20:43:33 - GraphTrainer - INFO - map@5: 0.011852
2025-12-26 20:43:33 - GraphTrainer - INFO - mrr@5: 0.012626
2025-12-26 20:43:33 - GraphTrainer - INFO - precision@10: 0.003893
2025-12-26 20:43:33 - GraphTrainer - INFO - recall@10: 0.036485
2025-12-26 20:43:33 - GraphTrainer - INFO - hit_rate@10: 0.038776
2025-12-26 20:43:33 - GraphTrainer - INFO - ndcg@10: 0.019206
2025-12-26 20:43:33 - GraphTrainer - INFO - map@10: 0.013675
2025-12-26 20:43:33 - GraphTrainer - INFO - mrr@10: 0.014545
2025-12-26 20:43:33 - GraphTrainer - INFO - precision@20: 0.003230
2025-12-26 20:43:33 - GraphTrainer - INFO - recall@20: 0.060648
2025-12-26 20:43:33 - GraphTrainer - INFO - hit_rate@20: 0.064078
2025-12-26 20:43:33 - GraphTrainer - INFO - ndcg@20: 0.025302
2025-12-26 20:43:33 - GraphTrainer - INFO - map@20: 0.015290
2025-12-26 20:43:33 - GraphTrainer - INFO - mrr@20: 0.016228
2025-12-26 20:43:33 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:43:33 - GraphTrainer - INFO - ============================================================
2025-12-26 20:43:33 - GraphTrainer - INFO - 开始第 34/1000 轮训练
2025-12-26 20:43:33 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(1.3070, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(1.3276, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(1.2755, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(1.3139, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(1.2990, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(1.2809, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(1.2715, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(1.2699, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(1.3135, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(1.2380, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(1.2432, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(1.3024, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(1.2816, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(1.2500, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(1.2979, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(1.2293, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(1.3335, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(1.3495, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(1.3162, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(1.3157, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(1.2871, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(1.3045, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(1.3069, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(1.3410, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(1.2952, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(1.2866, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(1.3176, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(1.2640, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(1.2903, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(1.3018, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(1.3248, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(1.2549, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(1.3411, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(1.2855, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(1.2996, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(1.2726, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(1.2939, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(1.3744, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(1.2658, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(1.3164, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(1.3148, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(1.3198, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(1.3061, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(1.2839, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(1.2958, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(1.3071, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(1.3195, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(1.3161, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(1.2962, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(1.2840, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(1.2858, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(1.2795, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(1.3049, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(1.2827, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(1.2965, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(1.3157, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(1.3170, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(1.3085, device='cuda:0', grad_fn=<AddBackward0>)
The 33 training average loss: 1.297829778030001
2025-12-26 20:43:43 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:43:43 - GraphTrainer - INFO -   precision@5: 0.004464
2025-12-26 20:43:43 - GraphTrainer - INFO -   recall@5: 0.020928
2025-12-26 20:43:43 - GraphTrainer - INFO -   hit_rate@5: 0.022319
2025-12-26 20:43:43 - GraphTrainer - INFO -   ndcg@5: 0.013285
2025-12-26 20:43:43 - GraphTrainer - INFO -   map@5: 0.010543
2025-12-26 20:43:43 - GraphTrainer - INFO -   mrr@5: 0.011307
2025-12-26 20:43:43 - GraphTrainer - INFO -   precision@10: 0.003692
2025-12-26 20:43:43 - GraphTrainer - INFO -   recall@10: 0.034598
2025-12-26 20:43:43 - GraphTrainer - INFO -   hit_rate@10: 0.036822
2025-12-26 20:43:43 - GraphTrainer - INFO -   ndcg@10: 0.017699
2025-12-26 20:43:43 - GraphTrainer - INFO -   map@10: 0.012307
2025-12-26 20:43:43 - GraphTrainer - INFO -   mrr@10: 0.013186
2025-12-26 20:43:43 - GraphTrainer - INFO -   precision@20: 0.003073
2025-12-26 20:43:43 - GraphTrainer - INFO -   recall@20: 0.057819
2025-12-26 20:43:43 - GraphTrainer - INFO -   hit_rate@20: 0.061044
2025-12-26 20:43:43 - GraphTrainer - INFO -   ndcg@20: 0.023584
2025-12-26 20:43:43 - GraphTrainer - INFO -   map@20: 0.013882
2025-12-26 20:43:43 - GraphTrainer - INFO -   mrr@20: 0.014827
2025-12-26 20:43:43 - GraphTrainer - INFO - 第 34 轮训练完成
2025-12-26 20:43:43 - GraphTrainer - INFO - train_loss: 1.281280
2025-12-26 20:43:43 - GraphTrainer - INFO - precision@5: 0.004464
2025-12-26 20:43:43 - GraphTrainer - INFO - recall@5: 0.020928
2025-12-26 20:43:43 - GraphTrainer - INFO - hit_rate@5: 0.022319
2025-12-26 20:43:43 - GraphTrainer - INFO - ndcg@5: 0.013285
2025-12-26 20:43:43 - GraphTrainer - INFO - map@5: 0.010543
2025-12-26 20:43:43 - GraphTrainer - INFO - mrr@5: 0.011307
2025-12-26 20:43:43 - GraphTrainer - INFO - precision@10: 0.003692
2025-12-26 20:43:43 - GraphTrainer - INFO - recall@10: 0.034598
2025-12-26 20:43:43 - GraphTrainer - INFO - hit_rate@10: 0.036822
2025-12-26 20:43:43 - GraphTrainer - INFO - ndcg@10: 0.017699
2025-12-26 20:43:43 - GraphTrainer - INFO - map@10: 0.012307
2025-12-26 20:43:43 - GraphTrainer - INFO - mrr@10: 0.013186
2025-12-26 20:43:43 - GraphTrainer - INFO - precision@20: 0.003073
2025-12-26 20:43:43 - GraphTrainer - INFO - recall@20: 0.057819
2025-12-26 20:43:43 - GraphTrainer - INFO - hit_rate@20: 0.061044
2025-12-26 20:43:43 - GraphTrainer - INFO - ndcg@20: 0.023584
2025-12-26 20:43:43 - GraphTrainer - INFO - map@20: 0.013882
2025-12-26 20:43:43 - GraphTrainer - INFO - mrr@20: 0.014827
2025-12-26 20:43:43 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:43:43 - GraphTrainer - INFO - ============================================================
2025-12-26 20:43:43 - GraphTrainer - INFO - 开始第 35/1000 轮训练
2025-12-26 20:43:43 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(1.2901, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(1.2467, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(1.2655, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(1.2509, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(1.2995, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(1.2153, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(1.2458, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(1.2878, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(1.2703, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(1.3213, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(1.3020, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(1.2925, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(1.2606, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(1.2742, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(1.3011, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(1.2967, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(1.3164, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(1.3437, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(1.2524, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(1.2607, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(1.2799, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(1.2128, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(1.2832, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(1.3099, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(1.2610, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(1.3057, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(1.2395, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(1.2833, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(1.1968, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(1.2723, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(1.2763, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(1.2595, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(1.2573, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(1.3002, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(1.2707, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(1.3059, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(1.2494, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(1.3119, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(1.2841, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(1.2898, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(1.2616, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(1.3050, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(1.3140, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(1.2663, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(1.3117, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(1.2888, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(1.2909, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(1.2775, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(1.2949, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(1.3040, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(1.2763, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(1.2967, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(1.3213, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(1.2850, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(1.2815, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(1.2818, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(1.3209, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(1.2935, device='cuda:0', grad_fn=<AddBackward0>)
The 34 training average loss: 1.281279781769062
2025-12-26 20:43:53 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:43:53 - GraphTrainer - INFO -   precision@5: 0.004577
2025-12-26 20:43:53 - GraphTrainer - INFO -   recall@5: 0.021317
2025-12-26 20:43:53 - GraphTrainer - INFO -   hit_rate@5: 0.022834
2025-12-26 20:43:53 - GraphTrainer - INFO -   ndcg@5: 0.013921
2025-12-26 20:43:53 - GraphTrainer - INFO -   map@5: 0.011214
2025-12-26 20:43:53 - GraphTrainer - INFO -   mrr@5: 0.012122
2025-12-26 20:43:53 - GraphTrainer - INFO -   precision@10: 0.003908
2025-12-26 20:43:53 - GraphTrainer - INFO -   recall@10: 0.036761
2025-12-26 20:43:53 - GraphTrainer - INFO -   hit_rate@10: 0.038982
2025-12-26 20:43:53 - GraphTrainer - INFO -   ndcg@10: 0.018898
2025-12-26 20:43:53 - GraphTrainer - INFO -   map@10: 0.013221
2025-12-26 20:43:53 - GraphTrainer - INFO -   mrr@10: 0.014217
2025-12-26 20:43:53 - GraphTrainer - INFO -   precision@20: 0.003204
2025-12-26 20:43:53 - GraphTrainer - INFO -   recall@20: 0.060084
2025-12-26 20:43:53 - GraphTrainer - INFO -   hit_rate@20: 0.063718
2025-12-26 20:43:53 - GraphTrainer - INFO -   ndcg@20: 0.024837
2025-12-26 20:43:53 - GraphTrainer - INFO -   map@20: 0.014809
2025-12-26 20:43:53 - GraphTrainer - INFO -   mrr@20: 0.015894
2025-12-26 20:43:53 - GraphTrainer - INFO - 第 35 轮训练完成
2025-12-26 20:43:53 - GraphTrainer - INFO - train_loss: 1.263781
2025-12-26 20:43:53 - GraphTrainer - INFO - precision@5: 0.004577
2025-12-26 20:43:53 - GraphTrainer - INFO - recall@5: 0.021317
2025-12-26 20:43:53 - GraphTrainer - INFO - hit_rate@5: 0.022834
2025-12-26 20:43:53 - GraphTrainer - INFO - ndcg@5: 0.013921
2025-12-26 20:43:53 - GraphTrainer - INFO - map@5: 0.011214
2025-12-26 20:43:53 - GraphTrainer - INFO - mrr@5: 0.012122
2025-12-26 20:43:53 - GraphTrainer - INFO - precision@10: 0.003908
2025-12-26 20:43:53 - GraphTrainer - INFO - recall@10: 0.036761
2025-12-26 20:43:53 - GraphTrainer - INFO - hit_rate@10: 0.038982
2025-12-26 20:43:53 - GraphTrainer - INFO - ndcg@10: 0.018898
2025-12-26 20:43:53 - GraphTrainer - INFO - map@10: 0.013221
2025-12-26 20:43:53 - GraphTrainer - INFO - mrr@10: 0.014217
2025-12-26 20:43:53 - GraphTrainer - INFO - precision@20: 0.003204
2025-12-26 20:43:53 - GraphTrainer - INFO - recall@20: 0.060084
2025-12-26 20:43:53 - GraphTrainer - INFO - hit_rate@20: 0.063718
2025-12-26 20:43:53 - GraphTrainer - INFO - ndcg@20: 0.024837
2025-12-26 20:43:53 - GraphTrainer - INFO - map@20: 0.014809
2025-12-26 20:43:53 - GraphTrainer - INFO - mrr@20: 0.015894
2025-12-26 20:43:53 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:43:53 - GraphTrainer - INFO - ============================================================
2025-12-26 20:43:53 - GraphTrainer - INFO - 开始第 36/1000 轮训练
2025-12-26 20:43:53 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(1.2671, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(1.2271, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(1.2321, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(1.2747, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(1.2261, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(1.2428, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(1.2516, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(1.3516, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(1.2493, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(1.2351, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(1.1972, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(1.2708, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(1.2741, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(1.2386, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(1.2603, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(1.3046, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(1.3056, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(1.2811, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(1.2033, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(1.2941, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(1.2976, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(1.3511, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(1.2363, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(1.2756, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(1.2951, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(1.2985, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(1.2592, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(1.2657, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(1.2114, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(1.2859, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(1.2530, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(1.2431, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(1.3072, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(1.2689, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(1.2191, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(1.2524, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(1.2676, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(1.2919, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(1.3021, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(1.3095, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(1.2397, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(1.2615, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(1.2339, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(1.2881, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(1.2608, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(1.2413, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(1.2848, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(1.2105, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(1.2660, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(1.2741, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(1.2475, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(1.2649, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(1.2903, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(1.2485, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(1.2513, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(1.2429, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(1.2964, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(1.2185, device='cuda:0', grad_fn=<AddBackward0>)
The 35 training average loss: 1.263780941223276
2025-12-26 20:44:02 - GraphTrainer - INFO - 验证结果:
2025-12-26 20:44:02 - GraphTrainer - INFO -   precision@5: 0.004248
2025-12-26 20:44:02 - GraphTrainer - INFO -   recall@5: 0.019637
2025-12-26 20:44:02 - GraphTrainer - INFO -   hit_rate@5: 0.021188
2025-12-26 20:44:02 - GraphTrainer - INFO -   ndcg@5: 0.013035
2025-12-26 20:44:02 - GraphTrainer - INFO -   map@5: 0.010603
2025-12-26 20:44:02 - GraphTrainer - INFO -   mrr@5: 0.011386
2025-12-26 20:44:02 - GraphTrainer - INFO -   precision@10: 0.003605
2025-12-26 20:44:02 - GraphTrainer - INFO -   recall@10: 0.033894
2025-12-26 20:44:02 - GraphTrainer - INFO -   hit_rate@10: 0.035896
2025-12-26 20:44:02 - GraphTrainer - INFO -   ndcg@10: 0.017637
2025-12-26 20:44:02 - GraphTrainer - INFO -   map@10: 0.012474
2025-12-26 20:44:02 - GraphTrainer - INFO -   mrr@10: 0.013311
2025-12-26 20:44:02 - GraphTrainer - INFO -   precision@20: 0.003060
2025-12-26 20:44:02 - GraphTrainer - INFO -   recall@20: 0.057608
2025-12-26 20:44:02 - GraphTrainer - INFO -   hit_rate@20: 0.060838
2025-12-26 20:44:02 - GraphTrainer - INFO -   ndcg@20: 0.023671
2025-12-26 20:44:02 - GraphTrainer - INFO -   map@20: 0.014096
2025-12-26 20:44:02 - GraphTrainer - INFO -   mrr@20: 0.015010
2025-12-26 20:44:02 - GraphTrainer - INFO - 第 36 轮训练完成
2025-12-26 20:44:02 - GraphTrainer - INFO - train_loss: 1.259356
2025-12-26 20:44:02 - GraphTrainer - INFO - precision@5: 0.004248
2025-12-26 20:44:02 - GraphTrainer - INFO - recall@5: 0.019637
2025-12-26 20:44:02 - GraphTrainer - INFO - hit_rate@5: 0.021188
2025-12-26 20:44:02 - GraphTrainer - INFO - ndcg@5: 0.013035
2025-12-26 20:44:02 - GraphTrainer - INFO - map@5: 0.010603
2025-12-26 20:44:02 - GraphTrainer - INFO - mrr@5: 0.011386
2025-12-26 20:44:02 - GraphTrainer - INFO - precision@10: 0.003605
2025-12-26 20:44:02 - GraphTrainer - INFO - recall@10: 0.033894
2025-12-26 20:44:02 - GraphTrainer - INFO - hit_rate@10: 0.035896
2025-12-26 20:44:02 - GraphTrainer - INFO - ndcg@10: 0.017637
2025-12-26 20:44:02 - GraphTrainer - INFO - map@10: 0.012474
2025-12-26 20:44:02 - GraphTrainer - INFO - mrr@10: 0.013311
2025-12-26 20:44:02 - GraphTrainer - INFO - precision@20: 0.003060
2025-12-26 20:44:02 - GraphTrainer - INFO - recall@20: 0.057608
2025-12-26 20:44:02 - GraphTrainer - INFO - hit_rate@20: 0.060838
2025-12-26 20:44:02 - GraphTrainer - INFO - ndcg@20: 0.023671
2025-12-26 20:44:02 - GraphTrainer - INFO - map@20: 0.014096
2025-12-26 20:44:02 - GraphTrainer - INFO - mrr@20: 0.015010
2025-12-26 20:44:02 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-26 20:44:02 - GraphTrainer - WARNING - 早停触发 - 第 36 轮，最佳指标: 0.065742
2025-12-26 20:44:02 - GraphTrainer - INFO - ============================================================
2025-12-26 20:44:02 - GraphTrainer - INFO - 训练完成!
2025-12-26 20:44:02 - GraphTrainer - INFO - 总训练时间: 0.11 hours
2025-12-26 20:44:02 - GraphTrainer - INFO - 最佳指标:
2025-12-26 20:44:02 - GraphTrainer - INFO -   best_precision@5: 0.004248
2025-12-26 20:44:02 - GraphTrainer - INFO -   best_recall@5: 0.019637
2025-12-26 20:44:02 - GraphTrainer - INFO -   best_hit_rate@5: 0.021188
2025-12-26 20:44:02 - GraphTrainer - INFO -   best_ndcg@5: 0.013035
2025-12-26 20:44:02 - GraphTrainer - INFO -   best_map@5: 0.010603
2025-12-26 20:44:02 - GraphTrainer - INFO -   best_mrr@5: 0.011386
2025-12-26 20:44:02 - GraphTrainer - INFO -   best_precision@10: 0.003605
2025-12-26 20:44:02 - GraphTrainer - INFO -   best_recall@10: 0.033894
2025-12-26 20:44:02 - GraphTrainer - INFO -   best_hit_rate@10: 0.035896
2025-12-26 20:44:02 - GraphTrainer - INFO -   best_ndcg@10: 0.017637
2025-12-26 20:44:02 - GraphTrainer - INFO -   best_map@10: 0.012474
2025-12-26 20:44:02 - GraphTrainer - INFO -   best_mrr@10: 0.013311
2025-12-26 20:44:02 - GraphTrainer - INFO -   best_precision@20: 0.003060
2025-12-26 20:44:02 - GraphTrainer - INFO -   best_recall@20: 0.057608
2025-12-26 20:44:02 - GraphTrainer - INFO -   best_hit_rate@20: 0.060838
2025-12-26 20:44:02 - GraphTrainer - INFO -   best_ndcg@20: 0.023671
2025-12-26 20:44:02 - GraphTrainer - INFO -   best_map@20: 0.014096
2025-12-26 20:44:02 - GraphTrainer - INFO -   best_mrr@20: 0.015010
2025-12-26 20:44:02 - GraphTrainer - INFO - ============================================================
2025-12-26 20:44:02 - GraphTrainer - INFO - Loaded best model from epoch 16
0 train_loss tensor(1.2527, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(1.2456, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(1.2500, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(1.2649, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(1.2783, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(1.2676, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(1.2511, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(1.2800, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(1.2630, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(1.2856, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(1.2954, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(1.2123, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(1.2687, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(1.2868, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(1.2530, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(1.2773, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(1.2527, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(1.2631, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(1.3000, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(1.2407, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(1.2466, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(1.2905, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(1.2560, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(1.3005, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(1.2533, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(1.2260, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(1.2539, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(1.2298, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(1.2467, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(1.2578, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(1.2817, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(1.2430, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(1.1779, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(1.2470, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(1.2540, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(1.2167, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(1.2932, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(1.2255, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(1.2570, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(1.2908, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(1.2684, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(1.2008, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(1.2551, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(1.2624, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(1.2374, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(1.2791, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(1.2841, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(1.2681, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(1.2705, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(1.2590, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(1.2693, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(1.3347, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(1.2713, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(1.2974, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(1.2463, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(1.1990, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(1.2349, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(1.2680, device='cuda:0', grad_fn=<AddBackward0>)
The 36 training average loss: 1.2593560301024338

============================================================
FINAL RESULTS
============================================================
Training Results:
  Best epoch: 16
  Best validation metric: 0.0657
  Training time: 0.11 hours

Test Metrics:
  precision@5: 0.0047
  recall@5: 0.0202
  hit_rate@5: 0.0232
  ndcg@5: 0.0132
  map@5: 0.0103
  mrr@5: 0.0118
  precision@10: 0.0039
  recall@10: 0.0348
  hit_rate@10: 0.0392
  ndcg@10: 0.0179
  map@10: 0.0122
  mrr@10: 0.0139
  precision@20: 0.0033
  recall@20: 0.0576
  hit_rate@20: 0.0650
  ndcg@20: 0.0238
  map@20: 0.0138
  mrr@20: 0.0156
Saving results...
Results saved to ./results/results_20251226_2044.json

Training completed successfully!

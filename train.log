nohup: ignoring input
[I 2025-11-22 21:06:49,293] A new study created in memory with name: no-name-7694a460-49f8-4d16-aed5-63f17e3df731
2025-11-22 21:07:08 - GraphTrainer - INFO - Starting training...
2025-11-22 21:07:08 - GraphTrainer - INFO - 模型: SGrec
2025-11-22 21:07:08 - GraphTrainer - INFO - 总参数量: 4,056,128
2025-11-22 21:07:08 - GraphTrainer - INFO - 可训练参数量: 4,056,128
2025-11-22 21:07:08 - GraphTrainer - INFO - ============================================================
2025-11-22 21:07:08 - GraphTrainer - INFO - 开始第 1/1000 轮训练
2025-11-22 21:07:08 - GraphTrainer - INFO - ============================================================

############################################################
Optuna Trial 0
############################################################
Trial config (partial):
  lr=0.001, wd=0, layer_num=3, graph_v_k=9, graph_t_k=3, gcn_v_k=7, gcn_t_k=3, k=4, alpha=0.3344256028151724, beta=0.6655743971848276, hidden_unit=512
Using GPU: NVIDIA GeForce RTX 3080
============================================================
Graph-based Recommendation System
============================================================
Dataset: baby
Device: cuda
Model: SGrec
Embedding dim: 64
Epochs: 1000
============================================================
Loading data...
Initializing full dataset from ../autodl-tmp/data/ori_data/baby
Loading interaction data from ../autodl-tmp/data/ori_data/baby
Loading features from ../autodl-tmp/data/ori_data/baby
Building user-item interaction index...
Dataset Statistics:
  num_users: 19445
  num_items: 7050
  num_interactions: 160792
  sparsity: 0.9988270827520429
  user_features: []
  item_features_dimensions: {'image_feat': 4096, 'text_feat': 384}
  user_feature_dimensions: {}
  train_ratio: 0.737294143987263
  val_ratio: 0.12786083884770386
  test_ratio: 0.13484501716503308
Full dataset initialized: 160792 interactions, 19445 users, 7050 items
Splitting dataset into train/val/test...
Initializing subset dataset (mode: train) with 118551 interactions
Initializing subset dataset (mode: val) with 20559 interactions
Initializing subset dataset (mode: test) with 21682 interactions
Split results - Train: 118551 interactions, Val: 20559, Test: 21682
Data loaders created - Train batches: 58, Val batches: 11, Test batches: 11
Data loaded: 19445 users, 7050 items
User features: []
Item features: ['image_feat', 'text_feat']
Building graph and model...
Extracting training interactions for graph construction...
Extracted 118551 positive interactions for graph construction
Graph built from training data only: 26495 nodes, 263597 edges
⚠️  Important: Graph constructed using only training data to prevent data leakage
SGrec(
  (user_emb): Embedding(19445, 64)
  (item_emb): Embedding(7050, 64)
  (graph): Graph(
    (input_feat_dropout): Dropout(p=0.1, inplace=False)
    (v_ffn): Sequential(
      (0): Linear(in_features=4096, out_features=512, bias=True)
      (1): Linear(in_features=512, out_features=64, bias=True)
    )
    (t_ffn): Sequential(
      (0): Linear(in_features=384, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=64, bias=True)
    )
    (v_gcn): II_GCN(
      (x_dropout): Dropout(p=0.3, inplace=False)
      (edge_dropout): Dropout(p=0.2, inplace=False)
      (z_dropout): Dropout(p=0.3, inplace=False)
    )
    (t_gcn): II_GCN(
      (x_dropout): Dropout(p=0.3, inplace=False)
      (edge_dropout): Dropout(p=0.2, inplace=False)
      (z_dropout): Dropout(p=0.3, inplace=False)
    )
    (iu_gcn): IU_GCN(
      (x_dropout): Dropout(p=0.3, inplace=False)
      (edge_dropout): Dropout(p=0.2, inplace=False)
      (z_dropout): Dropout(p=0.3, inplace=False)
    )
    (activate): ReLU()
  )
)
Model parameters: 4,056,128
init trainer,verifier,tester
2025-11-22 21:07:19 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:07:19 - GraphTrainer - INFO -   precision@5: 0.001574
2025-11-22 21:07:19 - GraphTrainer - INFO -   recall@5: 0.007289
2025-11-22 21:07:19 - GraphTrainer - INFO -   hit_rate@5: 0.007868
2025-11-22 21:07:19 - GraphTrainer - INFO -   ndcg@5: 0.004564
2025-11-22 21:07:19 - GraphTrainer - INFO -   map@5: 0.003567
2025-11-22 21:07:19 - GraphTrainer - INFO -   mrr@5: 0.003846
2025-11-22 21:07:19 - GraphTrainer - INFO -   precision@10: 0.001389
2025-11-22 21:07:19 - GraphTrainer - INFO -   recall@10: 0.013038
2025-11-22 21:07:19 - GraphTrainer - INFO -   hit_rate@10: 0.013885
2025-11-22 21:07:19 - GraphTrainer - INFO -   ndcg@10: 0.006420
2025-11-22 21:07:19 - GraphTrainer - INFO -   map@10: 0.004317
2025-11-22 21:07:19 - GraphTrainer - INFO -   mrr@10: 0.004634
2025-11-22 21:07:19 - GraphTrainer - INFO -   precision@20: 0.001124
2025-11-22 21:07:19 - GraphTrainer - INFO -   recall@20: 0.021171
2025-11-22 21:07:19 - GraphTrainer - INFO -   hit_rate@20: 0.022371
2025-11-22 21:07:19 - GraphTrainer - INFO -   ndcg@20: 0.008461
2025-11-22 21:07:19 - GraphTrainer - INFO -   map@20: 0.004853
2025-11-22 21:07:19 - GraphTrainer - INFO -   mrr@20: 0.005191
2025-11-22 21:07:19 - GraphTrainer - INFO - 第 1 轮训练完成
2025-11-22 21:07:19 - GraphTrainer - INFO - train_loss: 0.695402
2025-11-22 21:07:19 - GraphTrainer - INFO - precision@5: 0.001574
2025-11-22 21:07:19 - GraphTrainer - INFO - recall@5: 0.007289
2025-11-22 21:07:19 - GraphTrainer - INFO - hit_rate@5: 0.007868
2025-11-22 21:07:19 - GraphTrainer - INFO - ndcg@5: 0.004564
2025-11-22 21:07:19 - GraphTrainer - INFO - map@5: 0.003567
2025-11-22 21:07:19 - GraphTrainer - INFO - mrr@5: 0.003846
2025-11-22 21:07:19 - GraphTrainer - INFO - precision@10: 0.001389
2025-11-22 21:07:19 - GraphTrainer - INFO - recall@10: 0.013038
2025-11-22 21:07:19 - GraphTrainer - INFO - hit_rate@10: 0.013885
2025-11-22 21:07:19 - GraphTrainer - INFO - ndcg@10: 0.006420
2025-11-22 21:07:19 - GraphTrainer - INFO - map@10: 0.004317
2025-11-22 21:07:19 - GraphTrainer - INFO - mrr@10: 0.004634
2025-11-22 21:07:19 - GraphTrainer - INFO - precision@20: 0.001124
2025-11-22 21:07:19 - GraphTrainer - INFO - recall@20: 0.021171
2025-11-22 21:07:19 - GraphTrainer - INFO - hit_rate@20: 0.022371
2025-11-22 21:07:19 - GraphTrainer - INFO - ndcg@20: 0.008461
2025-11-22 21:07:19 - GraphTrainer - INFO - map@20: 0.004853
2025-11-22 21:07:19 - GraphTrainer - INFO - mrr@20: 0.005191
2025-11-22 21:07:19 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:07:19 - GraphTrainer - INFO - ============================================================
2025-11-22 21:07:19 - GraphTrainer - INFO - 开始第 2/1000 轮训练
2025-11-22 21:07:19 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.6969, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.6959, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.7073, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.7131, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.7112, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.7231, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.7210, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.7117, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.7147, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.7075, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.7102, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.7135, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.7057, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.7068, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.7159, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.7155, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.7132, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.7136, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.7027, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.7028, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.7179, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.7033, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.7028, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.6982, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.6931, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.6958, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.6989, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.6833, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.6963, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.6948, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.6937, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.7016, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.6954, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.6896, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.6889, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.6900, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.6890, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.6897, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.6959, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.6826, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.6904, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.6846, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.6936, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.6821, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.6887, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.6828, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.6865, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.6870, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.6661, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.6729, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.6721, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.6792, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.6805, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.6680, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.6601, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.6780, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.6728, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.6846, device='cuda:0', grad_fn=<AddBackward0>)
The 1 training average loss: 0.6954021690220669
2025-11-22 21:07:30 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:07:30 - GraphTrainer - INFO -   precision@5: 0.003147
2025-11-22 21:07:30 - GraphTrainer - INFO -   recall@5: 0.015032
2025-11-22 21:07:30 - GraphTrainer - INFO -   hit_rate@5: 0.015737
2025-11-22 21:07:30 - GraphTrainer - INFO -   ndcg@5: 0.010665
2025-11-22 21:07:30 - GraphTrainer - INFO -   map@5: 0.009095
2025-11-22 21:07:30 - GraphTrainer - INFO -   mrr@5: 0.009489
2025-11-22 21:07:30 - GraphTrainer - INFO -   precision@10: 0.002397
2025-11-22 21:07:30 - GraphTrainer - INFO -   recall@10: 0.022481
2025-11-22 21:07:30 - GraphTrainer - INFO -   hit_rate@10: 0.023862
2025-11-22 21:07:30 - GraphTrainer - INFO -   ndcg@10: 0.013080
2025-11-22 21:07:30 - GraphTrainer - INFO -   map@10: 0.010054
2025-11-22 21:07:30 - GraphTrainer - INFO -   mrr@10: 0.010530
2025-11-22 21:07:30 - GraphTrainer - INFO -   precision@20: 0.001939
2025-11-22 21:07:30 - GraphTrainer - INFO -   recall@20: 0.036438
2025-11-22 21:07:30 - GraphTrainer - INFO -   hit_rate@20: 0.038467
2025-11-22 21:07:30 - GraphTrainer - INFO -   ndcg@20: 0.016615
2025-11-22 21:07:30 - GraphTrainer - INFO -   map@20: 0.010996
2025-11-22 21:07:30 - GraphTrainer - INFO -   mrr@20: 0.011512
2025-11-22 21:07:30 - GraphTrainer - INFO - 第 2 轮训练完成
2025-11-22 21:07:30 - GraphTrainer - INFO - train_loss: 0.636026
2025-11-22 21:07:30 - GraphTrainer - INFO - precision@5: 0.003147
2025-11-22 21:07:30 - GraphTrainer - INFO - recall@5: 0.015032
2025-11-22 21:07:30 - GraphTrainer - INFO - hit_rate@5: 0.015737
2025-11-22 21:07:30 - GraphTrainer - INFO - ndcg@5: 0.010665
2025-11-22 21:07:30 - GraphTrainer - INFO - map@5: 0.009095
2025-11-22 21:07:30 - GraphTrainer - INFO - mrr@5: 0.009489
2025-11-22 21:07:30 - GraphTrainer - INFO - precision@10: 0.002397
2025-11-22 21:07:30 - GraphTrainer - INFO - recall@10: 0.022481
2025-11-22 21:07:30 - GraphTrainer - INFO - hit_rate@10: 0.023862
2025-11-22 21:07:30 - GraphTrainer - INFO - ndcg@10: 0.013080
2025-11-22 21:07:30 - GraphTrainer - INFO - map@10: 0.010054
2025-11-22 21:07:30 - GraphTrainer - INFO - mrr@10: 0.010530
2025-11-22 21:07:30 - GraphTrainer - INFO - precision@20: 0.001939
2025-11-22 21:07:30 - GraphTrainer - INFO - recall@20: 0.036438
2025-11-22 21:07:30 - GraphTrainer - INFO - hit_rate@20: 0.038467
2025-11-22 21:07:30 - GraphTrainer - INFO - ndcg@20: 0.016615
2025-11-22 21:07:30 - GraphTrainer - INFO - map@20: 0.010996
2025-11-22 21:07:30 - GraphTrainer - INFO - mrr@20: 0.011512
2025-11-22 21:07:30 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:07:30 - GraphTrainer - INFO - ============================================================
2025-11-22 21:07:30 - GraphTrainer - INFO - 开始第 3/1000 轮训练
2025-11-22 21:07:30 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.6739, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.6609, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.6578, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.6544, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.6509, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.6665, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.6658, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.6452, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.6708, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.6571, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.6715, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.6468, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.6497, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.6425, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.6517, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.6481, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.6457, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.6361, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.6529, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.6358, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.6477, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.6422, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.6307, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.6390, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.6142, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.6364, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.6405, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.6453, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.6401, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.6518, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.6362, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.6382, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.6399, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.6240, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.6292, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.6199, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.6091, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.6479, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.6236, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.6377, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.6450, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.6279, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.6169, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.6285, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.6335, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.6272, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.6182, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.6058, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.6159, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.6048, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.6171, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.6160, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.6108, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.6082, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.6033, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.6096, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.6043, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.6191, device='cuda:0', grad_fn=<AddBackward0>)
The 2 training average loss: 0.6360260207077553
2025-11-22 21:07:41 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:07:41 - GraphTrainer - INFO -   precision@5: 0.003394
2025-11-22 21:07:41 - GraphTrainer - INFO -   recall@5: 0.015931
2025-11-22 21:07:41 - GraphTrainer - INFO -   hit_rate@5: 0.016920
2025-11-22 21:07:41 - GraphTrainer - INFO -   ndcg@5: 0.009775
2025-11-22 21:07:41 - GraphTrainer - INFO -   map@5: 0.007568
2025-11-22 21:07:41 - GraphTrainer - INFO -   mrr@5: 0.008118
2025-11-22 21:07:41 - GraphTrainer - INFO -   precision@10: 0.002808
2025-11-22 21:07:41 - GraphTrainer - INFO -   recall@10: 0.026482
2025-11-22 21:07:41 - GraphTrainer - INFO -   hit_rate@10: 0.028028
2025-11-22 21:07:41 - GraphTrainer - INFO -   ndcg@10: 0.013224
2025-11-22 21:07:41 - GraphTrainer - INFO -   map@10: 0.008985
2025-11-22 21:07:41 - GraphTrainer - INFO -   mrr@10: 0.009606
2025-11-22 21:07:41 - GraphTrainer - INFO -   precision@20: 0.002296
2025-11-22 21:07:41 - GraphTrainer - INFO -   recall@20: 0.043392
2025-11-22 21:07:41 - GraphTrainer - INFO -   hit_rate@20: 0.045719
2025-11-22 21:07:41 - GraphTrainer - INFO -   ndcg@20: 0.017543
2025-11-22 21:07:41 - GraphTrainer - INFO -   map@20: 0.010158
2025-11-22 21:07:41 - GraphTrainer - INFO -   mrr@20: 0.010827
2025-11-22 21:07:41 - GraphTrainer - INFO - 第 3 轮训练完成
2025-11-22 21:07:41 - GraphTrainer - INFO - train_loss: 0.585731
2025-11-22 21:07:41 - GraphTrainer - INFO - precision@5: 0.003394
2025-11-22 21:07:41 - GraphTrainer - INFO - recall@5: 0.015931
2025-11-22 21:07:41 - GraphTrainer - INFO - hit_rate@5: 0.016920
2025-11-22 21:07:41 - GraphTrainer - INFO - ndcg@5: 0.009775
2025-11-22 21:07:41 - GraphTrainer - INFO - map@5: 0.007568
2025-11-22 21:07:41 - GraphTrainer - INFO - mrr@5: 0.008118
2025-11-22 21:07:41 - GraphTrainer - INFO - precision@10: 0.002808
2025-11-22 21:07:41 - GraphTrainer - INFO - recall@10: 0.026482
2025-11-22 21:07:41 - GraphTrainer - INFO - hit_rate@10: 0.028028
2025-11-22 21:07:41 - GraphTrainer - INFO - ndcg@10: 0.013224
2025-11-22 21:07:41 - GraphTrainer - INFO - map@10: 0.008985
2025-11-22 21:07:41 - GraphTrainer - INFO - mrr@10: 0.009606
2025-11-22 21:07:41 - GraphTrainer - INFO - precision@20: 0.002296
2025-11-22 21:07:41 - GraphTrainer - INFO - recall@20: 0.043392
2025-11-22 21:07:41 - GraphTrainer - INFO - hit_rate@20: 0.045719
2025-11-22 21:07:41 - GraphTrainer - INFO - ndcg@20: 0.017543
2025-11-22 21:07:41 - GraphTrainer - INFO - map@20: 0.010158
2025-11-22 21:07:41 - GraphTrainer - INFO - mrr@20: 0.010827
2025-11-22 21:07:41 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:07:41 - GraphTrainer - INFO - ============================================================
2025-11-22 21:07:41 - GraphTrainer - INFO - 开始第 4/1000 轮训练
2025-11-22 21:07:41 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.6197, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.6137, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.6000, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.6295, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.5998, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.5800, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.6168, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.6030, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.6153, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.6074, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.5911, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.6190, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.5988, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.6028, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.5841, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.6029, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.5947, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.6021, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.5941, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.6165, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.5898, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.5823, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.5873, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.5872, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.5903, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.5737, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.5714, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.5761, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.5731, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.5784, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.5744, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.5587, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.5675, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.5843, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.5760, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.5640, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.5853, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.5847, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.5746, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.5746, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.5659, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.5917, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.5833, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.5792, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.5725, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.5871, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.5553, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.5700, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.5738, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.5540, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.5705, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.5702, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.5696, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.5763, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.5766, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.5777, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.5793, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.5744, device='cuda:0', grad_fn=<AddBackward0>)
The 3 training average loss: 0.5857314107746914
2025-11-22 21:07:52 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:07:52 - GraphTrainer - INFO -   precision@5: 0.003178
2025-11-22 21:07:52 - GraphTrainer - INFO -   recall@5: 0.014770
2025-11-22 21:07:52 - GraphTrainer - INFO -   hit_rate@5: 0.015788
2025-11-22 21:07:52 - GraphTrainer - INFO -   ndcg@5: 0.009219
2025-11-22 21:07:52 - GraphTrainer - INFO -   map@5: 0.007252
2025-11-22 21:07:52 - GraphTrainer - INFO -   mrr@5: 0.007688
2025-11-22 21:07:52 - GraphTrainer - INFO -   precision@10: 0.002849
2025-11-22 21:07:52 - GraphTrainer - INFO -   recall@10: 0.026904
2025-11-22 21:07:52 - GraphTrainer - INFO -   hit_rate@10: 0.028388
2025-11-22 21:07:52 - GraphTrainer - INFO -   ndcg@10: 0.013154
2025-11-22 21:07:52 - GraphTrainer - INFO -   map@10: 0.008861
2025-11-22 21:07:52 - GraphTrainer - INFO -   mrr@10: 0.009354
2025-11-22 21:07:52 - GraphTrainer - INFO -   precision@20: 0.002379
2025-11-22 21:07:52 - GraphTrainer - INFO -   recall@20: 0.044935
2025-11-22 21:07:52 - GraphTrainer - INFO -   hit_rate@20: 0.047313
2025-11-22 21:07:52 - GraphTrainer - INFO -   ndcg@20: 0.017730
2025-11-22 21:07:52 - GraphTrainer - INFO -   map@20: 0.010087
2025-11-22 21:07:52 - GraphTrainer - INFO -   mrr@20: 0.010638
2025-11-22 21:07:52 - GraphTrainer - INFO - 第 4 轮训练完成
2025-11-22 21:07:52 - GraphTrainer - INFO - train_loss: 0.551053
2025-11-22 21:07:52 - GraphTrainer - INFO - precision@5: 0.003178
2025-11-22 21:07:52 - GraphTrainer - INFO - recall@5: 0.014770
2025-11-22 21:07:52 - GraphTrainer - INFO - hit_rate@5: 0.015788
2025-11-22 21:07:52 - GraphTrainer - INFO - ndcg@5: 0.009219
2025-11-22 21:07:52 - GraphTrainer - INFO - map@5: 0.007252
2025-11-22 21:07:52 - GraphTrainer - INFO - mrr@5: 0.007688
2025-11-22 21:07:52 - GraphTrainer - INFO - precision@10: 0.002849
2025-11-22 21:07:52 - GraphTrainer - INFO - recall@10: 0.026904
2025-11-22 21:07:52 - GraphTrainer - INFO - hit_rate@10: 0.028388
2025-11-22 21:07:52 - GraphTrainer - INFO - ndcg@10: 0.013154
2025-11-22 21:07:52 - GraphTrainer - INFO - map@10: 0.008861
2025-11-22 21:07:52 - GraphTrainer - INFO - mrr@10: 0.009354
2025-11-22 21:07:52 - GraphTrainer - INFO - precision@20: 0.002379
2025-11-22 21:07:52 - GraphTrainer - INFO - recall@20: 0.044935
2025-11-22 21:07:52 - GraphTrainer - INFO - hit_rate@20: 0.047313
2025-11-22 21:07:52 - GraphTrainer - INFO - ndcg@20: 0.017730
2025-11-22 21:07:52 - GraphTrainer - INFO - map@20: 0.010087
2025-11-22 21:07:52 - GraphTrainer - INFO - mrr@20: 0.010638
2025-11-22 21:07:52 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:07:52 - GraphTrainer - INFO - ============================================================
2025-11-22 21:07:52 - GraphTrainer - INFO - 开始第 5/1000 轮训练
2025-11-22 21:07:52 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.5689, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.5665, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.5395, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.5338, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.5605, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.5508, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.5388, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.5441, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.5348, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.5819, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.5632, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.5772, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.5513, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.5585, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.5638, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.5595, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.5636, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.5548, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.5577, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.5509, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.5429, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.5420, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.5602, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.5433, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.5449, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.5575, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.5616, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.5509, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.5499, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.5678, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.5622, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.5372, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.5552, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.5621, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.5422, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.5409, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.5778, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.5517, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.5326, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.5453, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.5539, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.5532, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.5547, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.5347, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.5530, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.5608, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.5615, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.5494, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.5502, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.5432, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.5418, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.5453, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.5347, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.5172, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.5566, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.5424, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.5310, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.5286, device='cuda:0', grad_fn=<AddBackward0>)
The 4 training average loss: 0.5510532239387775
2025-11-22 21:08:03 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:08:03 - GraphTrainer - INFO -   precision@5: 0.003826
2025-11-22 21:08:03 - GraphTrainer - INFO -   recall@5: 0.018395
2025-11-22 21:08:03 - GraphTrainer - INFO -   hit_rate@5: 0.019079
2025-11-22 21:08:03 - GraphTrainer - INFO -   ndcg@5: 0.011402
2025-11-22 21:08:03 - GraphTrainer - INFO -   map@5: 0.008995
2025-11-22 21:08:03 - GraphTrainer - INFO -   mrr@5: 0.009319
2025-11-22 21:08:03 - GraphTrainer - INFO -   precision@10: 0.003394
2025-11-22 21:08:03 - GraphTrainer - INFO -   recall@10: 0.032432
2025-11-22 21:08:03 - GraphTrainer - INFO -   hit_rate@10: 0.033839
2025-11-22 21:08:03 - GraphTrainer - INFO -   ndcg@10: 0.015921
2025-11-22 21:08:03 - GraphTrainer - INFO -   map@10: 0.010808
2025-11-22 21:08:03 - GraphTrainer - INFO -   mrr@10: 0.011219
2025-11-22 21:08:03 - GraphTrainer - INFO -   precision@20: 0.002790
2025-11-22 21:08:03 - GraphTrainer - INFO -   recall@20: 0.053019
2025-11-22 21:08:03 - GraphTrainer - INFO -   hit_rate@20: 0.055593
2025-11-22 21:08:03 - GraphTrainer - INFO -   ndcg@20: 0.021175
2025-11-22 21:08:03 - GraphTrainer - INFO -   map@20: 0.012225
2025-11-22 21:08:03 - GraphTrainer - INFO -   mrr@20: 0.012715
2025-11-22 21:08:03 - GraphTrainer - INFO - 第 5 轮训练完成
2025-11-22 21:08:03 - GraphTrainer - INFO - train_loss: 0.524057
2025-11-22 21:08:03 - GraphTrainer - INFO - precision@5: 0.003826
2025-11-22 21:08:03 - GraphTrainer - INFO - recall@5: 0.018395
2025-11-22 21:08:03 - GraphTrainer - INFO - hit_rate@5: 0.019079
2025-11-22 21:08:03 - GraphTrainer - INFO - ndcg@5: 0.011402
2025-11-22 21:08:03 - GraphTrainer - INFO - map@5: 0.008995
2025-11-22 21:08:03 - GraphTrainer - INFO - mrr@5: 0.009319
2025-11-22 21:08:03 - GraphTrainer - INFO - precision@10: 0.003394
2025-11-22 21:08:03 - GraphTrainer - INFO - recall@10: 0.032432
2025-11-22 21:08:03 - GraphTrainer - INFO - hit_rate@10: 0.033839
2025-11-22 21:08:03 - GraphTrainer - INFO - ndcg@10: 0.015921
2025-11-22 21:08:03 - GraphTrainer - INFO - map@10: 0.010808
2025-11-22 21:08:03 - GraphTrainer - INFO - mrr@10: 0.011219
2025-11-22 21:08:03 - GraphTrainer - INFO - precision@20: 0.002790
2025-11-22 21:08:03 - GraphTrainer - INFO - recall@20: 0.053019
2025-11-22 21:08:03 - GraphTrainer - INFO - hit_rate@20: 0.055593
2025-11-22 21:08:03 - GraphTrainer - INFO - ndcg@20: 0.021175
2025-11-22 21:08:03 - GraphTrainer - INFO - map@20: 0.012225
2025-11-22 21:08:03 - GraphTrainer - INFO - mrr@20: 0.012715
2025-11-22 21:08:03 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:08:03 - GraphTrainer - INFO - ============================================================
2025-11-22 21:08:03 - GraphTrainer - INFO - 开始第 6/1000 轮训练
2025-11-22 21:08:03 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.5456, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.5425, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.5379, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.5314, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.5277, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.5283, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.5427, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.5331, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.5249, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.5247, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.5395, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.5347, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.5381, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.5170, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.5465, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.5405, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.5514, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.5234, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.5044, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.5226, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4999, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.5218, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.5082, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.5108, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.5286, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.5244, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.5437, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.5324, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.5243, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.5106, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.5332, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.5112, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.5230, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.5211, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.5276, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.5147, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4932, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.5279, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.5172, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.5145, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.5217, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.5084, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.5128, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.5291, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.5191, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.5499, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.5307, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.5246, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.5140, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.5272, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.5157, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.5180, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.5357, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.5043, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.5297, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.5069, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4901, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.5122, device='cuda:0', grad_fn=<AddBackward0>)
The 5 training average loss: 0.5240570543141201
2025-11-22 21:08:14 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:08:14 - GraphTrainer - INFO -   precision@5: 0.003960
2025-11-22 21:08:14 - GraphTrainer - INFO -   recall@5: 0.018976
2025-11-22 21:08:14 - GraphTrainer - INFO -   hit_rate@5: 0.019697
2025-11-22 21:08:14 - GraphTrainer - INFO -   ndcg@5: 0.011673
2025-11-22 21:08:14 - GraphTrainer - INFO -   map@5: 0.009168
2025-11-22 21:08:14 - GraphTrainer - INFO -   mrr@5: 0.009511
2025-11-22 21:08:14 - GraphTrainer - INFO -   precision@10: 0.003353
2025-11-22 21:08:14 - GraphTrainer - INFO -   recall@10: 0.032008
2025-11-22 21:08:14 - GraphTrainer - INFO -   hit_rate@10: 0.033325
2025-11-22 21:08:14 - GraphTrainer - INFO -   ndcg@10: 0.015854
2025-11-22 21:08:14 - GraphTrainer - INFO -   map@10: 0.010839
2025-11-22 21:08:14 - GraphTrainer - INFO -   mrr@10: 0.011254
2025-11-22 21:08:14 - GraphTrainer - INFO -   precision@20: 0.002710
2025-11-22 21:08:14 - GraphTrainer - INFO -   recall@20: 0.051489
2025-11-22 21:08:14 - GraphTrainer - INFO -   hit_rate@20: 0.053896
2025-11-22 21:08:14 - GraphTrainer - INFO -   ndcg@20: 0.020826
2025-11-22 21:08:14 - GraphTrainer - INFO -   map@20: 0.012181
2025-11-22 21:08:14 - GraphTrainer - INFO -   mrr@20: 0.012672
2025-11-22 21:08:14 - GraphTrainer - INFO - 第 6 轮训练完成
2025-11-22 21:08:14 - GraphTrainer - INFO - train_loss: 0.504446
2025-11-22 21:08:14 - GraphTrainer - INFO - precision@5: 0.003960
2025-11-22 21:08:14 - GraphTrainer - INFO - recall@5: 0.018976
2025-11-22 21:08:14 - GraphTrainer - INFO - hit_rate@5: 0.019697
2025-11-22 21:08:14 - GraphTrainer - INFO - ndcg@5: 0.011673
2025-11-22 21:08:14 - GraphTrainer - INFO - map@5: 0.009168
2025-11-22 21:08:14 - GraphTrainer - INFO - mrr@5: 0.009511
2025-11-22 21:08:14 - GraphTrainer - INFO - precision@10: 0.003353
2025-11-22 21:08:14 - GraphTrainer - INFO - recall@10: 0.032008
2025-11-22 21:08:14 - GraphTrainer - INFO - hit_rate@10: 0.033325
2025-11-22 21:08:14 - GraphTrainer - INFO - ndcg@10: 0.015854
2025-11-22 21:08:14 - GraphTrainer - INFO - map@10: 0.010839
2025-11-22 21:08:14 - GraphTrainer - INFO - mrr@10: 0.011254
2025-11-22 21:08:14 - GraphTrainer - INFO - precision@20: 0.002710
2025-11-22 21:08:14 - GraphTrainer - INFO - recall@20: 0.051489
2025-11-22 21:08:14 - GraphTrainer - INFO - hit_rate@20: 0.053896
2025-11-22 21:08:14 - GraphTrainer - INFO - ndcg@20: 0.020826
2025-11-22 21:08:14 - GraphTrainer - INFO - map@20: 0.012181
2025-11-22 21:08:14 - GraphTrainer - INFO - mrr@20: 0.012672
2025-11-22 21:08:14 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:08:14 - GraphTrainer - INFO - ============================================================
2025-11-22 21:08:14 - GraphTrainer - INFO - 开始第 7/1000 轮训练
2025-11-22 21:08:14 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.5358, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.5125, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.5294, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.5076, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.5208, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4881, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.5045, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.5158, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.5015, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.5010, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.5295, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.5045, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.5106, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.5062, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.5291, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4856, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.5053, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4987, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.5028, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.5068, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.5029, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.5036, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4942, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.5005, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.5192, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.5085, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4906, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4795, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.5099, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.5280, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.5071, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.5108, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4850, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4811, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.5108, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.5084, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.5040, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.5159, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4811, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.5010, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.5162, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.5153, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4968, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4933, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4884, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4983, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.5105, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4904, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.5017, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4938, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4959, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4837, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.5093, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.5117, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4923, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.5062, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.5114, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.5048, device='cuda:0', grad_fn=<AddBackward0>)
The 6 training average loss: 0.5044460635760735
2025-11-22 21:08:25 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:08:25 - GraphTrainer - INFO -   precision@5: 0.004176
2025-11-22 21:08:25 - GraphTrainer - INFO -   recall@5: 0.019946
2025-11-22 21:08:25 - GraphTrainer - INFO -   hit_rate@5: 0.020828
2025-11-22 21:08:25 - GraphTrainer - INFO -   ndcg@5: 0.012572
2025-11-22 21:08:25 - GraphTrainer - INFO -   map@5: 0.010008
2025-11-22 21:08:25 - GraphTrainer - INFO -   mrr@5: 0.010426
2025-11-22 21:08:25 - GraphTrainer - INFO -   precision@10: 0.003374
2025-11-22 21:08:25 - GraphTrainer - INFO -   recall@10: 0.031935
2025-11-22 21:08:25 - GraphTrainer - INFO -   hit_rate@10: 0.033582
2025-11-22 21:08:25 - GraphTrainer - INFO -   ndcg@10: 0.016439
2025-11-22 21:08:25 - GraphTrainer - INFO -   map@10: 0.011553
2025-11-22 21:08:25 - GraphTrainer - INFO -   mrr@10: 0.012064
2025-11-22 21:08:25 - GraphTrainer - INFO -   precision@20: 0.002733
2025-11-22 21:08:25 - GraphTrainer - INFO -   recall@20: 0.051793
2025-11-22 21:08:25 - GraphTrainer - INFO -   hit_rate@20: 0.054307
2025-11-22 21:08:25 - GraphTrainer - INFO -   ndcg@20: 0.021507
2025-11-22 21:08:25 - GraphTrainer - INFO -   map@20: 0.012927
2025-11-22 21:08:25 - GraphTrainer - INFO -   mrr@20: 0.013495
2025-11-22 21:08:25 - GraphTrainer - INFO - 第 7 轮训练完成
2025-11-22 21:08:25 - GraphTrainer - INFO - train_loss: 0.486844
2025-11-22 21:08:25 - GraphTrainer - INFO - precision@5: 0.004176
2025-11-22 21:08:25 - GraphTrainer - INFO - recall@5: 0.019946
2025-11-22 21:08:25 - GraphTrainer - INFO - hit_rate@5: 0.020828
2025-11-22 21:08:25 - GraphTrainer - INFO - ndcg@5: 0.012572
2025-11-22 21:08:25 - GraphTrainer - INFO - map@5: 0.010008
2025-11-22 21:08:25 - GraphTrainer - INFO - mrr@5: 0.010426
2025-11-22 21:08:25 - GraphTrainer - INFO - precision@10: 0.003374
2025-11-22 21:08:25 - GraphTrainer - INFO - recall@10: 0.031935
2025-11-22 21:08:25 - GraphTrainer - INFO - hit_rate@10: 0.033582
2025-11-22 21:08:25 - GraphTrainer - INFO - ndcg@10: 0.016439
2025-11-22 21:08:25 - GraphTrainer - INFO - map@10: 0.011553
2025-11-22 21:08:25 - GraphTrainer - INFO - mrr@10: 0.012064
2025-11-22 21:08:25 - GraphTrainer - INFO - precision@20: 0.002733
2025-11-22 21:08:25 - GraphTrainer - INFO - recall@20: 0.051793
2025-11-22 21:08:25 - GraphTrainer - INFO - hit_rate@20: 0.054307
2025-11-22 21:08:25 - GraphTrainer - INFO - ndcg@20: 0.021507
2025-11-22 21:08:25 - GraphTrainer - INFO - map@20: 0.012927
2025-11-22 21:08:25 - GraphTrainer - INFO - mrr@20: 0.013495
2025-11-22 21:08:25 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:08:25 - GraphTrainer - INFO - ============================================================
2025-11-22 21:08:25 - GraphTrainer - INFO - 开始第 8/1000 轮训练
2025-11-22 21:08:25 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4853, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.5004, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4668, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4883, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.5007, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4967, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4822, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.5028, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4871, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4950, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4979, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4902, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4829, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4777, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4770, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4884, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4929, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4687, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4697, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4824, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4960, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4815, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4777, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.5111, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4997, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4888, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4918, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4877, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4997, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.5056, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4949, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4829, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4740, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.5112, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4835, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4934, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4999, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4879, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4865, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4775, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4830, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4695, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4972, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4764, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4800, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4770, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4928, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.5014, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4760, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4892, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4672, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4759, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4591, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4872, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4966, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4830, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4845, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4767, device='cuda:0', grad_fn=<AddBackward0>)
The 7 training average loss: 0.48684371134330484
2025-11-22 21:08:36 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:08:36 - GraphTrainer - INFO -   precision@5: 0.004063
2025-11-22 21:08:36 - GraphTrainer - INFO -   recall@5: 0.019395
2025-11-22 21:08:36 - GraphTrainer - INFO -   hit_rate@5: 0.020262
2025-11-22 21:08:36 - GraphTrainer - INFO -   ndcg@5: 0.011706
2025-11-22 21:08:36 - GraphTrainer - INFO -   map@5: 0.009028
2025-11-22 21:08:36 - GraphTrainer - INFO -   mrr@5: 0.009527
2025-11-22 21:08:36 - GraphTrainer - INFO -   precision@10: 0.003518
2025-11-22 21:08:36 - GraphTrainer - INFO -   recall@10: 0.033443
2025-11-22 21:08:36 - GraphTrainer - INFO -   hit_rate@10: 0.035022
2025-11-22 21:08:36 - GraphTrainer - INFO -   ndcg@10: 0.016277
2025-11-22 21:08:36 - GraphTrainer - INFO -   map@10: 0.010890
2025-11-22 21:08:36 - GraphTrainer - INFO -   mrr@10: 0.011472
2025-11-22 21:08:36 - GraphTrainer - INFO -   precision@20: 0.002839
2025-11-22 21:08:36 - GraphTrainer - INFO -   recall@20: 0.054213
2025-11-22 21:08:36 - GraphTrainer - INFO -   hit_rate@20: 0.056416
2025-11-22 21:08:36 - GraphTrainer - INFO -   ndcg@20: 0.021522
2025-11-22 21:08:36 - GraphTrainer - INFO -   map@20: 0.012296
2025-11-22 21:08:36 - GraphTrainer - INFO -   mrr@20: 0.012915
2025-11-22 21:08:36 - GraphTrainer - INFO - 第 8 轮训练完成
2025-11-22 21:08:36 - GraphTrainer - INFO - train_loss: 0.473872
2025-11-22 21:08:36 - GraphTrainer - INFO - precision@5: 0.004063
2025-11-22 21:08:36 - GraphTrainer - INFO - recall@5: 0.019395
2025-11-22 21:08:36 - GraphTrainer - INFO - hit_rate@5: 0.020262
2025-11-22 21:08:36 - GraphTrainer - INFO - ndcg@5: 0.011706
2025-11-22 21:08:36 - GraphTrainer - INFO - map@5: 0.009028
2025-11-22 21:08:36 - GraphTrainer - INFO - mrr@5: 0.009527
2025-11-22 21:08:36 - GraphTrainer - INFO - precision@10: 0.003518
2025-11-22 21:08:36 - GraphTrainer - INFO - recall@10: 0.033443
2025-11-22 21:08:36 - GraphTrainer - INFO - hit_rate@10: 0.035022
2025-11-22 21:08:36 - GraphTrainer - INFO - ndcg@10: 0.016277
2025-11-22 21:08:36 - GraphTrainer - INFO - map@10: 0.010890
2025-11-22 21:08:36 - GraphTrainer - INFO - mrr@10: 0.011472
2025-11-22 21:08:36 - GraphTrainer - INFO - precision@20: 0.002839
2025-11-22 21:08:36 - GraphTrainer - INFO - recall@20: 0.054213
2025-11-22 21:08:36 - GraphTrainer - INFO - hit_rate@20: 0.056416
2025-11-22 21:08:36 - GraphTrainer - INFO - ndcg@20: 0.021522
2025-11-22 21:08:36 - GraphTrainer - INFO - map@20: 0.012296
2025-11-22 21:08:36 - GraphTrainer - INFO - mrr@20: 0.012915
2025-11-22 21:08:36 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:08:36 - GraphTrainer - INFO - ============================================================
2025-11-22 21:08:36 - GraphTrainer - INFO - 开始第 9/1000 轮训练
2025-11-22 21:08:36 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4874, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4846, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4773, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4725, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4726, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4707, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4830, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4893, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4868, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4802, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4682, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4761, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4791, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4940, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4873, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4633, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4824, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4813, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4723, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4662, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4887, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4713, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4694, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4890, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4646, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4740, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4600, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4707, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4784, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4782, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4771, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4812, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4679, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4544, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4787, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4725, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4753, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4687, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4737, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4783, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4879, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4711, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4576, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4763, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4741, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4498, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4594, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4629, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4587, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4729, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4803, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4667, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4669, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4636, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4706, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4774, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4703, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4718, device='cuda:0', grad_fn=<AddBackward0>)
The 8 training average loss: 0.473872401591005
2025-11-22 21:08:47 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:08:47 - GraphTrainer - INFO -   precision@5: 0.004268
2025-11-22 21:08:47 - GraphTrainer - INFO -   recall@5: 0.020251
2025-11-22 21:08:47 - GraphTrainer - INFO -   hit_rate@5: 0.021239
2025-11-22 21:08:47 - GraphTrainer - INFO -   ndcg@5: 0.012891
2025-11-22 21:08:47 - GraphTrainer - INFO -   map@5: 0.010311
2025-11-22 21:08:47 - GraphTrainer - INFO -   mrr@5: 0.010774
2025-11-22 21:08:47 - GraphTrainer - INFO -   precision@10: 0.003420
2025-11-22 21:08:47 - GraphTrainer - INFO -   recall@10: 0.032409
2025-11-22 21:08:47 - GraphTrainer - INFO -   hit_rate@10: 0.034045
2025-11-22 21:08:47 - GraphTrainer - INFO -   ndcg@10: 0.016812
2025-11-22 21:08:47 - GraphTrainer - INFO -   map@10: 0.011890
2025-11-22 21:08:47 - GraphTrainer - INFO -   mrr@10: 0.012424
2025-11-22 21:08:47 - GraphTrainer - INFO -   precision@20: 0.002877
2025-11-22 21:08:47 - GraphTrainer - INFO -   recall@20: 0.054381
2025-11-22 21:08:47 - GraphTrainer - INFO -   hit_rate@20: 0.057238
2025-11-22 21:08:47 - GraphTrainer - INFO -   ndcg@20: 0.022411
2025-11-22 21:08:47 - GraphTrainer - INFO -   map@20: 0.013396
2025-11-22 21:08:47 - GraphTrainer - INFO -   mrr@20: 0.014010
2025-11-22 21:08:47 - GraphTrainer - INFO - 第 9 轮训练完成
2025-11-22 21:08:47 - GraphTrainer - INFO - train_loss: 0.459557
2025-11-22 21:08:47 - GraphTrainer - INFO - precision@5: 0.004268
2025-11-22 21:08:47 - GraphTrainer - INFO - recall@5: 0.020251
2025-11-22 21:08:47 - GraphTrainer - INFO - hit_rate@5: 0.021239
2025-11-22 21:08:47 - GraphTrainer - INFO - ndcg@5: 0.012891
2025-11-22 21:08:47 - GraphTrainer - INFO - map@5: 0.010311
2025-11-22 21:08:47 - GraphTrainer - INFO - mrr@5: 0.010774
2025-11-22 21:08:47 - GraphTrainer - INFO - precision@10: 0.003420
2025-11-22 21:08:47 - GraphTrainer - INFO - recall@10: 0.032409
2025-11-22 21:08:47 - GraphTrainer - INFO - hit_rate@10: 0.034045
2025-11-22 21:08:47 - GraphTrainer - INFO - ndcg@10: 0.016812
2025-11-22 21:08:47 - GraphTrainer - INFO - map@10: 0.011890
2025-11-22 21:08:47 - GraphTrainer - INFO - mrr@10: 0.012424
2025-11-22 21:08:47 - GraphTrainer - INFO - precision@20: 0.002877
2025-11-22 21:08:47 - GraphTrainer - INFO - recall@20: 0.054381
2025-11-22 21:08:47 - GraphTrainer - INFO - hit_rate@20: 0.057238
2025-11-22 21:08:47 - GraphTrainer - INFO - ndcg@20: 0.022411
2025-11-22 21:08:47 - GraphTrainer - INFO - map@20: 0.013396
2025-11-22 21:08:47 - GraphTrainer - INFO - mrr@20: 0.014010
2025-11-22 21:08:47 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:08:47 - GraphTrainer - INFO - ============================================================
2025-11-22 21:08:47 - GraphTrainer - INFO - 开始第 10/1000 轮训练
2025-11-22 21:08:47 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4595, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4530, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4639, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4785, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4385, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4491, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4757, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4680, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4554, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4475, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4466, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4470, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4658, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4607, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4611, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4720, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4423, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4518, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4500, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4523, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4688, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4604, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4440, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4599, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4685, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4471, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4645, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4464, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4571, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4644, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4685, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4683, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4674, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4455, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4407, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4728, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4690, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4649, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4447, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4762, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4360, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4857, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4628, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4855, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4689, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4580, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4824, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4564, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4614, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4583, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4473, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4578, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4693, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4686, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4557, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4420, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4533, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4673, device='cuda:0', grad_fn=<AddBackward0>)
The 9 training average loss: 0.45955710472731753
2025-11-22 21:08:59 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:08:59 - GraphTrainer - INFO -   precision@5: 0.004289
2025-11-22 21:08:59 - GraphTrainer - INFO -   recall@5: 0.020383
2025-11-22 21:08:59 - GraphTrainer - INFO -   hit_rate@5: 0.021394
2025-11-22 21:08:59 - GraphTrainer - INFO -   ndcg@5: 0.012660
2025-11-22 21:08:59 - GraphTrainer - INFO -   map@5: 0.009959
2025-11-22 21:08:59 - GraphTrainer - INFO -   mrr@5: 0.010451
2025-11-22 21:08:59 - GraphTrainer - INFO -   precision@10: 0.003636
2025-11-22 21:08:59 - GraphTrainer - INFO -   recall@10: 0.034722
2025-11-22 21:08:59 - GraphTrainer - INFO -   hit_rate@10: 0.036153
2025-11-22 21:08:59 - GraphTrainer - INFO -   ndcg@10: 0.017299
2025-11-22 21:08:59 - GraphTrainer - INFO -   map@10: 0.011850
2025-11-22 21:08:59 - GraphTrainer - INFO -   mrr@10: 0.012392
2025-11-22 21:08:59 - GraphTrainer - INFO -   precision@20: 0.002960
2025-11-22 21:08:59 - GraphTrainer - INFO -   recall@20: 0.056235
2025-11-22 21:08:59 - GraphTrainer - INFO -   hit_rate@20: 0.058884
2025-11-22 21:08:59 - GraphTrainer - INFO -   ndcg@20: 0.022786
2025-11-22 21:08:59 - GraphTrainer - INFO -   map@20: 0.013326
2025-11-22 21:08:59 - GraphTrainer - INFO -   mrr@20: 0.013953
2025-11-22 21:08:59 - GraphTrainer - INFO - 第 10 轮训练完成
2025-11-22 21:08:59 - GraphTrainer - INFO - train_loss: 0.448931
2025-11-22 21:08:59 - GraphTrainer - INFO - precision@5: 0.004289
2025-11-22 21:08:59 - GraphTrainer - INFO - recall@5: 0.020383
2025-11-22 21:08:59 - GraphTrainer - INFO - hit_rate@5: 0.021394
2025-11-22 21:08:59 - GraphTrainer - INFO - ndcg@5: 0.012660
2025-11-22 21:08:59 - GraphTrainer - INFO - map@5: 0.009959
2025-11-22 21:08:59 - GraphTrainer - INFO - mrr@5: 0.010451
2025-11-22 21:08:59 - GraphTrainer - INFO - precision@10: 0.003636
2025-11-22 21:08:59 - GraphTrainer - INFO - recall@10: 0.034722
2025-11-22 21:08:59 - GraphTrainer - INFO - hit_rate@10: 0.036153
2025-11-22 21:08:59 - GraphTrainer - INFO - ndcg@10: 0.017299
2025-11-22 21:08:59 - GraphTrainer - INFO - map@10: 0.011850
2025-11-22 21:08:59 - GraphTrainer - INFO - mrr@10: 0.012392
2025-11-22 21:08:59 - GraphTrainer - INFO - precision@20: 0.002960
2025-11-22 21:08:59 - GraphTrainer - INFO - recall@20: 0.056235
2025-11-22 21:08:59 - GraphTrainer - INFO - hit_rate@20: 0.058884
2025-11-22 21:08:59 - GraphTrainer - INFO - ndcg@20: 0.022786
2025-11-22 21:08:59 - GraphTrainer - INFO - map@20: 0.013326
2025-11-22 21:08:59 - GraphTrainer - INFO - mrr@20: 0.013953
2025-11-22 21:08:59 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:08:59 - GraphTrainer - INFO - 检查点已保存: Epoch 10 -> ./checkpoints/checkpoint_epoch_10.pth
2025-11-22 21:08:59 - GraphTrainer - INFO - ============================================================
2025-11-22 21:08:59 - GraphTrainer - INFO - 开始第 11/1000 轮训练
2025-11-22 21:08:59 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4540, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4600, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4519, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4517, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4777, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4559, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4304, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4608, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4529, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4561, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4511, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4320, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4339, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4203, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4435, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4452, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4510, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4380, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4537, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4397, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4364, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4529, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4613, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4651, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4595, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4602, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4196, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4668, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4482, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4673, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4323, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4518, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4679, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4519, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4716, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4413, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4342, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4521, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4363, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4222, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4375, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4461, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4357, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4506, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4581, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4511, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4636, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4394, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4331, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4415, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4618, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4502, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4356, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4579, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4544, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4498, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4620, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4508, device='cuda:0', grad_fn=<AddBackward0>)
The 10 training average loss: 0.44893115039529474
2025-11-22 21:09:10 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:09:10 - GraphTrainer - INFO -   precision@5: 0.004382
2025-11-22 21:09:10 - GraphTrainer - INFO -   recall@5: 0.021046
2025-11-22 21:09:10 - GraphTrainer - INFO -   hit_rate@5: 0.021908
2025-11-22 21:09:10 - GraphTrainer - INFO -   ndcg@5: 0.013997
2025-11-22 21:09:10 - GraphTrainer - INFO -   map@5: 0.011532
2025-11-22 21:09:10 - GraphTrainer - INFO -   mrr@5: 0.011956
2025-11-22 21:09:10 - GraphTrainer - INFO -   precision@10: 0.003626
2025-11-22 21:09:10 - GraphTrainer - INFO -   recall@10: 0.034743
2025-11-22 21:09:10 - GraphTrainer - INFO -   hit_rate@10: 0.036205
2025-11-22 21:09:10 - GraphTrainer - INFO -   ndcg@10: 0.018414
2025-11-22 21:09:10 - GraphTrainer - INFO -   map@10: 0.013310
2025-11-22 21:09:10 - GraphTrainer - INFO -   mrr@10: 0.013809
2025-11-22 21:09:10 - GraphTrainer - INFO -   precision@20: 0.002980
2025-11-22 21:09:10 - GraphTrainer - INFO -   recall@20: 0.056331
2025-11-22 21:09:10 - GraphTrainer - INFO -   hit_rate@20: 0.059347
2025-11-22 21:09:10 - GraphTrainer - INFO -   ndcg@20: 0.023924
2025-11-22 21:09:10 - GraphTrainer - INFO -   map@20: 0.014780
2025-11-22 21:09:10 - GraphTrainer - INFO -   mrr@20: 0.015379
2025-11-22 21:09:10 - GraphTrainer - INFO - 第 11 轮训练完成
2025-11-22 21:09:10 - GraphTrainer - INFO - train_loss: 0.441113
2025-11-22 21:09:10 - GraphTrainer - INFO - precision@5: 0.004382
2025-11-22 21:09:10 - GraphTrainer - INFO - recall@5: 0.021046
2025-11-22 21:09:10 - GraphTrainer - INFO - hit_rate@5: 0.021908
2025-11-22 21:09:10 - GraphTrainer - INFO - ndcg@5: 0.013997
2025-11-22 21:09:10 - GraphTrainer - INFO - map@5: 0.011532
2025-11-22 21:09:10 - GraphTrainer - INFO - mrr@5: 0.011956
2025-11-22 21:09:10 - GraphTrainer - INFO - precision@10: 0.003626
2025-11-22 21:09:10 - GraphTrainer - INFO - recall@10: 0.034743
2025-11-22 21:09:10 - GraphTrainer - INFO - hit_rate@10: 0.036205
2025-11-22 21:09:10 - GraphTrainer - INFO - ndcg@10: 0.018414
2025-11-22 21:09:10 - GraphTrainer - INFO - map@10: 0.013310
2025-11-22 21:09:10 - GraphTrainer - INFO - mrr@10: 0.013809
2025-11-22 21:09:10 - GraphTrainer - INFO - precision@20: 0.002980
2025-11-22 21:09:10 - GraphTrainer - INFO - recall@20: 0.056331
2025-11-22 21:09:10 - GraphTrainer - INFO - hit_rate@20: 0.059347
2025-11-22 21:09:10 - GraphTrainer - INFO - ndcg@20: 0.023924
2025-11-22 21:09:10 - GraphTrainer - INFO - map@20: 0.014780
2025-11-22 21:09:10 - GraphTrainer - INFO - mrr@20: 0.015379
2025-11-22 21:09:10 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:09:10 - GraphTrainer - INFO - ============================================================
2025-11-22 21:09:10 - GraphTrainer - INFO - 开始第 12/1000 轮训练
2025-11-22 21:09:10 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4413, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4690, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4298, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4270, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4450, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4679, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4366, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4115, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4457, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4232, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4375, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4452, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4568, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4423, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4465, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4593, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4190, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4182, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4538, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4558, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4413, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4316, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4297, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4389, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4365, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4435, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4528, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4464, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4615, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4538, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4182, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4443, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4247, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4495, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4364, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4526, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4394, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4446, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4365, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4303, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4596, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4313, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4470, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4530, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4243, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4559, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4629, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4510, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4298, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4322, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4222, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4463, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4299, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4148, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4591, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4454, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4325, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4432, device='cuda:0', grad_fn=<AddBackward0>)
The 11 training average loss: 0.44111261902184323
2025-11-22 21:09:21 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:09:21 - GraphTrainer - INFO -   precision@5: 0.004916
2025-11-22 21:09:21 - GraphTrainer - INFO -   recall@5: 0.023490
2025-11-22 21:09:21 - GraphTrainer - INFO -   hit_rate@5: 0.024531
2025-11-22 21:09:21 - GraphTrainer - INFO -   ndcg@5: 0.014931
2025-11-22 21:09:21 - GraphTrainer - INFO -   map@5: 0.011961
2025-11-22 21:09:21 - GraphTrainer - INFO -   mrr@5: 0.012453
2025-11-22 21:09:21 - GraphTrainer - INFO -   precision@10: 0.003862
2025-11-22 21:09:21 - GraphTrainer - INFO -   recall@10: 0.036799
2025-11-22 21:09:21 - GraphTrainer - INFO -   hit_rate@10: 0.038570
2025-11-22 21:09:21 - GraphTrainer - INFO -   ndcg@10: 0.019247
2025-11-22 21:09:21 - GraphTrainer - INFO -   map@10: 0.013710
2025-11-22 21:09:21 - GraphTrainer - INFO -   mrr@10: 0.014291
2025-11-22 21:09:21 - GraphTrainer - INFO -   precision@20: 0.002983
2025-11-22 21:09:21 - GraphTrainer - INFO -   recall@20: 0.056685
2025-11-22 21:09:21 - GraphTrainer - INFO -   hit_rate@20: 0.059450
2025-11-22 21:09:21 - GraphTrainer - INFO -   ndcg@20: 0.024327
2025-11-22 21:09:21 - GraphTrainer - INFO -   map@20: 0.015089
2025-11-22 21:09:21 - GraphTrainer - INFO -   mrr@20: 0.015735
2025-11-22 21:09:21 - GraphTrainer - INFO - 第 12 轮训练完成
2025-11-22 21:09:21 - GraphTrainer - INFO - train_loss: 0.433249
2025-11-22 21:09:21 - GraphTrainer - INFO - precision@5: 0.004916
2025-11-22 21:09:21 - GraphTrainer - INFO - recall@5: 0.023490
2025-11-22 21:09:21 - GraphTrainer - INFO - hit_rate@5: 0.024531
2025-11-22 21:09:21 - GraphTrainer - INFO - ndcg@5: 0.014931
2025-11-22 21:09:21 - GraphTrainer - INFO - map@5: 0.011961
2025-11-22 21:09:21 - GraphTrainer - INFO - mrr@5: 0.012453
2025-11-22 21:09:21 - GraphTrainer - INFO - precision@10: 0.003862
2025-11-22 21:09:21 - GraphTrainer - INFO - recall@10: 0.036799
2025-11-22 21:09:21 - GraphTrainer - INFO - hit_rate@10: 0.038570
2025-11-22 21:09:21 - GraphTrainer - INFO - ndcg@10: 0.019247
2025-11-22 21:09:21 - GraphTrainer - INFO - map@10: 0.013710
2025-11-22 21:09:21 - GraphTrainer - INFO - mrr@10: 0.014291
2025-11-22 21:09:21 - GraphTrainer - INFO - precision@20: 0.002983
2025-11-22 21:09:21 - GraphTrainer - INFO - recall@20: 0.056685
2025-11-22 21:09:21 - GraphTrainer - INFO - hit_rate@20: 0.059450
2025-11-22 21:09:21 - GraphTrainer - INFO - ndcg@20: 0.024327
2025-11-22 21:09:21 - GraphTrainer - INFO - map@20: 0.015089
2025-11-22 21:09:21 - GraphTrainer - INFO - mrr@20: 0.015735
2025-11-22 21:09:21 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:09:21 - GraphTrainer - INFO - ============================================================
2025-11-22 21:09:21 - GraphTrainer - INFO - 开始第 13/1000 轮训练
2025-11-22 21:09:21 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4406, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4127, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4462, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4296, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4203, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4472, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4276, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4372, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4451, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4176, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4354, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4307, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4132, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4288, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4449, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4523, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4346, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4411, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4373, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4164, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4452, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4171, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4259, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4236, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4108, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4352, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4347, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4241, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4241, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4376, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4448, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4512, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4492, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4592, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4309, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4480, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4372, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4153, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4492, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4372, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4308, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4549, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4497, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4230, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4389, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4288, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4126, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4293, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4504, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4056, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4222, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4269, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4506, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4080, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4292, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4335, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4375, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4373, device='cuda:0', grad_fn=<AddBackward0>)
The 12 training average loss: 0.4332485332571227
2025-11-22 21:09:32 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:09:32 - GraphTrainer - INFO -   precision@5: 0.004310
2025-11-22 21:09:32 - GraphTrainer - INFO -   recall@5: 0.020866
2025-11-22 21:09:32 - GraphTrainer - INFO -   hit_rate@5: 0.021548
2025-11-22 21:09:32 - GraphTrainer - INFO -   ndcg@5: 0.013314
2025-11-22 21:09:32 - GraphTrainer - INFO -   map@5: 0.010737
2025-11-22 21:09:32 - GraphTrainer - INFO -   mrr@5: 0.011035
2025-11-22 21:09:32 - GraphTrainer - INFO -   precision@10: 0.003631
2025-11-22 21:09:32 - GraphTrainer - INFO -   recall@10: 0.034932
2025-11-22 21:09:32 - GraphTrainer - INFO -   hit_rate@10: 0.036308
2025-11-22 21:09:32 - GraphTrainer - INFO -   ndcg@10: 0.017839
2025-11-22 21:09:32 - GraphTrainer - INFO -   map@10: 0.012549
2025-11-22 21:09:32 - GraphTrainer - INFO -   mrr@10: 0.012933
2025-11-22 21:09:32 - GraphTrainer - INFO -   precision@20: 0.003026
2025-11-22 21:09:32 - GraphTrainer - INFO -   recall@20: 0.057418
2025-11-22 21:09:32 - GraphTrainer - INFO -   hit_rate@20: 0.060221
2025-11-22 21:09:32 - GraphTrainer - INFO -   ndcg@20: 0.023577
2025-11-22 21:09:32 - GraphTrainer - INFO -   map@20: 0.014087
2025-11-22 21:09:32 - GraphTrainer - INFO -   mrr@20: 0.014561
2025-11-22 21:09:32 - GraphTrainer - INFO - 第 13 轮训练完成
2025-11-22 21:09:32 - GraphTrainer - INFO - train_loss: 0.424503
2025-11-22 21:09:32 - GraphTrainer - INFO - precision@5: 0.004310
2025-11-22 21:09:32 - GraphTrainer - INFO - recall@5: 0.020866
2025-11-22 21:09:32 - GraphTrainer - INFO - hit_rate@5: 0.021548
2025-11-22 21:09:32 - GraphTrainer - INFO - ndcg@5: 0.013314
2025-11-22 21:09:32 - GraphTrainer - INFO - map@5: 0.010737
2025-11-22 21:09:32 - GraphTrainer - INFO - mrr@5: 0.011035
2025-11-22 21:09:32 - GraphTrainer - INFO - precision@10: 0.003631
2025-11-22 21:09:32 - GraphTrainer - INFO - recall@10: 0.034932
2025-11-22 21:09:32 - GraphTrainer - INFO - hit_rate@10: 0.036308
2025-11-22 21:09:32 - GraphTrainer - INFO - ndcg@10: 0.017839
2025-11-22 21:09:32 - GraphTrainer - INFO - map@10: 0.012549
2025-11-22 21:09:32 - GraphTrainer - INFO - mrr@10: 0.012933
2025-11-22 21:09:32 - GraphTrainer - INFO - precision@20: 0.003026
2025-11-22 21:09:32 - GraphTrainer - INFO - recall@20: 0.057418
2025-11-22 21:09:32 - GraphTrainer - INFO - hit_rate@20: 0.060221
2025-11-22 21:09:32 - GraphTrainer - INFO - ndcg@20: 0.023577
2025-11-22 21:09:32 - GraphTrainer - INFO - map@20: 0.014087
2025-11-22 21:09:32 - GraphTrainer - INFO - mrr@20: 0.014561
2025-11-22 21:09:32 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:09:32 - GraphTrainer - INFO - ============================================================
2025-11-22 21:09:32 - GraphTrainer - INFO - 开始第 14/1000 轮训练
2025-11-22 21:09:32 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4226, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4128, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4298, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4267, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4286, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4106, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4405, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4336, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4137, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4182, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4202, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4240, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4098, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4341, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4266, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4055, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4179, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4355, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4179, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4175, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4215, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4186, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4154, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4315, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4185, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4436, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4128, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3980, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4210, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4357, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4499, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4355, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4264, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4239, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4137, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4379, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4254, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4202, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4344, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4229, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4303, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4262, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4239, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4195, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4432, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4146, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4338, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4385, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4288, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4156, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4246, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4293, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3982, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4298, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4146, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4218, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4120, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4632, device='cuda:0', grad_fn=<AddBackward0>)
The 13 training average loss: 0.4245025546386324
2025-11-22 21:09:43 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:09:43 - GraphTrainer - INFO -   precision@5: 0.004731
2025-11-22 21:09:43 - GraphTrainer - INFO -   recall@5: 0.022541
2025-11-22 21:09:43 - GraphTrainer - INFO -   hit_rate@5: 0.023605
2025-11-22 21:09:43 - GraphTrainer - INFO -   ndcg@5: 0.014405
2025-11-22 21:09:43 - GraphTrainer - INFO -   map@5: 0.011543
2025-11-22 21:09:43 - GraphTrainer - INFO -   mrr@5: 0.012180
2025-11-22 21:09:43 - GraphTrainer - INFO -   precision@10: 0.004037
2025-11-22 21:09:43 - GraphTrainer - INFO -   recall@10: 0.038315
2025-11-22 21:09:43 - GraphTrainer - INFO -   hit_rate@10: 0.040216
2025-11-22 21:09:43 - GraphTrainer - INFO -   ndcg@10: 0.019544
2025-11-22 21:09:43 - GraphTrainer - INFO -   map@10: 0.013639
2025-11-22 21:09:43 - GraphTrainer - INFO -   mrr@10: 0.014379
2025-11-22 21:09:43 - GraphTrainer - INFO -   precision@20: 0.003237
2025-11-22 21:09:43 - GraphTrainer - INFO -   recall@20: 0.061325
2025-11-22 21:09:43 - GraphTrainer - INFO -   hit_rate@20: 0.064335
2025-11-22 21:09:43 - GraphTrainer - INFO -   ndcg@20: 0.025360
2025-11-22 21:09:43 - GraphTrainer - INFO -   map@20: 0.015182
2025-11-22 21:09:43 - GraphTrainer - INFO -   mrr@20: 0.015993
2025-11-22 21:09:43 - GraphTrainer - INFO - 第 14 轮训练完成
2025-11-22 21:09:43 - GraphTrainer - INFO - train_loss: 0.420346
2025-11-22 21:09:43 - GraphTrainer - INFO - precision@5: 0.004731
2025-11-22 21:09:43 - GraphTrainer - INFO - recall@5: 0.022541
2025-11-22 21:09:43 - GraphTrainer - INFO - hit_rate@5: 0.023605
2025-11-22 21:09:43 - GraphTrainer - INFO - ndcg@5: 0.014405
2025-11-22 21:09:43 - GraphTrainer - INFO - map@5: 0.011543
2025-11-22 21:09:43 - GraphTrainer - INFO - mrr@5: 0.012180
2025-11-22 21:09:43 - GraphTrainer - INFO - precision@10: 0.004037
2025-11-22 21:09:43 - GraphTrainer - INFO - recall@10: 0.038315
2025-11-22 21:09:43 - GraphTrainer - INFO - hit_rate@10: 0.040216
2025-11-22 21:09:43 - GraphTrainer - INFO - ndcg@10: 0.019544
2025-11-22 21:09:43 - GraphTrainer - INFO - map@10: 0.013639
2025-11-22 21:09:43 - GraphTrainer - INFO - mrr@10: 0.014379
2025-11-22 21:09:43 - GraphTrainer - INFO - precision@20: 0.003237
2025-11-22 21:09:43 - GraphTrainer - INFO - recall@20: 0.061325
2025-11-22 21:09:43 - GraphTrainer - INFO - hit_rate@20: 0.064335
2025-11-22 21:09:43 - GraphTrainer - INFO - ndcg@20: 0.025360
2025-11-22 21:09:43 - GraphTrainer - INFO - map@20: 0.015182
2025-11-22 21:09:43 - GraphTrainer - INFO - mrr@20: 0.015993
2025-11-22 21:09:43 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:09:43 - GraphTrainer - INFO - ============================================================
2025-11-22 21:09:43 - GraphTrainer - INFO - 开始第 15/1000 轮训练
2025-11-22 21:09:43 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4231, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4365, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4210, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4148, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4074, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4386, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4282, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4415, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4200, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4090, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4064, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3942, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3927, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4238, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4304, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4474, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4220, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4316, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4209, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4257, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4219, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4185, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4047, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4141, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4201, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4223, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4225, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4324, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3980, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4277, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4440, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4148, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4041, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4380, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4104, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4079, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4084, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4350, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4228, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4245, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4412, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4137, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4253, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4052, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4234, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4263, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4082, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4043, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4312, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4274, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4184, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3934, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4133, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4320, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4140, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4146, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4364, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4246, device='cuda:0', grad_fn=<AddBackward0>)
The 14 training average loss: 0.42034646046572716
2025-11-22 21:09:54 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:09:54 - GraphTrainer - INFO -   precision@5: 0.004711
2025-11-22 21:09:54 - GraphTrainer - INFO -   recall@5: 0.022493
2025-11-22 21:09:54 - GraphTrainer - INFO -   hit_rate@5: 0.023502
2025-11-22 21:09:54 - GraphTrainer - INFO -   ndcg@5: 0.014800
2025-11-22 21:09:54 - GraphTrainer - INFO -   map@5: 0.012105
2025-11-22 21:09:54 - GraphTrainer - INFO -   mrr@5: 0.012649
2025-11-22 21:09:54 - GraphTrainer - INFO -   precision@10: 0.003903
2025-11-22 21:09:54 - GraphTrainer - INFO -   recall@10: 0.037122
2025-11-22 21:09:54 - GraphTrainer - INFO -   hit_rate@10: 0.038982
2025-11-22 21:09:54 - GraphTrainer - INFO -   ndcg@10: 0.019525
2025-11-22 21:09:54 - GraphTrainer - INFO -   map@10: 0.014002
2025-11-22 21:09:54 - GraphTrainer - INFO -   mrr@10: 0.014663
2025-11-22 21:09:54 - GraphTrainer - INFO -   precision@20: 0.003230
2025-11-22 21:09:54 - GraphTrainer - INFO -   recall@20: 0.061115
2025-11-22 21:09:54 - GraphTrainer - INFO -   hit_rate@20: 0.064335
2025-11-22 21:09:54 - GraphTrainer - INFO -   ndcg@20: 0.025610
2025-11-22 21:09:54 - GraphTrainer - INFO -   map@20: 0.015623
2025-11-22 21:09:54 - GraphTrainer - INFO -   mrr@20: 0.016368
2025-11-22 21:09:54 - GraphTrainer - INFO - 第 15 轮训练完成
2025-11-22 21:09:54 - GraphTrainer - INFO - train_loss: 0.416035
2025-11-22 21:09:54 - GraphTrainer - INFO - precision@5: 0.004711
2025-11-22 21:09:54 - GraphTrainer - INFO - recall@5: 0.022493
2025-11-22 21:09:54 - GraphTrainer - INFO - hit_rate@5: 0.023502
2025-11-22 21:09:54 - GraphTrainer - INFO - ndcg@5: 0.014800
2025-11-22 21:09:54 - GraphTrainer - INFO - map@5: 0.012105
2025-11-22 21:09:54 - GraphTrainer - INFO - mrr@5: 0.012649
2025-11-22 21:09:54 - GraphTrainer - INFO - precision@10: 0.003903
2025-11-22 21:09:54 - GraphTrainer - INFO - recall@10: 0.037122
2025-11-22 21:09:54 - GraphTrainer - INFO - hit_rate@10: 0.038982
2025-11-22 21:09:54 - GraphTrainer - INFO - ndcg@10: 0.019525
2025-11-22 21:09:54 - GraphTrainer - INFO - map@10: 0.014002
2025-11-22 21:09:54 - GraphTrainer - INFO - mrr@10: 0.014663
2025-11-22 21:09:54 - GraphTrainer - INFO - precision@20: 0.003230
2025-11-22 21:09:54 - GraphTrainer - INFO - recall@20: 0.061115
2025-11-22 21:09:54 - GraphTrainer - INFO - hit_rate@20: 0.064335
2025-11-22 21:09:54 - GraphTrainer - INFO - ndcg@20: 0.025610
2025-11-22 21:09:54 - GraphTrainer - INFO - map@20: 0.015623
2025-11-22 21:09:54 - GraphTrainer - INFO - mrr@20: 0.016368
2025-11-22 21:09:54 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:09:54 - GraphTrainer - INFO - ============================================================
2025-11-22 21:09:54 - GraphTrainer - INFO - 开始第 16/1000 轮训练
2025-11-22 21:09:54 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3989, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4191, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4042, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4023, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4116, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4070, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4367, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4265, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4120, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4053, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4149, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4146, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4195, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4246, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4336, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4305, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4398, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4114, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4300, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4065, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4262, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4306, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4015, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4108, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4124, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4051, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4116, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4420, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4016, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3973, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3898, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4197, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4193, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4267, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4286, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4445, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4091, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4477, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4138, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4071, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4282, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4160, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4000, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4063, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4279, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4039, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4079, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4007, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4203, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4084, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4178, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4200, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4110, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3955, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4125, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4070, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4313, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4207, device='cuda:0', grad_fn=<AddBackward0>)
The 15 training average loss: 0.4160349985648846
2025-11-22 21:10:05 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:10:05 - GraphTrainer - INFO -   precision@5: 0.005050
2025-11-22 21:10:05 - GraphTrainer - INFO -   recall@5: 0.024043
2025-11-22 21:10:05 - GraphTrainer - INFO -   hit_rate@5: 0.025199
2025-11-22 21:10:05 - GraphTrainer - INFO -   ndcg@5: 0.015582
2025-11-22 21:10:05 - GraphTrainer - INFO -   map@5: 0.012603
2025-11-22 21:10:05 - GraphTrainer - INFO -   mrr@5: 0.013182
2025-11-22 21:10:05 - GraphTrainer - INFO -   precision@10: 0.004181
2025-11-22 21:10:05 - GraphTrainer - INFO -   recall@10: 0.039719
2025-11-22 21:10:05 - GraphTrainer - INFO -   hit_rate@10: 0.041707
2025-11-22 21:10:05 - GraphTrainer - INFO -   ndcg@10: 0.020639
2025-11-22 21:10:05 - GraphTrainer - INFO -   map@10: 0.014634
2025-11-22 21:10:05 - GraphTrainer - INFO -   mrr@10: 0.015321
2025-11-22 21:10:05 - GraphTrainer - INFO -   precision@20: 0.003263
2025-11-22 21:10:05 - GraphTrainer - INFO -   recall@20: 0.062033
2025-11-22 21:10:05 - GraphTrainer - INFO -   hit_rate@20: 0.065004
2025-11-22 21:10:05 - GraphTrainer - INFO -   ndcg@20: 0.026319
2025-11-22 21:10:05 - GraphTrainer - INFO -   map@20: 0.016170
2025-11-22 21:10:05 - GraphTrainer - INFO -   mrr@20: 0.016921
2025-11-22 21:10:05 - GraphTrainer - INFO - 第 16 轮训练完成
2025-11-22 21:10:05 - GraphTrainer - INFO - train_loss: 0.410859
2025-11-22 21:10:05 - GraphTrainer - INFO - precision@5: 0.005050
2025-11-22 21:10:05 - GraphTrainer - INFO - recall@5: 0.024043
2025-11-22 21:10:05 - GraphTrainer - INFO - hit_rate@5: 0.025199
2025-11-22 21:10:05 - GraphTrainer - INFO - ndcg@5: 0.015582
2025-11-22 21:10:05 - GraphTrainer - INFO - map@5: 0.012603
2025-11-22 21:10:05 - GraphTrainer - INFO - mrr@5: 0.013182
2025-11-22 21:10:05 - GraphTrainer - INFO - precision@10: 0.004181
2025-11-22 21:10:05 - GraphTrainer - INFO - recall@10: 0.039719
2025-11-22 21:10:05 - GraphTrainer - INFO - hit_rate@10: 0.041707
2025-11-22 21:10:05 - GraphTrainer - INFO - ndcg@10: 0.020639
2025-11-22 21:10:05 - GraphTrainer - INFO - map@10: 0.014634
2025-11-22 21:10:05 - GraphTrainer - INFO - mrr@10: 0.015321
2025-11-22 21:10:05 - GraphTrainer - INFO - precision@20: 0.003263
2025-11-22 21:10:05 - GraphTrainer - INFO - recall@20: 0.062033
2025-11-22 21:10:05 - GraphTrainer - INFO - hit_rate@20: 0.065004
2025-11-22 21:10:05 - GraphTrainer - INFO - ndcg@20: 0.026319
2025-11-22 21:10:05 - GraphTrainer - INFO - map@20: 0.016170
2025-11-22 21:10:05 - GraphTrainer - INFO - mrr@20: 0.016921
2025-11-22 21:10:05 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:10:05 - GraphTrainer - INFO - ============================================================
2025-11-22 21:10:05 - GraphTrainer - INFO - 开始第 17/1000 轮训练
2025-11-22 21:10:05 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3997, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4159, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4289, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4087, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4141, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4152, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3984, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4090, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3902, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4035, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4280, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3823, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4091, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4289, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4220, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4069, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4116, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4268, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4192, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4385, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3931, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4155, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4062, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4060, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4066, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4195, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4358, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4100, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4057, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4258, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4129, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3958, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3974, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4084, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3913, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4082, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4157, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4013, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4119, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4059, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4106, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4548, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4214, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4177, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4083, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4019, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4069, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3798, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4010, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3927, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4113, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4121, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4373, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4095, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4174, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4083, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4095, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3992, device='cuda:0', grad_fn=<AddBackward0>)
The 16 training average loss: 0.41085871231967
2025-11-22 21:10:16 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:10:16 - GraphTrainer - INFO -   precision@5: 0.005307
2025-11-22 21:10:16 - GraphTrainer - INFO -   recall@5: 0.025244
2025-11-22 21:10:16 - GraphTrainer - INFO -   hit_rate@5: 0.026485
2025-11-22 21:10:16 - GraphTrainer - INFO -   ndcg@5: 0.016236
2025-11-22 21:10:16 - GraphTrainer - INFO -   map@5: 0.013083
2025-11-22 21:10:16 - GraphTrainer - INFO -   mrr@5: 0.013692
2025-11-22 21:10:16 - GraphTrainer - INFO -   precision@10: 0.004124
2025-11-22 21:10:16 - GraphTrainer - INFO -   recall@10: 0.039202
2025-11-22 21:10:16 - GraphTrainer - INFO -   hit_rate@10: 0.041193
2025-11-22 21:10:16 - GraphTrainer - INFO -   ndcg@10: 0.020773
2025-11-22 21:10:16 - GraphTrainer - INFO -   map@10: 0.014929
2025-11-22 21:10:16 - GraphTrainer - INFO -   mrr@10: 0.015639
2025-11-22 21:10:16 - GraphTrainer - INFO -   precision@20: 0.003330
2025-11-22 21:10:16 - GraphTrainer - INFO -   recall@20: 0.062989
2025-11-22 21:10:16 - GraphTrainer - INFO -   hit_rate@20: 0.066135
2025-11-22 21:10:16 - GraphTrainer - INFO -   ndcg@20: 0.026854
2025-11-22 21:10:16 - GraphTrainer - INFO -   map@20: 0.016578
2025-11-22 21:10:16 - GraphTrainer - INFO -   mrr@20: 0.017357
2025-11-22 21:10:16 - GraphTrainer - INFO - 第 17 轮训练完成
2025-11-22 21:10:16 - GraphTrainer - INFO - train_loss: 0.404177
2025-11-22 21:10:16 - GraphTrainer - INFO - precision@5: 0.005307
2025-11-22 21:10:16 - GraphTrainer - INFO - recall@5: 0.025244
2025-11-22 21:10:16 - GraphTrainer - INFO - hit_rate@5: 0.026485
2025-11-22 21:10:16 - GraphTrainer - INFO - ndcg@5: 0.016236
2025-11-22 21:10:16 - GraphTrainer - INFO - map@5: 0.013083
2025-11-22 21:10:16 - GraphTrainer - INFO - mrr@5: 0.013692
2025-11-22 21:10:16 - GraphTrainer - INFO - precision@10: 0.004124
2025-11-22 21:10:16 - GraphTrainer - INFO - recall@10: 0.039202
2025-11-22 21:10:16 - GraphTrainer - INFO - hit_rate@10: 0.041193
2025-11-22 21:10:16 - GraphTrainer - INFO - ndcg@10: 0.020773
2025-11-22 21:10:16 - GraphTrainer - INFO - map@10: 0.014929
2025-11-22 21:10:16 - GraphTrainer - INFO - mrr@10: 0.015639
2025-11-22 21:10:16 - GraphTrainer - INFO - precision@20: 0.003330
2025-11-22 21:10:16 - GraphTrainer - INFO - recall@20: 0.062989
2025-11-22 21:10:16 - GraphTrainer - INFO - hit_rate@20: 0.066135
2025-11-22 21:10:16 - GraphTrainer - INFO - ndcg@20: 0.026854
2025-11-22 21:10:16 - GraphTrainer - INFO - map@20: 0.016578
2025-11-22 21:10:16 - GraphTrainer - INFO - mrr@20: 0.017357
2025-11-22 21:10:16 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:10:16 - GraphTrainer - INFO - ============================================================
2025-11-22 21:10:16 - GraphTrainer - INFO - 开始第 18/1000 轮训练
2025-11-22 21:10:16 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4126, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4189, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4029, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4049, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4007, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4019, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4195, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4172, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4075, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4129, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3855, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3923, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4006, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4090, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4214, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3866, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4495, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3734, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4087, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3954, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4084, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4038, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4054, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4098, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4108, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3884, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3968, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4185, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3984, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4172, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4135, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4138, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4092, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3973, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4180, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3669, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4194, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4263, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3909, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3973, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4008, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4378, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3917, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4117, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3862, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4033, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3878, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4065, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3941, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3926, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4039, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4074, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3962, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3986, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3743, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3969, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3970, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4243, device='cuda:0', grad_fn=<AddBackward0>)
The 17 training average loss: 0.40417744733136274
2025-11-22 21:10:27 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:10:27 - GraphTrainer - INFO -   precision@5: 0.004803
2025-11-22 21:10:27 - GraphTrainer - INFO -   recall@5: 0.023102
2025-11-22 21:10:27 - GraphTrainer - INFO -   hit_rate@5: 0.023965
2025-11-22 21:10:27 - GraphTrainer - INFO -   ndcg@5: 0.015147
2025-11-22 21:10:27 - GraphTrainer - INFO -   map@5: 0.012370
2025-11-22 21:10:27 - GraphTrainer - INFO -   mrr@5: 0.012925
2025-11-22 21:10:27 - GraphTrainer - INFO -   precision@10: 0.003975
2025-11-22 21:10:27 - GraphTrainer - INFO -   recall@10: 0.038063
2025-11-22 21:10:27 - GraphTrainer - INFO -   hit_rate@10: 0.039650
2025-11-22 21:10:27 - GraphTrainer - INFO -   ndcg@10: 0.020014
2025-11-22 21:10:27 - GraphTrainer - INFO -   map@10: 0.014353
2025-11-22 21:10:27 - GraphTrainer - INFO -   mrr@10: 0.015005
2025-11-22 21:10:27 - GraphTrainer - INFO -   precision@20: 0.003320
2025-11-22 21:10:27 - GraphTrainer - INFO -   recall@20: 0.062984
2025-11-22 21:10:27 - GraphTrainer - INFO -   hit_rate@20: 0.065878
2025-11-22 21:10:27 - GraphTrainer - INFO -   ndcg@20: 0.026333
2025-11-22 21:10:27 - GraphTrainer - INFO -   map@20: 0.016036
2025-11-22 21:10:27 - GraphTrainer - INFO -   mrr@20: 0.016771
2025-11-22 21:10:27 - GraphTrainer - INFO - 第 18 轮训练完成
2025-11-22 21:10:27 - GraphTrainer - INFO - train_loss: 0.401676
2025-11-22 21:10:27 - GraphTrainer - INFO - precision@5: 0.004803
2025-11-22 21:10:27 - GraphTrainer - INFO - recall@5: 0.023102
2025-11-22 21:10:27 - GraphTrainer - INFO - hit_rate@5: 0.023965
2025-11-22 21:10:27 - GraphTrainer - INFO - ndcg@5: 0.015147
2025-11-22 21:10:27 - GraphTrainer - INFO - map@5: 0.012370
2025-11-22 21:10:27 - GraphTrainer - INFO - mrr@5: 0.012925
2025-11-22 21:10:27 - GraphTrainer - INFO - precision@10: 0.003975
2025-11-22 21:10:27 - GraphTrainer - INFO - recall@10: 0.038063
2025-11-22 21:10:27 - GraphTrainer - INFO - hit_rate@10: 0.039650
2025-11-22 21:10:27 - GraphTrainer - INFO - ndcg@10: 0.020014
2025-11-22 21:10:27 - GraphTrainer - INFO - map@10: 0.014353
2025-11-22 21:10:27 - GraphTrainer - INFO - mrr@10: 0.015005
2025-11-22 21:10:27 - GraphTrainer - INFO - precision@20: 0.003320
2025-11-22 21:10:27 - GraphTrainer - INFO - recall@20: 0.062984
2025-11-22 21:10:27 - GraphTrainer - INFO - hit_rate@20: 0.065878
2025-11-22 21:10:27 - GraphTrainer - INFO - ndcg@20: 0.026333
2025-11-22 21:10:27 - GraphTrainer - INFO - map@20: 0.016036
2025-11-22 21:10:27 - GraphTrainer - INFO - mrr@20: 0.016771
2025-11-22 21:10:27 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:10:27 - GraphTrainer - INFO - ============================================================
2025-11-22 21:10:27 - GraphTrainer - INFO - 开始第 19/1000 轮训练
2025-11-22 21:10:27 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4089, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4175, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3878, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3944, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4053, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4210, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3803, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3800, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3692, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4049, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4125, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3977, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4097, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4023, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3922, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3996, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4058, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4037, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4211, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4299, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4143, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3959, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3844, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3956, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3947, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3995, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4066, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3971, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4168, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4123, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4077, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3910, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4013, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4087, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4117, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3943, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4049, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4065, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3881, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4050, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4032, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3965, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4028, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4168, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3893, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3935, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3764, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4077, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3902, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4046, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4031, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4166, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4029, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3847, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3899, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4176, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4175, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4034, device='cuda:0', grad_fn=<AddBackward0>)
The 18 training average loss: 0.40167550434326305
2025-11-22 21:10:38 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:10:38 - GraphTrainer - INFO -   precision@5: 0.005287
2025-11-22 21:10:38 - GraphTrainer - INFO -   recall@5: 0.025232
2025-11-22 21:10:38 - GraphTrainer - INFO -   hit_rate@5: 0.026382
2025-11-22 21:10:38 - GraphTrainer - INFO -   ndcg@5: 0.016174
2025-11-22 21:10:38 - GraphTrainer - INFO -   map@5: 0.012985
2025-11-22 21:10:38 - GraphTrainer - INFO -   mrr@5: 0.013632
2025-11-22 21:10:38 - GraphTrainer - INFO -   precision@10: 0.004130
2025-11-22 21:10:38 - GraphTrainer - INFO -   recall@10: 0.039223
2025-11-22 21:10:38 - GraphTrainer - INFO -   hit_rate@10: 0.041142
2025-11-22 21:10:38 - GraphTrainer - INFO -   ndcg@10: 0.020716
2025-11-22 21:10:38 - GraphTrainer - INFO -   map@10: 0.014825
2025-11-22 21:10:38 - GraphTrainer - INFO -   mrr@10: 0.015570
2025-11-22 21:10:38 - GraphTrainer - INFO -   precision@20: 0.003404
2025-11-22 21:10:38 - GraphTrainer - INFO -   recall@20: 0.064401
2025-11-22 21:10:38 - GraphTrainer - INFO -   hit_rate@20: 0.067575
2025-11-22 21:10:38 - GraphTrainer - INFO -   ndcg@20: 0.027108
2025-11-22 21:10:38 - GraphTrainer - INFO -   map@20: 0.016535
2025-11-22 21:10:38 - GraphTrainer - INFO -   mrr@20: 0.017356
2025-11-22 21:10:38 - GraphTrainer - INFO - 第 19 轮训练完成
2025-11-22 21:10:38 - GraphTrainer - INFO - train_loss: 0.397172
2025-11-22 21:10:38 - GraphTrainer - INFO - precision@5: 0.005287
2025-11-22 21:10:38 - GraphTrainer - INFO - recall@5: 0.025232
2025-11-22 21:10:38 - GraphTrainer - INFO - hit_rate@5: 0.026382
2025-11-22 21:10:38 - GraphTrainer - INFO - ndcg@5: 0.016174
2025-11-22 21:10:38 - GraphTrainer - INFO - map@5: 0.012985
2025-11-22 21:10:38 - GraphTrainer - INFO - mrr@5: 0.013632
2025-11-22 21:10:38 - GraphTrainer - INFO - precision@10: 0.004130
2025-11-22 21:10:38 - GraphTrainer - INFO - recall@10: 0.039223
2025-11-22 21:10:38 - GraphTrainer - INFO - hit_rate@10: 0.041142
2025-11-22 21:10:38 - GraphTrainer - INFO - ndcg@10: 0.020716
2025-11-22 21:10:38 - GraphTrainer - INFO - map@10: 0.014825
2025-11-22 21:10:38 - GraphTrainer - INFO - mrr@10: 0.015570
2025-11-22 21:10:38 - GraphTrainer - INFO - precision@20: 0.003404
2025-11-22 21:10:38 - GraphTrainer - INFO - recall@20: 0.064401
2025-11-22 21:10:38 - GraphTrainer - INFO - hit_rate@20: 0.067575
2025-11-22 21:10:38 - GraphTrainer - INFO - ndcg@20: 0.027108
2025-11-22 21:10:38 - GraphTrainer - INFO - map@20: 0.016535
2025-11-22 21:10:38 - GraphTrainer - INFO - mrr@20: 0.017356
2025-11-22 21:10:38 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:10:38 - GraphTrainer - INFO - ============================================================
2025-11-22 21:10:38 - GraphTrainer - INFO - 开始第 20/1000 轮训练
2025-11-22 21:10:38 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3998, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3979, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4017, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3854, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4188, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4397, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3809, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3922, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3991, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4126, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4261, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3857, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3827, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4035, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3614, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4083, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3889, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4031, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3847, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3818, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4065, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3920, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4016, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3982, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3857, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3850, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4106, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4159, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4129, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3922, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3996, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3975, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3988, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3819, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3584, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3946, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4312, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3861, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4142, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4051, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3743, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4078, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4004, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3865, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4015, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3997, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3885, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3915, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3834, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3725, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3932, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3835, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3960, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3966, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4205, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3857, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4176, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4143, device='cuda:0', grad_fn=<AddBackward0>)
The 19 training average loss: 0.397172077462591
2025-11-22 21:10:49 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:10:49 - GraphTrainer - INFO -   precision@5: 0.005019
2025-11-22 21:10:49 - GraphTrainer - INFO -   recall@5: 0.024342
2025-11-22 21:10:49 - GraphTrainer - INFO -   hit_rate@5: 0.025096
2025-11-22 21:10:49 - GraphTrainer - INFO -   ndcg@5: 0.015828
2025-11-22 21:10:49 - GraphTrainer - INFO -   map@5: 0.012914
2025-11-22 21:10:49 - GraphTrainer - INFO -   mrr@5: 0.013313
2025-11-22 21:10:49 - GraphTrainer - INFO -   precision@10: 0.004135
2025-11-22 21:10:49 - GraphTrainer - INFO -   recall@10: 0.039795
2025-11-22 21:10:49 - GraphTrainer - INFO -   hit_rate@10: 0.041296
2025-11-22 21:10:49 - GraphTrainer - INFO -   ndcg@10: 0.020854
2025-11-22 21:10:49 - GraphTrainer - INFO -   map@10: 0.014955
2025-11-22 21:10:49 - GraphTrainer - INFO -   mrr@10: 0.015447
2025-11-22 21:10:49 - GraphTrainer - INFO -   precision@20: 0.003343
2025-11-22 21:10:49 - GraphTrainer - INFO -   recall@20: 0.063565
2025-11-22 21:10:49 - GraphTrainer - INFO -   hit_rate@20: 0.066598
2025-11-22 21:10:49 - GraphTrainer - INFO -   ndcg@20: 0.026900
2025-11-22 21:10:49 - GraphTrainer - INFO -   map@20: 0.016566
2025-11-22 21:10:49 - GraphTrainer - INFO -   mrr@20: 0.017154
2025-11-22 21:10:49 - GraphTrainer - INFO - 第 20 轮训练完成
2025-11-22 21:10:49 - GraphTrainer - INFO - train_loss: 0.391611
2025-11-22 21:10:49 - GraphTrainer - INFO - precision@5: 0.005019
2025-11-22 21:10:49 - GraphTrainer - INFO - recall@5: 0.024342
2025-11-22 21:10:49 - GraphTrainer - INFO - hit_rate@5: 0.025096
2025-11-22 21:10:49 - GraphTrainer - INFO - ndcg@5: 0.015828
2025-11-22 21:10:49 - GraphTrainer - INFO - map@5: 0.012914
2025-11-22 21:10:49 - GraphTrainer - INFO - mrr@5: 0.013313
2025-11-22 21:10:49 - GraphTrainer - INFO - precision@10: 0.004135
2025-11-22 21:10:49 - GraphTrainer - INFO - recall@10: 0.039795
2025-11-22 21:10:49 - GraphTrainer - INFO - hit_rate@10: 0.041296
2025-11-22 21:10:49 - GraphTrainer - INFO - ndcg@10: 0.020854
2025-11-22 21:10:49 - GraphTrainer - INFO - map@10: 0.014955
2025-11-22 21:10:49 - GraphTrainer - INFO - mrr@10: 0.015447
2025-11-22 21:10:49 - GraphTrainer - INFO - precision@20: 0.003343
2025-11-22 21:10:49 - GraphTrainer - INFO - recall@20: 0.063565
2025-11-22 21:10:49 - GraphTrainer - INFO - hit_rate@20: 0.066598
2025-11-22 21:10:49 - GraphTrainer - INFO - ndcg@20: 0.026900
2025-11-22 21:10:49 - GraphTrainer - INFO - map@20: 0.016566
2025-11-22 21:10:49 - GraphTrainer - INFO - mrr@20: 0.017154
2025-11-22 21:10:49 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:10:49 - GraphTrainer - INFO - 检查点已保存: Epoch 20 -> ./checkpoints/checkpoint_epoch_20.pth
2025-11-22 21:10:49 - GraphTrainer - INFO - ============================================================
2025-11-22 21:10:49 - GraphTrainer - INFO - 开始第 21/1000 轮训练
2025-11-22 21:10:49 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3824, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3865, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4047, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3775, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3914, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3853, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4233, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3936, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3919, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3997, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3855, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3910, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4034, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3983, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3930, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3809, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3667, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3951, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3957, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3873, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4112, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4057, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4107, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3892, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3964, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3963, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3907, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3970, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3930, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3828, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3907, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4202, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3611, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3916, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3608, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4305, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3718, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4008, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3863, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3981, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3989, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3873, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3822, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4038, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4061, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3703, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3961, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3747, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4061, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3820, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3951, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3762, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3693, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3919, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4003, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3987, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3808, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3757, device='cuda:0', grad_fn=<AddBackward0>)
The 20 training average loss: 0.39161111054749326
2025-11-22 21:11:00 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:11:00 - GraphTrainer - INFO -   precision@5: 0.005153
2025-11-22 21:11:00 - GraphTrainer - INFO -   recall@5: 0.024664
2025-11-22 21:11:00 - GraphTrainer - INFO -   hit_rate@5: 0.025765
2025-11-22 21:11:00 - GraphTrainer - INFO -   ndcg@5: 0.015646
2025-11-22 21:11:00 - GraphTrainer - INFO -   map@5: 0.012532
2025-11-22 21:11:00 - GraphTrainer - INFO -   mrr@5: 0.013038
2025-11-22 21:11:00 - GraphTrainer - INFO -   precision@10: 0.004418
2025-11-22 21:11:00 - GraphTrainer - INFO -   recall@10: 0.042221
2025-11-22 21:11:00 - GraphTrainer - INFO -   hit_rate@10: 0.044124
2025-11-22 21:11:00 - GraphTrainer - INFO -   ndcg@10: 0.021308
2025-11-22 21:11:00 - GraphTrainer - INFO -   map@10: 0.014809
2025-11-22 21:11:00 - GraphTrainer - INFO -   mrr@10: 0.015417
2025-11-22 21:11:00 - GraphTrainer - INFO -   precision@20: 0.003466
2025-11-22 21:11:00 - GraphTrainer - INFO -   recall@20: 0.065930
2025-11-22 21:11:00 - GraphTrainer - INFO -   hit_rate@20: 0.069118
2025-11-22 21:11:00 - GraphTrainer - INFO -   ndcg@20: 0.027317
2025-11-22 21:11:00 - GraphTrainer - INFO -   map@20: 0.016408
2025-11-22 21:11:00 - GraphTrainer - INFO -   mrr@20: 0.017101
2025-11-22 21:11:00 - GraphTrainer - INFO - 第 21 轮训练完成
2025-11-22 21:11:00 - GraphTrainer - INFO - train_loss: 0.391814
2025-11-22 21:11:00 - GraphTrainer - INFO - precision@5: 0.005153
2025-11-22 21:11:00 - GraphTrainer - INFO - recall@5: 0.024664
2025-11-22 21:11:00 - GraphTrainer - INFO - hit_rate@5: 0.025765
2025-11-22 21:11:00 - GraphTrainer - INFO - ndcg@5: 0.015646
2025-11-22 21:11:00 - GraphTrainer - INFO - map@5: 0.012532
2025-11-22 21:11:00 - GraphTrainer - INFO - mrr@5: 0.013038
2025-11-22 21:11:00 - GraphTrainer - INFO - precision@10: 0.004418
2025-11-22 21:11:00 - GraphTrainer - INFO - recall@10: 0.042221
2025-11-22 21:11:00 - GraphTrainer - INFO - hit_rate@10: 0.044124
2025-11-22 21:11:00 - GraphTrainer - INFO - ndcg@10: 0.021308
2025-11-22 21:11:00 - GraphTrainer - INFO - map@10: 0.014809
2025-11-22 21:11:00 - GraphTrainer - INFO - mrr@10: 0.015417
2025-11-22 21:11:00 - GraphTrainer - INFO - precision@20: 0.003466
2025-11-22 21:11:00 - GraphTrainer - INFO - recall@20: 0.065930
2025-11-22 21:11:00 - GraphTrainer - INFO - hit_rate@20: 0.069118
2025-11-22 21:11:00 - GraphTrainer - INFO - ndcg@20: 0.027317
2025-11-22 21:11:00 - GraphTrainer - INFO - map@20: 0.016408
2025-11-22 21:11:00 - GraphTrainer - INFO - mrr@20: 0.017101
2025-11-22 21:11:00 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:11:00 - GraphTrainer - INFO - ============================================================
2025-11-22 21:11:00 - GraphTrainer - INFO - 开始第 22/1000 轮训练
2025-11-22 21:11:00 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3856, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3798, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3794, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3974, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3820, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3871, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3897, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4003, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3877, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4016, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3823, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3875, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3965, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3968, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3933, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4000, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3995, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3963, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3793, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4199, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3917, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3876, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3924, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3764, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4051, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3859, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3856, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3923, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3984, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3946, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4057, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4013, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3607, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3770, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4093, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3882, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3921, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3833, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4082, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4024, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3913, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3848, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3961, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3901, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4054, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3928, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3954, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3842, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3891, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3845, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3673, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4021, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4059, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3815, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3729, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4098, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3996, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3921, device='cuda:0', grad_fn=<AddBackward0>)
The 21 training average loss: 0.39181386037119503
2025-11-22 21:11:12 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:11:12 - GraphTrainer - INFO -   precision@5: 0.004711
2025-11-22 21:11:12 - GraphTrainer - INFO -   recall@5: 0.022633
2025-11-22 21:11:12 - GraphTrainer - INFO -   hit_rate@5: 0.023554
2025-11-22 21:11:12 - GraphTrainer - INFO -   ndcg@5: 0.014517
2025-11-22 21:11:12 - GraphTrainer - INFO -   map@5: 0.011715
2025-11-22 21:11:12 - GraphTrainer - INFO -   mrr@5: 0.012173
2025-11-22 21:11:12 - GraphTrainer - INFO -   precision@10: 0.004037
2025-11-22 21:11:12 - GraphTrainer - INFO -   recall@10: 0.038573
2025-11-22 21:11:12 - GraphTrainer - INFO -   hit_rate@10: 0.040113
2025-11-22 21:11:12 - GraphTrainer - INFO -   ndcg@10: 0.019689
2025-11-22 21:11:12 - GraphTrainer - INFO -   map@10: 0.013812
2025-11-22 21:11:12 - GraphTrainer - INFO -   mrr@10: 0.014349
2025-11-22 21:11:12 - GraphTrainer - INFO -   precision@20: 0.003407
2025-11-22 21:11:12 - GraphTrainer - INFO -   recall@20: 0.064973
2025-11-22 21:11:12 - GraphTrainer - INFO -   hit_rate@20: 0.067832
2025-11-22 21:11:12 - GraphTrainer - INFO -   ndcg@20: 0.026373
2025-11-22 21:11:12 - GraphTrainer - INFO -   map@20: 0.015596
2025-11-22 21:11:12 - GraphTrainer - INFO -   mrr@20: 0.016220
2025-11-22 21:11:12 - GraphTrainer - INFO - 第 22 轮训练完成
2025-11-22 21:11:12 - GraphTrainer - INFO - train_loss: 0.386691
2025-11-22 21:11:12 - GraphTrainer - INFO - precision@5: 0.004711
2025-11-22 21:11:12 - GraphTrainer - INFO - recall@5: 0.022633
2025-11-22 21:11:12 - GraphTrainer - INFO - hit_rate@5: 0.023554
2025-11-22 21:11:12 - GraphTrainer - INFO - ndcg@5: 0.014517
2025-11-22 21:11:12 - GraphTrainer - INFO - map@5: 0.011715
2025-11-22 21:11:12 - GraphTrainer - INFO - mrr@5: 0.012173
2025-11-22 21:11:12 - GraphTrainer - INFO - precision@10: 0.004037
2025-11-22 21:11:12 - GraphTrainer - INFO - recall@10: 0.038573
2025-11-22 21:11:12 - GraphTrainer - INFO - hit_rate@10: 0.040113
2025-11-22 21:11:12 - GraphTrainer - INFO - ndcg@10: 0.019689
2025-11-22 21:11:12 - GraphTrainer - INFO - map@10: 0.013812
2025-11-22 21:11:12 - GraphTrainer - INFO - mrr@10: 0.014349
2025-11-22 21:11:12 - GraphTrainer - INFO - precision@20: 0.003407
2025-11-22 21:11:12 - GraphTrainer - INFO - recall@20: 0.064973
2025-11-22 21:11:12 - GraphTrainer - INFO - hit_rate@20: 0.067832
2025-11-22 21:11:12 - GraphTrainer - INFO - ndcg@20: 0.026373
2025-11-22 21:11:12 - GraphTrainer - INFO - map@20: 0.015596
2025-11-22 21:11:12 - GraphTrainer - INFO - mrr@20: 0.016220
2025-11-22 21:11:12 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:11:12 - GraphTrainer - INFO - ============================================================
2025-11-22 21:11:12 - GraphTrainer - INFO - 开始第 23/1000 轮训练
2025-11-22 21:11:12 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3709, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3946, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4005, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3991, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3615, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3838, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3766, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3772, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3835, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3851, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3804, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3947, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3550, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4238, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3771, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3995, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3994, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3874, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3923, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4215, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3780, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3955, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3911, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3889, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3881, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3730, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3911, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3817, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3740, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3938, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3969, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3945, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4098, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3906, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3951, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3726, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3539, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4017, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3582, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3701, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3731, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3973, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4022, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3935, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3968, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4016, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4051, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3823, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3789, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3891, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3901, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3957, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3803, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3662, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4066, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4031, device='cuda:0', grad_fn=<AddBackward0>)
The 22 training average loss: 0.386690783603438
2025-11-22 21:11:23 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:11:23 - GraphTrainer - INFO -   precision@5: 0.005153
2025-11-22 21:11:23 - GraphTrainer - INFO -   recall@5: 0.024683
2025-11-22 21:11:23 - GraphTrainer - INFO -   hit_rate@5: 0.025714
2025-11-22 21:11:23 - GraphTrainer - INFO -   ndcg@5: 0.016154
2025-11-22 21:11:23 - GraphTrainer - INFO -   map@5: 0.013141
2025-11-22 21:11:23 - GraphTrainer - INFO -   mrr@5: 0.013734
2025-11-22 21:11:23 - GraphTrainer - INFO -   precision@10: 0.004346
2025-11-22 21:11:23 - GraphTrainer - INFO -   recall@10: 0.041553
2025-11-22 21:11:23 - GraphTrainer - INFO -   hit_rate@10: 0.043353
2025-11-22 21:11:23 - GraphTrainer - INFO -   ndcg@10: 0.021565
2025-11-22 21:11:23 - GraphTrainer - INFO -   map@10: 0.015303
2025-11-22 21:11:23 - GraphTrainer - INFO -   mrr@10: 0.016000
2025-11-22 21:11:23 - GraphTrainer - INFO -   precision@20: 0.003435
2025-11-22 21:11:23 - GraphTrainer - INFO -   recall@20: 0.065539
2025-11-22 21:11:23 - GraphTrainer - INFO -   hit_rate@20: 0.068295
2025-11-22 21:11:23 - GraphTrainer - INFO -   ndcg@20: 0.027635
2025-11-22 21:11:23 - GraphTrainer - INFO -   map@20: 0.016927
2025-11-22 21:11:23 - GraphTrainer - INFO -   mrr@20: 0.017683
2025-11-22 21:11:23 - GraphTrainer - INFO - 第 23 轮训练完成
2025-11-22 21:11:23 - GraphTrainer - INFO - train_loss: 0.381630
2025-11-22 21:11:23 - GraphTrainer - INFO - precision@5: 0.005153
2025-11-22 21:11:23 - GraphTrainer - INFO - recall@5: 0.024683
2025-11-22 21:11:23 - GraphTrainer - INFO - hit_rate@5: 0.025714
2025-11-22 21:11:23 - GraphTrainer - INFO - ndcg@5: 0.016154
2025-11-22 21:11:23 - GraphTrainer - INFO - map@5: 0.013141
2025-11-22 21:11:23 - GraphTrainer - INFO - mrr@5: 0.013734
2025-11-22 21:11:23 - GraphTrainer - INFO - precision@10: 0.004346
2025-11-22 21:11:23 - GraphTrainer - INFO - recall@10: 0.041553
2025-11-22 21:11:23 - GraphTrainer - INFO - hit_rate@10: 0.043353
2025-11-22 21:11:23 - GraphTrainer - INFO - ndcg@10: 0.021565
2025-11-22 21:11:23 - GraphTrainer - INFO - map@10: 0.015303
2025-11-22 21:11:23 - GraphTrainer - INFO - mrr@10: 0.016000
2025-11-22 21:11:23 - GraphTrainer - INFO - precision@20: 0.003435
2025-11-22 21:11:23 - GraphTrainer - INFO - recall@20: 0.065539
2025-11-22 21:11:23 - GraphTrainer - INFO - hit_rate@20: 0.068295
2025-11-22 21:11:23 - GraphTrainer - INFO - ndcg@20: 0.027635
2025-11-22 21:11:23 - GraphTrainer - INFO - map@20: 0.016927
2025-11-22 21:11:23 - GraphTrainer - INFO - mrr@20: 0.017683
2025-11-22 21:11:23 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:11:23 - GraphTrainer - INFO - ============================================================
2025-11-22 21:11:23 - GraphTrainer - INFO - 开始第 24/1000 轮训练
2025-11-22 21:11:23 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3842, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3938, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3671, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3898, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3870, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3851, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3695, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4038, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3806, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3908, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3716, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3693, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3740, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3792, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3822, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3783, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3805, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3748, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3910, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3768, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3967, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3996, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3918, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3845, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3780, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3819, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3721, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3735, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3900, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3793, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3689, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3843, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3642, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3621, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3858, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3817, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3852, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4014, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3963, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3592, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3893, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3857, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4042, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4026, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3863, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3895, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3742, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3878, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3823, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3759, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3731, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3982, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3749, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3783, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
The 23 training average loss: 0.3816303615940028
2025-11-22 21:11:34 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:11:34 - GraphTrainer - INFO -   precision@5: 0.005163
2025-11-22 21:11:34 - GraphTrainer - INFO -   recall@5: 0.024899
2025-11-22 21:11:34 - GraphTrainer - INFO -   hit_rate@5: 0.025816
2025-11-22 21:11:34 - GraphTrainer - INFO -   ndcg@5: 0.016261
2025-11-22 21:11:34 - GraphTrainer - INFO -   map@5: 0.013268
2025-11-22 21:11:34 - GraphTrainer - INFO -   mrr@5: 0.013748
2025-11-22 21:11:34 - GraphTrainer - INFO -   precision@10: 0.004392
2025-11-22 21:11:34 - GraphTrainer - INFO -   recall@10: 0.042115
2025-11-22 21:11:34 - GraphTrainer - INFO -   hit_rate@10: 0.043867
2025-11-22 21:11:34 - GraphTrainer - INFO -   ndcg@10: 0.021839
2025-11-22 21:11:34 - GraphTrainer - INFO -   map@10: 0.015519
2025-11-22 21:11:34 - GraphTrainer - INFO -   mrr@10: 0.016111
2025-11-22 21:11:34 - GraphTrainer - INFO -   precision@20: 0.003569
2025-11-22 21:11:34 - GraphTrainer - INFO -   recall@20: 0.067742
2025-11-22 21:11:34 - GraphTrainer - INFO -   hit_rate@20: 0.071072
2025-11-22 21:11:34 - GraphTrainer - INFO -   ndcg@20: 0.028368
2025-11-22 21:11:34 - GraphTrainer - INFO -   map@20: 0.017268
2025-11-22 21:11:34 - GraphTrainer - INFO -   mrr@20: 0.017959
2025-11-22 21:11:34 - GraphTrainer - INFO - 第 24 轮训练完成
2025-11-22 21:11:34 - GraphTrainer - INFO - train_loss: 0.375870
2025-11-22 21:11:34 - GraphTrainer - INFO - precision@5: 0.005163
2025-11-22 21:11:34 - GraphTrainer - INFO - recall@5: 0.024899
2025-11-22 21:11:34 - GraphTrainer - INFO - hit_rate@5: 0.025816
2025-11-22 21:11:34 - GraphTrainer - INFO - ndcg@5: 0.016261
2025-11-22 21:11:34 - GraphTrainer - INFO - map@5: 0.013268
2025-11-22 21:11:34 - GraphTrainer - INFO - mrr@5: 0.013748
2025-11-22 21:11:34 - GraphTrainer - INFO - precision@10: 0.004392
2025-11-22 21:11:34 - GraphTrainer - INFO - recall@10: 0.042115
2025-11-22 21:11:34 - GraphTrainer - INFO - hit_rate@10: 0.043867
2025-11-22 21:11:34 - GraphTrainer - INFO - ndcg@10: 0.021839
2025-11-22 21:11:34 - GraphTrainer - INFO - map@10: 0.015519
2025-11-22 21:11:34 - GraphTrainer - INFO - mrr@10: 0.016111
2025-11-22 21:11:34 - GraphTrainer - INFO - precision@20: 0.003569
2025-11-22 21:11:34 - GraphTrainer - INFO - recall@20: 0.067742
2025-11-22 21:11:34 - GraphTrainer - INFO - hit_rate@20: 0.071072
2025-11-22 21:11:34 - GraphTrainer - INFO - ndcg@20: 0.028368
2025-11-22 21:11:34 - GraphTrainer - INFO - map@20: 0.017268
2025-11-22 21:11:34 - GraphTrainer - INFO - mrr@20: 0.017959
2025-11-22 21:11:34 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:11:34 - GraphTrainer - INFO - ============================================================
2025-11-22 21:11:34 - GraphTrainer - INFO - 开始第 25/1000 轮训练
2025-11-22 21:11:34 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3747, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3653, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3848, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3822, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3900, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3797, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3861, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3787, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3778, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3703, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3878, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3793, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3798, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3876, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3697, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3706, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3716, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3537, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3905, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3939, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3797, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3772, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3693, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3709, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3794, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3848, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3532, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3753, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4030, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3705, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3927, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3844, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3738, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3822, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3576, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3754, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3850, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4013, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3708, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3749, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3778, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3604, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3818, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3709, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3890, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3607, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4082, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3797, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3863, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3821, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3700, device='cuda:0', grad_fn=<AddBackward0>)
The 24 training average loss: 0.37587009935543453
2025-11-22 21:11:45 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:11:45 - GraphTrainer - INFO -   precision@5: 0.005060
2025-11-22 21:11:45 - GraphTrainer - INFO -   recall@5: 0.024204
2025-11-22 21:11:45 - GraphTrainer - INFO -   hit_rate@5: 0.025251
2025-11-22 21:11:45 - GraphTrainer - INFO -   ndcg@5: 0.015695
2025-11-22 21:11:45 - GraphTrainer - INFO -   map@5: 0.012751
2025-11-22 21:11:45 - GraphTrainer - INFO -   mrr@5: 0.013193
2025-11-22 21:11:45 - GraphTrainer - INFO -   precision@10: 0.004274
2025-11-22 21:11:45 - GraphTrainer - INFO -   recall@10: 0.040643
2025-11-22 21:11:45 - GraphTrainer - INFO -   hit_rate@10: 0.042633
2025-11-22 21:11:45 - GraphTrainer - INFO -   ndcg@10: 0.021029
2025-11-22 21:11:45 - GraphTrainer - INFO -   map@10: 0.014903
2025-11-22 21:11:45 - GraphTrainer - INFO -   mrr@10: 0.015463
2025-11-22 21:11:45 - GraphTrainer - INFO -   precision@20: 0.003533
2025-11-22 21:11:45 - GraphTrainer - INFO -   recall@20: 0.066908
2025-11-22 21:11:45 - GraphTrainer - INFO -   hit_rate@20: 0.070352
2025-11-22 21:11:45 - GraphTrainer - INFO -   ndcg@20: 0.027696
2025-11-22 21:11:45 - GraphTrainer - INFO -   map@20: 0.016683
2025-11-22 21:11:45 - GraphTrainer - INFO -   mrr@20: 0.017335
2025-11-22 21:11:45 - GraphTrainer - INFO - 第 25 轮训练完成
2025-11-22 21:11:45 - GraphTrainer - INFO - train_loss: 0.377734
2025-11-22 21:11:45 - GraphTrainer - INFO - precision@5: 0.005060
2025-11-22 21:11:45 - GraphTrainer - INFO - recall@5: 0.024204
2025-11-22 21:11:45 - GraphTrainer - INFO - hit_rate@5: 0.025251
2025-11-22 21:11:45 - GraphTrainer - INFO - ndcg@5: 0.015695
2025-11-22 21:11:45 - GraphTrainer - INFO - map@5: 0.012751
2025-11-22 21:11:45 - GraphTrainer - INFO - mrr@5: 0.013193
2025-11-22 21:11:45 - GraphTrainer - INFO - precision@10: 0.004274
2025-11-22 21:11:45 - GraphTrainer - INFO - recall@10: 0.040643
2025-11-22 21:11:45 - GraphTrainer - INFO - hit_rate@10: 0.042633
2025-11-22 21:11:45 - GraphTrainer - INFO - ndcg@10: 0.021029
2025-11-22 21:11:45 - GraphTrainer - INFO - map@10: 0.014903
2025-11-22 21:11:45 - GraphTrainer - INFO - mrr@10: 0.015463
2025-11-22 21:11:45 - GraphTrainer - INFO - precision@20: 0.003533
2025-11-22 21:11:45 - GraphTrainer - INFO - recall@20: 0.066908
2025-11-22 21:11:45 - GraphTrainer - INFO - hit_rate@20: 0.070352
2025-11-22 21:11:45 - GraphTrainer - INFO - ndcg@20: 0.027696
2025-11-22 21:11:45 - GraphTrainer - INFO - map@20: 0.016683
2025-11-22 21:11:45 - GraphTrainer - INFO - mrr@20: 0.017335
2025-11-22 21:11:45 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:11:45 - GraphTrainer - INFO - ============================================================
2025-11-22 21:11:45 - GraphTrainer - INFO - 开始第 26/1000 轮训练
2025-11-22 21:11:45 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3662, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3620, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3819, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3577, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3904, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3741, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3797, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3890, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3750, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3971, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3876, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3763, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4081, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3985, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3872, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3630, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3737, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3883, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3940, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3623, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3617, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3812, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3823, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3698, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3829, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3803, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3668, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4021, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3762, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3908, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3807, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3943, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3848, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3685, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3793, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3598, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3664, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3634, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3855, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4079, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3696, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3631, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3928, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3749, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3645, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3654, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3885, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3577, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3620, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3637, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3952, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3710, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3647, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3845, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3947, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3806, device='cuda:0', grad_fn=<AddBackward0>)
The 25 training average loss: 0.37773438517389624
2025-11-22 21:11:57 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:11:57 - GraphTrainer - INFO -   precision@5: 0.005030
2025-11-22 21:11:57 - GraphTrainer - INFO -   recall@5: 0.024006
2025-11-22 21:11:57 - GraphTrainer - INFO -   hit_rate@5: 0.025045
2025-11-22 21:11:57 - GraphTrainer - INFO -   ndcg@5: 0.015370
2025-11-22 21:11:57 - GraphTrainer - INFO -   map@5: 0.012364
2025-11-22 21:11:57 - GraphTrainer - INFO -   mrr@5: 0.012910
2025-11-22 21:11:57 - GraphTrainer - INFO -   precision@10: 0.004238
2025-11-22 21:11:57 - GraphTrainer - INFO -   recall@10: 0.040349
2025-11-22 21:11:57 - GraphTrainer - INFO -   hit_rate@10: 0.042222
2025-11-22 21:11:57 - GraphTrainer - INFO -   ndcg@10: 0.020671
2025-11-22 21:11:57 - GraphTrainer - INFO -   map@10: 0.014513
2025-11-22 21:11:57 - GraphTrainer - INFO -   mrr@10: 0.015163
2025-11-22 21:11:57 - GraphTrainer - INFO -   precision@20: 0.003523
2025-11-22 21:11:57 - GraphTrainer - INFO -   recall@20: 0.066865
2025-11-22 21:11:57 - GraphTrainer - INFO -   hit_rate@20: 0.070044
2025-11-22 21:11:57 - GraphTrainer - INFO -   ndcg@20: 0.027424
2025-11-22 21:11:57 - GraphTrainer - INFO -   map@20: 0.016332
2025-11-22 21:11:57 - GraphTrainer - INFO -   mrr@20: 0.017064
2025-11-22 21:11:57 - GraphTrainer - INFO - 第 26 轮训练完成
2025-11-22 21:11:57 - GraphTrainer - INFO - train_loss: 0.372754
2025-11-22 21:11:57 - GraphTrainer - INFO - precision@5: 0.005030
2025-11-22 21:11:57 - GraphTrainer - INFO - recall@5: 0.024006
2025-11-22 21:11:57 - GraphTrainer - INFO - hit_rate@5: 0.025045
2025-11-22 21:11:57 - GraphTrainer - INFO - ndcg@5: 0.015370
2025-11-22 21:11:57 - GraphTrainer - INFO - map@5: 0.012364
2025-11-22 21:11:57 - GraphTrainer - INFO - mrr@5: 0.012910
2025-11-22 21:11:57 - GraphTrainer - INFO - precision@10: 0.004238
2025-11-22 21:11:57 - GraphTrainer - INFO - recall@10: 0.040349
2025-11-22 21:11:57 - GraphTrainer - INFO - hit_rate@10: 0.042222
2025-11-22 21:11:57 - GraphTrainer - INFO - ndcg@10: 0.020671
2025-11-22 21:11:57 - GraphTrainer - INFO - map@10: 0.014513
2025-11-22 21:11:57 - GraphTrainer - INFO - mrr@10: 0.015163
2025-11-22 21:11:57 - GraphTrainer - INFO - precision@20: 0.003523
2025-11-22 21:11:57 - GraphTrainer - INFO - recall@20: 0.066865
2025-11-22 21:11:57 - GraphTrainer - INFO - hit_rate@20: 0.070044
2025-11-22 21:11:57 - GraphTrainer - INFO - ndcg@20: 0.027424
2025-11-22 21:11:57 - GraphTrainer - INFO - map@20: 0.016332
2025-11-22 21:11:57 - GraphTrainer - INFO - mrr@20: 0.017064
2025-11-22 21:11:57 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:11:57 - GraphTrainer - INFO - ============================================================
2025-11-22 21:11:57 - GraphTrainer - INFO - 开始第 27/1000 轮训练
2025-11-22 21:11:57 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3688, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3827, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3752, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3627, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3984, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3737, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3803, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3815, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3691, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3683, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3769, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3710, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3603, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3768, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3641, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3658, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3729, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3676, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3713, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3848, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3660, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3870, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3663, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4068, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3634, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3785, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3862, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3758, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3821, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3710, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3833, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3775, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3636, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3752, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3785, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3869, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3944, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3768, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3576, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3771, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3576, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3758, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3654, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3800, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3726, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3633, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3924, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3711, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3628, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3571, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4018, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3818, device='cuda:0', grad_fn=<AddBackward0>)
The 26 training average loss: 0.3727540759177044
2025-11-22 21:12:08 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:12:08 - GraphTrainer - INFO -   precision@5: 0.005040
2025-11-22 21:12:08 - GraphTrainer - INFO -   recall@5: 0.024033
2025-11-22 21:12:08 - GraphTrainer - INFO -   hit_rate@5: 0.025199
2025-11-22 21:12:08 - GraphTrainer - INFO -   ndcg@5: 0.015334
2025-11-22 21:12:08 - GraphTrainer - INFO -   map@5: 0.012303
2025-11-22 21:12:08 - GraphTrainer - INFO -   mrr@5: 0.012816
2025-11-22 21:12:08 - GraphTrainer - INFO -   precision@10: 0.004263
2025-11-22 21:12:08 - GraphTrainer - INFO -   recall@10: 0.040626
2025-11-22 21:12:08 - GraphTrainer - INFO -   hit_rate@10: 0.042479
2025-11-22 21:12:08 - GraphTrainer - INFO -   ndcg@10: 0.020730
2025-11-22 21:12:08 - GraphTrainer - INFO -   map@10: 0.014502
2025-11-22 21:12:08 - GraphTrainer - INFO -   mrr@10: 0.015100
2025-11-22 21:12:08 - GraphTrainer - INFO -   precision@20: 0.003410
2025-11-22 21:12:08 - GraphTrainer - INFO -   recall@20: 0.064606
2025-11-22 21:12:08 - GraphTrainer - INFO -   hit_rate@20: 0.067729
2025-11-22 21:12:08 - GraphTrainer - INFO -   ndcg@20: 0.026819
2025-11-22 21:12:08 - GraphTrainer - INFO -   map@20: 0.016129
2025-11-22 21:12:08 - GraphTrainer - INFO -   mrr@20: 0.016801
2025-11-22 21:12:08 - GraphTrainer - INFO - 第 27 轮训练完成
2025-11-22 21:12:08 - GraphTrainer - INFO - train_loss: 0.373910
2025-11-22 21:12:08 - GraphTrainer - INFO - precision@5: 0.005040
2025-11-22 21:12:08 - GraphTrainer - INFO - recall@5: 0.024033
2025-11-22 21:12:08 - GraphTrainer - INFO - hit_rate@5: 0.025199
2025-11-22 21:12:08 - GraphTrainer - INFO - ndcg@5: 0.015334
2025-11-22 21:12:08 - GraphTrainer - INFO - map@5: 0.012303
2025-11-22 21:12:08 - GraphTrainer - INFO - mrr@5: 0.012816
2025-11-22 21:12:08 - GraphTrainer - INFO - precision@10: 0.004263
2025-11-22 21:12:08 - GraphTrainer - INFO - recall@10: 0.040626
2025-11-22 21:12:08 - GraphTrainer - INFO - hit_rate@10: 0.042479
2025-11-22 21:12:08 - GraphTrainer - INFO - ndcg@10: 0.020730
2025-11-22 21:12:08 - GraphTrainer - INFO - map@10: 0.014502
2025-11-22 21:12:08 - GraphTrainer - INFO - mrr@10: 0.015100
2025-11-22 21:12:08 - GraphTrainer - INFO - precision@20: 0.003410
2025-11-22 21:12:08 - GraphTrainer - INFO - recall@20: 0.064606
2025-11-22 21:12:08 - GraphTrainer - INFO - hit_rate@20: 0.067729
2025-11-22 21:12:08 - GraphTrainer - INFO - ndcg@20: 0.026819
2025-11-22 21:12:08 - GraphTrainer - INFO - map@20: 0.016129
2025-11-22 21:12:08 - GraphTrainer - INFO - mrr@20: 0.016801
2025-11-22 21:12:08 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:12:08 - GraphTrainer - INFO - ============================================================
2025-11-22 21:12:08 - GraphTrainer - INFO - 开始第 28/1000 轮训练
2025-11-22 21:12:08 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3673, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3681, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3857, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4153, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3874, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3805, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3726, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3793, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3912, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3658, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3745, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3577, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3693, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3672, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3709, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3642, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3987, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3611, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3548, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3718, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3794, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3713, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3833, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3687, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3860, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3918, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3744, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3873, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3913, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3827, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3827, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3620, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3674, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3689, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3703, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3748, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3802, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3769, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3972, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3747, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3847, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4072, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3805, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3608, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3806, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3828, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3820, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3726, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3799, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3645, device='cuda:0', grad_fn=<AddBackward0>)
The 27 training average loss: 0.3739095340515005
2025-11-22 21:12:19 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:12:19 - GraphTrainer - INFO -   precision@5: 0.005431
2025-11-22 21:12:19 - GraphTrainer - INFO -   recall@5: 0.025973
2025-11-22 21:12:19 - GraphTrainer - INFO -   hit_rate@5: 0.027102
2025-11-22 21:12:19 - GraphTrainer - INFO -   ndcg@5: 0.016838
2025-11-22 21:12:19 - GraphTrainer - INFO -   map@5: 0.013648
2025-11-22 21:12:19 - GraphTrainer - INFO -   mrr@5: 0.014240
2025-11-22 21:12:19 - GraphTrainer - INFO -   precision@10: 0.004423
2025-11-22 21:12:19 - GraphTrainer - INFO -   recall@10: 0.042403
2025-11-22 21:12:19 - GraphTrainer - INFO -   hit_rate@10: 0.044176
2025-11-22 21:12:19 - GraphTrainer - INFO -   ndcg@10: 0.022155
2025-11-22 21:12:19 - GraphTrainer - INFO -   map@10: 0.015806
2025-11-22 21:12:19 - GraphTrainer - INFO -   mrr@10: 0.016482
2025-11-22 21:12:19 - GraphTrainer - INFO -   precision@20: 0.003587
2025-11-22 21:12:19 - GraphTrainer - INFO -   recall@20: 0.068376
2025-11-22 21:12:19 - GraphTrainer - INFO -   hit_rate@20: 0.071329
2025-11-22 21:12:19 - GraphTrainer - INFO -   ndcg@20: 0.028739
2025-11-22 21:12:19 - GraphTrainer - INFO -   map@20: 0.017566
2025-11-22 21:12:19 - GraphTrainer - INFO -   mrr@20: 0.018316
2025-11-22 21:12:19 - GraphTrainer - INFO - 第 28 轮训练完成
2025-11-22 21:12:19 - GraphTrainer - INFO - train_loss: 0.367288
2025-11-22 21:12:19 - GraphTrainer - INFO - precision@5: 0.005431
2025-11-22 21:12:19 - GraphTrainer - INFO - recall@5: 0.025973
2025-11-22 21:12:19 - GraphTrainer - INFO - hit_rate@5: 0.027102
2025-11-22 21:12:19 - GraphTrainer - INFO - ndcg@5: 0.016838
2025-11-22 21:12:19 - GraphTrainer - INFO - map@5: 0.013648
2025-11-22 21:12:19 - GraphTrainer - INFO - mrr@5: 0.014240
2025-11-22 21:12:19 - GraphTrainer - INFO - precision@10: 0.004423
2025-11-22 21:12:19 - GraphTrainer - INFO - recall@10: 0.042403
2025-11-22 21:12:19 - GraphTrainer - INFO - hit_rate@10: 0.044176
2025-11-22 21:12:19 - GraphTrainer - INFO - ndcg@10: 0.022155
2025-11-22 21:12:19 - GraphTrainer - INFO - map@10: 0.015806
2025-11-22 21:12:19 - GraphTrainer - INFO - mrr@10: 0.016482
2025-11-22 21:12:19 - GraphTrainer - INFO - precision@20: 0.003587
2025-11-22 21:12:19 - GraphTrainer - INFO - recall@20: 0.068376
2025-11-22 21:12:19 - GraphTrainer - INFO - hit_rate@20: 0.071329
2025-11-22 21:12:19 - GraphTrainer - INFO - ndcg@20: 0.028739
2025-11-22 21:12:19 - GraphTrainer - INFO - map@20: 0.017566
2025-11-22 21:12:19 - GraphTrainer - INFO - mrr@20: 0.018316
2025-11-22 21:12:19 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:12:19 - GraphTrainer - INFO - ============================================================
2025-11-22 21:12:19 - GraphTrainer - INFO - 开始第 29/1000 轮训练
2025-11-22 21:12:19 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3848, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3701, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3740, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3733, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3632, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3822, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3691, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3749, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3533, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3628, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3841, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3549, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3662, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3433, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3653, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3899, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3642, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3601, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3861, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3773, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3913, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3562, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3713, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3619, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3806, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3780, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3525, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3744, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3556, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3714, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3976, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3747, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3913, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3829, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3507, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3791, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3798, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3709, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3667, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3652, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3824, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3563, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3670, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3812, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3758, device='cuda:0', grad_fn=<AddBackward0>)
The 28 training average loss: 0.36728794307544316
2025-11-22 21:12:31 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:12:31 - GraphTrainer - INFO -   precision@5: 0.005492
2025-11-22 21:12:31 - GraphTrainer - INFO -   recall@5: 0.026313
2025-11-22 21:12:31 - GraphTrainer - INFO -   hit_rate@5: 0.027359
2025-11-22 21:12:31 - GraphTrainer - INFO -   ndcg@5: 0.016944
2025-11-22 21:12:31 - GraphTrainer - INFO -   map@5: 0.013709
2025-11-22 21:12:31 - GraphTrainer - INFO -   mrr@5: 0.014171
2025-11-22 21:12:31 - GraphTrainer - INFO -   precision@10: 0.004567
2025-11-22 21:12:31 - GraphTrainer - INFO -   recall@10: 0.043721
2025-11-22 21:12:31 - GraphTrainer - INFO -   hit_rate@10: 0.045513
2025-11-22 21:12:31 - GraphTrainer - INFO -   ndcg@10: 0.022527
2025-11-22 21:12:31 - GraphTrainer - INFO -   map@10: 0.015939
2025-11-22 21:12:31 - GraphTrainer - INFO -   mrr@10: 0.016501
2025-11-22 21:12:31 - GraphTrainer - INFO -   precision@20: 0.003577
2025-11-22 21:12:31 - GraphTrainer - INFO -   recall@20: 0.067909
2025-11-22 21:12:31 - GraphTrainer - INFO -   hit_rate@20: 0.071072
2025-11-22 21:12:31 - GraphTrainer - INFO -   ndcg@20: 0.028680
2025-11-22 21:12:31 - GraphTrainer - INFO -   map@20: 0.017584
2025-11-22 21:12:31 - GraphTrainer - INFO -   mrr@20: 0.018238
2025-11-22 21:12:31 - GraphTrainer - INFO - 第 29 轮训练完成
2025-11-22 21:12:31 - GraphTrainer - INFO - train_loss: 0.365800
2025-11-22 21:12:31 - GraphTrainer - INFO - precision@5: 0.005492
2025-11-22 21:12:31 - GraphTrainer - INFO - recall@5: 0.026313
2025-11-22 21:12:31 - GraphTrainer - INFO - hit_rate@5: 0.027359
2025-11-22 21:12:31 - GraphTrainer - INFO - ndcg@5: 0.016944
2025-11-22 21:12:31 - GraphTrainer - INFO - map@5: 0.013709
2025-11-22 21:12:31 - GraphTrainer - INFO - mrr@5: 0.014171
2025-11-22 21:12:31 - GraphTrainer - INFO - precision@10: 0.004567
2025-11-22 21:12:31 - GraphTrainer - INFO - recall@10: 0.043721
2025-11-22 21:12:31 - GraphTrainer - INFO - hit_rate@10: 0.045513
2025-11-22 21:12:31 - GraphTrainer - INFO - ndcg@10: 0.022527
2025-11-22 21:12:31 - GraphTrainer - INFO - map@10: 0.015939
2025-11-22 21:12:31 - GraphTrainer - INFO - mrr@10: 0.016501
2025-11-22 21:12:31 - GraphTrainer - INFO - precision@20: 0.003577
2025-11-22 21:12:31 - GraphTrainer - INFO - recall@20: 0.067909
2025-11-22 21:12:31 - GraphTrainer - INFO - hit_rate@20: 0.071072
2025-11-22 21:12:31 - GraphTrainer - INFO - ndcg@20: 0.028680
2025-11-22 21:12:31 - GraphTrainer - INFO - map@20: 0.017584
2025-11-22 21:12:31 - GraphTrainer - INFO - mrr@20: 0.018238
2025-11-22 21:12:31 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:12:31 - GraphTrainer - INFO - ============================================================
2025-11-22 21:12:31 - GraphTrainer - INFO - 开始第 30/1000 轮训练
2025-11-22 21:12:31 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3743, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3644, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3623, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3807, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3707, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3697, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3616, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3509, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3635, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3732, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3664, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3853, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3677, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3656, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3655, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3726, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3837, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3626, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3812, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3622, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3828, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3433, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3654, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3699, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3682, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3645, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3707, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3807, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3227, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3748, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3816, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3845, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3762, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3845, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3874, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3615, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3682, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3809, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3992, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3672, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3573, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3636, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3543, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3718, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3728, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3670, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3602, device='cuda:0', grad_fn=<AddBackward0>)
The 29 training average loss: 0.36580037402695625
2025-11-22 21:12:42 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:12:42 - GraphTrainer - INFO -   precision@5: 0.005091
2025-11-22 21:12:42 - GraphTrainer - INFO -   recall@5: 0.024135
2025-11-22 21:12:42 - GraphTrainer - INFO -   hit_rate@5: 0.025405
2025-11-22 21:12:42 - GraphTrainer - INFO -   ndcg@5: 0.015637
2025-11-22 21:12:42 - GraphTrainer - INFO -   map@5: 0.012644
2025-11-22 21:12:42 - GraphTrainer - INFO -   mrr@5: 0.013265
2025-11-22 21:12:42 - GraphTrainer - INFO -   precision@10: 0.004361
2025-11-22 21:12:42 - GraphTrainer - INFO -   recall@10: 0.041536
2025-11-22 21:12:42 - GraphTrainer - INFO -   hit_rate@10: 0.043507
2025-11-22 21:12:42 - GraphTrainer - INFO -   ndcg@10: 0.021267
2025-11-22 21:12:42 - GraphTrainer - INFO -   map@10: 0.014933
2025-11-22 21:12:42 - GraphTrainer - INFO -   mrr@10: 0.015637
2025-11-22 21:12:42 - GraphTrainer - INFO -   precision@20: 0.003572
2025-11-22 21:12:42 - GraphTrainer - INFO -   recall@20: 0.067932
2025-11-22 21:12:42 - GraphTrainer - INFO -   hit_rate@20: 0.071227
2025-11-22 21:12:42 - GraphTrainer - INFO -   ndcg@20: 0.027968
2025-11-22 21:12:42 - GraphTrainer - INFO -   map@20: 0.016729
2025-11-22 21:12:42 - GraphTrainer - INFO -   mrr@20: 0.017524
2025-11-22 21:12:42 - GraphTrainer - INFO - 第 30 轮训练完成
2025-11-22 21:12:42 - GraphTrainer - INFO - train_loss: 0.363938
2025-11-22 21:12:42 - GraphTrainer - INFO - precision@5: 0.005091
2025-11-22 21:12:42 - GraphTrainer - INFO - recall@5: 0.024135
2025-11-22 21:12:42 - GraphTrainer - INFO - hit_rate@5: 0.025405
2025-11-22 21:12:42 - GraphTrainer - INFO - ndcg@5: 0.015637
2025-11-22 21:12:42 - GraphTrainer - INFO - map@5: 0.012644
2025-11-22 21:12:42 - GraphTrainer - INFO - mrr@5: 0.013265
2025-11-22 21:12:42 - GraphTrainer - INFO - precision@10: 0.004361
2025-11-22 21:12:42 - GraphTrainer - INFO - recall@10: 0.041536
2025-11-22 21:12:42 - GraphTrainer - INFO - hit_rate@10: 0.043507
2025-11-22 21:12:42 - GraphTrainer - INFO - ndcg@10: 0.021267
2025-11-22 21:12:42 - GraphTrainer - INFO - map@10: 0.014933
2025-11-22 21:12:42 - GraphTrainer - INFO - mrr@10: 0.015637
2025-11-22 21:12:42 - GraphTrainer - INFO - precision@20: 0.003572
2025-11-22 21:12:42 - GraphTrainer - INFO - recall@20: 0.067932
2025-11-22 21:12:42 - GraphTrainer - INFO - hit_rate@20: 0.071227
2025-11-22 21:12:42 - GraphTrainer - INFO - ndcg@20: 0.027968
2025-11-22 21:12:42 - GraphTrainer - INFO - map@20: 0.016729
2025-11-22 21:12:42 - GraphTrainer - INFO - mrr@20: 0.017524
2025-11-22 21:12:42 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:12:42 - GraphTrainer - INFO - 检查点已保存: Epoch 30 -> ./checkpoints/checkpoint_epoch_30.pth
2025-11-22 21:12:42 - GraphTrainer - INFO - ============================================================
2025-11-22 21:12:42 - GraphTrainer - INFO - 开始第 31/1000 轮训练
2025-11-22 21:12:42 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3565, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3632, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3646, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3669, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3749, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3692, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3976, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3543, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3703, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3750, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3816, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3557, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3769, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3628, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3571, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3670, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3795, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3627, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3565, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3791, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3681, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3532, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3731, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3638, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3894, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3829, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3791, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3739, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3573, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3434, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3730, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3550, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3647, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3631, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3617, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3822, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3663, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3664, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3681, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3718, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3728, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3739, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3612, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3845, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)
The 30 training average loss: 0.3639377946483678
2025-11-22 21:12:53 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:12:53 - GraphTrainer - INFO -   precision@5: 0.005225
2025-11-22 21:12:53 - GraphTrainer - INFO -   recall@5: 0.025082
2025-11-22 21:12:53 - GraphTrainer - INFO -   hit_rate@5: 0.026074
2025-11-22 21:12:53 - GraphTrainer - INFO -   ndcg@5: 0.015918
2025-11-22 21:12:53 - GraphTrainer - INFO -   map@5: 0.012740
2025-11-22 21:12:53 - GraphTrainer - INFO -   mrr@5: 0.013256
2025-11-22 21:12:53 - GraphTrainer - INFO -   precision@10: 0.004227
2025-11-22 21:12:53 - GraphTrainer - INFO -   recall@10: 0.040697
2025-11-22 21:12:53 - GraphTrainer - INFO -   hit_rate@10: 0.042119
2025-11-22 21:12:53 - GraphTrainer - INFO -   ndcg@10: 0.020932
2025-11-22 21:12:53 - GraphTrainer - INFO -   map@10: 0.014762
2025-11-22 21:12:53 - GraphTrainer - INFO -   mrr@10: 0.015334
2025-11-22 21:12:53 - GraphTrainer - INFO -   precision@20: 0.003556
2025-11-22 21:12:53 - GraphTrainer - INFO -   recall@20: 0.067917
2025-11-22 21:12:53 - GraphTrainer - INFO -   hit_rate@20: 0.070609
2025-11-22 21:12:53 - GraphTrainer - INFO -   ndcg@20: 0.027859
2025-11-22 21:12:53 - GraphTrainer - INFO -   map@20: 0.016629
2025-11-22 21:12:53 - GraphTrainer - INFO -   mrr@20: 0.017279
2025-11-22 21:12:53 - GraphTrainer - INFO - 第 31 轮训练完成
2025-11-22 21:12:53 - GraphTrainer - INFO - train_loss: 0.359966
2025-11-22 21:12:53 - GraphTrainer - INFO - precision@5: 0.005225
2025-11-22 21:12:53 - GraphTrainer - INFO - recall@5: 0.025082
2025-11-22 21:12:53 - GraphTrainer - INFO - hit_rate@5: 0.026074
2025-11-22 21:12:53 - GraphTrainer - INFO - ndcg@5: 0.015918
2025-11-22 21:12:53 - GraphTrainer - INFO - map@5: 0.012740
2025-11-22 21:12:53 - GraphTrainer - INFO - mrr@5: 0.013256
2025-11-22 21:12:53 - GraphTrainer - INFO - precision@10: 0.004227
2025-11-22 21:12:53 - GraphTrainer - INFO - recall@10: 0.040697
2025-11-22 21:12:53 - GraphTrainer - INFO - hit_rate@10: 0.042119
2025-11-22 21:12:53 - GraphTrainer - INFO - ndcg@10: 0.020932
2025-11-22 21:12:53 - GraphTrainer - INFO - map@10: 0.014762
2025-11-22 21:12:53 - GraphTrainer - INFO - mrr@10: 0.015334
2025-11-22 21:12:53 - GraphTrainer - INFO - precision@20: 0.003556
2025-11-22 21:12:53 - GraphTrainer - INFO - recall@20: 0.067917
2025-11-22 21:12:53 - GraphTrainer - INFO - hit_rate@20: 0.070609
2025-11-22 21:12:53 - GraphTrainer - INFO - ndcg@20: 0.027859
2025-11-22 21:12:53 - GraphTrainer - INFO - map@20: 0.016629
2025-11-22 21:12:53 - GraphTrainer - INFO - mrr@20: 0.017279
2025-11-22 21:12:53 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:12:53 - GraphTrainer - INFO - ============================================================
2025-11-22 21:12:53 - GraphTrainer - INFO - 开始第 32/1000 轮训练
2025-11-22 21:12:53 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3767, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3655, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3494, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3856, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3549, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3762, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3492, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3644, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3633, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3632, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3653, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3531, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3434, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3962, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3644, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3817, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3652, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3409, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3665, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3695, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3665, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3866, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3676, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3721, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3550, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3659, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3653, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3743, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3775, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3685, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3787, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3644, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3679, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3626, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3610, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3667, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3801, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3663, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>)
The 31 training average loss: 0.3599663546373104
2025-11-22 21:13:04 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:13:04 - GraphTrainer - INFO -   precision@5: 0.005523
2025-11-22 21:13:04 - GraphTrainer - INFO -   recall@5: 0.026319
2025-11-22 21:13:04 - GraphTrainer - INFO -   hit_rate@5: 0.027565
2025-11-22 21:13:04 - GraphTrainer - INFO -   ndcg@5: 0.016916
2025-11-22 21:13:04 - GraphTrainer - INFO -   map@5: 0.013634
2025-11-22 21:13:04 - GraphTrainer - INFO -   mrr@5: 0.014272
2025-11-22 21:13:04 - GraphTrainer - INFO -   precision@10: 0.004654
2025-11-22 21:13:04 - GraphTrainer - INFO -   recall@10: 0.044259
2025-11-22 21:13:04 - GraphTrainer - INFO -   hit_rate@10: 0.046490
2025-11-22 21:13:04 - GraphTrainer - INFO -   ndcg@10: 0.022766
2025-11-22 21:13:04 - GraphTrainer - INFO -   map@10: 0.016021
2025-11-22 21:13:04 - GraphTrainer - INFO -   mrr@10: 0.016785
2025-11-22 21:13:04 - GraphTrainer - INFO -   precision@20: 0.003749
2025-11-22 21:13:04 - GraphTrainer - INFO -   recall@20: 0.071129
2025-11-22 21:13:04 - GraphTrainer - INFO -   hit_rate@20: 0.074672
2025-11-22 21:13:04 - GraphTrainer - INFO -   ndcg@20: 0.029588
2025-11-22 21:13:04 - GraphTrainer - INFO -   map@20: 0.017850
2025-11-22 21:13:04 - GraphTrainer - INFO -   mrr@20: 0.018694
2025-11-22 21:13:04 - GraphTrainer - INFO - 第 32 轮训练完成
2025-11-22 21:13:04 - GraphTrainer - INFO - train_loss: 0.358144
2025-11-22 21:13:04 - GraphTrainer - INFO - precision@5: 0.005523
2025-11-22 21:13:04 - GraphTrainer - INFO - recall@5: 0.026319
2025-11-22 21:13:04 - GraphTrainer - INFO - hit_rate@5: 0.027565
2025-11-22 21:13:04 - GraphTrainer - INFO - ndcg@5: 0.016916
2025-11-22 21:13:04 - GraphTrainer - INFO - map@5: 0.013634
2025-11-22 21:13:04 - GraphTrainer - INFO - mrr@5: 0.014272
2025-11-22 21:13:04 - GraphTrainer - INFO - precision@10: 0.004654
2025-11-22 21:13:04 - GraphTrainer - INFO - recall@10: 0.044259
2025-11-22 21:13:04 - GraphTrainer - INFO - hit_rate@10: 0.046490
2025-11-22 21:13:04 - GraphTrainer - INFO - ndcg@10: 0.022766
2025-11-22 21:13:04 - GraphTrainer - INFO - map@10: 0.016021
2025-11-22 21:13:04 - GraphTrainer - INFO - mrr@10: 0.016785
2025-11-22 21:13:04 - GraphTrainer - INFO - precision@20: 0.003749
2025-11-22 21:13:04 - GraphTrainer - INFO - recall@20: 0.071129
2025-11-22 21:13:04 - GraphTrainer - INFO - hit_rate@20: 0.074672
2025-11-22 21:13:04 - GraphTrainer - INFO - ndcg@20: 0.029588
2025-11-22 21:13:04 - GraphTrainer - INFO - map@20: 0.017850
2025-11-22 21:13:04 - GraphTrainer - INFO - mrr@20: 0.018694
2025-11-22 21:13:04 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:13:04 - GraphTrainer - INFO - ============================================================
2025-11-22 21:13:04 - GraphTrainer - INFO - 开始第 33/1000 轮训练
2025-11-22 21:13:04 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3597, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3656, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3602, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3627, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3685, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3577, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3518, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3725, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3769, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3626, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3588, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3466, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3758, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3896, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3682, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3574, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3632, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3510, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3908, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3595, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3676, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3793, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3859, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3624, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3563, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3643, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3787, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3657, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3536, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3677, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3821, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3615, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3537, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
The 32 training average loss: 0.3581444461797846
2025-11-22 21:13:15 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:13:15 - GraphTrainer - INFO -   precision@5: 0.005246
2025-11-22 21:13:15 - GraphTrainer - INFO -   recall@5: 0.025097
2025-11-22 21:13:15 - GraphTrainer - INFO -   hit_rate@5: 0.026228
2025-11-22 21:13:15 - GraphTrainer - INFO -   ndcg@5: 0.016101
2025-11-22 21:13:15 - GraphTrainer - INFO -   map@5: 0.012986
2025-11-22 21:13:15 - GraphTrainer - INFO -   mrr@5: 0.013506
2025-11-22 21:13:15 - GraphTrainer - INFO -   precision@10: 0.004582
2025-11-22 21:13:15 - GraphTrainer - INFO -   recall@10: 0.043805
2025-11-22 21:13:15 - GraphTrainer - INFO -   hit_rate@10: 0.045719
2025-11-22 21:13:15 - GraphTrainer - INFO -   ndcg@10: 0.022215
2025-11-22 21:13:15 - GraphTrainer - INFO -   map@10: 0.015494
2025-11-22 21:13:15 - GraphTrainer - INFO -   mrr@10: 0.016116
2025-11-22 21:13:15 - GraphTrainer - INFO -   precision@20: 0.003641
2025-11-22 21:13:15 - GraphTrainer - INFO -   recall@20: 0.069281
2025-11-22 21:13:15 - GraphTrainer - INFO -   hit_rate@20: 0.072358
2025-11-22 21:13:15 - GraphTrainer - INFO -   ndcg@20: 0.028680
2025-11-22 21:13:15 - GraphTrainer - INFO -   map@20: 0.017227
2025-11-22 21:13:15 - GraphTrainer - INFO -   mrr@20: 0.017917
2025-11-22 21:13:15 - GraphTrainer - INFO - 第 33 轮训练完成
2025-11-22 21:13:15 - GraphTrainer - INFO - train_loss: 0.357595
2025-11-22 21:13:15 - GraphTrainer - INFO - precision@5: 0.005246
2025-11-22 21:13:15 - GraphTrainer - INFO - recall@5: 0.025097
2025-11-22 21:13:15 - GraphTrainer - INFO - hit_rate@5: 0.026228
2025-11-22 21:13:15 - GraphTrainer - INFO - ndcg@5: 0.016101
2025-11-22 21:13:15 - GraphTrainer - INFO - map@5: 0.012986
2025-11-22 21:13:15 - GraphTrainer - INFO - mrr@5: 0.013506
2025-11-22 21:13:15 - GraphTrainer - INFO - precision@10: 0.004582
2025-11-22 21:13:15 - GraphTrainer - INFO - recall@10: 0.043805
2025-11-22 21:13:15 - GraphTrainer - INFO - hit_rate@10: 0.045719
2025-11-22 21:13:15 - GraphTrainer - INFO - ndcg@10: 0.022215
2025-11-22 21:13:15 - GraphTrainer - INFO - map@10: 0.015494
2025-11-22 21:13:15 - GraphTrainer - INFO - mrr@10: 0.016116
2025-11-22 21:13:15 - GraphTrainer - INFO - precision@20: 0.003641
2025-11-22 21:13:15 - GraphTrainer - INFO - recall@20: 0.069281
2025-11-22 21:13:15 - GraphTrainer - INFO - hit_rate@20: 0.072358
2025-11-22 21:13:15 - GraphTrainer - INFO - ndcg@20: 0.028680
2025-11-22 21:13:15 - GraphTrainer - INFO - map@20: 0.017227
2025-11-22 21:13:15 - GraphTrainer - INFO - mrr@20: 0.017917
2025-11-22 21:13:15 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:13:15 - GraphTrainer - INFO - ============================================================
2025-11-22 21:13:15 - GraphTrainer - INFO - 开始第 34/1000 轮训练
2025-11-22 21:13:15 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3643, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3433, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3923, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3303, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3863, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3644, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3550, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3558, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3801, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3712, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3712, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3502, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3467, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3584, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3668, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3627, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3687, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3768, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3582, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3713, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3632, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3604, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3655, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3677, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3638, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3586, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3664, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3590, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3568, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3626, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3765, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3599, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3662, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3616, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3586, device='cuda:0', grad_fn=<AddBackward0>)
The 33 training average loss: 0.3575948019479883
2025-11-22 21:13:26 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:13:26 - GraphTrainer - INFO -   precision@5: 0.005369
2025-11-22 21:13:26 - GraphTrainer - INFO -   recall@5: 0.025612
2025-11-22 21:13:26 - GraphTrainer - INFO -   hit_rate@5: 0.026794
2025-11-22 21:13:26 - GraphTrainer - INFO -   ndcg@5: 0.016722
2025-11-22 21:13:26 - GraphTrainer - INFO -   map@5: 0.013600
2025-11-22 21:13:26 - GraphTrainer - INFO -   mrr@5: 0.014178
2025-11-22 21:13:26 - GraphTrainer - INFO -   precision@10: 0.004551
2025-11-22 21:13:26 - GraphTrainer - INFO -   recall@10: 0.043152
2025-11-22 21:13:26 - GraphTrainer - INFO -   hit_rate@10: 0.045410
2025-11-22 21:13:26 - GraphTrainer - INFO -   ndcg@10: 0.022418
2025-11-22 21:13:26 - GraphTrainer - INFO -   map@10: 0.015900
2025-11-22 21:13:26 - GraphTrainer - INFO -   mrr@10: 0.016625
2025-11-22 21:13:26 - GraphTrainer - INFO -   precision@20: 0.003659
2025-11-22 21:13:26 - GraphTrainer - INFO -   recall@20: 0.069201
2025-11-22 21:13:26 - GraphTrainer - INFO -   hit_rate@20: 0.072718
2025-11-22 21:13:26 - GraphTrainer - INFO -   ndcg@20: 0.029043
2025-11-22 21:13:26 - GraphTrainer - INFO -   map@20: 0.017681
2025-11-22 21:13:26 - GraphTrainer - INFO -   mrr@20: 0.018483
2025-11-22 21:13:26 - GraphTrainer - INFO - 第 34 轮训练完成
2025-11-22 21:13:26 - GraphTrainer - INFO - train_loss: 0.353703
2025-11-22 21:13:26 - GraphTrainer - INFO - precision@5: 0.005369
2025-11-22 21:13:26 - GraphTrainer - INFO - recall@5: 0.025612
2025-11-22 21:13:26 - GraphTrainer - INFO - hit_rate@5: 0.026794
2025-11-22 21:13:26 - GraphTrainer - INFO - ndcg@5: 0.016722
2025-11-22 21:13:26 - GraphTrainer - INFO - map@5: 0.013600
2025-11-22 21:13:26 - GraphTrainer - INFO - mrr@5: 0.014178
2025-11-22 21:13:26 - GraphTrainer - INFO - precision@10: 0.004551
2025-11-22 21:13:26 - GraphTrainer - INFO - recall@10: 0.043152
2025-11-22 21:13:26 - GraphTrainer - INFO - hit_rate@10: 0.045410
2025-11-22 21:13:26 - GraphTrainer - INFO - ndcg@10: 0.022418
2025-11-22 21:13:26 - GraphTrainer - INFO - map@10: 0.015900
2025-11-22 21:13:26 - GraphTrainer - INFO - mrr@10: 0.016625
2025-11-22 21:13:26 - GraphTrainer - INFO - precision@20: 0.003659
2025-11-22 21:13:26 - GraphTrainer - INFO - recall@20: 0.069201
2025-11-22 21:13:26 - GraphTrainer - INFO - hit_rate@20: 0.072718
2025-11-22 21:13:26 - GraphTrainer - INFO - ndcg@20: 0.029043
2025-11-22 21:13:26 - GraphTrainer - INFO - map@20: 0.017681
2025-11-22 21:13:26 - GraphTrainer - INFO - mrr@20: 0.018483
2025-11-22 21:13:26 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:13:26 - GraphTrainer - INFO - ============================================================
2025-11-22 21:13:26 - GraphTrainer - INFO - 开始第 35/1000 轮训练
2025-11-22 21:13:26 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3568, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3544, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3534, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3421, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3632, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3702, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3732, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3539, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3532, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3467, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3670, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3701, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3659, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3768, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3615, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3457, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3704, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3571, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3562, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3543, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3480, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3584, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3521, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3685, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3737, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3643, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3841, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3774, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3735, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3516, device='cuda:0', grad_fn=<AddBackward0>)
The 34 training average loss: 0.35370333544139204
2025-11-22 21:13:38 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:13:38 - GraphTrainer - INFO -   precision@5: 0.005750
2025-11-22 21:13:38 - GraphTrainer - INFO -   recall@5: 0.027490
2025-11-22 21:13:38 - GraphTrainer - INFO -   hit_rate@5: 0.028696
2025-11-22 21:13:38 - GraphTrainer - INFO -   ndcg@5: 0.018136
2025-11-22 21:13:38 - GraphTrainer - INFO -   map@5: 0.014861
2025-11-22 21:13:38 - GraphTrainer - INFO -   mrr@5: 0.015418
2025-11-22 21:13:38 - GraphTrainer - INFO -   precision@10: 0.004587
2025-11-22 21:13:38 - GraphTrainer - INFO -   recall@10: 0.043674
2025-11-22 21:13:38 - GraphTrainer - INFO -   hit_rate@10: 0.045822
2025-11-22 21:13:38 - GraphTrainer - INFO -   ndcg@10: 0.023386
2025-11-22 21:13:38 - GraphTrainer - INFO -   map@10: 0.016983
2025-11-22 21:13:38 - GraphTrainer - INFO -   mrr@10: 0.017659
2025-11-22 21:13:38 - GraphTrainer - INFO -   precision@20: 0.003677
2025-11-22 21:13:38 - GraphTrainer - INFO -   recall@20: 0.069898
2025-11-22 21:13:38 - GraphTrainer - INFO -   hit_rate@20: 0.073181
2025-11-22 21:13:38 - GraphTrainer - INFO -   ndcg@20: 0.030042
2025-11-22 21:13:38 - GraphTrainer - INFO -   map@20: 0.018770
2025-11-22 21:13:38 - GraphTrainer - INFO -   mrr@20: 0.019518
2025-11-22 21:13:38 - GraphTrainer - INFO - 第 35 轮训练完成
2025-11-22 21:13:38 - GraphTrainer - INFO - train_loss: 0.353347
2025-11-22 21:13:38 - GraphTrainer - INFO - precision@5: 0.005750
2025-11-22 21:13:38 - GraphTrainer - INFO - recall@5: 0.027490
2025-11-22 21:13:38 - GraphTrainer - INFO - hit_rate@5: 0.028696
2025-11-22 21:13:38 - GraphTrainer - INFO - ndcg@5: 0.018136
2025-11-22 21:13:38 - GraphTrainer - INFO - map@5: 0.014861
2025-11-22 21:13:38 - GraphTrainer - INFO - mrr@5: 0.015418
2025-11-22 21:13:38 - GraphTrainer - INFO - precision@10: 0.004587
2025-11-22 21:13:38 - GraphTrainer - INFO - recall@10: 0.043674
2025-11-22 21:13:38 - GraphTrainer - INFO - hit_rate@10: 0.045822
2025-11-22 21:13:38 - GraphTrainer - INFO - ndcg@10: 0.023386
2025-11-22 21:13:38 - GraphTrainer - INFO - map@10: 0.016983
2025-11-22 21:13:38 - GraphTrainer - INFO - mrr@10: 0.017659
2025-11-22 21:13:38 - GraphTrainer - INFO - precision@20: 0.003677
2025-11-22 21:13:38 - GraphTrainer - INFO - recall@20: 0.069898
2025-11-22 21:13:38 - GraphTrainer - INFO - hit_rate@20: 0.073181
2025-11-22 21:13:38 - GraphTrainer - INFO - ndcg@20: 0.030042
2025-11-22 21:13:38 - GraphTrainer - INFO - map@20: 0.018770
2025-11-22 21:13:38 - GraphTrainer - INFO - mrr@20: 0.019518
2025-11-22 21:13:38 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:13:38 - GraphTrainer - INFO - ============================================================
2025-11-22 21:13:38 - GraphTrainer - INFO - 开始第 36/1000 轮训练
2025-11-22 21:13:38 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3614, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3611, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3484, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3115, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3666, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3484, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3562, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3605, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3625, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3749, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3796, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3667, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3713, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3299, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3557, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3547, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3550, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3670, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3577, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3512, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3712, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3687, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3555, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3614, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3484, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3738, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3621, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3533, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3660, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3747, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3904, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3622, device='cuda:0', grad_fn=<AddBackward0>)
The 35 training average loss: 0.35334659958707876
2025-11-22 21:13:49 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:13:49 - GraphTrainer - INFO -   precision@5: 0.005667
2025-11-22 21:13:49 - GraphTrainer - INFO -   recall@5: 0.027469
2025-11-22 21:13:49 - GraphTrainer - INFO -   hit_rate@5: 0.028336
2025-11-22 21:13:49 - GraphTrainer - INFO -   ndcg@5: 0.017908
2025-11-22 21:13:49 - GraphTrainer - INFO -   map@5: 0.014637
2025-11-22 21:13:49 - GraphTrainer - INFO -   mrr@5: 0.015013
2025-11-22 21:13:49 - GraphTrainer - INFO -   precision@10: 0.004587
2025-11-22 21:13:49 - GraphTrainer - INFO -   recall@10: 0.043874
2025-11-22 21:13:49 - GraphTrainer - INFO -   hit_rate@10: 0.045822
2025-11-22 21:13:49 - GraphTrainer - INFO -   ndcg@10: 0.023245
2025-11-22 21:13:49 - GraphTrainer - INFO -   map@10: 0.016786
2025-11-22 21:13:49 - GraphTrainer - INFO -   mrr@10: 0.017306
2025-11-22 21:13:49 - GraphTrainer - INFO -   precision@20: 0.003721
2025-11-22 21:13:49 - GraphTrainer - INFO -   recall@20: 0.070619
2025-11-22 21:13:49 - GraphTrainer - INFO -   hit_rate@20: 0.074158
2025-11-22 21:13:49 - GraphTrainer - INFO -   ndcg@20: 0.030052
2025-11-22 21:13:49 - GraphTrainer - INFO -   map@20: 0.018607
2025-11-22 21:13:49 - GraphTrainer - INFO -   mrr@20: 0.019232
2025-11-22 21:13:49 - GraphTrainer - INFO - 第 36 轮训练完成
2025-11-22 21:13:49 - GraphTrainer - INFO - train_loss: 0.352795
2025-11-22 21:13:49 - GraphTrainer - INFO - precision@5: 0.005667
2025-11-22 21:13:49 - GraphTrainer - INFO - recall@5: 0.027469
2025-11-22 21:13:49 - GraphTrainer - INFO - hit_rate@5: 0.028336
2025-11-22 21:13:49 - GraphTrainer - INFO - ndcg@5: 0.017908
2025-11-22 21:13:49 - GraphTrainer - INFO - map@5: 0.014637
2025-11-22 21:13:49 - GraphTrainer - INFO - mrr@5: 0.015013
2025-11-22 21:13:49 - GraphTrainer - INFO - precision@10: 0.004587
2025-11-22 21:13:49 - GraphTrainer - INFO - recall@10: 0.043874
2025-11-22 21:13:49 - GraphTrainer - INFO - hit_rate@10: 0.045822
2025-11-22 21:13:49 - GraphTrainer - INFO - ndcg@10: 0.023245
2025-11-22 21:13:49 - GraphTrainer - INFO - map@10: 0.016786
2025-11-22 21:13:49 - GraphTrainer - INFO - mrr@10: 0.017306
2025-11-22 21:13:49 - GraphTrainer - INFO - precision@20: 0.003721
2025-11-22 21:13:49 - GraphTrainer - INFO - recall@20: 0.070619
2025-11-22 21:13:49 - GraphTrainer - INFO - hit_rate@20: 0.074158
2025-11-22 21:13:49 - GraphTrainer - INFO - ndcg@20: 0.030052
2025-11-22 21:13:49 - GraphTrainer - INFO - map@20: 0.018607
2025-11-22 21:13:49 - GraphTrainer - INFO - mrr@20: 0.019232
2025-11-22 21:13:49 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:13:49 - GraphTrainer - INFO - ============================================================
2025-11-22 21:13:49 - GraphTrainer - INFO - 开始第 37/1000 轮训练
2025-11-22 21:13:49 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3779, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3571, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3556, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3549, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3342, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3710, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3547, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3490, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3696, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3556, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3518, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3499, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3832, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3490, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3464, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3615, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3870, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3633, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3682, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3559, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3559, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3572, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3591, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3435, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3880, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3664, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3568, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3559, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3657, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3709, device='cuda:0', grad_fn=<AddBackward0>)
The 36 training average loss: 0.35279500278933296
2025-11-22 21:14:00 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:14:00 - GraphTrainer - INFO -   precision@5: 0.005935
2025-11-22 21:14:00 - GraphTrainer - INFO -   recall@5: 0.028407
2025-11-22 21:14:00 - GraphTrainer - INFO -   hit_rate@5: 0.029622
2025-11-22 21:14:00 - GraphTrainer - INFO -   ndcg@5: 0.018518
2025-11-22 21:14:00 - GraphTrainer - INFO -   map@5: 0.015064
2025-11-22 21:14:00 - GraphTrainer - INFO -   mrr@5: 0.015666
2025-11-22 21:14:00 - GraphTrainer - INFO -   precision@10: 0.004711
2025-11-22 21:14:00 - GraphTrainer - INFO -   recall@10: 0.044703
2025-11-22 21:14:00 - GraphTrainer - INFO -   hit_rate@10: 0.046953
2025-11-22 21:14:00 - GraphTrainer - INFO -   ndcg@10: 0.023812
2025-11-22 21:14:00 - GraphTrainer - INFO -   map@10: 0.017200
2025-11-22 21:14:00 - GraphTrainer - INFO -   mrr@10: 0.017939
2025-11-22 21:14:00 - GraphTrainer - INFO -   precision@20: 0.003764
2025-11-22 21:14:00 - GraphTrainer - INFO -   recall@20: 0.071362
2025-11-22 21:14:00 - GraphTrainer - INFO -   hit_rate@20: 0.074929
2025-11-22 21:14:00 - GraphTrainer - INFO -   ndcg@20: 0.030591
2025-11-22 21:14:00 - GraphTrainer - INFO -   map@20: 0.019024
2025-11-22 21:14:00 - GraphTrainer - INFO -   mrr@20: 0.019845
2025-11-22 21:14:00 - GraphTrainer - INFO - 第 37 轮训练完成
2025-11-22 21:14:00 - GraphTrainer - INFO - train_loss: 0.350293
2025-11-22 21:14:00 - GraphTrainer - INFO - precision@5: 0.005935
2025-11-22 21:14:00 - GraphTrainer - INFO - recall@5: 0.028407
2025-11-22 21:14:00 - GraphTrainer - INFO - hit_rate@5: 0.029622
2025-11-22 21:14:00 - GraphTrainer - INFO - ndcg@5: 0.018518
2025-11-22 21:14:00 - GraphTrainer - INFO - map@5: 0.015064
2025-11-22 21:14:00 - GraphTrainer - INFO - mrr@5: 0.015666
2025-11-22 21:14:00 - GraphTrainer - INFO - precision@10: 0.004711
2025-11-22 21:14:00 - GraphTrainer - INFO - recall@10: 0.044703
2025-11-22 21:14:00 - GraphTrainer - INFO - hit_rate@10: 0.046953
2025-11-22 21:14:00 - GraphTrainer - INFO - ndcg@10: 0.023812
2025-11-22 21:14:00 - GraphTrainer - INFO - map@10: 0.017200
2025-11-22 21:14:00 - GraphTrainer - INFO - mrr@10: 0.017939
2025-11-22 21:14:00 - GraphTrainer - INFO - precision@20: 0.003764
2025-11-22 21:14:00 - GraphTrainer - INFO - recall@20: 0.071362
2025-11-22 21:14:00 - GraphTrainer - INFO - hit_rate@20: 0.074929
2025-11-22 21:14:00 - GraphTrainer - INFO - ndcg@20: 0.030591
2025-11-22 21:14:00 - GraphTrainer - INFO - map@20: 0.019024
2025-11-22 21:14:00 - GraphTrainer - INFO - mrr@20: 0.019845
2025-11-22 21:14:00 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:14:00 - GraphTrainer - INFO - ============================================================
2025-11-22 21:14:00 - GraphTrainer - INFO - 开始第 38/1000 轮训练
2025-11-22 21:14:00 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3680, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3730, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3705, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3462, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3206, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3628, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3818, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3558, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3490, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3649, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3574, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3435, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3824, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3670, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3434, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3517, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3409, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3746, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3543, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3572, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3642, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3604, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3639, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3643, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3639, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
The 37 training average loss: 0.3502927263235224
2025-11-22 21:14:11 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:14:11 - GraphTrainer - INFO -   precision@5: 0.005462
2025-11-22 21:14:11 - GraphTrainer - INFO -   recall@5: 0.026100
2025-11-22 21:14:11 - GraphTrainer - INFO -   hit_rate@5: 0.027308
2025-11-22 21:14:11 - GraphTrainer - INFO -   ndcg@5: 0.016699
2025-11-22 21:14:11 - GraphTrainer - INFO -   map@5: 0.013438
2025-11-22 21:14:11 - GraphTrainer - INFO -   mrr@5: 0.013973
2025-11-22 21:14:11 - GraphTrainer - INFO -   precision@10: 0.004505
2025-11-22 21:14:11 - GraphTrainer - INFO -   recall@10: 0.042892
2025-11-22 21:14:11 - GraphTrainer - INFO -   hit_rate@10: 0.044999
2025-11-22 21:14:11 - GraphTrainer - INFO -   ndcg@10: 0.022117
2025-11-22 21:14:11 - GraphTrainer - INFO -   map@10: 0.015614
2025-11-22 21:14:11 - GraphTrainer - INFO -   mrr@10: 0.016264
2025-11-22 21:14:11 - GraphTrainer - INFO -   precision@20: 0.003664
2025-11-22 21:14:11 - GraphTrainer - INFO -   recall@20: 0.069552
2025-11-22 21:14:11 - GraphTrainer - INFO -   hit_rate@20: 0.073129
2025-11-22 21:14:11 - GraphTrainer - INFO -   ndcg@20: 0.028875
2025-11-22 21:14:11 - GraphTrainer - INFO -   map@20: 0.017415
2025-11-22 21:14:11 - GraphTrainer - INFO -   mrr@20: 0.018161
2025-11-22 21:14:11 - GraphTrainer - INFO - 第 38 轮训练完成
2025-11-22 21:14:11 - GraphTrainer - INFO - train_loss: 0.347216
2025-11-22 21:14:11 - GraphTrainer - INFO - precision@5: 0.005462
2025-11-22 21:14:11 - GraphTrainer - INFO - recall@5: 0.026100
2025-11-22 21:14:11 - GraphTrainer - INFO - hit_rate@5: 0.027308
2025-11-22 21:14:11 - GraphTrainer - INFO - ndcg@5: 0.016699
2025-11-22 21:14:11 - GraphTrainer - INFO - map@5: 0.013438
2025-11-22 21:14:11 - GraphTrainer - INFO - mrr@5: 0.013973
2025-11-22 21:14:11 - GraphTrainer - INFO - precision@10: 0.004505
2025-11-22 21:14:11 - GraphTrainer - INFO - recall@10: 0.042892
2025-11-22 21:14:11 - GraphTrainer - INFO - hit_rate@10: 0.044999
2025-11-22 21:14:11 - GraphTrainer - INFO - ndcg@10: 0.022117
2025-11-22 21:14:11 - GraphTrainer - INFO - map@10: 0.015614
2025-11-22 21:14:11 - GraphTrainer - INFO - mrr@10: 0.016264
2025-11-22 21:14:11 - GraphTrainer - INFO - precision@20: 0.003664
2025-11-22 21:14:11 - GraphTrainer - INFO - recall@20: 0.069552
2025-11-22 21:14:11 - GraphTrainer - INFO - hit_rate@20: 0.073129
2025-11-22 21:14:11 - GraphTrainer - INFO - ndcg@20: 0.028875
2025-11-22 21:14:11 - GraphTrainer - INFO - map@20: 0.017415
2025-11-22 21:14:11 - GraphTrainer - INFO - mrr@20: 0.018161
2025-11-22 21:14:11 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:14:11 - GraphTrainer - INFO - ============================================================
2025-11-22 21:14:11 - GraphTrainer - INFO - 开始第 39/1000 轮训练
2025-11-22 21:14:11 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3543, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3206, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3691, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3562, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3763, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3630, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3516, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3510, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3494, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3288, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3569, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3620, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3685, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3376, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3373, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3512, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3551, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3707, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3333, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3711, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3579, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3219, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3579, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3302, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
The 38 training average loss: 0.3472158883152337
2025-11-22 21:14:23 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:14:23 - GraphTrainer - INFO -   precision@5: 0.005626
2025-11-22 21:14:23 - GraphTrainer - INFO -   recall@5: 0.026851
2025-11-22 21:14:23 - GraphTrainer - INFO -   hit_rate@5: 0.028131
2025-11-22 21:14:23 - GraphTrainer - INFO -   ndcg@5: 0.017091
2025-11-22 21:14:23 - GraphTrainer - INFO -   map@5: 0.013684
2025-11-22 21:14:23 - GraphTrainer - INFO -   mrr@5: 0.014267
2025-11-22 21:14:23 - GraphTrainer - INFO -   precision@10: 0.004515
2025-11-22 21:14:23 - GraphTrainer - INFO -   recall@10: 0.043028
2025-11-22 21:14:23 - GraphTrainer - INFO -   hit_rate@10: 0.045153
2025-11-22 21:14:23 - GraphTrainer - INFO -   ndcg@10: 0.022314
2025-11-22 21:14:23 - GraphTrainer - INFO -   map@10: 0.015786
2025-11-22 21:14:23 - GraphTrainer - INFO -   mrr@10: 0.016474
2025-11-22 21:14:23 - GraphTrainer - INFO -   precision@20: 0.003692
2025-11-22 21:14:23 - GraphTrainer - INFO -   recall@20: 0.070209
2025-11-22 21:14:23 - GraphTrainer - INFO -   hit_rate@20: 0.073695
2025-11-22 21:14:23 - GraphTrainer - INFO -   ndcg@20: 0.029242
2025-11-22 21:14:23 - GraphTrainer - INFO -   map@20: 0.017656
2025-11-22 21:14:23 - GraphTrainer - INFO -   mrr@20: 0.018436
2025-11-22 21:14:23 - GraphTrainer - INFO - 第 39 轮训练完成
2025-11-22 21:14:23 - GraphTrainer - INFO - train_loss: 0.343375
2025-11-22 21:14:23 - GraphTrainer - INFO - precision@5: 0.005626
2025-11-22 21:14:23 - GraphTrainer - INFO - recall@5: 0.026851
2025-11-22 21:14:23 - GraphTrainer - INFO - hit_rate@5: 0.028131
2025-11-22 21:14:23 - GraphTrainer - INFO - ndcg@5: 0.017091
2025-11-22 21:14:23 - GraphTrainer - INFO - map@5: 0.013684
2025-11-22 21:14:23 - GraphTrainer - INFO - mrr@5: 0.014267
2025-11-22 21:14:23 - GraphTrainer - INFO - precision@10: 0.004515
2025-11-22 21:14:23 - GraphTrainer - INFO - recall@10: 0.043028
2025-11-22 21:14:23 - GraphTrainer - INFO - hit_rate@10: 0.045153
2025-11-22 21:14:23 - GraphTrainer - INFO - ndcg@10: 0.022314
2025-11-22 21:14:23 - GraphTrainer - INFO - map@10: 0.015786
2025-11-22 21:14:23 - GraphTrainer - INFO - mrr@10: 0.016474
2025-11-22 21:14:23 - GraphTrainer - INFO - precision@20: 0.003692
2025-11-22 21:14:23 - GraphTrainer - INFO - recall@20: 0.070209
2025-11-22 21:14:23 - GraphTrainer - INFO - hit_rate@20: 0.073695
2025-11-22 21:14:23 - GraphTrainer - INFO - ndcg@20: 0.029242
2025-11-22 21:14:23 - GraphTrainer - INFO - map@20: 0.017656
2025-11-22 21:14:23 - GraphTrainer - INFO - mrr@20: 0.018436
2025-11-22 21:14:23 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:14:23 - GraphTrainer - INFO - ============================================================
2025-11-22 21:14:23 - GraphTrainer - INFO - 开始第 40/1000 轮训练
2025-11-22 21:14:23 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3462, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3521, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3614, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3177, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3480, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3607, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3142, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3480, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3560, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3284, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3226, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3629, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3499, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3227, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3621, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3570, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3184, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3137, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3633, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3586, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3624, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3677, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)
The 39 training average loss: 0.3433750492745432
2025-11-22 21:14:34 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:14:34 - GraphTrainer - INFO -   precision@5: 0.005657
2025-11-22 21:14:34 - GraphTrainer - INFO -   recall@5: 0.027220
2025-11-22 21:14:34 - GraphTrainer - INFO -   hit_rate@5: 0.028285
2025-11-22 21:14:34 - GraphTrainer - INFO -   ndcg@5: 0.017525
2025-11-22 21:14:34 - GraphTrainer - INFO -   map@5: 0.014153
2025-11-22 21:14:34 - GraphTrainer - INFO -   mrr@5: 0.014741
2025-11-22 21:14:34 - GraphTrainer - INFO -   precision@10: 0.004772
2025-11-22 21:14:34 - GraphTrainer - INFO -   recall@10: 0.045424
2025-11-22 21:14:34 - GraphTrainer - INFO -   hit_rate@10: 0.047673
2025-11-22 21:14:34 - GraphTrainer - INFO -   ndcg@10: 0.023420
2025-11-22 21:14:34 - GraphTrainer - INFO -   map@10: 0.016515
2025-11-22 21:14:34 - GraphTrainer - INFO -   mrr@10: 0.017262
2025-11-22 21:14:34 - GraphTrainer - INFO -   precision@20: 0.003726
2025-11-22 21:14:34 - GraphTrainer - INFO -   recall@20: 0.070465
2025-11-22 21:14:34 - GraphTrainer - INFO -   hit_rate@20: 0.074261
2025-11-22 21:14:34 - GraphTrainer - INFO -   ndcg@20: 0.029810
2025-11-22 21:14:34 - GraphTrainer - INFO -   map@20: 0.018233
2025-11-22 21:14:34 - GraphTrainer - INFO -   mrr@20: 0.019081
2025-11-22 21:14:34 - GraphTrainer - INFO - 第 40 轮训练完成
2025-11-22 21:14:34 - GraphTrainer - INFO - train_loss: 0.342491
2025-11-22 21:14:34 - GraphTrainer - INFO - precision@5: 0.005657
2025-11-22 21:14:34 - GraphTrainer - INFO - recall@5: 0.027220
2025-11-22 21:14:34 - GraphTrainer - INFO - hit_rate@5: 0.028285
2025-11-22 21:14:34 - GraphTrainer - INFO - ndcg@5: 0.017525
2025-11-22 21:14:34 - GraphTrainer - INFO - map@5: 0.014153
2025-11-22 21:14:34 - GraphTrainer - INFO - mrr@5: 0.014741
2025-11-22 21:14:34 - GraphTrainer - INFO - precision@10: 0.004772
2025-11-22 21:14:34 - GraphTrainer - INFO - recall@10: 0.045424
2025-11-22 21:14:34 - GraphTrainer - INFO - hit_rate@10: 0.047673
2025-11-22 21:14:34 - GraphTrainer - INFO - ndcg@10: 0.023420
2025-11-22 21:14:34 - GraphTrainer - INFO - map@10: 0.016515
2025-11-22 21:14:34 - GraphTrainer - INFO - mrr@10: 0.017262
2025-11-22 21:14:34 - GraphTrainer - INFO - precision@20: 0.003726
2025-11-22 21:14:34 - GraphTrainer - INFO - recall@20: 0.070465
2025-11-22 21:14:34 - GraphTrainer - INFO - hit_rate@20: 0.074261
2025-11-22 21:14:34 - GraphTrainer - INFO - ndcg@20: 0.029810
2025-11-22 21:14:34 - GraphTrainer - INFO - map@20: 0.018233
2025-11-22 21:14:34 - GraphTrainer - INFO - mrr@20: 0.019081
2025-11-22 21:14:34 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:14:34 - GraphTrainer - INFO - 检查点已保存: Epoch 40 -> ./checkpoints/checkpoint_epoch_40.pth
2025-11-22 21:14:34 - GraphTrainer - INFO - ============================================================
2025-11-22 21:14:34 - GraphTrainer - INFO - 开始第 41/1000 轮训练
2025-11-22 21:14:34 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3561, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3598, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3239, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3209, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3227, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3231, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3118, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3683, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3693, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3313, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3510, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3665, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3376, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3645, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3633, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3222, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3536, device='cuda:0', grad_fn=<AddBackward0>)
The 40 training average loss: 0.34249089195810517
2025-11-22 21:14:46 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:14:46 - GraphTrainer - INFO -   precision@5: 0.005924
2025-11-22 21:14:46 - GraphTrainer - INFO -   recall@5: 0.028367
2025-11-22 21:14:46 - GraphTrainer - INFO -   hit_rate@5: 0.029622
2025-11-22 21:14:46 - GraphTrainer - INFO -   ndcg@5: 0.018543
2025-11-22 21:14:46 - GraphTrainer - INFO -   map@5: 0.015098
2025-11-22 21:14:46 - GraphTrainer - INFO -   mrr@5: 0.015723
2025-11-22 21:14:46 - GraphTrainer - INFO -   precision@10: 0.004752
2025-11-22 21:14:46 - GraphTrainer - INFO -   recall@10: 0.045401
2025-11-22 21:14:46 - GraphTrainer - INFO -   hit_rate@10: 0.047519
2025-11-22 21:14:46 - GraphTrainer - INFO -   ndcg@10: 0.024072
2025-11-22 21:14:46 - GraphTrainer - INFO -   map@10: 0.017341
2025-11-22 21:14:46 - GraphTrainer - INFO -   mrr@10: 0.018077
2025-11-22 21:14:46 - GraphTrainer - INFO -   precision@20: 0.003705
2025-11-22 21:14:46 - GraphTrainer - INFO -   recall@20: 0.070322
2025-11-22 21:14:46 - GraphTrainer - INFO -   hit_rate@20: 0.073746
2025-11-22 21:14:46 - GraphTrainer - INFO -   ndcg@20: 0.030411
2025-11-22 21:14:46 - GraphTrainer - INFO -   map@20: 0.019043
2025-11-22 21:14:46 - GraphTrainer - INFO -   mrr@20: 0.019856
2025-11-22 21:14:46 - GraphTrainer - INFO - 第 41 轮训练完成
2025-11-22 21:14:46 - GraphTrainer - INFO - train_loss: 0.342248
2025-11-22 21:14:46 - GraphTrainer - INFO - precision@5: 0.005924
2025-11-22 21:14:46 - GraphTrainer - INFO - recall@5: 0.028367
2025-11-22 21:14:46 - GraphTrainer - INFO - hit_rate@5: 0.029622
2025-11-22 21:14:46 - GraphTrainer - INFO - ndcg@5: 0.018543
2025-11-22 21:14:46 - GraphTrainer - INFO - map@5: 0.015098
2025-11-22 21:14:46 - GraphTrainer - INFO - mrr@5: 0.015723
2025-11-22 21:14:46 - GraphTrainer - INFO - precision@10: 0.004752
2025-11-22 21:14:46 - GraphTrainer - INFO - recall@10: 0.045401
2025-11-22 21:14:46 - GraphTrainer - INFO - hit_rate@10: 0.047519
2025-11-22 21:14:46 - GraphTrainer - INFO - ndcg@10: 0.024072
2025-11-22 21:14:46 - GraphTrainer - INFO - map@10: 0.017341
2025-11-22 21:14:46 - GraphTrainer - INFO - mrr@10: 0.018077
2025-11-22 21:14:46 - GraphTrainer - INFO - precision@20: 0.003705
2025-11-22 21:14:46 - GraphTrainer - INFO - recall@20: 0.070322
2025-11-22 21:14:46 - GraphTrainer - INFO - hit_rate@20: 0.073746
2025-11-22 21:14:46 - GraphTrainer - INFO - ndcg@20: 0.030411
2025-11-22 21:14:46 - GraphTrainer - INFO - map@20: 0.019043
2025-11-22 21:14:46 - GraphTrainer - INFO - mrr@20: 0.019856
2025-11-22 21:14:46 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:14:46 - GraphTrainer - INFO - ============================================================
2025-11-22 21:14:46 - GraphTrainer - INFO - 开始第 42/1000 轮训练
2025-11-22 21:14:46 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3633, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3312, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3661, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3631, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3666, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3727, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3290, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3502, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3434, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3214, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3211, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3575, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3249, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3236, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3327, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3316, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3509, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3258, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3208, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3640, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3409, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3639, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3435, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
The 41 training average loss: 0.34224769935525695
2025-11-22 21:14:57 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:14:57 - GraphTrainer - INFO -   precision@5: 0.005698
2025-11-22 21:14:57 - GraphTrainer - INFO -   recall@5: 0.027099
2025-11-22 21:14:57 - GraphTrainer - INFO -   hit_rate@5: 0.028439
2025-11-22 21:14:57 - GraphTrainer - INFO -   ndcg@5: 0.017700
2025-11-22 21:14:57 - GraphTrainer - INFO -   map@5: 0.014393
2025-11-22 21:14:57 - GraphTrainer - INFO -   mrr@5: 0.014983
2025-11-22 21:14:57 - GraphTrainer - INFO -   precision@10: 0.004670
2025-11-22 21:14:57 - GraphTrainer - INFO -   recall@10: 0.044244
2025-11-22 21:14:57 - GraphTrainer - INFO -   hit_rate@10: 0.046644
2025-11-22 21:14:57 - GraphTrainer - INFO -   ndcg@10: 0.023248
2025-11-22 21:14:57 - GraphTrainer - INFO -   map@10: 0.016619
2025-11-22 21:14:57 - GraphTrainer - INFO -   mrr@10: 0.017352
2025-11-22 21:14:57 - GraphTrainer - INFO -   precision@20: 0.003682
2025-11-22 21:14:57 - GraphTrainer - INFO -   recall@20: 0.069830
2025-11-22 21:14:57 - GraphTrainer - INFO -   hit_rate@20: 0.073386
2025-11-22 21:14:57 - GraphTrainer - INFO -   ndcg@20: 0.029698
2025-11-22 21:14:57 - GraphTrainer - INFO -   map@20: 0.018331
2025-11-22 21:14:57 - GraphTrainer - INFO -   mrr@20: 0.019134
2025-11-22 21:14:57 - GraphTrainer - INFO - 第 42 轮训练完成
2025-11-22 21:14:57 - GraphTrainer - INFO - train_loss: 0.341582
2025-11-22 21:14:57 - GraphTrainer - INFO - precision@5: 0.005698
2025-11-22 21:14:57 - GraphTrainer - INFO - recall@5: 0.027099
2025-11-22 21:14:57 - GraphTrainer - INFO - hit_rate@5: 0.028439
2025-11-22 21:14:57 - GraphTrainer - INFO - ndcg@5: 0.017700
2025-11-22 21:14:57 - GraphTrainer - INFO - map@5: 0.014393
2025-11-22 21:14:57 - GraphTrainer - INFO - mrr@5: 0.014983
2025-11-22 21:14:57 - GraphTrainer - INFO - precision@10: 0.004670
2025-11-22 21:14:57 - GraphTrainer - INFO - recall@10: 0.044244
2025-11-22 21:14:57 - GraphTrainer - INFO - hit_rate@10: 0.046644
2025-11-22 21:14:57 - GraphTrainer - INFO - ndcg@10: 0.023248
2025-11-22 21:14:57 - GraphTrainer - INFO - map@10: 0.016619
2025-11-22 21:14:57 - GraphTrainer - INFO - mrr@10: 0.017352
2025-11-22 21:14:57 - GraphTrainer - INFO - precision@20: 0.003682
2025-11-22 21:14:57 - GraphTrainer - INFO - recall@20: 0.069830
2025-11-22 21:14:57 - GraphTrainer - INFO - hit_rate@20: 0.073386
2025-11-22 21:14:57 - GraphTrainer - INFO - ndcg@20: 0.029698
2025-11-22 21:14:57 - GraphTrainer - INFO - map@20: 0.018331
2025-11-22 21:14:57 - GraphTrainer - INFO - mrr@20: 0.019134
2025-11-22 21:14:57 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:14:57 - GraphTrainer - INFO - ============================================================
2025-11-22 21:14:57 - GraphTrainer - INFO - 开始第 43/1000 轮训练
2025-11-22 21:14:57 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3544, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3241, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3285, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3237, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3484, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3198, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3225, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3701, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3373, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3625, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3480, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3131, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3651, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3257, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3603, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3303, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3661, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3579, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3490, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3240, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3457, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3548, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>)
The 42 training average loss: 0.34158227515631706
2025-11-22 21:15:08 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:15:08 - GraphTrainer - INFO -   precision@5: 0.005729
2025-11-22 21:15:08 - GraphTrainer - INFO -   recall@5: 0.027417
2025-11-22 21:15:08 - GraphTrainer - INFO -   hit_rate@5: 0.028593
2025-11-22 21:15:08 - GraphTrainer - INFO -   ndcg@5: 0.017775
2025-11-22 21:15:08 - GraphTrainer - INFO -   map@5: 0.014407
2025-11-22 21:15:08 - GraphTrainer - INFO -   mrr@5: 0.015001
2025-11-22 21:15:08 - GraphTrainer - INFO -   precision@10: 0.004742
2025-11-22 21:15:08 - GraphTrainer - INFO -   recall@10: 0.045142
2025-11-22 21:15:08 - GraphTrainer - INFO -   hit_rate@10: 0.047364
2025-11-22 21:15:08 - GraphTrainer - INFO -   ndcg@10: 0.023546
2025-11-22 21:15:08 - GraphTrainer - INFO -   map@10: 0.016752
2025-11-22 21:15:08 - GraphTrainer - INFO -   mrr@10: 0.017481
2025-11-22 21:15:08 - GraphTrainer - INFO -   precision@20: 0.003710
2025-11-22 21:15:08 - GraphTrainer - INFO -   recall@20: 0.070360
2025-11-22 21:15:08 - GraphTrainer - INFO -   hit_rate@20: 0.073901
2025-11-22 21:15:08 - GraphTrainer - INFO -   ndcg@20: 0.029949
2025-11-22 21:15:08 - GraphTrainer - INFO -   map@20: 0.018464
2025-11-22 21:15:08 - GraphTrainer - INFO -   mrr@20: 0.019278
2025-11-22 21:15:08 - GraphTrainer - INFO - 第 43 轮训练完成
2025-11-22 21:15:08 - GraphTrainer - INFO - train_loss: 0.338886
2025-11-22 21:15:08 - GraphTrainer - INFO - precision@5: 0.005729
2025-11-22 21:15:08 - GraphTrainer - INFO - recall@5: 0.027417
2025-11-22 21:15:08 - GraphTrainer - INFO - hit_rate@5: 0.028593
2025-11-22 21:15:08 - GraphTrainer - INFO - ndcg@5: 0.017775
2025-11-22 21:15:08 - GraphTrainer - INFO - map@5: 0.014407
2025-11-22 21:15:08 - GraphTrainer - INFO - mrr@5: 0.015001
2025-11-22 21:15:08 - GraphTrainer - INFO - precision@10: 0.004742
2025-11-22 21:15:08 - GraphTrainer - INFO - recall@10: 0.045142
2025-11-22 21:15:08 - GraphTrainer - INFO - hit_rate@10: 0.047364
2025-11-22 21:15:08 - GraphTrainer - INFO - ndcg@10: 0.023546
2025-11-22 21:15:08 - GraphTrainer - INFO - map@10: 0.016752
2025-11-22 21:15:08 - GraphTrainer - INFO - mrr@10: 0.017481
2025-11-22 21:15:08 - GraphTrainer - INFO - precision@20: 0.003710
2025-11-22 21:15:08 - GraphTrainer - INFO - recall@20: 0.070360
2025-11-22 21:15:08 - GraphTrainer - INFO - hit_rate@20: 0.073901
2025-11-22 21:15:08 - GraphTrainer - INFO - ndcg@20: 0.029949
2025-11-22 21:15:08 - GraphTrainer - INFO - map@20: 0.018464
2025-11-22 21:15:08 - GraphTrainer - INFO - mrr@20: 0.019278
2025-11-22 21:15:08 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:15:08 - GraphTrainer - INFO - ============================================================
2025-11-22 21:15:08 - GraphTrainer - INFO - 开始第 44/1000 轮训练
2025-11-22 21:15:08 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3203, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3249, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3331, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3248, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3145, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3223, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3278, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3234, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3373, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3284, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3568, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3148, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3690, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3235, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3509, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3297, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3179, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3464, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3066, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3558, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3596, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3599, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3539, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3506, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3468, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3529, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
The 43 training average loss: 0.33888607549256294
2025-11-22 21:15:19 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:15:19 - GraphTrainer - INFO -   precision@5: 0.005616
2025-11-22 21:15:19 - GraphTrainer - INFO -   recall@5: 0.026796
2025-11-22 21:15:19 - GraphTrainer - INFO -   hit_rate@5: 0.027976
2025-11-22 21:15:19 - GraphTrainer - INFO -   ndcg@5: 0.017579
2025-11-22 21:15:19 - GraphTrainer - INFO -   map@5: 0.014335
2025-11-22 21:15:19 - GraphTrainer - INFO -   mrr@5: 0.014957
2025-11-22 21:15:19 - GraphTrainer - INFO -   precision@10: 0.004670
2025-11-22 21:15:19 - GraphTrainer - INFO -   recall@10: 0.044425
2025-11-22 21:15:19 - GraphTrainer - INFO -   hit_rate@10: 0.046593
2025-11-22 21:15:19 - GraphTrainer - INFO -   ndcg@10: 0.023318
2025-11-22 21:15:19 - GraphTrainer - INFO -   map@10: 0.016668
2025-11-22 21:15:19 - GraphTrainer - INFO -   mrr@10: 0.017424
2025-11-22 21:15:19 - GraphTrainer - INFO -   precision@20: 0.003757
2025-11-22 21:15:19 - GraphTrainer - INFO -   recall@20: 0.071433
2025-11-22 21:15:19 - GraphTrainer - INFO -   hit_rate@20: 0.074724
2025-11-22 21:15:19 - GraphTrainer - INFO -   ndcg@20: 0.030136
2025-11-22 21:15:19 - GraphTrainer - INFO -   map@20: 0.018480
2025-11-22 21:15:19 - GraphTrainer - INFO -   mrr@20: 0.019310
2025-11-22 21:15:19 - GraphTrainer - INFO - 第 44 轮训练完成
2025-11-22 21:15:19 - GraphTrainer - INFO - train_loss: 0.336196
2025-11-22 21:15:19 - GraphTrainer - INFO - precision@5: 0.005616
2025-11-22 21:15:19 - GraphTrainer - INFO - recall@5: 0.026796
2025-11-22 21:15:19 - GraphTrainer - INFO - hit_rate@5: 0.027976
2025-11-22 21:15:19 - GraphTrainer - INFO - ndcg@5: 0.017579
2025-11-22 21:15:19 - GraphTrainer - INFO - map@5: 0.014335
2025-11-22 21:15:19 - GraphTrainer - INFO - mrr@5: 0.014957
2025-11-22 21:15:19 - GraphTrainer - INFO - precision@10: 0.004670
2025-11-22 21:15:19 - GraphTrainer - INFO - recall@10: 0.044425
2025-11-22 21:15:19 - GraphTrainer - INFO - hit_rate@10: 0.046593
2025-11-22 21:15:19 - GraphTrainer - INFO - ndcg@10: 0.023318
2025-11-22 21:15:19 - GraphTrainer - INFO - map@10: 0.016668
2025-11-22 21:15:19 - GraphTrainer - INFO - mrr@10: 0.017424
2025-11-22 21:15:19 - GraphTrainer - INFO - precision@20: 0.003757
2025-11-22 21:15:19 - GraphTrainer - INFO - recall@20: 0.071433
2025-11-22 21:15:19 - GraphTrainer - INFO - hit_rate@20: 0.074724
2025-11-22 21:15:19 - GraphTrainer - INFO - ndcg@20: 0.030136
2025-11-22 21:15:19 - GraphTrainer - INFO - map@20: 0.018480
2025-11-22 21:15:19 - GraphTrainer - INFO - mrr@20: 0.019310
2025-11-22 21:15:19 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:15:19 - GraphTrainer - INFO - ============================================================
2025-11-22 21:15:19 - GraphTrainer - INFO - 开始第 45/1000 轮训练
2025-11-22 21:15:19 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3230, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3612, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3240, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3226, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3062, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3641, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3102, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3129, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3232, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3457, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3105, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3273, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3290, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3466, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3213, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3543, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3162, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3144, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3021, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3531, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3622, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3571, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3373, device='cuda:0', grad_fn=<AddBackward0>)
The 44 training average loss: 0.33619568060184346
2025-11-22 21:15:30 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:15:30 - GraphTrainer - INFO -   precision@5: 0.006151
2025-11-22 21:15:30 - GraphTrainer - INFO -   recall@5: 0.029420
2025-11-22 21:15:30 - GraphTrainer - INFO -   hit_rate@5: 0.030702
2025-11-22 21:15:30 - GraphTrainer - INFO -   ndcg@5: 0.019503
2025-11-22 21:15:30 - GraphTrainer - INFO -   map@5: 0.016037
2025-11-22 21:15:30 - GraphTrainer - INFO -   mrr@5: 0.016599
2025-11-22 21:15:30 - GraphTrainer - INFO -   precision@10: 0.004767
2025-11-22 21:15:30 - GraphTrainer - INFO -   recall@10: 0.045516
2025-11-22 21:15:30 - GraphTrainer - INFO -   hit_rate@10: 0.047570
2025-11-22 21:15:30 - GraphTrainer - INFO -   ndcg@10: 0.024687
2025-11-22 21:15:30 - GraphTrainer - INFO -   map@10: 0.018120
2025-11-22 21:15:30 - GraphTrainer - INFO -   mrr@10: 0.018782
2025-11-22 21:15:30 - GraphTrainer - INFO -   precision@20: 0.003844
2025-11-22 21:15:30 - GraphTrainer - INFO -   recall@20: 0.072907
2025-11-22 21:15:30 - GraphTrainer - INFO -   hit_rate@20: 0.076421
2025-11-22 21:15:30 - GraphTrainer - INFO -   ndcg@20: 0.031662
2025-11-22 21:15:30 - GraphTrainer - INFO -   map@20: 0.019995
2025-11-22 21:15:30 - GraphTrainer - INFO -   mrr@20: 0.020746
2025-11-22 21:15:30 - GraphTrainer - INFO - 第 45 轮训练完成
2025-11-22 21:15:30 - GraphTrainer - INFO - train_loss: 0.336089
2025-11-22 21:15:30 - GraphTrainer - INFO - precision@5: 0.006151
2025-11-22 21:15:30 - GraphTrainer - INFO - recall@5: 0.029420
2025-11-22 21:15:30 - GraphTrainer - INFO - hit_rate@5: 0.030702
2025-11-22 21:15:30 - GraphTrainer - INFO - ndcg@5: 0.019503
2025-11-22 21:15:30 - GraphTrainer - INFO - map@5: 0.016037
2025-11-22 21:15:30 - GraphTrainer - INFO - mrr@5: 0.016599
2025-11-22 21:15:30 - GraphTrainer - INFO - precision@10: 0.004767
2025-11-22 21:15:30 - GraphTrainer - INFO - recall@10: 0.045516
2025-11-22 21:15:30 - GraphTrainer - INFO - hit_rate@10: 0.047570
2025-11-22 21:15:30 - GraphTrainer - INFO - ndcg@10: 0.024687
2025-11-22 21:15:30 - GraphTrainer - INFO - map@10: 0.018120
2025-11-22 21:15:30 - GraphTrainer - INFO - mrr@10: 0.018782
2025-11-22 21:15:30 - GraphTrainer - INFO - precision@20: 0.003844
2025-11-22 21:15:30 - GraphTrainer - INFO - recall@20: 0.072907
2025-11-22 21:15:30 - GraphTrainer - INFO - hit_rate@20: 0.076421
2025-11-22 21:15:30 - GraphTrainer - INFO - ndcg@20: 0.031662
2025-11-22 21:15:30 - GraphTrainer - INFO - map@20: 0.019995
2025-11-22 21:15:30 - GraphTrainer - INFO - mrr@20: 0.020746
2025-11-22 21:15:30 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:15:30 - GraphTrainer - INFO - ============================================================
2025-11-22 21:15:30 - GraphTrainer - INFO - 开始第 46/1000 轮训练
2025-11-22 21:15:30 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3433, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3208, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3193, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3285, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3213, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3158, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3529, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3228, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3067, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3642, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3545, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3127, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3206, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3161, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3333, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3588, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3312, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3634, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3744, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3195, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3293, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3258, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3180, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3159, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3342, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3163, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3244, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3644, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3473, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3058, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3548, device='cuda:0', grad_fn=<AddBackward0>)
The 45 training average loss: 0.33608922619244147
2025-11-22 21:15:41 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:15:41 - GraphTrainer - INFO -   precision@5: 0.006202
2025-11-22 21:15:41 - GraphTrainer - INFO -   recall@5: 0.029720
2025-11-22 21:15:41 - GraphTrainer - INFO -   hit_rate@5: 0.030959
2025-11-22 21:15:41 - GraphTrainer - INFO -   ndcg@5: 0.019179
2025-11-22 21:15:41 - GraphTrainer - INFO -   map@5: 0.015492
2025-11-22 21:15:41 - GraphTrainer - INFO -   mrr@5: 0.016134
2025-11-22 21:15:41 - GraphTrainer - INFO -   precision@10: 0.004829
2025-11-22 21:15:41 - GraphTrainer - INFO -   recall@10: 0.045882
2025-11-22 21:15:41 - GraphTrainer - INFO -   hit_rate@10: 0.048187
2025-11-22 21:15:41 - GraphTrainer - INFO -   ndcg@10: 0.024428
2025-11-22 21:15:41 - GraphTrainer - INFO -   map@10: 0.017611
2025-11-22 21:15:41 - GraphTrainer - INFO -   mrr@10: 0.018390
2025-11-22 21:15:41 - GraphTrainer - INFO -   precision@20: 0.003734
2025-11-22 21:15:41 - GraphTrainer - INFO -   recall@20: 0.070671
2025-11-22 21:15:41 - GraphTrainer - INFO -   hit_rate@20: 0.074312
2025-11-22 21:15:41 - GraphTrainer - INFO -   ndcg@20: 0.030764
2025-11-22 21:15:41 - GraphTrainer - INFO -   map@20: 0.019323
2025-11-22 21:15:41 - GraphTrainer - INFO -   mrr@20: 0.020192
2025-11-22 21:15:41 - GraphTrainer - INFO - 第 46 轮训练完成
2025-11-22 21:15:41 - GraphTrainer - INFO - train_loss: 0.333114
2025-11-22 21:15:41 - GraphTrainer - INFO - precision@5: 0.006202
2025-11-22 21:15:41 - GraphTrainer - INFO - recall@5: 0.029720
2025-11-22 21:15:41 - GraphTrainer - INFO - hit_rate@5: 0.030959
2025-11-22 21:15:41 - GraphTrainer - INFO - ndcg@5: 0.019179
2025-11-22 21:15:41 - GraphTrainer - INFO - map@5: 0.015492
2025-11-22 21:15:41 - GraphTrainer - INFO - mrr@5: 0.016134
2025-11-22 21:15:41 - GraphTrainer - INFO - precision@10: 0.004829
2025-11-22 21:15:41 - GraphTrainer - INFO - recall@10: 0.045882
2025-11-22 21:15:41 - GraphTrainer - INFO - hit_rate@10: 0.048187
2025-11-22 21:15:41 - GraphTrainer - INFO - ndcg@10: 0.024428
2025-11-22 21:15:41 - GraphTrainer - INFO - map@10: 0.017611
2025-11-22 21:15:41 - GraphTrainer - INFO - mrr@10: 0.018390
2025-11-22 21:15:41 - GraphTrainer - INFO - precision@20: 0.003734
2025-11-22 21:15:41 - GraphTrainer - INFO - recall@20: 0.070671
2025-11-22 21:15:41 - GraphTrainer - INFO - hit_rate@20: 0.074312
2025-11-22 21:15:41 - GraphTrainer - INFO - ndcg@20: 0.030764
2025-11-22 21:15:41 - GraphTrainer - INFO - map@20: 0.019323
2025-11-22 21:15:41 - GraphTrainer - INFO - mrr@20: 0.020192
2025-11-22 21:15:41 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:15:41 - GraphTrainer - INFO - ============================================================
2025-11-22 21:15:41 - GraphTrainer - INFO - 开始第 47/1000 轮训练
2025-11-22 21:15:41 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3484, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3187, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3022, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3529, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3035, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3181, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3201, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3191, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3133, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3288, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3484, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3230, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3648, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3205, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3279, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3236, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3327, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2921, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3169, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2989, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3276, device='cuda:0', grad_fn=<AddBackward0>)
The 46 training average loss: 0.3331144503478346
2025-11-22 21:15:53 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:15:53 - GraphTrainer - INFO -   precision@5: 0.005575
2025-11-22 21:15:53 - GraphTrainer - INFO -   recall@5: 0.026441
2025-11-22 21:15:53 - GraphTrainer - INFO -   hit_rate@5: 0.027822
2025-11-22 21:15:53 - GraphTrainer - INFO -   ndcg@5: 0.017428
2025-11-22 21:15:53 - GraphTrainer - INFO -   map@5: 0.014231
2025-11-22 21:15:53 - GraphTrainer - INFO -   mrr@5: 0.014867
2025-11-22 21:15:53 - GraphTrainer - INFO -   precision@10: 0.004613
2025-11-22 21:15:53 - GraphTrainer - INFO -   recall@10: 0.043808
2025-11-22 21:15:53 - GraphTrainer - INFO -   hit_rate@10: 0.046079
2025-11-22 21:15:53 - GraphTrainer - INFO -   ndcg@10: 0.023067
2025-11-22 21:15:53 - GraphTrainer - INFO -   map@10: 0.016519
2025-11-22 21:15:53 - GraphTrainer - INFO -   mrr@10: 0.017277
2025-11-22 21:15:53 - GraphTrainer - INFO -   precision@20: 0.003788
2025-11-22 21:15:53 - GraphTrainer - INFO -   recall@20: 0.071825
2025-11-22 21:15:53 - GraphTrainer - INFO -   hit_rate@20: 0.075392
2025-11-22 21:15:53 - GraphTrainer - INFO -   ndcg@20: 0.030207
2025-11-22 21:15:53 - GraphTrainer - INFO -   map@20: 0.018448
2025-11-22 21:15:53 - GraphTrainer - INFO -   mrr@20: 0.019293
2025-11-22 21:15:53 - GraphTrainer - INFO - 第 47 轮训练完成
2025-11-22 21:15:53 - GraphTrainer - INFO - train_loss: 0.330579
2025-11-22 21:15:53 - GraphTrainer - INFO - precision@5: 0.005575
2025-11-22 21:15:53 - GraphTrainer - INFO - recall@5: 0.026441
2025-11-22 21:15:53 - GraphTrainer - INFO - hit_rate@5: 0.027822
2025-11-22 21:15:53 - GraphTrainer - INFO - ndcg@5: 0.017428
2025-11-22 21:15:53 - GraphTrainer - INFO - map@5: 0.014231
2025-11-22 21:15:53 - GraphTrainer - INFO - mrr@5: 0.014867
2025-11-22 21:15:53 - GraphTrainer - INFO - precision@10: 0.004613
2025-11-22 21:15:53 - GraphTrainer - INFO - recall@10: 0.043808
2025-11-22 21:15:53 - GraphTrainer - INFO - hit_rate@10: 0.046079
2025-11-22 21:15:53 - GraphTrainer - INFO - ndcg@10: 0.023067
2025-11-22 21:15:53 - GraphTrainer - INFO - map@10: 0.016519
2025-11-22 21:15:53 - GraphTrainer - INFO - mrr@10: 0.017277
2025-11-22 21:15:53 - GraphTrainer - INFO - precision@20: 0.003788
2025-11-22 21:15:53 - GraphTrainer - INFO - recall@20: 0.071825
2025-11-22 21:15:53 - GraphTrainer - INFO - hit_rate@20: 0.075392
2025-11-22 21:15:53 - GraphTrainer - INFO - ndcg@20: 0.030207
2025-11-22 21:15:53 - GraphTrainer - INFO - map@20: 0.018448
2025-11-22 21:15:53 - GraphTrainer - INFO - mrr@20: 0.019293
2025-11-22 21:15:53 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:15:53 - GraphTrainer - INFO - ============================================================
2025-11-22 21:15:53 - GraphTrainer - INFO - 开始第 48/1000 轮训练
2025-11-22 21:15:53 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3059, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3235, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3183, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3033, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3262, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3169, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3204, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3232, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3196, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3244, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3201, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3131, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3194, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3276, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3499, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3235, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3376, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3290, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3210, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3218, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3273, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3076, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3273, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3260, device='cuda:0', grad_fn=<AddBackward0>)
The 47 training average loss: 0.33057942524038514
2025-11-22 21:16:04 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:16:04 - GraphTrainer - INFO -   precision@5: 0.006089
2025-11-22 21:16:04 - GraphTrainer - INFO -   recall@5: 0.029104
2025-11-22 21:16:04 - GraphTrainer - INFO -   hit_rate@5: 0.030393
2025-11-22 21:16:04 - GraphTrainer - INFO -   ndcg@5: 0.018396
2025-11-22 21:16:04 - GraphTrainer - INFO -   map@5: 0.014683
2025-11-22 21:16:04 - GraphTrainer - INFO -   mrr@5: 0.015230
2025-11-22 21:16:04 - GraphTrainer - INFO -   precision@10: 0.004870
2025-11-22 21:16:04 - GraphTrainer - INFO -   recall@10: 0.046387
2025-11-22 21:16:04 - GraphTrainer - INFO -   hit_rate@10: 0.048599
2025-11-22 21:16:04 - GraphTrainer - INFO -   ndcg@10: 0.024001
2025-11-22 21:16:04 - GraphTrainer - INFO -   map@10: 0.016948
2025-11-22 21:16:04 - GraphTrainer - INFO -   mrr@10: 0.017622
2025-11-22 21:16:04 - GraphTrainer - INFO -   precision@20: 0.003893
2025-11-22 21:16:04 - GraphTrainer - INFO -   recall@20: 0.073785
2025-11-22 21:16:04 - GraphTrainer - INFO -   hit_rate@20: 0.077501
2025-11-22 21:16:04 - GraphTrainer - INFO -   ndcg@20: 0.030975
2025-11-22 21:16:04 - GraphTrainer - INFO -   map@20: 0.018822
2025-11-22 21:16:04 - GraphTrainer - INFO -   mrr@20: 0.019591
2025-11-22 21:16:04 - GraphTrainer - INFO - 第 48 轮训练完成
2025-11-22 21:16:04 - GraphTrainer - INFO - train_loss: 0.332445
2025-11-22 21:16:04 - GraphTrainer - INFO - precision@5: 0.006089
2025-11-22 21:16:04 - GraphTrainer - INFO - recall@5: 0.029104
2025-11-22 21:16:04 - GraphTrainer - INFO - hit_rate@5: 0.030393
2025-11-22 21:16:04 - GraphTrainer - INFO - ndcg@5: 0.018396
2025-11-22 21:16:04 - GraphTrainer - INFO - map@5: 0.014683
2025-11-22 21:16:04 - GraphTrainer - INFO - mrr@5: 0.015230
2025-11-22 21:16:04 - GraphTrainer - INFO - precision@10: 0.004870
2025-11-22 21:16:04 - GraphTrainer - INFO - recall@10: 0.046387
2025-11-22 21:16:04 - GraphTrainer - INFO - hit_rate@10: 0.048599
2025-11-22 21:16:04 - GraphTrainer - INFO - ndcg@10: 0.024001
2025-11-22 21:16:04 - GraphTrainer - INFO - map@10: 0.016948
2025-11-22 21:16:04 - GraphTrainer - INFO - mrr@10: 0.017622
2025-11-22 21:16:04 - GraphTrainer - INFO - precision@20: 0.003893
2025-11-22 21:16:04 - GraphTrainer - INFO - recall@20: 0.073785
2025-11-22 21:16:04 - GraphTrainer - INFO - hit_rate@20: 0.077501
2025-11-22 21:16:04 - GraphTrainer - INFO - ndcg@20: 0.030975
2025-11-22 21:16:04 - GraphTrainer - INFO - map@20: 0.018822
2025-11-22 21:16:04 - GraphTrainer - INFO - mrr@20: 0.019591
2025-11-22 21:16:04 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:16:04 - GraphTrainer - INFO - ============================================================
2025-11-22 21:16:04 - GraphTrainer - INFO - 开始第 49/1000 轮训练
2025-11-22 21:16:04 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3610, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3259, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3150, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3544, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3100, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3086, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3235, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3211, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3241, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3139, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3510, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3130, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3094, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3216, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3244, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3219, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3211, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3188, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3252, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3221, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3599, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3024, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3571, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3667, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3112, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3563, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3182, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3258, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3237, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3228, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3063, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3573, device='cuda:0', grad_fn=<AddBackward0>)
The 48 training average loss: 0.3324447125196457
2025-11-22 21:16:15 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:16:15 - GraphTrainer - INFO -   precision@5: 0.005955
2025-11-22 21:16:15 - GraphTrainer - INFO -   recall@5: 0.028534
2025-11-22 21:16:15 - GraphTrainer - INFO -   hit_rate@5: 0.029776
2025-11-22 21:16:15 - GraphTrainer - INFO -   ndcg@5: 0.018953
2025-11-22 21:16:15 - GraphTrainer - INFO -   map@5: 0.015611
2025-11-22 21:16:15 - GraphTrainer - INFO -   mrr@5: 0.016225
2025-11-22 21:16:15 - GraphTrainer - INFO -   precision@10: 0.004772
2025-11-22 21:16:15 - GraphTrainer - INFO -   recall@10: 0.045441
2025-11-22 21:16:15 - GraphTrainer - INFO -   hit_rate@10: 0.047724
2025-11-22 21:16:15 - GraphTrainer - INFO -   ndcg@10: 0.024441
2025-11-22 21:16:15 - GraphTrainer - INFO -   map@10: 0.017822
2025-11-22 21:16:15 - GraphTrainer - INFO -   mrr@10: 0.018571
2025-11-22 21:16:15 - GraphTrainer - INFO -   precision@20: 0.003813
2025-11-22 21:16:15 - GraphTrainer - INFO -   recall@20: 0.072245
2025-11-22 21:16:15 - GraphTrainer - INFO -   hit_rate@20: 0.075752
2025-11-22 21:16:15 - GraphTrainer - INFO -   ndcg@20: 0.031277
2025-11-22 21:16:15 - GraphTrainer - INFO -   map@20: 0.019669
2025-11-22 21:16:15 - GraphTrainer - INFO -   mrr@20: 0.020489
2025-11-22 21:16:15 - GraphTrainer - INFO - 第 49 轮训练完成
2025-11-22 21:16:15 - GraphTrainer - INFO - train_loss: 0.329291
2025-11-22 21:16:15 - GraphTrainer - INFO - precision@5: 0.005955
2025-11-22 21:16:15 - GraphTrainer - INFO - recall@5: 0.028534
2025-11-22 21:16:15 - GraphTrainer - INFO - hit_rate@5: 0.029776
2025-11-22 21:16:15 - GraphTrainer - INFO - ndcg@5: 0.018953
2025-11-22 21:16:15 - GraphTrainer - INFO - map@5: 0.015611
2025-11-22 21:16:15 - GraphTrainer - INFO - mrr@5: 0.016225
2025-11-22 21:16:15 - GraphTrainer - INFO - precision@10: 0.004772
2025-11-22 21:16:15 - GraphTrainer - INFO - recall@10: 0.045441
2025-11-22 21:16:15 - GraphTrainer - INFO - hit_rate@10: 0.047724
2025-11-22 21:16:15 - GraphTrainer - INFO - ndcg@10: 0.024441
2025-11-22 21:16:15 - GraphTrainer - INFO - map@10: 0.017822
2025-11-22 21:16:15 - GraphTrainer - INFO - mrr@10: 0.018571
2025-11-22 21:16:15 - GraphTrainer - INFO - precision@20: 0.003813
2025-11-22 21:16:15 - GraphTrainer - INFO - recall@20: 0.072245
2025-11-22 21:16:15 - GraphTrainer - INFO - hit_rate@20: 0.075752
2025-11-22 21:16:15 - GraphTrainer - INFO - ndcg@20: 0.031277
2025-11-22 21:16:15 - GraphTrainer - INFO - map@20: 0.019669
2025-11-22 21:16:15 - GraphTrainer - INFO - mrr@20: 0.020489
2025-11-22 21:16:15 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:16:15 - GraphTrainer - INFO - ============================================================
2025-11-22 21:16:15 - GraphTrainer - INFO - 开始第 50/1000 轮训练
2025-11-22 21:16:15 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3225, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3188, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3269, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3188, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3044, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3153, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3121, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3141, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3123, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3510, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3547, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3213, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3168, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3318, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3213, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3269, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3281, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3468, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3141, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3272, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3054, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3309, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3297, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3220, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3230, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3260, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3169, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3257, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3273, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3306, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3246, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3274, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3086, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3281, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3189, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
The 49 training average loss: 0.32929057859141253
2025-11-22 21:16:26 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:16:26 - GraphTrainer - INFO -   precision@5: 0.005863
2025-11-22 21:16:26 - GraphTrainer - INFO -   recall@5: 0.027965
2025-11-22 21:16:26 - GraphTrainer - INFO -   hit_rate@5: 0.029262
2025-11-22 21:16:26 - GraphTrainer - INFO -   ndcg@5: 0.018166
2025-11-22 21:16:26 - GraphTrainer - INFO -   map@5: 0.014707
2025-11-22 21:16:26 - GraphTrainer - INFO -   mrr@5: 0.015431
2025-11-22 21:16:26 - GraphTrainer - INFO -   precision@10: 0.004670
2025-11-22 21:16:26 - GraphTrainer - INFO -   recall@10: 0.044258
2025-11-22 21:16:26 - GraphTrainer - INFO -   hit_rate@10: 0.046542
2025-11-22 21:16:26 - GraphTrainer - INFO -   ndcg@10: 0.023465
2025-11-22 21:16:26 - GraphTrainer - INFO -   map@10: 0.016855
2025-11-22 21:16:26 - GraphTrainer - INFO -   mrr@10: 0.017708
2025-11-22 21:16:26 - GraphTrainer - INFO -   precision@20: 0.003700
2025-11-22 21:16:26 - GraphTrainer - INFO -   recall@20: 0.070217
2025-11-22 21:16:26 - GraphTrainer - INFO -   hit_rate@20: 0.073798
2025-11-22 21:16:26 - GraphTrainer - INFO -   ndcg@20: 0.030038
2025-11-22 21:16:26 - GraphTrainer - INFO -   map@20: 0.018611
2025-11-22 21:16:26 - GraphTrainer - INFO -   mrr@20: 0.019544
2025-11-22 21:16:26 - GraphTrainer - INFO - 第 50 轮训练完成
2025-11-22 21:16:26 - GraphTrainer - INFO - train_loss: 0.331380
2025-11-22 21:16:26 - GraphTrainer - INFO - precision@5: 0.005863
2025-11-22 21:16:26 - GraphTrainer - INFO - recall@5: 0.027965
2025-11-22 21:16:26 - GraphTrainer - INFO - hit_rate@5: 0.029262
2025-11-22 21:16:26 - GraphTrainer - INFO - ndcg@5: 0.018166
2025-11-22 21:16:26 - GraphTrainer - INFO - map@5: 0.014707
2025-11-22 21:16:26 - GraphTrainer - INFO - mrr@5: 0.015431
2025-11-22 21:16:26 - GraphTrainer - INFO - precision@10: 0.004670
2025-11-22 21:16:26 - GraphTrainer - INFO - recall@10: 0.044258
2025-11-22 21:16:26 - GraphTrainer - INFO - hit_rate@10: 0.046542
2025-11-22 21:16:26 - GraphTrainer - INFO - ndcg@10: 0.023465
2025-11-22 21:16:26 - GraphTrainer - INFO - map@10: 0.016855
2025-11-22 21:16:26 - GraphTrainer - INFO - mrr@10: 0.017708
2025-11-22 21:16:26 - GraphTrainer - INFO - precision@20: 0.003700
2025-11-22 21:16:26 - GraphTrainer - INFO - recall@20: 0.070217
2025-11-22 21:16:26 - GraphTrainer - INFO - hit_rate@20: 0.073798
2025-11-22 21:16:26 - GraphTrainer - INFO - ndcg@20: 0.030038
2025-11-22 21:16:26 - GraphTrainer - INFO - map@20: 0.018611
2025-11-22 21:16:26 - GraphTrainer - INFO - mrr@20: 0.019544
2025-11-22 21:16:26 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:16:26 - GraphTrainer - INFO - 检查点已保存: Epoch 50 -> ./checkpoints/checkpoint_epoch_50.pth
2025-11-22 21:16:26 - GraphTrainer - INFO - ============================================================
2025-11-22 21:16:26 - GraphTrainer - INFO - 开始第 51/1000 轮训练
2025-11-22 21:16:26 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3192, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3218, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3215, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3191, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3376, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3189, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3178, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3560, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3274, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3468, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3151, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3057, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3421, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3276, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3146, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3290, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3260, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3196, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3200, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3171, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3200, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3131, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3233, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3206, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3566, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3060, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3178, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3599, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3173, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3223, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3531, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3228, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
The 50 training average loss: 0.33138019925561446
2025-11-22 21:16:37 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:16:37 - GraphTrainer - INFO -   precision@5: 0.006192
2025-11-22 21:16:37 - GraphTrainer - INFO -   recall@5: 0.029435
2025-11-22 21:16:37 - GraphTrainer - INFO -   hit_rate@5: 0.030908
2025-11-22 21:16:37 - GraphTrainer - INFO -   ndcg@5: 0.019115
2025-11-22 21:16:37 - GraphTrainer - INFO -   map@5: 0.015500
2025-11-22 21:16:37 - GraphTrainer - INFO -   mrr@5: 0.016146
2025-11-22 21:16:37 - GraphTrainer - INFO -   precision@10: 0.005019
2025-11-22 21:16:37 - GraphTrainer - INFO -   recall@10: 0.047591
2025-11-22 21:16:37 - GraphTrainer - INFO -   hit_rate@10: 0.050090
2025-11-22 21:16:37 - GraphTrainer - INFO -   ndcg@10: 0.025013
2025-11-22 21:16:37 - GraphTrainer - INFO -   map@10: 0.017888
2025-11-22 21:16:37 - GraphTrainer - INFO -   mrr@10: 0.018667
2025-11-22 21:16:37 - GraphTrainer - INFO -   precision@20: 0.003764
2025-11-22 21:16:37 - GraphTrainer - INFO -   recall@20: 0.071434
2025-11-22 21:16:37 - GraphTrainer - INFO -   hit_rate@20: 0.074929
2025-11-22 21:16:37 - GraphTrainer - INFO -   ndcg@20: 0.031071
2025-11-22 21:16:37 - GraphTrainer - INFO -   map@20: 0.019520
2025-11-22 21:16:37 - GraphTrainer - INFO -   mrr@20: 0.020363
2025-11-22 21:16:37 - GraphTrainer - INFO - 第 51 轮训练完成
2025-11-22 21:16:37 - GraphTrainer - INFO - train_loss: 0.328241
2025-11-22 21:16:37 - GraphTrainer - INFO - precision@5: 0.006192
2025-11-22 21:16:37 - GraphTrainer - INFO - recall@5: 0.029435
2025-11-22 21:16:37 - GraphTrainer - INFO - hit_rate@5: 0.030908
2025-11-22 21:16:37 - GraphTrainer - INFO - ndcg@5: 0.019115
2025-11-22 21:16:37 - GraphTrainer - INFO - map@5: 0.015500
2025-11-22 21:16:37 - GraphTrainer - INFO - mrr@5: 0.016146
2025-11-22 21:16:37 - GraphTrainer - INFO - precision@10: 0.005019
2025-11-22 21:16:37 - GraphTrainer - INFO - recall@10: 0.047591
2025-11-22 21:16:37 - GraphTrainer - INFO - hit_rate@10: 0.050090
2025-11-22 21:16:37 - GraphTrainer - INFO - ndcg@10: 0.025013
2025-11-22 21:16:37 - GraphTrainer - INFO - map@10: 0.017888
2025-11-22 21:16:37 - GraphTrainer - INFO - mrr@10: 0.018667
2025-11-22 21:16:37 - GraphTrainer - INFO - precision@20: 0.003764
2025-11-22 21:16:37 - GraphTrainer - INFO - recall@20: 0.071434
2025-11-22 21:16:37 - GraphTrainer - INFO - hit_rate@20: 0.074929
2025-11-22 21:16:37 - GraphTrainer - INFO - ndcg@20: 0.031071
2025-11-22 21:16:37 - GraphTrainer - INFO - map@20: 0.019520
2025-11-22 21:16:37 - GraphTrainer - INFO - mrr@20: 0.020363
2025-11-22 21:16:37 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:16:37 - GraphTrainer - INFO - ============================================================
2025-11-22 21:16:37 - GraphTrainer - INFO - 开始第 52/1000 轮训练
2025-11-22 21:16:37 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3179, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3248, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3073, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3090, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3218, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3218, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3129, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3260, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3086, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3212, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3113, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3080, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3303, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3099, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3138, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3208, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3278, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3128, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3303, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3047, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3190, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3313, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3090, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3297, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3263, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3172, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3149, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
The 51 training average loss: 0.32824060526387444
2025-11-22 21:16:48 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:16:48 - GraphTrainer - INFO -   precision@5: 0.006079
2025-11-22 21:16:48 - GraphTrainer - INFO -   recall@5: 0.029043
2025-11-22 21:16:48 - GraphTrainer - INFO -   hit_rate@5: 0.030393
2025-11-22 21:16:48 - GraphTrainer - INFO -   ndcg@5: 0.019145
2025-11-22 21:16:48 - GraphTrainer - INFO -   map@5: 0.015693
2025-11-22 21:16:48 - GraphTrainer - INFO -   mrr@5: 0.016278
2025-11-22 21:16:48 - GraphTrainer - INFO -   precision@10: 0.004860
2025-11-22 21:16:48 - GraphTrainer - INFO -   recall@10: 0.046293
2025-11-22 21:16:48 - GraphTrainer - INFO -   hit_rate@10: 0.048599
2025-11-22 21:16:48 - GraphTrainer - INFO -   ndcg@10: 0.024773
2025-11-22 21:16:48 - GraphTrainer - INFO -   map@10: 0.017988
2025-11-22 21:16:48 - GraphTrainer - INFO -   mrr@10: 0.018696
2025-11-22 21:16:48 - GraphTrainer - INFO -   precision@20: 0.003836
2025-11-22 21:16:48 - GraphTrainer - INFO -   recall@20: 0.072766
2025-11-22 21:16:48 - GraphTrainer - INFO -   hit_rate@20: 0.076369
2025-11-22 21:16:48 - GraphTrainer - INFO -   ndcg@20: 0.031491
2025-11-22 21:16:48 - GraphTrainer - INFO -   map@20: 0.019781
2025-11-22 21:16:48 - GraphTrainer - INFO -   mrr@20: 0.020572
2025-11-22 21:16:48 - GraphTrainer - INFO - 第 52 轮训练完成
2025-11-22 21:16:48 - GraphTrainer - INFO - train_loss: 0.326070
2025-11-22 21:16:48 - GraphTrainer - INFO - precision@5: 0.006079
2025-11-22 21:16:48 - GraphTrainer - INFO - recall@5: 0.029043
2025-11-22 21:16:48 - GraphTrainer - INFO - hit_rate@5: 0.030393
2025-11-22 21:16:48 - GraphTrainer - INFO - ndcg@5: 0.019145
2025-11-22 21:16:48 - GraphTrainer - INFO - map@5: 0.015693
2025-11-22 21:16:48 - GraphTrainer - INFO - mrr@5: 0.016278
2025-11-22 21:16:48 - GraphTrainer - INFO - precision@10: 0.004860
2025-11-22 21:16:48 - GraphTrainer - INFO - recall@10: 0.046293
2025-11-22 21:16:48 - GraphTrainer - INFO - hit_rate@10: 0.048599
2025-11-22 21:16:48 - GraphTrainer - INFO - ndcg@10: 0.024773
2025-11-22 21:16:48 - GraphTrainer - INFO - map@10: 0.017988
2025-11-22 21:16:48 - GraphTrainer - INFO - mrr@10: 0.018696
2025-11-22 21:16:48 - GraphTrainer - INFO - precision@20: 0.003836
2025-11-22 21:16:48 - GraphTrainer - INFO - recall@20: 0.072766
2025-11-22 21:16:48 - GraphTrainer - INFO - hit_rate@20: 0.076369
2025-11-22 21:16:48 - GraphTrainer - INFO - ndcg@20: 0.031491
2025-11-22 21:16:48 - GraphTrainer - INFO - map@20: 0.019781
2025-11-22 21:16:48 - GraphTrainer - INFO - mrr@20: 0.020572
2025-11-22 21:16:48 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:16:48 - GraphTrainer - INFO - ============================================================
2025-11-22 21:16:48 - GraphTrainer - INFO - 开始第 53/1000 轮训练
2025-11-22 21:16:48 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3142, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3181, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3175, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3167, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3078, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3241, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2984, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3085, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3327, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3204, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3237, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3148, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3152, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3193, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3181, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3124, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3033, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3143, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3245, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3190, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3084, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3183, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3244, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3222, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3085, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3111, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3303, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3160, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3246, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3282, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3214, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
The 52 training average loss: 0.32607018536534804
2025-11-22 21:16:59 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:16:59 - GraphTrainer - INFO -   precision@5: 0.005822
2025-11-22 21:16:59 - GraphTrainer - INFO -   recall@5: 0.027833
2025-11-22 21:16:59 - GraphTrainer - INFO -   hit_rate@5: 0.029056
2025-11-22 21:16:59 - GraphTrainer - INFO -   ndcg@5: 0.018709
2025-11-22 21:16:59 - GraphTrainer - INFO -   map@5: 0.015504
2025-11-22 21:16:59 - GraphTrainer - INFO -   mrr@5: 0.016168
2025-11-22 21:16:59 - GraphTrainer - INFO -   precision@10: 0.004808
2025-11-22 21:16:59 - GraphTrainer - INFO -   recall@10: 0.045746
2025-11-22 21:16:59 - GraphTrainer - INFO -   hit_rate@10: 0.047981
2025-11-22 21:16:59 - GraphTrainer - INFO -   ndcg@10: 0.024528
2025-11-22 21:16:59 - GraphTrainer - INFO -   map@10: 0.017855
2025-11-22 21:16:59 - GraphTrainer - INFO -   mrr@10: 0.018651
2025-11-22 21:16:59 - GraphTrainer - INFO -   precision@20: 0.003777
2025-11-22 21:16:59 - GraphTrainer - INFO -   recall@20: 0.071578
2025-11-22 21:16:59 - GraphTrainer - INFO -   hit_rate@20: 0.075238
2025-11-22 21:16:59 - GraphTrainer - INFO -   ndcg@20: 0.031095
2025-11-22 21:16:59 - GraphTrainer - INFO -   map@20: 0.019616
2025-11-22 21:16:59 - GraphTrainer - INFO -   mrr@20: 0.020502
2025-11-22 21:16:59 - GraphTrainer - INFO - 第 53 轮训练完成
2025-11-22 21:16:59 - GraphTrainer - INFO - train_loss: 0.325819
2025-11-22 21:16:59 - GraphTrainer - INFO - precision@5: 0.005822
2025-11-22 21:16:59 - GraphTrainer - INFO - recall@5: 0.027833
2025-11-22 21:16:59 - GraphTrainer - INFO - hit_rate@5: 0.029056
2025-11-22 21:16:59 - GraphTrainer - INFO - ndcg@5: 0.018709
2025-11-22 21:16:59 - GraphTrainer - INFO - map@5: 0.015504
2025-11-22 21:16:59 - GraphTrainer - INFO - mrr@5: 0.016168
2025-11-22 21:16:59 - GraphTrainer - INFO - precision@10: 0.004808
2025-11-22 21:16:59 - GraphTrainer - INFO - recall@10: 0.045746
2025-11-22 21:16:59 - GraphTrainer - INFO - hit_rate@10: 0.047981
2025-11-22 21:16:59 - GraphTrainer - INFO - ndcg@10: 0.024528
2025-11-22 21:16:59 - GraphTrainer - INFO - map@10: 0.017855
2025-11-22 21:16:59 - GraphTrainer - INFO - mrr@10: 0.018651
2025-11-22 21:16:59 - GraphTrainer - INFO - precision@20: 0.003777
2025-11-22 21:16:59 - GraphTrainer - INFO - recall@20: 0.071578
2025-11-22 21:16:59 - GraphTrainer - INFO - hit_rate@20: 0.075238
2025-11-22 21:16:59 - GraphTrainer - INFO - ndcg@20: 0.031095
2025-11-22 21:16:59 - GraphTrainer - INFO - map@20: 0.019616
2025-11-22 21:16:59 - GraphTrainer - INFO - mrr@20: 0.020502
2025-11-22 21:16:59 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:16:59 - GraphTrainer - INFO - ============================================================
2025-11-22 21:16:59 - GraphTrainer - INFO - 开始第 54/1000 轮训练
2025-11-22 21:16:59 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3042, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3102, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3132, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3171, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3269, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3134, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3234, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3220, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3069, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3257, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3151, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3203, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3228, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3210, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3260, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3245, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3213, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3134, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3184, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3259, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3507, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3198, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3232, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3086, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3566, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3198, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3190, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2966, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3126, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3293, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3109, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3118, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3108, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3003, device='cuda:0', grad_fn=<AddBackward0>)
The 53 training average loss: 0.325819400363955
2025-11-22 21:17:09 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:17:09 - GraphTrainer - INFO -   precision@5: 0.006130
2025-11-22 21:17:09 - GraphTrainer - INFO -   recall@5: 0.029383
2025-11-22 21:17:09 - GraphTrainer - INFO -   hit_rate@5: 0.030651
2025-11-22 21:17:09 - GraphTrainer - INFO -   ndcg@5: 0.019316
2025-11-22 21:17:09 - GraphTrainer - INFO -   map@5: 0.015795
2025-11-22 21:17:09 - GraphTrainer - INFO -   mrr@5: 0.016437
2025-11-22 21:17:09 - GraphTrainer - INFO -   precision@10: 0.004880
2025-11-22 21:17:09 - GraphTrainer - INFO -   recall@10: 0.046673
2025-11-22 21:17:09 - GraphTrainer - INFO -   hit_rate@10: 0.048650
2025-11-22 21:17:09 - GraphTrainer - INFO -   ndcg@10: 0.024906
2025-11-22 21:17:09 - GraphTrainer - INFO -   map@10: 0.018055
2025-11-22 21:17:09 - GraphTrainer - INFO -   mrr@10: 0.018789
2025-11-22 21:17:09 - GraphTrainer - INFO -   precision@20: 0.003872
2025-11-22 21:17:09 - GraphTrainer - INFO -   recall@20: 0.073810
2025-11-22 21:17:09 - GraphTrainer - INFO -   hit_rate@20: 0.077141
2025-11-22 21:17:09 - GraphTrainer - INFO -   ndcg@20: 0.031806
2025-11-22 21:17:09 - GraphTrainer - INFO -   map@20: 0.019909
2025-11-22 21:17:09 - GraphTrainer - INFO -   mrr@20: 0.020733
2025-11-22 21:17:09 - GraphTrainer - INFO - 第 54 轮训练完成
2025-11-22 21:17:09 - GraphTrainer - INFO - train_loss: 0.326327
2025-11-22 21:17:09 - GraphTrainer - INFO - precision@5: 0.006130
2025-11-22 21:17:09 - GraphTrainer - INFO - recall@5: 0.029383
2025-11-22 21:17:09 - GraphTrainer - INFO - hit_rate@5: 0.030651
2025-11-22 21:17:09 - GraphTrainer - INFO - ndcg@5: 0.019316
2025-11-22 21:17:09 - GraphTrainer - INFO - map@5: 0.015795
2025-11-22 21:17:09 - GraphTrainer - INFO - mrr@5: 0.016437
2025-11-22 21:17:09 - GraphTrainer - INFO - precision@10: 0.004880
2025-11-22 21:17:09 - GraphTrainer - INFO - recall@10: 0.046673
2025-11-22 21:17:09 - GraphTrainer - INFO - hit_rate@10: 0.048650
2025-11-22 21:17:09 - GraphTrainer - INFO - ndcg@10: 0.024906
2025-11-22 21:17:09 - GraphTrainer - INFO - map@10: 0.018055
2025-11-22 21:17:09 - GraphTrainer - INFO - mrr@10: 0.018789
2025-11-22 21:17:09 - GraphTrainer - INFO - precision@20: 0.003872
2025-11-22 21:17:09 - GraphTrainer - INFO - recall@20: 0.073810
2025-11-22 21:17:09 - GraphTrainer - INFO - hit_rate@20: 0.077141
2025-11-22 21:17:09 - GraphTrainer - INFO - ndcg@20: 0.031806
2025-11-22 21:17:09 - GraphTrainer - INFO - map@20: 0.019909
2025-11-22 21:17:09 - GraphTrainer - INFO - mrr@20: 0.020733
2025-11-22 21:17:09 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:17:09 - GraphTrainer - INFO - ============================================================
2025-11-22 21:17:09 - GraphTrainer - INFO - 开始第 55/1000 轮训练
2025-11-22 21:17:09 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3174, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3063, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3158, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3480, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3184, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3058, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3192, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3131, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3102, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3333, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3191, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3148, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3119, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3135, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3116, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3175, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3189, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3256, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3186, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3156, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3262, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3113, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3132, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3181, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3127, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3055, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3205, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3272, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3534, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3186, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3088, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3199, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3222, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3327, device='cuda:0', grad_fn=<AddBackward0>)
The 54 training average loss: 0.3263269334003843
2025-11-22 21:17:20 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:17:20 - GraphTrainer - INFO -   precision@5: 0.006233
2025-11-22 21:17:20 - GraphTrainer - INFO -   recall@5: 0.029704
2025-11-22 21:17:20 - GraphTrainer - INFO -   hit_rate@5: 0.031165
2025-11-22 21:17:20 - GraphTrainer - INFO -   ndcg@5: 0.019346
2025-11-22 21:17:20 - GraphTrainer - INFO -   map@5: 0.015712
2025-11-22 21:17:20 - GraphTrainer - INFO -   mrr@5: 0.016440
2025-11-22 21:17:20 - GraphTrainer - INFO -   precision@10: 0.004880
2025-11-22 21:17:20 - GraphTrainer - INFO -   recall@10: 0.046254
2025-11-22 21:17:20 - GraphTrainer - INFO -   hit_rate@10: 0.048650
2025-11-22 21:17:20 - GraphTrainer - INFO -   ndcg@10: 0.024718
2025-11-22 21:17:20 - GraphTrainer - INFO -   map@10: 0.017876
2025-11-22 21:17:20 - GraphTrainer - INFO -   mrr@10: 0.018736
2025-11-22 21:17:20 - GraphTrainer - INFO -   precision@20: 0.003806
2025-11-22 21:17:20 - GraphTrainer - INFO -   recall@20: 0.071815
2025-11-22 21:17:20 - GraphTrainer - INFO -   hit_rate@20: 0.075649
2025-11-22 21:17:20 - GraphTrainer - INFO -   ndcg@20: 0.031210
2025-11-22 21:17:20 - GraphTrainer - INFO -   map@20: 0.019610
2025-11-22 21:17:20 - GraphTrainer - INFO -   mrr@20: 0.020557
2025-11-22 21:17:20 - GraphTrainer - INFO - 第 55 轮训练完成
2025-11-22 21:17:20 - GraphTrainer - INFO - train_loss: 0.325341
2025-11-22 21:17:20 - GraphTrainer - INFO - precision@5: 0.006233
2025-11-22 21:17:20 - GraphTrainer - INFO - recall@5: 0.029704
2025-11-22 21:17:20 - GraphTrainer - INFO - hit_rate@5: 0.031165
2025-11-22 21:17:20 - GraphTrainer - INFO - ndcg@5: 0.019346
2025-11-22 21:17:20 - GraphTrainer - INFO - map@5: 0.015712
2025-11-22 21:17:20 - GraphTrainer - INFO - mrr@5: 0.016440
2025-11-22 21:17:20 - GraphTrainer - INFO - precision@10: 0.004880
2025-11-22 21:17:20 - GraphTrainer - INFO - recall@10: 0.046254
2025-11-22 21:17:20 - GraphTrainer - INFO - hit_rate@10: 0.048650
2025-11-22 21:17:20 - GraphTrainer - INFO - ndcg@10: 0.024718
2025-11-22 21:17:20 - GraphTrainer - INFO - map@10: 0.017876
2025-11-22 21:17:20 - GraphTrainer - INFO - mrr@10: 0.018736
2025-11-22 21:17:20 - GraphTrainer - INFO - precision@20: 0.003806
2025-11-22 21:17:20 - GraphTrainer - INFO - recall@20: 0.071815
2025-11-22 21:17:20 - GraphTrainer - INFO - hit_rate@20: 0.075649
2025-11-22 21:17:20 - GraphTrainer - INFO - ndcg@20: 0.031210
2025-11-22 21:17:20 - GraphTrainer - INFO - map@20: 0.019610
2025-11-22 21:17:20 - GraphTrainer - INFO - mrr@20: 0.020557
2025-11-22 21:17:20 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:17:20 - GraphTrainer - INFO - ============================================================
2025-11-22 21:17:20 - GraphTrainer - INFO - 开始第 56/1000 轮训练
2025-11-22 21:17:20 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3098, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3269, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3157, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3306, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3222, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3154, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2875, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3033, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3082, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3039, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2999, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3179, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3240, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3598, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3222, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3199, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3099, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3178, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3205, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3078, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3164, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3143, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3318, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3261, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3211, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3051, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3221, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3110, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3342, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3331, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3189, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3176, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3166, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3273, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3276, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
The 55 training average loss: 0.32534129249638527
2025-11-22 21:17:31 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:17:31 - GraphTrainer - INFO -   precision@5: 0.005935
2025-11-22 21:17:31 - GraphTrainer - INFO -   recall@5: 0.028165
2025-11-22 21:17:31 - GraphTrainer - INFO -   hit_rate@5: 0.029673
2025-11-22 21:17:31 - GraphTrainer - INFO -   ndcg@5: 0.018434
2025-11-22 21:17:31 - GraphTrainer - INFO -   map@5: 0.014992
2025-11-22 21:17:31 - GraphTrainer - INFO -   mrr@5: 0.015676
2025-11-22 21:17:31 - GraphTrainer - INFO -   precision@10: 0.004829
2025-11-22 21:17:31 - GraphTrainer - INFO -   recall@10: 0.045748
2025-11-22 21:17:31 - GraphTrainer - INFO -   hit_rate@10: 0.048239
2025-11-22 21:17:31 - GraphTrainer - INFO -   ndcg@10: 0.024112
2025-11-22 21:17:31 - GraphTrainer - INFO -   map@10: 0.017270
2025-11-22 21:17:31 - GraphTrainer - INFO -   mrr@10: 0.018080
2025-11-22 21:17:31 - GraphTrainer - INFO -   precision@20: 0.003831
2025-11-22 21:17:31 - GraphTrainer - INFO -   recall@20: 0.072560
2025-11-22 21:17:31 - GraphTrainer - INFO -   hit_rate@20: 0.076266
2025-11-22 21:17:31 - GraphTrainer - INFO -   ndcg@20: 0.030926
2025-11-22 21:17:31 - GraphTrainer - INFO -   map@20: 0.019104
2025-11-22 21:17:31 - GraphTrainer - INFO -   mrr@20: 0.019983
2025-11-22 21:17:31 - GraphTrainer - INFO - 第 56 轮训练完成
2025-11-22 21:17:31 - GraphTrainer - INFO - train_loss: 0.321075
2025-11-22 21:17:31 - GraphTrainer - INFO - precision@5: 0.005935
2025-11-22 21:17:31 - GraphTrainer - INFO - recall@5: 0.028165
2025-11-22 21:17:31 - GraphTrainer - INFO - hit_rate@5: 0.029673
2025-11-22 21:17:31 - GraphTrainer - INFO - ndcg@5: 0.018434
2025-11-22 21:17:31 - GraphTrainer - INFO - map@5: 0.014992
2025-11-22 21:17:31 - GraphTrainer - INFO - mrr@5: 0.015676
2025-11-22 21:17:31 - GraphTrainer - INFO - precision@10: 0.004829
2025-11-22 21:17:31 - GraphTrainer - INFO - recall@10: 0.045748
2025-11-22 21:17:31 - GraphTrainer - INFO - hit_rate@10: 0.048239
2025-11-22 21:17:31 - GraphTrainer - INFO - ndcg@10: 0.024112
2025-11-22 21:17:31 - GraphTrainer - INFO - map@10: 0.017270
2025-11-22 21:17:31 - GraphTrainer - INFO - mrr@10: 0.018080
2025-11-22 21:17:31 - GraphTrainer - INFO - precision@20: 0.003831
2025-11-22 21:17:31 - GraphTrainer - INFO - recall@20: 0.072560
2025-11-22 21:17:31 - GraphTrainer - INFO - hit_rate@20: 0.076266
2025-11-22 21:17:31 - GraphTrainer - INFO - ndcg@20: 0.030926
2025-11-22 21:17:31 - GraphTrainer - INFO - map@20: 0.019104
2025-11-22 21:17:31 - GraphTrainer - INFO - mrr@20: 0.019983
2025-11-22 21:17:31 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:17:31 - GraphTrainer - INFO - ============================================================
2025-11-22 21:17:31 - GraphTrainer - INFO - 开始第 57/1000 轮训练
2025-11-22 21:17:31 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3217, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3236, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3118, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3186, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3038, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3216, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3096, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3124, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3221, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2922, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3094, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3231, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3172, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3230, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3024, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3030, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3234, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3167, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3166, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3197, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3254, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3183, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3178, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3158, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3116, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3157, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3231, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3239, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3145, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3055, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3130, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3284, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3122, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3117, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3116, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2979, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3083, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3232, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3230, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3258, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3138, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3234, device='cuda:0', grad_fn=<AddBackward0>)
The 56 training average loss: 0.3210746460947497
2025-11-22 21:17:42 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:17:42 - GraphTrainer - INFO -   precision@5: 0.006048
2025-11-22 21:17:42 - GraphTrainer - INFO -   recall@5: 0.028743
2025-11-22 21:17:42 - GraphTrainer - INFO -   hit_rate@5: 0.030239
2025-11-22 21:17:42 - GraphTrainer - INFO -   ndcg@5: 0.018685
2025-11-22 21:17:42 - GraphTrainer - INFO -   map@5: 0.015136
2025-11-22 21:17:42 - GraphTrainer - INFO -   mrr@5: 0.015835
2025-11-22 21:17:42 - GraphTrainer - INFO -   precision@10: 0.004824
2025-11-22 21:17:42 - GraphTrainer - INFO -   recall@10: 0.045706
2025-11-22 21:17:42 - GraphTrainer - INFO -   hit_rate@10: 0.048084
2025-11-22 21:17:42 - GraphTrainer - INFO -   ndcg@10: 0.024193
2025-11-22 21:17:42 - GraphTrainer - INFO -   map@10: 0.017367
2025-11-22 21:17:42 - GraphTrainer - INFO -   mrr@10: 0.018171
2025-11-22 21:17:42 - GraphTrainer - INFO -   precision@20: 0.003898
2025-11-22 21:17:42 - GraphTrainer - INFO -   recall@20: 0.073422
2025-11-22 21:17:42 - GraphTrainer - INFO -   hit_rate@20: 0.077346
2025-11-22 21:17:42 - GraphTrainer - INFO -   ndcg@20: 0.031246
2025-11-22 21:17:42 - GraphTrainer - INFO -   map@20: 0.019256
2025-11-22 21:17:42 - GraphTrainer - INFO -   mrr@20: 0.020155
2025-11-22 21:17:42 - GraphTrainer - INFO - 第 57 轮训练完成
2025-11-22 21:17:42 - GraphTrainer - INFO - train_loss: 0.319797
2025-11-22 21:17:42 - GraphTrainer - INFO - precision@5: 0.006048
2025-11-22 21:17:42 - GraphTrainer - INFO - recall@5: 0.028743
2025-11-22 21:17:42 - GraphTrainer - INFO - hit_rate@5: 0.030239
2025-11-22 21:17:42 - GraphTrainer - INFO - ndcg@5: 0.018685
2025-11-22 21:17:42 - GraphTrainer - INFO - map@5: 0.015136
2025-11-22 21:17:42 - GraphTrainer - INFO - mrr@5: 0.015835
2025-11-22 21:17:42 - GraphTrainer - INFO - precision@10: 0.004824
2025-11-22 21:17:42 - GraphTrainer - INFO - recall@10: 0.045706
2025-11-22 21:17:42 - GraphTrainer - INFO - hit_rate@10: 0.048084
2025-11-22 21:17:42 - GraphTrainer - INFO - ndcg@10: 0.024193
2025-11-22 21:17:42 - GraphTrainer - INFO - map@10: 0.017367
2025-11-22 21:17:42 - GraphTrainer - INFO - mrr@10: 0.018171
2025-11-22 21:17:42 - GraphTrainer - INFO - precision@20: 0.003898
2025-11-22 21:17:42 - GraphTrainer - INFO - recall@20: 0.073422
2025-11-22 21:17:42 - GraphTrainer - INFO - hit_rate@20: 0.077346
2025-11-22 21:17:42 - GraphTrainer - INFO - ndcg@20: 0.031246
2025-11-22 21:17:42 - GraphTrainer - INFO - map@20: 0.019256
2025-11-22 21:17:42 - GraphTrainer - INFO - mrr@20: 0.020155
2025-11-22 21:17:42 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:17:42 - GraphTrainer - INFO - ============================================================
2025-11-22 21:17:42 - GraphTrainer - INFO - 开始第 58/1000 轮训练
2025-11-22 21:17:42 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3220, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3048, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3296, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3167, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3181, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3435, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3119, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3018, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3225, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3226, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3016, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3293, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3373, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3245, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3254, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3052, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3177, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3273, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3184, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3099, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3023, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3033, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3177, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2936, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3006, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3192, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3041, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3254, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3099, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3215, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3119, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3124, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3119, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3198, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3134, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3278, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3154, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3139, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3076, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3165, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3304, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3119, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3183, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2964, device='cuda:0', grad_fn=<AddBackward0>)
The 57 training average loss: 0.3197973473318692
2025-11-22 21:17:53 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:17:53 - GraphTrainer - INFO -   precision@5: 0.005955
2025-11-22 21:17:53 - GraphTrainer - INFO -   recall@5: 0.028052
2025-11-22 21:17:53 - GraphTrainer - INFO -   hit_rate@5: 0.029725
2025-11-22 21:17:53 - GraphTrainer - INFO -   ndcg@5: 0.018720
2025-11-22 21:17:53 - GraphTrainer - INFO -   map@5: 0.015368
2025-11-22 21:17:53 - GraphTrainer - INFO -   mrr@5: 0.016229
2025-11-22 21:17:53 - GraphTrainer - INFO -   precision@10: 0.004839
2025-11-22 21:17:53 - GraphTrainer - INFO -   recall@10: 0.045841
2025-11-22 21:17:53 - GraphTrainer - INFO -   hit_rate@10: 0.048239
2025-11-22 21:17:53 - GraphTrainer - INFO -   ndcg@10: 0.024506
2025-11-22 21:17:53 - GraphTrainer - INFO -   map@10: 0.017733
2025-11-22 21:17:53 - GraphTrainer - INFO -   mrr@10: 0.018687
2025-11-22 21:17:53 - GraphTrainer - INFO -   precision@20: 0.003818
2025-11-22 21:17:53 - GraphTrainer - INFO -   recall@20: 0.072170
2025-11-22 21:17:53 - GraphTrainer - INFO -   hit_rate@20: 0.075958
2025-11-22 21:17:53 - GraphTrainer - INFO -   ndcg@20: 0.031184
2025-11-22 21:17:53 - GraphTrainer - INFO -   map@20: 0.019515
2025-11-22 21:17:53 - GraphTrainer - INFO -   mrr@20: 0.020554
2025-11-22 21:17:53 - GraphTrainer - INFO - 第 58 轮训练完成
2025-11-22 21:17:53 - GraphTrainer - INFO - train_loss: 0.317817
2025-11-22 21:17:53 - GraphTrainer - INFO - precision@5: 0.005955
2025-11-22 21:17:53 - GraphTrainer - INFO - recall@5: 0.028052
2025-11-22 21:17:53 - GraphTrainer - INFO - hit_rate@5: 0.029725
2025-11-22 21:17:53 - GraphTrainer - INFO - ndcg@5: 0.018720
2025-11-22 21:17:53 - GraphTrainer - INFO - map@5: 0.015368
2025-11-22 21:17:53 - GraphTrainer - INFO - mrr@5: 0.016229
2025-11-22 21:17:53 - GraphTrainer - INFO - precision@10: 0.004839
2025-11-22 21:17:53 - GraphTrainer - INFO - recall@10: 0.045841
2025-11-22 21:17:53 - GraphTrainer - INFO - hit_rate@10: 0.048239
2025-11-22 21:17:53 - GraphTrainer - INFO - ndcg@10: 0.024506
2025-11-22 21:17:53 - GraphTrainer - INFO - map@10: 0.017733
2025-11-22 21:17:53 - GraphTrainer - INFO - mrr@10: 0.018687
2025-11-22 21:17:53 - GraphTrainer - INFO - precision@20: 0.003818
2025-11-22 21:17:53 - GraphTrainer - INFO - recall@20: 0.072170
2025-11-22 21:17:53 - GraphTrainer - INFO - hit_rate@20: 0.075958
2025-11-22 21:17:53 - GraphTrainer - INFO - ndcg@20: 0.031184
2025-11-22 21:17:53 - GraphTrainer - INFO - map@20: 0.019515
2025-11-22 21:17:53 - GraphTrainer - INFO - mrr@20: 0.020554
2025-11-22 21:17:53 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:17:53 - GraphTrainer - INFO - ============================================================
2025-11-22 21:17:53 - GraphTrainer - INFO - 开始第 59/1000 轮训练
2025-11-22 21:17:53 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2998, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3193, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3121, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3053, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3142, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3110, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3058, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3107, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3221, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3148, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3040, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3161, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3226, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3077, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3084, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3161, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3220, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3097, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3041, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3304, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3151, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3023, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3011, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3055, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3226, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3222, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3221, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3172, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3206, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3096, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3232, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3112, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3060, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2941, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3529, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3141, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2920, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3124, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3302, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3158, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3131, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3241, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3214, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3067, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3045, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3117, device='cuda:0', grad_fn=<AddBackward0>)
The 58 training average loss: 0.3178173766053956
2025-11-22 21:18:04 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:18:04 - GraphTrainer - INFO -   precision@5: 0.006130
2025-11-22 21:18:04 - GraphTrainer - INFO -   recall@5: 0.029266
2025-11-22 21:18:04 - GraphTrainer - INFO -   hit_rate@5: 0.030651
2025-11-22 21:18:04 - GraphTrainer - INFO -   ndcg@5: 0.019328
2025-11-22 21:18:04 - GraphTrainer - INFO -   map@5: 0.015834
2025-11-22 21:18:04 - GraphTrainer - INFO -   mrr@5: 0.016542
2025-11-22 21:18:04 - GraphTrainer - INFO -   precision@10: 0.004844
2025-11-22 21:18:04 - GraphTrainer - INFO -   recall@10: 0.046065
2025-11-22 21:18:04 - GraphTrainer - INFO -   hit_rate@10: 0.048393
2025-11-22 21:18:04 - GraphTrainer - INFO -   ndcg@10: 0.024765
2025-11-22 21:18:04 - GraphTrainer - INFO -   map@10: 0.018022
2025-11-22 21:18:04 - GraphTrainer - INFO -   mrr@10: 0.018854
2025-11-22 21:18:04 - GraphTrainer - INFO -   precision@20: 0.003862
2025-11-22 21:18:04 - GraphTrainer - INFO -   recall@20: 0.073265
2025-11-22 21:18:04 - GraphTrainer - INFO -   hit_rate@20: 0.076935
2025-11-22 21:18:04 - GraphTrainer - INFO -   ndcg@20: 0.031672
2025-11-22 21:18:04 - GraphTrainer - INFO -   map@20: 0.019873
2025-11-22 21:18:04 - GraphTrainer - INFO -   mrr@20: 0.020791
2025-11-22 21:18:04 - GraphTrainer - INFO - 第 59 轮训练完成
2025-11-22 21:18:04 - GraphTrainer - INFO - train_loss: 0.316425
2025-11-22 21:18:04 - GraphTrainer - INFO - precision@5: 0.006130
2025-11-22 21:18:04 - GraphTrainer - INFO - recall@5: 0.029266
2025-11-22 21:18:04 - GraphTrainer - INFO - hit_rate@5: 0.030651
2025-11-22 21:18:04 - GraphTrainer - INFO - ndcg@5: 0.019328
2025-11-22 21:18:04 - GraphTrainer - INFO - map@5: 0.015834
2025-11-22 21:18:04 - GraphTrainer - INFO - mrr@5: 0.016542
2025-11-22 21:18:04 - GraphTrainer - INFO - precision@10: 0.004844
2025-11-22 21:18:04 - GraphTrainer - INFO - recall@10: 0.046065
2025-11-22 21:18:04 - GraphTrainer - INFO - hit_rate@10: 0.048393
2025-11-22 21:18:04 - GraphTrainer - INFO - ndcg@10: 0.024765
2025-11-22 21:18:04 - GraphTrainer - INFO - map@10: 0.018022
2025-11-22 21:18:04 - GraphTrainer - INFO - mrr@10: 0.018854
2025-11-22 21:18:04 - GraphTrainer - INFO - precision@20: 0.003862
2025-11-22 21:18:04 - GraphTrainer - INFO - recall@20: 0.073265
2025-11-22 21:18:04 - GraphTrainer - INFO - hit_rate@20: 0.076935
2025-11-22 21:18:04 - GraphTrainer - INFO - ndcg@20: 0.031672
2025-11-22 21:18:04 - GraphTrainer - INFO - map@20: 0.019873
2025-11-22 21:18:04 - GraphTrainer - INFO - mrr@20: 0.020791
2025-11-22 21:18:04 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:18:04 - GraphTrainer - INFO - ============================================================
2025-11-22 21:18:04 - GraphTrainer - INFO - 开始第 60/1000 轮训练
2025-11-22 21:18:04 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3153, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3231, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2849, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2913, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3065, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3484, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2963, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3539, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3062, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3089, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3135, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3124, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3060, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3304, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2956, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3099, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3075, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3067, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2941, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3226, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3098, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2907, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3218, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3080, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3140, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3262, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3213, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3160, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2939, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3069, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3139, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3023, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2941, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3220, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3114, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3201, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3281, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3147, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3058, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3075, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3254, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3150, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2969, device='cuda:0', grad_fn=<AddBackward0>)
The 59 training average loss: 0.3164251138424051
2025-11-22 21:18:15 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:18:15 - GraphTrainer - INFO -   precision@5: 0.006068
2025-11-22 21:18:15 - GraphTrainer - INFO -   recall@5: 0.028904
2025-11-22 21:18:15 - GraphTrainer - INFO -   hit_rate@5: 0.030342
2025-11-22 21:18:15 - GraphTrainer - INFO -   ndcg@5: 0.019171
2025-11-22 21:18:15 - GraphTrainer - INFO -   map@5: 0.015744
2025-11-22 21:18:15 - GraphTrainer - INFO -   mrr@5: 0.016444
2025-11-22 21:18:15 - GraphTrainer - INFO -   precision@10: 0.004850
2025-11-22 21:18:15 - GraphTrainer - INFO -   recall@10: 0.046233
2025-11-22 21:18:15 - GraphTrainer - INFO -   hit_rate@10: 0.048444
2025-11-22 21:18:15 - GraphTrainer - INFO -   ndcg@10: 0.024779
2025-11-22 21:18:15 - GraphTrainer - INFO -   map@10: 0.018015
2025-11-22 21:18:15 - GraphTrainer - INFO -   mrr@10: 0.018809
2025-11-22 21:18:15 - GraphTrainer - INFO -   precision@20: 0.003829
2025-11-22 21:18:15 - GraphTrainer - INFO -   recall@20: 0.072604
2025-11-22 21:18:15 - GraphTrainer - INFO -   hit_rate@20: 0.076318
2025-11-22 21:18:15 - GraphTrainer - INFO -   ndcg@20: 0.031486
2025-11-22 21:18:15 - GraphTrainer - INFO -   map@20: 0.019811
2025-11-22 21:18:15 - GraphTrainer - INFO -   mrr@20: 0.020706
2025-11-22 21:18:15 - GraphTrainer - INFO - 第 60 轮训练完成
2025-11-22 21:18:15 - GraphTrainer - INFO - train_loss: 0.317962
2025-11-22 21:18:15 - GraphTrainer - INFO - precision@5: 0.006068
2025-11-22 21:18:15 - GraphTrainer - INFO - recall@5: 0.028904
2025-11-22 21:18:15 - GraphTrainer - INFO - hit_rate@5: 0.030342
2025-11-22 21:18:15 - GraphTrainer - INFO - ndcg@5: 0.019171
2025-11-22 21:18:15 - GraphTrainer - INFO - map@5: 0.015744
2025-11-22 21:18:15 - GraphTrainer - INFO - mrr@5: 0.016444
2025-11-22 21:18:15 - GraphTrainer - INFO - precision@10: 0.004850
2025-11-22 21:18:15 - GraphTrainer - INFO - recall@10: 0.046233
2025-11-22 21:18:15 - GraphTrainer - INFO - hit_rate@10: 0.048444
2025-11-22 21:18:15 - GraphTrainer - INFO - ndcg@10: 0.024779
2025-11-22 21:18:15 - GraphTrainer - INFO - map@10: 0.018015
2025-11-22 21:18:15 - GraphTrainer - INFO - mrr@10: 0.018809
2025-11-22 21:18:15 - GraphTrainer - INFO - precision@20: 0.003829
2025-11-22 21:18:15 - GraphTrainer - INFO - recall@20: 0.072604
2025-11-22 21:18:15 - GraphTrainer - INFO - hit_rate@20: 0.076318
2025-11-22 21:18:15 - GraphTrainer - INFO - ndcg@20: 0.031486
2025-11-22 21:18:15 - GraphTrainer - INFO - map@20: 0.019811
2025-11-22 21:18:15 - GraphTrainer - INFO - mrr@20: 0.020706
2025-11-22 21:18:15 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:18:15 - GraphTrainer - INFO - 检查点已保存: Epoch 60 -> ./checkpoints/checkpoint_epoch_60.pth
2025-11-22 21:18:15 - GraphTrainer - INFO - ============================================================
2025-11-22 21:18:15 - GraphTrainer - INFO - 开始第 61/1000 轮训练
2025-11-22 21:18:15 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3000, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3017, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3213, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3249, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3304, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3060, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2904, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3104, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3220, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2937, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2910, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3299, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3019, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3071, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3187, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3107, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3076, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2999, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3202, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3268, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3195, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3297, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3074, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2990, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3547, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3040, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3246, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3173, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3091, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3227, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3159, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3241, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3226, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3177, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3225, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2999, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3236, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3254, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2935, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3220, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3164, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3306, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2940, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3203, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3254, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3018, device='cuda:0', grad_fn=<AddBackward0>)
The 60 training average loss: 0.3179617308337113
2025-11-22 21:18:27 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:18:27 - GraphTrainer - INFO -   precision@5: 0.006212
2025-11-22 21:18:27 - GraphTrainer - INFO -   recall@5: 0.029595
2025-11-22 21:18:27 - GraphTrainer - INFO -   hit_rate@5: 0.030959
2025-11-22 21:18:27 - GraphTrainer - INFO -   ndcg@5: 0.019402
2025-11-22 21:18:27 - GraphTrainer - INFO -   map@5: 0.015841
2025-11-22 21:18:27 - GraphTrainer - INFO -   mrr@5: 0.016446
2025-11-22 21:18:27 - GraphTrainer - INFO -   precision@10: 0.004978
2025-11-22 21:18:27 - GraphTrainer - INFO -   recall@10: 0.047228
2025-11-22 21:18:27 - GraphTrainer - INFO -   hit_rate@10: 0.049679
2025-11-22 21:18:27 - GraphTrainer - INFO -   ndcg@10: 0.025095
2025-11-22 21:18:27 - GraphTrainer - INFO -   map@10: 0.018124
2025-11-22 21:18:27 - GraphTrainer - INFO -   mrr@10: 0.018867
2025-11-22 21:18:27 - GraphTrainer - INFO -   precision@20: 0.003947
2025-11-22 21:18:27 - GraphTrainer - INFO -   recall@20: 0.074561
2025-11-22 21:18:27 - GraphTrainer - INFO -   hit_rate@20: 0.078426
2025-11-22 21:18:27 - GraphTrainer - INFO -   ndcg@20: 0.032060
2025-11-22 21:18:27 - GraphTrainer - INFO -   map@20: 0.019999
2025-11-22 21:18:27 - GraphTrainer - INFO -   mrr@20: 0.020829
2025-11-22 21:18:27 - GraphTrainer - INFO - 第 61 轮训练完成
2025-11-22 21:18:27 - GraphTrainer - INFO - train_loss: 0.317204
2025-11-22 21:18:27 - GraphTrainer - INFO - precision@5: 0.006212
2025-11-22 21:18:27 - GraphTrainer - INFO - recall@5: 0.029595
2025-11-22 21:18:27 - GraphTrainer - INFO - hit_rate@5: 0.030959
2025-11-22 21:18:27 - GraphTrainer - INFO - ndcg@5: 0.019402
2025-11-22 21:18:27 - GraphTrainer - INFO - map@5: 0.015841
2025-11-22 21:18:27 - GraphTrainer - INFO - mrr@5: 0.016446
2025-11-22 21:18:27 - GraphTrainer - INFO - precision@10: 0.004978
2025-11-22 21:18:27 - GraphTrainer - INFO - recall@10: 0.047228
2025-11-22 21:18:27 - GraphTrainer - INFO - hit_rate@10: 0.049679
2025-11-22 21:18:27 - GraphTrainer - INFO - ndcg@10: 0.025095
2025-11-22 21:18:27 - GraphTrainer - INFO - map@10: 0.018124
2025-11-22 21:18:27 - GraphTrainer - INFO - mrr@10: 0.018867
2025-11-22 21:18:27 - GraphTrainer - INFO - precision@20: 0.003947
2025-11-22 21:18:27 - GraphTrainer - INFO - recall@20: 0.074561
2025-11-22 21:18:27 - GraphTrainer - INFO - hit_rate@20: 0.078426
2025-11-22 21:18:27 - GraphTrainer - INFO - ndcg@20: 0.032060
2025-11-22 21:18:27 - GraphTrainer - INFO - map@20: 0.019999
2025-11-22 21:18:27 - GraphTrainer - INFO - mrr@20: 0.020829
2025-11-22 21:18:27 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:18:27 - GraphTrainer - INFO - ============================================================
2025-11-22 21:18:27 - GraphTrainer - INFO - 开始第 62/1000 轮训练
2025-11-22 21:18:27 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3183, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2991, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3241, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2906, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3067, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3069, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3177, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3303, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3150, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3288, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3170, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3241, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2986, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3262, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3192, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3029, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3060, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3074, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3226, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3272, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3143, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3189, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3206, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3142, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2971, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3197, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3112, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3081, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3105, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3131, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3258, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3173, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3220, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3081, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3145, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3186, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3175, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3073, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3210, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2992, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3110, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3168, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3189, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3143, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3080, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3167, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3030, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3237, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)
The 61 training average loss: 0.31720445022500793
2025-11-22 21:18:37 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:18:37 - GraphTrainer - INFO -   precision@5: 0.005667
2025-11-22 21:18:37 - GraphTrainer - INFO -   recall@5: 0.027199
2025-11-22 21:18:37 - GraphTrainer - INFO -   hit_rate@5: 0.028336
2025-11-22 21:18:37 - GraphTrainer - INFO -   ndcg@5: 0.017455
2025-11-22 21:18:37 - GraphTrainer - INFO -   map@5: 0.014070
2025-11-22 21:18:37 - GraphTrainer - INFO -   mrr@5: 0.014652
2025-11-22 21:18:37 - GraphTrainer - INFO -   precision@10: 0.004757
2025-11-22 21:18:37 - GraphTrainer - INFO -   recall@10: 0.045378
2025-11-22 21:18:37 - GraphTrainer - INFO -   hit_rate@10: 0.047519
2025-11-22 21:18:37 - GraphTrainer - INFO -   ndcg@10: 0.023380
2025-11-22 21:18:37 - GraphTrainer - INFO -   map@10: 0.016478
2025-11-22 21:18:37 - GraphTrainer - INFO -   mrr@10: 0.017196
2025-11-22 21:18:37 - GraphTrainer - INFO -   precision@20: 0.003829
2025-11-22 21:18:37 - GraphTrainer - INFO -   recall@20: 0.072672
2025-11-22 21:18:37 - GraphTrainer - INFO -   hit_rate@20: 0.076164
2025-11-22 21:18:37 - GraphTrainer - INFO -   ndcg@20: 0.030312
2025-11-22 21:18:37 - GraphTrainer - INFO -   map@20: 0.018331
2025-11-22 21:18:37 - GraphTrainer - INFO -   mrr@20: 0.019140
2025-11-22 21:18:37 - GraphTrainer - INFO - 第 62 轮训练完成
2025-11-22 21:18:37 - GraphTrainer - INFO - train_loss: 0.316466
2025-11-22 21:18:37 - GraphTrainer - INFO - precision@5: 0.005667
2025-11-22 21:18:37 - GraphTrainer - INFO - recall@5: 0.027199
2025-11-22 21:18:37 - GraphTrainer - INFO - hit_rate@5: 0.028336
2025-11-22 21:18:37 - GraphTrainer - INFO - ndcg@5: 0.017455
2025-11-22 21:18:37 - GraphTrainer - INFO - map@5: 0.014070
2025-11-22 21:18:37 - GraphTrainer - INFO - mrr@5: 0.014652
2025-11-22 21:18:37 - GraphTrainer - INFO - precision@10: 0.004757
2025-11-22 21:18:37 - GraphTrainer - INFO - recall@10: 0.045378
2025-11-22 21:18:37 - GraphTrainer - INFO - hit_rate@10: 0.047519
2025-11-22 21:18:37 - GraphTrainer - INFO - ndcg@10: 0.023380
2025-11-22 21:18:37 - GraphTrainer - INFO - map@10: 0.016478
2025-11-22 21:18:37 - GraphTrainer - INFO - mrr@10: 0.017196
2025-11-22 21:18:37 - GraphTrainer - INFO - precision@20: 0.003829
2025-11-22 21:18:37 - GraphTrainer - INFO - recall@20: 0.072672
2025-11-22 21:18:37 - GraphTrainer - INFO - hit_rate@20: 0.076164
2025-11-22 21:18:37 - GraphTrainer - INFO - ndcg@20: 0.030312
2025-11-22 21:18:37 - GraphTrainer - INFO - map@20: 0.018331
2025-11-22 21:18:37 - GraphTrainer - INFO - mrr@20: 0.019140
2025-11-22 21:18:37 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:18:37 - GraphTrainer - INFO - ============================================================
2025-11-22 21:18:37 - GraphTrainer - INFO - 开始第 63/1000 轮训练
2025-11-22 21:18:37 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3076, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3170, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3217, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3106, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2987, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3143, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3249, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3207, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3193, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3178, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2947, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3150, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3069, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3188, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3185, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3100, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3284, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2929, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3132, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3061, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3290, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3124, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3130, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3182, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3026, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3039, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3185, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3073, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3080, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3127, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3466, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2994, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3057, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2966, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3091, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3296, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3151, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3021, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3083, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3077, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3244, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3248, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3046, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2986, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3221, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3157, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3093, device='cuda:0', grad_fn=<AddBackward0>)
The 62 training average loss: 0.3164663890312458
2025-11-22 21:18:48 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:18:48 - GraphTrainer - INFO -   precision@5: 0.006007
2025-11-22 21:18:48 - GraphTrainer - INFO -   recall@5: 0.028709
2025-11-22 21:18:48 - GraphTrainer - INFO -   hit_rate@5: 0.029982
2025-11-22 21:18:48 - GraphTrainer - INFO -   ndcg@5: 0.018910
2025-11-22 21:18:48 - GraphTrainer - INFO -   map@5: 0.015494
2025-11-22 21:18:48 - GraphTrainer - INFO -   mrr@5: 0.016138
2025-11-22 21:18:48 - GraphTrainer - INFO -   precision@10: 0.004834
2025-11-22 21:18:48 - GraphTrainer - INFO -   recall@10: 0.045864
2025-11-22 21:18:48 - GraphTrainer - INFO -   hit_rate@10: 0.048239
2025-11-22 21:18:48 - GraphTrainer - INFO -   ndcg@10: 0.024488
2025-11-22 21:18:48 - GraphTrainer - INFO -   map@10: 0.017746
2025-11-22 21:18:48 - GraphTrainer - INFO -   mrr@10: 0.018534
2025-11-22 21:18:48 - GraphTrainer - INFO -   precision@20: 0.003870
2025-11-22 21:18:48 - GraphTrainer - INFO -   recall@20: 0.073303
2025-11-22 21:18:48 - GraphTrainer - INFO -   hit_rate@20: 0.077089
2025-11-22 21:18:48 - GraphTrainer - INFO -   ndcg@20: 0.031470
2025-11-22 21:18:48 - GraphTrainer - INFO -   map@20: 0.019622
2025-11-22 21:18:48 - GraphTrainer - INFO -   mrr@20: 0.020500
2025-11-22 21:18:48 - GraphTrainer - INFO - 第 63 轮训练完成
2025-11-22 21:18:48 - GraphTrainer - INFO - train_loss: 0.316190
2025-11-22 21:18:48 - GraphTrainer - INFO - precision@5: 0.006007
2025-11-22 21:18:48 - GraphTrainer - INFO - recall@5: 0.028709
2025-11-22 21:18:48 - GraphTrainer - INFO - hit_rate@5: 0.029982
2025-11-22 21:18:48 - GraphTrainer - INFO - ndcg@5: 0.018910
2025-11-22 21:18:48 - GraphTrainer - INFO - map@5: 0.015494
2025-11-22 21:18:48 - GraphTrainer - INFO - mrr@5: 0.016138
2025-11-22 21:18:48 - GraphTrainer - INFO - precision@10: 0.004834
2025-11-22 21:18:48 - GraphTrainer - INFO - recall@10: 0.045864
2025-11-22 21:18:48 - GraphTrainer - INFO - hit_rate@10: 0.048239
2025-11-22 21:18:48 - GraphTrainer - INFO - ndcg@10: 0.024488
2025-11-22 21:18:48 - GraphTrainer - INFO - map@10: 0.017746
2025-11-22 21:18:48 - GraphTrainer - INFO - mrr@10: 0.018534
2025-11-22 21:18:48 - GraphTrainer - INFO - precision@20: 0.003870
2025-11-22 21:18:48 - GraphTrainer - INFO - recall@20: 0.073303
2025-11-22 21:18:48 - GraphTrainer - INFO - hit_rate@20: 0.077089
2025-11-22 21:18:48 - GraphTrainer - INFO - ndcg@20: 0.031470
2025-11-22 21:18:48 - GraphTrainer - INFO - map@20: 0.019622
2025-11-22 21:18:48 - GraphTrainer - INFO - mrr@20: 0.020500
2025-11-22 21:18:48 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:18:48 - GraphTrainer - INFO - ============================================================
2025-11-22 21:18:48 - GraphTrainer - INFO - 开始第 64/1000 轮训练
2025-11-22 21:18:48 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3001, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3127, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3177, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3237, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3160, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3107, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3062, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3218, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3196, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3105, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3141, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3092, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3148, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3128, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3116, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3003, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2928, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3165, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2959, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3148, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2958, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3065, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2941, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3082, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3203, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3249, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3074, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2980, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3004, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3233, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3118, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3195, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3119, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3024, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3115, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2973, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2983, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2946, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3200, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3244, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3166, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3155, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3095, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3045, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3142, device='cuda:0', grad_fn=<AddBackward0>)
The 63 training average loss: 0.316189962214437
2025-11-22 21:18:59 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:18:59 - GraphTrainer - INFO -   precision@5: 0.006243
2025-11-22 21:18:59 - GraphTrainer - INFO -   recall@5: 0.029822
2025-11-22 21:18:59 - GraphTrainer - INFO -   hit_rate@5: 0.031165
2025-11-22 21:18:59 - GraphTrainer - INFO -   ndcg@5: 0.019620
2025-11-22 21:18:59 - GraphTrainer - INFO -   map@5: 0.016050
2025-11-22 21:18:59 - GraphTrainer - INFO -   mrr@5: 0.016681
2025-11-22 21:18:59 - GraphTrainer - INFO -   precision@10: 0.004860
2025-11-22 21:18:59 - GraphTrainer - INFO -   recall@10: 0.045978
2025-11-22 21:18:59 - GraphTrainer - INFO -   hit_rate@10: 0.048547
2025-11-22 21:18:59 - GraphTrainer - INFO -   ndcg@10: 0.024908
2025-11-22 21:18:59 - GraphTrainer - INFO -   map@10: 0.018198
2025-11-22 21:18:59 - GraphTrainer - INFO -   mrr@10: 0.018988
2025-11-22 21:18:59 - GraphTrainer - INFO -   precision@20: 0.003816
2025-11-22 21:18:59 - GraphTrainer - INFO -   recall@20: 0.072176
2025-11-22 21:18:59 - GraphTrainer - INFO -   hit_rate@20: 0.076009
2025-11-22 21:18:59 - GraphTrainer - INFO -   ndcg@20: 0.031545
2025-11-22 21:18:59 - GraphTrainer - INFO -   map@20: 0.019969
2025-11-22 21:18:59 - GraphTrainer - INFO -   mrr@20: 0.020835
2025-11-22 21:18:59 - GraphTrainer - INFO - 第 64 轮训练完成
2025-11-22 21:18:59 - GraphTrainer - INFO - train_loss: 0.313237
2025-11-22 21:18:59 - GraphTrainer - INFO - precision@5: 0.006243
2025-11-22 21:18:59 - GraphTrainer - INFO - recall@5: 0.029822
2025-11-22 21:18:59 - GraphTrainer - INFO - hit_rate@5: 0.031165
2025-11-22 21:18:59 - GraphTrainer - INFO - ndcg@5: 0.019620
2025-11-22 21:18:59 - GraphTrainer - INFO - map@5: 0.016050
2025-11-22 21:18:59 - GraphTrainer - INFO - mrr@5: 0.016681
2025-11-22 21:18:59 - GraphTrainer - INFO - precision@10: 0.004860
2025-11-22 21:18:59 - GraphTrainer - INFO - recall@10: 0.045978
2025-11-22 21:18:59 - GraphTrainer - INFO - hit_rate@10: 0.048547
2025-11-22 21:18:59 - GraphTrainer - INFO - ndcg@10: 0.024908
2025-11-22 21:18:59 - GraphTrainer - INFO - map@10: 0.018198
2025-11-22 21:18:59 - GraphTrainer - INFO - mrr@10: 0.018988
2025-11-22 21:18:59 - GraphTrainer - INFO - precision@20: 0.003816
2025-11-22 21:18:59 - GraphTrainer - INFO - recall@20: 0.072176
2025-11-22 21:18:59 - GraphTrainer - INFO - hit_rate@20: 0.076009
2025-11-22 21:18:59 - GraphTrainer - INFO - ndcg@20: 0.031545
2025-11-22 21:18:59 - GraphTrainer - INFO - map@20: 0.019969
2025-11-22 21:18:59 - GraphTrainer - INFO - mrr@20: 0.020835
2025-11-22 21:18:59 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:18:59 - GraphTrainer - INFO - ============================================================
2025-11-22 21:18:59 - GraphTrainer - INFO - 开始第 65/1000 轮训练
2025-11-22 21:18:59 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3039, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3133, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3081, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2981, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3099, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3208, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3132, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3036, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3207, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3038, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2869, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3304, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3175, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3104, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3009, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3183, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3172, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3095, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3161, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3046, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2850, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2987, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3123, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3041, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3049, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3087, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3019, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3246, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3260, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3058, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2982, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3097, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3233, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2902, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3479, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3016, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2978, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3036, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3193, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3033, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3088, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3135, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3070, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3197, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3055, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3052, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3245, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3165, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3274, device='cuda:0', grad_fn=<AddBackward0>)
The 64 training average loss: 0.3132371301281041
2025-11-22 21:19:10 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:19:10 - GraphTrainer - INFO -   precision@5: 0.006120
2025-11-22 21:19:10 - GraphTrainer - INFO -   recall@5: 0.029027
2025-11-22 21:19:10 - GraphTrainer - INFO -   hit_rate@5: 0.030548
2025-11-22 21:19:10 - GraphTrainer - INFO -   ndcg@5: 0.019342
2025-11-22 21:19:10 - GraphTrainer - INFO -   map@5: 0.015928
2025-11-22 21:19:10 - GraphTrainer - INFO -   mrr@5: 0.016608
2025-11-22 21:19:10 - GraphTrainer - INFO -   precision@10: 0.004793
2025-11-22 21:19:10 - GraphTrainer - INFO -   recall@10: 0.045352
2025-11-22 21:19:10 - GraphTrainer - INFO -   hit_rate@10: 0.047673
2025-11-22 21:19:10 - GraphTrainer - INFO -   ndcg@10: 0.024644
2025-11-22 21:19:10 - GraphTrainer - INFO -   map@10: 0.018079
2025-11-22 21:19:10 - GraphTrainer - INFO -   mrr@10: 0.018856
2025-11-22 21:19:10 - GraphTrainer - INFO -   precision@20: 0.003824
2025-11-22 21:19:10 - GraphTrainer - INFO -   recall@20: 0.072529
2025-11-22 21:19:10 - GraphTrainer - INFO -   hit_rate@20: 0.076009
2025-11-22 21:19:10 - GraphTrainer - INFO -   ndcg@20: 0.031551
2025-11-22 21:19:10 - GraphTrainer - INFO -   map@20: 0.019943
2025-11-22 21:19:10 - GraphTrainer - INFO -   mrr@20: 0.020795
2025-11-22 21:19:10 - GraphTrainer - INFO - 第 65 轮训练完成
2025-11-22 21:19:10 - GraphTrainer - INFO - train_loss: 0.316153
2025-11-22 21:19:10 - GraphTrainer - INFO - precision@5: 0.006120
2025-11-22 21:19:10 - GraphTrainer - INFO - recall@5: 0.029027
2025-11-22 21:19:10 - GraphTrainer - INFO - hit_rate@5: 0.030548
2025-11-22 21:19:10 - GraphTrainer - INFO - ndcg@5: 0.019342
2025-11-22 21:19:10 - GraphTrainer - INFO - map@5: 0.015928
2025-11-22 21:19:10 - GraphTrainer - INFO - mrr@5: 0.016608
2025-11-22 21:19:10 - GraphTrainer - INFO - precision@10: 0.004793
2025-11-22 21:19:10 - GraphTrainer - INFO - recall@10: 0.045352
2025-11-22 21:19:10 - GraphTrainer - INFO - hit_rate@10: 0.047673
2025-11-22 21:19:10 - GraphTrainer - INFO - ndcg@10: 0.024644
2025-11-22 21:19:10 - GraphTrainer - INFO - map@10: 0.018079
2025-11-22 21:19:10 - GraphTrainer - INFO - mrr@10: 0.018856
2025-11-22 21:19:10 - GraphTrainer - INFO - precision@20: 0.003824
2025-11-22 21:19:10 - GraphTrainer - INFO - recall@20: 0.072529
2025-11-22 21:19:10 - GraphTrainer - INFO - hit_rate@20: 0.076009
2025-11-22 21:19:10 - GraphTrainer - INFO - ndcg@20: 0.031551
2025-11-22 21:19:10 - GraphTrainer - INFO - map@20: 0.019943
2025-11-22 21:19:10 - GraphTrainer - INFO - mrr@20: 0.020795
2025-11-22 21:19:10 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:19:10 - GraphTrainer - INFO - ============================================================
2025-11-22 21:19:10 - GraphTrainer - INFO - 开始第 66/1000 轮训练
2025-11-22 21:19:10 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3162, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3001, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3072, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3136, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3216, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3165, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3174, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3217, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3188, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3082, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3150, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3177, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2959, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3004, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3096, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3166, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3001, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3030, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2970, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3122, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3043, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3239, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3122, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2951, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3104, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2822, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3241, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3142, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3220, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3128, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3119, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3061, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3025, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3105, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3127, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3245, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3222, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3226, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3259, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3139, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3435, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3193, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3165, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3130, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3211, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3124, device='cuda:0', grad_fn=<AddBackward0>)
The 65 training average loss: 0.3161525608136736
2025-11-22 21:19:21 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:19:21 - GraphTrainer - INFO -   precision@5: 0.006295
2025-11-22 21:19:21 - GraphTrainer - INFO -   recall@5: 0.029940
2025-11-22 21:19:21 - GraphTrainer - INFO -   hit_rate@5: 0.031371
2025-11-22 21:19:21 - GraphTrainer - INFO -   ndcg@5: 0.020165
2025-11-22 21:19:21 - GraphTrainer - INFO -   map@5: 0.016711
2025-11-22 21:19:21 - GraphTrainer - INFO -   mrr@5: 0.017374
2025-11-22 21:19:21 - GraphTrainer - INFO -   precision@10: 0.004880
2025-11-22 21:19:21 - GraphTrainer - INFO -   recall@10: 0.046190
2025-11-22 21:19:21 - GraphTrainer - INFO -   hit_rate@10: 0.048650
2025-11-22 21:19:21 - GraphTrainer - INFO -   ndcg@10: 0.025449
2025-11-22 21:19:21 - GraphTrainer - INFO -   map@10: 0.018846
2025-11-22 21:19:21 - GraphTrainer - INFO -   mrr@10: 0.019651
2025-11-22 21:19:21 - GraphTrainer - INFO -   precision@20: 0.003860
2025-11-22 21:19:21 - GraphTrainer - INFO -   recall@20: 0.073069
2025-11-22 21:19:21 - GraphTrainer - INFO -   hit_rate@20: 0.076729
2025-11-22 21:19:21 - GraphTrainer - INFO -   ndcg@20: 0.032275
2025-11-22 21:19:21 - GraphTrainer - INFO -   map@20: 0.020680
2025-11-22 21:19:21 - GraphTrainer - INFO -   mrr@20: 0.021556
2025-11-22 21:19:21 - GraphTrainer - INFO - 第 66 轮训练完成
2025-11-22 21:19:21 - GraphTrainer - INFO - train_loss: 0.311250
2025-11-22 21:19:21 - GraphTrainer - INFO - precision@5: 0.006295
2025-11-22 21:19:21 - GraphTrainer - INFO - recall@5: 0.029940
2025-11-22 21:19:21 - GraphTrainer - INFO - hit_rate@5: 0.031371
2025-11-22 21:19:21 - GraphTrainer - INFO - ndcg@5: 0.020165
2025-11-22 21:19:21 - GraphTrainer - INFO - map@5: 0.016711
2025-11-22 21:19:21 - GraphTrainer - INFO - mrr@5: 0.017374
2025-11-22 21:19:21 - GraphTrainer - INFO - precision@10: 0.004880
2025-11-22 21:19:21 - GraphTrainer - INFO - recall@10: 0.046190
2025-11-22 21:19:21 - GraphTrainer - INFO - hit_rate@10: 0.048650
2025-11-22 21:19:21 - GraphTrainer - INFO - ndcg@10: 0.025449
2025-11-22 21:19:21 - GraphTrainer - INFO - map@10: 0.018846
2025-11-22 21:19:21 - GraphTrainer - INFO - mrr@10: 0.019651
2025-11-22 21:19:21 - GraphTrainer - INFO - precision@20: 0.003860
2025-11-22 21:19:21 - GraphTrainer - INFO - recall@20: 0.073069
2025-11-22 21:19:21 - GraphTrainer - INFO - hit_rate@20: 0.076729
2025-11-22 21:19:21 - GraphTrainer - INFO - ndcg@20: 0.032275
2025-11-22 21:19:21 - GraphTrainer - INFO - map@20: 0.020680
2025-11-22 21:19:21 - GraphTrainer - INFO - mrr@20: 0.021556
2025-11-22 21:19:21 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:19:21 - GraphTrainer - INFO - ============================================================
2025-11-22 21:19:21 - GraphTrainer - INFO - 开始第 67/1000 轮训练
2025-11-22 21:19:21 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3138, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3126, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3034, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3204, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3191, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2991, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3039, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3007, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3170, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2970, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3035, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3231, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3153, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3107, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3038, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3048, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3136, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3118, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3007, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3065, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3028, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3059, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3084, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2903, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2973, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3177, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3153, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3060, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3130, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2965, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3105, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3025, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3028, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3122, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3192, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3233, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3077, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3036, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3037, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3165, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3086, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3051, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3002, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3468, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3067, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3105, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3207, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3028, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3162, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2979, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3026, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3074, device='cuda:0', grad_fn=<AddBackward0>)
The 66 training average loss: 0.3112503043536482
2025-11-22 21:19:32 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:19:32 - GraphTrainer - INFO -   precision@5: 0.006192
2025-11-22 21:19:32 - GraphTrainer - INFO -   recall@5: 0.029512
2025-11-22 21:19:32 - GraphTrainer - INFO -   hit_rate@5: 0.030908
2025-11-22 21:19:32 - GraphTrainer - INFO -   ndcg@5: 0.019325
2025-11-22 21:19:32 - GraphTrainer - INFO -   map@5: 0.015750
2025-11-22 21:19:32 - GraphTrainer - INFO -   mrr@5: 0.016434
2025-11-22 21:19:32 - GraphTrainer - INFO -   precision@10: 0.004963
2025-11-22 21:19:32 - GraphTrainer - INFO -   recall@10: 0.047381
2025-11-22 21:19:32 - GraphTrainer - INFO -   hit_rate@10: 0.049473
2025-11-22 21:19:32 - GraphTrainer - INFO -   ndcg@10: 0.025068
2025-11-22 21:19:32 - GraphTrainer - INFO -   map@10: 0.018060
2025-11-22 21:19:32 - GraphTrainer - INFO -   mrr@10: 0.018832
2025-11-22 21:19:32 - GraphTrainer - INFO -   precision@20: 0.003929
2025-11-22 21:19:32 - GraphTrainer - INFO -   recall@20: 0.074422
2025-11-22 21:19:32 - GraphTrainer - INFO -   hit_rate@20: 0.078169
2025-11-22 21:19:32 - GraphTrainer - INFO -   ndcg@20: 0.031963
2025-11-22 21:19:32 - GraphTrainer - INFO -   map@20: 0.019910
2025-11-22 21:19:32 - GraphTrainer - INFO -   mrr@20: 0.020792
2025-11-22 21:19:32 - GraphTrainer - INFO - 第 67 轮训练完成
2025-11-22 21:19:32 - GraphTrainer - INFO - train_loss: 0.310908
2025-11-22 21:19:32 - GraphTrainer - INFO - precision@5: 0.006192
2025-11-22 21:19:32 - GraphTrainer - INFO - recall@5: 0.029512
2025-11-22 21:19:32 - GraphTrainer - INFO - hit_rate@5: 0.030908
2025-11-22 21:19:32 - GraphTrainer - INFO - ndcg@5: 0.019325
2025-11-22 21:19:32 - GraphTrainer - INFO - map@5: 0.015750
2025-11-22 21:19:32 - GraphTrainer - INFO - mrr@5: 0.016434
2025-11-22 21:19:32 - GraphTrainer - INFO - precision@10: 0.004963
2025-11-22 21:19:32 - GraphTrainer - INFO - recall@10: 0.047381
2025-11-22 21:19:32 - GraphTrainer - INFO - hit_rate@10: 0.049473
2025-11-22 21:19:32 - GraphTrainer - INFO - ndcg@10: 0.025068
2025-11-22 21:19:32 - GraphTrainer - INFO - map@10: 0.018060
2025-11-22 21:19:32 - GraphTrainer - INFO - mrr@10: 0.018832
2025-11-22 21:19:32 - GraphTrainer - INFO - precision@20: 0.003929
2025-11-22 21:19:32 - GraphTrainer - INFO - recall@20: 0.074422
2025-11-22 21:19:32 - GraphTrainer - INFO - hit_rate@20: 0.078169
2025-11-22 21:19:32 - GraphTrainer - INFO - ndcg@20: 0.031963
2025-11-22 21:19:32 - GraphTrainer - INFO - map@20: 0.019910
2025-11-22 21:19:32 - GraphTrainer - INFO - mrr@20: 0.020792
2025-11-22 21:19:32 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:19:32 - GraphTrainer - INFO - ============================================================
2025-11-22 21:19:32 - GraphTrainer - INFO - 开始第 68/1000 轮训练
2025-11-22 21:19:32 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3212, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3175, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3233, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3304, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3246, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3093, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3144, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3089, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2975, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3170, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3167, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3217, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3126, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3046, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3117, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3035, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2939, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3071, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3067, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3002, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3152, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2983, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3192, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2961, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3020, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2717, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3020, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3234, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3061, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3007, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3223, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3072, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2999, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2996, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3202, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3208, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3234, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3235, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3107, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3082, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3087, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3161, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3115, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3103, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2870, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3032, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3059, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3072, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2965, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3077, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3116, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3193, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2842, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3257, device='cuda:0', grad_fn=<AddBackward0>)
The 67 training average loss: 0.3109082959849259
2025-11-22 21:19:43 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:19:43 - GraphTrainer - INFO -   precision@5: 0.006140
2025-11-22 21:19:43 - GraphTrainer - INFO -   recall@5: 0.029217
2025-11-22 21:19:43 - GraphTrainer - INFO -   hit_rate@5: 0.030599
2025-11-22 21:19:43 - GraphTrainer - INFO -   ndcg@5: 0.019164
2025-11-22 21:19:43 - GraphTrainer - INFO -   map@5: 0.015608
2025-11-22 21:19:43 - GraphTrainer - INFO -   mrr@5: 0.016311
2025-11-22 21:19:43 - GraphTrainer - INFO -   precision@10: 0.004932
2025-11-22 21:19:43 - GraphTrainer - INFO -   recall@10: 0.046732
2025-11-22 21:19:43 - GraphTrainer - INFO -   hit_rate@10: 0.049164
2025-11-22 21:19:43 - GraphTrainer - INFO -   ndcg@10: 0.024827
2025-11-22 21:19:43 - GraphTrainer - INFO -   map@10: 0.017882
2025-11-22 21:19:43 - GraphTrainer - INFO -   mrr@10: 0.018723
2025-11-22 21:19:43 - GraphTrainer - INFO -   precision@20: 0.003924
2025-11-22 21:19:43 - GraphTrainer - INFO -   recall@20: 0.074002
2025-11-22 21:19:43 - GraphTrainer - INFO -   hit_rate@20: 0.078015
2025-11-22 21:19:43 - GraphTrainer - INFO -   ndcg@20: 0.031754
2025-11-22 21:19:43 - GraphTrainer - INFO -   map@20: 0.019728
2025-11-22 21:19:43 - GraphTrainer - INFO -   mrr@20: 0.020673
2025-11-22 21:19:43 - GraphTrainer - INFO - 第 68 轮训练完成
2025-11-22 21:19:43 - GraphTrainer - INFO - train_loss: 0.310597
2025-11-22 21:19:43 - GraphTrainer - INFO - precision@5: 0.006140
2025-11-22 21:19:43 - GraphTrainer - INFO - recall@5: 0.029217
2025-11-22 21:19:43 - GraphTrainer - INFO - hit_rate@5: 0.030599
2025-11-22 21:19:43 - GraphTrainer - INFO - ndcg@5: 0.019164
2025-11-22 21:19:43 - GraphTrainer - INFO - map@5: 0.015608
2025-11-22 21:19:43 - GraphTrainer - INFO - mrr@5: 0.016311
2025-11-22 21:19:43 - GraphTrainer - INFO - precision@10: 0.004932
2025-11-22 21:19:43 - GraphTrainer - INFO - recall@10: 0.046732
2025-11-22 21:19:43 - GraphTrainer - INFO - hit_rate@10: 0.049164
2025-11-22 21:19:43 - GraphTrainer - INFO - ndcg@10: 0.024827
2025-11-22 21:19:43 - GraphTrainer - INFO - map@10: 0.017882
2025-11-22 21:19:43 - GraphTrainer - INFO - mrr@10: 0.018723
2025-11-22 21:19:43 - GraphTrainer - INFO - precision@20: 0.003924
2025-11-22 21:19:43 - GraphTrainer - INFO - recall@20: 0.074002
2025-11-22 21:19:43 - GraphTrainer - INFO - hit_rate@20: 0.078015
2025-11-22 21:19:43 - GraphTrainer - INFO - ndcg@20: 0.031754
2025-11-22 21:19:43 - GraphTrainer - INFO - map@20: 0.019728
2025-11-22 21:19:43 - GraphTrainer - INFO - mrr@20: 0.020673
2025-11-22 21:19:43 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:19:43 - GraphTrainer - INFO - ============================================================
2025-11-22 21:19:43 - GraphTrainer - INFO - 开始第 69/1000 轮训练
2025-11-22 21:19:43 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3125, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3202, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3008, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2898, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3087, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3087, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3135, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3244, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2920, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2920, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3082, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3167, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3081, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3206, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3093, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3159, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3126, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3182, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3137, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3170, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3064, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2985, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2943, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3219, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3051, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3068, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3037, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3086, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3001, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3059, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3177, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3069, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2952, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3024, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2958, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3154, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3067, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3160, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2998, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3167, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3098, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2964, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3198, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2994, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3051, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3200, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3088, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3129, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3078, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2953, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3058, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3088, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
The 68 training average loss: 0.31059745365175706
2025-11-22 21:19:54 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:19:54 - GraphTrainer - INFO -   precision@5: 0.006192
2025-11-22 21:19:54 - GraphTrainer - INFO -   recall@5: 0.029566
2025-11-22 21:19:54 - GraphTrainer - INFO -   hit_rate@5: 0.030856
2025-11-22 21:19:54 - GraphTrainer - INFO -   ndcg@5: 0.019454
2025-11-22 21:19:54 - GraphTrainer - INFO -   map@5: 0.015907
2025-11-22 21:19:54 - GraphTrainer - INFO -   mrr@5: 0.016590
2025-11-22 21:19:54 - GraphTrainer - INFO -   precision@10: 0.005060
2025-11-22 21:19:54 - GraphTrainer - INFO -   recall@10: 0.048044
2025-11-22 21:19:54 - GraphTrainer - INFO -   hit_rate@10: 0.050450
2025-11-22 21:19:54 - GraphTrainer - INFO -   ndcg@10: 0.025435
2025-11-22 21:19:54 - GraphTrainer - INFO -   map@10: 0.018309
2025-11-22 21:19:54 - GraphTrainer - INFO -   mrr@10: 0.019140
2025-11-22 21:19:54 - GraphTrainer - INFO -   precision@20: 0.003975
2025-11-22 21:19:54 - GraphTrainer - INFO -   recall@20: 0.075233
2025-11-22 21:19:54 - GraphTrainer - INFO -   hit_rate@20: 0.079198
2025-11-22 21:19:54 - GraphTrainer - INFO -   ndcg@20: 0.032285
2025-11-22 21:19:54 - GraphTrainer - INFO -   map@20: 0.020109
2025-11-22 21:19:54 - GraphTrainer - INFO -   mrr@20: 0.021042
2025-11-22 21:19:54 - GraphTrainer - INFO - 第 69 轮训练完成
2025-11-22 21:19:54 - GraphTrainer - INFO - train_loss: 0.308695
2025-11-22 21:19:54 - GraphTrainer - INFO - precision@5: 0.006192
2025-11-22 21:19:54 - GraphTrainer - INFO - recall@5: 0.029566
2025-11-22 21:19:54 - GraphTrainer - INFO - hit_rate@5: 0.030856
2025-11-22 21:19:54 - GraphTrainer - INFO - ndcg@5: 0.019454
2025-11-22 21:19:54 - GraphTrainer - INFO - map@5: 0.015907
2025-11-22 21:19:54 - GraphTrainer - INFO - mrr@5: 0.016590
2025-11-22 21:19:54 - GraphTrainer - INFO - precision@10: 0.005060
2025-11-22 21:19:54 - GraphTrainer - INFO - recall@10: 0.048044
2025-11-22 21:19:54 - GraphTrainer - INFO - hit_rate@10: 0.050450
2025-11-22 21:19:54 - GraphTrainer - INFO - ndcg@10: 0.025435
2025-11-22 21:19:54 - GraphTrainer - INFO - map@10: 0.018309
2025-11-22 21:19:54 - GraphTrainer - INFO - mrr@10: 0.019140
2025-11-22 21:19:54 - GraphTrainer - INFO - precision@20: 0.003975
2025-11-22 21:19:54 - GraphTrainer - INFO - recall@20: 0.075233
2025-11-22 21:19:54 - GraphTrainer - INFO - hit_rate@20: 0.079198
2025-11-22 21:19:54 - GraphTrainer - INFO - ndcg@20: 0.032285
2025-11-22 21:19:54 - GraphTrainer - INFO - map@20: 0.020109
2025-11-22 21:19:54 - GraphTrainer - INFO - mrr@20: 0.021042
2025-11-22 21:19:54 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:19:54 - GraphTrainer - INFO - ============================================================
2025-11-22 21:19:54 - GraphTrainer - INFO - 开始第 70/1000 轮训练
2025-11-22 21:19:54 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3130, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2880, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3018, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2885, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3016, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3036, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3136, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3198, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2959, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3128, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3211, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3080, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3131, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3076, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3141, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3091, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3111, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3042, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3134, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3254, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3494, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3035, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3092, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3110, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3064, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3127, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3094, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2951, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3043, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3119, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2961, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3109, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3146, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2926, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3146, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2965, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2874, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2944, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3047, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3067, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2944, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2975, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2882, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3233, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3056, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2980, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3141, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3290, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3118, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3136, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2959, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3132, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3012, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3032, device='cuda:0', grad_fn=<AddBackward0>)
The 69 training average loss: 0.3086951462359264
2025-11-22 21:20:05 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:20:05 - GraphTrainer - INFO -   precision@5: 0.006099
2025-11-22 21:20:05 - GraphTrainer - INFO -   recall@5: 0.029238
2025-11-22 21:20:05 - GraphTrainer - INFO -   hit_rate@5: 0.030496
2025-11-22 21:20:05 - GraphTrainer - INFO -   ndcg@5: 0.018939
2025-11-22 21:20:05 - GraphTrainer - INFO -   map@5: 0.015359
2025-11-22 21:20:05 - GraphTrainer - INFO -   mrr@5: 0.015903
2025-11-22 21:20:05 - GraphTrainer - INFO -   precision@10: 0.004839
2025-11-22 21:20:05 - GraphTrainer - INFO -   recall@10: 0.046272
2025-11-22 21:20:05 - GraphTrainer - INFO -   hit_rate@10: 0.048341
2025-11-22 21:20:05 - GraphTrainer - INFO -   ndcg@10: 0.024442
2025-11-22 21:20:05 - GraphTrainer - INFO -   map@10: 0.017576
2025-11-22 21:20:05 - GraphTrainer - INFO -   mrr@10: 0.018223
2025-11-22 21:20:05 - GraphTrainer - INFO -   precision@20: 0.003939
2025-11-22 21:20:05 - GraphTrainer - INFO -   recall@20: 0.074594
2025-11-22 21:20:05 - GraphTrainer - INFO -   hit_rate@20: 0.078323
2025-11-22 21:20:05 - GraphTrainer - INFO -   ndcg@20: 0.031658
2025-11-22 21:20:05 - GraphTrainer - INFO -   map@20: 0.019511
2025-11-22 21:20:05 - GraphTrainer - INFO -   mrr@20: 0.020259
2025-11-22 21:20:05 - GraphTrainer - INFO - 第 70 轮训练完成
2025-11-22 21:20:05 - GraphTrainer - INFO - train_loss: 0.311087
2025-11-22 21:20:05 - GraphTrainer - INFO - precision@5: 0.006099
2025-11-22 21:20:05 - GraphTrainer - INFO - recall@5: 0.029238
2025-11-22 21:20:05 - GraphTrainer - INFO - hit_rate@5: 0.030496
2025-11-22 21:20:05 - GraphTrainer - INFO - ndcg@5: 0.018939
2025-11-22 21:20:05 - GraphTrainer - INFO - map@5: 0.015359
2025-11-22 21:20:05 - GraphTrainer - INFO - mrr@5: 0.015903
2025-11-22 21:20:05 - GraphTrainer - INFO - precision@10: 0.004839
2025-11-22 21:20:05 - GraphTrainer - INFO - recall@10: 0.046272
2025-11-22 21:20:05 - GraphTrainer - INFO - hit_rate@10: 0.048341
2025-11-22 21:20:05 - GraphTrainer - INFO - ndcg@10: 0.024442
2025-11-22 21:20:05 - GraphTrainer - INFO - map@10: 0.017576
2025-11-22 21:20:05 - GraphTrainer - INFO - mrr@10: 0.018223
2025-11-22 21:20:05 - GraphTrainer - INFO - precision@20: 0.003939
2025-11-22 21:20:05 - GraphTrainer - INFO - recall@20: 0.074594
2025-11-22 21:20:05 - GraphTrainer - INFO - hit_rate@20: 0.078323
2025-11-22 21:20:05 - GraphTrainer - INFO - ndcg@20: 0.031658
2025-11-22 21:20:05 - GraphTrainer - INFO - map@20: 0.019511
2025-11-22 21:20:05 - GraphTrainer - INFO - mrr@20: 0.020259
2025-11-22 21:20:05 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:20:05 - GraphTrainer - INFO - 检查点已保存: Epoch 70 -> ./checkpoints/checkpoint_epoch_70.pth
2025-11-22 21:20:05 - GraphTrainer - INFO - ============================================================
2025-11-22 21:20:05 - GraphTrainer - INFO - 开始第 71/1000 轮训练
2025-11-22 21:20:05 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2788, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3170, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3031, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2884, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3061, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2845, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3072, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3000, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2961, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3009, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3025, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3011, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3060, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2963, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3045, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2993, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3235, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3000, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2884, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3223, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3183, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3246, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3133, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3203, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3208, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3282, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3194, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3207, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2923, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3125, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3160, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3013, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3120, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3223, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3133, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3033, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3190, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3263, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3104, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3152, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3146, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2846, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3161, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3141, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3005, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3154, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3049, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3035, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2878, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3061, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3103, device='cuda:0', grad_fn=<AddBackward0>)
The 70 training average loss: 0.31108719727088663
2025-11-22 21:20:16 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:20:16 - GraphTrainer - INFO -   precision@5: 0.005945
2025-11-22 21:20:16 - GraphTrainer - INFO -   recall@5: 0.028514
2025-11-22 21:20:16 - GraphTrainer - INFO -   hit_rate@5: 0.029725
2025-11-22 21:20:16 - GraphTrainer - INFO -   ndcg@5: 0.018353
2025-11-22 21:20:16 - GraphTrainer - INFO -   map@5: 0.014832
2025-11-22 21:20:16 - GraphTrainer - INFO -   mrr@5: 0.015353
2025-11-22 21:20:16 - GraphTrainer - INFO -   precision@10: 0.004886
2025-11-22 21:20:16 - GraphTrainer - INFO -   recall@10: 0.046476
2025-11-22 21:20:16 - GraphTrainer - INFO -   hit_rate@10: 0.048753
2025-11-22 21:20:16 - GraphTrainer - INFO -   ndcg@10: 0.024173
2025-11-22 21:20:16 - GraphTrainer - INFO -   map@10: 0.017171
2025-11-22 21:20:16 - GraphTrainer - INFO -   mrr@10: 0.017823
2025-11-22 21:20:16 - GraphTrainer - INFO -   precision@20: 0.003944
2025-11-22 21:20:16 - GraphTrainer - INFO -   recall@20: 0.074478
2025-11-22 21:20:16 - GraphTrainer - INFO -   hit_rate@20: 0.078478
2025-11-22 21:20:16 - GraphTrainer - INFO -   ndcg@20: 0.031338
2025-11-22 21:20:16 - GraphTrainer - INFO -   map@20: 0.019105
2025-11-22 21:20:16 - GraphTrainer - INFO -   mrr@20: 0.019870
2025-11-22 21:20:16 - GraphTrainer - INFO - 第 71 轮训练完成
2025-11-22 21:20:16 - GraphTrainer - INFO - train_loss: 0.310234
2025-11-22 21:20:16 - GraphTrainer - INFO - precision@5: 0.005945
2025-11-22 21:20:16 - GraphTrainer - INFO - recall@5: 0.028514
2025-11-22 21:20:16 - GraphTrainer - INFO - hit_rate@5: 0.029725
2025-11-22 21:20:16 - GraphTrainer - INFO - ndcg@5: 0.018353
2025-11-22 21:20:16 - GraphTrainer - INFO - map@5: 0.014832
2025-11-22 21:20:16 - GraphTrainer - INFO - mrr@5: 0.015353
2025-11-22 21:20:16 - GraphTrainer - INFO - precision@10: 0.004886
2025-11-22 21:20:16 - GraphTrainer - INFO - recall@10: 0.046476
2025-11-22 21:20:16 - GraphTrainer - INFO - hit_rate@10: 0.048753
2025-11-22 21:20:16 - GraphTrainer - INFO - ndcg@10: 0.024173
2025-11-22 21:20:16 - GraphTrainer - INFO - map@10: 0.017171
2025-11-22 21:20:16 - GraphTrainer - INFO - mrr@10: 0.017823
2025-11-22 21:20:16 - GraphTrainer - INFO - precision@20: 0.003944
2025-11-22 21:20:16 - GraphTrainer - INFO - recall@20: 0.074478
2025-11-22 21:20:16 - GraphTrainer - INFO - hit_rate@20: 0.078478
2025-11-22 21:20:16 - GraphTrainer - INFO - ndcg@20: 0.031338
2025-11-22 21:20:16 - GraphTrainer - INFO - map@20: 0.019105
2025-11-22 21:20:16 - GraphTrainer - INFO - mrr@20: 0.019870
2025-11-22 21:20:16 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:20:16 - GraphTrainer - INFO - ============================================================
2025-11-22 21:20:16 - GraphTrainer - INFO - 开始第 72/1000 轮训练
2025-11-22 21:20:16 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2906, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3057, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3179, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2978, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3138, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3069, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3175, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3077, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3021, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3088, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3108, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3150, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3205, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2893, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2911, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3200, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3020, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3055, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3124, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2981, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3194, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3130, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3119, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3156, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3062, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3075, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3175, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3163, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2975, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3189, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3222, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3012, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3164, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2816, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3142, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3121, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3103, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3179, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3196, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2874, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2965, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3182, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3042, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2986, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2926, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2909, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3158, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3099, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3030, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3049, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3092, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3299, device='cuda:0', grad_fn=<AddBackward0>)
The 71 training average loss: 0.31023438429010325
2025-11-22 21:20:27 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:20:27 - GraphTrainer - INFO -   precision@5: 0.006233
2025-11-22 21:20:27 - GraphTrainer - INFO -   recall@5: 0.029603
2025-11-22 21:20:27 - GraphTrainer - INFO -   hit_rate@5: 0.031113
2025-11-22 21:20:27 - GraphTrainer - INFO -   ndcg@5: 0.019470
2025-11-22 21:20:27 - GraphTrainer - INFO -   map@5: 0.015915
2025-11-22 21:20:27 - GraphTrainer - INFO -   mrr@5: 0.016563
2025-11-22 21:20:27 - GraphTrainer - INFO -   precision@10: 0.004999
2025-11-22 21:20:27 - GraphTrainer - INFO -   recall@10: 0.047317
2025-11-22 21:20:27 - GraphTrainer - INFO -   hit_rate@10: 0.049833
2025-11-22 21:20:27 - GraphTrainer - INFO -   ndcg@10: 0.025186
2025-11-22 21:20:27 - GraphTrainer - INFO -   map@10: 0.018206
2025-11-22 21:20:27 - GraphTrainer - INFO -   mrr@10: 0.018977
2025-11-22 21:20:27 - GraphTrainer - INFO -   precision@20: 0.003975
2025-11-22 21:20:27 - GraphTrainer - INFO -   recall@20: 0.075218
2025-11-22 21:20:27 - GraphTrainer - INFO -   hit_rate@20: 0.079043
2025-11-22 21:20:27 - GraphTrainer - INFO -   ndcg@20: 0.032223
2025-11-22 21:20:27 - GraphTrainer - INFO -   map@20: 0.020069
2025-11-22 21:20:27 - GraphTrainer - INFO -   mrr@20: 0.020923
2025-11-22 21:20:27 - GraphTrainer - INFO - 第 72 轮训练完成
2025-11-22 21:20:27 - GraphTrainer - INFO - train_loss: 0.307410
2025-11-22 21:20:27 - GraphTrainer - INFO - precision@5: 0.006233
2025-11-22 21:20:27 - GraphTrainer - INFO - recall@5: 0.029603
2025-11-22 21:20:27 - GraphTrainer - INFO - hit_rate@5: 0.031113
2025-11-22 21:20:27 - GraphTrainer - INFO - ndcg@5: 0.019470
2025-11-22 21:20:27 - GraphTrainer - INFO - map@5: 0.015915
2025-11-22 21:20:27 - GraphTrainer - INFO - mrr@5: 0.016563
2025-11-22 21:20:27 - GraphTrainer - INFO - precision@10: 0.004999
2025-11-22 21:20:27 - GraphTrainer - INFO - recall@10: 0.047317
2025-11-22 21:20:27 - GraphTrainer - INFO - hit_rate@10: 0.049833
2025-11-22 21:20:27 - GraphTrainer - INFO - ndcg@10: 0.025186
2025-11-22 21:20:27 - GraphTrainer - INFO - map@10: 0.018206
2025-11-22 21:20:27 - GraphTrainer - INFO - mrr@10: 0.018977
2025-11-22 21:20:27 - GraphTrainer - INFO - precision@20: 0.003975
2025-11-22 21:20:27 - GraphTrainer - INFO - recall@20: 0.075218
2025-11-22 21:20:27 - GraphTrainer - INFO - hit_rate@20: 0.079043
2025-11-22 21:20:27 - GraphTrainer - INFO - ndcg@20: 0.032223
2025-11-22 21:20:27 - GraphTrainer - INFO - map@20: 0.020069
2025-11-22 21:20:27 - GraphTrainer - INFO - mrr@20: 0.020923
2025-11-22 21:20:27 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:20:27 - GraphTrainer - INFO - ============================================================
2025-11-22 21:20:27 - GraphTrainer - INFO - 开始第 73/1000 轮训练
2025-11-22 21:20:27 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2938, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3051, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2887, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2955, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3571, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3071, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2878, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3233, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3097, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3049, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3191, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2988, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3095, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3178, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2922, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3207, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2925, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2965, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2941, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2919, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2951, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3126, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2945, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3026, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3048, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2846, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3007, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3060, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3051, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3202, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3263, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3032, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2865, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3154, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2862, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3198, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2860, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3017, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3065, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3134, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3099, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3183, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3107, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3058, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3036, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3079, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3139, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2891, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3232, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3116, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3281, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3193, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3127, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3192, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3245, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3054, device='cuda:0', grad_fn=<AddBackward0>)
The 72 training average loss: 0.30740978748633946
2025-11-22 21:20:38 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:20:38 - GraphTrainer - INFO -   precision@5: 0.006398
2025-11-22 21:20:38 - GraphTrainer - INFO -   recall@5: 0.030778
2025-11-22 21:20:38 - GraphTrainer - INFO -   hit_rate@5: 0.031988
2025-11-22 21:20:38 - GraphTrainer - INFO -   ndcg@5: 0.019822
2025-11-22 21:20:38 - GraphTrainer - INFO -   map@5: 0.016043
2025-11-22 21:20:38 - GraphTrainer - INFO -   mrr@5: 0.016601
2025-11-22 21:20:38 - GraphTrainer - INFO -   precision@10: 0.004988
2025-11-22 21:20:38 - GraphTrainer - INFO -   recall@10: 0.047527
2025-11-22 21:20:38 - GraphTrainer - INFO -   hit_rate@10: 0.049833
2025-11-22 21:20:38 - GraphTrainer - INFO -   ndcg@10: 0.025241
2025-11-22 21:20:38 - GraphTrainer - INFO -   map@10: 0.018210
2025-11-22 21:20:38 - GraphTrainer - INFO -   mrr@10: 0.018907
2025-11-22 21:20:38 - GraphTrainer - INFO -   precision@20: 0.004004
2025-11-22 21:20:38 - GraphTrainer - INFO -   recall@20: 0.075710
2025-11-22 21:20:38 - GraphTrainer - INFO -   hit_rate@20: 0.079609
2025-11-22 21:20:38 - GraphTrainer - INFO -   ndcg@20: 0.032402
2025-11-22 21:20:38 - GraphTrainer - INFO -   map@20: 0.020123
2025-11-22 21:20:38 - GraphTrainer - INFO -   mrr@20: 0.020920
2025-11-22 21:20:38 - GraphTrainer - INFO - 第 73 轮训练完成
2025-11-22 21:20:38 - GraphTrainer - INFO - train_loss: 0.302942
2025-11-22 21:20:38 - GraphTrainer - INFO - precision@5: 0.006398
2025-11-22 21:20:38 - GraphTrainer - INFO - recall@5: 0.030778
2025-11-22 21:20:38 - GraphTrainer - INFO - hit_rate@5: 0.031988
2025-11-22 21:20:38 - GraphTrainer - INFO - ndcg@5: 0.019822
2025-11-22 21:20:38 - GraphTrainer - INFO - map@5: 0.016043
2025-11-22 21:20:38 - GraphTrainer - INFO - mrr@5: 0.016601
2025-11-22 21:20:38 - GraphTrainer - INFO - precision@10: 0.004988
2025-11-22 21:20:38 - GraphTrainer - INFO - recall@10: 0.047527
2025-11-22 21:20:38 - GraphTrainer - INFO - hit_rate@10: 0.049833
2025-11-22 21:20:38 - GraphTrainer - INFO - ndcg@10: 0.025241
2025-11-22 21:20:38 - GraphTrainer - INFO - map@10: 0.018210
2025-11-22 21:20:38 - GraphTrainer - INFO - mrr@10: 0.018907
2025-11-22 21:20:38 - GraphTrainer - INFO - precision@20: 0.004004
2025-11-22 21:20:38 - GraphTrainer - INFO - recall@20: 0.075710
2025-11-22 21:20:38 - GraphTrainer - INFO - hit_rate@20: 0.079609
2025-11-22 21:20:38 - GraphTrainer - INFO - ndcg@20: 0.032402
2025-11-22 21:20:38 - GraphTrainer - INFO - map@20: 0.020123
2025-11-22 21:20:38 - GraphTrainer - INFO - mrr@20: 0.020920
2025-11-22 21:20:38 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:20:38 - GraphTrainer - INFO - ============================================================
2025-11-22 21:20:38 - GraphTrainer - INFO - 开始第 74/1000 轮训练
2025-11-22 21:20:38 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3000, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3023, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2976, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3136, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3164, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3213, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3169, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2956, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3156, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2979, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2976, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3086, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2929, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3043, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3303, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2994, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3099, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2851, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2880, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3209, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3063, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2831, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3152, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3087, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3069, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2901, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2993, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3027, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2999, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3135, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2852, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3038, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3019, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2986, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2947, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3038, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2928, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3079, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2863, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2925, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2962, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3276, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2864, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2998, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2792, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3180, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3115, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2931, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3036, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3106, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3031, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2985, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3213, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2805, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3222, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2955, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2924, device='cuda:0', grad_fn=<AddBackward0>)
The 73 training average loss: 0.30294178529032345
2025-11-22 21:20:48 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:20:48 - GraphTrainer - INFO -   precision@5: 0.005966
2025-11-22 21:20:48 - GraphTrainer - INFO -   recall@5: 0.028734
2025-11-22 21:20:48 - GraphTrainer - INFO -   hit_rate@5: 0.029828
2025-11-22 21:20:48 - GraphTrainer - INFO -   ndcg@5: 0.018941
2025-11-22 21:20:48 - GraphTrainer - INFO -   map@5: 0.015538
2025-11-22 21:20:48 - GraphTrainer - INFO -   mrr@5: 0.016086
2025-11-22 21:20:48 - GraphTrainer - INFO -   precision@10: 0.004875
2025-11-22 21:20:48 - GraphTrainer - INFO -   recall@10: 0.046622
2025-11-22 21:20:48 - GraphTrainer - INFO -   hit_rate@10: 0.048701
2025-11-22 21:20:48 - GraphTrainer - INFO -   ndcg@10: 0.024746
2025-11-22 21:20:48 - GraphTrainer - INFO -   map@10: 0.017880
2025-11-22 21:20:48 - GraphTrainer - INFO -   mrr@10: 0.018554
2025-11-22 21:20:48 - GraphTrainer - INFO -   precision@20: 0.003849
2025-11-22 21:20:48 - GraphTrainer - INFO -   recall@20: 0.073381
2025-11-22 21:20:48 - GraphTrainer - INFO -   hit_rate@20: 0.076678
2025-11-22 21:20:48 - GraphTrainer - INFO -   ndcg@20: 0.031565
2025-11-22 21:20:48 - GraphTrainer - INFO -   map@20: 0.019725
2025-11-22 21:20:48 - GraphTrainer - INFO -   mrr@20: 0.020475
2025-11-22 21:20:48 - GraphTrainer - INFO - 第 74 轮训练完成
2025-11-22 21:20:48 - GraphTrainer - INFO - train_loss: 0.304076
2025-11-22 21:20:48 - GraphTrainer - INFO - precision@5: 0.005966
2025-11-22 21:20:48 - GraphTrainer - INFO - recall@5: 0.028734
2025-11-22 21:20:48 - GraphTrainer - INFO - hit_rate@5: 0.029828
2025-11-22 21:20:48 - GraphTrainer - INFO - ndcg@5: 0.018941
2025-11-22 21:20:48 - GraphTrainer - INFO - map@5: 0.015538
2025-11-22 21:20:48 - GraphTrainer - INFO - mrr@5: 0.016086
2025-11-22 21:20:48 - GraphTrainer - INFO - precision@10: 0.004875
2025-11-22 21:20:48 - GraphTrainer - INFO - recall@10: 0.046622
2025-11-22 21:20:48 - GraphTrainer - INFO - hit_rate@10: 0.048701
2025-11-22 21:20:48 - GraphTrainer - INFO - ndcg@10: 0.024746
2025-11-22 21:20:48 - GraphTrainer - INFO - map@10: 0.017880
2025-11-22 21:20:48 - GraphTrainer - INFO - mrr@10: 0.018554
2025-11-22 21:20:48 - GraphTrainer - INFO - precision@20: 0.003849
2025-11-22 21:20:48 - GraphTrainer - INFO - recall@20: 0.073381
2025-11-22 21:20:48 - GraphTrainer - INFO - hit_rate@20: 0.076678
2025-11-22 21:20:48 - GraphTrainer - INFO - ndcg@20: 0.031565
2025-11-22 21:20:48 - GraphTrainer - INFO - map@20: 0.019725
2025-11-22 21:20:48 - GraphTrainer - INFO - mrr@20: 0.020475
2025-11-22 21:20:48 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:20:48 - GraphTrainer - INFO - ============================================================
2025-11-22 21:20:48 - GraphTrainer - INFO - 开始第 75/1000 轮训练
2025-11-22 21:20:48 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3057, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3067, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2959, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3108, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3202, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2805, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3192, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3065, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3098, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2977, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2931, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3227, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2758, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2838, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2959, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3028, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3114, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2893, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3044, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2992, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3067, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3050, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2961, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3094, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2991, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3180, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3154, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3062, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3148, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3138, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2888, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3033, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2765, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2956, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3118, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3433, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3122, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2916, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2980, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3006, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3259, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3204, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2974, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3034, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2935, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2958, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2882, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3090, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3155, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2911, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3000, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2985, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3162, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3041, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3009, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2987, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3027, device='cuda:0', grad_fn=<AddBackward0>)
The 74 training average loss: 0.30407561875622846
2025-11-22 21:21:00 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:21:00 - GraphTrainer - INFO -   precision@5: 0.006192
2025-11-22 21:21:00 - GraphTrainer - INFO -   recall@5: 0.029635
2025-11-22 21:21:00 - GraphTrainer - INFO -   hit_rate@5: 0.030959
2025-11-22 21:21:00 - GraphTrainer - INFO -   ndcg@5: 0.019269
2025-11-22 21:21:00 - GraphTrainer - INFO -   map@5: 0.015669
2025-11-22 21:21:00 - GraphTrainer - INFO -   mrr@5: 0.016234
2025-11-22 21:21:00 - GraphTrainer - INFO -   precision@10: 0.005009
2025-11-22 21:21:00 - GraphTrainer - INFO -   recall@10: 0.047418
2025-11-22 21:21:00 - GraphTrainer - INFO -   hit_rate@10: 0.050039
2025-11-22 21:21:00 - GraphTrainer - INFO -   ndcg@10: 0.025022
2025-11-22 21:21:00 - GraphTrainer - INFO -   map@10: 0.017965
2025-11-22 21:21:00 - GraphTrainer - INFO -   mrr@10: 0.018687
2025-11-22 21:21:00 - GraphTrainer - INFO -   precision@20: 0.003950
2025-11-22 21:21:00 - GraphTrainer - INFO -   recall@20: 0.074506
2025-11-22 21:21:00 - GraphTrainer - INFO -   hit_rate@20: 0.078529
2025-11-22 21:21:00 - GraphTrainer - INFO -   ndcg@20: 0.031913
2025-11-22 21:21:00 - GraphTrainer - INFO -   map@20: 0.019814
2025-11-22 21:21:00 - GraphTrainer - INFO -   mrr@20: 0.020618
2025-11-22 21:21:00 - GraphTrainer - INFO - 第 75 轮训练完成
2025-11-22 21:21:00 - GraphTrainer - INFO - train_loss: 0.303968
2025-11-22 21:21:00 - GraphTrainer - INFO - precision@5: 0.006192
2025-11-22 21:21:00 - GraphTrainer - INFO - recall@5: 0.029635
2025-11-22 21:21:00 - GraphTrainer - INFO - hit_rate@5: 0.030959
2025-11-22 21:21:00 - GraphTrainer - INFO - ndcg@5: 0.019269
2025-11-22 21:21:00 - GraphTrainer - INFO - map@5: 0.015669
2025-11-22 21:21:00 - GraphTrainer - INFO - mrr@5: 0.016234
2025-11-22 21:21:00 - GraphTrainer - INFO - precision@10: 0.005009
2025-11-22 21:21:00 - GraphTrainer - INFO - recall@10: 0.047418
2025-11-22 21:21:00 - GraphTrainer - INFO - hit_rate@10: 0.050039
2025-11-22 21:21:00 - GraphTrainer - INFO - ndcg@10: 0.025022
2025-11-22 21:21:00 - GraphTrainer - INFO - map@10: 0.017965
2025-11-22 21:21:00 - GraphTrainer - INFO - mrr@10: 0.018687
2025-11-22 21:21:00 - GraphTrainer - INFO - precision@20: 0.003950
2025-11-22 21:21:00 - GraphTrainer - INFO - recall@20: 0.074506
2025-11-22 21:21:00 - GraphTrainer - INFO - hit_rate@20: 0.078529
2025-11-22 21:21:00 - GraphTrainer - INFO - ndcg@20: 0.031913
2025-11-22 21:21:00 - GraphTrainer - INFO - map@20: 0.019814
2025-11-22 21:21:00 - GraphTrainer - INFO - mrr@20: 0.020618
2025-11-22 21:21:00 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:21:00 - GraphTrainer - INFO - ============================================================
2025-11-22 21:21:00 - GraphTrainer - INFO - 开始第 76/1000 轮训练
2025-11-22 21:21:00 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2781, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2924, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2946, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3066, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3047, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2914, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3202, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2832, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2952, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3100, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2923, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2742, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2891, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3167, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2937, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3098, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2962, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3084, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3094, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3047, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3110, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3084, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3011, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2867, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3155, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2939, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3111, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3183, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3173, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2894, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3228, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2942, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3232, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3123, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2946, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2871, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2831, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3095, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3013, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2820, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3106, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3168, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2925, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2934, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2820, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3019, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2959, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3290, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3104, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3198, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2961, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3170, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2997, device='cuda:0', grad_fn=<AddBackward0>)
The 75 training average loss: 0.3039680565225667
2025-11-22 21:21:11 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:21:11 - GraphTrainer - INFO -   precision@5: 0.006305
2025-11-22 21:21:11 - GraphTrainer - INFO -   recall@5: 0.029989
2025-11-22 21:21:11 - GraphTrainer - INFO -   hit_rate@5: 0.031525
2025-11-22 21:21:11 - GraphTrainer - INFO -   ndcg@5: 0.019730
2025-11-22 21:21:11 - GraphTrainer - INFO -   map@5: 0.016087
2025-11-22 21:21:11 - GraphTrainer - INFO -   mrr@5: 0.016854
2025-11-22 21:21:11 - GraphTrainer - INFO -   precision@10: 0.005040
2025-11-22 21:21:11 - GraphTrainer - INFO -   recall@10: 0.047753
2025-11-22 21:21:11 - GraphTrainer - INFO -   hit_rate@10: 0.050193
2025-11-22 21:21:11 - GraphTrainer - INFO -   ndcg@10: 0.025489
2025-11-22 21:21:11 - GraphTrainer - INFO -   map@10: 0.018413
2025-11-22 21:21:11 - GraphTrainer - INFO -   mrr@10: 0.019287
2025-11-22 21:21:11 - GraphTrainer - INFO -   precision@20: 0.003993
2025-11-22 21:21:11 - GraphTrainer - INFO -   recall@20: 0.075489
2025-11-22 21:21:11 - GraphTrainer - INFO -   hit_rate@20: 0.079455
2025-11-22 21:21:11 - GraphTrainer - INFO -   ndcg@20: 0.032511
2025-11-22 21:21:11 - GraphTrainer - INFO -   map@20: 0.020279
2025-11-22 21:21:11 - GraphTrainer - INFO -   mrr@20: 0.021251
2025-11-22 21:21:11 - GraphTrainer - INFO - 第 76 轮训练完成
2025-11-22 21:21:11 - GraphTrainer - INFO - train_loss: 0.306250
2025-11-22 21:21:11 - GraphTrainer - INFO - precision@5: 0.006305
2025-11-22 21:21:11 - GraphTrainer - INFO - recall@5: 0.029989
2025-11-22 21:21:11 - GraphTrainer - INFO - hit_rate@5: 0.031525
2025-11-22 21:21:11 - GraphTrainer - INFO - ndcg@5: 0.019730
2025-11-22 21:21:11 - GraphTrainer - INFO - map@5: 0.016087
2025-11-22 21:21:11 - GraphTrainer - INFO - mrr@5: 0.016854
2025-11-22 21:21:11 - GraphTrainer - INFO - precision@10: 0.005040
2025-11-22 21:21:11 - GraphTrainer - INFO - recall@10: 0.047753
2025-11-22 21:21:11 - GraphTrainer - INFO - hit_rate@10: 0.050193
2025-11-22 21:21:11 - GraphTrainer - INFO - ndcg@10: 0.025489
2025-11-22 21:21:11 - GraphTrainer - INFO - map@10: 0.018413
2025-11-22 21:21:11 - GraphTrainer - INFO - mrr@10: 0.019287
2025-11-22 21:21:11 - GraphTrainer - INFO - precision@20: 0.003993
2025-11-22 21:21:11 - GraphTrainer - INFO - recall@20: 0.075489
2025-11-22 21:21:11 - GraphTrainer - INFO - hit_rate@20: 0.079455
2025-11-22 21:21:11 - GraphTrainer - INFO - ndcg@20: 0.032511
2025-11-22 21:21:11 - GraphTrainer - INFO - map@20: 0.020279
2025-11-22 21:21:11 - GraphTrainer - INFO - mrr@20: 0.021251
2025-11-22 21:21:11 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:21:11 - GraphTrainer - INFO - ============================================================
2025-11-22 21:21:11 - GraphTrainer - INFO - 开始第 77/1000 轮训练
2025-11-22 21:21:11 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3183, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3092, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2970, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3040, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2923, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2997, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3312, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3111, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3161, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3084, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2872, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3071, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3062, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3212, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3108, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3057, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3065, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2972, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2844, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2995, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3009, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2872, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2905, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3031, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3312, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3083, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3176, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2955, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2938, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3154, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3070, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2984, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3204, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3178, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3004, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3052, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3153, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2885, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2937, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3121, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2956, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3072, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3013, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3073, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3039, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2932, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3075, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2837, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3051, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3106, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2985, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3179, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3150, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3297, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2861, device='cuda:0', grad_fn=<AddBackward0>)
The 76 training average loss: 0.30624987185001373
2025-11-22 21:21:22 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:21:22 - GraphTrainer - INFO -   precision@5: 0.005996
2025-11-22 21:21:22 - GraphTrainer - INFO -   recall@5: 0.028642
2025-11-22 21:21:22 - GraphTrainer - INFO -   hit_rate@5: 0.029931
2025-11-22 21:21:22 - GraphTrainer - INFO -   ndcg@5: 0.018625
2025-11-22 21:21:22 - GraphTrainer - INFO -   map@5: 0.015145
2025-11-22 21:21:22 - GraphTrainer - INFO -   mrr@5: 0.015686
2025-11-22 21:21:22 - GraphTrainer - INFO -   precision@10: 0.004860
2025-11-22 21:21:22 - GraphTrainer - INFO -   recall@10: 0.046169
2025-11-22 21:21:22 - GraphTrainer - INFO -   hit_rate@10: 0.048496
2025-11-22 21:21:22 - GraphTrainer - INFO -   ndcg@10: 0.024315
2025-11-22 21:21:22 - GraphTrainer - INFO -   map@10: 0.017442
2025-11-22 21:21:22 - GraphTrainer - INFO -   mrr@10: 0.018122
2025-11-22 21:21:22 - GraphTrainer - INFO -   precision@20: 0.004001
2025-11-22 21:21:22 - GraphTrainer - INFO -   recall@20: 0.075964
2025-11-22 21:21:22 - GraphTrainer - INFO -   hit_rate@20: 0.079712
2025-11-22 21:21:22 - GraphTrainer - INFO -   ndcg@20: 0.031870
2025-11-22 21:21:22 - GraphTrainer - INFO -   map@20: 0.019464
2025-11-22 21:21:22 - GraphTrainer - INFO -   mrr@20: 0.020237
2025-11-22 21:21:22 - GraphTrainer - INFO - 第 77 轮训练完成
2025-11-22 21:21:22 - GraphTrainer - INFO - train_loss: 0.304327
2025-11-22 21:21:22 - GraphTrainer - INFO - precision@5: 0.005996
2025-11-22 21:21:22 - GraphTrainer - INFO - recall@5: 0.028642
2025-11-22 21:21:22 - GraphTrainer - INFO - hit_rate@5: 0.029931
2025-11-22 21:21:22 - GraphTrainer - INFO - ndcg@5: 0.018625
2025-11-22 21:21:22 - GraphTrainer - INFO - map@5: 0.015145
2025-11-22 21:21:22 - GraphTrainer - INFO - mrr@5: 0.015686
2025-11-22 21:21:22 - GraphTrainer - INFO - precision@10: 0.004860
2025-11-22 21:21:22 - GraphTrainer - INFO - recall@10: 0.046169
2025-11-22 21:21:22 - GraphTrainer - INFO - hit_rate@10: 0.048496
2025-11-22 21:21:22 - GraphTrainer - INFO - ndcg@10: 0.024315
2025-11-22 21:21:22 - GraphTrainer - INFO - map@10: 0.017442
2025-11-22 21:21:22 - GraphTrainer - INFO - mrr@10: 0.018122
2025-11-22 21:21:22 - GraphTrainer - INFO - precision@20: 0.004001
2025-11-22 21:21:22 - GraphTrainer - INFO - recall@20: 0.075964
2025-11-22 21:21:22 - GraphTrainer - INFO - hit_rate@20: 0.079712
2025-11-22 21:21:22 - GraphTrainer - INFO - ndcg@20: 0.031870
2025-11-22 21:21:22 - GraphTrainer - INFO - map@20: 0.019464
2025-11-22 21:21:22 - GraphTrainer - INFO - mrr@20: 0.020237
2025-11-22 21:21:22 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:21:22 - GraphTrainer - INFO - ============================================================
2025-11-22 21:21:22 - GraphTrainer - INFO - 开始第 78/1000 轮训练
2025-11-22 21:21:22 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2917, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2961, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2761, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3127, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3073, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2996, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2793, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3146, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2867, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2898, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2956, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3120, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2892, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3240, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3159, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2993, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3066, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3140, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3184, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2880, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3001, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3090, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3000, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3227, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3112, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2886, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2895, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2989, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3212, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2874, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3103, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3152, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2967, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3087, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3051, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2972, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3060, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3128, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2980, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3046, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3071, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2913, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3188, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3261, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2976, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2960, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3117, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2881, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3062, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2917, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3136, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3091, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3064, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2890, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3085, device='cuda:0', grad_fn=<AddBackward0>)
The 77 training average loss: 0.3043272813846325
2025-11-22 21:21:32 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:21:32 - GraphTrainer - INFO -   precision@5: 0.006079
2025-11-22 21:21:32 - GraphTrainer - INFO -   recall@5: 0.029204
2025-11-22 21:21:32 - GraphTrainer - INFO -   hit_rate@5: 0.030393
2025-11-22 21:21:32 - GraphTrainer - INFO -   ndcg@5: 0.018508
2025-11-22 21:21:32 - GraphTrainer - INFO -   map@5: 0.014822
2025-11-22 21:21:32 - GraphTrainer - INFO -   mrr@5: 0.015343
2025-11-22 21:21:32 - GraphTrainer - INFO -   precision@10: 0.004906
2025-11-22 21:21:32 - GraphTrainer - INFO -   recall@10: 0.046861
2025-11-22 21:21:32 - GraphTrainer - INFO -   hit_rate@10: 0.049010
2025-11-22 21:21:32 - GraphTrainer - INFO -   ndcg@10: 0.024244
2025-11-22 21:21:32 - GraphTrainer - INFO -   map@10: 0.017142
2025-11-22 21:21:32 - GraphTrainer - INFO -   mrr@10: 0.017797
2025-11-22 21:21:32 - GraphTrainer - INFO -   precision@20: 0.003998
2025-11-22 21:21:32 - GraphTrainer - INFO -   recall@20: 0.075919
2025-11-22 21:21:32 - GraphTrainer - INFO -   hit_rate@20: 0.079763
2025-11-22 21:21:32 - GraphTrainer - INFO -   ndcg@20: 0.031592
2025-11-22 21:21:32 - GraphTrainer - INFO -   map@20: 0.019085
2025-11-22 21:21:32 - GraphTrainer - INFO -   mrr@20: 0.019857
2025-11-22 21:21:32 - GraphTrainer - INFO - 第 78 轮训练完成
2025-11-22 21:21:32 - GraphTrainer - INFO - train_loss: 0.302265
2025-11-22 21:21:32 - GraphTrainer - INFO - precision@5: 0.006079
2025-11-22 21:21:32 - GraphTrainer - INFO - recall@5: 0.029204
2025-11-22 21:21:32 - GraphTrainer - INFO - hit_rate@5: 0.030393
2025-11-22 21:21:32 - GraphTrainer - INFO - ndcg@5: 0.018508
2025-11-22 21:21:32 - GraphTrainer - INFO - map@5: 0.014822
2025-11-22 21:21:32 - GraphTrainer - INFO - mrr@5: 0.015343
2025-11-22 21:21:32 - GraphTrainer - INFO - precision@10: 0.004906
2025-11-22 21:21:32 - GraphTrainer - INFO - recall@10: 0.046861
2025-11-22 21:21:32 - GraphTrainer - INFO - hit_rate@10: 0.049010
2025-11-22 21:21:32 - GraphTrainer - INFO - ndcg@10: 0.024244
2025-11-22 21:21:32 - GraphTrainer - INFO - map@10: 0.017142
2025-11-22 21:21:32 - GraphTrainer - INFO - mrr@10: 0.017797
2025-11-22 21:21:32 - GraphTrainer - INFO - precision@20: 0.003998
2025-11-22 21:21:32 - GraphTrainer - INFO - recall@20: 0.075919
2025-11-22 21:21:32 - GraphTrainer - INFO - hit_rate@20: 0.079763
2025-11-22 21:21:32 - GraphTrainer - INFO - ndcg@20: 0.031592
2025-11-22 21:21:32 - GraphTrainer - INFO - map@20: 0.019085
2025-11-22 21:21:32 - GraphTrainer - INFO - mrr@20: 0.019857
2025-11-22 21:21:32 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:21:32 - GraphTrainer - INFO - ============================================================
2025-11-22 21:21:32 - GraphTrainer - INFO - 开始第 79/1000 轮训练
2025-11-22 21:21:32 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3016, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2818, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2966, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3241, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2978, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3113, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3023, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3205, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2850, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3048, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2880, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2965, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3137, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3103, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2859, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3012, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2946, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3010, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2969, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3130, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2768, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2869, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3069, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3127, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2992, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3053, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2982, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2863, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2993, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2978, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3191, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2880, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2952, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3193, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2935, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2968, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3208, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3057, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3157, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3005, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2934, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2865, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3209, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3178, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2875, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2985, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2993, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3000, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2854, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2999, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2892, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3180, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2894, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2987, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2933, device='cuda:0', grad_fn=<AddBackward0>)
The 78 training average loss: 0.3022646898853368
2025-11-22 21:21:43 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:21:43 - GraphTrainer - INFO -   precision@5: 0.006284
2025-11-22 21:21:43 - GraphTrainer - INFO -   recall@5: 0.029867
2025-11-22 21:21:43 - GraphTrainer - INFO -   hit_rate@5: 0.031422
2025-11-22 21:21:43 - GraphTrainer - INFO -   ndcg@5: 0.019788
2025-11-22 21:21:43 - GraphTrainer - INFO -   map@5: 0.016215
2025-11-22 21:21:43 - GraphTrainer - INFO -   mrr@5: 0.016954
2025-11-22 21:21:43 - GraphTrainer - INFO -   precision@10: 0.005055
2025-11-22 21:21:43 - GraphTrainer - INFO -   recall@10: 0.047922
2025-11-22 21:21:43 - GraphTrainer - INFO -   hit_rate@10: 0.050399
2025-11-22 21:21:43 - GraphTrainer - INFO -   ndcg@10: 0.025655
2025-11-22 21:21:43 - GraphTrainer - INFO -   map@10: 0.018598
2025-11-22 21:21:43 - GraphTrainer - INFO -   mrr@10: 0.019452
2025-11-22 21:21:43 - GraphTrainer - INFO -   precision@20: 0.004014
2025-11-22 21:21:43 - GraphTrainer - INFO -   recall@20: 0.075821
2025-11-22 21:21:43 - GraphTrainer - INFO -   hit_rate@20: 0.079866
2025-11-22 21:21:43 - GraphTrainer - INFO -   ndcg@20: 0.032733
2025-11-22 21:21:43 - GraphTrainer - INFO -   map@20: 0.020482
2025-11-22 21:21:43 - GraphTrainer - INFO -   mrr@20: 0.021445
2025-11-22 21:21:43 - GraphTrainer - INFO - 第 79 轮训练完成
2025-11-22 21:21:43 - GraphTrainer - INFO - train_loss: 0.300086
2025-11-22 21:21:43 - GraphTrainer - INFO - precision@5: 0.006284
2025-11-22 21:21:43 - GraphTrainer - INFO - recall@5: 0.029867
2025-11-22 21:21:43 - GraphTrainer - INFO - hit_rate@5: 0.031422
2025-11-22 21:21:43 - GraphTrainer - INFO - ndcg@5: 0.019788
2025-11-22 21:21:43 - GraphTrainer - INFO - map@5: 0.016215
2025-11-22 21:21:43 - GraphTrainer - INFO - mrr@5: 0.016954
2025-11-22 21:21:43 - GraphTrainer - INFO - precision@10: 0.005055
2025-11-22 21:21:43 - GraphTrainer - INFO - recall@10: 0.047922
2025-11-22 21:21:43 - GraphTrainer - INFO - hit_rate@10: 0.050399
2025-11-22 21:21:43 - GraphTrainer - INFO - ndcg@10: 0.025655
2025-11-22 21:21:43 - GraphTrainer - INFO - map@10: 0.018598
2025-11-22 21:21:43 - GraphTrainer - INFO - mrr@10: 0.019452
2025-11-22 21:21:43 - GraphTrainer - INFO - precision@20: 0.004014
2025-11-22 21:21:43 - GraphTrainer - INFO - recall@20: 0.075821
2025-11-22 21:21:43 - GraphTrainer - INFO - hit_rate@20: 0.079866
2025-11-22 21:21:43 - GraphTrainer - INFO - ndcg@20: 0.032733
2025-11-22 21:21:43 - GraphTrainer - INFO - map@20: 0.020482
2025-11-22 21:21:43 - GraphTrainer - INFO - mrr@20: 0.021445
2025-11-22 21:21:43 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:21:43 - GraphTrainer - INFO - ============================================================
2025-11-22 21:21:43 - GraphTrainer - INFO - 开始第 80/1000 轮训练
2025-11-22 21:21:43 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2743, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3025, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2904, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2878, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3202, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3071, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3089, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3015, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2896, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3198, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2938, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3019, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2868, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2798, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3236, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3094, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2975, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3209, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2853, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2981, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2852, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2894, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3137, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2973, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2992, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2806, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3196, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2931, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3025, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3177, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2819, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2843, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3070, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3194, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2641, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2927, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2971, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2871, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2953, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3154, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2939, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3031, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2857, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3105, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2773, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2978, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3025, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2921, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3022, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3217, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3044, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3155, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3182, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3066, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2889, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3089, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3037, device='cuda:0', grad_fn=<AddBackward0>)
The 79 training average loss: 0.30008566430930433
2025-11-22 21:21:54 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:21:54 - GraphTrainer - INFO -   precision@5: 0.006315
2025-11-22 21:21:54 - GraphTrainer - INFO -   recall@5: 0.030379
2025-11-22 21:21:54 - GraphTrainer - INFO -   hit_rate@5: 0.031576
2025-11-22 21:21:54 - GraphTrainer - INFO -   ndcg@5: 0.019879
2025-11-22 21:21:54 - GraphTrainer - INFO -   map@5: 0.016260
2025-11-22 21:21:54 - GraphTrainer - INFO -   mrr@5: 0.016767
2025-11-22 21:21:54 - GraphTrainer - INFO -   precision@10: 0.004891
2025-11-22 21:21:54 - GraphTrainer - INFO -   recall@10: 0.046576
2025-11-22 21:21:54 - GraphTrainer - INFO -   hit_rate@10: 0.048804
2025-11-22 21:21:54 - GraphTrainer - INFO -   ndcg@10: 0.025127
2025-11-22 21:21:54 - GraphTrainer - INFO -   map@10: 0.018364
2025-11-22 21:21:54 - GraphTrainer - INFO -   mrr@10: 0.018995
2025-11-22 21:21:54 - GraphTrainer - INFO -   precision@20: 0.003991
2025-11-22 21:21:54 - GraphTrainer - INFO -   recall@20: 0.075801
2025-11-22 21:21:54 - GraphTrainer - INFO -   hit_rate@20: 0.079506
2025-11-22 21:21:54 - GraphTrainer - INFO -   ndcg@20: 0.032541
2025-11-22 21:21:54 - GraphTrainer - INFO -   map@20: 0.020346
2025-11-22 21:21:54 - GraphTrainer - INFO -   mrr@20: 0.021073
2025-11-22 21:21:54 - GraphTrainer - INFO - 第 80 轮训练完成
2025-11-22 21:21:54 - GraphTrainer - INFO - train_loss: 0.302260
2025-11-22 21:21:54 - GraphTrainer - INFO - precision@5: 0.006315
2025-11-22 21:21:54 - GraphTrainer - INFO - recall@5: 0.030379
2025-11-22 21:21:54 - GraphTrainer - INFO - hit_rate@5: 0.031576
2025-11-22 21:21:54 - GraphTrainer - INFO - ndcg@5: 0.019879
2025-11-22 21:21:54 - GraphTrainer - INFO - map@5: 0.016260
2025-11-22 21:21:54 - GraphTrainer - INFO - mrr@5: 0.016767
2025-11-22 21:21:54 - GraphTrainer - INFO - precision@10: 0.004891
2025-11-22 21:21:54 - GraphTrainer - INFO - recall@10: 0.046576
2025-11-22 21:21:54 - GraphTrainer - INFO - hit_rate@10: 0.048804
2025-11-22 21:21:54 - GraphTrainer - INFO - ndcg@10: 0.025127
2025-11-22 21:21:54 - GraphTrainer - INFO - map@10: 0.018364
2025-11-22 21:21:54 - GraphTrainer - INFO - mrr@10: 0.018995
2025-11-22 21:21:54 - GraphTrainer - INFO - precision@20: 0.003991
2025-11-22 21:21:54 - GraphTrainer - INFO - recall@20: 0.075801
2025-11-22 21:21:54 - GraphTrainer - INFO - hit_rate@20: 0.079506
2025-11-22 21:21:54 - GraphTrainer - INFO - ndcg@20: 0.032541
2025-11-22 21:21:54 - GraphTrainer - INFO - map@20: 0.020346
2025-11-22 21:21:54 - GraphTrainer - INFO - mrr@20: 0.021073
2025-11-22 21:21:54 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:21:54 - GraphTrainer - INFO - 检查点已保存: Epoch 80 -> ./checkpoints/checkpoint_epoch_80.pth
2025-11-22 21:21:54 - GraphTrainer - INFO - ============================================================
2025-11-22 21:21:54 - GraphTrainer - INFO - 开始第 81/1000 轮训练
2025-11-22 21:21:54 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3052, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2862, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2941, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2928, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2999, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2755, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2983, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2933, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3019, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2907, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2931, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2945, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3189, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3149, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2929, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2858, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2938, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3131, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3192, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3094, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2815, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3116, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3019, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2952, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3079, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2923, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2964, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3197, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2895, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3182, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3136, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3054, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3131, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3002, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2941, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3179, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2877, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2791, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3020, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2979, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3121, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2822, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2986, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2983, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3032, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2987, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3225, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3093, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3202, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2894, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3197, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2942, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3160, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2889, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3124, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3044, device='cuda:0', grad_fn=<AddBackward0>)
The 80 training average loss: 0.3022601342406766
2025-11-22 21:22:05 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:22:05 - GraphTrainer - INFO -   precision@5: 0.006377
2025-11-22 21:22:05 - GraphTrainer - INFO -   recall@5: 0.030467
2025-11-22 21:22:05 - GraphTrainer - INFO -   hit_rate@5: 0.031885
2025-11-22 21:22:05 - GraphTrainer - INFO -   ndcg@5: 0.020195
2025-11-22 21:22:05 - GraphTrainer - INFO -   map@5: 0.016601
2025-11-22 21:22:05 - GraphTrainer - INFO -   mrr@5: 0.017256
2025-11-22 21:22:05 - GraphTrainer - INFO -   precision@10: 0.005112
2025-11-22 21:22:05 - GraphTrainer - INFO -   recall@10: 0.048401
2025-11-22 21:22:05 - GraphTrainer - INFO -   hit_rate@10: 0.050964
2025-11-22 21:22:05 - GraphTrainer - INFO -   ndcg@10: 0.025989
2025-11-22 21:22:05 - GraphTrainer - INFO -   map@10: 0.018915
2025-11-22 21:22:05 - GraphTrainer - INFO -   mrr@10: 0.019716
2025-11-22 21:22:05 - GraphTrainer - INFO -   precision@20: 0.004091
2025-11-22 21:22:05 - GraphTrainer - INFO -   recall@20: 0.077378
2025-11-22 21:22:05 - GraphTrainer - INFO -   hit_rate@20: 0.081409
2025-11-22 21:22:05 - GraphTrainer - INFO -   ndcg@20: 0.033331
2025-11-22 21:22:05 - GraphTrainer - INFO -   map@20: 0.020872
2025-11-22 21:22:05 - GraphTrainer - INFO -   mrr@20: 0.021762
2025-11-22 21:22:05 - GraphTrainer - INFO - 第 81 轮训练完成
2025-11-22 21:22:05 - GraphTrainer - INFO - train_loss: 0.299653
2025-11-22 21:22:05 - GraphTrainer - INFO - precision@5: 0.006377
2025-11-22 21:22:05 - GraphTrainer - INFO - recall@5: 0.030467
2025-11-22 21:22:05 - GraphTrainer - INFO - hit_rate@5: 0.031885
2025-11-22 21:22:05 - GraphTrainer - INFO - ndcg@5: 0.020195
2025-11-22 21:22:05 - GraphTrainer - INFO - map@5: 0.016601
2025-11-22 21:22:05 - GraphTrainer - INFO - mrr@5: 0.017256
2025-11-22 21:22:05 - GraphTrainer - INFO - precision@10: 0.005112
2025-11-22 21:22:05 - GraphTrainer - INFO - recall@10: 0.048401
2025-11-22 21:22:05 - GraphTrainer - INFO - hit_rate@10: 0.050964
2025-11-22 21:22:05 - GraphTrainer - INFO - ndcg@10: 0.025989
2025-11-22 21:22:05 - GraphTrainer - INFO - map@10: 0.018915
2025-11-22 21:22:05 - GraphTrainer - INFO - mrr@10: 0.019716
2025-11-22 21:22:05 - GraphTrainer - INFO - precision@20: 0.004091
2025-11-22 21:22:05 - GraphTrainer - INFO - recall@20: 0.077378
2025-11-22 21:22:05 - GraphTrainer - INFO - hit_rate@20: 0.081409
2025-11-22 21:22:05 - GraphTrainer - INFO - ndcg@20: 0.033331
2025-11-22 21:22:05 - GraphTrainer - INFO - map@20: 0.020872
2025-11-22 21:22:05 - GraphTrainer - INFO - mrr@20: 0.021762
2025-11-22 21:22:05 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:22:05 - GraphTrainer - INFO - ============================================================
2025-11-22 21:22:05 - GraphTrainer - INFO - 开始第 82/1000 轮训练
2025-11-22 21:22:05 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2695, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3128, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3073, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3087, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3237, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3046, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2957, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3110, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3047, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2964, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2938, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3000, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2900, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2932, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2928, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3256, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3112, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3001, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3022, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2966, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2847, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2725, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3031, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2914, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3039, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2939, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3257, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2943, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3082, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3071, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3000, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3008, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3016, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3138, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2916, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2948, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3035, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3065, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3181, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2835, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3000, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2979, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2906, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2727, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3109, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2884, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3012, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3045, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3083, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2841, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2863, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2866, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2932, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3044, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3191, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2836, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3149, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2942, device='cuda:0', grad_fn=<AddBackward0>)
The 81 training average loss: 0.29965294178189905
2025-11-22 21:22:16 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:22:16 - GraphTrainer - INFO -   precision@5: 0.006367
2025-11-22 21:22:16 - GraphTrainer - INFO -   recall@5: 0.030397
2025-11-22 21:22:16 - GraphTrainer - INFO -   hit_rate@5: 0.031833
2025-11-22 21:22:16 - GraphTrainer - INFO -   ndcg@5: 0.019956
2025-11-22 21:22:16 - GraphTrainer - INFO -   map@5: 0.016289
2025-11-22 21:22:16 - GraphTrainer - INFO -   mrr@5: 0.016981
2025-11-22 21:22:16 - GraphTrainer - INFO -   precision@10: 0.005019
2025-11-22 21:22:16 - GraphTrainer - INFO -   recall@10: 0.047726
2025-11-22 21:22:16 - GraphTrainer - INFO -   hit_rate@10: 0.050039
2025-11-22 21:22:16 - GraphTrainer - INFO -   ndcg@10: 0.025547
2025-11-22 21:22:16 - GraphTrainer - INFO -   map@10: 0.018533
2025-11-22 21:22:16 - GraphTrainer - INFO -   mrr@10: 0.019335
2025-11-22 21:22:16 - GraphTrainer - INFO -   precision@20: 0.003934
2025-11-22 21:22:16 - GraphTrainer - INFO -   recall@20: 0.074687
2025-11-22 21:22:16 - GraphTrainer - INFO -   hit_rate@20: 0.078323
2025-11-22 21:22:16 - GraphTrainer - INFO -   ndcg@20: 0.032396
2025-11-22 21:22:16 - GraphTrainer - INFO -   map@20: 0.020369
2025-11-22 21:22:16 - GraphTrainer - INFO -   mrr@20: 0.021263
2025-11-22 21:22:16 - GraphTrainer - INFO - 第 82 轮训练完成
2025-11-22 21:22:16 - GraphTrainer - INFO - train_loss: 0.300756
2025-11-22 21:22:16 - GraphTrainer - INFO - precision@5: 0.006367
2025-11-22 21:22:16 - GraphTrainer - INFO - recall@5: 0.030397
2025-11-22 21:22:16 - GraphTrainer - INFO - hit_rate@5: 0.031833
2025-11-22 21:22:16 - GraphTrainer - INFO - ndcg@5: 0.019956
2025-11-22 21:22:16 - GraphTrainer - INFO - map@5: 0.016289
2025-11-22 21:22:16 - GraphTrainer - INFO - mrr@5: 0.016981
2025-11-22 21:22:16 - GraphTrainer - INFO - precision@10: 0.005019
2025-11-22 21:22:16 - GraphTrainer - INFO - recall@10: 0.047726
2025-11-22 21:22:16 - GraphTrainer - INFO - hit_rate@10: 0.050039
2025-11-22 21:22:16 - GraphTrainer - INFO - ndcg@10: 0.025547
2025-11-22 21:22:16 - GraphTrainer - INFO - map@10: 0.018533
2025-11-22 21:22:16 - GraphTrainer - INFO - mrr@10: 0.019335
2025-11-22 21:22:16 - GraphTrainer - INFO - precision@20: 0.003934
2025-11-22 21:22:16 - GraphTrainer - INFO - recall@20: 0.074687
2025-11-22 21:22:16 - GraphTrainer - INFO - hit_rate@20: 0.078323
2025-11-22 21:22:16 - GraphTrainer - INFO - ndcg@20: 0.032396
2025-11-22 21:22:16 - GraphTrainer - INFO - map@20: 0.020369
2025-11-22 21:22:16 - GraphTrainer - INFO - mrr@20: 0.021263
2025-11-22 21:22:16 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:22:16 - GraphTrainer - INFO - ============================================================
2025-11-22 21:22:16 - GraphTrainer - INFO - 开始第 83/1000 轮训练
2025-11-22 21:22:16 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2903, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3045, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2764, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3165, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2943, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3119, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2964, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2969, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3062, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3078, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2946, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3136, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2843, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3117, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2892, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2936, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2850, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2946, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2930, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3288, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2926, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3020, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2924, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3049, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2955, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2741, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2883, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3122, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3179, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3091, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3316, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3232, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2904, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2797, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2843, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2982, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3020, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2972, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2918, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2873, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2775, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2890, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3042, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2947, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3083, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3230, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3092, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3221, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2938, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2816, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3168, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3130, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3126, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3070, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3089, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2989, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3034, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3155, device='cuda:0', grad_fn=<AddBackward0>)
The 82 training average loss: 0.3007559586187889
2025-11-22 21:22:27 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:22:27 - GraphTrainer - INFO -   precision@5: 0.006182
2025-11-22 21:22:27 - GraphTrainer - INFO -   recall@5: 0.029473
2025-11-22 21:22:27 - GraphTrainer - INFO -   hit_rate@5: 0.030908
2025-11-22 21:22:27 - GraphTrainer - INFO -   ndcg@5: 0.019839
2025-11-22 21:22:27 - GraphTrainer - INFO -   map@5: 0.016420
2025-11-22 21:22:27 - GraphTrainer - INFO -   mrr@5: 0.017220
2025-11-22 21:22:27 - GraphTrainer - INFO -   precision@10: 0.004901
2025-11-22 21:22:27 - GraphTrainer - INFO -   recall@10: 0.046361
2025-11-22 21:22:27 - GraphTrainer - INFO -   hit_rate@10: 0.048959
2025-11-22 21:22:27 - GraphTrainer - INFO -   ndcg@10: 0.025337
2025-11-22 21:22:27 - GraphTrainer - INFO -   map@10: 0.018637
2025-11-22 21:22:27 - GraphTrainer - INFO -   mrr@10: 0.019586
2025-11-22 21:22:27 - GraphTrainer - INFO -   precision@20: 0.003903
2025-11-22 21:22:27 - GraphTrainer - INFO -   recall@20: 0.073733
2025-11-22 21:22:27 - GraphTrainer - INFO -   hit_rate@20: 0.077655
2025-11-22 21:22:27 - GraphTrainer - INFO -   ndcg@20: 0.032288
2025-11-22 21:22:27 - GraphTrainer - INFO -   map@20: 0.020501
2025-11-22 21:22:27 - GraphTrainer - INFO -   mrr@20: 0.021530
2025-11-22 21:22:27 - GraphTrainer - INFO - 第 83 轮训练完成
2025-11-22 21:22:27 - GraphTrainer - INFO - train_loss: 0.299496
2025-11-22 21:22:27 - GraphTrainer - INFO - precision@5: 0.006182
2025-11-22 21:22:27 - GraphTrainer - INFO - recall@5: 0.029473
2025-11-22 21:22:27 - GraphTrainer - INFO - hit_rate@5: 0.030908
2025-11-22 21:22:27 - GraphTrainer - INFO - ndcg@5: 0.019839
2025-11-22 21:22:27 - GraphTrainer - INFO - map@5: 0.016420
2025-11-22 21:22:27 - GraphTrainer - INFO - mrr@5: 0.017220
2025-11-22 21:22:27 - GraphTrainer - INFO - precision@10: 0.004901
2025-11-22 21:22:27 - GraphTrainer - INFO - recall@10: 0.046361
2025-11-22 21:22:27 - GraphTrainer - INFO - hit_rate@10: 0.048959
2025-11-22 21:22:27 - GraphTrainer - INFO - ndcg@10: 0.025337
2025-11-22 21:22:27 - GraphTrainer - INFO - map@10: 0.018637
2025-11-22 21:22:27 - GraphTrainer - INFO - mrr@10: 0.019586
2025-11-22 21:22:27 - GraphTrainer - INFO - precision@20: 0.003903
2025-11-22 21:22:27 - GraphTrainer - INFO - recall@20: 0.073733
2025-11-22 21:22:27 - GraphTrainer - INFO - hit_rate@20: 0.077655
2025-11-22 21:22:27 - GraphTrainer - INFO - ndcg@20: 0.032288
2025-11-22 21:22:27 - GraphTrainer - INFO - map@20: 0.020501
2025-11-22 21:22:27 - GraphTrainer - INFO - mrr@20: 0.021530
2025-11-22 21:22:27 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:22:27 - GraphTrainer - INFO - ============================================================
2025-11-22 21:22:27 - GraphTrainer - INFO - 开始第 84/1000 轮训练
2025-11-22 21:22:27 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3115, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3090, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3052, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2910, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3132, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2970, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3092, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2899, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2944, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2831, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2857, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3063, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3122, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2984, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2960, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2763, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3050, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2919, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3033, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2922, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3052, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2966, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3156, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2995, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3167, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3138, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2774, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3067, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2940, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3051, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2973, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3230, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2958, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3017, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3112, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2899, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2993, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2973, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3112, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3022, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2847, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2968, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2987, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2903, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3199, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2946, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3031, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2795, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2927, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2914, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2793, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3223, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3065, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2893, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2858, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3019, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3072, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2960, device='cuda:0', grad_fn=<AddBackward0>)
The 83 training average loss: 0.2994958234244379
2025-11-22 21:22:38 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:22:38 - GraphTrainer - INFO -   precision@5: 0.005904
2025-11-22 21:22:38 - GraphTrainer - INFO -   recall@5: 0.028210
2025-11-22 21:22:38 - GraphTrainer - INFO -   hit_rate@5: 0.029519
2025-11-22 21:22:38 - GraphTrainer - INFO -   ndcg@5: 0.018802
2025-11-22 21:22:38 - GraphTrainer - INFO -   map@5: 0.015505
2025-11-22 21:22:38 - GraphTrainer - INFO -   mrr@5: 0.016086
2025-11-22 21:22:38 - GraphTrainer - INFO -   precision@10: 0.004891
2025-11-22 21:22:38 - GraphTrainer - INFO -   recall@10: 0.046124
2025-11-22 21:22:38 - GraphTrainer - INFO -   hit_rate@10: 0.048753
2025-11-22 21:22:38 - GraphTrainer - INFO -   ndcg@10: 0.024637
2025-11-22 21:22:38 - GraphTrainer - INFO -   map@10: 0.017851
2025-11-22 21:22:38 - GraphTrainer - INFO -   mrr@10: 0.018606
2025-11-22 21:22:38 - GraphTrainer - INFO -   precision@20: 0.003875
2025-11-22 21:22:38 - GraphTrainer - INFO -   recall@20: 0.073018
2025-11-22 21:22:38 - GraphTrainer - INFO -   hit_rate@20: 0.077038
2025-11-22 21:22:38 - GraphTrainer - INFO -   ndcg@20: 0.031491
2025-11-22 21:22:38 - GraphTrainer - INFO -   map@20: 0.019697
2025-11-22 21:22:38 - GraphTrainer - INFO -   mrr@20: 0.020537
2025-11-22 21:22:38 - GraphTrainer - INFO - 第 84 轮训练完成
2025-11-22 21:22:38 - GraphTrainer - INFO - train_loss: 0.298639
2025-11-22 21:22:38 - GraphTrainer - INFO - precision@5: 0.005904
2025-11-22 21:22:38 - GraphTrainer - INFO - recall@5: 0.028210
2025-11-22 21:22:38 - GraphTrainer - INFO - hit_rate@5: 0.029519
2025-11-22 21:22:38 - GraphTrainer - INFO - ndcg@5: 0.018802
2025-11-22 21:22:38 - GraphTrainer - INFO - map@5: 0.015505
2025-11-22 21:22:38 - GraphTrainer - INFO - mrr@5: 0.016086
2025-11-22 21:22:38 - GraphTrainer - INFO - precision@10: 0.004891
2025-11-22 21:22:38 - GraphTrainer - INFO - recall@10: 0.046124
2025-11-22 21:22:38 - GraphTrainer - INFO - hit_rate@10: 0.048753
2025-11-22 21:22:38 - GraphTrainer - INFO - ndcg@10: 0.024637
2025-11-22 21:22:38 - GraphTrainer - INFO - map@10: 0.017851
2025-11-22 21:22:38 - GraphTrainer - INFO - mrr@10: 0.018606
2025-11-22 21:22:38 - GraphTrainer - INFO - precision@20: 0.003875
2025-11-22 21:22:38 - GraphTrainer - INFO - recall@20: 0.073018
2025-11-22 21:22:38 - GraphTrainer - INFO - hit_rate@20: 0.077038
2025-11-22 21:22:38 - GraphTrainer - INFO - ndcg@20: 0.031491
2025-11-22 21:22:38 - GraphTrainer - INFO - map@20: 0.019697
2025-11-22 21:22:38 - GraphTrainer - INFO - mrr@20: 0.020537
2025-11-22 21:22:38 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:22:38 - GraphTrainer - INFO - ============================================================
2025-11-22 21:22:38 - GraphTrainer - INFO - 开始第 85/1000 轮训练
2025-11-22 21:22:38 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2990, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2986, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3112, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3162, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3066, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3188, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3059, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2904, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3055, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2935, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3158, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2657, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2907, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2961, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3022, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2908, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2775, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2984, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2968, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2983, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3049, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2792, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2963, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2962, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3039, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2905, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3085, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2918, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2785, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2797, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2866, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2925, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2959, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3178, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3172, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3174, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3154, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2963, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3098, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3011, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2981, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3030, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3078, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2906, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3027, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2965, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2965, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2998, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2792, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2930, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3102, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2914, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2987, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3031, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2961, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2907, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3027, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3032, device='cuda:0', grad_fn=<AddBackward0>)
The 84 training average loss: 0.29863851337597286
2025-11-22 21:22:49 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:22:49 - GraphTrainer - INFO -   precision@5: 0.006428
2025-11-22 21:22:49 - GraphTrainer - INFO -   recall@5: 0.030616
2025-11-22 21:22:49 - GraphTrainer - INFO -   hit_rate@5: 0.032142
2025-11-22 21:22:49 - GraphTrainer - INFO -   ndcg@5: 0.020353
2025-11-22 21:22:49 - GraphTrainer - INFO -   map@5: 0.016742
2025-11-22 21:22:49 - GraphTrainer - INFO -   mrr@5: 0.017468
2025-11-22 21:22:49 - GraphTrainer - INFO -   precision@10: 0.005174
2025-11-22 21:22:49 - GraphTrainer - INFO -   recall@10: 0.049020
2025-11-22 21:22:49 - GraphTrainer - INFO -   hit_rate@10: 0.051633
2025-11-22 21:22:49 - GraphTrainer - INFO -   ndcg@10: 0.026357
2025-11-22 21:22:49 - GraphTrainer - INFO -   map@10: 0.019178
2025-11-22 21:22:49 - GraphTrainer - INFO -   mrr@10: 0.020043
2025-11-22 21:22:49 - GraphTrainer - INFO -   precision@20: 0.004040
2025-11-22 21:22:49 - GraphTrainer - INFO -   recall@20: 0.076435
2025-11-22 21:22:49 - GraphTrainer - INFO -   hit_rate@20: 0.080329
2025-11-22 21:22:49 - GraphTrainer - INFO -   ndcg@20: 0.033309
2025-11-22 21:22:49 - GraphTrainer - INFO -   map@20: 0.021037
2025-11-22 21:22:49 - GraphTrainer - INFO -   mrr@20: 0.021986
2025-11-22 21:22:49 - GraphTrainer - INFO - 第 85 轮训练完成
2025-11-22 21:22:49 - GraphTrainer - INFO - train_loss: 0.297925
2025-11-22 21:22:49 - GraphTrainer - INFO - precision@5: 0.006428
2025-11-22 21:22:49 - GraphTrainer - INFO - recall@5: 0.030616
2025-11-22 21:22:49 - GraphTrainer - INFO - hit_rate@5: 0.032142
2025-11-22 21:22:49 - GraphTrainer - INFO - ndcg@5: 0.020353
2025-11-22 21:22:49 - GraphTrainer - INFO - map@5: 0.016742
2025-11-22 21:22:49 - GraphTrainer - INFO - mrr@5: 0.017468
2025-11-22 21:22:49 - GraphTrainer - INFO - precision@10: 0.005174
2025-11-22 21:22:49 - GraphTrainer - INFO - recall@10: 0.049020
2025-11-22 21:22:49 - GraphTrainer - INFO - hit_rate@10: 0.051633
2025-11-22 21:22:49 - GraphTrainer - INFO - ndcg@10: 0.026357
2025-11-22 21:22:49 - GraphTrainer - INFO - map@10: 0.019178
2025-11-22 21:22:49 - GraphTrainer - INFO - mrr@10: 0.020043
2025-11-22 21:22:49 - GraphTrainer - INFO - precision@20: 0.004040
2025-11-22 21:22:49 - GraphTrainer - INFO - recall@20: 0.076435
2025-11-22 21:22:49 - GraphTrainer - INFO - hit_rate@20: 0.080329
2025-11-22 21:22:49 - GraphTrainer - INFO - ndcg@20: 0.033309
2025-11-22 21:22:49 - GraphTrainer - INFO - map@20: 0.021037
2025-11-22 21:22:49 - GraphTrainer - INFO - mrr@20: 0.021986
2025-11-22 21:22:49 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:22:49 - GraphTrainer - INFO - ============================================================
2025-11-22 21:22:49 - GraphTrainer - INFO - 开始第 86/1000 轮训练
2025-11-22 21:22:49 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2811, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2804, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2931, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3074, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3096, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2935, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2955, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3085, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2917, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3048, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3092, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2888, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3211, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2901, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2988, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2908, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3087, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3011, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2829, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3013, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2992, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2953, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2900, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3031, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2912, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2829, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2917, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2795, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2927, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2987, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2959, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3082, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2915, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2829, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3073, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3168, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3112, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2796, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2998, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2875, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3163, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2978, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2887, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3054, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3008, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3040, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3166, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3005, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2890, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3133, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3204, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3107, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2914, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2895, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3043, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2915, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2826, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2939, device='cuda:0', grad_fn=<AddBackward0>)
The 85 training average loss: 0.2979246583478204
2025-11-22 21:23:00 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:23:00 - GraphTrainer - INFO -   precision@5: 0.006233
2025-11-22 21:23:00 - GraphTrainer - INFO -   recall@5: 0.030059
2025-11-22 21:23:00 - GraphTrainer - INFO -   hit_rate@5: 0.031113
2025-11-22 21:23:00 - GraphTrainer - INFO -   ndcg@5: 0.019846
2025-11-22 21:23:00 - GraphTrainer - INFO -   map@5: 0.016321
2025-11-22 21:23:00 - GraphTrainer - INFO -   mrr@5: 0.016823
2025-11-22 21:23:00 - GraphTrainer - INFO -   precision@10: 0.005004
2025-11-22 21:23:00 - GraphTrainer - INFO -   recall@10: 0.047883
2025-11-22 21:23:00 - GraphTrainer - INFO -   hit_rate@10: 0.049936
2025-11-22 21:23:00 - GraphTrainer - INFO -   ndcg@10: 0.025659
2025-11-22 21:23:00 - GraphTrainer - INFO -   map@10: 0.018683
2025-11-22 21:23:00 - GraphTrainer - INFO -   mrr@10: 0.019312
2025-11-22 21:23:00 - GraphTrainer - INFO -   precision@20: 0.003955
2025-11-22 21:23:00 - GraphTrainer - INFO -   recall@20: 0.075289
2025-11-22 21:23:00 - GraphTrainer - INFO -   hit_rate@20: 0.078735
2025-11-22 21:23:00 - GraphTrainer - INFO -   ndcg@20: 0.032649
2025-11-22 21:23:00 - GraphTrainer - INFO -   map@20: 0.020571
2025-11-22 21:23:00 - GraphTrainer - INFO -   mrr@20: 0.021291
2025-11-22 21:23:00 - GraphTrainer - INFO - 第 86 轮训练完成
2025-11-22 21:23:00 - GraphTrainer - INFO - train_loss: 0.299988
2025-11-22 21:23:00 - GraphTrainer - INFO - precision@5: 0.006233
2025-11-22 21:23:00 - GraphTrainer - INFO - recall@5: 0.030059
2025-11-22 21:23:00 - GraphTrainer - INFO - hit_rate@5: 0.031113
2025-11-22 21:23:00 - GraphTrainer - INFO - ndcg@5: 0.019846
2025-11-22 21:23:00 - GraphTrainer - INFO - map@5: 0.016321
2025-11-22 21:23:00 - GraphTrainer - INFO - mrr@5: 0.016823
2025-11-22 21:23:00 - GraphTrainer - INFO - precision@10: 0.005004
2025-11-22 21:23:00 - GraphTrainer - INFO - recall@10: 0.047883
2025-11-22 21:23:00 - GraphTrainer - INFO - hit_rate@10: 0.049936
2025-11-22 21:23:00 - GraphTrainer - INFO - ndcg@10: 0.025659
2025-11-22 21:23:00 - GraphTrainer - INFO - map@10: 0.018683
2025-11-22 21:23:00 - GraphTrainer - INFO - mrr@10: 0.019312
2025-11-22 21:23:00 - GraphTrainer - INFO - precision@20: 0.003955
2025-11-22 21:23:00 - GraphTrainer - INFO - recall@20: 0.075289
2025-11-22 21:23:00 - GraphTrainer - INFO - hit_rate@20: 0.078735
2025-11-22 21:23:00 - GraphTrainer - INFO - ndcg@20: 0.032649
2025-11-22 21:23:00 - GraphTrainer - INFO - map@20: 0.020571
2025-11-22 21:23:00 - GraphTrainer - INFO - mrr@20: 0.021291
2025-11-22 21:23:00 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:23:00 - GraphTrainer - INFO - ============================================================
2025-11-22 21:23:00 - GraphTrainer - INFO - 开始第 87/1000 轮训练
2025-11-22 21:23:00 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3136, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3100, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3033, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2992, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2965, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2716, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3173, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2941, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3060, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3015, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2904, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3038, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3005, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3089, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2964, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3001, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2754, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2794, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2928, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2884, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3075, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2862, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2897, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2999, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3213, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2892, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3174, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2833, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2963, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3069, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3108, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2901, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2839, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3203, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3034, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2911, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2920, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2978, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3008, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3121, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2844, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2839, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3116, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3077, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3090, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3092, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3016, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2977, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3162, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3098, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2890, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2933, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3001, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2703, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3047, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2967, device='cuda:0', grad_fn=<AddBackward0>)
The 86 training average loss: 0.29998848253283006
2025-11-22 21:23:11 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:23:11 - GraphTrainer - INFO -   precision@5: 0.006284
2025-11-22 21:23:11 - GraphTrainer - INFO -   recall@5: 0.030122
2025-11-22 21:23:11 - GraphTrainer - INFO -   hit_rate@5: 0.031422
2025-11-22 21:23:11 - GraphTrainer - INFO -   ndcg@5: 0.019866
2025-11-22 21:23:11 - GraphTrainer - INFO -   map@5: 0.016274
2025-11-22 21:23:11 - GraphTrainer - INFO -   mrr@5: 0.016944
2025-11-22 21:23:11 - GraphTrainer - INFO -   precision@10: 0.005060
2025-11-22 21:23:11 - GraphTrainer - INFO -   recall@10: 0.047970
2025-11-22 21:23:11 - GraphTrainer - INFO -   hit_rate@10: 0.050501
2025-11-22 21:23:11 - GraphTrainer - INFO -   ndcg@10: 0.025669
2025-11-22 21:23:11 - GraphTrainer - INFO -   map@10: 0.018607
2025-11-22 21:23:11 - GraphTrainer - INFO -   mrr@10: 0.019434
2025-11-22 21:23:11 - GraphTrainer - INFO -   precision@20: 0.004058
2025-11-22 21:23:11 - GraphTrainer - INFO -   recall@20: 0.076787
2025-11-22 21:23:11 - GraphTrainer - INFO -   hit_rate@20: 0.080843
2025-11-22 21:23:11 - GraphTrainer - INFO -   ndcg@20: 0.033012
2025-11-22 21:23:11 - GraphTrainer - INFO -   map@20: 0.020587
2025-11-22 21:23:11 - GraphTrainer - INFO -   mrr@20: 0.021515
2025-11-22 21:23:11 - GraphTrainer - INFO - 第 87 轮训练完成
2025-11-22 21:23:11 - GraphTrainer - INFO - train_loss: 0.296582
2025-11-22 21:23:11 - GraphTrainer - INFO - precision@5: 0.006284
2025-11-22 21:23:11 - GraphTrainer - INFO - recall@5: 0.030122
2025-11-22 21:23:11 - GraphTrainer - INFO - hit_rate@5: 0.031422
2025-11-22 21:23:11 - GraphTrainer - INFO - ndcg@5: 0.019866
2025-11-22 21:23:11 - GraphTrainer - INFO - map@5: 0.016274
2025-11-22 21:23:11 - GraphTrainer - INFO - mrr@5: 0.016944
2025-11-22 21:23:11 - GraphTrainer - INFO - precision@10: 0.005060
2025-11-22 21:23:11 - GraphTrainer - INFO - recall@10: 0.047970
2025-11-22 21:23:11 - GraphTrainer - INFO - hit_rate@10: 0.050501
2025-11-22 21:23:11 - GraphTrainer - INFO - ndcg@10: 0.025669
2025-11-22 21:23:11 - GraphTrainer - INFO - map@10: 0.018607
2025-11-22 21:23:11 - GraphTrainer - INFO - mrr@10: 0.019434
2025-11-22 21:23:11 - GraphTrainer - INFO - precision@20: 0.004058
2025-11-22 21:23:11 - GraphTrainer - INFO - recall@20: 0.076787
2025-11-22 21:23:11 - GraphTrainer - INFO - hit_rate@20: 0.080843
2025-11-22 21:23:11 - GraphTrainer - INFO - ndcg@20: 0.033012
2025-11-22 21:23:11 - GraphTrainer - INFO - map@20: 0.020587
2025-11-22 21:23:11 - GraphTrainer - INFO - mrr@20: 0.021515
2025-11-22 21:23:11 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:23:11 - GraphTrainer - INFO - ============================================================
2025-11-22 21:23:11 - GraphTrainer - INFO - 开始第 88/1000 轮训练
2025-11-22 21:23:11 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2932, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2721, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2973, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3000, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2751, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3049, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3098, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3376, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2940, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3078, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2939, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2817, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2986, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3050, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2977, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2990, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3004, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2846, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2961, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2820, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2999, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3076, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2880, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3096, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2982, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2959, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2897, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2812, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3056, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2885, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2941, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2999, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2909, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2917, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3048, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2936, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2867, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3168, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2825, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2821, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2978, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3018, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3088, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3111, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2835, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3076, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3059, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3124, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3095, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3127, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2932, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2706, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2727, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3228, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2935, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2873, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2735, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2990, device='cuda:0', grad_fn=<AddBackward0>)
The 87 training average loss: 0.29658162285541667
2025-11-22 21:23:22 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:23:22 - GraphTrainer - INFO -   precision@5: 0.006140
2025-11-22 21:23:22 - GraphTrainer - INFO -   recall@5: 0.029484
2025-11-22 21:23:22 - GraphTrainer - INFO -   hit_rate@5: 0.030702
2025-11-22 21:23:22 - GraphTrainer - INFO -   ndcg@5: 0.019633
2025-11-22 21:23:22 - GraphTrainer - INFO -   map@5: 0.016182
2025-11-22 21:23:22 - GraphTrainer - INFO -   mrr@5: 0.016812
2025-11-22 21:23:22 - GraphTrainer - INFO -   precision@10: 0.005199
2025-11-22 21:23:22 - GraphTrainer - INFO -   recall@10: 0.049609
2025-11-22 21:23:22 - GraphTrainer - INFO -   hit_rate@10: 0.051890
2025-11-22 21:23:22 - GraphTrainer - INFO -   ndcg@10: 0.026152
2025-11-22 21:23:22 - GraphTrainer - INFO -   map@10: 0.018810
2025-11-22 21:23:22 - GraphTrainer - INFO -   mrr@10: 0.019581
2025-11-22 21:23:22 - GraphTrainer - INFO -   precision@20: 0.004055
2025-11-22 21:23:22 - GraphTrainer - INFO -   recall@20: 0.076810
2025-11-22 21:23:22 - GraphTrainer - INFO -   hit_rate@20: 0.080741
2025-11-22 21:23:22 - GraphTrainer - INFO -   ndcg@20: 0.033055
2025-11-22 21:23:22 - GraphTrainer - INFO -   map@20: 0.020647
2025-11-22 21:23:22 - GraphTrainer - INFO -   mrr@20: 0.021522
2025-11-22 21:23:22 - GraphTrainer - INFO - 第 88 轮训练完成
2025-11-22 21:23:22 - GraphTrainer - INFO - train_loss: 0.297894
2025-11-22 21:23:22 - GraphTrainer - INFO - precision@5: 0.006140
2025-11-22 21:23:22 - GraphTrainer - INFO - recall@5: 0.029484
2025-11-22 21:23:22 - GraphTrainer - INFO - hit_rate@5: 0.030702
2025-11-22 21:23:22 - GraphTrainer - INFO - ndcg@5: 0.019633
2025-11-22 21:23:22 - GraphTrainer - INFO - map@5: 0.016182
2025-11-22 21:23:22 - GraphTrainer - INFO - mrr@5: 0.016812
2025-11-22 21:23:22 - GraphTrainer - INFO - precision@10: 0.005199
2025-11-22 21:23:22 - GraphTrainer - INFO - recall@10: 0.049609
2025-11-22 21:23:22 - GraphTrainer - INFO - hit_rate@10: 0.051890
2025-11-22 21:23:22 - GraphTrainer - INFO - ndcg@10: 0.026152
2025-11-22 21:23:22 - GraphTrainer - INFO - map@10: 0.018810
2025-11-22 21:23:22 - GraphTrainer - INFO - mrr@10: 0.019581
2025-11-22 21:23:22 - GraphTrainer - INFO - precision@20: 0.004055
2025-11-22 21:23:22 - GraphTrainer - INFO - recall@20: 0.076810
2025-11-22 21:23:22 - GraphTrainer - INFO - hit_rate@20: 0.080741
2025-11-22 21:23:22 - GraphTrainer - INFO - ndcg@20: 0.033055
2025-11-22 21:23:22 - GraphTrainer - INFO - map@20: 0.020647
2025-11-22 21:23:22 - GraphTrainer - INFO - mrr@20: 0.021522
2025-11-22 21:23:22 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:23:22 - GraphTrainer - INFO - ============================================================
2025-11-22 21:23:22 - GraphTrainer - INFO - 开始第 89/1000 轮训练
2025-11-22 21:23:22 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2726, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2872, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2851, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3014, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2703, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3205, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3023, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2888, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2796, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3034, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2899, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3185, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3148, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2970, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2952, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3015, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2788, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3145, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2830, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3029, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2889, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3005, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3306, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2909, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3076, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3013, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3047, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2788, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3003, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3034, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3028, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2897, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2915, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2854, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2798, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2985, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2996, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2919, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3078, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2611, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3135, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2886, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3105, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2876, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2990, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3092, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3172, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3202, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3179, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2900, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2766, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2966, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2998, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3142, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2941, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3020, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2930, device='cuda:0', grad_fn=<AddBackward0>)
The 88 training average loss: 0.29789402464340475
2025-11-22 21:23:33 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:23:33 - GraphTrainer - INFO -   precision@5: 0.006624
2025-11-22 21:23:33 - GraphTrainer - INFO -   recall@5: 0.031571
2025-11-22 21:23:33 - GraphTrainer - INFO -   hit_rate@5: 0.033119
2025-11-22 21:23:33 - GraphTrainer - INFO -   ndcg@5: 0.020552
2025-11-22 21:23:33 - GraphTrainer - INFO -   map@5: 0.016697
2025-11-22 21:23:33 - GraphTrainer - INFO -   mrr@5: 0.017375
2025-11-22 21:23:33 - GraphTrainer - INFO -   precision@10: 0.005184
2025-11-22 21:23:33 - GraphTrainer - INFO -   recall@10: 0.049459
2025-11-22 21:23:33 - GraphTrainer - INFO -   hit_rate@10: 0.051736
2025-11-22 21:23:33 - GraphTrainer - INFO -   ndcg@10: 0.026310
2025-11-22 21:23:33 - GraphTrainer - INFO -   map@10: 0.019011
2025-11-22 21:23:33 - GraphTrainer - INFO -   mrr@10: 0.019785
2025-11-22 21:23:33 - GraphTrainer - INFO -   precision@20: 0.004052
2025-11-22 21:23:33 - GraphTrainer - INFO -   recall@20: 0.076654
2025-11-22 21:23:33 - GraphTrainer - INFO -   hit_rate@20: 0.080689
2025-11-22 21:23:33 - GraphTrainer - INFO -   ndcg@20: 0.033250
2025-11-22 21:23:33 - GraphTrainer - INFO -   map@20: 0.020872
2025-11-22 21:23:33 - GraphTrainer - INFO -   mrr@20: 0.021765
2025-11-22 21:23:33 - GraphTrainer - INFO - 第 89 轮训练完成
2025-11-22 21:23:33 - GraphTrainer - INFO - train_loss: 0.296105
2025-11-22 21:23:33 - GraphTrainer - INFO - precision@5: 0.006624
2025-11-22 21:23:33 - GraphTrainer - INFO - recall@5: 0.031571
2025-11-22 21:23:33 - GraphTrainer - INFO - hit_rate@5: 0.033119
2025-11-22 21:23:33 - GraphTrainer - INFO - ndcg@5: 0.020552
2025-11-22 21:23:33 - GraphTrainer - INFO - map@5: 0.016697
2025-11-22 21:23:33 - GraphTrainer - INFO - mrr@5: 0.017375
2025-11-22 21:23:33 - GraphTrainer - INFO - precision@10: 0.005184
2025-11-22 21:23:33 - GraphTrainer - INFO - recall@10: 0.049459
2025-11-22 21:23:33 - GraphTrainer - INFO - hit_rate@10: 0.051736
2025-11-22 21:23:33 - GraphTrainer - INFO - ndcg@10: 0.026310
2025-11-22 21:23:33 - GraphTrainer - INFO - map@10: 0.019011
2025-11-22 21:23:33 - GraphTrainer - INFO - mrr@10: 0.019785
2025-11-22 21:23:33 - GraphTrainer - INFO - precision@20: 0.004052
2025-11-22 21:23:33 - GraphTrainer - INFO - recall@20: 0.076654
2025-11-22 21:23:33 - GraphTrainer - INFO - hit_rate@20: 0.080689
2025-11-22 21:23:33 - GraphTrainer - INFO - ndcg@20: 0.033250
2025-11-22 21:23:33 - GraphTrainer - INFO - map@20: 0.020872
2025-11-22 21:23:33 - GraphTrainer - INFO - mrr@20: 0.021765
2025-11-22 21:23:33 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:23:33 - GraphTrainer - INFO - ============================================================
2025-11-22 21:23:33 - GraphTrainer - INFO - 开始第 90/1000 轮训练
2025-11-22 21:23:33 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2905, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3040, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2905, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2988, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2924, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2982, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2696, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2876, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2937, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3047, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2695, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2992, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2934, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2950, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2815, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3112, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2790, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2941, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2997, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3019, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2924, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3012, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2854, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2813, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2963, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2981, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3038, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3029, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2948, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2992, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2922, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2956, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2992, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2844, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3040, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2784, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2984, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3028, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3180, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3118, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2993, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3075, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3095, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2845, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2959, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3051, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2918, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3121, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2852, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3088, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3093, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2954, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3068, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3063, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2936, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2966, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2869, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2851, device='cuda:0', grad_fn=<AddBackward0>)
The 89 training average loss: 0.29610515874007654
2025-11-22 21:23:44 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:23:44 - GraphTrainer - INFO -   precision@5: 0.006099
2025-11-22 21:23:44 - GraphTrainer - INFO -   recall@5: 0.029350
2025-11-22 21:23:44 - GraphTrainer - INFO -   hit_rate@5: 0.030496
2025-11-22 21:23:44 - GraphTrainer - INFO -   ndcg@5: 0.019584
2025-11-22 21:23:44 - GraphTrainer - INFO -   map@5: 0.016193
2025-11-22 21:23:44 - GraphTrainer - INFO -   mrr@5: 0.016801
2025-11-22 21:23:44 - GraphTrainer - INFO -   precision@10: 0.005004
2025-11-22 21:23:44 - GraphTrainer - INFO -   recall@10: 0.047832
2025-11-22 21:23:44 - GraphTrainer - INFO -   hit_rate@10: 0.050039
2025-11-22 21:23:44 - GraphTrainer - INFO -   ndcg@10: 0.025566
2025-11-22 21:23:44 - GraphTrainer - INFO -   map@10: 0.018597
2025-11-22 21:23:44 - GraphTrainer - INFO -   mrr@10: 0.019347
2025-11-22 21:23:44 - GraphTrainer - INFO -   precision@20: 0.003978
2025-11-22 21:23:44 - GraphTrainer - INFO -   recall@20: 0.075600
2025-11-22 21:23:44 - GraphTrainer - INFO -   hit_rate@20: 0.079301
2025-11-22 21:23:44 - GraphTrainer - INFO -   ndcg@20: 0.032577
2025-11-22 21:23:44 - GraphTrainer - INFO -   map@20: 0.020450
2025-11-22 21:23:44 - GraphTrainer - INFO -   mrr@20: 0.021293
2025-11-22 21:23:44 - GraphTrainer - INFO - 第 90 轮训练完成
2025-11-22 21:23:44 - GraphTrainer - INFO - train_loss: 0.296784
2025-11-22 21:23:44 - GraphTrainer - INFO - precision@5: 0.006099
2025-11-22 21:23:44 - GraphTrainer - INFO - recall@5: 0.029350
2025-11-22 21:23:44 - GraphTrainer - INFO - hit_rate@5: 0.030496
2025-11-22 21:23:44 - GraphTrainer - INFO - ndcg@5: 0.019584
2025-11-22 21:23:44 - GraphTrainer - INFO - map@5: 0.016193
2025-11-22 21:23:44 - GraphTrainer - INFO - mrr@5: 0.016801
2025-11-22 21:23:44 - GraphTrainer - INFO - precision@10: 0.005004
2025-11-22 21:23:44 - GraphTrainer - INFO - recall@10: 0.047832
2025-11-22 21:23:44 - GraphTrainer - INFO - hit_rate@10: 0.050039
2025-11-22 21:23:44 - GraphTrainer - INFO - ndcg@10: 0.025566
2025-11-22 21:23:44 - GraphTrainer - INFO - map@10: 0.018597
2025-11-22 21:23:44 - GraphTrainer - INFO - mrr@10: 0.019347
2025-11-22 21:23:44 - GraphTrainer - INFO - precision@20: 0.003978
2025-11-22 21:23:44 - GraphTrainer - INFO - recall@20: 0.075600
2025-11-22 21:23:44 - GraphTrainer - INFO - hit_rate@20: 0.079301
2025-11-22 21:23:44 - GraphTrainer - INFO - ndcg@20: 0.032577
2025-11-22 21:23:44 - GraphTrainer - INFO - map@20: 0.020450
2025-11-22 21:23:44 - GraphTrainer - INFO - mrr@20: 0.021293
2025-11-22 21:23:44 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:23:44 - GraphTrainer - INFO - 检查点已保存: Epoch 90 -> ./checkpoints/checkpoint_epoch_90.pth
2025-11-22 21:23:44 - GraphTrainer - INFO - ============================================================
2025-11-22 21:23:44 - GraphTrainer - INFO - 开始第 91/1000 轮训练
2025-11-22 21:23:44 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3092, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3299, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2915, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3022, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3046, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2848, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2908, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2727, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3069, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3182, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2959, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3042, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3085, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3053, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2910, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2793, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3047, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3019, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3115, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2854, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2994, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2800, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2885, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2891, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3005, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2886, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2900, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2834, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2964, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3038, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2731, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3021, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2912, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2952, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2784, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3028, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2909, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3139, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2932, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2866, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2813, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2960, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3058, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2905, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3223, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2913, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2813, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3025, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2967, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2760, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3158, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3143, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2910, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2743, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2841, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2790, device='cuda:0', grad_fn=<AddBackward0>)
The 90 training average loss: 0.2967840484504042
2025-11-22 21:23:55 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:23:55 - GraphTrainer - INFO -   precision@5: 0.006233
2025-11-22 21:23:55 - GraphTrainer - INFO -   recall@5: 0.029733
2025-11-22 21:23:55 - GraphTrainer - INFO -   hit_rate@5: 0.031165
2025-11-22 21:23:55 - GraphTrainer - INFO -   ndcg@5: 0.019459
2025-11-22 21:23:55 - GraphTrainer - INFO -   map@5: 0.015864
2025-11-22 21:23:55 - GraphTrainer - INFO -   mrr@5: 0.016541
2025-11-22 21:23:55 - GraphTrainer - INFO -   precision@10: 0.004932
2025-11-22 21:23:55 - GraphTrainer - INFO -   recall@10: 0.046533
2025-11-22 21:23:55 - GraphTrainer - INFO -   hit_rate@10: 0.049164
2025-11-22 21:23:55 - GraphTrainer - INFO -   ndcg@10: 0.024929
2025-11-22 21:23:55 - GraphTrainer - INFO -   map@10: 0.018068
2025-11-22 21:23:55 - GraphTrainer - INFO -   mrr@10: 0.018886
2025-11-22 21:23:55 - GraphTrainer - INFO -   precision@20: 0.003975
2025-11-22 21:23:55 - GraphTrainer - INFO -   recall@20: 0.075092
2025-11-22 21:23:55 - GraphTrainer - INFO -   hit_rate@20: 0.078992
2025-11-22 21:23:55 - GraphTrainer - INFO -   ndcg@20: 0.032168
2025-11-22 21:23:55 - GraphTrainer - INFO -   map@20: 0.020005
2025-11-22 21:23:55 - GraphTrainer - INFO -   mrr@20: 0.020902
2025-11-22 21:23:55 - GraphTrainer - INFO - 第 91 轮训练完成
2025-11-22 21:23:55 - GraphTrainer - INFO - train_loss: 0.295511
2025-11-22 21:23:55 - GraphTrainer - INFO - precision@5: 0.006233
2025-11-22 21:23:55 - GraphTrainer - INFO - recall@5: 0.029733
2025-11-22 21:23:55 - GraphTrainer - INFO - hit_rate@5: 0.031165
2025-11-22 21:23:55 - GraphTrainer - INFO - ndcg@5: 0.019459
2025-11-22 21:23:55 - GraphTrainer - INFO - map@5: 0.015864
2025-11-22 21:23:55 - GraphTrainer - INFO - mrr@5: 0.016541
2025-11-22 21:23:55 - GraphTrainer - INFO - precision@10: 0.004932
2025-11-22 21:23:55 - GraphTrainer - INFO - recall@10: 0.046533
2025-11-22 21:23:55 - GraphTrainer - INFO - hit_rate@10: 0.049164
2025-11-22 21:23:55 - GraphTrainer - INFO - ndcg@10: 0.024929
2025-11-22 21:23:55 - GraphTrainer - INFO - map@10: 0.018068
2025-11-22 21:23:55 - GraphTrainer - INFO - mrr@10: 0.018886
2025-11-22 21:23:55 - GraphTrainer - INFO - precision@20: 0.003975
2025-11-22 21:23:55 - GraphTrainer - INFO - recall@20: 0.075092
2025-11-22 21:23:55 - GraphTrainer - INFO - hit_rate@20: 0.078992
2025-11-22 21:23:55 - GraphTrainer - INFO - ndcg@20: 0.032168
2025-11-22 21:23:55 - GraphTrainer - INFO - map@20: 0.020005
2025-11-22 21:23:55 - GraphTrainer - INFO - mrr@20: 0.020902
2025-11-22 21:23:55 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:23:55 - GraphTrainer - INFO - ============================================================
2025-11-22 21:23:55 - GraphTrainer - INFO - 开始第 92/1000 轮训练
2025-11-22 21:23:55 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3032, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2773, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2900, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2923, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3179, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2777, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2882, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2740, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3171, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2832, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2904, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3048, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3042, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2990, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2933, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2930, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2948, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2924, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2889, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2990, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2872, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2758, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2695, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2954, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3218, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2816, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2793, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3130, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3038, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2889, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2799, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3051, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3099, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2759, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3117, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3102, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2687, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2959, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3044, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3133, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2963, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2841, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3091, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2970, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3002, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2986, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3028, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2968, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3107, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2930, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2853, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2879, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3101, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2917, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3006, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3057, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3058, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2920, device='cuda:0', grad_fn=<AddBackward0>)
The 91 training average loss: 0.2955109867556342
2025-11-22 21:24:06 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:24:06 - GraphTrainer - INFO -   precision@5: 0.006408
2025-11-22 21:24:06 - GraphTrainer - INFO -   recall@5: 0.030328
2025-11-22 21:24:06 - GraphTrainer - INFO -   hit_rate@5: 0.031988
2025-11-22 21:24:06 - GraphTrainer - INFO -   ndcg@5: 0.020207
2025-11-22 21:24:06 - GraphTrainer - INFO -   map@5: 0.016619
2025-11-22 21:24:06 - GraphTrainer - INFO -   mrr@5: 0.017413
2025-11-22 21:24:06 - GraphTrainer - INFO -   precision@10: 0.004999
2025-11-22 21:24:06 - GraphTrainer - INFO -   recall@10: 0.047108
2025-11-22 21:24:06 - GraphTrainer - INFO -   hit_rate@10: 0.049781
2025-11-22 21:24:06 - GraphTrainer - INFO -   ndcg@10: 0.025627
2025-11-22 21:24:06 - GraphTrainer - INFO -   map@10: 0.018788
2025-11-22 21:24:06 - GraphTrainer - INFO -   mrr@10: 0.019708
2025-11-22 21:24:06 - GraphTrainer - INFO -   precision@20: 0.003998
2025-11-22 21:24:06 - GraphTrainer - INFO -   recall@20: 0.075819
2025-11-22 21:24:06 - GraphTrainer - INFO -   hit_rate@20: 0.079609
2025-11-22 21:24:06 - GraphTrainer - INFO -   ndcg@20: 0.032870
2025-11-22 21:24:06 - GraphTrainer - INFO -   map@20: 0.020718
2025-11-22 21:24:06 - GraphTrainer - INFO -   mrr@20: 0.021712
2025-11-22 21:24:06 - GraphTrainer - INFO - 第 92 轮训练完成
2025-11-22 21:24:06 - GraphTrainer - INFO - train_loss: 0.295815
2025-11-22 21:24:06 - GraphTrainer - INFO - precision@5: 0.006408
2025-11-22 21:24:06 - GraphTrainer - INFO - recall@5: 0.030328
2025-11-22 21:24:06 - GraphTrainer - INFO - hit_rate@5: 0.031988
2025-11-22 21:24:06 - GraphTrainer - INFO - ndcg@5: 0.020207
2025-11-22 21:24:06 - GraphTrainer - INFO - map@5: 0.016619
2025-11-22 21:24:06 - GraphTrainer - INFO - mrr@5: 0.017413
2025-11-22 21:24:06 - GraphTrainer - INFO - precision@10: 0.004999
2025-11-22 21:24:06 - GraphTrainer - INFO - recall@10: 0.047108
2025-11-22 21:24:06 - GraphTrainer - INFO - hit_rate@10: 0.049781
2025-11-22 21:24:06 - GraphTrainer - INFO - ndcg@10: 0.025627
2025-11-22 21:24:06 - GraphTrainer - INFO - map@10: 0.018788
2025-11-22 21:24:06 - GraphTrainer - INFO - mrr@10: 0.019708
2025-11-22 21:24:06 - GraphTrainer - INFO - precision@20: 0.003998
2025-11-22 21:24:06 - GraphTrainer - INFO - recall@20: 0.075819
2025-11-22 21:24:06 - GraphTrainer - INFO - hit_rate@20: 0.079609
2025-11-22 21:24:06 - GraphTrainer - INFO - ndcg@20: 0.032870
2025-11-22 21:24:06 - GraphTrainer - INFO - map@20: 0.020718
2025-11-22 21:24:06 - GraphTrainer - INFO - mrr@20: 0.021712
2025-11-22 21:24:06 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:24:06 - GraphTrainer - INFO - ============================================================
2025-11-22 21:24:06 - GraphTrainer - INFO - 开始第 93/1000 轮训练
2025-11-22 21:24:06 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2745, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2835, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2887, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2916, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2903, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3169, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2807, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3200, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3034, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2852, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2952, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3101, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2884, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3082, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2678, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2977, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3117, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3073, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2994, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2873, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2932, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2991, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2892, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2848, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2952, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2890, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2974, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2973, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3024, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3048, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3041, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2862, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3107, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2968, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2756, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2911, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3037, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2934, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2675, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2949, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3201, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3217, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2914, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2993, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2883, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2727, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2988, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3024, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2960, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3146, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2822, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3090, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2960, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2910, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2906, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2748, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2972, device='cuda:0', grad_fn=<AddBackward0>)
The 92 training average loss: 0.2958146749899305
2025-11-22 21:24:17 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:24:17 - GraphTrainer - INFO -   precision@5: 0.006542
2025-11-22 21:24:17 - GraphTrainer - INFO -   recall@5: 0.031331
2025-11-22 21:24:17 - GraphTrainer - INFO -   hit_rate@5: 0.032708
2025-11-22 21:24:17 - GraphTrainer - INFO -   ndcg@5: 0.020683
2025-11-22 21:24:17 - GraphTrainer - INFO -   map@5: 0.016972
2025-11-22 21:24:17 - GraphTrainer - INFO -   mrr@5: 0.017633
2025-11-22 21:24:17 - GraphTrainer - INFO -   precision@10: 0.005127
2025-11-22 21:24:17 - GraphTrainer - INFO -   recall@10: 0.048459
2025-11-22 21:24:17 - GraphTrainer - INFO -   hit_rate@10: 0.051170
2025-11-22 21:24:17 - GraphTrainer - INFO -   ndcg@10: 0.026266
2025-11-22 21:24:17 - GraphTrainer - INFO -   map@10: 0.019216
2025-11-22 21:24:17 - GraphTrainer - INFO -   mrr@10: 0.020042
2025-11-22 21:24:17 - GraphTrainer - INFO -   precision@20: 0.004055
2025-11-22 21:24:17 - GraphTrainer - INFO -   recall@20: 0.076389
2025-11-22 21:24:17 - GraphTrainer - INFO -   hit_rate@20: 0.080586
2025-11-22 21:24:17 - GraphTrainer - INFO -   ndcg@20: 0.033399
2025-11-22 21:24:17 - GraphTrainer - INFO -   map@20: 0.021144
2025-11-22 21:24:17 - GraphTrainer - INFO -   mrr@20: 0.022058
2025-11-22 21:24:17 - GraphTrainer - INFO - 第 93 轮训练完成
2025-11-22 21:24:17 - GraphTrainer - INFO - train_loss: 0.286700
2025-11-22 21:24:17 - GraphTrainer - INFO - precision@5: 0.006542
2025-11-22 21:24:17 - GraphTrainer - INFO - recall@5: 0.031331
2025-11-22 21:24:17 - GraphTrainer - INFO - hit_rate@5: 0.032708
2025-11-22 21:24:17 - GraphTrainer - INFO - ndcg@5: 0.020683
2025-11-22 21:24:17 - GraphTrainer - INFO - map@5: 0.016972
2025-11-22 21:24:17 - GraphTrainer - INFO - mrr@5: 0.017633
2025-11-22 21:24:17 - GraphTrainer - INFO - precision@10: 0.005127
2025-11-22 21:24:17 - GraphTrainer - INFO - recall@10: 0.048459
2025-11-22 21:24:17 - GraphTrainer - INFO - hit_rate@10: 0.051170
2025-11-22 21:24:17 - GraphTrainer - INFO - ndcg@10: 0.026266
2025-11-22 21:24:17 - GraphTrainer - INFO - map@10: 0.019216
2025-11-22 21:24:17 - GraphTrainer - INFO - mrr@10: 0.020042
2025-11-22 21:24:17 - GraphTrainer - INFO - precision@20: 0.004055
2025-11-22 21:24:17 - GraphTrainer - INFO - recall@20: 0.076389
2025-11-22 21:24:17 - GraphTrainer - INFO - hit_rate@20: 0.080586
2025-11-22 21:24:17 - GraphTrainer - INFO - ndcg@20: 0.033399
2025-11-22 21:24:17 - GraphTrainer - INFO - map@20: 0.021144
2025-11-22 21:24:17 - GraphTrainer - INFO - mrr@20: 0.022058
2025-11-22 21:24:17 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:24:17 - GraphTrainer - INFO - ============================================================
2025-11-22 21:24:17 - GraphTrainer - INFO - 开始第 94/1000 轮训练
2025-11-22 21:24:17 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2831, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2562, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2820, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2691, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2822, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2903, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3029, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2834, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2825, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3089, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3048, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2596, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2982, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3070, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2672, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2902, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2809, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2710, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2903, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2880, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2839, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2995, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2781, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2832, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3093, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2978, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2880, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2955, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2796, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2792, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2969, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3027, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3014, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2671, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2737, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2676, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2863, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2992, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3059, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2807, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3151, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3063, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2629, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2937, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2967, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2902, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2996, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2788, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2837, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2598, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2978, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2946, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2879, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2955, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2910, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2838, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2659, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2522, device='cuda:0', grad_fn=<AddBackward0>)
The 93 training average loss: 0.28669998203885966
2025-11-22 21:24:28 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:24:28 - GraphTrainer - INFO -   precision@5: 0.006686
2025-11-22 21:24:28 - GraphTrainer - INFO -   recall@5: 0.031939
2025-11-22 21:24:28 - GraphTrainer - INFO -   hit_rate@5: 0.033428
2025-11-22 21:24:28 - GraphTrainer - INFO -   ndcg@5: 0.021149
2025-11-22 21:24:28 - GraphTrainer - INFO -   map@5: 0.017364
2025-11-22 21:24:28 - GraphTrainer - INFO -   mrr@5: 0.018057
2025-11-22 21:24:28 - GraphTrainer - INFO -   precision@10: 0.005266
2025-11-22 21:24:28 - GraphTrainer - INFO -   recall@10: 0.049925
2025-11-22 21:24:28 - GraphTrainer - INFO -   hit_rate@10: 0.052404
2025-11-22 21:24:28 - GraphTrainer - INFO -   ndcg@10: 0.026988
2025-11-22 21:24:28 - GraphTrainer - INFO -   map@10: 0.019720
2025-11-22 21:24:28 - GraphTrainer - INFO -   mrr@10: 0.020534
2025-11-22 21:24:28 - GraphTrainer - INFO -   precision@20: 0.004168
2025-11-22 21:24:28 - GraphTrainer - INFO -   recall@20: 0.078789
2025-11-22 21:24:28 - GraphTrainer - INFO -   hit_rate@20: 0.082798
2025-11-22 21:24:28 - GraphTrainer - INFO -   ndcg@20: 0.034343
2025-11-22 21:24:28 - GraphTrainer - INFO -   map@20: 0.021699
2025-11-22 21:24:28 - GraphTrainer - INFO -   mrr@20: 0.022615
2025-11-22 21:24:28 - GraphTrainer - INFO - 第 94 轮训练完成
2025-11-22 21:24:28 - GraphTrainer - INFO - train_loss: 0.281788
2025-11-22 21:24:28 - GraphTrainer - INFO - precision@5: 0.006686
2025-11-22 21:24:28 - GraphTrainer - INFO - recall@5: 0.031939
2025-11-22 21:24:28 - GraphTrainer - INFO - hit_rate@5: 0.033428
2025-11-22 21:24:28 - GraphTrainer - INFO - ndcg@5: 0.021149
2025-11-22 21:24:28 - GraphTrainer - INFO - map@5: 0.017364
2025-11-22 21:24:28 - GraphTrainer - INFO - mrr@5: 0.018057
2025-11-22 21:24:28 - GraphTrainer - INFO - precision@10: 0.005266
2025-11-22 21:24:28 - GraphTrainer - INFO - recall@10: 0.049925
2025-11-22 21:24:28 - GraphTrainer - INFO - hit_rate@10: 0.052404
2025-11-22 21:24:28 - GraphTrainer - INFO - ndcg@10: 0.026988
2025-11-22 21:24:28 - GraphTrainer - INFO - map@10: 0.019720
2025-11-22 21:24:28 - GraphTrainer - INFO - mrr@10: 0.020534
2025-11-22 21:24:28 - GraphTrainer - INFO - precision@20: 0.004168
2025-11-22 21:24:28 - GraphTrainer - INFO - recall@20: 0.078789
2025-11-22 21:24:28 - GraphTrainer - INFO - hit_rate@20: 0.082798
2025-11-22 21:24:28 - GraphTrainer - INFO - ndcg@20: 0.034343
2025-11-22 21:24:28 - GraphTrainer - INFO - map@20: 0.021699
2025-11-22 21:24:28 - GraphTrainer - INFO - mrr@20: 0.022615
2025-11-22 21:24:28 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:24:28 - GraphTrainer - INFO - ============================================================
2025-11-22 21:24:28 - GraphTrainer - INFO - 开始第 95/1000 轮训练
2025-11-22 21:24:28 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2755, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2880, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2818, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2532, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2975, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2609, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2724, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2766, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2633, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2777, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2942, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2785, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2922, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2780, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2703, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2717, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2702, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2848, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3024, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2912, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2981, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2775, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2953, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2789, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2849, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2731, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2883, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2671, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2703, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3039, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2756, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3028, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2795, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2893, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2867, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2959, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2731, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2628, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2724, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2974, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2770, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2715, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2799, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2940, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3012, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2796, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2799, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3012, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2865, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2872, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2757, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2624, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2817, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2797, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2816, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2823, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2789, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2903, device='cuda:0', grad_fn=<AddBackward0>)
The 94 training average loss: 0.28178761539788083
2025-11-22 21:24:39 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:24:39 - GraphTrainer - INFO -   precision@5: 0.006531
2025-11-22 21:24:39 - GraphTrainer - INFO -   recall@5: 0.031331
2025-11-22 21:24:39 - GraphTrainer - INFO -   hit_rate@5: 0.032656
2025-11-22 21:24:39 - GraphTrainer - INFO -   ndcg@5: 0.020822
2025-11-22 21:24:39 - GraphTrainer - INFO -   map@5: 0.017132
2025-11-22 21:24:39 - GraphTrainer - INFO -   mrr@5: 0.017815
2025-11-22 21:24:39 - GraphTrainer - INFO -   precision@10: 0.005112
2025-11-22 21:24:39 - GraphTrainer - INFO -   recall@10: 0.048771
2025-11-22 21:24:39 - GraphTrainer - INFO -   hit_rate@10: 0.051067
2025-11-22 21:24:39 - GraphTrainer - INFO -   ndcg@10: 0.026489
2025-11-22 21:24:39 - GraphTrainer - INFO -   map@10: 0.019425
2025-11-22 21:24:39 - GraphTrainer - INFO -   mrr@10: 0.020237
2025-11-22 21:24:39 - GraphTrainer - INFO -   precision@20: 0.004148
2025-11-22 21:24:39 - GraphTrainer - INFO -   recall@20: 0.078614
2025-11-22 21:24:39 - GraphTrainer - INFO -   hit_rate@20: 0.082592
2025-11-22 21:24:39 - GraphTrainer - INFO -   ndcg@20: 0.034066
2025-11-22 21:24:39 - GraphTrainer - INFO -   map@20: 0.021445
2025-11-22 21:24:39 - GraphTrainer - INFO -   mrr@20: 0.022362
2025-11-22 21:24:39 - GraphTrainer - INFO - 第 95 轮训练完成
2025-11-22 21:24:39 - GraphTrainer - INFO - train_loss: 0.282381
2025-11-22 21:24:39 - GraphTrainer - INFO - precision@5: 0.006531
2025-11-22 21:24:39 - GraphTrainer - INFO - recall@5: 0.031331
2025-11-22 21:24:39 - GraphTrainer - INFO - hit_rate@5: 0.032656
2025-11-22 21:24:39 - GraphTrainer - INFO - ndcg@5: 0.020822
2025-11-22 21:24:39 - GraphTrainer - INFO - map@5: 0.017132
2025-11-22 21:24:39 - GraphTrainer - INFO - mrr@5: 0.017815
2025-11-22 21:24:39 - GraphTrainer - INFO - precision@10: 0.005112
2025-11-22 21:24:39 - GraphTrainer - INFO - recall@10: 0.048771
2025-11-22 21:24:39 - GraphTrainer - INFO - hit_rate@10: 0.051067
2025-11-22 21:24:39 - GraphTrainer - INFO - ndcg@10: 0.026489
2025-11-22 21:24:39 - GraphTrainer - INFO - map@10: 0.019425
2025-11-22 21:24:39 - GraphTrainer - INFO - mrr@10: 0.020237
2025-11-22 21:24:39 - GraphTrainer - INFO - precision@20: 0.004148
2025-11-22 21:24:39 - GraphTrainer - INFO - recall@20: 0.078614
2025-11-22 21:24:39 - GraphTrainer - INFO - hit_rate@20: 0.082592
2025-11-22 21:24:39 - GraphTrainer - INFO - ndcg@20: 0.034066
2025-11-22 21:24:39 - GraphTrainer - INFO - map@20: 0.021445
2025-11-22 21:24:39 - GraphTrainer - INFO - mrr@20: 0.022362
2025-11-22 21:24:39 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:24:39 - GraphTrainer - INFO - ============================================================
2025-11-22 21:24:39 - GraphTrainer - INFO - 开始第 96/1000 轮训练
2025-11-22 21:24:39 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2649, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2693, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2643, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2636, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2928, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2958, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2868, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2905, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2844, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2738, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2761, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2628, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2959, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2728, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2693, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2843, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2843, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2591, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2835, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2679, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2692, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2719, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3019, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2812, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2936, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2827, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2781, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2808, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2773, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2714, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2866, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2918, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2890, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2955, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2664, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2869, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2923, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2834, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2992, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2811, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2825, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2707, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2976, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2921, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2864, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2914, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2863, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2861, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2895, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3051, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2996, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2788, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2736, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2599, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2741, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3029, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2935, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2852, device='cuda:0', grad_fn=<AddBackward0>)
The 95 training average loss: 0.28238134908265083
2025-11-22 21:24:50 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:24:50 - GraphTrainer - INFO -   precision@5: 0.006377
2025-11-22 21:24:50 - GraphTrainer - INFO -   recall@5: 0.030436
2025-11-22 21:24:50 - GraphTrainer - INFO -   hit_rate@5: 0.031885
2025-11-22 21:24:50 - GraphTrainer - INFO -   ndcg@5: 0.020323
2025-11-22 21:24:50 - GraphTrainer - INFO -   map@5: 0.016792
2025-11-22 21:24:50 - GraphTrainer - INFO -   mrr@5: 0.017375
2025-11-22 21:24:50 - GraphTrainer - INFO -   precision@10: 0.005184
2025-11-22 21:24:50 - GraphTrainer - INFO -   recall@10: 0.049218
2025-11-22 21:24:50 - GraphTrainer - INFO -   hit_rate@10: 0.051736
2025-11-22 21:24:50 - GraphTrainer - INFO -   ndcg@10: 0.026445
2025-11-22 21:24:50 - GraphTrainer - INFO -   map@10: 0.019279
2025-11-22 21:24:50 - GraphTrainer - INFO -   mrr@10: 0.019999
2025-11-22 21:24:50 - GraphTrainer - INFO -   precision@20: 0.004155
2025-11-22 21:24:50 - GraphTrainer - INFO -   recall@20: 0.078550
2025-11-22 21:24:50 - GraphTrainer - INFO -   hit_rate@20: 0.082386
2025-11-22 21:24:50 - GraphTrainer - INFO -   ndcg@20: 0.033914
2025-11-22 21:24:50 - GraphTrainer - INFO -   map@20: 0.021290
2025-11-22 21:24:50 - GraphTrainer - INFO -   mrr@20: 0.022093
2025-11-22 21:24:50 - GraphTrainer - INFO - 第 96 轮训练完成
2025-11-22 21:24:50 - GraphTrainer - INFO - train_loss: 0.279203
2025-11-22 21:24:50 - GraphTrainer - INFO - precision@5: 0.006377
2025-11-22 21:24:50 - GraphTrainer - INFO - recall@5: 0.030436
2025-11-22 21:24:50 - GraphTrainer - INFO - hit_rate@5: 0.031885
2025-11-22 21:24:50 - GraphTrainer - INFO - ndcg@5: 0.020323
2025-11-22 21:24:50 - GraphTrainer - INFO - map@5: 0.016792
2025-11-22 21:24:50 - GraphTrainer - INFO - mrr@5: 0.017375
2025-11-22 21:24:50 - GraphTrainer - INFO - precision@10: 0.005184
2025-11-22 21:24:50 - GraphTrainer - INFO - recall@10: 0.049218
2025-11-22 21:24:50 - GraphTrainer - INFO - hit_rate@10: 0.051736
2025-11-22 21:24:50 - GraphTrainer - INFO - ndcg@10: 0.026445
2025-11-22 21:24:50 - GraphTrainer - INFO - map@10: 0.019279
2025-11-22 21:24:50 - GraphTrainer - INFO - mrr@10: 0.019999
2025-11-22 21:24:50 - GraphTrainer - INFO - precision@20: 0.004155
2025-11-22 21:24:50 - GraphTrainer - INFO - recall@20: 0.078550
2025-11-22 21:24:50 - GraphTrainer - INFO - hit_rate@20: 0.082386
2025-11-22 21:24:50 - GraphTrainer - INFO - ndcg@20: 0.033914
2025-11-22 21:24:50 - GraphTrainer - INFO - map@20: 0.021290
2025-11-22 21:24:50 - GraphTrainer - INFO - mrr@20: 0.022093
2025-11-22 21:24:50 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:24:50 - GraphTrainer - INFO - ============================================================
2025-11-22 21:24:50 - GraphTrainer - INFO - 开始第 97/1000 轮训练
2025-11-22 21:24:50 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2776, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2723, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2926, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2877, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2519, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2935, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2851, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2983, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2851, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2848, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2777, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2960, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2725, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2810, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2614, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2735, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3043, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2822, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2617, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2838, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2914, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2920, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2883, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2766, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2988, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2828, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2644, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2682, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2850, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2632, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2833, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2776, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2882, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2704, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2693, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2766, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2786, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2828, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2810, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2741, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2742, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2709, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2853, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2534, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2723, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2768, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2779, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2998, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2895, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2710, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2813, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2700, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2650, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2855, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2710, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2698, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2710, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2932, device='cuda:0', grad_fn=<AddBackward0>)
The 96 training average loss: 0.27920268578776
2025-11-22 21:25:01 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:25:01 - GraphTrainer - INFO -   precision@5: 0.006151
2025-11-22 21:25:01 - GraphTrainer - INFO -   recall@5: 0.029521
2025-11-22 21:25:01 - GraphTrainer - INFO -   hit_rate@5: 0.030753
2025-11-22 21:25:01 - GraphTrainer - INFO -   ndcg@5: 0.020145
2025-11-22 21:25:01 - GraphTrainer - INFO -   map@5: 0.016849
2025-11-22 21:25:01 - GraphTrainer - INFO -   mrr@5: 0.017526
2025-11-22 21:25:01 - GraphTrainer - INFO -   precision@10: 0.005030
2025-11-22 21:25:01 - GraphTrainer - INFO -   recall@10: 0.047587
2025-11-22 21:25:01 - GraphTrainer - INFO -   hit_rate@10: 0.050193
2025-11-22 21:25:01 - GraphTrainer - INFO -   ndcg@10: 0.026080
2025-11-22 21:25:01 - GraphTrainer - INFO -   map@10: 0.019263
2025-11-22 21:25:01 - GraphTrainer - INFO -   mrr@10: 0.020121
2025-11-22 21:25:01 - GraphTrainer - INFO -   precision@20: 0.004127
2025-11-22 21:25:01 - GraphTrainer - INFO -   recall@20: 0.078108
2025-11-22 21:25:01 - GraphTrainer - INFO -   hit_rate@20: 0.082232
2025-11-22 21:25:01 - GraphTrainer - INFO -   ndcg@20: 0.033818
2025-11-22 21:25:01 - GraphTrainer - INFO -   map@20: 0.021333
2025-11-22 21:25:01 - GraphTrainer - INFO -   mrr@20: 0.022291
2025-11-22 21:25:01 - GraphTrainer - INFO - 第 97 轮训练完成
2025-11-22 21:25:01 - GraphTrainer - INFO - train_loss: 0.281999
2025-11-22 21:25:01 - GraphTrainer - INFO - precision@5: 0.006151
2025-11-22 21:25:01 - GraphTrainer - INFO - recall@5: 0.029521
2025-11-22 21:25:01 - GraphTrainer - INFO - hit_rate@5: 0.030753
2025-11-22 21:25:01 - GraphTrainer - INFO - ndcg@5: 0.020145
2025-11-22 21:25:01 - GraphTrainer - INFO - map@5: 0.016849
2025-11-22 21:25:01 - GraphTrainer - INFO - mrr@5: 0.017526
2025-11-22 21:25:01 - GraphTrainer - INFO - precision@10: 0.005030
2025-11-22 21:25:01 - GraphTrainer - INFO - recall@10: 0.047587
2025-11-22 21:25:01 - GraphTrainer - INFO - hit_rate@10: 0.050193
2025-11-22 21:25:01 - GraphTrainer - INFO - ndcg@10: 0.026080
2025-11-22 21:25:01 - GraphTrainer - INFO - map@10: 0.019263
2025-11-22 21:25:01 - GraphTrainer - INFO - mrr@10: 0.020121
2025-11-22 21:25:01 - GraphTrainer - INFO - precision@20: 0.004127
2025-11-22 21:25:01 - GraphTrainer - INFO - recall@20: 0.078108
2025-11-22 21:25:01 - GraphTrainer - INFO - hit_rate@20: 0.082232
2025-11-22 21:25:01 - GraphTrainer - INFO - ndcg@20: 0.033818
2025-11-22 21:25:01 - GraphTrainer - INFO - map@20: 0.021333
2025-11-22 21:25:01 - GraphTrainer - INFO - mrr@20: 0.022291
2025-11-22 21:25:01 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:25:01 - GraphTrainer - INFO - ============================================================
2025-11-22 21:25:01 - GraphTrainer - INFO - 开始第 98/1000 轮训练
2025-11-22 21:25:01 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2839, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2708, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3071, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2609, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2656, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2882, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2671, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2998, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2835, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2839, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2903, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2493, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2754, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2770, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2705, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2622, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2801, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2606, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3136, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2775, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2940, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2782, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2888, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2790, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2856, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3103, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2964, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2619, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2752, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2812, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2786, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3018, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2642, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2723, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2975, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2916, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2806, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3022, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2703, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2742, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2850, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2848, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2628, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2744, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2874, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2982, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2836, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2827, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3168, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2880, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2840, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2680, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2851, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2504, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2917, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3069, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2747, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2803, device='cuda:0', grad_fn=<AddBackward0>)
The 97 training average loss: 0.2819988216305601
2025-11-22 21:25:12 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:25:12 - GraphTrainer - INFO -   precision@5: 0.006644
2025-11-22 21:25:12 - GraphTrainer - INFO -   recall@5: 0.031760
2025-11-22 21:25:12 - GraphTrainer - INFO -   hit_rate@5: 0.033222
2025-11-22 21:25:12 - GraphTrainer - INFO -   ndcg@5: 0.021254
2025-11-22 21:25:12 - GraphTrainer - INFO -   map@5: 0.017560
2025-11-22 21:25:12 - GraphTrainer - INFO -   mrr@5: 0.018320
2025-11-22 21:25:12 - GraphTrainer - INFO -   precision@10: 0.005240
2025-11-22 21:25:12 - GraphTrainer - INFO -   recall@10: 0.049545
2025-11-22 21:25:12 - GraphTrainer - INFO -   hit_rate@10: 0.052301
2025-11-22 21:25:12 - GraphTrainer - INFO -   ndcg@10: 0.027016
2025-11-22 21:25:12 - GraphTrainer - INFO -   map@10: 0.019864
2025-11-22 21:25:12 - GraphTrainer - INFO -   mrr@10: 0.020786
2025-11-22 21:25:12 - GraphTrainer - INFO -   precision@20: 0.004189
2025-11-22 21:25:12 - GraphTrainer - INFO -   recall@20: 0.078906
2025-11-22 21:25:12 - GraphTrainer - INFO -   hit_rate@20: 0.083312
2025-11-22 21:25:12 - GraphTrainer - INFO -   ndcg@20: 0.034484
2025-11-22 21:25:12 - GraphTrainer - INFO -   map@20: 0.021860
2025-11-22 21:25:12 - GraphTrainer - INFO -   mrr@20: 0.022890
2025-11-22 21:25:12 - GraphTrainer - INFO - 第 98 轮训练完成
2025-11-22 21:25:12 - GraphTrainer - INFO - train_loss: 0.279148
2025-11-22 21:25:12 - GraphTrainer - INFO - precision@5: 0.006644
2025-11-22 21:25:12 - GraphTrainer - INFO - recall@5: 0.031760
2025-11-22 21:25:12 - GraphTrainer - INFO - hit_rate@5: 0.033222
2025-11-22 21:25:12 - GraphTrainer - INFO - ndcg@5: 0.021254
2025-11-22 21:25:12 - GraphTrainer - INFO - map@5: 0.017560
2025-11-22 21:25:12 - GraphTrainer - INFO - mrr@5: 0.018320
2025-11-22 21:25:12 - GraphTrainer - INFO - precision@10: 0.005240
2025-11-22 21:25:12 - GraphTrainer - INFO - recall@10: 0.049545
2025-11-22 21:25:12 - GraphTrainer - INFO - hit_rate@10: 0.052301
2025-11-22 21:25:12 - GraphTrainer - INFO - ndcg@10: 0.027016
2025-11-22 21:25:12 - GraphTrainer - INFO - map@10: 0.019864
2025-11-22 21:25:12 - GraphTrainer - INFO - mrr@10: 0.020786
2025-11-22 21:25:12 - GraphTrainer - INFO - precision@20: 0.004189
2025-11-22 21:25:12 - GraphTrainer - INFO - recall@20: 0.078906
2025-11-22 21:25:12 - GraphTrainer - INFO - hit_rate@20: 0.083312
2025-11-22 21:25:12 - GraphTrainer - INFO - ndcg@20: 0.034484
2025-11-22 21:25:12 - GraphTrainer - INFO - map@20: 0.021860
2025-11-22 21:25:12 - GraphTrainer - INFO - mrr@20: 0.022890
2025-11-22 21:25:12 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:25:12 - GraphTrainer - INFO - ============================================================
2025-11-22 21:25:12 - GraphTrainer - INFO - 开始第 99/1000 轮训练
2025-11-22 21:25:12 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2795, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2801, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2947, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2992, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2492, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2765, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2767, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2730, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2687, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2651, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2921, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2803, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2819, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2758, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2684, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2873, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2725, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2745, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2881, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2805, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2801, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2858, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2950, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2610, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2748, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2785, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2570, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2956, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2736, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2943, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2943, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2805, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2842, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2761, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2687, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2632, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2622, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2762, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2719, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2681, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2829, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2764, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2855, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2764, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2551, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2967, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2921, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2873, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2747, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2940, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2694, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2842, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2646, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2896, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2816, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2963, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2798, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2991, device='cuda:0', grad_fn=<AddBackward0>)
The 98 training average loss: 0.2791479841388505
2025-11-22 21:25:23 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:25:23 - GraphTrainer - INFO -   precision@5: 0.006706
2025-11-22 21:25:23 - GraphTrainer - INFO -   recall@5: 0.031929
2025-11-22 21:25:23 - GraphTrainer - INFO -   hit_rate@5: 0.033530
2025-11-22 21:25:23 - GraphTrainer - INFO -   ndcg@5: 0.021274
2025-11-22 21:25:23 - GraphTrainer - INFO -   map@5: 0.017506
2025-11-22 21:25:23 - GraphTrainer - INFO -   mrr@5: 0.018322
2025-11-22 21:25:23 - GraphTrainer - INFO -   precision@10: 0.005354
2025-11-22 21:25:23 - GraphTrainer - INFO -   recall@10: 0.050809
2025-11-22 21:25:23 - GraphTrainer - INFO -   hit_rate@10: 0.053433
2025-11-22 21:25:23 - GraphTrainer - INFO -   ndcg@10: 0.027392
2025-11-22 21:25:23 - GraphTrainer - INFO -   map@10: 0.019972
2025-11-22 21:25:23 - GraphTrainer - INFO -   mrr@10: 0.020922
2025-11-22 21:25:23 - GraphTrainer - INFO -   precision@20: 0.004189
2025-11-22 21:25:23 - GraphTrainer - INFO -   recall@20: 0.079156
2025-11-22 21:25:23 - GraphTrainer - INFO -   hit_rate@20: 0.083415
2025-11-22 21:25:23 - GraphTrainer - INFO -   ndcg@20: 0.034588
2025-11-22 21:25:23 - GraphTrainer - INFO -   map@20: 0.021888
2025-11-22 21:25:23 - GraphTrainer - INFO -   mrr@20: 0.022946
2025-11-22 21:25:23 - GraphTrainer - INFO - 第 99 轮训练完成
2025-11-22 21:25:23 - GraphTrainer - INFO - train_loss: 0.276367
2025-11-22 21:25:23 - GraphTrainer - INFO - precision@5: 0.006706
2025-11-22 21:25:23 - GraphTrainer - INFO - recall@5: 0.031929
2025-11-22 21:25:23 - GraphTrainer - INFO - hit_rate@5: 0.033530
2025-11-22 21:25:23 - GraphTrainer - INFO - ndcg@5: 0.021274
2025-11-22 21:25:23 - GraphTrainer - INFO - map@5: 0.017506
2025-11-22 21:25:23 - GraphTrainer - INFO - mrr@5: 0.018322
2025-11-22 21:25:23 - GraphTrainer - INFO - precision@10: 0.005354
2025-11-22 21:25:23 - GraphTrainer - INFO - recall@10: 0.050809
2025-11-22 21:25:23 - GraphTrainer - INFO - hit_rate@10: 0.053433
2025-11-22 21:25:23 - GraphTrainer - INFO - ndcg@10: 0.027392
2025-11-22 21:25:23 - GraphTrainer - INFO - map@10: 0.019972
2025-11-22 21:25:23 - GraphTrainer - INFO - mrr@10: 0.020922
2025-11-22 21:25:23 - GraphTrainer - INFO - precision@20: 0.004189
2025-11-22 21:25:23 - GraphTrainer - INFO - recall@20: 0.079156
2025-11-22 21:25:23 - GraphTrainer - INFO - hit_rate@20: 0.083415
2025-11-22 21:25:23 - GraphTrainer - INFO - ndcg@20: 0.034588
2025-11-22 21:25:23 - GraphTrainer - INFO - map@20: 0.021888
2025-11-22 21:25:23 - GraphTrainer - INFO - mrr@20: 0.022946
2025-11-22 21:25:23 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:25:23 - GraphTrainer - INFO - ============================================================
2025-11-22 21:25:23 - GraphTrainer - INFO - 开始第 100/1000 轮训练
2025-11-22 21:25:23 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2798, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2751, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2855, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2758, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2754, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2735, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2806, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2840, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2940, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2855, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2731, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2630, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2816, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2662, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2859, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2886, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2718, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2704, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2865, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2809, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2700, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2781, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2779, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2840, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2544, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2736, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2833, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2714, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2600, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2567, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2892, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2699, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2882, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2874, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2919, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2603, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2681, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2752, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2823, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2932, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2834, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2854, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2626, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2803, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2675, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2583, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2571, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2894, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2726, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2783, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2690, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2918, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2640, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2758, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2693, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2772, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2912, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2637, device='cuda:0', grad_fn=<AddBackward0>)
The 99 training average loss: 0.2763665780938905
2025-11-22 21:25:34 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:25:34 - GraphTrainer - INFO -   precision@5: 0.006747
2025-11-22 21:25:34 - GraphTrainer - INFO -   recall@5: 0.032301
2025-11-22 21:25:34 - GraphTrainer - INFO -   hit_rate@5: 0.033736
2025-11-22 21:25:34 - GraphTrainer - INFO -   ndcg@5: 0.021371
2025-11-22 21:25:34 - GraphTrainer - INFO -   map@5: 0.017557
2025-11-22 21:25:34 - GraphTrainer - INFO -   mrr@5: 0.018239
2025-11-22 21:25:34 - GraphTrainer - INFO -   precision@10: 0.005163
2025-11-22 21:25:34 - GraphTrainer - INFO -   recall@10: 0.049168
2025-11-22 21:25:34 - GraphTrainer - INFO -   hit_rate@10: 0.051581
2025-11-22 21:25:34 - GraphTrainer - INFO -   ndcg@10: 0.026846
2025-11-22 21:25:34 - GraphTrainer - INFO -   map@10: 0.019766
2025-11-22 21:25:34 - GraphTrainer - INFO -   mrr@10: 0.020575
2025-11-22 21:25:34 - GraphTrainer - INFO -   precision@20: 0.004140
2025-11-22 21:25:34 - GraphTrainer - INFO -   recall@20: 0.078055
2025-11-22 21:25:34 - GraphTrainer - INFO -   hit_rate@20: 0.082232
2025-11-22 21:25:34 - GraphTrainer - INFO -   ndcg@20: 0.034210
2025-11-22 21:25:34 - GraphTrainer - INFO -   map@20: 0.021733
2025-11-22 21:25:34 - GraphTrainer - INFO -   mrr@20: 0.022660
2025-11-22 21:25:34 - GraphTrainer - INFO - 第 100 轮训练完成
2025-11-22 21:25:34 - GraphTrainer - INFO - train_loss: 0.277974
2025-11-22 21:25:34 - GraphTrainer - INFO - precision@5: 0.006747
2025-11-22 21:25:34 - GraphTrainer - INFO - recall@5: 0.032301
2025-11-22 21:25:34 - GraphTrainer - INFO - hit_rate@5: 0.033736
2025-11-22 21:25:34 - GraphTrainer - INFO - ndcg@5: 0.021371
2025-11-22 21:25:34 - GraphTrainer - INFO - map@5: 0.017557
2025-11-22 21:25:34 - GraphTrainer - INFO - mrr@5: 0.018239
2025-11-22 21:25:34 - GraphTrainer - INFO - precision@10: 0.005163
2025-11-22 21:25:34 - GraphTrainer - INFO - recall@10: 0.049168
2025-11-22 21:25:34 - GraphTrainer - INFO - hit_rate@10: 0.051581
2025-11-22 21:25:34 - GraphTrainer - INFO - ndcg@10: 0.026846
2025-11-22 21:25:34 - GraphTrainer - INFO - map@10: 0.019766
2025-11-22 21:25:34 - GraphTrainer - INFO - mrr@10: 0.020575
2025-11-22 21:25:34 - GraphTrainer - INFO - precision@20: 0.004140
2025-11-22 21:25:34 - GraphTrainer - INFO - recall@20: 0.078055
2025-11-22 21:25:34 - GraphTrainer - INFO - hit_rate@20: 0.082232
2025-11-22 21:25:34 - GraphTrainer - INFO - ndcg@20: 0.034210
2025-11-22 21:25:34 - GraphTrainer - INFO - map@20: 0.021733
2025-11-22 21:25:34 - GraphTrainer - INFO - mrr@20: 0.022660
2025-11-22 21:25:34 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:25:34 - GraphTrainer - INFO - 检查点已保存: Epoch 100 -> ./checkpoints/checkpoint_epoch_100.pth
2025-11-22 21:25:34 - GraphTrainer - INFO - ============================================================
2025-11-22 21:25:34 - GraphTrainer - INFO - 开始第 101/1000 轮训练
2025-11-22 21:25:34 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2801, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2796, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2748, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2890, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2930, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3050, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2718, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2995, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2984, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2824, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2629, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2585, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2621, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2829, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2764, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2729, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2899, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2707, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2841, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2808, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2879, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2772, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2893, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2624, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2694, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2895, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2786, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2904, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2759, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2633, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2640, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2848, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2751, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2669, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2975, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2767, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2901, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2524, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2844, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2920, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2553, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2805, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2663, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2931, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2666, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2730, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2988, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2908, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2908, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2646, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2621, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2675, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2815, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2917, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2713, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2637, device='cuda:0', grad_fn=<AddBackward0>)
The 100 training average loss: 0.27797403571934537
2025-11-22 21:25:45 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:25:45 - GraphTrainer - INFO -   precision@5: 0.006644
2025-11-22 21:25:45 - GraphTrainer - INFO -   recall@5: 0.031780
2025-11-22 21:25:45 - GraphTrainer - INFO -   hit_rate@5: 0.033222
2025-11-22 21:25:45 - GraphTrainer - INFO -   ndcg@5: 0.021285
2025-11-22 21:25:45 - GraphTrainer - INFO -   map@5: 0.017606
2025-11-22 21:25:45 - GraphTrainer - INFO -   mrr@5: 0.018269
2025-11-22 21:25:45 - GraphTrainer - INFO -   precision@10: 0.005215
2025-11-22 21:25:45 - GraphTrainer - INFO -   recall@10: 0.049607
2025-11-22 21:25:45 - GraphTrainer - INFO -   hit_rate@10: 0.052096
2025-11-22 21:25:45 - GraphTrainer - INFO -   ndcg@10: 0.027091
2025-11-22 21:25:45 - GraphTrainer - INFO -   map@10: 0.019962
2025-11-22 21:25:45 - GraphTrainer - INFO -   mrr@10: 0.020766
2025-11-22 21:25:45 - GraphTrainer - INFO -   precision@20: 0.004076
2025-11-22 21:25:45 - GraphTrainer - INFO -   recall@20: 0.077239
2025-11-22 21:25:45 - GraphTrainer - INFO -   hit_rate@20: 0.081101
2025-11-22 21:25:45 - GraphTrainer - INFO -   ndcg@20: 0.034131
2025-11-22 21:25:45 - GraphTrainer - INFO -   map@20: 0.021857
2025-11-22 21:25:45 - GraphTrainer - INFO -   mrr@20: 0.022746
2025-11-22 21:25:45 - GraphTrainer - INFO - 第 101 轮训练完成
2025-11-22 21:25:45 - GraphTrainer - INFO - train_loss: 0.278614
2025-11-22 21:25:45 - GraphTrainer - INFO - precision@5: 0.006644
2025-11-22 21:25:45 - GraphTrainer - INFO - recall@5: 0.031780
2025-11-22 21:25:45 - GraphTrainer - INFO - hit_rate@5: 0.033222
2025-11-22 21:25:45 - GraphTrainer - INFO - ndcg@5: 0.021285
2025-11-22 21:25:45 - GraphTrainer - INFO - map@5: 0.017606
2025-11-22 21:25:45 - GraphTrainer - INFO - mrr@5: 0.018269
2025-11-22 21:25:45 - GraphTrainer - INFO - precision@10: 0.005215
2025-11-22 21:25:45 - GraphTrainer - INFO - recall@10: 0.049607
2025-11-22 21:25:45 - GraphTrainer - INFO - hit_rate@10: 0.052096
2025-11-22 21:25:45 - GraphTrainer - INFO - ndcg@10: 0.027091
2025-11-22 21:25:45 - GraphTrainer - INFO - map@10: 0.019962
2025-11-22 21:25:45 - GraphTrainer - INFO - mrr@10: 0.020766
2025-11-22 21:25:45 - GraphTrainer - INFO - precision@20: 0.004076
2025-11-22 21:25:45 - GraphTrainer - INFO - recall@20: 0.077239
2025-11-22 21:25:45 - GraphTrainer - INFO - hit_rate@20: 0.081101
2025-11-22 21:25:45 - GraphTrainer - INFO - ndcg@20: 0.034131
2025-11-22 21:25:45 - GraphTrainer - INFO - map@20: 0.021857
2025-11-22 21:25:45 - GraphTrainer - INFO - mrr@20: 0.022746
2025-11-22 21:25:45 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:25:45 - GraphTrainer - INFO - ============================================================
2025-11-22 21:25:45 - GraphTrainer - INFO - 开始第 102/1000 轮训练
2025-11-22 21:25:45 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2866, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2650, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2839, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2867, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2674, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2786, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2543, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2990, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2826, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2920, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2681, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2601, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2775, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2793, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2689, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2848, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2928, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2814, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2910, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2762, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2615, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2815, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2890, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2718, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2832, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2658, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2972, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2480, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2915, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2846, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2691, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2896, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2681, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2724, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2887, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2874, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2765, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2869, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2695, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2901, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2694, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2822, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2709, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2811, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2890, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2937, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2750, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2563, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2879, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2868, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2889, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2855, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2796, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2671, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2566, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2856, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2809, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2745, device='cuda:0', grad_fn=<AddBackward0>)
The 101 training average loss: 0.2786144054141538
2025-11-22 21:25:55 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:25:55 - GraphTrainer - INFO -   precision@5: 0.006675
2025-11-22 21:25:55 - GraphTrainer - INFO -   recall@5: 0.031971
2025-11-22 21:25:55 - GraphTrainer - INFO -   hit_rate@5: 0.033376
2025-11-22 21:25:55 - GraphTrainer - INFO -   ndcg@5: 0.021087
2025-11-22 21:25:55 - GraphTrainer - INFO -   map@5: 0.017288
2025-11-22 21:25:55 - GraphTrainer - INFO -   mrr@5: 0.017951
2025-11-22 21:25:55 - GraphTrainer - INFO -   precision@10: 0.005122
2025-11-22 21:25:55 - GraphTrainer - INFO -   recall@10: 0.048674
2025-11-22 21:25:55 - GraphTrainer - INFO -   hit_rate@10: 0.051119
2025-11-22 21:25:55 - GraphTrainer - INFO -   ndcg@10: 0.026501
2025-11-22 21:25:55 - GraphTrainer - INFO -   map@10: 0.019460
2025-11-22 21:25:55 - GraphTrainer - INFO -   mrr@10: 0.020258
2025-11-22 21:25:55 - GraphTrainer - INFO -   precision@20: 0.004055
2025-11-22 21:25:55 - GraphTrainer - INFO -   recall@20: 0.076313
2025-11-22 21:25:55 - GraphTrainer - INFO -   hit_rate@20: 0.080432
2025-11-22 21:25:55 - GraphTrainer - INFO -   ndcg@20: 0.033598
2025-11-22 21:25:55 - GraphTrainer - INFO -   map@20: 0.021387
2025-11-22 21:25:55 - GraphTrainer - INFO -   mrr@20: 0.022291
2025-11-22 21:25:55 - GraphTrainer - INFO - 第 102 轮训练完成
2025-11-22 21:25:55 - GraphTrainer - INFO - train_loss: 0.278954
2025-11-22 21:25:55 - GraphTrainer - INFO - precision@5: 0.006675
2025-11-22 21:25:55 - GraphTrainer - INFO - recall@5: 0.031971
2025-11-22 21:25:55 - GraphTrainer - INFO - hit_rate@5: 0.033376
2025-11-22 21:25:55 - GraphTrainer - INFO - ndcg@5: 0.021087
2025-11-22 21:25:55 - GraphTrainer - INFO - map@5: 0.017288
2025-11-22 21:25:55 - GraphTrainer - INFO - mrr@5: 0.017951
2025-11-22 21:25:55 - GraphTrainer - INFO - precision@10: 0.005122
2025-11-22 21:25:55 - GraphTrainer - INFO - recall@10: 0.048674
2025-11-22 21:25:55 - GraphTrainer - INFO - hit_rate@10: 0.051119
2025-11-22 21:25:55 - GraphTrainer - INFO - ndcg@10: 0.026501
2025-11-22 21:25:55 - GraphTrainer - INFO - map@10: 0.019460
2025-11-22 21:25:55 - GraphTrainer - INFO - mrr@10: 0.020258
2025-11-22 21:25:55 - GraphTrainer - INFO - precision@20: 0.004055
2025-11-22 21:25:55 - GraphTrainer - INFO - recall@20: 0.076313
2025-11-22 21:25:55 - GraphTrainer - INFO - hit_rate@20: 0.080432
2025-11-22 21:25:55 - GraphTrainer - INFO - ndcg@20: 0.033598
2025-11-22 21:25:55 - GraphTrainer - INFO - map@20: 0.021387
2025-11-22 21:25:55 - GraphTrainer - INFO - mrr@20: 0.022291
2025-11-22 21:25:55 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:25:55 - GraphTrainer - INFO - ============================================================
2025-11-22 21:25:55 - GraphTrainer - INFO - 开始第 103/1000 轮训练
2025-11-22 21:25:55 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2912, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2847, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2856, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2577, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2693, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2758, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2826, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2597, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3062, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2538, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2574, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2696, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2719, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2729, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2823, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2754, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2914, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2785, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2877, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2786, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2576, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2701, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2734, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2745, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2735, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2650, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2828, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2842, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2880, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2693, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2883, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2884, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2934, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2785, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2539, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2762, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2679, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2918, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2843, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2944, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2532, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2970, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2872, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2731, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2773, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2885, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2939, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2881, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2706, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2974, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2943, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2979, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2838, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2746, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2700, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2905, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2930, device='cuda:0', grad_fn=<AddBackward0>)
The 102 training average loss: 0.2789543039839843
2025-11-22 21:26:06 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:26:06 - GraphTrainer - INFO -   precision@5: 0.006644
2025-11-22 21:26:06 - GraphTrainer - INFO -   recall@5: 0.031620
2025-11-22 21:26:06 - GraphTrainer - INFO -   hit_rate@5: 0.033222
2025-11-22 21:26:06 - GraphTrainer - INFO -   ndcg@5: 0.021081
2025-11-22 21:26:06 - GraphTrainer - INFO -   map@5: 0.017369
2025-11-22 21:26:06 - GraphTrainer - INFO -   mrr@5: 0.018094
2025-11-22 21:26:06 - GraphTrainer - INFO -   precision@10: 0.005220
2025-11-22 21:26:06 - GraphTrainer - INFO -   recall@10: 0.049704
2025-11-22 21:26:06 - GraphTrainer - INFO -   hit_rate@10: 0.052147
2025-11-22 21:26:06 - GraphTrainer - INFO -   ndcg@10: 0.026962
2025-11-22 21:26:06 - GraphTrainer - INFO -   map@10: 0.019762
2025-11-22 21:26:06 - GraphTrainer - INFO -   mrr@10: 0.020599
2025-11-22 21:26:06 - GraphTrainer - INFO -   precision@20: 0.004112
2025-11-22 21:26:06 - GraphTrainer - INFO -   recall@20: 0.077656
2025-11-22 21:26:06 - GraphTrainer - INFO -   hit_rate@20: 0.081666
2025-11-22 21:26:06 - GraphTrainer - INFO -   ndcg@20: 0.034080
2025-11-22 21:26:06 - GraphTrainer - INFO -   map@20: 0.021668
2025-11-22 21:26:06 - GraphTrainer - INFO -   mrr@20: 0.022604
2025-11-22 21:26:06 - GraphTrainer - INFO - 第 103 轮训练完成
2025-11-22 21:26:06 - GraphTrainer - INFO - train_loss: 0.279689
2025-11-22 21:26:06 - GraphTrainer - INFO - precision@5: 0.006644
2025-11-22 21:26:06 - GraphTrainer - INFO - recall@5: 0.031620
2025-11-22 21:26:06 - GraphTrainer - INFO - hit_rate@5: 0.033222
2025-11-22 21:26:06 - GraphTrainer - INFO - ndcg@5: 0.021081
2025-11-22 21:26:06 - GraphTrainer - INFO - map@5: 0.017369
2025-11-22 21:26:06 - GraphTrainer - INFO - mrr@5: 0.018094
2025-11-22 21:26:06 - GraphTrainer - INFO - precision@10: 0.005220
2025-11-22 21:26:06 - GraphTrainer - INFO - recall@10: 0.049704
2025-11-22 21:26:06 - GraphTrainer - INFO - hit_rate@10: 0.052147
2025-11-22 21:26:06 - GraphTrainer - INFO - ndcg@10: 0.026962
2025-11-22 21:26:06 - GraphTrainer - INFO - map@10: 0.019762
2025-11-22 21:26:06 - GraphTrainer - INFO - mrr@10: 0.020599
2025-11-22 21:26:06 - GraphTrainer - INFO - precision@20: 0.004112
2025-11-22 21:26:06 - GraphTrainer - INFO - recall@20: 0.077656
2025-11-22 21:26:06 - GraphTrainer - INFO - hit_rate@20: 0.081666
2025-11-22 21:26:06 - GraphTrainer - INFO - ndcg@20: 0.034080
2025-11-22 21:26:06 - GraphTrainer - INFO - map@20: 0.021668
2025-11-22 21:26:06 - GraphTrainer - INFO - mrr@20: 0.022604
2025-11-22 21:26:06 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:26:06 - GraphTrainer - INFO - ============================================================
2025-11-22 21:26:06 - GraphTrainer - INFO - 开始第 104/1000 轮训练
2025-11-22 21:26:06 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2648, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2813, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2831, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2695, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2922, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2998, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2987, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2728, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2591, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2906, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2767, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2759, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2728, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3246, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2821, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3005, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2888, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2818, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2781, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2579, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2622, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3050, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2721, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2933, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2652, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2552, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2597, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2619, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2767, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2649, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2788, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2606, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2687, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2821, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2996, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2942, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3018, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2719, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2710, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2619, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2650, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2721, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2723, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2834, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2989, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2719, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2888, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2999, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2851, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2823, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2972, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2857, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2930, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2888, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2839, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2824, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2542, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2593, device='cuda:0', grad_fn=<AddBackward0>)
The 103 training average loss: 0.2796893685028471
2025-11-22 21:26:17 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:26:17 - GraphTrainer - INFO -   precision@5: 0.006696
2025-11-22 21:26:17 - GraphTrainer - INFO -   recall@5: 0.032125
2025-11-22 21:26:17 - GraphTrainer - INFO -   hit_rate@5: 0.033479
2025-11-22 21:26:17 - GraphTrainer - INFO -   ndcg@5: 0.021506
2025-11-22 21:26:17 - GraphTrainer - INFO -   map@5: 0.017817
2025-11-22 21:26:17 - GraphTrainer - INFO -   mrr@5: 0.018409
2025-11-22 21:26:17 - GraphTrainer - INFO -   precision@10: 0.005246
2025-11-22 21:26:17 - GraphTrainer - INFO -   recall@10: 0.049662
2025-11-22 21:26:17 - GraphTrainer - INFO -   hit_rate@10: 0.052404
2025-11-22 21:26:17 - GraphTrainer - INFO -   ndcg@10: 0.027215
2025-11-22 21:26:17 - GraphTrainer - INFO -   map@10: 0.020108
2025-11-22 21:26:17 - GraphTrainer - INFO -   mrr@10: 0.020875
2025-11-22 21:26:17 - GraphTrainer - INFO -   precision@20: 0.004148
2025-11-22 21:26:17 - GraphTrainer - INFO -   recall@20: 0.078303
2025-11-22 21:26:17 - GraphTrainer - INFO -   hit_rate@20: 0.082386
2025-11-22 21:26:17 - GraphTrainer - INFO -   ndcg@20: 0.034504
2025-11-22 21:26:17 - GraphTrainer - INFO -   map@20: 0.022068
2025-11-22 21:26:17 - GraphTrainer - INFO -   mrr@20: 0.022918
2025-11-22 21:26:17 - GraphTrainer - INFO - 第 104 轮训练完成
2025-11-22 21:26:17 - GraphTrainer - INFO - train_loss: 0.278590
2025-11-22 21:26:17 - GraphTrainer - INFO - precision@5: 0.006696
2025-11-22 21:26:17 - GraphTrainer - INFO - recall@5: 0.032125
2025-11-22 21:26:17 - GraphTrainer - INFO - hit_rate@5: 0.033479
2025-11-22 21:26:17 - GraphTrainer - INFO - ndcg@5: 0.021506
2025-11-22 21:26:17 - GraphTrainer - INFO - map@5: 0.017817
2025-11-22 21:26:17 - GraphTrainer - INFO - mrr@5: 0.018409
2025-11-22 21:26:17 - GraphTrainer - INFO - precision@10: 0.005246
2025-11-22 21:26:17 - GraphTrainer - INFO - recall@10: 0.049662
2025-11-22 21:26:17 - GraphTrainer - INFO - hit_rate@10: 0.052404
2025-11-22 21:26:17 - GraphTrainer - INFO - ndcg@10: 0.027215
2025-11-22 21:26:17 - GraphTrainer - INFO - map@10: 0.020108
2025-11-22 21:26:17 - GraphTrainer - INFO - mrr@10: 0.020875
2025-11-22 21:26:17 - GraphTrainer - INFO - precision@20: 0.004148
2025-11-22 21:26:17 - GraphTrainer - INFO - recall@20: 0.078303
2025-11-22 21:26:17 - GraphTrainer - INFO - hit_rate@20: 0.082386
2025-11-22 21:26:17 - GraphTrainer - INFO - ndcg@20: 0.034504
2025-11-22 21:26:17 - GraphTrainer - INFO - map@20: 0.022068
2025-11-22 21:26:17 - GraphTrainer - INFO - mrr@20: 0.022918
2025-11-22 21:26:17 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:26:17 - GraphTrainer - INFO - ============================================================
2025-11-22 21:26:17 - GraphTrainer - INFO - 开始第 105/1000 轮训练
2025-11-22 21:26:17 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2778, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2744, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2685, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2638, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2901, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2880, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3017, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2793, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2638, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2775, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2903, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2810, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2935, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2873, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2653, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2729, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2700, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2988, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2764, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2818, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2887, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2720, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2764, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2740, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2797, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2831, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2876, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2633, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2674, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2752, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2712, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2787, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2867, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2518, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2437, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2832, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2916, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3088, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3163, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2560, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2509, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2714, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2768, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2542, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2777, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2878, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2783, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2674, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2787, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2830, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2924, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2838, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2919, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2542, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2859, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2804, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2933, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2924, device='cuda:0', grad_fn=<AddBackward0>)
The 104 training average loss: 0.278589500692384
2025-11-22 21:26:28 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:26:28 - GraphTrainer - INFO -   precision@5: 0.006665
2025-11-22 21:26:28 - GraphTrainer - INFO -   recall@5: 0.031897
2025-11-22 21:26:28 - GraphTrainer - INFO -   hit_rate@5: 0.033325
2025-11-22 21:26:28 - GraphTrainer - INFO -   ndcg@5: 0.021415
2025-11-22 21:26:28 - GraphTrainer - INFO -   map@5: 0.017740
2025-11-22 21:26:28 - GraphTrainer - INFO -   mrr@5: 0.018419
2025-11-22 21:26:28 - GraphTrainer - INFO -   precision@10: 0.005102
2025-11-22 21:26:28 - GraphTrainer - INFO -   recall@10: 0.048498
2025-11-22 21:26:28 - GraphTrainer - INFO -   hit_rate@10: 0.050913
2025-11-22 21:26:28 - GraphTrainer - INFO -   ndcg@10: 0.026823
2025-11-22 21:26:28 - GraphTrainer - INFO -   map@10: 0.019930
2025-11-22 21:26:28 - GraphTrainer - INFO -   mrr@10: 0.020738
2025-11-22 21:26:28 - GraphTrainer - INFO -   precision@20: 0.004137
2025-11-22 21:26:28 - GraphTrainer - INFO -   recall@20: 0.078188
2025-11-22 21:26:28 - GraphTrainer - INFO -   hit_rate@20: 0.082438
2025-11-22 21:26:28 - GraphTrainer - INFO -   ndcg@20: 0.034383
2025-11-22 21:26:28 - GraphTrainer - INFO -   map@20: 0.021952
2025-11-22 21:26:28 - GraphTrainer - INFO -   mrr@20: 0.022884
2025-11-22 21:26:28 - GraphTrainer - INFO - 第 105 轮训练完成
2025-11-22 21:26:28 - GraphTrainer - INFO - train_loss: 0.277519
2025-11-22 21:26:28 - GraphTrainer - INFO - precision@5: 0.006665
2025-11-22 21:26:28 - GraphTrainer - INFO - recall@5: 0.031897
2025-11-22 21:26:28 - GraphTrainer - INFO - hit_rate@5: 0.033325
2025-11-22 21:26:28 - GraphTrainer - INFO - ndcg@5: 0.021415
2025-11-22 21:26:28 - GraphTrainer - INFO - map@5: 0.017740
2025-11-22 21:26:28 - GraphTrainer - INFO - mrr@5: 0.018419
2025-11-22 21:26:28 - GraphTrainer - INFO - precision@10: 0.005102
2025-11-22 21:26:28 - GraphTrainer - INFO - recall@10: 0.048498
2025-11-22 21:26:28 - GraphTrainer - INFO - hit_rate@10: 0.050913
2025-11-22 21:26:28 - GraphTrainer - INFO - ndcg@10: 0.026823
2025-11-22 21:26:28 - GraphTrainer - INFO - map@10: 0.019930
2025-11-22 21:26:28 - GraphTrainer - INFO - mrr@10: 0.020738
2025-11-22 21:26:28 - GraphTrainer - INFO - precision@20: 0.004137
2025-11-22 21:26:28 - GraphTrainer - INFO - recall@20: 0.078188
2025-11-22 21:26:28 - GraphTrainer - INFO - hit_rate@20: 0.082438
2025-11-22 21:26:28 - GraphTrainer - INFO - ndcg@20: 0.034383
2025-11-22 21:26:28 - GraphTrainer - INFO - map@20: 0.021952
2025-11-22 21:26:28 - GraphTrainer - INFO - mrr@20: 0.022884
2025-11-22 21:26:28 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:26:28 - GraphTrainer - INFO - ============================================================
2025-11-22 21:26:28 - GraphTrainer - INFO - 开始第 106/1000 轮训练
2025-11-22 21:26:28 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2826, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2759, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2678, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2788, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2583, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2776, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2726, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2916, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2685, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3028, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2853, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3095, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2667, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2673, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2549, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2772, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2858, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2778, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2890, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2737, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2647, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2832, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2554, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3037, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2721, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2803, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2741, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2597, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2854, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2765, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2819, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2791, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2675, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2671, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2989, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2806, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2809, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2719, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2740, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2758, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2719, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2854, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2586, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2953, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2800, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2847, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2629, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2929, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2891, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2897, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2647, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2725, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2626, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2850, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2868, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2895, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2444, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2838, device='cuda:0', grad_fn=<AddBackward0>)
The 105 training average loss: 0.2775190400666204
2025-11-22 21:26:39 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:26:39 - GraphTrainer - INFO -   precision@5: 0.006624
2025-11-22 21:26:39 - GraphTrainer - INFO -   recall@5: 0.031677
2025-11-22 21:26:39 - GraphTrainer - INFO -   hit_rate@5: 0.033119
2025-11-22 21:26:39 - GraphTrainer - INFO -   ndcg@5: 0.021125
2025-11-22 21:26:39 - GraphTrainer - INFO -   map@5: 0.017427
2025-11-22 21:26:39 - GraphTrainer - INFO -   mrr@5: 0.018085
2025-11-22 21:26:39 - GraphTrainer - INFO -   precision@10: 0.005364
2025-11-22 21:26:39 - GraphTrainer - INFO -   recall@10: 0.050939
2025-11-22 21:26:39 - GraphTrainer - INFO -   hit_rate@10: 0.053536
2025-11-22 21:26:39 - GraphTrainer - INFO -   ndcg@10: 0.027383
2025-11-22 21:26:39 - GraphTrainer - INFO -   map@10: 0.019955
2025-11-22 21:26:39 - GraphTrainer - INFO -   mrr@10: 0.020762
2025-11-22 21:26:39 - GraphTrainer - INFO -   precision@20: 0.004207
2025-11-22 21:26:39 - GraphTrainer - INFO -   recall@20: 0.079367
2025-11-22 21:26:39 - GraphTrainer - INFO -   hit_rate@20: 0.083569
2025-11-22 21:26:39 - GraphTrainer - INFO -   ndcg@20: 0.034604
2025-11-22 21:26:39 - GraphTrainer - INFO -   map@20: 0.021876
2025-11-22 21:26:39 - GraphTrainer - INFO -   mrr@20: 0.022786
2025-11-22 21:26:39 - GraphTrainer - INFO - 第 106 轮训练完成
2025-11-22 21:26:39 - GraphTrainer - INFO - train_loss: 0.275700
2025-11-22 21:26:39 - GraphTrainer - INFO - precision@5: 0.006624
2025-11-22 21:26:39 - GraphTrainer - INFO - recall@5: 0.031677
2025-11-22 21:26:39 - GraphTrainer - INFO - hit_rate@5: 0.033119
2025-11-22 21:26:39 - GraphTrainer - INFO - ndcg@5: 0.021125
2025-11-22 21:26:39 - GraphTrainer - INFO - map@5: 0.017427
2025-11-22 21:26:39 - GraphTrainer - INFO - mrr@5: 0.018085
2025-11-22 21:26:39 - GraphTrainer - INFO - precision@10: 0.005364
2025-11-22 21:26:39 - GraphTrainer - INFO - recall@10: 0.050939
2025-11-22 21:26:39 - GraphTrainer - INFO - hit_rate@10: 0.053536
2025-11-22 21:26:39 - GraphTrainer - INFO - ndcg@10: 0.027383
2025-11-22 21:26:39 - GraphTrainer - INFO - map@10: 0.019955
2025-11-22 21:26:39 - GraphTrainer - INFO - mrr@10: 0.020762
2025-11-22 21:26:39 - GraphTrainer - INFO - precision@20: 0.004207
2025-11-22 21:26:39 - GraphTrainer - INFO - recall@20: 0.079367
2025-11-22 21:26:39 - GraphTrainer - INFO - hit_rate@20: 0.083569
2025-11-22 21:26:39 - GraphTrainer - INFO - ndcg@20: 0.034604
2025-11-22 21:26:39 - GraphTrainer - INFO - map@20: 0.021876
2025-11-22 21:26:39 - GraphTrainer - INFO - mrr@20: 0.022786
2025-11-22 21:26:39 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:26:39 - GraphTrainer - INFO - ============================================================
2025-11-22 21:26:39 - GraphTrainer - INFO - 开始第 107/1000 轮训练
2025-11-22 21:26:39 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2522, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2629, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2610, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2868, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2744, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2769, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2639, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2789, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2784, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2938, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2869, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2720, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2772, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2918, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2784, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2723, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2635, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2775, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2799, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2641, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2978, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2669, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2678, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2722, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2947, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2546, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2778, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2977, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2865, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2877, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2591, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2816, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2779, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2772, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2545, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2532, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2864, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2475, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2893, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2875, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2832, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2546, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2808, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2661, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2735, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2894, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2724, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2778, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2763, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2856, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2826, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2801, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2726, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2912, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2616, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2793, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2798, device='cuda:0', grad_fn=<AddBackward0>)
The 106 training average loss: 0.2757003363864175
2025-11-22 21:26:51 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:26:51 - GraphTrainer - INFO -   precision@5: 0.006634
2025-11-22 21:26:51 - GraphTrainer - INFO -   recall@5: 0.031718
2025-11-22 21:26:51 - GraphTrainer - INFO -   hit_rate@5: 0.033170
2025-11-22 21:26:51 - GraphTrainer - INFO -   ndcg@5: 0.021100
2025-11-22 21:26:51 - GraphTrainer - INFO -   map@5: 0.017367
2025-11-22 21:26:51 - GraphTrainer - INFO -   mrr@5: 0.018100
2025-11-22 21:26:51 - GraphTrainer - INFO -   precision@10: 0.005189
2025-11-22 21:26:51 - GraphTrainer - INFO -   recall@10: 0.049320
2025-11-22 21:26:51 - GraphTrainer - INFO -   hit_rate@10: 0.051787
2025-11-22 21:26:51 - GraphTrainer - INFO -   ndcg@10: 0.026811
2025-11-22 21:26:51 - GraphTrainer - INFO -   map@10: 0.019669
2025-11-22 21:26:51 - GraphTrainer - INFO -   mrr@10: 0.020534
2025-11-22 21:26:51 - GraphTrainer - INFO -   precision@20: 0.004148
2025-11-22 21:26:51 - GraphTrainer - INFO -   recall@20: 0.078371
2025-11-22 21:26:51 - GraphTrainer - INFO -   hit_rate@20: 0.082386
2025-11-22 21:26:51 - GraphTrainer - INFO -   ndcg@20: 0.034205
2025-11-22 21:26:51 - GraphTrainer - INFO -   map@20: 0.021652
2025-11-22 21:26:51 - GraphTrainer - INFO -   mrr@20: 0.022615
2025-11-22 21:26:51 - GraphTrainer - INFO - 第 107 轮训练完成
2025-11-22 21:26:51 - GraphTrainer - INFO - train_loss: 0.275909
2025-11-22 21:26:51 - GraphTrainer - INFO - precision@5: 0.006634
2025-11-22 21:26:51 - GraphTrainer - INFO - recall@5: 0.031718
2025-11-22 21:26:51 - GraphTrainer - INFO - hit_rate@5: 0.033170
2025-11-22 21:26:51 - GraphTrainer - INFO - ndcg@5: 0.021100
2025-11-22 21:26:51 - GraphTrainer - INFO - map@5: 0.017367
2025-11-22 21:26:51 - GraphTrainer - INFO - mrr@5: 0.018100
2025-11-22 21:26:51 - GraphTrainer - INFO - precision@10: 0.005189
2025-11-22 21:26:51 - GraphTrainer - INFO - recall@10: 0.049320
2025-11-22 21:26:51 - GraphTrainer - INFO - hit_rate@10: 0.051787
2025-11-22 21:26:51 - GraphTrainer - INFO - ndcg@10: 0.026811
2025-11-22 21:26:51 - GraphTrainer - INFO - map@10: 0.019669
2025-11-22 21:26:51 - GraphTrainer - INFO - mrr@10: 0.020534
2025-11-22 21:26:51 - GraphTrainer - INFO - precision@20: 0.004148
2025-11-22 21:26:51 - GraphTrainer - INFO - recall@20: 0.078371
2025-11-22 21:26:51 - GraphTrainer - INFO - hit_rate@20: 0.082386
2025-11-22 21:26:51 - GraphTrainer - INFO - ndcg@20: 0.034205
2025-11-22 21:26:51 - GraphTrainer - INFO - map@20: 0.021652
2025-11-22 21:26:51 - GraphTrainer - INFO - mrr@20: 0.022615
2025-11-22 21:26:51 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:26:51 - GraphTrainer - INFO - ============================================================
2025-11-22 21:26:51 - GraphTrainer - INFO - 开始第 108/1000 轮训练
2025-11-22 21:26:51 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2823, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2881, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2648, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2768, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2759, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2809, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2514, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2894, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2740, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2893, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2903, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2631, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2691, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2906, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2890, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2847, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2871, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2592, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2694, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2541, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2734, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2601, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2453, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2595, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2905, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3001, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2760, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2759, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2392, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2827, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2683, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2702, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2604, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2847, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2890, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2864, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2703, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2842, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2664, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3026, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2745, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2637, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2764, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2679, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2837, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2611, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2848, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2866, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2764, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2846, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2935, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2957, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2785, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2601, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2890, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2466, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2870, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2779, device='cuda:0', grad_fn=<AddBackward0>)
The 107 training average loss: 0.2759088606669985
2025-11-22 21:27:02 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:27:02 - GraphTrainer - INFO -   precision@5: 0.006583
2025-11-22 21:27:02 - GraphTrainer - INFO -   recall@5: 0.031288
2025-11-22 21:27:02 - GraphTrainer - INFO -   hit_rate@5: 0.032913
2025-11-22 21:27:02 - GraphTrainer - INFO -   ndcg@5: 0.020842
2025-11-22 21:27:02 - GraphTrainer - INFO -   map@5: 0.017147
2025-11-22 21:27:02 - GraphTrainer - INFO -   mrr@5: 0.017920
2025-11-22 21:27:02 - GraphTrainer - INFO -   precision@10: 0.005400
2025-11-22 21:27:02 - GraphTrainer - INFO -   recall@10: 0.051035
2025-11-22 21:27:02 - GraphTrainer - INFO -   hit_rate@10: 0.053793
2025-11-22 21:27:02 - GraphTrainer - INFO -   ndcg@10: 0.027255
2025-11-22 21:27:02 - GraphTrainer - INFO -   map@10: 0.019738
2025-11-22 21:27:02 - GraphTrainer - INFO -   mrr@10: 0.020648
2025-11-22 21:27:02 - GraphTrainer - INFO -   precision@20: 0.004248
2025-11-22 21:27:02 - GraphTrainer - INFO -   recall@20: 0.080377
2025-11-22 21:27:02 - GraphTrainer - INFO -   hit_rate@20: 0.084495
2025-11-22 21:27:02 - GraphTrainer - INFO -   ndcg@20: 0.034711
2025-11-22 21:27:02 - GraphTrainer - INFO -   map@20: 0.021741
2025-11-22 21:27:02 - GraphTrainer - INFO -   mrr@20: 0.022741
2025-11-22 21:27:02 - GraphTrainer - INFO - 第 108 轮训练完成
2025-11-22 21:27:02 - GraphTrainer - INFO - train_loss: 0.278294
2025-11-22 21:27:02 - GraphTrainer - INFO - precision@5: 0.006583
2025-11-22 21:27:02 - GraphTrainer - INFO - recall@5: 0.031288
2025-11-22 21:27:02 - GraphTrainer - INFO - hit_rate@5: 0.032913
2025-11-22 21:27:02 - GraphTrainer - INFO - ndcg@5: 0.020842
2025-11-22 21:27:02 - GraphTrainer - INFO - map@5: 0.017147
2025-11-22 21:27:02 - GraphTrainer - INFO - mrr@5: 0.017920
2025-11-22 21:27:02 - GraphTrainer - INFO - precision@10: 0.005400
2025-11-22 21:27:02 - GraphTrainer - INFO - recall@10: 0.051035
2025-11-22 21:27:02 - GraphTrainer - INFO - hit_rate@10: 0.053793
2025-11-22 21:27:02 - GraphTrainer - INFO - ndcg@10: 0.027255
2025-11-22 21:27:02 - GraphTrainer - INFO - map@10: 0.019738
2025-11-22 21:27:02 - GraphTrainer - INFO - mrr@10: 0.020648
2025-11-22 21:27:02 - GraphTrainer - INFO - precision@20: 0.004248
2025-11-22 21:27:02 - GraphTrainer - INFO - recall@20: 0.080377
2025-11-22 21:27:02 - GraphTrainer - INFO - hit_rate@20: 0.084495
2025-11-22 21:27:02 - GraphTrainer - INFO - ndcg@20: 0.034711
2025-11-22 21:27:02 - GraphTrainer - INFO - map@20: 0.021741
2025-11-22 21:27:02 - GraphTrainer - INFO - mrr@20: 0.022741
2025-11-22 21:27:02 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:27:02 - GraphTrainer - INFO - ============================================================
2025-11-22 21:27:02 - GraphTrainer - INFO - 开始第 109/1000 轮训练
2025-11-22 21:27:02 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2540, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2690, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2771, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2756, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2866, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2787, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2890, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2871, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2935, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2655, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2759, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2960, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2911, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2782, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2638, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2687, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2917, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2705, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2632, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2694, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2791, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2611, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2604, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2841, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2702, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2847, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2776, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2854, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2915, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2960, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2959, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2853, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2777, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2690, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2756, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3044, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2698, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2740, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2854, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2846, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2841, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2775, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2771, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3043, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2644, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2593, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2874, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2763, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2790, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2710, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2972, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2868, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2785, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2709, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2622, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2587, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2887, device='cuda:0', grad_fn=<AddBackward0>)
The 108 training average loss: 0.2782941948750923
2025-11-22 21:27:13 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:27:13 - GraphTrainer - INFO -   precision@5: 0.006768
2025-11-22 21:27:13 - GraphTrainer - INFO -   recall@5: 0.032178
2025-11-22 21:27:13 - GraphTrainer - INFO -   hit_rate@5: 0.033839
2025-11-22 21:27:13 - GraphTrainer - INFO -   ndcg@5: 0.021709
2025-11-22 21:27:13 - GraphTrainer - INFO -   map@5: 0.017993
2025-11-22 21:27:13 - GraphTrainer - INFO -   mrr@5: 0.018817
2025-11-22 21:27:13 - GraphTrainer - INFO -   precision@10: 0.005328
2025-11-22 21:27:13 - GraphTrainer - INFO -   recall@10: 0.050368
2025-11-22 21:27:13 - GraphTrainer - INFO -   hit_rate@10: 0.053176
2025-11-22 21:27:13 - GraphTrainer - INFO -   ndcg@10: 0.027599
2025-11-22 21:27:13 - GraphTrainer - INFO -   map@10: 0.020353
2025-11-22 21:27:13 - GraphTrainer - INFO -   mrr@10: 0.021328
2025-11-22 21:27:13 - GraphTrainer - INFO -   precision@20: 0.004243
2025-11-22 21:27:13 - GraphTrainer - INFO -   recall@20: 0.080084
2025-11-22 21:27:13 - GraphTrainer - INFO -   hit_rate@20: 0.084340
2025-11-22 21:27:13 - GraphTrainer - INFO -   ndcg@20: 0.035134
2025-11-22 21:27:13 - GraphTrainer - INFO -   map@20: 0.022366
2025-11-22 21:27:13 - GraphTrainer - INFO -   mrr@20: 0.023431
2025-11-22 21:27:13 - GraphTrainer - INFO - 第 109 轮训练完成
2025-11-22 21:27:13 - GraphTrainer - INFO - train_loss: 0.274027
2025-11-22 21:27:13 - GraphTrainer - INFO - precision@5: 0.006768
2025-11-22 21:27:13 - GraphTrainer - INFO - recall@5: 0.032178
2025-11-22 21:27:13 - GraphTrainer - INFO - hit_rate@5: 0.033839
2025-11-22 21:27:13 - GraphTrainer - INFO - ndcg@5: 0.021709
2025-11-22 21:27:13 - GraphTrainer - INFO - map@5: 0.017993
2025-11-22 21:27:13 - GraphTrainer - INFO - mrr@5: 0.018817
2025-11-22 21:27:13 - GraphTrainer - INFO - precision@10: 0.005328
2025-11-22 21:27:13 - GraphTrainer - INFO - recall@10: 0.050368
2025-11-22 21:27:13 - GraphTrainer - INFO - hit_rate@10: 0.053176
2025-11-22 21:27:13 - GraphTrainer - INFO - ndcg@10: 0.027599
2025-11-22 21:27:13 - GraphTrainer - INFO - map@10: 0.020353
2025-11-22 21:27:13 - GraphTrainer - INFO - mrr@10: 0.021328
2025-11-22 21:27:13 - GraphTrainer - INFO - precision@20: 0.004243
2025-11-22 21:27:13 - GraphTrainer - INFO - recall@20: 0.080084
2025-11-22 21:27:13 - GraphTrainer - INFO - hit_rate@20: 0.084340
2025-11-22 21:27:13 - GraphTrainer - INFO - ndcg@20: 0.035134
2025-11-22 21:27:13 - GraphTrainer - INFO - map@20: 0.022366
2025-11-22 21:27:13 - GraphTrainer - INFO - mrr@20: 0.023431
2025-11-22 21:27:13 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:27:13 - GraphTrainer - INFO - ============================================================
2025-11-22 21:27:13 - GraphTrainer - INFO - 开始第 110/1000 轮训练
2025-11-22 21:27:13 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2544, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2541, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2759, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2687, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2730, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2541, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2664, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2933, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2580, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2764, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2662, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2780, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2707, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2759, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2809, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2948, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2933, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2492, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2800, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2846, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2750, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2601, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2754, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2508, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2660, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2888, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2912, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2778, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2940, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2707, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2691, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2845, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2826, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2696, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2709, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2968, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2695, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2803, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2755, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2977, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2839, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2437, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2640, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2822, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2583, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2620, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2748, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2889, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2824, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2689, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2915, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2799, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2690, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2728, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2691, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2602, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2747, device='cuda:0', grad_fn=<AddBackward0>)
The 109 training average loss: 0.2740273930389306
2025-11-22 21:27:24 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:27:24 - GraphTrainer - INFO -   precision@5: 0.006542
2025-11-22 21:27:24 - GraphTrainer - INFO -   recall@5: 0.031330
2025-11-22 21:27:24 - GraphTrainer - INFO -   hit_rate@5: 0.032708
2025-11-22 21:27:24 - GraphTrainer - INFO -   ndcg@5: 0.021413
2025-11-22 21:27:24 - GraphTrainer - INFO -   map@5: 0.017923
2025-11-22 21:27:24 - GraphTrainer - INFO -   mrr@5: 0.018573
2025-11-22 21:27:24 - GraphTrainer - INFO -   precision@10: 0.005354
2025-11-22 21:27:24 - GraphTrainer - INFO -   recall@10: 0.050795
2025-11-22 21:27:24 - GraphTrainer - INFO -   hit_rate@10: 0.053381
2025-11-22 21:27:24 - GraphTrainer - INFO -   ndcg@10: 0.027714
2025-11-22 21:27:24 - GraphTrainer - INFO -   map@10: 0.020446
2025-11-22 21:27:24 - GraphTrainer - INFO -   mrr@10: 0.021253
2025-11-22 21:27:24 - GraphTrainer - INFO -   precision@20: 0.004119
2025-11-22 21:27:24 - GraphTrainer - INFO -   recall@20: 0.077907
2025-11-22 21:27:24 - GraphTrainer - INFO -   hit_rate@20: 0.081923
2025-11-22 21:27:24 - GraphTrainer - INFO -   ndcg@20: 0.034607
2025-11-22 21:27:24 - GraphTrainer - INFO -   map@20: 0.022293
2025-11-22 21:27:24 - GraphTrainer - INFO -   mrr@20: 0.023190
2025-11-22 21:27:24 - GraphTrainer - INFO - 第 110 轮训练完成
2025-11-22 21:27:24 - GraphTrainer - INFO - train_loss: 0.276047
2025-11-22 21:27:24 - GraphTrainer - INFO - precision@5: 0.006542
2025-11-22 21:27:24 - GraphTrainer - INFO - recall@5: 0.031330
2025-11-22 21:27:24 - GraphTrainer - INFO - hit_rate@5: 0.032708
2025-11-22 21:27:24 - GraphTrainer - INFO - ndcg@5: 0.021413
2025-11-22 21:27:24 - GraphTrainer - INFO - map@5: 0.017923
2025-11-22 21:27:24 - GraphTrainer - INFO - mrr@5: 0.018573
2025-11-22 21:27:24 - GraphTrainer - INFO - precision@10: 0.005354
2025-11-22 21:27:24 - GraphTrainer - INFO - recall@10: 0.050795
2025-11-22 21:27:24 - GraphTrainer - INFO - hit_rate@10: 0.053381
2025-11-22 21:27:24 - GraphTrainer - INFO - ndcg@10: 0.027714
2025-11-22 21:27:24 - GraphTrainer - INFO - map@10: 0.020446
2025-11-22 21:27:24 - GraphTrainer - INFO - mrr@10: 0.021253
2025-11-22 21:27:24 - GraphTrainer - INFO - precision@20: 0.004119
2025-11-22 21:27:24 - GraphTrainer - INFO - recall@20: 0.077907
2025-11-22 21:27:24 - GraphTrainer - INFO - hit_rate@20: 0.081923
2025-11-22 21:27:24 - GraphTrainer - INFO - ndcg@20: 0.034607
2025-11-22 21:27:24 - GraphTrainer - INFO - map@20: 0.022293
2025-11-22 21:27:24 - GraphTrainer - INFO - mrr@20: 0.023190
2025-11-22 21:27:24 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:27:24 - GraphTrainer - INFO - 检查点已保存: Epoch 110 -> ./checkpoints/checkpoint_epoch_110.pth
2025-11-22 21:27:24 - GraphTrainer - INFO - ============================================================
2025-11-22 21:27:24 - GraphTrainer - INFO - 开始第 111/1000 轮训练
2025-11-22 21:27:24 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2922, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2667, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2688, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2880, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2520, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2672, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2657, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2694, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2849, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2617, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2781, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2837, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2593, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2623, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2667, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2935, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2721, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2778, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2879, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2524, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2833, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2926, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2677, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2887, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2760, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3103, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2831, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2961, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2582, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2939, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2791, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2659, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2649, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2876, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2900, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2664, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2766, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2811, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2690, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2669, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2688, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2511, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2797, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2763, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2606, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2732, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2877, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2697, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2863, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2660, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2609, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2878, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2727, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2890, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2739, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2836, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2868, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2889, device='cuda:0', grad_fn=<AddBackward0>)
The 110 training average loss: 0.27604730273115224
2025-11-22 21:27:36 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:27:36 - GraphTrainer - INFO -   precision@5: 0.006737
2025-11-22 21:27:36 - GraphTrainer - INFO -   recall@5: 0.032244
2025-11-22 21:27:36 - GraphTrainer - INFO -   hit_rate@5: 0.033685
2025-11-22 21:27:36 - GraphTrainer - INFO -   ndcg@5: 0.021706
2025-11-22 21:27:36 - GraphTrainer - INFO -   map@5: 0.018024
2025-11-22 21:27:36 - GraphTrainer - INFO -   mrr@5: 0.018671
2025-11-22 21:27:36 - GraphTrainer - INFO -   precision@10: 0.005225
2025-11-22 21:27:36 - GraphTrainer - INFO -   recall@10: 0.049659
2025-11-22 21:27:36 - GraphTrainer - INFO -   hit_rate@10: 0.052044
2025-11-22 21:27:36 - GraphTrainer - INFO -   ndcg@10: 0.027324
2025-11-22 21:27:36 - GraphTrainer - INFO -   map@10: 0.020271
2025-11-22 21:27:36 - GraphTrainer - INFO -   mrr@10: 0.021036
2025-11-22 21:27:36 - GraphTrainer - INFO -   precision@20: 0.004184
2025-11-22 21:27:36 - GraphTrainer - INFO -   recall@20: 0.079119
2025-11-22 21:27:36 - GraphTrainer - INFO -   hit_rate@20: 0.083209
2025-11-22 21:27:36 - GraphTrainer - INFO -   ndcg@20: 0.034861
2025-11-22 21:27:36 - GraphTrainer - INFO -   map@20: 0.022310
2025-11-22 21:27:36 - GraphTrainer - INFO -   mrr@20: 0.023186
2025-11-22 21:27:36 - GraphTrainer - INFO - 第 111 轮训练完成
2025-11-22 21:27:36 - GraphTrainer - INFO - train_loss: 0.276115
2025-11-22 21:27:36 - GraphTrainer - INFO - precision@5: 0.006737
2025-11-22 21:27:36 - GraphTrainer - INFO - recall@5: 0.032244
2025-11-22 21:27:36 - GraphTrainer - INFO - hit_rate@5: 0.033685
2025-11-22 21:27:36 - GraphTrainer - INFO - ndcg@5: 0.021706
2025-11-22 21:27:36 - GraphTrainer - INFO - map@5: 0.018024
2025-11-22 21:27:36 - GraphTrainer - INFO - mrr@5: 0.018671
2025-11-22 21:27:36 - GraphTrainer - INFO - precision@10: 0.005225
2025-11-22 21:27:36 - GraphTrainer - INFO - recall@10: 0.049659
2025-11-22 21:27:36 - GraphTrainer - INFO - hit_rate@10: 0.052044
2025-11-22 21:27:36 - GraphTrainer - INFO - ndcg@10: 0.027324
2025-11-22 21:27:36 - GraphTrainer - INFO - map@10: 0.020271
2025-11-22 21:27:36 - GraphTrainer - INFO - mrr@10: 0.021036
2025-11-22 21:27:36 - GraphTrainer - INFO - precision@20: 0.004184
2025-11-22 21:27:36 - GraphTrainer - INFO - recall@20: 0.079119
2025-11-22 21:27:36 - GraphTrainer - INFO - hit_rate@20: 0.083209
2025-11-22 21:27:36 - GraphTrainer - INFO - ndcg@20: 0.034861
2025-11-22 21:27:36 - GraphTrainer - INFO - map@20: 0.022310
2025-11-22 21:27:36 - GraphTrainer - INFO - mrr@20: 0.023186
2025-11-22 21:27:36 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:27:36 - GraphTrainer - INFO - ============================================================
2025-11-22 21:27:36 - GraphTrainer - INFO - 开始第 112/1000 轮训练
2025-11-22 21:27:36 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2594, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2833, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2623, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2874, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2690, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2805, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2974, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2538, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2749, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3074, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2819, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2802, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2689, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2907, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2701, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2788, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2969, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2601, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2662, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2723, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2689, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2789, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2873, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2698, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2639, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2835, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2860, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2687, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2748, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2695, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2760, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2830, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2879, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2762, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2703, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2782, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2853, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2680, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2900, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2651, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2809, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2786, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2554, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2868, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2908, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2519, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2742, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2855, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2457, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2747, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2832, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2848, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2778, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2746, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2661, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2717, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2908, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2684, device='cuda:0', grad_fn=<AddBackward0>)
The 111 training average loss: 0.27611546218395233
2025-11-22 21:27:47 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:27:47 - GraphTrainer - INFO -   precision@5: 0.006542
2025-11-22 21:27:47 - GraphTrainer - INFO -   recall@5: 0.031222
2025-11-22 21:27:47 - GraphTrainer - INFO -   hit_rate@5: 0.032708
2025-11-22 21:27:47 - GraphTrainer - INFO -   ndcg@5: 0.021327
2025-11-22 21:27:47 - GraphTrainer - INFO -   map@5: 0.017854
2025-11-22 21:27:47 - GraphTrainer - INFO -   mrr@5: 0.018430
2025-11-22 21:27:47 - GraphTrainer - INFO -   precision@10: 0.005256
2025-11-22 21:27:47 - GraphTrainer - INFO -   recall@10: 0.049977
2025-11-22 21:27:47 - GraphTrainer - INFO -   hit_rate@10: 0.052507
2025-11-22 21:27:47 - GraphTrainer - INFO -   ndcg@10: 0.027424
2025-11-22 21:27:47 - GraphTrainer - INFO -   map@10: 0.020322
2025-11-22 21:27:47 - GraphTrainer - INFO -   mrr@10: 0.021032
2025-11-22 21:27:47 - GraphTrainer - INFO -   precision@20: 0.004176
2025-11-22 21:27:47 - GraphTrainer - INFO -   recall@20: 0.079261
2025-11-22 21:27:47 - GraphTrainer - INFO -   hit_rate@20: 0.083055
2025-11-22 21:27:47 - GraphTrainer - INFO -   ndcg@20: 0.034854
2025-11-22 21:27:47 - GraphTrainer - INFO -   map@20: 0.022314
2025-11-22 21:27:47 - GraphTrainer - INFO -   mrr@20: 0.023104
2025-11-22 21:27:47 - GraphTrainer - INFO - 第 112 轮训练完成
2025-11-22 21:27:47 - GraphTrainer - INFO - train_loss: 0.272732
2025-11-22 21:27:47 - GraphTrainer - INFO - precision@5: 0.006542
2025-11-22 21:27:47 - GraphTrainer - INFO - recall@5: 0.031222
2025-11-22 21:27:47 - GraphTrainer - INFO - hit_rate@5: 0.032708
2025-11-22 21:27:47 - GraphTrainer - INFO - ndcg@5: 0.021327
2025-11-22 21:27:47 - GraphTrainer - INFO - map@5: 0.017854
2025-11-22 21:27:47 - GraphTrainer - INFO - mrr@5: 0.018430
2025-11-22 21:27:47 - GraphTrainer - INFO - precision@10: 0.005256
2025-11-22 21:27:47 - GraphTrainer - INFO - recall@10: 0.049977
2025-11-22 21:27:47 - GraphTrainer - INFO - hit_rate@10: 0.052507
2025-11-22 21:27:47 - GraphTrainer - INFO - ndcg@10: 0.027424
2025-11-22 21:27:47 - GraphTrainer - INFO - map@10: 0.020322
2025-11-22 21:27:47 - GraphTrainer - INFO - mrr@10: 0.021032
2025-11-22 21:27:47 - GraphTrainer - INFO - precision@20: 0.004176
2025-11-22 21:27:47 - GraphTrainer - INFO - recall@20: 0.079261
2025-11-22 21:27:47 - GraphTrainer - INFO - hit_rate@20: 0.083055
2025-11-22 21:27:47 - GraphTrainer - INFO - ndcg@20: 0.034854
2025-11-22 21:27:47 - GraphTrainer - INFO - map@20: 0.022314
2025-11-22 21:27:47 - GraphTrainer - INFO - mrr@20: 0.023104
2025-11-22 21:27:47 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:27:47 - GraphTrainer - INFO - ============================================================
2025-11-22 21:27:47 - GraphTrainer - INFO - 开始第 113/1000 轮训练
2025-11-22 21:27:47 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2702, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2864, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2753, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2608, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2764, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2555, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2545, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2650, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2827, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2577, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2834, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2847, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2571, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2741, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2527, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2617, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2619, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2833, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2662, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2545, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2756, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2829, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2635, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2742, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2521, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2599, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2785, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2951, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2621, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2961, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2838, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2868, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2706, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3044, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2880, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2637, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2436, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2743, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2818, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2688, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2728, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2912, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2631, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3013, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2978, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2696, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2792, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2696, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2717, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2973, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2738, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2598, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2822, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2620, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2716, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2560, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2684, device='cuda:0', grad_fn=<AddBackward0>)
The 112 training average loss: 0.272732426380289
2025-11-22 21:27:58 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:27:58 - GraphTrainer - INFO -   precision@5: 0.006428
2025-11-22 21:27:58 - GraphTrainer - INFO -   recall@5: 0.030761
2025-11-22 21:27:58 - GraphTrainer - INFO -   hit_rate@5: 0.032142
2025-11-22 21:27:58 - GraphTrainer - INFO -   ndcg@5: 0.020908
2025-11-22 21:27:58 - GraphTrainer - INFO -   map@5: 0.017434
2025-11-22 21:27:58 - GraphTrainer - INFO -   mrr@5: 0.018117
2025-11-22 21:27:58 - GraphTrainer - INFO -   precision@10: 0.005210
2025-11-22 21:27:58 - GraphTrainer - INFO -   recall@10: 0.049343
2025-11-22 21:27:58 - GraphTrainer - INFO -   hit_rate@10: 0.051993
2025-11-22 21:27:58 - GraphTrainer - INFO -   ndcg@10: 0.026960
2025-11-22 21:27:58 - GraphTrainer - INFO -   map@10: 0.019876
2025-11-22 21:27:58 - GraphTrainer - INFO -   mrr@10: 0.020723
2025-11-22 21:27:58 - GraphTrainer - INFO -   precision@20: 0.004222
2025-11-22 21:27:58 - GraphTrainer - INFO -   recall@20: 0.079951
2025-11-22 21:27:58 - GraphTrainer - INFO -   hit_rate@20: 0.083878
2025-11-22 21:27:58 - GraphTrainer - INFO -   ndcg@20: 0.034751
2025-11-22 21:27:58 - GraphTrainer - INFO -   map@20: 0.021980
2025-11-22 21:27:58 - GraphTrainer - INFO -   mrr@20: 0.022909
2025-11-22 21:27:58 - GraphTrainer - INFO - 第 113 轮训练完成
2025-11-22 21:27:58 - GraphTrainer - INFO - train_loss: 0.274149
2025-11-22 21:27:58 - GraphTrainer - INFO - precision@5: 0.006428
2025-11-22 21:27:58 - GraphTrainer - INFO - recall@5: 0.030761
2025-11-22 21:27:58 - GraphTrainer - INFO - hit_rate@5: 0.032142
2025-11-22 21:27:58 - GraphTrainer - INFO - ndcg@5: 0.020908
2025-11-22 21:27:58 - GraphTrainer - INFO - map@5: 0.017434
2025-11-22 21:27:58 - GraphTrainer - INFO - mrr@5: 0.018117
2025-11-22 21:27:58 - GraphTrainer - INFO - precision@10: 0.005210
2025-11-22 21:27:58 - GraphTrainer - INFO - recall@10: 0.049343
2025-11-22 21:27:58 - GraphTrainer - INFO - hit_rate@10: 0.051993
2025-11-22 21:27:58 - GraphTrainer - INFO - ndcg@10: 0.026960
2025-11-22 21:27:58 - GraphTrainer - INFO - map@10: 0.019876
2025-11-22 21:27:58 - GraphTrainer - INFO - mrr@10: 0.020723
2025-11-22 21:27:58 - GraphTrainer - INFO - precision@20: 0.004222
2025-11-22 21:27:58 - GraphTrainer - INFO - recall@20: 0.079951
2025-11-22 21:27:58 - GraphTrainer - INFO - hit_rate@20: 0.083878
2025-11-22 21:27:58 - GraphTrainer - INFO - ndcg@20: 0.034751
2025-11-22 21:27:58 - GraphTrainer - INFO - map@20: 0.021980
2025-11-22 21:27:58 - GraphTrainer - INFO - mrr@20: 0.022909
2025-11-22 21:27:58 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:27:58 - GraphTrainer - INFO - ============================================================
2025-11-22 21:27:58 - GraphTrainer - INFO - 开始第 114/1000 轮训练
2025-11-22 21:27:58 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2740, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2730, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2840, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2607, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2726, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2684, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2723, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2716, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2586, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3154, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2660, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2727, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2755, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2922, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2652, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2778, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2942, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2546, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2696, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2718, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2772, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2936, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2749, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2758, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2623, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2735, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2496, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2957, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2915, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2771, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2798, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2807, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2620, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2911, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2884, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2544, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2751, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2627, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2714, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2743, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2683, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2919, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2614, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2588, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2559, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2569, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2795, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2825, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2680, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2884, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2542, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2797, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2804, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2507, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2723, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3041, device='cuda:0', grad_fn=<AddBackward0>)
The 113 training average loss: 0.2741486044793293
2025-11-22 21:28:09 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:28:09 - GraphTrainer - INFO -   precision@5: 0.006706
2025-11-22 21:28:09 - GraphTrainer - INFO -   recall@5: 0.031909
2025-11-22 21:28:09 - GraphTrainer - INFO -   hit_rate@5: 0.033530
2025-11-22 21:28:09 - GraphTrainer - INFO -   ndcg@5: 0.021407
2025-11-22 21:28:09 - GraphTrainer - INFO -   map@5: 0.017727
2025-11-22 21:28:09 - GraphTrainer - INFO -   mrr@5: 0.018362
2025-11-22 21:28:09 - GraphTrainer - INFO -   precision@10: 0.005328
2025-11-22 21:28:09 - GraphTrainer - INFO -   recall@10: 0.050679
2025-11-22 21:28:09 - GraphTrainer - INFO -   hit_rate@10: 0.053227
2025-11-22 21:28:09 - GraphTrainer - INFO -   ndcg@10: 0.027469
2025-11-22 21:28:09 - GraphTrainer - INFO -   map@10: 0.020164
2025-11-22 21:28:09 - GraphTrainer - INFO -   mrr@10: 0.020922
2025-11-22 21:28:09 - GraphTrainer - INFO -   precision@20: 0.004212
2025-11-22 21:28:09 - GraphTrainer - INFO -   recall@20: 0.079819
2025-11-22 21:28:09 - GraphTrainer - INFO -   hit_rate@20: 0.083826
2025-11-22 21:28:09 - GraphTrainer - INFO -   ndcg@20: 0.034874
2025-11-22 21:28:09 - GraphTrainer - INFO -   map@20: 0.022150
2025-11-22 21:28:09 - GraphTrainer - INFO -   mrr@20: 0.022999
2025-11-22 21:28:09 - GraphTrainer - INFO - 第 114 轮训练完成
2025-11-22 21:28:09 - GraphTrainer - INFO - train_loss: 0.272059
2025-11-22 21:28:09 - GraphTrainer - INFO - precision@5: 0.006706
2025-11-22 21:28:09 - GraphTrainer - INFO - recall@5: 0.031909
2025-11-22 21:28:09 - GraphTrainer - INFO - hit_rate@5: 0.033530
2025-11-22 21:28:09 - GraphTrainer - INFO - ndcg@5: 0.021407
2025-11-22 21:28:09 - GraphTrainer - INFO - map@5: 0.017727
2025-11-22 21:28:09 - GraphTrainer - INFO - mrr@5: 0.018362
2025-11-22 21:28:09 - GraphTrainer - INFO - precision@10: 0.005328
2025-11-22 21:28:09 - GraphTrainer - INFO - recall@10: 0.050679
2025-11-22 21:28:09 - GraphTrainer - INFO - hit_rate@10: 0.053227
2025-11-22 21:28:09 - GraphTrainer - INFO - ndcg@10: 0.027469
2025-11-22 21:28:09 - GraphTrainer - INFO - map@10: 0.020164
2025-11-22 21:28:09 - GraphTrainer - INFO - mrr@10: 0.020922
2025-11-22 21:28:09 - GraphTrainer - INFO - precision@20: 0.004212
2025-11-22 21:28:09 - GraphTrainer - INFO - recall@20: 0.079819
2025-11-22 21:28:09 - GraphTrainer - INFO - hit_rate@20: 0.083826
2025-11-22 21:28:09 - GraphTrainer - INFO - ndcg@20: 0.034874
2025-11-22 21:28:09 - GraphTrainer - INFO - map@20: 0.022150
2025-11-22 21:28:09 - GraphTrainer - INFO - mrr@20: 0.022999
2025-11-22 21:28:09 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:28:09 - GraphTrainer - INFO - ============================================================
2025-11-22 21:28:09 - GraphTrainer - INFO - 开始第 115/1000 轮训练
2025-11-22 21:28:09 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2763, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2669, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2711, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2700, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2665, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2587, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2584, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2732, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2781, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2541, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2595, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2731, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2703, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2899, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2511, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2805, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2844, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2629, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2796, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2740, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2697, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2796, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2796, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2764, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2772, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2883, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2933, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2619, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2722, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2581, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2974, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2552, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2592, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3020, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2556, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2816, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2611, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2599, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2750, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2675, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2861, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2577, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2627, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2657, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2751, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2708, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2578, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2822, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2803, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2729, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2599, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2854, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2854, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2903, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2612, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2790, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2760, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2617, device='cuda:0', grad_fn=<AddBackward0>)
The 114 training average loss: 0.2720587705743724
2025-11-22 21:28:20 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:28:20 - GraphTrainer - INFO -   precision@5: 0.006665
2025-11-22 21:28:20 - GraphTrainer - INFO -   recall@5: 0.032007
2025-11-22 21:28:20 - GraphTrainer - INFO -   hit_rate@5: 0.033325
2025-11-22 21:28:20 - GraphTrainer - INFO -   ndcg@5: 0.021334
2025-11-22 21:28:20 - GraphTrainer - INFO -   map@5: 0.017624
2025-11-22 21:28:20 - GraphTrainer - INFO -   mrr@5: 0.018219
2025-11-22 21:28:20 - GraphTrainer - INFO -   precision@10: 0.005287
2025-11-22 21:28:20 - GraphTrainer - INFO -   recall@10: 0.050253
2025-11-22 21:28:20 - GraphTrainer - INFO -   hit_rate@10: 0.052764
2025-11-22 21:28:20 - GraphTrainer - INFO -   ndcg@10: 0.027281
2025-11-22 21:28:20 - GraphTrainer - INFO -   map@10: 0.020026
2025-11-22 21:28:20 - GraphTrainer - INFO -   mrr@10: 0.020778
2025-11-22 21:28:20 - GraphTrainer - INFO -   precision@20: 0.004173
2025-11-22 21:28:20 - GraphTrainer - INFO -   recall@20: 0.079028
2025-11-22 21:28:20 - GraphTrainer - INFO -   hit_rate@20: 0.083055
2025-11-22 21:28:20 - GraphTrainer - INFO -   ndcg@20: 0.034606
2025-11-22 21:28:20 - GraphTrainer - INFO -   map@20: 0.021995
2025-11-22 21:28:20 - GraphTrainer - INFO -   mrr@20: 0.022842
2025-11-22 21:28:20 - GraphTrainer - INFO - 第 115 轮训练完成
2025-11-22 21:28:20 - GraphTrainer - INFO - train_loss: 0.273461
2025-11-22 21:28:20 - GraphTrainer - INFO - precision@5: 0.006665
2025-11-22 21:28:20 - GraphTrainer - INFO - recall@5: 0.032007
2025-11-22 21:28:20 - GraphTrainer - INFO - hit_rate@5: 0.033325
2025-11-22 21:28:20 - GraphTrainer - INFO - ndcg@5: 0.021334
2025-11-22 21:28:20 - GraphTrainer - INFO - map@5: 0.017624
2025-11-22 21:28:20 - GraphTrainer - INFO - mrr@5: 0.018219
2025-11-22 21:28:20 - GraphTrainer - INFO - precision@10: 0.005287
2025-11-22 21:28:20 - GraphTrainer - INFO - recall@10: 0.050253
2025-11-22 21:28:20 - GraphTrainer - INFO - hit_rate@10: 0.052764
2025-11-22 21:28:20 - GraphTrainer - INFO - ndcg@10: 0.027281
2025-11-22 21:28:20 - GraphTrainer - INFO - map@10: 0.020026
2025-11-22 21:28:20 - GraphTrainer - INFO - mrr@10: 0.020778
2025-11-22 21:28:20 - GraphTrainer - INFO - precision@20: 0.004173
2025-11-22 21:28:20 - GraphTrainer - INFO - recall@20: 0.079028
2025-11-22 21:28:20 - GraphTrainer - INFO - hit_rate@20: 0.083055
2025-11-22 21:28:20 - GraphTrainer - INFO - ndcg@20: 0.034606
2025-11-22 21:28:20 - GraphTrainer - INFO - map@20: 0.021995
2025-11-22 21:28:20 - GraphTrainer - INFO - mrr@20: 0.022842
2025-11-22 21:28:20 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:28:20 - GraphTrainer - INFO - ============================================================
2025-11-22 21:28:20 - GraphTrainer - INFO - 开始第 116/1000 轮训练
2025-11-22 21:28:20 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2609, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2658, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2770, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2753, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2711, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2747, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2781, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2706, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2770, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2786, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2846, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2832, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2761, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2705, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2628, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2571, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2685, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2689, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2632, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2701, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2546, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2590, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3101, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2648, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2821, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2784, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2701, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2642, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2860, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2790, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2531, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2756, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2802, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2701, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3049, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2838, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2841, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2721, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2636, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2738, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2935, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2791, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2688, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2709, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2724, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2446, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2747, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2938, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2843, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2587, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2623, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2682, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2623, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2747, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2724, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2808, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2886, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2668, device='cuda:0', grad_fn=<AddBackward0>)
The 115 training average loss: 0.2734610474315183
2025-11-22 21:28:31 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:28:31 - GraphTrainer - INFO -   precision@5: 0.006706
2025-11-22 21:28:31 - GraphTrainer - INFO -   recall@5: 0.031926
2025-11-22 21:28:31 - GraphTrainer - INFO -   hit_rate@5: 0.033530
2025-11-22 21:28:31 - GraphTrainer - INFO -   ndcg@5: 0.021151
2025-11-22 21:28:31 - GraphTrainer - INFO -   map@5: 0.017352
2025-11-22 21:28:31 - GraphTrainer - INFO -   mrr@5: 0.018089
2025-11-22 21:28:31 - GraphTrainer - INFO -   precision@10: 0.005354
2025-11-22 21:28:31 - GraphTrainer - INFO -   recall@10: 0.050953
2025-11-22 21:28:31 - GraphTrainer - INFO -   hit_rate@10: 0.053536
2025-11-22 21:28:31 - GraphTrainer - INFO -   ndcg@10: 0.027318
2025-11-22 21:28:31 - GraphTrainer - INFO -   map@10: 0.019847
2025-11-22 21:28:31 - GraphTrainer - INFO -   mrr@10: 0.020709
2025-11-22 21:28:31 - GraphTrainer - INFO -   precision@20: 0.004171
2025-11-22 21:28:31 - GraphTrainer - INFO -   recall@20: 0.079047
2025-11-22 21:28:31 - GraphTrainer - INFO -   hit_rate@20: 0.082900
2025-11-22 21:28:31 - GraphTrainer - INFO -   ndcg@20: 0.034482
2025-11-22 21:28:31 - GraphTrainer - INFO -   map@20: 0.021784
2025-11-22 21:28:31 - GraphTrainer - INFO -   mrr@20: 0.022723
2025-11-22 21:28:31 - GraphTrainer - INFO - 第 116 轮训练完成
2025-11-22 21:28:31 - GraphTrainer - INFO - train_loss: 0.272727
2025-11-22 21:28:31 - GraphTrainer - INFO - precision@5: 0.006706
2025-11-22 21:28:31 - GraphTrainer - INFO - recall@5: 0.031926
2025-11-22 21:28:31 - GraphTrainer - INFO - hit_rate@5: 0.033530
2025-11-22 21:28:31 - GraphTrainer - INFO - ndcg@5: 0.021151
2025-11-22 21:28:31 - GraphTrainer - INFO - map@5: 0.017352
2025-11-22 21:28:31 - GraphTrainer - INFO - mrr@5: 0.018089
2025-11-22 21:28:31 - GraphTrainer - INFO - precision@10: 0.005354
2025-11-22 21:28:31 - GraphTrainer - INFO - recall@10: 0.050953
2025-11-22 21:28:31 - GraphTrainer - INFO - hit_rate@10: 0.053536
2025-11-22 21:28:31 - GraphTrainer - INFO - ndcg@10: 0.027318
2025-11-22 21:28:31 - GraphTrainer - INFO - map@10: 0.019847
2025-11-22 21:28:31 - GraphTrainer - INFO - mrr@10: 0.020709
2025-11-22 21:28:31 - GraphTrainer - INFO - precision@20: 0.004171
2025-11-22 21:28:31 - GraphTrainer - INFO - recall@20: 0.079047
2025-11-22 21:28:31 - GraphTrainer - INFO - hit_rate@20: 0.082900
2025-11-22 21:28:31 - GraphTrainer - INFO - ndcg@20: 0.034482
2025-11-22 21:28:31 - GraphTrainer - INFO - map@20: 0.021784
2025-11-22 21:28:31 - GraphTrainer - INFO - mrr@20: 0.022723
2025-11-22 21:28:31 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:28:31 - GraphTrainer - INFO - ============================================================
2025-11-22 21:28:31 - GraphTrainer - INFO - 开始第 117/1000 轮训练
2025-11-22 21:28:31 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2713, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2446, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2742, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2713, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2698, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2564, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2655, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2609, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2859, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2848, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2762, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2724, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2675, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2780, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2746, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3017, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2743, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2632, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2727, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2709, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2791, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2609, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2713, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2641, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2801, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2461, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2785, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2748, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2648, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2835, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2842, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2652, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2562, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2673, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2815, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2915, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2749, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2633, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2760, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2725, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2826, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2859, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2966, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2943, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2756, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2760, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2696, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2757, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2603, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2722, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2698, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2797, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2719, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2750, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2751, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2615, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2631, device='cuda:0', grad_fn=<AddBackward0>)
The 116 training average loss: 0.27272712259457027
2025-11-22 21:28:42 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:28:42 - GraphTrainer - INFO -   precision@5: 0.006686
2025-11-22 21:28:42 - GraphTrainer - INFO -   recall@5: 0.031867
2025-11-22 21:28:42 - GraphTrainer - INFO -   hit_rate@5: 0.033428
2025-11-22 21:28:42 - GraphTrainer - INFO -   ndcg@5: 0.020942
2025-11-22 21:28:42 - GraphTrainer - INFO -   map@5: 0.017109
2025-11-22 21:28:42 - GraphTrainer - INFO -   mrr@5: 0.017807
2025-11-22 21:28:42 - GraphTrainer - INFO -   precision@10: 0.005297
2025-11-22 21:28:42 - GraphTrainer - INFO -   recall@10: 0.050366
2025-11-22 21:28:42 - GraphTrainer - INFO -   hit_rate@10: 0.052918
2025-11-22 21:28:42 - GraphTrainer - INFO -   ndcg@10: 0.026962
2025-11-22 21:28:42 - GraphTrainer - INFO -   map@10: 0.019552
2025-11-22 21:28:42 - GraphTrainer - INFO -   mrr@10: 0.020376
2025-11-22 21:28:42 - GraphTrainer - INFO -   precision@20: 0.004191
2025-11-22 21:28:42 - GraphTrainer - INFO -   recall@20: 0.079149
2025-11-22 21:28:42 - GraphTrainer - INFO -   hit_rate@20: 0.083055
2025-11-22 21:28:42 - GraphTrainer - INFO -   ndcg@20: 0.034300
2025-11-22 21:28:42 - GraphTrainer - INFO -   map@20: 0.021530
2025-11-22 21:28:42 - GraphTrainer - INFO -   mrr@20: 0.022428
2025-11-22 21:28:42 - GraphTrainer - INFO - 第 117 轮训练完成
2025-11-22 21:28:42 - GraphTrainer - INFO - train_loss: 0.271859
2025-11-22 21:28:42 - GraphTrainer - INFO - precision@5: 0.006686
2025-11-22 21:28:42 - GraphTrainer - INFO - recall@5: 0.031867
2025-11-22 21:28:42 - GraphTrainer - INFO - hit_rate@5: 0.033428
2025-11-22 21:28:42 - GraphTrainer - INFO - ndcg@5: 0.020942
2025-11-22 21:28:42 - GraphTrainer - INFO - map@5: 0.017109
2025-11-22 21:28:42 - GraphTrainer - INFO - mrr@5: 0.017807
2025-11-22 21:28:42 - GraphTrainer - INFO - precision@10: 0.005297
2025-11-22 21:28:42 - GraphTrainer - INFO - recall@10: 0.050366
2025-11-22 21:28:42 - GraphTrainer - INFO - hit_rate@10: 0.052918
2025-11-22 21:28:42 - GraphTrainer - INFO - ndcg@10: 0.026962
2025-11-22 21:28:42 - GraphTrainer - INFO - map@10: 0.019552
2025-11-22 21:28:42 - GraphTrainer - INFO - mrr@10: 0.020376
2025-11-22 21:28:42 - GraphTrainer - INFO - precision@20: 0.004191
2025-11-22 21:28:42 - GraphTrainer - INFO - recall@20: 0.079149
2025-11-22 21:28:42 - GraphTrainer - INFO - hit_rate@20: 0.083055
2025-11-22 21:28:42 - GraphTrainer - INFO - ndcg@20: 0.034300
2025-11-22 21:28:42 - GraphTrainer - INFO - map@20: 0.021530
2025-11-22 21:28:42 - GraphTrainer - INFO - mrr@20: 0.022428
2025-11-22 21:28:42 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:28:42 - GraphTrainer - INFO - ============================================================
2025-11-22 21:28:42 - GraphTrainer - INFO - 开始第 118/1000 轮训练
2025-11-22 21:28:42 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2633, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2450, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2684, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2754, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2560, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2715, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2696, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2656, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2661, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2641, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2578, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2776, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2925, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2705, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2586, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2547, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2907, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2894, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2784, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2705, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2858, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2725, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2797, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2693, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2836, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2753, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2701, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2701, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2684, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2592, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2782, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2736, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2845, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2600, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2579, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2431, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2639, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2658, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2691, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2843, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2742, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2740, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2894, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2891, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2693, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2722, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2764, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2929, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2741, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2811, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2582, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2951, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2565, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2858, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2734, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2715, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>)
The 117 training average loss: 0.2718594079387599
2025-11-22 21:28:54 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:28:54 - GraphTrainer - INFO -   precision@5: 0.006758
2025-11-22 21:28:54 - GraphTrainer - INFO -   recall@5: 0.032247
2025-11-22 21:28:54 - GraphTrainer - INFO -   hit_rate@5: 0.033788
2025-11-22 21:28:54 - GraphTrainer - INFO -   ndcg@5: 0.021706
2025-11-22 21:28:54 - GraphTrainer - INFO -   map@5: 0.018001
2025-11-22 21:28:54 - GraphTrainer - INFO -   mrr@5: 0.018699
2025-11-22 21:28:54 - GraphTrainer - INFO -   precision@10: 0.005261
2025-11-22 21:28:54 - GraphTrainer - INFO -   recall@10: 0.050025
2025-11-22 21:28:54 - GraphTrainer - INFO -   hit_rate@10: 0.052404
2025-11-22 21:28:54 - GraphTrainer - INFO -   ndcg@10: 0.027466
2025-11-22 21:28:54 - GraphTrainer - INFO -   map@10: 0.020330
2025-11-22 21:28:54 - GraphTrainer - INFO -   mrr@10: 0.021131
2025-11-22 21:28:54 - GraphTrainer - INFO -   precision@20: 0.004240
2025-11-22 21:28:54 - GraphTrainer - INFO -   recall@20: 0.080379
2025-11-22 21:28:54 - GraphTrainer - INFO -   hit_rate@20: 0.084340
2025-11-22 21:28:54 - GraphTrainer - INFO -   ndcg@20: 0.035186
2025-11-22 21:28:54 - GraphTrainer - INFO -   map@20: 0.022405
2025-11-22 21:28:54 - GraphTrainer - INFO -   mrr@20: 0.023306
2025-11-22 21:28:54 - GraphTrainer - INFO - 第 118 轮训练完成
2025-11-22 21:28:54 - GraphTrainer - INFO - train_loss: 0.273651
2025-11-22 21:28:54 - GraphTrainer - INFO - precision@5: 0.006758
2025-11-22 21:28:54 - GraphTrainer - INFO - recall@5: 0.032247
2025-11-22 21:28:54 - GraphTrainer - INFO - hit_rate@5: 0.033788
2025-11-22 21:28:54 - GraphTrainer - INFO - ndcg@5: 0.021706
2025-11-22 21:28:54 - GraphTrainer - INFO - map@5: 0.018001
2025-11-22 21:28:54 - GraphTrainer - INFO - mrr@5: 0.018699
2025-11-22 21:28:54 - GraphTrainer - INFO - precision@10: 0.005261
2025-11-22 21:28:54 - GraphTrainer - INFO - recall@10: 0.050025
2025-11-22 21:28:54 - GraphTrainer - INFO - hit_rate@10: 0.052404
2025-11-22 21:28:54 - GraphTrainer - INFO - ndcg@10: 0.027466
2025-11-22 21:28:54 - GraphTrainer - INFO - map@10: 0.020330
2025-11-22 21:28:54 - GraphTrainer - INFO - mrr@10: 0.021131
2025-11-22 21:28:54 - GraphTrainer - INFO - precision@20: 0.004240
2025-11-22 21:28:54 - GraphTrainer - INFO - recall@20: 0.080379
2025-11-22 21:28:54 - GraphTrainer - INFO - hit_rate@20: 0.084340
2025-11-22 21:28:54 - GraphTrainer - INFO - ndcg@20: 0.035186
2025-11-22 21:28:54 - GraphTrainer - INFO - map@20: 0.022405
2025-11-22 21:28:54 - GraphTrainer - INFO - mrr@20: 0.023306
2025-11-22 21:28:54 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:28:54 - GraphTrainer - INFO - ============================================================
2025-11-22 21:28:54 - GraphTrainer - INFO - 开始第 119/1000 轮训练
2025-11-22 21:28:54 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2479, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2775, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2748, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2639, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2746, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2646, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2802, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2667, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2815, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2718, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2567, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2593, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2587, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2603, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2989, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2795, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2659, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2706, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2492, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2708, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2985, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2957, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2812, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2918, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2726, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2816, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2720, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2803, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2701, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2706, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2644, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2708, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2750, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2808, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2746, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2585, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2771, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2569, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2702, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2616, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2725, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2711, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2660, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2788, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2847, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2837, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2546, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2715, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2760, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2949, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2635, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2903, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2706, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2787, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2935, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2772, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2930, device='cuda:0', grad_fn=<AddBackward0>)
The 118 training average loss: 0.27365077004350463
2025-11-22 21:29:05 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:29:05 - GraphTrainer - INFO -   precision@5: 0.006840
2025-11-22 21:29:05 - GraphTrainer - INFO -   recall@5: 0.032827
2025-11-22 21:29:05 - GraphTrainer - INFO -   hit_rate@5: 0.034199
2025-11-22 21:29:05 - GraphTrainer - INFO -   ndcg@5: 0.021698
2025-11-22 21:29:05 - GraphTrainer - INFO -   map@5: 0.017839
2025-11-22 21:29:05 - GraphTrainer - INFO -   mrr@5: 0.018484
2025-11-22 21:29:05 - GraphTrainer - INFO -   precision@10: 0.005364
2025-11-22 21:29:05 - GraphTrainer - INFO -   recall@10: 0.051007
2025-11-22 21:29:05 - GraphTrainer - INFO -   hit_rate@10: 0.053587
2025-11-22 21:29:05 - GraphTrainer - INFO -   ndcg@10: 0.027594
2025-11-22 21:29:05 - GraphTrainer - INFO -   map@10: 0.020205
2025-11-22 21:29:05 - GraphTrainer - INFO -   mrr@10: 0.021008
2025-11-22 21:29:05 - GraphTrainer - INFO -   precision@20: 0.004209
2025-11-22 21:29:05 - GraphTrainer - INFO -   recall@20: 0.079772
2025-11-22 21:29:05 - GraphTrainer - INFO -   hit_rate@20: 0.083672
2025-11-22 21:29:05 - GraphTrainer - INFO -   ndcg@20: 0.034899
2025-11-22 21:29:05 - GraphTrainer - INFO -   map@20: 0.022164
2025-11-22 21:29:05 - GraphTrainer - INFO -   mrr@20: 0.023050
2025-11-22 21:29:05 - GraphTrainer - INFO - 第 119 轮训练完成
2025-11-22 21:29:05 - GraphTrainer - INFO - train_loss: 0.275120
2025-11-22 21:29:05 - GraphTrainer - INFO - precision@5: 0.006840
2025-11-22 21:29:05 - GraphTrainer - INFO - recall@5: 0.032827
2025-11-22 21:29:05 - GraphTrainer - INFO - hit_rate@5: 0.034199
2025-11-22 21:29:05 - GraphTrainer - INFO - ndcg@5: 0.021698
2025-11-22 21:29:05 - GraphTrainer - INFO - map@5: 0.017839
2025-11-22 21:29:05 - GraphTrainer - INFO - mrr@5: 0.018484
2025-11-22 21:29:05 - GraphTrainer - INFO - precision@10: 0.005364
2025-11-22 21:29:05 - GraphTrainer - INFO - recall@10: 0.051007
2025-11-22 21:29:05 - GraphTrainer - INFO - hit_rate@10: 0.053587
2025-11-22 21:29:05 - GraphTrainer - INFO - ndcg@10: 0.027594
2025-11-22 21:29:05 - GraphTrainer - INFO - map@10: 0.020205
2025-11-22 21:29:05 - GraphTrainer - INFO - mrr@10: 0.021008
2025-11-22 21:29:05 - GraphTrainer - INFO - precision@20: 0.004209
2025-11-22 21:29:05 - GraphTrainer - INFO - recall@20: 0.079772
2025-11-22 21:29:05 - GraphTrainer - INFO - hit_rate@20: 0.083672
2025-11-22 21:29:05 - GraphTrainer - INFO - ndcg@20: 0.034899
2025-11-22 21:29:05 - GraphTrainer - INFO - map@20: 0.022164
2025-11-22 21:29:05 - GraphTrainer - INFO - mrr@20: 0.023050
2025-11-22 21:29:05 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:29:05 - GraphTrainer - INFO - ============================================================
2025-11-22 21:29:05 - GraphTrainer - INFO - 开始第 120/1000 轮训练
2025-11-22 21:29:05 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2686, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2696, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2869, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2857, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2943, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2524, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2626, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2745, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2725, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2633, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2665, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2740, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2732, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2750, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2751, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2683, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2583, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2791, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2723, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2860, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2751, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2921, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2778, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2590, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2938, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2887, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2761, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3011, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2771, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2727, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2745, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2703, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2582, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2785, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2671, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2768, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2746, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2740, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2676, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2797, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2751, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2683, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2802, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2658, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2852, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2742, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2618, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2827, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2719, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2635, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2875, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2797, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2593, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2880, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2747, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3020, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2793, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2643, device='cuda:0', grad_fn=<AddBackward0>)
The 119 training average loss: 0.27511979896446753
2025-11-22 21:29:16 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:29:16 - GraphTrainer - INFO -   precision@5: 0.006706
2025-11-22 21:29:16 - GraphTrainer - INFO -   recall@5: 0.032049
2025-11-22 21:29:16 - GraphTrainer - INFO -   hit_rate@5: 0.033530
2025-11-22 21:29:16 - GraphTrainer - INFO -   ndcg@5: 0.021602
2025-11-22 21:29:16 - GraphTrainer - INFO -   map@5: 0.017931
2025-11-22 21:29:16 - GraphTrainer - INFO -   mrr@5: 0.018608
2025-11-22 21:29:16 - GraphTrainer - INFO -   precision@10: 0.005292
2025-11-22 21:29:16 - GraphTrainer - INFO -   recall@10: 0.050608
2025-11-22 21:29:16 - GraphTrainer - INFO -   hit_rate@10: 0.052867
2025-11-22 21:29:16 - GraphTrainer - INFO -   ndcg@10: 0.027612
2025-11-22 21:29:16 - GraphTrainer - INFO -   map@10: 0.020366
2025-11-22 21:29:16 - GraphTrainer - INFO -   mrr@10: 0.021147
2025-11-22 21:29:16 - GraphTrainer - INFO -   precision@20: 0.004276
2025-11-22 21:29:16 - GraphTrainer - INFO -   recall@20: 0.080918
2025-11-22 21:29:16 - GraphTrainer - INFO -   hit_rate@20: 0.084906
2025-11-22 21:29:16 - GraphTrainer - INFO -   ndcg@20: 0.035305
2025-11-22 21:29:16 - GraphTrainer - INFO -   map@20: 0.022411
2025-11-22 21:29:16 - GraphTrainer - INFO -   mrr@20: 0.023303
2025-11-22 21:29:16 - GraphTrainer - INFO - 第 120 轮训练完成
2025-11-22 21:29:16 - GraphTrainer - INFO - train_loss: 0.266297
2025-11-22 21:29:16 - GraphTrainer - INFO - precision@5: 0.006706
2025-11-22 21:29:16 - GraphTrainer - INFO - recall@5: 0.032049
2025-11-22 21:29:16 - GraphTrainer - INFO - hit_rate@5: 0.033530
2025-11-22 21:29:16 - GraphTrainer - INFO - ndcg@5: 0.021602
2025-11-22 21:29:16 - GraphTrainer - INFO - map@5: 0.017931
2025-11-22 21:29:16 - GraphTrainer - INFO - mrr@5: 0.018608
2025-11-22 21:29:16 - GraphTrainer - INFO - precision@10: 0.005292
2025-11-22 21:29:16 - GraphTrainer - INFO - recall@10: 0.050608
2025-11-22 21:29:16 - GraphTrainer - INFO - hit_rate@10: 0.052867
2025-11-22 21:29:16 - GraphTrainer - INFO - ndcg@10: 0.027612
2025-11-22 21:29:16 - GraphTrainer - INFO - map@10: 0.020366
2025-11-22 21:29:16 - GraphTrainer - INFO - mrr@10: 0.021147
2025-11-22 21:29:16 - GraphTrainer - INFO - precision@20: 0.004276
2025-11-22 21:29:16 - GraphTrainer - INFO - recall@20: 0.080918
2025-11-22 21:29:16 - GraphTrainer - INFO - hit_rate@20: 0.084906
2025-11-22 21:29:16 - GraphTrainer - INFO - ndcg@20: 0.035305
2025-11-22 21:29:16 - GraphTrainer - INFO - map@20: 0.022411
2025-11-22 21:29:16 - GraphTrainer - INFO - mrr@20: 0.023303
2025-11-22 21:29:16 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:29:16 - GraphTrainer - INFO - 检查点已保存: Epoch 120 -> ./checkpoints/checkpoint_epoch_120.pth
2025-11-22 21:29:16 - GraphTrainer - INFO - ============================================================
2025-11-22 21:29:16 - GraphTrainer - INFO - 开始第 121/1000 轮训练
2025-11-22 21:29:16 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2619, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2714, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2604, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2813, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2691, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2717, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2761, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2895, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2985, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2953, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2524, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2967, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2489, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2761, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2512, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2693, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2681, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2615, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2697, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2303, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2645, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2641, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2597, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2793, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2717, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2713, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2562, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2716, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2625, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2689, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2596, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2745, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2614, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2509, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2623, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2454, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2531, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2542, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2633, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2836, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2702, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2617, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2531, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2728, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2599, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2695, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2411, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2693, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2618, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2761, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2679, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2564, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2750, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2516, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2740, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2671, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2666, device='cuda:0', grad_fn=<AddBackward0>)
The 120 training average loss: 0.26629664440607204
2025-11-22 21:29:27 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:29:27 - GraphTrainer - INFO -   precision@5: 0.006881
2025-11-22 21:29:27 - GraphTrainer - INFO -   recall@5: 0.032964
2025-11-22 21:29:27 - GraphTrainer - INFO -   hit_rate@5: 0.034405
2025-11-22 21:29:27 - GraphTrainer - INFO -   ndcg@5: 0.022162
2025-11-22 21:29:27 - GraphTrainer - INFO -   map@5: 0.018391
2025-11-22 21:29:27 - GraphTrainer - INFO -   mrr@5: 0.019065
2025-11-22 21:29:27 - GraphTrainer - INFO -   precision@10: 0.005395
2025-11-22 21:29:27 - GraphTrainer - INFO -   recall@10: 0.051260
2025-11-22 21:29:27 - GraphTrainer - INFO -   hit_rate@10: 0.053947
2025-11-22 21:29:27 - GraphTrainer - INFO -   ndcg@10: 0.028123
2025-11-22 21:29:27 - GraphTrainer - INFO -   map@10: 0.020797
2025-11-22 21:29:27 - GraphTrainer - INFO -   mrr@10: 0.021638
2025-11-22 21:29:27 - GraphTrainer - INFO -   precision@20: 0.004307
2025-11-22 21:29:27 - GraphTrainer - INFO -   recall@20: 0.081529
2025-11-22 21:29:27 - GraphTrainer - INFO -   hit_rate@20: 0.085729
2025-11-22 21:29:27 - GraphTrainer - INFO -   ndcg@20: 0.035834
2025-11-22 21:29:27 - GraphTrainer - INFO -   map@20: 0.022872
2025-11-22 21:29:27 - GraphTrainer - INFO -   mrr@20: 0.023815
2025-11-22 21:29:27 - GraphTrainer - INFO - 第 121 轮训练完成
2025-11-22 21:29:27 - GraphTrainer - INFO - train_loss: 0.268214
2025-11-22 21:29:27 - GraphTrainer - INFO - precision@5: 0.006881
2025-11-22 21:29:27 - GraphTrainer - INFO - recall@5: 0.032964
2025-11-22 21:29:27 - GraphTrainer - INFO - hit_rate@5: 0.034405
2025-11-22 21:29:27 - GraphTrainer - INFO - ndcg@5: 0.022162
2025-11-22 21:29:27 - GraphTrainer - INFO - map@5: 0.018391
2025-11-22 21:29:27 - GraphTrainer - INFO - mrr@5: 0.019065
2025-11-22 21:29:27 - GraphTrainer - INFO - precision@10: 0.005395
2025-11-22 21:29:27 - GraphTrainer - INFO - recall@10: 0.051260
2025-11-22 21:29:27 - GraphTrainer - INFO - hit_rate@10: 0.053947
2025-11-22 21:29:27 - GraphTrainer - INFO - ndcg@10: 0.028123
2025-11-22 21:29:27 - GraphTrainer - INFO - map@10: 0.020797
2025-11-22 21:29:27 - GraphTrainer - INFO - mrr@10: 0.021638
2025-11-22 21:29:27 - GraphTrainer - INFO - precision@20: 0.004307
2025-11-22 21:29:27 - GraphTrainer - INFO - recall@20: 0.081529
2025-11-22 21:29:27 - GraphTrainer - INFO - hit_rate@20: 0.085729
2025-11-22 21:29:27 - GraphTrainer - INFO - ndcg@20: 0.035834
2025-11-22 21:29:27 - GraphTrainer - INFO - map@20: 0.022872
2025-11-22 21:29:27 - GraphTrainer - INFO - mrr@20: 0.023815
2025-11-22 21:29:27 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:29:27 - GraphTrainer - INFO - ============================================================
2025-11-22 21:29:27 - GraphTrainer - INFO - 开始第 122/1000 轮训练
2025-11-22 21:29:27 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2760, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2683, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2683, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2782, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2780, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2697, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2575, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2718, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2601, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2655, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2573, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2763, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2852, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2788, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2656, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2579, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2740, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2661, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2705, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2776, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2565, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2860, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2552, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2762, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2620, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2612, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2584, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2911, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2695, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2795, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2726, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2808, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2718, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2678, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2579, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2642, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2853, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2461, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2370, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2863, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2626, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2592, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2762, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2461, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2651, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2814, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2749, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2734, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2656, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2573, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2790, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2650, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2717, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2445, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2763, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2554, device='cuda:0', grad_fn=<AddBackward0>)
The 121 training average loss: 0.2682136096831026
2025-11-22 21:29:38 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:29:38 - GraphTrainer - INFO -   precision@5: 0.006902
2025-11-22 21:29:38 - GraphTrainer - INFO -   recall@5: 0.033084
2025-11-22 21:29:38 - GraphTrainer - INFO -   hit_rate@5: 0.034508
2025-11-22 21:29:38 - GraphTrainer - INFO -   ndcg@5: 0.022131
2025-11-22 21:29:38 - GraphTrainer - INFO -   map@5: 0.018300
2025-11-22 21:29:38 - GraphTrainer - INFO -   mrr@5: 0.018967
2025-11-22 21:29:38 - GraphTrainer - INFO -   precision@10: 0.005420
2025-11-22 21:29:38 - GraphTrainer - INFO -   recall@10: 0.051825
2025-11-22 21:29:38 - GraphTrainer - INFO -   hit_rate@10: 0.054204
2025-11-22 21:29:38 - GraphTrainer - INFO -   ndcg@10: 0.028192
2025-11-22 21:29:38 - GraphTrainer - INFO -   map@10: 0.020744
2025-11-22 21:29:38 - GraphTrainer - INFO -   mrr@10: 0.021530
2025-11-22 21:29:38 - GraphTrainer - INFO -   precision@20: 0.004279
2025-11-22 21:29:38 - GraphTrainer - INFO -   recall@20: 0.080845
2025-11-22 21:29:38 - GraphTrainer - INFO -   hit_rate@20: 0.085060
2025-11-22 21:29:38 - GraphTrainer - INFO -   ndcg@20: 0.035564
2025-11-22 21:29:38 - GraphTrainer - INFO -   map@20: 0.022697
2025-11-22 21:29:38 - GraphTrainer - INFO -   mrr@20: 0.023606
2025-11-22 21:29:38 - GraphTrainer - INFO - 第 122 轮训练完成
2025-11-22 21:29:38 - GraphTrainer - INFO - train_loss: 0.268096
2025-11-22 21:29:38 - GraphTrainer - INFO - precision@5: 0.006902
2025-11-22 21:29:38 - GraphTrainer - INFO - recall@5: 0.033084
2025-11-22 21:29:38 - GraphTrainer - INFO - hit_rate@5: 0.034508
2025-11-22 21:29:38 - GraphTrainer - INFO - ndcg@5: 0.022131
2025-11-22 21:29:38 - GraphTrainer - INFO - map@5: 0.018300
2025-11-22 21:29:38 - GraphTrainer - INFO - mrr@5: 0.018967
2025-11-22 21:29:38 - GraphTrainer - INFO - precision@10: 0.005420
2025-11-22 21:29:38 - GraphTrainer - INFO - recall@10: 0.051825
2025-11-22 21:29:38 - GraphTrainer - INFO - hit_rate@10: 0.054204
2025-11-22 21:29:38 - GraphTrainer - INFO - ndcg@10: 0.028192
2025-11-22 21:29:38 - GraphTrainer - INFO - map@10: 0.020744
2025-11-22 21:29:38 - GraphTrainer - INFO - mrr@10: 0.021530
2025-11-22 21:29:38 - GraphTrainer - INFO - precision@20: 0.004279
2025-11-22 21:29:38 - GraphTrainer - INFO - recall@20: 0.080845
2025-11-22 21:29:38 - GraphTrainer - INFO - hit_rate@20: 0.085060
2025-11-22 21:29:38 - GraphTrainer - INFO - ndcg@20: 0.035564
2025-11-22 21:29:38 - GraphTrainer - INFO - map@20: 0.022697
2025-11-22 21:29:38 - GraphTrainer - INFO - mrr@20: 0.023606
2025-11-22 21:29:38 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:29:38 - GraphTrainer - INFO - ============================================================
2025-11-22 21:29:38 - GraphTrainer - INFO - 开始第 123/1000 轮训练
2025-11-22 21:29:38 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2689, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2670, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2654, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2656, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2683, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2860, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2565, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2658, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2799, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2781, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2479, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2844, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2605, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2793, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2593, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2566, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2774, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2745, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2608, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2669, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2606, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2717, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2480, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2522, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2975, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2565, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2673, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2848, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2788, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2640, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2644, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2657, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2544, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2600, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2720, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2688, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2286, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2471, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2865, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2741, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2538, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2817, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2584, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2754, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2574, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3003, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2584, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2539, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2924, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2999, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2658, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2623, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2699, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2771, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2773, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2504, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2694, device='cuda:0', grad_fn=<AddBackward0>)
The 122 training average loss: 0.2680957651343839
2025-11-22 21:29:49 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:29:49 - GraphTrainer - INFO -   precision@5: 0.006809
2025-11-22 21:29:49 - GraphTrainer - INFO -   recall@5: 0.032603
2025-11-22 21:29:49 - GraphTrainer - INFO -   hit_rate@5: 0.034045
2025-11-22 21:29:49 - GraphTrainer - INFO -   ndcg@5: 0.021930
2025-11-22 21:29:49 - GraphTrainer - INFO -   map@5: 0.018177
2025-11-22 21:29:49 - GraphTrainer - INFO -   mrr@5: 0.018851
2025-11-22 21:29:49 - GraphTrainer - INFO -   precision@10: 0.005467
2025-11-22 21:29:49 - GraphTrainer - INFO -   recall@10: 0.051856
2025-11-22 21:29:49 - GraphTrainer - INFO -   hit_rate@10: 0.054564
2025-11-22 21:29:49 - GraphTrainer - INFO -   ndcg@10: 0.028232
2025-11-22 21:29:49 - GraphTrainer - INFO -   map@10: 0.020739
2025-11-22 21:29:49 - GraphTrainer - INFO -   mrr@10: 0.021584
2025-11-22 21:29:49 - GraphTrainer - INFO -   precision@20: 0.004312
2025-11-22 21:29:49 - GraphTrainer - INFO -   recall@20: 0.081475
2025-11-22 21:29:49 - GraphTrainer - INFO -   hit_rate@20: 0.085729
2025-11-22 21:29:49 - GraphTrainer - INFO -   ndcg@20: 0.035731
2025-11-22 21:29:49 - GraphTrainer - INFO -   map@20: 0.022730
2025-11-22 21:29:49 - GraphTrainer - INFO -   mrr@20: 0.023673
2025-11-22 21:29:49 - GraphTrainer - INFO - 第 123 轮训练完成
2025-11-22 21:29:49 - GraphTrainer - INFO - train_loss: 0.266732
2025-11-22 21:29:49 - GraphTrainer - INFO - precision@5: 0.006809
2025-11-22 21:29:49 - GraphTrainer - INFO - recall@5: 0.032603
2025-11-22 21:29:49 - GraphTrainer - INFO - hit_rate@5: 0.034045
2025-11-22 21:29:49 - GraphTrainer - INFO - ndcg@5: 0.021930
2025-11-22 21:29:49 - GraphTrainer - INFO - map@5: 0.018177
2025-11-22 21:29:49 - GraphTrainer - INFO - mrr@5: 0.018851
2025-11-22 21:29:49 - GraphTrainer - INFO - precision@10: 0.005467
2025-11-22 21:29:49 - GraphTrainer - INFO - recall@10: 0.051856
2025-11-22 21:29:49 - GraphTrainer - INFO - hit_rate@10: 0.054564
2025-11-22 21:29:49 - GraphTrainer - INFO - ndcg@10: 0.028232
2025-11-22 21:29:49 - GraphTrainer - INFO - map@10: 0.020739
2025-11-22 21:29:49 - GraphTrainer - INFO - mrr@10: 0.021584
2025-11-22 21:29:49 - GraphTrainer - INFO - precision@20: 0.004312
2025-11-22 21:29:49 - GraphTrainer - INFO - recall@20: 0.081475
2025-11-22 21:29:49 - GraphTrainer - INFO - hit_rate@20: 0.085729
2025-11-22 21:29:49 - GraphTrainer - INFO - ndcg@20: 0.035731
2025-11-22 21:29:49 - GraphTrainer - INFO - map@20: 0.022730
2025-11-22 21:29:49 - GraphTrainer - INFO - mrr@20: 0.023673
2025-11-22 21:29:49 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:29:49 - GraphTrainer - INFO - ============================================================
2025-11-22 21:29:49 - GraphTrainer - INFO - 开始第 124/1000 轮训练
2025-11-22 21:29:49 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2640, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2785, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2560, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2559, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2641, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2732, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2727, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2641, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2756, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2827, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2836, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2571, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2644, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2777, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2716, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2739, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2705, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2494, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2740, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2675, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2596, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2553, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2449, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2656, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2871, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2640, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2709, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2608, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2717, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2612, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2669, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2637, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2607, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2893, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2597, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2773, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2457, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2759, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2865, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2687, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2679, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2580, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2635, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2495, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2723, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2718, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2431, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2900, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2619, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2516, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2819, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2541, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2692, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2629, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2724, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2490, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2681, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2716, device='cuda:0', grad_fn=<AddBackward0>)
The 123 training average loss: 0.2667317793800913
2025-11-22 21:30:00 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:30:00 - GraphTrainer - INFO -   precision@5: 0.006974
2025-11-22 21:30:00 - GraphTrainer - INFO -   recall@5: 0.033404
2025-11-22 21:30:00 - GraphTrainer - INFO -   hit_rate@5: 0.034868
2025-11-22 21:30:00 - GraphTrainer - INFO -   ndcg@5: 0.022281
2025-11-22 21:30:00 - GraphTrainer - INFO -   map@5: 0.018375
2025-11-22 21:30:00 - GraphTrainer - INFO -   mrr@5: 0.019109
2025-11-22 21:30:00 - GraphTrainer - INFO -   precision@10: 0.005446
2025-11-22 21:30:00 - GraphTrainer - INFO -   recall@10: 0.051856
2025-11-22 21:30:00 - GraphTrainer - INFO -   hit_rate@10: 0.054410
2025-11-22 21:30:00 - GraphTrainer - INFO -   ndcg@10: 0.028252
2025-11-22 21:30:00 - GraphTrainer - INFO -   map@10: 0.020772
2025-11-22 21:30:00 - GraphTrainer - INFO -   mrr@10: 0.021651
2025-11-22 21:30:00 - GraphTrainer - INFO -   precision@20: 0.004304
2025-11-22 21:30:00 - GraphTrainer - INFO -   recall@20: 0.081411
2025-11-22 21:30:00 - GraphTrainer - INFO -   hit_rate@20: 0.085575
2025-11-22 21:30:00 - GraphTrainer - INFO -   ndcg@20: 0.035775
2025-11-22 21:30:00 - GraphTrainer - INFO -   map@20: 0.022787
2025-11-22 21:30:00 - GraphTrainer - INFO -   mrr@20: 0.023772
2025-11-22 21:30:00 - GraphTrainer - INFO - 第 124 轮训练完成
2025-11-22 21:30:00 - GraphTrainer - INFO - train_loss: 0.264950
2025-11-22 21:30:00 - GraphTrainer - INFO - precision@5: 0.006974
2025-11-22 21:30:00 - GraphTrainer - INFO - recall@5: 0.033404
2025-11-22 21:30:00 - GraphTrainer - INFO - hit_rate@5: 0.034868
2025-11-22 21:30:00 - GraphTrainer - INFO - ndcg@5: 0.022281
2025-11-22 21:30:00 - GraphTrainer - INFO - map@5: 0.018375
2025-11-22 21:30:00 - GraphTrainer - INFO - mrr@5: 0.019109
2025-11-22 21:30:00 - GraphTrainer - INFO - precision@10: 0.005446
2025-11-22 21:30:00 - GraphTrainer - INFO - recall@10: 0.051856
2025-11-22 21:30:00 - GraphTrainer - INFO - hit_rate@10: 0.054410
2025-11-22 21:30:00 - GraphTrainer - INFO - ndcg@10: 0.028252
2025-11-22 21:30:00 - GraphTrainer - INFO - map@10: 0.020772
2025-11-22 21:30:00 - GraphTrainer - INFO - mrr@10: 0.021651
2025-11-22 21:30:00 - GraphTrainer - INFO - precision@20: 0.004304
2025-11-22 21:30:00 - GraphTrainer - INFO - recall@20: 0.081411
2025-11-22 21:30:00 - GraphTrainer - INFO - hit_rate@20: 0.085575
2025-11-22 21:30:00 - GraphTrainer - INFO - ndcg@20: 0.035775
2025-11-22 21:30:00 - GraphTrainer - INFO - map@20: 0.022787
2025-11-22 21:30:00 - GraphTrainer - INFO - mrr@20: 0.023772
2025-11-22 21:30:00 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:30:00 - GraphTrainer - INFO - ============================================================
2025-11-22 21:30:00 - GraphTrainer - INFO - 开始第 125/1000 轮训练
2025-11-22 21:30:00 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2696, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2578, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2748, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2624, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2535, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2434, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2673, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2697, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2893, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2740, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2758, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2391, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2673, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2548, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2716, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2820, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2878, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2493, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2770, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2660, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2455, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2581, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2684, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2595, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2535, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2550, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2639, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2513, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2676, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2655, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2561, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2797, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2630, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2529, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2642, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2457, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2724, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2592, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2900, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2416, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2558, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2619, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2883, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2726, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2683, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2704, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2770, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2878, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2630, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2602, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2850, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2716, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2546, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2547, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2715, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2685, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2516, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2587, device='cuda:0', grad_fn=<AddBackward0>)
The 124 training average loss: 0.26495007887996475
2025-11-22 21:30:11 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:30:11 - GraphTrainer - INFO -   precision@5: 0.006840
2025-11-22 21:30:11 - GraphTrainer - INFO -   recall@5: 0.032881
2025-11-22 21:30:11 - GraphTrainer - INFO -   hit_rate@5: 0.034199
2025-11-22 21:30:11 - GraphTrainer - INFO -   ndcg@5: 0.021412
2025-11-22 21:30:11 - GraphTrainer - INFO -   map@5: 0.017419
2025-11-22 21:30:11 - GraphTrainer - INFO -   mrr@5: 0.018055
2025-11-22 21:30:11 - GraphTrainer - INFO -   precision@10: 0.005354
2025-11-22 21:30:11 - GraphTrainer - INFO -   recall@10: 0.050721
2025-11-22 21:30:11 - GraphTrainer - INFO -   hit_rate@10: 0.053484
2025-11-22 21:30:11 - GraphTrainer - INFO -   ndcg@10: 0.027218
2025-11-22 21:30:11 - GraphTrainer - INFO -   map@10: 0.019745
2025-11-22 21:30:11 - GraphTrainer - INFO -   mrr@10: 0.020573
2025-11-22 21:30:11 - GraphTrainer - INFO -   precision@20: 0.004320
2025-11-22 21:30:11 - GraphTrainer - INFO -   recall@20: 0.081562
2025-11-22 21:30:11 - GraphTrainer - INFO -   hit_rate@20: 0.085986
2025-11-22 21:30:11 - GraphTrainer - INFO -   ndcg@20: 0.035059
2025-11-22 21:30:11 - GraphTrainer - INFO -   map@20: 0.021841
2025-11-22 21:30:11 - GraphTrainer - INFO -   mrr@20: 0.022777
2025-11-22 21:30:11 - GraphTrainer - INFO - 第 125 轮训练完成
2025-11-22 21:30:11 - GraphTrainer - INFO - train_loss: 0.265933
2025-11-22 21:30:11 - GraphTrainer - INFO - precision@5: 0.006840
2025-11-22 21:30:11 - GraphTrainer - INFO - recall@5: 0.032881
2025-11-22 21:30:11 - GraphTrainer - INFO - hit_rate@5: 0.034199
2025-11-22 21:30:11 - GraphTrainer - INFO - ndcg@5: 0.021412
2025-11-22 21:30:11 - GraphTrainer - INFO - map@5: 0.017419
2025-11-22 21:30:11 - GraphTrainer - INFO - mrr@5: 0.018055
2025-11-22 21:30:11 - GraphTrainer - INFO - precision@10: 0.005354
2025-11-22 21:30:11 - GraphTrainer - INFO - recall@10: 0.050721
2025-11-22 21:30:11 - GraphTrainer - INFO - hit_rate@10: 0.053484
2025-11-22 21:30:11 - GraphTrainer - INFO - ndcg@10: 0.027218
2025-11-22 21:30:11 - GraphTrainer - INFO - map@10: 0.019745
2025-11-22 21:30:11 - GraphTrainer - INFO - mrr@10: 0.020573
2025-11-22 21:30:11 - GraphTrainer - INFO - precision@20: 0.004320
2025-11-22 21:30:11 - GraphTrainer - INFO - recall@20: 0.081562
2025-11-22 21:30:11 - GraphTrainer - INFO - hit_rate@20: 0.085986
2025-11-22 21:30:11 - GraphTrainer - INFO - ndcg@20: 0.035059
2025-11-22 21:30:11 - GraphTrainer - INFO - map@20: 0.021841
2025-11-22 21:30:11 - GraphTrainer - INFO - mrr@20: 0.022777
2025-11-22 21:30:11 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:30:11 - GraphTrainer - INFO - ============================================================
2025-11-22 21:30:11 - GraphTrainer - INFO - 开始第 126/1000 轮训练
2025-11-22 21:30:11 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2515, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2589, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2755, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2653, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2680, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2857, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2600, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2643, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2626, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2611, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2707, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2535, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2647, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2670, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2743, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2751, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2798, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2652, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2609, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2609, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2525, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2682, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2716, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2684, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2460, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2534, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2673, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2545, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2725, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2448, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2610, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2832, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2658, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2526, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2703, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2840, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2587, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2813, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2743, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2748, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2758, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2670, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2467, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2646, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2577, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2759, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2948, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2702, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2610, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2473, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2340, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2818, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2755, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2689, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2756, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2653, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2483, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2836, device='cuda:0', grad_fn=<AddBackward0>)
The 125 training average loss: 0.26593304733777867
2025-11-22 21:30:22 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:30:22 - GraphTrainer - INFO -   precision@5: 0.006850
2025-11-22 21:30:22 - GraphTrainer - INFO -   recall@5: 0.032750
2025-11-22 21:30:22 - GraphTrainer - INFO -   hit_rate@5: 0.034250
2025-11-22 21:30:22 - GraphTrainer - INFO -   ndcg@5: 0.021739
2025-11-22 21:30:22 - GraphTrainer - INFO -   map@5: 0.017886
2025-11-22 21:30:22 - GraphTrainer - INFO -   mrr@5: 0.018580
2025-11-22 21:30:22 - GraphTrainer - INFO -   precision@10: 0.005390
2025-11-22 21:30:22 - GraphTrainer - INFO -   recall@10: 0.051162
2025-11-22 21:30:22 - GraphTrainer - INFO -   hit_rate@10: 0.053896
2025-11-22 21:30:22 - GraphTrainer - INFO -   ndcg@10: 0.027706
2025-11-22 21:30:22 - GraphTrainer - INFO -   map@10: 0.020279
2025-11-22 21:30:22 - GraphTrainer - INFO -   mrr@10: 0.021135
2025-11-22 21:30:22 - GraphTrainer - INFO -   precision@20: 0.004310
2025-11-22 21:30:22 - GraphTrainer - INFO -   recall@20: 0.081557
2025-11-22 21:30:22 - GraphTrainer - INFO -   hit_rate@20: 0.085575
2025-11-22 21:30:22 - GraphTrainer - INFO -   ndcg@20: 0.035428
2025-11-22 21:30:22 - GraphTrainer - INFO -   map@20: 0.022352
2025-11-22 21:30:22 - GraphTrainer - INFO -   mrr@20: 0.023287
2025-11-22 21:30:22 - GraphTrainer - INFO - 第 126 轮训练完成
2025-11-22 21:30:22 - GraphTrainer - INFO - train_loss: 0.267744
2025-11-22 21:30:22 - GraphTrainer - INFO - precision@5: 0.006850
2025-11-22 21:30:22 - GraphTrainer - INFO - recall@5: 0.032750
2025-11-22 21:30:22 - GraphTrainer - INFO - hit_rate@5: 0.034250
2025-11-22 21:30:22 - GraphTrainer - INFO - ndcg@5: 0.021739
2025-11-22 21:30:22 - GraphTrainer - INFO - map@5: 0.017886
2025-11-22 21:30:22 - GraphTrainer - INFO - mrr@5: 0.018580
2025-11-22 21:30:22 - GraphTrainer - INFO - precision@10: 0.005390
2025-11-22 21:30:22 - GraphTrainer - INFO - recall@10: 0.051162
2025-11-22 21:30:22 - GraphTrainer - INFO - hit_rate@10: 0.053896
2025-11-22 21:30:22 - GraphTrainer - INFO - ndcg@10: 0.027706
2025-11-22 21:30:22 - GraphTrainer - INFO - map@10: 0.020279
2025-11-22 21:30:22 - GraphTrainer - INFO - mrr@10: 0.021135
2025-11-22 21:30:22 - GraphTrainer - INFO - precision@20: 0.004310
2025-11-22 21:30:22 - GraphTrainer - INFO - recall@20: 0.081557
2025-11-22 21:30:22 - GraphTrainer - INFO - hit_rate@20: 0.085575
2025-11-22 21:30:22 - GraphTrainer - INFO - ndcg@20: 0.035428
2025-11-22 21:30:22 - GraphTrainer - INFO - map@20: 0.022352
2025-11-22 21:30:22 - GraphTrainer - INFO - mrr@20: 0.023287
2025-11-22 21:30:22 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:30:22 - GraphTrainer - INFO - ============================================================
2025-11-22 21:30:22 - GraphTrainer - INFO - 开始第 127/1000 轮训练
2025-11-22 21:30:22 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2704, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2532, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2763, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2581, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2697, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2383, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2789, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2723, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2791, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2740, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2981, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2423, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2888, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2610, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2855, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3122, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2595, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2593, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2621, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2525, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2594, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2835, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2395, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2671, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2549, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2501, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2698, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2581, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2686, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2701, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2651, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2564, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2763, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2558, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2573, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2573, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2852, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2564, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2754, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2836, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2798, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2665, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2647, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2548, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2728, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2888, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2543, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2493, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2598, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2759, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2729, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2625, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2610, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2636, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2696, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2815, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2882, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2819, device='cuda:0', grad_fn=<AddBackward0>)
The 126 training average loss: 0.26774444328299885
2025-11-22 21:30:33 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:30:33 - GraphTrainer - INFO -   precision@5: 0.006871
2025-11-22 21:30:33 - GraphTrainer - INFO -   recall@5: 0.032975
2025-11-22 21:30:33 - GraphTrainer - INFO -   hit_rate@5: 0.034353
2025-11-22 21:30:33 - GraphTrainer - INFO -   ndcg@5: 0.021816
2025-11-22 21:30:33 - GraphTrainer - INFO -   map@5: 0.017920
2025-11-22 21:30:33 - GraphTrainer - INFO -   mrr@5: 0.018601
2025-11-22 21:30:33 - GraphTrainer - INFO -   precision@10: 0.005410
2025-11-22 21:30:33 - GraphTrainer - INFO -   recall@10: 0.051189
2025-11-22 21:30:33 - GraphTrainer - INFO -   hit_rate@10: 0.054050
2025-11-22 21:30:33 - GraphTrainer - INFO -   ndcg@10: 0.027793
2025-11-22 21:30:33 - GraphTrainer - INFO -   map@10: 0.020343
2025-11-22 21:30:33 - GraphTrainer - INFO -   mrr@10: 0.021217
2025-11-22 21:30:33 - GraphTrainer - INFO -   precision@20: 0.004232
2025-11-22 21:30:33 - GraphTrainer - INFO -   recall@20: 0.080181
2025-11-22 21:30:33 - GraphTrainer - INFO -   hit_rate@20: 0.084083
2025-11-22 21:30:33 - GraphTrainer - INFO -   ndcg@20: 0.035156
2025-11-22 21:30:33 - GraphTrainer - INFO -   map@20: 0.022328
2025-11-22 21:30:33 - GraphTrainer - INFO -   mrr@20: 0.023263
2025-11-22 21:30:33 - GraphTrainer - INFO - 第 127 轮训练完成
2025-11-22 21:30:33 - GraphTrainer - INFO - train_loss: 0.265553
2025-11-22 21:30:33 - GraphTrainer - INFO - precision@5: 0.006871
2025-11-22 21:30:33 - GraphTrainer - INFO - recall@5: 0.032975
2025-11-22 21:30:33 - GraphTrainer - INFO - hit_rate@5: 0.034353
2025-11-22 21:30:33 - GraphTrainer - INFO - ndcg@5: 0.021816
2025-11-22 21:30:33 - GraphTrainer - INFO - map@5: 0.017920
2025-11-22 21:30:33 - GraphTrainer - INFO - mrr@5: 0.018601
2025-11-22 21:30:33 - GraphTrainer - INFO - precision@10: 0.005410
2025-11-22 21:30:33 - GraphTrainer - INFO - recall@10: 0.051189
2025-11-22 21:30:33 - GraphTrainer - INFO - hit_rate@10: 0.054050
2025-11-22 21:30:33 - GraphTrainer - INFO - ndcg@10: 0.027793
2025-11-22 21:30:33 - GraphTrainer - INFO - map@10: 0.020343
2025-11-22 21:30:33 - GraphTrainer - INFO - mrr@10: 0.021217
2025-11-22 21:30:33 - GraphTrainer - INFO - precision@20: 0.004232
2025-11-22 21:30:33 - GraphTrainer - INFO - recall@20: 0.080181
2025-11-22 21:30:33 - GraphTrainer - INFO - hit_rate@20: 0.084083
2025-11-22 21:30:33 - GraphTrainer - INFO - ndcg@20: 0.035156
2025-11-22 21:30:33 - GraphTrainer - INFO - map@20: 0.022328
2025-11-22 21:30:33 - GraphTrainer - INFO - mrr@20: 0.023263
2025-11-22 21:30:33 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:30:33 - GraphTrainer - INFO - ============================================================
2025-11-22 21:30:33 - GraphTrainer - INFO - 开始第 128/1000 轮训练
2025-11-22 21:30:33 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2506, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2680, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2635, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2417, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2644, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2561, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2437, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2448, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2861, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2663, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2703, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2889, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2656, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2685, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2874, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2778, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2675, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2616, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2903, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2563, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2556, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2766, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2704, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2796, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2761, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2401, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2553, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2915, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2678, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2559, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2599, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2534, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2520, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2819, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2582, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2644, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2643, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2705, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2657, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3006, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2582, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2629, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2547, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2533, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2745, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2644, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2483, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2487, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2781, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2491, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2596, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2847, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2747, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2663, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2738, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2713, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2557, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2645, device='cuda:0', grad_fn=<AddBackward0>)
The 127 training average loss: 0.26555301326102226
2025-11-22 21:30:45 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:30:45 - GraphTrainer - INFO -   precision@5: 0.006932
2025-11-22 21:30:45 - GraphTrainer - INFO -   recall@5: 0.033328
2025-11-22 21:30:45 - GraphTrainer - INFO -   hit_rate@5: 0.034662
2025-11-22 21:30:45 - GraphTrainer - INFO -   ndcg@5: 0.022123
2025-11-22 21:30:45 - GraphTrainer - INFO -   map@5: 0.018240
2025-11-22 21:30:45 - GraphTrainer - INFO -   mrr@5: 0.018859
2025-11-22 21:30:45 - GraphTrainer - INFO -   precision@10: 0.005539
2025-11-22 21:30:45 - GraphTrainer - INFO -   recall@10: 0.052690
2025-11-22 21:30:45 - GraphTrainer - INFO -   hit_rate@10: 0.055336
2025-11-22 21:30:45 - GraphTrainer - INFO -   ndcg@10: 0.028398
2025-11-22 21:30:45 - GraphTrainer - INFO -   map@10: 0.020753
2025-11-22 21:30:45 - GraphTrainer - INFO -   mrr@10: 0.021543
2025-11-22 21:30:45 - GraphTrainer - INFO -   precision@20: 0.004286
2025-11-22 21:30:45 - GraphTrainer - INFO -   recall@20: 0.081077
2025-11-22 21:30:45 - GraphTrainer - INFO -   hit_rate@20: 0.085163
2025-11-22 21:30:45 - GraphTrainer - INFO -   ndcg@20: 0.035589
2025-11-22 21:30:45 - GraphTrainer - INFO -   map@20: 0.022665
2025-11-22 21:30:45 - GraphTrainer - INFO -   mrr@20: 0.023545
2025-11-22 21:30:45 - GraphTrainer - INFO - 第 128 轮训练完成
2025-11-22 21:30:45 - GraphTrainer - INFO - train_loss: 0.266867
2025-11-22 21:30:45 - GraphTrainer - INFO - precision@5: 0.006932
2025-11-22 21:30:45 - GraphTrainer - INFO - recall@5: 0.033328
2025-11-22 21:30:45 - GraphTrainer - INFO - hit_rate@5: 0.034662
2025-11-22 21:30:45 - GraphTrainer - INFO - ndcg@5: 0.022123
2025-11-22 21:30:45 - GraphTrainer - INFO - map@5: 0.018240
2025-11-22 21:30:45 - GraphTrainer - INFO - mrr@5: 0.018859
2025-11-22 21:30:45 - GraphTrainer - INFO - precision@10: 0.005539
2025-11-22 21:30:45 - GraphTrainer - INFO - recall@10: 0.052690
2025-11-22 21:30:45 - GraphTrainer - INFO - hit_rate@10: 0.055336
2025-11-22 21:30:45 - GraphTrainer - INFO - ndcg@10: 0.028398
2025-11-22 21:30:45 - GraphTrainer - INFO - map@10: 0.020753
2025-11-22 21:30:45 - GraphTrainer - INFO - mrr@10: 0.021543
2025-11-22 21:30:45 - GraphTrainer - INFO - precision@20: 0.004286
2025-11-22 21:30:45 - GraphTrainer - INFO - recall@20: 0.081077
2025-11-22 21:30:45 - GraphTrainer - INFO - hit_rate@20: 0.085163
2025-11-22 21:30:45 - GraphTrainer - INFO - ndcg@20: 0.035589
2025-11-22 21:30:45 - GraphTrainer - INFO - map@20: 0.022665
2025-11-22 21:30:45 - GraphTrainer - INFO - mrr@20: 0.023545
2025-11-22 21:30:45 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:30:45 - GraphTrainer - INFO - ============================================================
2025-11-22 21:30:45 - GraphTrainer - INFO - 开始第 129/1000 轮训练
2025-11-22 21:30:45 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2726, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2629, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2602, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2482, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2548, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2876, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2469, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2722, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2675, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2622, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2563, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2409, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2852, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2635, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2663, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2700, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2709, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2632, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2667, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2616, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2693, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2885, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2683, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2704, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2699, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2660, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2561, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2572, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2693, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2780, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2608, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2810, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2480, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2805, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2778, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2701, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2602, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2712, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2943, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2618, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2829, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2627, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2691, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2639, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2693, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2745, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2754, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2656, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2419, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2574, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2680, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2568, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2828, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2699, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2919, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2452, device='cuda:0', grad_fn=<AddBackward0>)
The 128 training average loss: 0.26686674099544
2025-11-22 21:30:56 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:30:56 - GraphTrainer - INFO -   precision@5: 0.006963
2025-11-22 21:30:56 - GraphTrainer - INFO -   recall@5: 0.033243
2025-11-22 21:30:56 - GraphTrainer - INFO -   hit_rate@5: 0.034816
2025-11-22 21:30:56 - GraphTrainer - INFO -   ndcg@5: 0.022422
2025-11-22 21:30:56 - GraphTrainer - INFO -   map@5: 0.018608
2025-11-22 21:30:56 - GraphTrainer - INFO -   mrr@5: 0.019385
2025-11-22 21:30:56 - GraphTrainer - INFO -   precision@10: 0.005395
2025-11-22 21:30:56 - GraphTrainer - INFO -   recall@10: 0.050955
2025-11-22 21:30:56 - GraphTrainer - INFO -   hit_rate@10: 0.053844
2025-11-22 21:30:56 - GraphTrainer - INFO -   ndcg@10: 0.028177
2025-11-22 21:30:56 - GraphTrainer - INFO -   map@10: 0.020915
2025-11-22 21:30:56 - GraphTrainer - INFO -   mrr@10: 0.021858
2025-11-22 21:30:56 - GraphTrainer - INFO -   precision@20: 0.004348
2025-11-22 21:30:56 - GraphTrainer - INFO -   recall@20: 0.082252
2025-11-22 21:30:56 - GraphTrainer - INFO -   hit_rate@20: 0.086500
2025-11-22 21:30:56 - GraphTrainer - INFO -   ndcg@20: 0.036113
2025-11-22 21:30:56 - GraphTrainer - INFO -   map@20: 0.023042
2025-11-22 21:30:56 - GraphTrainer - INFO -   mrr@20: 0.024070
2025-11-22 21:30:56 - GraphTrainer - INFO - 第 129 轮训练完成
2025-11-22 21:30:56 - GraphTrainer - INFO - train_loss: 0.266452
2025-11-22 21:30:56 - GraphTrainer - INFO - precision@5: 0.006963
2025-11-22 21:30:56 - GraphTrainer - INFO - recall@5: 0.033243
2025-11-22 21:30:56 - GraphTrainer - INFO - hit_rate@5: 0.034816
2025-11-22 21:30:56 - GraphTrainer - INFO - ndcg@5: 0.022422
2025-11-22 21:30:56 - GraphTrainer - INFO - map@5: 0.018608
2025-11-22 21:30:56 - GraphTrainer - INFO - mrr@5: 0.019385
2025-11-22 21:30:56 - GraphTrainer - INFO - precision@10: 0.005395
2025-11-22 21:30:56 - GraphTrainer - INFO - recall@10: 0.050955
2025-11-22 21:30:56 - GraphTrainer - INFO - hit_rate@10: 0.053844
2025-11-22 21:30:56 - GraphTrainer - INFO - ndcg@10: 0.028177
2025-11-22 21:30:56 - GraphTrainer - INFO - map@10: 0.020915
2025-11-22 21:30:56 - GraphTrainer - INFO - mrr@10: 0.021858
2025-11-22 21:30:56 - GraphTrainer - INFO - precision@20: 0.004348
2025-11-22 21:30:56 - GraphTrainer - INFO - recall@20: 0.082252
2025-11-22 21:30:56 - GraphTrainer - INFO - hit_rate@20: 0.086500
2025-11-22 21:30:56 - GraphTrainer - INFO - ndcg@20: 0.036113
2025-11-22 21:30:56 - GraphTrainer - INFO - map@20: 0.023042
2025-11-22 21:30:56 - GraphTrainer - INFO - mrr@20: 0.024070
2025-11-22 21:30:56 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:30:56 - GraphTrainer - INFO - ============================================================
2025-11-22 21:30:56 - GraphTrainer - INFO - 开始第 130/1000 轮训练
2025-11-22 21:30:56 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2551, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2705, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2686, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2539, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2678, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2438, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2687, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2551, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2779, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2503, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2889, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2940, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2625, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2717, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2884, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2588, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2635, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2661, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2655, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2620, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2580, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2683, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2677, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2630, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2925, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2473, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2632, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2587, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2779, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2781, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2548, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2609, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2761, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2550, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2696, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2518, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2899, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2549, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2751, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2646, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2747, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2719, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2916, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2806, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2704, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2629, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2592, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2566, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2530, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2680, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2736, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2635, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2683, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2385, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2948, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2515, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2598, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2549, device='cuda:0', grad_fn=<AddBackward0>)
The 129 training average loss: 0.26645160415049257
2025-11-22 21:31:07 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:31:07 - GraphTrainer - INFO -   precision@5: 0.006850
2025-11-22 21:31:07 - GraphTrainer - INFO -   recall@5: 0.032832
2025-11-22 21:31:07 - GraphTrainer - INFO -   hit_rate@5: 0.034250
2025-11-22 21:31:07 - GraphTrainer - INFO -   ndcg@5: 0.021832
2025-11-22 21:31:07 - GraphTrainer - INFO -   map@5: 0.017982
2025-11-22 21:31:07 - GraphTrainer - INFO -   mrr@5: 0.018693
2025-11-22 21:31:07 - GraphTrainer - INFO -   precision@10: 0.005333
2025-11-22 21:31:07 - GraphTrainer - INFO -   recall@10: 0.050385
2025-11-22 21:31:07 - GraphTrainer - INFO -   hit_rate@10: 0.053227
2025-11-22 21:31:07 - GraphTrainer - INFO -   ndcg@10: 0.027555
2025-11-22 21:31:07 - GraphTrainer - INFO -   map@10: 0.020276
2025-11-22 21:31:07 - GraphTrainer - INFO -   mrr@10: 0.021176
2025-11-22 21:31:07 - GraphTrainer - INFO -   precision@20: 0.004297
2025-11-22 21:31:07 - GraphTrainer - INFO -   recall@20: 0.081111
2025-11-22 21:31:07 - GraphTrainer - INFO -   hit_rate@20: 0.085472
2025-11-22 21:31:07 - GraphTrainer - INFO -   ndcg@20: 0.035381
2025-11-22 21:31:07 - GraphTrainer - INFO -   map@20: 0.022385
2025-11-22 21:31:07 - GraphTrainer - INFO -   mrr@20: 0.023381
2025-11-22 21:31:07 - GraphTrainer - INFO - 第 130 轮训练完成
2025-11-22 21:31:07 - GraphTrainer - INFO - train_loss: 0.266379
2025-11-22 21:31:07 - GraphTrainer - INFO - precision@5: 0.006850
2025-11-22 21:31:07 - GraphTrainer - INFO - recall@5: 0.032832
2025-11-22 21:31:07 - GraphTrainer - INFO - hit_rate@5: 0.034250
2025-11-22 21:31:07 - GraphTrainer - INFO - ndcg@5: 0.021832
2025-11-22 21:31:07 - GraphTrainer - INFO - map@5: 0.017982
2025-11-22 21:31:07 - GraphTrainer - INFO - mrr@5: 0.018693
2025-11-22 21:31:07 - GraphTrainer - INFO - precision@10: 0.005333
2025-11-22 21:31:07 - GraphTrainer - INFO - recall@10: 0.050385
2025-11-22 21:31:07 - GraphTrainer - INFO - hit_rate@10: 0.053227
2025-11-22 21:31:07 - GraphTrainer - INFO - ndcg@10: 0.027555
2025-11-22 21:31:07 - GraphTrainer - INFO - map@10: 0.020276
2025-11-22 21:31:07 - GraphTrainer - INFO - mrr@10: 0.021176
2025-11-22 21:31:07 - GraphTrainer - INFO - precision@20: 0.004297
2025-11-22 21:31:07 - GraphTrainer - INFO - recall@20: 0.081111
2025-11-22 21:31:07 - GraphTrainer - INFO - hit_rate@20: 0.085472
2025-11-22 21:31:07 - GraphTrainer - INFO - ndcg@20: 0.035381
2025-11-22 21:31:07 - GraphTrainer - INFO - map@20: 0.022385
2025-11-22 21:31:07 - GraphTrainer - INFO - mrr@20: 0.023381
2025-11-22 21:31:07 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:31:07 - GraphTrainer - INFO - 检查点已保存: Epoch 130 -> ./checkpoints/checkpoint_epoch_130.pth
2025-11-22 21:31:07 - GraphTrainer - INFO - ============================================================
2025-11-22 21:31:07 - GraphTrainer - INFO - 开始第 131/1000 轮训练
2025-11-22 21:31:07 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2732, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2754, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2675, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2729, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2680, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2550, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2761, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2708, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2551, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2779, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2747, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2663, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2617, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2700, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2540, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2491, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2517, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2621, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2596, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2732, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2690, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2660, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2656, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2759, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2337, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2557, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2643, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2662, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2728, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2560, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2655, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2754, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2541, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2554, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2683, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2683, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2618, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2638, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2668, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2784, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2869, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2871, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2777, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2693, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2758, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2676, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2736, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2511, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2653, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2720, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2527, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2477, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2535, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2524, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2786, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2649, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3090, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2677, device='cuda:0', grad_fn=<AddBackward0>)
The 130 training average loss: 0.2663790683807998
2025-11-22 21:31:18 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:31:18 - GraphTrainer - INFO -   precision@5: 0.006902
2025-11-22 21:31:18 - GraphTrainer - INFO -   recall@5: 0.033063
2025-11-22 21:31:18 - GraphTrainer - INFO -   hit_rate@5: 0.034508
2025-11-22 21:31:18 - GraphTrainer - INFO -   ndcg@5: 0.022567
2025-11-22 21:31:18 - GraphTrainer - INFO -   map@5: 0.018860
2025-11-22 21:31:18 - GraphTrainer - INFO -   mrr@5: 0.019601
2025-11-22 21:31:18 - GraphTrainer - INFO -   precision@10: 0.005420
2025-11-22 21:31:18 - GraphTrainer - INFO -   recall@10: 0.051373
2025-11-22 21:31:18 - GraphTrainer - INFO -   hit_rate@10: 0.054101
2025-11-22 21:31:18 - GraphTrainer - INFO -   ndcg@10: 0.028527
2025-11-22 21:31:18 - GraphTrainer - INFO -   map@10: 0.021257
2025-11-22 21:31:18 - GraphTrainer - INFO -   mrr@10: 0.022170
2025-11-22 21:31:18 - GraphTrainer - INFO -   precision@20: 0.004307
2025-11-22 21:31:18 - GraphTrainer - INFO -   recall@20: 0.081444
2025-11-22 21:31:18 - GraphTrainer - INFO -   hit_rate@20: 0.085626
2025-11-22 21:31:18 - GraphTrainer - INFO -   ndcg@20: 0.036139
2025-11-22 21:31:18 - GraphTrainer - INFO -   map@20: 0.023281
2025-11-22 21:31:18 - GraphTrainer - INFO -   mrr@20: 0.024290
2025-11-22 21:31:18 - GraphTrainer - INFO - 第 131 轮训练完成
2025-11-22 21:31:18 - GraphTrainer - INFO - train_loss: 0.265025
2025-11-22 21:31:18 - GraphTrainer - INFO - precision@5: 0.006902
2025-11-22 21:31:18 - GraphTrainer - INFO - recall@5: 0.033063
2025-11-22 21:31:18 - GraphTrainer - INFO - hit_rate@5: 0.034508
2025-11-22 21:31:18 - GraphTrainer - INFO - ndcg@5: 0.022567
2025-11-22 21:31:18 - GraphTrainer - INFO - map@5: 0.018860
2025-11-22 21:31:18 - GraphTrainer - INFO - mrr@5: 0.019601
2025-11-22 21:31:18 - GraphTrainer - INFO - precision@10: 0.005420
2025-11-22 21:31:18 - GraphTrainer - INFO - recall@10: 0.051373
2025-11-22 21:31:18 - GraphTrainer - INFO - hit_rate@10: 0.054101
2025-11-22 21:31:18 - GraphTrainer - INFO - ndcg@10: 0.028527
2025-11-22 21:31:18 - GraphTrainer - INFO - map@10: 0.021257
2025-11-22 21:31:18 - GraphTrainer - INFO - mrr@10: 0.022170
2025-11-22 21:31:18 - GraphTrainer - INFO - precision@20: 0.004307
2025-11-22 21:31:18 - GraphTrainer - INFO - recall@20: 0.081444
2025-11-22 21:31:18 - GraphTrainer - INFO - hit_rate@20: 0.085626
2025-11-22 21:31:18 - GraphTrainer - INFO - ndcg@20: 0.036139
2025-11-22 21:31:18 - GraphTrainer - INFO - map@20: 0.023281
2025-11-22 21:31:18 - GraphTrainer - INFO - mrr@20: 0.024290
2025-11-22 21:31:18 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:31:18 - GraphTrainer - INFO - ============================================================
2025-11-22 21:31:18 - GraphTrainer - INFO - 开始第 132/1000 轮训练
2025-11-22 21:31:18 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2751, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2487, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2579, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2603, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2837, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2674, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2799, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2634, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2640, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2607, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2698, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2566, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2668, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2683, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2361, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2955, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2642, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2632, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2779, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2630, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2950, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2630, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2764, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2454, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2656, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2480, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2574, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2604, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2817, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2796, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2492, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2609, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2601, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2558, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2713, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2489, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2716, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2548, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2820, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2794, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2476, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2745, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2756, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2712, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2582, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2657, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2595, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2504, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2556, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2514, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2473, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2687, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2699, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2602, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2858, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2694, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2598, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2717, device='cuda:0', grad_fn=<AddBackward0>)
The 131 training average loss: 0.26502505253101216
2025-11-22 21:31:29 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:31:29 - GraphTrainer - INFO -   precision@5: 0.006922
2025-11-22 21:31:29 - GraphTrainer - INFO -   recall@5: 0.033221
2025-11-22 21:31:29 - GraphTrainer - INFO -   hit_rate@5: 0.034610
2025-11-22 21:31:29 - GraphTrainer - INFO -   ndcg@5: 0.022460
2025-11-22 21:31:29 - GraphTrainer - INFO -   map@5: 0.018691
2025-11-22 21:31:29 - GraphTrainer - INFO -   mrr@5: 0.019376
2025-11-22 21:31:29 - GraphTrainer - INFO -   precision@10: 0.005379
2025-11-22 21:31:29 - GraphTrainer - INFO -   recall@10: 0.050979
2025-11-22 21:31:29 - GraphTrainer - INFO -   hit_rate@10: 0.053690
2025-11-22 21:31:29 - GraphTrainer - INFO -   ndcg@10: 0.028260
2025-11-22 21:31:29 - GraphTrainer - INFO -   map@10: 0.021032
2025-11-22 21:31:29 - GraphTrainer - INFO -   mrr@10: 0.021890
2025-11-22 21:31:29 - GraphTrainer - INFO -   precision@20: 0.004322
2025-11-22 21:31:29 - GraphTrainer - INFO -   recall@20: 0.081698
2025-11-22 21:31:29 - GraphTrainer - INFO -   hit_rate@20: 0.086038
2025-11-22 21:31:29 - GraphTrainer - INFO -   ndcg@20: 0.036079
2025-11-22 21:31:29 - GraphTrainer - INFO -   map@20: 0.023132
2025-11-22 21:31:29 - GraphTrainer - INFO -   mrr@20: 0.024096
2025-11-22 21:31:29 - GraphTrainer - INFO - 第 132 轮训练完成
2025-11-22 21:31:29 - GraphTrainer - INFO - train_loss: 0.266070
2025-11-22 21:31:29 - GraphTrainer - INFO - precision@5: 0.006922
2025-11-22 21:31:29 - GraphTrainer - INFO - recall@5: 0.033221
2025-11-22 21:31:29 - GraphTrainer - INFO - hit_rate@5: 0.034610
2025-11-22 21:31:29 - GraphTrainer - INFO - ndcg@5: 0.022460
2025-11-22 21:31:29 - GraphTrainer - INFO - map@5: 0.018691
2025-11-22 21:31:29 - GraphTrainer - INFO - mrr@5: 0.019376
2025-11-22 21:31:29 - GraphTrainer - INFO - precision@10: 0.005379
2025-11-22 21:31:29 - GraphTrainer - INFO - recall@10: 0.050979
2025-11-22 21:31:29 - GraphTrainer - INFO - hit_rate@10: 0.053690
2025-11-22 21:31:29 - GraphTrainer - INFO - ndcg@10: 0.028260
2025-11-22 21:31:29 - GraphTrainer - INFO - map@10: 0.021032
2025-11-22 21:31:29 - GraphTrainer - INFO - mrr@10: 0.021890
2025-11-22 21:31:29 - GraphTrainer - INFO - precision@20: 0.004322
2025-11-22 21:31:29 - GraphTrainer - INFO - recall@20: 0.081698
2025-11-22 21:31:29 - GraphTrainer - INFO - hit_rate@20: 0.086038
2025-11-22 21:31:29 - GraphTrainer - INFO - ndcg@20: 0.036079
2025-11-22 21:31:29 - GraphTrainer - INFO - map@20: 0.023132
2025-11-22 21:31:29 - GraphTrainer - INFO - mrr@20: 0.024096
2025-11-22 21:31:29 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:31:29 - GraphTrainer - INFO - ============================================================
2025-11-22 21:31:29 - GraphTrainer - INFO - 开始第 133/1000 轮训练
2025-11-22 21:31:29 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2664, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2837, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2625, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2679, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2528, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2532, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2504, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2663, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2608, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2568, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2595, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2624, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2941, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2564, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2672, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2724, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2799, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2696, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2849, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2804, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2476, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2520, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2619, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2531, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2784, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2510, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2771, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2877, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2806, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2632, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2790, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2739, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2650, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2754, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2563, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2598, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2850, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2815, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2647, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2658, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2410, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2391, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2608, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2649, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2773, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2588, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2635, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2690, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2764, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2530, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2626, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2650, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2670, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2654, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2731, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2597, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2555, device='cuda:0', grad_fn=<AddBackward0>)
The 132 training average loss: 0.26607003833713205
2025-11-22 21:31:40 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:31:40 - GraphTrainer - INFO -   precision@5: 0.007015
2025-11-22 21:31:40 - GraphTrainer - INFO -   recall@5: 0.033491
2025-11-22 21:31:40 - GraphTrainer - INFO -   hit_rate@5: 0.035073
2025-11-22 21:31:40 - GraphTrainer - INFO -   ndcg@5: 0.022171
2025-11-22 21:31:40 - GraphTrainer - INFO -   map@5: 0.018208
2025-11-22 21:31:40 - GraphTrainer - INFO -   mrr@5: 0.018927
2025-11-22 21:31:40 - GraphTrainer - INFO -   precision@10: 0.005431
2025-11-22 21:31:40 - GraphTrainer - INFO -   recall@10: 0.051552
2025-11-22 21:31:40 - GraphTrainer - INFO -   hit_rate@10: 0.054204
2025-11-22 21:31:40 - GraphTrainer - INFO -   ndcg@10: 0.028039
2025-11-22 21:31:40 - GraphTrainer - INFO -   map@10: 0.020579
2025-11-22 21:31:40 - GraphTrainer - INFO -   mrr@10: 0.021438
2025-11-22 21:31:40 - GraphTrainer - INFO -   precision@20: 0.004289
2025-11-22 21:31:40 - GraphTrainer - INFO -   recall@20: 0.081026
2025-11-22 21:31:40 - GraphTrainer - INFO -   hit_rate@20: 0.085163
2025-11-22 21:31:40 - GraphTrainer - INFO -   ndcg@20: 0.035529
2025-11-22 21:31:40 - GraphTrainer - INFO -   map@20: 0.022583
2025-11-22 21:31:40 - GraphTrainer - INFO -   mrr@20: 0.023534
2025-11-22 21:31:40 - GraphTrainer - INFO - 第 133 轮训练完成
2025-11-22 21:31:40 - GraphTrainer - INFO - train_loss: 0.260868
2025-11-22 21:31:40 - GraphTrainer - INFO - precision@5: 0.007015
2025-11-22 21:31:40 - GraphTrainer - INFO - recall@5: 0.033491
2025-11-22 21:31:40 - GraphTrainer - INFO - hit_rate@5: 0.035073
2025-11-22 21:31:40 - GraphTrainer - INFO - ndcg@5: 0.022171
2025-11-22 21:31:40 - GraphTrainer - INFO - map@5: 0.018208
2025-11-22 21:31:40 - GraphTrainer - INFO - mrr@5: 0.018927
2025-11-22 21:31:40 - GraphTrainer - INFO - precision@10: 0.005431
2025-11-22 21:31:40 - GraphTrainer - INFO - recall@10: 0.051552
2025-11-22 21:31:40 - GraphTrainer - INFO - hit_rate@10: 0.054204
2025-11-22 21:31:40 - GraphTrainer - INFO - ndcg@10: 0.028039
2025-11-22 21:31:40 - GraphTrainer - INFO - map@10: 0.020579
2025-11-22 21:31:40 - GraphTrainer - INFO - mrr@10: 0.021438
2025-11-22 21:31:40 - GraphTrainer - INFO - precision@20: 0.004289
2025-11-22 21:31:40 - GraphTrainer - INFO - recall@20: 0.081026
2025-11-22 21:31:40 - GraphTrainer - INFO - hit_rate@20: 0.085163
2025-11-22 21:31:40 - GraphTrainer - INFO - ndcg@20: 0.035529
2025-11-22 21:31:40 - GraphTrainer - INFO - map@20: 0.022583
2025-11-22 21:31:40 - GraphTrainer - INFO - mrr@20: 0.023534
2025-11-22 21:31:40 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:31:40 - GraphTrainer - INFO - ============================================================
2025-11-22 21:31:40 - GraphTrainer - INFO - 开始第 134/1000 轮训练
2025-11-22 21:31:40 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2745, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2828, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2512, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2673, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2519, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2558, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2466, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2573, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2714, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2495, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2557, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2579, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2779, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2561, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2538, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2641, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2807, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2745, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2463, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2499, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2602, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2633, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2566, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2409, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2530, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2583, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2578, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2399, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2727, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2565, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2562, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2781, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2617, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2722, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2525, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2725, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2748, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2397, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2459, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2495, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2590, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2585, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2685, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2656, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2678, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2714, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2661, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2611, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2432, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2653, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2725, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2714, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2459, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2659, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2617, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2543, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2643, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2803, device='cuda:0', grad_fn=<AddBackward0>)
The 133 training average loss: 0.26086799415021106
2025-11-22 21:31:52 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:31:52 - GraphTrainer - INFO -   precision@5: 0.007076
2025-11-22 21:31:52 - GraphTrainer - INFO -   recall@5: 0.033755
2025-11-22 21:31:52 - GraphTrainer - INFO -   hit_rate@5: 0.035382
2025-11-22 21:31:52 - GraphTrainer - INFO -   ndcg@5: 0.022279
2025-11-22 21:31:52 - GraphTrainer - INFO -   map@5: 0.018264
2025-11-22 21:31:52 - GraphTrainer - INFO -   mrr@5: 0.018961
2025-11-22 21:31:52 - GraphTrainer - INFO -   precision@10: 0.005292
2025-11-22 21:31:52 - GraphTrainer - INFO -   recall@10: 0.050346
2025-11-22 21:31:52 - GraphTrainer - INFO -   hit_rate@10: 0.052867
2025-11-22 21:31:52 - GraphTrainer - INFO -   ndcg@10: 0.027653
2025-11-22 21:31:52 - GraphTrainer - INFO -   map@10: 0.020431
2025-11-22 21:31:52 - GraphTrainer - INFO -   mrr@10: 0.021251
2025-11-22 21:31:52 - GraphTrainer - INFO -   precision@20: 0.004250
2025-11-22 21:31:52 - GraphTrainer - INFO -   recall@20: 0.080253
2025-11-22 21:31:52 - GraphTrainer - INFO -   hit_rate@20: 0.084340
2025-11-22 21:31:52 - GraphTrainer - INFO -   ndcg@20: 0.035256
2025-11-22 21:31:52 - GraphTrainer - INFO -   map@20: 0.022460
2025-11-22 21:31:52 - GraphTrainer - INFO -   mrr@20: 0.023379
2025-11-22 21:31:52 - GraphTrainer - INFO - 第 134 轮训练完成
2025-11-22 21:31:52 - GraphTrainer - INFO - train_loss: 0.262695
2025-11-22 21:31:52 - GraphTrainer - INFO - precision@5: 0.007076
2025-11-22 21:31:52 - GraphTrainer - INFO - recall@5: 0.033755
2025-11-22 21:31:52 - GraphTrainer - INFO - hit_rate@5: 0.035382
2025-11-22 21:31:52 - GraphTrainer - INFO - ndcg@5: 0.022279
2025-11-22 21:31:52 - GraphTrainer - INFO - map@5: 0.018264
2025-11-22 21:31:52 - GraphTrainer - INFO - mrr@5: 0.018961
2025-11-22 21:31:52 - GraphTrainer - INFO - precision@10: 0.005292
2025-11-22 21:31:52 - GraphTrainer - INFO - recall@10: 0.050346
2025-11-22 21:31:52 - GraphTrainer - INFO - hit_rate@10: 0.052867
2025-11-22 21:31:52 - GraphTrainer - INFO - ndcg@10: 0.027653
2025-11-22 21:31:52 - GraphTrainer - INFO - map@10: 0.020431
2025-11-22 21:31:52 - GraphTrainer - INFO - mrr@10: 0.021251
2025-11-22 21:31:52 - GraphTrainer - INFO - precision@20: 0.004250
2025-11-22 21:31:52 - GraphTrainer - INFO - recall@20: 0.080253
2025-11-22 21:31:52 - GraphTrainer - INFO - hit_rate@20: 0.084340
2025-11-22 21:31:52 - GraphTrainer - INFO - ndcg@20: 0.035256
2025-11-22 21:31:52 - GraphTrainer - INFO - map@20: 0.022460
2025-11-22 21:31:52 - GraphTrainer - INFO - mrr@20: 0.023379
2025-11-22 21:31:52 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:31:52 - GraphTrainer - INFO - ============================================================
2025-11-22 21:31:52 - GraphTrainer - INFO - 开始第 135/1000 轮训练
2025-11-22 21:31:52 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2729, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2587, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2462, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2674, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2652, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2578, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2538, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2610, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2646, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2479, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2690, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2580, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2460, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2579, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2738, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2893, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2699, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2663, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2498, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2584, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2727, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2463, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2712, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2738, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2447, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2963, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2995, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2780, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2551, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2575, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2588, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2661, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2602, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2622, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2645, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2595, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2632, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2644, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2630, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2365, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2703, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2625, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2488, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2594, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2718, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2528, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2817, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2636, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2630, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2816, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2394, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2533, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2821, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2532, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2564, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2457, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2655, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2580, device='cuda:0', grad_fn=<AddBackward0>)
The 134 training average loss: 0.26269490631489917
2025-11-22 21:32:03 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:32:03 - GraphTrainer - INFO -   precision@5: 0.006830
2025-11-22 21:32:03 - GraphTrainer - INFO -   recall@5: 0.032551
2025-11-22 21:32:03 - GraphTrainer - INFO -   hit_rate@5: 0.034148
2025-11-22 21:32:03 - GraphTrainer - INFO -   ndcg@5: 0.021622
2025-11-22 21:32:03 - GraphTrainer - INFO -   map@5: 0.017792
2025-11-22 21:32:03 - GraphTrainer - INFO -   mrr@5: 0.018479
2025-11-22 21:32:03 - GraphTrainer - INFO -   precision@10: 0.005348
2025-11-22 21:32:03 - GraphTrainer - INFO -   recall@10: 0.050752
2025-11-22 21:32:03 - GraphTrainer - INFO -   hit_rate@10: 0.053433
2025-11-22 21:32:03 - GraphTrainer - INFO -   ndcg@10: 0.027557
2025-11-22 21:32:03 - GraphTrainer - INFO -   map@10: 0.020204
2025-11-22 21:32:03 - GraphTrainer - INFO -   mrr@10: 0.021027
2025-11-22 21:32:03 - GraphTrainer - INFO -   precision@20: 0.004245
2025-11-22 21:32:03 - GraphTrainer - INFO -   recall@20: 0.080274
2025-11-22 21:32:03 - GraphTrainer - INFO -   hit_rate@20: 0.084340
2025-11-22 21:32:03 - GraphTrainer - INFO -   ndcg@20: 0.035079
2025-11-22 21:32:03 - GraphTrainer - INFO -   map@20: 0.022229
2025-11-22 21:32:03 - GraphTrainer - INFO -   mrr@20: 0.023136
2025-11-22 21:32:03 - GraphTrainer - INFO - 第 135 轮训练完成
2025-11-22 21:32:03 - GraphTrainer - INFO - train_loss: 0.264678
2025-11-22 21:32:03 - GraphTrainer - INFO - precision@5: 0.006830
2025-11-22 21:32:03 - GraphTrainer - INFO - recall@5: 0.032551
2025-11-22 21:32:03 - GraphTrainer - INFO - hit_rate@5: 0.034148
2025-11-22 21:32:03 - GraphTrainer - INFO - ndcg@5: 0.021622
2025-11-22 21:32:03 - GraphTrainer - INFO - map@5: 0.017792
2025-11-22 21:32:03 - GraphTrainer - INFO - mrr@5: 0.018479
2025-11-22 21:32:03 - GraphTrainer - INFO - precision@10: 0.005348
2025-11-22 21:32:03 - GraphTrainer - INFO - recall@10: 0.050752
2025-11-22 21:32:03 - GraphTrainer - INFO - hit_rate@10: 0.053433
2025-11-22 21:32:03 - GraphTrainer - INFO - ndcg@10: 0.027557
2025-11-22 21:32:03 - GraphTrainer - INFO - map@10: 0.020204
2025-11-22 21:32:03 - GraphTrainer - INFO - mrr@10: 0.021027
2025-11-22 21:32:03 - GraphTrainer - INFO - precision@20: 0.004245
2025-11-22 21:32:03 - GraphTrainer - INFO - recall@20: 0.080274
2025-11-22 21:32:03 - GraphTrainer - INFO - hit_rate@20: 0.084340
2025-11-22 21:32:03 - GraphTrainer - INFO - ndcg@20: 0.035079
2025-11-22 21:32:03 - GraphTrainer - INFO - map@20: 0.022229
2025-11-22 21:32:03 - GraphTrainer - INFO - mrr@20: 0.023136
2025-11-22 21:32:03 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:32:03 - GraphTrainer - INFO - ============================================================
2025-11-22 21:32:03 - GraphTrainer - INFO - 开始第 136/1000 轮训练
2025-11-22 21:32:03 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2938, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2675, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2554, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2673, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2425, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2592, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2818, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2435, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2563, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2919, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2600, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2498, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2606, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2599, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2688, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2795, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2843, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2605, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2529, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2516, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2777, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2573, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2622, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2522, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2646, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2563, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2644, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2695, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2601, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2642, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2669, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2565, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2716, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2657, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2641, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2779, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2592, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2575, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2573, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2529, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2475, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2736, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2744, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2601, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2698, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2803, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2498, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2711, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2560, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2812, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2668, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2602, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2594, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2687, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2641, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2796, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2695, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2743, device='cuda:0', grad_fn=<AddBackward0>)
The 135 training average loss: 0.26467803351838015
2025-11-22 21:32:14 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:32:14 - GraphTrainer - INFO -   precision@5: 0.006922
2025-11-22 21:32:14 - GraphTrainer - INFO -   recall@5: 0.033049
2025-11-22 21:32:14 - GraphTrainer - INFO -   hit_rate@5: 0.034559
2025-11-22 21:32:14 - GraphTrainer - INFO -   ndcg@5: 0.022335
2025-11-22 21:32:14 - GraphTrainer - INFO -   map@5: 0.018574
2025-11-22 21:32:14 - GraphTrainer - INFO -   mrr@5: 0.019276
2025-11-22 21:32:14 - GraphTrainer - INFO -   precision@10: 0.005487
2025-11-22 21:32:14 - GraphTrainer - INFO -   recall@10: 0.051973
2025-11-22 21:32:14 - GraphTrainer - INFO -   hit_rate@10: 0.054770
2025-11-22 21:32:14 - GraphTrainer - INFO -   ndcg@10: 0.028504
2025-11-22 21:32:14 - GraphTrainer - INFO -   map@10: 0.021070
2025-11-22 21:32:14 - GraphTrainer - INFO -   mrr@10: 0.021936
2025-11-22 21:32:14 - GraphTrainer - INFO -   precision@20: 0.004384
2025-11-22 21:32:14 - GraphTrainer - INFO -   recall@20: 0.082774
2025-11-22 21:32:14 - GraphTrainer - INFO -   hit_rate@20: 0.087169
2025-11-22 21:32:14 - GraphTrainer - INFO -   ndcg@20: 0.036310
2025-11-22 21:32:14 - GraphTrainer - INFO -   map@20: 0.023147
2025-11-22 21:32:14 - GraphTrainer - INFO -   mrr@20: 0.024112
2025-11-22 21:32:14 - GraphTrainer - INFO - 第 136 轮训练完成
2025-11-22 21:32:14 - GraphTrainer - INFO - train_loss: 0.264460
2025-11-22 21:32:14 - GraphTrainer - INFO - precision@5: 0.006922
2025-11-22 21:32:14 - GraphTrainer - INFO - recall@5: 0.033049
2025-11-22 21:32:14 - GraphTrainer - INFO - hit_rate@5: 0.034559
2025-11-22 21:32:14 - GraphTrainer - INFO - ndcg@5: 0.022335
2025-11-22 21:32:14 - GraphTrainer - INFO - map@5: 0.018574
2025-11-22 21:32:14 - GraphTrainer - INFO - mrr@5: 0.019276
2025-11-22 21:32:14 - GraphTrainer - INFO - precision@10: 0.005487
2025-11-22 21:32:14 - GraphTrainer - INFO - recall@10: 0.051973
2025-11-22 21:32:14 - GraphTrainer - INFO - hit_rate@10: 0.054770
2025-11-22 21:32:14 - GraphTrainer - INFO - ndcg@10: 0.028504
2025-11-22 21:32:14 - GraphTrainer - INFO - map@10: 0.021070
2025-11-22 21:32:14 - GraphTrainer - INFO - mrr@10: 0.021936
2025-11-22 21:32:14 - GraphTrainer - INFO - precision@20: 0.004384
2025-11-22 21:32:14 - GraphTrainer - INFO - recall@20: 0.082774
2025-11-22 21:32:14 - GraphTrainer - INFO - hit_rate@20: 0.087169
2025-11-22 21:32:14 - GraphTrainer - INFO - ndcg@20: 0.036310
2025-11-22 21:32:14 - GraphTrainer - INFO - map@20: 0.023147
2025-11-22 21:32:14 - GraphTrainer - INFO - mrr@20: 0.024112
2025-11-22 21:32:14 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:32:14 - GraphTrainer - INFO - ============================================================
2025-11-22 21:32:14 - GraphTrainer - INFO - 开始第 137/1000 轮训练
2025-11-22 21:32:14 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2486, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2715, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2537, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2597, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2600, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2528, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2698, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2658, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2610, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2756, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2608, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2338, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2810, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2711, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2500, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2678, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2562, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2646, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2355, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2594, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2688, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2783, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2664, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2747, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2292, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2552, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2593, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2673, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2769, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2804, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2590, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2703, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2533, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2759, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2920, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2632, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2686, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2891, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2688, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2708, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2754, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2629, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2892, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2684, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2385, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2530, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2522, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2641, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2474, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2721, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2736, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2404, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2657, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2767, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2895, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2714, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2737, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2581, device='cuda:0', grad_fn=<AddBackward0>)
The 136 training average loss: 0.2644599958740432
2025-11-22 21:32:25 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:32:25 - GraphTrainer - INFO -   precision@5: 0.006788
2025-11-22 21:32:25 - GraphTrainer - INFO -   recall@5: 0.032469
2025-11-22 21:32:25 - GraphTrainer - INFO -   hit_rate@5: 0.033942
2025-11-22 21:32:25 - GraphTrainer - INFO -   ndcg@5: 0.022175
2025-11-22 21:32:25 - GraphTrainer - INFO -   map@5: 0.018543
2025-11-22 21:32:25 - GraphTrainer - INFO -   mrr@5: 0.019271
2025-11-22 21:32:25 - GraphTrainer - INFO -   precision@10: 0.005492
2025-11-22 21:32:25 - GraphTrainer - INFO -   recall@10: 0.052019
2025-11-22 21:32:25 - GraphTrainer - INFO -   hit_rate@10: 0.054873
2025-11-22 21:32:25 - GraphTrainer - INFO -   ndcg@10: 0.028547
2025-11-22 21:32:25 - GraphTrainer - INFO -   map@10: 0.021115
2025-11-22 21:32:25 - GraphTrainer - INFO -   mrr@10: 0.022022
2025-11-22 21:32:25 - GraphTrainer - INFO -   precision@20: 0.004299
2025-11-22 21:32:25 - GraphTrainer - INFO -   recall@20: 0.081284
2025-11-22 21:32:25 - GraphTrainer - INFO -   hit_rate@20: 0.085472
2025-11-22 21:32:25 - GraphTrainer - INFO -   ndcg@20: 0.035969
2025-11-22 21:32:25 - GraphTrainer - INFO -   map@20: 0.023100
2025-11-22 21:32:25 - GraphTrainer - INFO -   mrr@20: 0.024087
2025-11-22 21:32:25 - GraphTrainer - INFO - 第 137 轮训练完成
2025-11-22 21:32:25 - GraphTrainer - INFO - train_loss: 0.262911
2025-11-22 21:32:25 - GraphTrainer - INFO - precision@5: 0.006788
2025-11-22 21:32:25 - GraphTrainer - INFO - recall@5: 0.032469
2025-11-22 21:32:25 - GraphTrainer - INFO - hit_rate@5: 0.033942
2025-11-22 21:32:25 - GraphTrainer - INFO - ndcg@5: 0.022175
2025-11-22 21:32:25 - GraphTrainer - INFO - map@5: 0.018543
2025-11-22 21:32:25 - GraphTrainer - INFO - mrr@5: 0.019271
2025-11-22 21:32:25 - GraphTrainer - INFO - precision@10: 0.005492
2025-11-22 21:32:25 - GraphTrainer - INFO - recall@10: 0.052019
2025-11-22 21:32:25 - GraphTrainer - INFO - hit_rate@10: 0.054873
2025-11-22 21:32:25 - GraphTrainer - INFO - ndcg@10: 0.028547
2025-11-22 21:32:25 - GraphTrainer - INFO - map@10: 0.021115
2025-11-22 21:32:25 - GraphTrainer - INFO - mrr@10: 0.022022
2025-11-22 21:32:25 - GraphTrainer - INFO - precision@20: 0.004299
2025-11-22 21:32:25 - GraphTrainer - INFO - recall@20: 0.081284
2025-11-22 21:32:25 - GraphTrainer - INFO - hit_rate@20: 0.085472
2025-11-22 21:32:25 - GraphTrainer - INFO - ndcg@20: 0.035969
2025-11-22 21:32:25 - GraphTrainer - INFO - map@20: 0.023100
2025-11-22 21:32:25 - GraphTrainer - INFO - mrr@20: 0.024087
2025-11-22 21:32:25 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:32:25 - GraphTrainer - INFO - ============================================================
2025-11-22 21:32:25 - GraphTrainer - INFO - 开始第 138/1000 轮训练
2025-11-22 21:32:25 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2600, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2641, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2701, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2638, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2528, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2731, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2644, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2600, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2748, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2646, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2602, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2790, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2715, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2396, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2502, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2564, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2610, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2441, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2875, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2656, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2535, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2555, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2565, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2598, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2586, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2532, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2807, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2496, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2791, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2623, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2865, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2264, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2865, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2410, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2572, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2920, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2674, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2452, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2779, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2582, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2686, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2549, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2651, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2654, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2442, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2540, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2697, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2699, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2574, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2659, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2772, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2585, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2589, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2537, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2639, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2813, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2691, device='cuda:0', grad_fn=<AddBackward0>)
The 137 training average loss: 0.2629110574208457
2025-11-22 21:32:36 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:32:36 - GraphTrainer - INFO -   precision@5: 0.006799
2025-11-22 21:32:36 - GraphTrainer - INFO -   recall@5: 0.032507
2025-11-22 21:32:36 - GraphTrainer - INFO -   hit_rate@5: 0.033993
2025-11-22 21:32:36 - GraphTrainer - INFO -   ndcg@5: 0.022023
2025-11-22 21:32:36 - GraphTrainer - INFO -   map@5: 0.018328
2025-11-22 21:32:36 - GraphTrainer - INFO -   mrr@5: 0.019033
2025-11-22 21:32:36 - GraphTrainer - INFO -   precision@10: 0.005426
2025-11-22 21:32:36 - GraphTrainer - INFO -   recall@10: 0.051542
2025-11-22 21:32:36 - GraphTrainer - INFO -   hit_rate@10: 0.054204
2025-11-22 21:32:36 - GraphTrainer - INFO -   ndcg@10: 0.028237
2025-11-22 21:32:36 - GraphTrainer - INFO -   map@10: 0.020853
2025-11-22 21:32:36 - GraphTrainer - INFO -   mrr@10: 0.021710
2025-11-22 21:32:36 - GraphTrainer - INFO -   precision@20: 0.004328
2025-11-22 21:32:36 - GraphTrainer - INFO -   recall@20: 0.081776
2025-11-22 21:32:36 - GraphTrainer - INFO -   hit_rate@20: 0.086140
2025-11-22 21:32:36 - GraphTrainer - INFO -   ndcg@20: 0.035904
2025-11-22 21:32:36 - GraphTrainer - INFO -   map@20: 0.022892
2025-11-22 21:32:36 - GraphTrainer - INFO -   mrr@20: 0.023865
2025-11-22 21:32:36 - GraphTrainer - INFO - 第 138 轮训练完成
2025-11-22 21:32:36 - GraphTrainer - INFO - train_loss: 0.262704
2025-11-22 21:32:36 - GraphTrainer - INFO - precision@5: 0.006799
2025-11-22 21:32:36 - GraphTrainer - INFO - recall@5: 0.032507
2025-11-22 21:32:36 - GraphTrainer - INFO - hit_rate@5: 0.033993
2025-11-22 21:32:36 - GraphTrainer - INFO - ndcg@5: 0.022023
2025-11-22 21:32:36 - GraphTrainer - INFO - map@5: 0.018328
2025-11-22 21:32:36 - GraphTrainer - INFO - mrr@5: 0.019033
2025-11-22 21:32:36 - GraphTrainer - INFO - precision@10: 0.005426
2025-11-22 21:32:36 - GraphTrainer - INFO - recall@10: 0.051542
2025-11-22 21:32:36 - GraphTrainer - INFO - hit_rate@10: 0.054204
2025-11-22 21:32:36 - GraphTrainer - INFO - ndcg@10: 0.028237
2025-11-22 21:32:36 - GraphTrainer - INFO - map@10: 0.020853
2025-11-22 21:32:36 - GraphTrainer - INFO - mrr@10: 0.021710
2025-11-22 21:32:36 - GraphTrainer - INFO - precision@20: 0.004328
2025-11-22 21:32:36 - GraphTrainer - INFO - recall@20: 0.081776
2025-11-22 21:32:36 - GraphTrainer - INFO - hit_rate@20: 0.086140
2025-11-22 21:32:36 - GraphTrainer - INFO - ndcg@20: 0.035904
2025-11-22 21:32:36 - GraphTrainer - INFO - map@20: 0.022892
2025-11-22 21:32:36 - GraphTrainer - INFO - mrr@20: 0.023865
2025-11-22 21:32:36 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:32:36 - GraphTrainer - INFO - ============================================================
2025-11-22 21:32:36 - GraphTrainer - INFO - 开始第 139/1000 轮训练
2025-11-22 21:32:36 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2583, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2741, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2461, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2330, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2367, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2627, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2718, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2589, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2726, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2542, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2526, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2577, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2528, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2638, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2781, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2676, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2689, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2457, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2806, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2718, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2618, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2605, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2627, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2618, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2378, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2513, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2289, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2569, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2585, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2696, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2773, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2598, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2605, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2714, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2634, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2707, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2665, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2616, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2820, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2651, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2656, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2710, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2633, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2334, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2433, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2651, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2755, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2683, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3010, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3012, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2797, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2695, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2549, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2535, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2495, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2677, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2685, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2696, device='cuda:0', grad_fn=<AddBackward0>)
The 138 training average loss: 0.26270440708974313
2025-11-22 21:32:47 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:32:47 - GraphTrainer - INFO -   precision@5: 0.006737
2025-11-22 21:32:47 - GraphTrainer - INFO -   recall@5: 0.032216
2025-11-22 21:32:47 - GraphTrainer - INFO -   hit_rate@5: 0.033685
2025-11-22 21:32:47 - GraphTrainer - INFO -   ndcg@5: 0.021908
2025-11-22 21:32:47 - GraphTrainer - INFO -   map@5: 0.018293
2025-11-22 21:32:47 - GraphTrainer - INFO -   mrr@5: 0.018934
2025-11-22 21:32:47 - GraphTrainer - INFO -   precision@10: 0.005431
2025-11-22 21:32:47 - GraphTrainer - INFO -   recall@10: 0.051679
2025-11-22 21:32:47 - GraphTrainer - INFO -   hit_rate@10: 0.054256
2025-11-22 21:32:47 - GraphTrainer - INFO -   ndcg@10: 0.028259
2025-11-22 21:32:47 - GraphTrainer - INFO -   map@10: 0.020874
2025-11-22 21:32:47 - GraphTrainer - INFO -   mrr@10: 0.021666
2025-11-22 21:32:47 - GraphTrainer - INFO -   precision@20: 0.004392
2025-11-22 21:32:47 - GraphTrainer - INFO -   recall@20: 0.083109
2025-11-22 21:32:47 - GraphTrainer - INFO -   hit_rate@20: 0.087272
2025-11-22 21:32:47 - GraphTrainer - INFO -   ndcg@20: 0.036223
2025-11-22 21:32:47 - GraphTrainer - INFO -   map@20: 0.022992
2025-11-22 21:32:47 - GraphTrainer - INFO -   mrr@20: 0.023889
2025-11-22 21:32:47 - GraphTrainer - INFO - 第 139 轮训练完成
2025-11-22 21:32:47 - GraphTrainer - INFO - train_loss: 0.266326
2025-11-22 21:32:47 - GraphTrainer - INFO - precision@5: 0.006737
2025-11-22 21:32:47 - GraphTrainer - INFO - recall@5: 0.032216
2025-11-22 21:32:47 - GraphTrainer - INFO - hit_rate@5: 0.033685
2025-11-22 21:32:47 - GraphTrainer - INFO - ndcg@5: 0.021908
2025-11-22 21:32:47 - GraphTrainer - INFO - map@5: 0.018293
2025-11-22 21:32:47 - GraphTrainer - INFO - mrr@5: 0.018934
2025-11-22 21:32:47 - GraphTrainer - INFO - precision@10: 0.005431
2025-11-22 21:32:47 - GraphTrainer - INFO - recall@10: 0.051679
2025-11-22 21:32:47 - GraphTrainer - INFO - hit_rate@10: 0.054256
2025-11-22 21:32:47 - GraphTrainer - INFO - ndcg@10: 0.028259
2025-11-22 21:32:47 - GraphTrainer - INFO - map@10: 0.020874
2025-11-22 21:32:47 - GraphTrainer - INFO - mrr@10: 0.021666
2025-11-22 21:32:47 - GraphTrainer - INFO - precision@20: 0.004392
2025-11-22 21:32:47 - GraphTrainer - INFO - recall@20: 0.083109
2025-11-22 21:32:47 - GraphTrainer - INFO - hit_rate@20: 0.087272
2025-11-22 21:32:47 - GraphTrainer - INFO - ndcg@20: 0.036223
2025-11-22 21:32:47 - GraphTrainer - INFO - map@20: 0.022992
2025-11-22 21:32:47 - GraphTrainer - INFO - mrr@20: 0.023889
2025-11-22 21:32:47 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:32:47 - GraphTrainer - INFO - ============================================================
2025-11-22 21:32:47 - GraphTrainer - INFO - 开始第 140/1000 轮训练
2025-11-22 21:32:47 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2682, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2632, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2688, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2681, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2780, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2591, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2817, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2710, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2578, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2617, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2832, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2536, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2518, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2670, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2581, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2710, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2511, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2599, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2612, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2623, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2498, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3075, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2577, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2492, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2859, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2575, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2534, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2696, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2559, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2702, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2645, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2595, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2723, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2602, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2607, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2796, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2713, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2471, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2573, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2825, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2753, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2521, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2504, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2767, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2479, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2460, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2659, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2810, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2517, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2828, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2469, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2599, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2968, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2966, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2879, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2857, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2736, device='cuda:0', grad_fn=<AddBackward0>)
The 139 training average loss: 0.2663256525993347
2025-11-22 21:32:58 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:32:58 - GraphTrainer - INFO -   precision@5: 0.006799
2025-11-22 21:32:58 - GraphTrainer - INFO -   recall@5: 0.032327
2025-11-22 21:32:58 - GraphTrainer - INFO -   hit_rate@5: 0.033993
2025-11-22 21:32:58 - GraphTrainer - INFO -   ndcg@5: 0.021810
2025-11-22 21:32:58 - GraphTrainer - INFO -   map@5: 0.018088
2025-11-22 21:32:58 - GraphTrainer - INFO -   mrr@5: 0.018827
2025-11-22 21:32:58 - GraphTrainer - INFO -   precision@10: 0.005426
2025-11-22 21:32:58 - GraphTrainer - INFO -   recall@10: 0.051613
2025-11-22 21:32:58 - GraphTrainer - INFO -   hit_rate@10: 0.054153
2025-11-22 21:32:58 - GraphTrainer - INFO -   ndcg@10: 0.028033
2025-11-22 21:32:58 - GraphTrainer - INFO -   map@10: 0.020596
2025-11-22 21:32:58 - GraphTrainer - INFO -   mrr@10: 0.021441
2025-11-22 21:32:58 - GraphTrainer - INFO -   precision@20: 0.004325
2025-11-22 21:32:58 - GraphTrainer - INFO -   recall@20: 0.081482
2025-11-22 21:32:58 - GraphTrainer - INFO -   hit_rate@20: 0.085935
2025-11-22 21:32:58 - GraphTrainer - INFO -   ndcg@20: 0.035652
2025-11-22 21:32:58 - GraphTrainer - INFO -   map@20: 0.022631
2025-11-22 21:32:58 - GraphTrainer - INFO -   mrr@20: 0.023598
2025-11-22 21:32:58 - GraphTrainer - INFO - 第 140 轮训练完成
2025-11-22 21:32:58 - GraphTrainer - INFO - train_loss: 0.261466
2025-11-22 21:32:58 - GraphTrainer - INFO - precision@5: 0.006799
2025-11-22 21:32:58 - GraphTrainer - INFO - recall@5: 0.032327
2025-11-22 21:32:58 - GraphTrainer - INFO - hit_rate@5: 0.033993
2025-11-22 21:32:58 - GraphTrainer - INFO - ndcg@5: 0.021810
2025-11-22 21:32:58 - GraphTrainer - INFO - map@5: 0.018088
2025-11-22 21:32:58 - GraphTrainer - INFO - mrr@5: 0.018827
2025-11-22 21:32:58 - GraphTrainer - INFO - precision@10: 0.005426
2025-11-22 21:32:58 - GraphTrainer - INFO - recall@10: 0.051613
2025-11-22 21:32:58 - GraphTrainer - INFO - hit_rate@10: 0.054153
2025-11-22 21:32:58 - GraphTrainer - INFO - ndcg@10: 0.028033
2025-11-22 21:32:58 - GraphTrainer - INFO - map@10: 0.020596
2025-11-22 21:32:58 - GraphTrainer - INFO - mrr@10: 0.021441
2025-11-22 21:32:58 - GraphTrainer - INFO - precision@20: 0.004325
2025-11-22 21:32:58 - GraphTrainer - INFO - recall@20: 0.081482
2025-11-22 21:32:58 - GraphTrainer - INFO - hit_rate@20: 0.085935
2025-11-22 21:32:58 - GraphTrainer - INFO - ndcg@20: 0.035652
2025-11-22 21:32:58 - GraphTrainer - INFO - map@20: 0.022631
2025-11-22 21:32:58 - GraphTrainer - INFO - mrr@20: 0.023598
2025-11-22 21:32:58 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:32:59 - GraphTrainer - INFO - 检查点已保存: Epoch 140 -> ./checkpoints/checkpoint_epoch_140.pth
2025-11-22 21:32:59 - GraphTrainer - INFO - ============================================================
2025-11-22 21:32:59 - GraphTrainer - INFO - 开始第 141/1000 轮训练
2025-11-22 21:32:59 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2784, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2537, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2622, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2748, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2649, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2689, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2761, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2717, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2450, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2470, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2523, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2435, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2500, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2509, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2565, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2538, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2442, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2437, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2590, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2734, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2451, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2590, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2728, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2570, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2720, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2426, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2725, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2776, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2883, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2542, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2647, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2655, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2828, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2671, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2598, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2600, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2562, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2540, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2581, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2592, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2634, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2648, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2508, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2793, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2750, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2641, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2635, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2377, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2577, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2379, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2797, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2492, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2576, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2715, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2648, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2578, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2784, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2734, device='cuda:0', grad_fn=<AddBackward0>)
The 140 training average loss: 0.26146571363868387
2025-11-22 21:33:09 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:33:09 - GraphTrainer - INFO -   precision@5: 0.006758
2025-11-22 21:33:09 - GraphTrainer - INFO -   recall@5: 0.032367
2025-11-22 21:33:09 - GraphTrainer - INFO -   hit_rate@5: 0.033788
2025-11-22 21:33:09 - GraphTrainer - INFO -   ndcg@5: 0.021984
2025-11-22 21:33:09 - GraphTrainer - INFO -   map@5: 0.018334
2025-11-22 21:33:09 - GraphTrainer - INFO -   mrr@5: 0.019039
2025-11-22 21:33:09 - GraphTrainer - INFO -   precision@10: 0.005390
2025-11-22 21:33:09 - GraphTrainer - INFO -   recall@10: 0.050966
2025-11-22 21:33:09 - GraphTrainer - INFO -   hit_rate@10: 0.053793
2025-11-22 21:33:09 - GraphTrainer - INFO -   ndcg@10: 0.028036
2025-11-22 21:33:09 - GraphTrainer - INFO -   map@10: 0.020765
2025-11-22 21:33:09 - GraphTrainer - INFO -   mrr@10: 0.021651
2025-11-22 21:33:09 - GraphTrainer - INFO -   precision@20: 0.004330
2025-11-22 21:33:09 - GraphTrainer - INFO -   recall@20: 0.081989
2025-11-22 21:33:09 - GraphTrainer - INFO -   hit_rate@20: 0.086192
2025-11-22 21:33:09 - GraphTrainer - INFO -   ndcg@20: 0.035909
2025-11-22 21:33:09 - GraphTrainer - INFO -   map@20: 0.022879
2025-11-22 21:33:09 - GraphTrainer - INFO -   mrr@20: 0.023854
2025-11-22 21:33:09 - GraphTrainer - INFO - 第 141 轮训练完成
2025-11-22 21:33:09 - GraphTrainer - INFO - train_loss: 0.262799
2025-11-22 21:33:09 - GraphTrainer - INFO - precision@5: 0.006758
2025-11-22 21:33:09 - GraphTrainer - INFO - recall@5: 0.032367
2025-11-22 21:33:09 - GraphTrainer - INFO - hit_rate@5: 0.033788
2025-11-22 21:33:09 - GraphTrainer - INFO - ndcg@5: 0.021984
2025-11-22 21:33:09 - GraphTrainer - INFO - map@5: 0.018334
2025-11-22 21:33:09 - GraphTrainer - INFO - mrr@5: 0.019039
2025-11-22 21:33:09 - GraphTrainer - INFO - precision@10: 0.005390
2025-11-22 21:33:09 - GraphTrainer - INFO - recall@10: 0.050966
2025-11-22 21:33:09 - GraphTrainer - INFO - hit_rate@10: 0.053793
2025-11-22 21:33:09 - GraphTrainer - INFO - ndcg@10: 0.028036
2025-11-22 21:33:09 - GraphTrainer - INFO - map@10: 0.020765
2025-11-22 21:33:09 - GraphTrainer - INFO - mrr@10: 0.021651
2025-11-22 21:33:09 - GraphTrainer - INFO - precision@20: 0.004330
2025-11-22 21:33:09 - GraphTrainer - INFO - recall@20: 0.081989
2025-11-22 21:33:09 - GraphTrainer - INFO - hit_rate@20: 0.086192
2025-11-22 21:33:09 - GraphTrainer - INFO - ndcg@20: 0.035909
2025-11-22 21:33:09 - GraphTrainer - INFO - map@20: 0.022879
2025-11-22 21:33:09 - GraphTrainer - INFO - mrr@20: 0.023854
2025-11-22 21:33:09 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:33:09 - GraphTrainer - INFO - ============================================================
2025-11-22 21:33:09 - GraphTrainer - INFO - 开始第 142/1000 轮训练
2025-11-22 21:33:09 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2552, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2595, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2674, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2786, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2652, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2692, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2698, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2687, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2592, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2492, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2769, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2639, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2644, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2712, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2552, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2515, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2342, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2675, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2563, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2608, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2584, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2581, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2825, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2658, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2523, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2771, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2750, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2567, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2663, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2665, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2496, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2543, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2761, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2454, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2620, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2620, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2749, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2623, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2897, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2921, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2834, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2545, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2486, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2339, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2841, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2666, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2570, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2668, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2529, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2708, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2604, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2482, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2655, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2685, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2623, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2594, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2343, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2544, device='cuda:0', grad_fn=<AddBackward0>)
The 141 training average loss: 0.26279899786258565
2025-11-22 21:33:20 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:33:20 - GraphTrainer - INFO -   precision@5: 0.006840
2025-11-22 21:33:20 - GraphTrainer - INFO -   recall@5: 0.032773
2025-11-22 21:33:20 - GraphTrainer - INFO -   hit_rate@5: 0.034199
2025-11-22 21:33:20 - GraphTrainer - INFO -   ndcg@5: 0.021830
2025-11-22 21:33:20 - GraphTrainer - INFO -   map@5: 0.018015
2025-11-22 21:33:20 - GraphTrainer - INFO -   mrr@5: 0.018650
2025-11-22 21:33:20 - GraphTrainer - INFO -   precision@10: 0.005359
2025-11-22 21:33:20 - GraphTrainer - INFO -   recall@10: 0.050772
2025-11-22 21:33:20 - GraphTrainer - INFO -   hit_rate@10: 0.053587
2025-11-22 21:33:20 - GraphTrainer - INFO -   ndcg@10: 0.027710
2025-11-22 21:33:20 - GraphTrainer - INFO -   map@10: 0.020391
2025-11-22 21:33:20 - GraphTrainer - INFO -   mrr@10: 0.021208
2025-11-22 21:33:20 - GraphTrainer - INFO -   precision@20: 0.004268
2025-11-22 21:33:20 - GraphTrainer - INFO -   recall@20: 0.080690
2025-11-22 21:33:20 - GraphTrainer - INFO -   hit_rate@20: 0.084906
2025-11-22 21:33:20 - GraphTrainer - INFO -   ndcg@20: 0.035319
2025-11-22 21:33:20 - GraphTrainer - INFO -   map@20: 0.022435
2025-11-22 21:33:20 - GraphTrainer - INFO -   mrr@20: 0.023340
2025-11-22 21:33:20 - GraphTrainer - INFO - 第 142 轮训练完成
2025-11-22 21:33:20 - GraphTrainer - INFO - train_loss: 0.262241
2025-11-22 21:33:20 - GraphTrainer - INFO - precision@5: 0.006840
2025-11-22 21:33:20 - GraphTrainer - INFO - recall@5: 0.032773
2025-11-22 21:33:20 - GraphTrainer - INFO - hit_rate@5: 0.034199
2025-11-22 21:33:20 - GraphTrainer - INFO - ndcg@5: 0.021830
2025-11-22 21:33:20 - GraphTrainer - INFO - map@5: 0.018015
2025-11-22 21:33:20 - GraphTrainer - INFO - mrr@5: 0.018650
2025-11-22 21:33:20 - GraphTrainer - INFO - precision@10: 0.005359
2025-11-22 21:33:20 - GraphTrainer - INFO - recall@10: 0.050772
2025-11-22 21:33:20 - GraphTrainer - INFO - hit_rate@10: 0.053587
2025-11-22 21:33:20 - GraphTrainer - INFO - ndcg@10: 0.027710
2025-11-22 21:33:20 - GraphTrainer - INFO - map@10: 0.020391
2025-11-22 21:33:20 - GraphTrainer - INFO - mrr@10: 0.021208
2025-11-22 21:33:20 - GraphTrainer - INFO - precision@20: 0.004268
2025-11-22 21:33:20 - GraphTrainer - INFO - recall@20: 0.080690
2025-11-22 21:33:20 - GraphTrainer - INFO - hit_rate@20: 0.084906
2025-11-22 21:33:20 - GraphTrainer - INFO - ndcg@20: 0.035319
2025-11-22 21:33:20 - GraphTrainer - INFO - map@20: 0.022435
2025-11-22 21:33:20 - GraphTrainer - INFO - mrr@20: 0.023340
2025-11-22 21:33:20 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:33:20 - GraphTrainer - INFO - ============================================================
2025-11-22 21:33:20 - GraphTrainer - INFO - 开始第 143/1000 轮训练
2025-11-22 21:33:20 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2581, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2495, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2554, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2489, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2698, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2637, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2938, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2646, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2510, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2488, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2438, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2668, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2676, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2643, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2504, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2719, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2663, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2648, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2416, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2640, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2821, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2565, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2640, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2678, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2418, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2806, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2598, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2610, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2581, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2582, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2654, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2424, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2734, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2646, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2538, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2665, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2596, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2589, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2585, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2555, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2625, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2547, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2608, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2600, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2686, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2644, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2589, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2605, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2621, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2752, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2520, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2737, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2853, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2725, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2718, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2667, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2701, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2567, device='cuda:0', grad_fn=<AddBackward0>)
The 142 training average loss: 0.2622411523399682
2025-11-22 21:33:31 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:33:31 - GraphTrainer - INFO -   precision@5: 0.006809
2025-11-22 21:33:31 - GraphTrainer - INFO -   recall@5: 0.032627
2025-11-22 21:33:31 - GraphTrainer - INFO -   hit_rate@5: 0.034045
2025-11-22 21:33:31 - GraphTrainer - INFO -   ndcg@5: 0.022023
2025-11-22 21:33:31 - GraphTrainer - INFO -   map@5: 0.018301
2025-11-22 21:33:31 - GraphTrainer - INFO -   mrr@5: 0.018981
2025-11-22 21:33:31 - GraphTrainer - INFO -   precision@10: 0.005410
2025-11-22 21:33:31 - GraphTrainer - INFO -   recall@10: 0.051288
2025-11-22 21:33:31 - GraphTrainer - INFO -   hit_rate@10: 0.053998
2025-11-22 21:33:31 - GraphTrainer - INFO -   ndcg@10: 0.028108
2025-11-22 21:33:31 - GraphTrainer - INFO -   map@10: 0.020759
2025-11-22 21:33:31 - GraphTrainer - INFO -   mrr@10: 0.021612
2025-11-22 21:33:31 - GraphTrainer - INFO -   precision@20: 0.004294
2025-11-22 21:33:31 - GraphTrainer - INFO -   recall@20: 0.081182
2025-11-22 21:33:31 - GraphTrainer - INFO -   hit_rate@20: 0.085318
2025-11-22 21:33:31 - GraphTrainer - INFO -   ndcg@20: 0.035705
2025-11-22 21:33:31 - GraphTrainer - INFO -   map@20: 0.022795
2025-11-22 21:33:31 - GraphTrainer - INFO -   mrr@20: 0.023740
2025-11-22 21:33:31 - GraphTrainer - INFO - 第 143 轮训练完成
2025-11-22 21:33:31 - GraphTrainer - INFO - train_loss: 0.260572
2025-11-22 21:33:31 - GraphTrainer - INFO - precision@5: 0.006809
2025-11-22 21:33:31 - GraphTrainer - INFO - recall@5: 0.032627
2025-11-22 21:33:31 - GraphTrainer - INFO - hit_rate@5: 0.034045
2025-11-22 21:33:31 - GraphTrainer - INFO - ndcg@5: 0.022023
2025-11-22 21:33:31 - GraphTrainer - INFO - map@5: 0.018301
2025-11-22 21:33:31 - GraphTrainer - INFO - mrr@5: 0.018981
2025-11-22 21:33:31 - GraphTrainer - INFO - precision@10: 0.005410
2025-11-22 21:33:31 - GraphTrainer - INFO - recall@10: 0.051288
2025-11-22 21:33:31 - GraphTrainer - INFO - hit_rate@10: 0.053998
2025-11-22 21:33:31 - GraphTrainer - INFO - ndcg@10: 0.028108
2025-11-22 21:33:31 - GraphTrainer - INFO - map@10: 0.020759
2025-11-22 21:33:31 - GraphTrainer - INFO - mrr@10: 0.021612
2025-11-22 21:33:31 - GraphTrainer - INFO - precision@20: 0.004294
2025-11-22 21:33:31 - GraphTrainer - INFO - recall@20: 0.081182
2025-11-22 21:33:31 - GraphTrainer - INFO - hit_rate@20: 0.085318
2025-11-22 21:33:31 - GraphTrainer - INFO - ndcg@20: 0.035705
2025-11-22 21:33:31 - GraphTrainer - INFO - map@20: 0.022795
2025-11-22 21:33:31 - GraphTrainer - INFO - mrr@20: 0.023740
2025-11-22 21:33:31 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:33:31 - GraphTrainer - INFO - ============================================================
2025-11-22 21:33:31 - GraphTrainer - INFO - 开始第 144/1000 轮训练
2025-11-22 21:33:31 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2367, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2437, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2581, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2660, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2609, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2553, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2806, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2638, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2589, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2666, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2776, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2549, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2547, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2515, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2427, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2417, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2458, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2706, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2726, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2654, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2688, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2629, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2681, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2705, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2334, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2730, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2577, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2556, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2493, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2653, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2536, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2419, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2724, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2729, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2522, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2606, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2540, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2499, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2647, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2654, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2823, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2731, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2551, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2569, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2494, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2597, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2493, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2527, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2654, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2630, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2647, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2824, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2731, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2522, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2696, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2643, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2664, device='cuda:0', grad_fn=<AddBackward0>)
The 143 training average loss: 0.2605721986499326
2025-11-22 21:33:42 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:33:42 - GraphTrainer - INFO -   precision@5: 0.006891
2025-11-22 21:33:42 - GraphTrainer - INFO -   recall@5: 0.032931
2025-11-22 21:33:42 - GraphTrainer - INFO -   hit_rate@5: 0.034456
2025-11-22 21:33:42 - GraphTrainer - INFO -   ndcg@5: 0.022167
2025-11-22 21:33:42 - GraphTrainer - INFO -   map@5: 0.018395
2025-11-22 21:33:42 - GraphTrainer - INFO -   mrr@5: 0.019088
2025-11-22 21:33:42 - GraphTrainer - INFO -   precision@10: 0.005415
2025-11-22 21:33:42 - GraphTrainer - INFO -   recall@10: 0.051451
2025-11-22 21:33:42 - GraphTrainer - INFO -   hit_rate@10: 0.054153
2025-11-22 21:33:42 - GraphTrainer - INFO -   ndcg@10: 0.028175
2025-11-22 21:33:42 - GraphTrainer - INFO -   map@10: 0.020813
2025-11-22 21:33:42 - GraphTrainer - INFO -   mrr@10: 0.021656
2025-11-22 21:33:42 - GraphTrainer - INFO -   precision@20: 0.004312
2025-11-22 21:33:42 - GraphTrainer - INFO -   recall@20: 0.081505
2025-11-22 21:33:42 - GraphTrainer - INFO -   hit_rate@20: 0.085780
2025-11-22 21:33:42 - GraphTrainer - INFO -   ndcg@20: 0.035837
2025-11-22 21:33:42 - GraphTrainer - INFO -   map@20: 0.022876
2025-11-22 21:33:42 - GraphTrainer - INFO -   mrr@20: 0.023821
2025-11-22 21:33:42 - GraphTrainer - INFO - 第 144 轮训练完成
2025-11-22 21:33:42 - GraphTrainer - INFO - train_loss: 0.263873
2025-11-22 21:33:42 - GraphTrainer - INFO - precision@5: 0.006891
2025-11-22 21:33:42 - GraphTrainer - INFO - recall@5: 0.032931
2025-11-22 21:33:42 - GraphTrainer - INFO - hit_rate@5: 0.034456
2025-11-22 21:33:42 - GraphTrainer - INFO - ndcg@5: 0.022167
2025-11-22 21:33:42 - GraphTrainer - INFO - map@5: 0.018395
2025-11-22 21:33:42 - GraphTrainer - INFO - mrr@5: 0.019088
2025-11-22 21:33:42 - GraphTrainer - INFO - precision@10: 0.005415
2025-11-22 21:33:42 - GraphTrainer - INFO - recall@10: 0.051451
2025-11-22 21:33:42 - GraphTrainer - INFO - hit_rate@10: 0.054153
2025-11-22 21:33:42 - GraphTrainer - INFO - ndcg@10: 0.028175
2025-11-22 21:33:42 - GraphTrainer - INFO - map@10: 0.020813
2025-11-22 21:33:42 - GraphTrainer - INFO - mrr@10: 0.021656
2025-11-22 21:33:42 - GraphTrainer - INFO - precision@20: 0.004312
2025-11-22 21:33:42 - GraphTrainer - INFO - recall@20: 0.081505
2025-11-22 21:33:42 - GraphTrainer - INFO - hit_rate@20: 0.085780
2025-11-22 21:33:42 - GraphTrainer - INFO - ndcg@20: 0.035837
2025-11-22 21:33:42 - GraphTrainer - INFO - map@20: 0.022876
2025-11-22 21:33:42 - GraphTrainer - INFO - mrr@20: 0.023821
2025-11-22 21:33:42 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:33:42 - GraphTrainer - INFO - ============================================================
2025-11-22 21:33:42 - GraphTrainer - INFO - 开始第 145/1000 轮训练
2025-11-22 21:33:42 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2716, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2867, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2604, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2832, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2728, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2525, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2605, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2398, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2499, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2453, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2580, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2674, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2610, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2585, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2708, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2412, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2707, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2558, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2690, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2724, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2656, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2530, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2850, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2767, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2564, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2688, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2731, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2691, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2474, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2695, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2698, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2626, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2602, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2564, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2830, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2717, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2590, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2797, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2543, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2669, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2527, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2924, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2608, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2520, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2697, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2626, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2550, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2954, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2481, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2576, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2596, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2757, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2596, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2332, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2522, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2648, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2762, device='cuda:0', grad_fn=<AddBackward0>)
The 144 training average loss: 0.26387306071560956
2025-11-22 21:33:53 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:33:53 - GraphTrainer - INFO -   precision@5: 0.006809
2025-11-22 21:33:53 - GraphTrainer - INFO -   recall@5: 0.032469
2025-11-22 21:33:53 - GraphTrainer - INFO -   hit_rate@5: 0.034045
2025-11-22 21:33:53 - GraphTrainer - INFO -   ndcg@5: 0.021587
2025-11-22 21:33:53 - GraphTrainer - INFO -   map@5: 0.017742
2025-11-22 21:33:53 - GraphTrainer - INFO -   mrr@5: 0.018537
2025-11-22 21:33:53 - GraphTrainer - INFO -   precision@10: 0.005420
2025-11-22 21:33:53 - GraphTrainer - INFO -   recall@10: 0.051439
2025-11-22 21:33:53 - GraphTrainer - INFO -   hit_rate@10: 0.054101
2025-11-22 21:33:53 - GraphTrainer - INFO -   ndcg@10: 0.027714
2025-11-22 21:33:53 - GraphTrainer - INFO -   map@10: 0.020196
2025-11-22 21:33:53 - GraphTrainer - INFO -   mrr@10: 0.021137
2025-11-22 21:33:53 - GraphTrainer - INFO -   precision@20: 0.004333
2025-11-22 21:33:53 - GraphTrainer - INFO -   recall@20: 0.081685
2025-11-22 21:33:53 - GraphTrainer - INFO -   hit_rate@20: 0.086140
2025-11-22 21:33:53 - GraphTrainer - INFO -   ndcg@20: 0.035424
2025-11-22 21:33:53 - GraphTrainer - INFO -   map@20: 0.022263
2025-11-22 21:33:53 - GraphTrainer - INFO -   mrr@20: 0.023316
2025-11-22 21:33:53 - GraphTrainer - INFO - 第 145 轮训练完成
2025-11-22 21:33:53 - GraphTrainer - INFO - train_loss: 0.259789
2025-11-22 21:33:53 - GraphTrainer - INFO - precision@5: 0.006809
2025-11-22 21:33:53 - GraphTrainer - INFO - recall@5: 0.032469
2025-11-22 21:33:53 - GraphTrainer - INFO - hit_rate@5: 0.034045
2025-11-22 21:33:53 - GraphTrainer - INFO - ndcg@5: 0.021587
2025-11-22 21:33:53 - GraphTrainer - INFO - map@5: 0.017742
2025-11-22 21:33:53 - GraphTrainer - INFO - mrr@5: 0.018537
2025-11-22 21:33:53 - GraphTrainer - INFO - precision@10: 0.005420
2025-11-22 21:33:53 - GraphTrainer - INFO - recall@10: 0.051439
2025-11-22 21:33:53 - GraphTrainer - INFO - hit_rate@10: 0.054101
2025-11-22 21:33:53 - GraphTrainer - INFO - ndcg@10: 0.027714
2025-11-22 21:33:53 - GraphTrainer - INFO - map@10: 0.020196
2025-11-22 21:33:53 - GraphTrainer - INFO - mrr@10: 0.021137
2025-11-22 21:33:53 - GraphTrainer - INFO - precision@20: 0.004333
2025-11-22 21:33:53 - GraphTrainer - INFO - recall@20: 0.081685
2025-11-22 21:33:53 - GraphTrainer - INFO - hit_rate@20: 0.086140
2025-11-22 21:33:53 - GraphTrainer - INFO - ndcg@20: 0.035424
2025-11-22 21:33:53 - GraphTrainer - INFO - map@20: 0.022263
2025-11-22 21:33:53 - GraphTrainer - INFO - mrr@20: 0.023316
2025-11-22 21:33:53 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:33:53 - GraphTrainer - INFO - ============================================================
2025-11-22 21:33:53 - GraphTrainer - INFO - 开始第 146/1000 轮训练
2025-11-22 21:33:53 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2743, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2688, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2495, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2429, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2816, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2577, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2792, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2684, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2707, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2448, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2701, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2600, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2452, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2449, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2567, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2467, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2581, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2473, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2590, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2616, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2464, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2555, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2787, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2691, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2681, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2571, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2500, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2691, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2441, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2602, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2420, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2587, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2676, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2660, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2516, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2720, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2469, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2509, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2518, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2807, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2755, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2524, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2609, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2741, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2589, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2483, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2766, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2679, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2643, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2518, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2545, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2643, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2521, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2343, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2678, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2549, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2718, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2637, device='cuda:0', grad_fn=<AddBackward0>)
The 145 training average loss: 0.2597890131432435
2025-11-22 21:34:04 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:34:04 - GraphTrainer - INFO -   precision@5: 0.006902
2025-11-22 21:34:04 - GraphTrainer - INFO -   recall@5: 0.033135
2025-11-22 21:34:04 - GraphTrainer - INFO -   hit_rate@5: 0.034508
2025-11-22 21:34:04 - GraphTrainer - INFO -   ndcg@5: 0.022014
2025-11-22 21:34:04 - GraphTrainer - INFO -   map@5: 0.018130
2025-11-22 21:34:04 - GraphTrainer - INFO -   mrr@5: 0.018787
2025-11-22 21:34:04 - GraphTrainer - INFO -   precision@10: 0.005508
2025-11-22 21:34:04 - GraphTrainer - INFO -   recall@10: 0.052333
2025-11-22 21:34:04 - GraphTrainer - INFO -   hit_rate@10: 0.054976
2025-11-22 21:34:04 - GraphTrainer - INFO -   ndcg@10: 0.028214
2025-11-22 21:34:04 - GraphTrainer - INFO -   map@10: 0.020601
2025-11-22 21:34:04 - GraphTrainer - INFO -   mrr@10: 0.021420
2025-11-22 21:34:04 - GraphTrainer - INFO -   precision@20: 0.004276
2025-11-22 21:34:04 - GraphTrainer - INFO -   recall@20: 0.080824
2025-11-22 21:34:04 - GraphTrainer - INFO -   hit_rate@20: 0.085112
2025-11-22 21:34:04 - GraphTrainer - INFO -   ndcg@20: 0.035472
2025-11-22 21:34:04 - GraphTrainer - INFO -   map@20: 0.022546
2025-11-22 21:34:04 - GraphTrainer - INFO -   mrr@20: 0.023475
2025-11-22 21:34:04 - GraphTrainer - INFO - 第 146 轮训练完成
2025-11-22 21:34:04 - GraphTrainer - INFO - train_loss: 0.258047
2025-11-22 21:34:04 - GraphTrainer - INFO - precision@5: 0.006902
2025-11-22 21:34:04 - GraphTrainer - INFO - recall@5: 0.033135
2025-11-22 21:34:04 - GraphTrainer - INFO - hit_rate@5: 0.034508
2025-11-22 21:34:04 - GraphTrainer - INFO - ndcg@5: 0.022014
2025-11-22 21:34:04 - GraphTrainer - INFO - map@5: 0.018130
2025-11-22 21:34:04 - GraphTrainer - INFO - mrr@5: 0.018787
2025-11-22 21:34:04 - GraphTrainer - INFO - precision@10: 0.005508
2025-11-22 21:34:04 - GraphTrainer - INFO - recall@10: 0.052333
2025-11-22 21:34:04 - GraphTrainer - INFO - hit_rate@10: 0.054976
2025-11-22 21:34:04 - GraphTrainer - INFO - ndcg@10: 0.028214
2025-11-22 21:34:04 - GraphTrainer - INFO - map@10: 0.020601
2025-11-22 21:34:04 - GraphTrainer - INFO - mrr@10: 0.021420
2025-11-22 21:34:04 - GraphTrainer - INFO - precision@20: 0.004276
2025-11-22 21:34:04 - GraphTrainer - INFO - recall@20: 0.080824
2025-11-22 21:34:04 - GraphTrainer - INFO - hit_rate@20: 0.085112
2025-11-22 21:34:04 - GraphTrainer - INFO - ndcg@20: 0.035472
2025-11-22 21:34:04 - GraphTrainer - INFO - map@20: 0.022546
2025-11-22 21:34:04 - GraphTrainer - INFO - mrr@20: 0.023475
2025-11-22 21:34:04 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:34:04 - GraphTrainer - INFO - ============================================================
2025-11-22 21:34:04 - GraphTrainer - INFO - 开始第 147/1000 轮训练
2025-11-22 21:34:04 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2368, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2716, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2684, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2512, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2801, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2527, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2331, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2583, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2472, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2549, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2783, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2660, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2543, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2459, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2516, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2290, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2428, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2702, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2636, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2466, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2596, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2831, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2758, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2662, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2738, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2786, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2533, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2596, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2545, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2603, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2362, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2636, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2842, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2388, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2639, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2486, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2378, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2513, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2407, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2504, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2522, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2641, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2437, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2600, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2753, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2453, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2588, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2532, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2660, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2559, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2594, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2797, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2592, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2711, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2578, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2652, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2560, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2608, device='cuda:0', grad_fn=<AddBackward0>)
The 146 training average loss: 0.2580466514517521
2025-11-22 21:34:15 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:34:15 - GraphTrainer - INFO -   precision@5: 0.006860
2025-11-22 21:34:15 - GraphTrainer - INFO -   recall@5: 0.032774
2025-11-22 21:34:15 - GraphTrainer - INFO -   hit_rate@5: 0.034302
2025-11-22 21:34:15 - GraphTrainer - INFO -   ndcg@5: 0.021851
2025-11-22 21:34:15 - GraphTrainer - INFO -   map@5: 0.018019
2025-11-22 21:34:15 - GraphTrainer - INFO -   mrr@5: 0.018691
2025-11-22 21:34:15 - GraphTrainer - INFO -   precision@10: 0.005436
2025-11-22 21:34:15 - GraphTrainer - INFO -   recall@10: 0.051484
2025-11-22 21:34:15 - GraphTrainer - INFO -   hit_rate@10: 0.054256
2025-11-22 21:34:15 - GraphTrainer - INFO -   ndcg@10: 0.027937
2025-11-22 21:34:15 - GraphTrainer - INFO -   map@10: 0.020471
2025-11-22 21:34:15 - GraphTrainer - INFO -   mrr@10: 0.021304
2025-11-22 21:34:15 - GraphTrainer - INFO -   precision@20: 0.004268
2025-11-22 21:34:15 - GraphTrainer - INFO -   recall@20: 0.080565
2025-11-22 21:34:15 - GraphTrainer - INFO -   hit_rate@20: 0.084855
2025-11-22 21:34:15 - GraphTrainer - INFO -   ndcg@20: 0.035362
2025-11-22 21:34:15 - GraphTrainer - INFO -   map@20: 0.022476
2025-11-22 21:34:15 - GraphTrainer - INFO -   mrr@20: 0.023405
2025-11-22 21:34:15 - GraphTrainer - INFO - 第 147 轮训练完成
2025-11-22 21:34:15 - GraphTrainer - INFO - train_loss: 0.259467
2025-11-22 21:34:15 - GraphTrainer - INFO - precision@5: 0.006860
2025-11-22 21:34:15 - GraphTrainer - INFO - recall@5: 0.032774
2025-11-22 21:34:15 - GraphTrainer - INFO - hit_rate@5: 0.034302
2025-11-22 21:34:15 - GraphTrainer - INFO - ndcg@5: 0.021851
2025-11-22 21:34:15 - GraphTrainer - INFO - map@5: 0.018019
2025-11-22 21:34:15 - GraphTrainer - INFO - mrr@5: 0.018691
2025-11-22 21:34:15 - GraphTrainer - INFO - precision@10: 0.005436
2025-11-22 21:34:15 - GraphTrainer - INFO - recall@10: 0.051484
2025-11-22 21:34:15 - GraphTrainer - INFO - hit_rate@10: 0.054256
2025-11-22 21:34:15 - GraphTrainer - INFO - ndcg@10: 0.027937
2025-11-22 21:34:15 - GraphTrainer - INFO - map@10: 0.020471
2025-11-22 21:34:15 - GraphTrainer - INFO - mrr@10: 0.021304
2025-11-22 21:34:15 - GraphTrainer - INFO - precision@20: 0.004268
2025-11-22 21:34:15 - GraphTrainer - INFO - recall@20: 0.080565
2025-11-22 21:34:15 - GraphTrainer - INFO - hit_rate@20: 0.084855
2025-11-22 21:34:15 - GraphTrainer - INFO - ndcg@20: 0.035362
2025-11-22 21:34:15 - GraphTrainer - INFO - map@20: 0.022476
2025-11-22 21:34:15 - GraphTrainer - INFO - mrr@20: 0.023405
2025-11-22 21:34:15 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:34:15 - GraphTrainer - INFO - ============================================================
2025-11-22 21:34:15 - GraphTrainer - INFO - 开始第 148/1000 轮训练
2025-11-22 21:34:15 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2376, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2597, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2412, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2537, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2547, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2636, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2623, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2410, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2447, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2640, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2576, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2620, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2465, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2818, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2423, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2576, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2593, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2440, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2446, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2589, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2505, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2750, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2620, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2646, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2627, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2726, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2338, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2481, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2725, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2451, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2582, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2714, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2503, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2642, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2746, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2683, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2565, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2535, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2493, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2752, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2540, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2780, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2651, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2594, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2505, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2522, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2656, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2445, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2560, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2667, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2735, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2811, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2807, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2809, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2697, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2736, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2668, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2450, device='cuda:0', grad_fn=<AddBackward0>)
The 147 training average loss: 0.25946698491943293
2025-11-22 21:34:26 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:34:26 - GraphTrainer - INFO -   precision@5: 0.006727
2025-11-22 21:34:26 - GraphTrainer - INFO -   recall@5: 0.032129
2025-11-22 21:34:26 - GraphTrainer - INFO -   hit_rate@5: 0.033582
2025-11-22 21:34:26 - GraphTrainer - INFO -   ndcg@5: 0.021324
2025-11-22 21:34:26 - GraphTrainer - INFO -   map@5: 0.017535
2025-11-22 21:34:26 - GraphTrainer - INFO -   mrr@5: 0.018238
2025-11-22 21:34:26 - GraphTrainer - INFO -   precision@10: 0.005390
2025-11-22 21:34:26 - GraphTrainer - INFO -   recall@10: 0.050998
2025-11-22 21:34:26 - GraphTrainer - INFO -   hit_rate@10: 0.053793
2025-11-22 21:34:26 - GraphTrainer - INFO -   ndcg@10: 0.027445
2025-11-22 21:34:26 - GraphTrainer - INFO -   map@10: 0.019985
2025-11-22 21:34:26 - GraphTrainer - INFO -   mrr@10: 0.020863
2025-11-22 21:34:26 - GraphTrainer - INFO -   precision@20: 0.004315
2025-11-22 21:34:26 - GraphTrainer - INFO -   recall@20: 0.081351
2025-11-22 21:34:26 - GraphTrainer - INFO -   hit_rate@20: 0.085780
2025-11-22 21:34:26 - GraphTrainer - INFO -   ndcg@20: 0.035140
2025-11-22 21:34:26 - GraphTrainer - INFO -   map@20: 0.022031
2025-11-22 21:34:26 - GraphTrainer - INFO -   mrr@20: 0.023013
2025-11-22 21:34:26 - GraphTrainer - INFO - 第 148 轮训练完成
2025-11-22 21:34:26 - GraphTrainer - INFO - train_loss: 0.263259
2025-11-22 21:34:26 - GraphTrainer - INFO - precision@5: 0.006727
2025-11-22 21:34:26 - GraphTrainer - INFO - recall@5: 0.032129
2025-11-22 21:34:26 - GraphTrainer - INFO - hit_rate@5: 0.033582
2025-11-22 21:34:26 - GraphTrainer - INFO - ndcg@5: 0.021324
2025-11-22 21:34:26 - GraphTrainer - INFO - map@5: 0.017535
2025-11-22 21:34:26 - GraphTrainer - INFO - mrr@5: 0.018238
2025-11-22 21:34:26 - GraphTrainer - INFO - precision@10: 0.005390
2025-11-22 21:34:26 - GraphTrainer - INFO - recall@10: 0.050998
2025-11-22 21:34:26 - GraphTrainer - INFO - hit_rate@10: 0.053793
2025-11-22 21:34:26 - GraphTrainer - INFO - ndcg@10: 0.027445
2025-11-22 21:34:26 - GraphTrainer - INFO - map@10: 0.019985
2025-11-22 21:34:26 - GraphTrainer - INFO - mrr@10: 0.020863
2025-11-22 21:34:26 - GraphTrainer - INFO - precision@20: 0.004315
2025-11-22 21:34:26 - GraphTrainer - INFO - recall@20: 0.081351
2025-11-22 21:34:26 - GraphTrainer - INFO - hit_rate@20: 0.085780
2025-11-22 21:34:26 - GraphTrainer - INFO - ndcg@20: 0.035140
2025-11-22 21:34:26 - GraphTrainer - INFO - map@20: 0.022031
2025-11-22 21:34:26 - GraphTrainer - INFO - mrr@20: 0.023013
2025-11-22 21:34:26 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:34:26 - GraphTrainer - INFO - ============================================================
2025-11-22 21:34:26 - GraphTrainer - INFO - 开始第 149/1000 轮训练
2025-11-22 21:34:26 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2565, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2549, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2448, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2574, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2522, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2308, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2661, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2598, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2574, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2744, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2699, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2718, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2747, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2516, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2813, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2696, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2623, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2700, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2565, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2683, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2531, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2724, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2756, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2586, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2573, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2759, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2699, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2786, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2786, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2367, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2651, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2596, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2475, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2518, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2604, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2419, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2480, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2715, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2633, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2586, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2650, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2850, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2723, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2608, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2664, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2619, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2720, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2775, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2687, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2732, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2819, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2704, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2564, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2585, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2660, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2618, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2556, device='cuda:0', grad_fn=<AddBackward0>)
The 148 training average loss: 0.2632592050679799
2025-11-22 21:34:36 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:34:36 - GraphTrainer - INFO -   precision@5: 0.006778
2025-11-22 21:34:36 - GraphTrainer - INFO -   recall@5: 0.032420
2025-11-22 21:34:36 - GraphTrainer - INFO -   hit_rate@5: 0.033890
2025-11-22 21:34:36 - GraphTrainer - INFO -   ndcg@5: 0.021727
2025-11-22 21:34:36 - GraphTrainer - INFO -   map@5: 0.017973
2025-11-22 21:34:36 - GraphTrainer - INFO -   mrr@5: 0.018653
2025-11-22 21:34:36 - GraphTrainer - INFO -   precision@10: 0.005431
2025-11-22 21:34:36 - GraphTrainer - INFO -   recall@10: 0.051445
2025-11-22 21:34:36 - GraphTrainer - INFO -   hit_rate@10: 0.054153
2025-11-22 21:34:36 - GraphTrainer - INFO -   ndcg@10: 0.027905
2025-11-22 21:34:36 - GraphTrainer - INFO -   map@10: 0.020457
2025-11-22 21:34:36 - GraphTrainer - INFO -   mrr@10: 0.021297
2025-11-22 21:34:36 - GraphTrainer - INFO -   precision@20: 0.004289
2025-11-22 21:34:36 - GraphTrainer - INFO -   recall@20: 0.081105
2025-11-22 21:34:36 - GraphTrainer - INFO -   hit_rate@20: 0.085369
2025-11-22 21:34:36 - GraphTrainer - INFO -   ndcg@20: 0.035442
2025-11-22 21:34:36 - GraphTrainer - INFO -   map@20: 0.022474
2025-11-22 21:34:36 - GraphTrainer - INFO -   mrr@20: 0.023417
2025-11-22 21:34:36 - GraphTrainer - INFO - 第 149 轮训练完成
2025-11-22 21:34:36 - GraphTrainer - INFO - train_loss: 0.260286
2025-11-22 21:34:36 - GraphTrainer - INFO - precision@5: 0.006778
2025-11-22 21:34:36 - GraphTrainer - INFO - recall@5: 0.032420
2025-11-22 21:34:36 - GraphTrainer - INFO - hit_rate@5: 0.033890
2025-11-22 21:34:36 - GraphTrainer - INFO - ndcg@5: 0.021727
2025-11-22 21:34:36 - GraphTrainer - INFO - map@5: 0.017973
2025-11-22 21:34:36 - GraphTrainer - INFO - mrr@5: 0.018653
2025-11-22 21:34:36 - GraphTrainer - INFO - precision@10: 0.005431
2025-11-22 21:34:36 - GraphTrainer - INFO - recall@10: 0.051445
2025-11-22 21:34:36 - GraphTrainer - INFO - hit_rate@10: 0.054153
2025-11-22 21:34:36 - GraphTrainer - INFO - ndcg@10: 0.027905
2025-11-22 21:34:36 - GraphTrainer - INFO - map@10: 0.020457
2025-11-22 21:34:36 - GraphTrainer - INFO - mrr@10: 0.021297
2025-11-22 21:34:36 - GraphTrainer - INFO - precision@20: 0.004289
2025-11-22 21:34:36 - GraphTrainer - INFO - recall@20: 0.081105
2025-11-22 21:34:36 - GraphTrainer - INFO - hit_rate@20: 0.085369
2025-11-22 21:34:36 - GraphTrainer - INFO - ndcg@20: 0.035442
2025-11-22 21:34:36 - GraphTrainer - INFO - map@20: 0.022474
2025-11-22 21:34:36 - GraphTrainer - INFO - mrr@20: 0.023417
2025-11-22 21:34:36 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:34:36 - GraphTrainer - INFO - ============================================================
2025-11-22 21:34:36 - GraphTrainer - INFO - 开始第 150/1000 轮训练
2025-11-22 21:34:36 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2699, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2537, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2729, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2614, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2413, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2596, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2418, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2584, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2584, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2561, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2640, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2545, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2671, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2756, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2692, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2552, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2696, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2517, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2708, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2420, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2507, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2698, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2448, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2570, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2512, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2616, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2606, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2692, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2738, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2806, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2572, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2671, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2435, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2356, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2587, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2638, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2595, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2644, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2660, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2780, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2528, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2713, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2589, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2717, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2489, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2649, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2659, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2828, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2384, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2413, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2533, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2699, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2473, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2842, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2551, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2611, device='cuda:0', grad_fn=<AddBackward0>)
The 149 training average loss: 0.2602862725997793
2025-11-22 21:34:47 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:34:47 - GraphTrainer - INFO -   precision@5: 0.006809
2025-11-22 21:34:47 - GraphTrainer - INFO -   recall@5: 0.032485
2025-11-22 21:34:47 - GraphTrainer - INFO -   hit_rate@5: 0.034045
2025-11-22 21:34:47 - GraphTrainer - INFO -   ndcg@5: 0.021746
2025-11-22 21:34:47 - GraphTrainer - INFO -   map@5: 0.017966
2025-11-22 21:34:47 - GraphTrainer - INFO -   mrr@5: 0.018687
2025-11-22 21:34:47 - GraphTrainer - INFO -   precision@10: 0.005369
2025-11-22 21:34:47 - GraphTrainer - INFO -   recall@10: 0.050966
2025-11-22 21:34:47 - GraphTrainer - INFO -   hit_rate@10: 0.053638
2025-11-22 21:34:47 - GraphTrainer - INFO -   ndcg@10: 0.027721
2025-11-22 21:34:47 - GraphTrainer - INFO -   map@10: 0.020362
2025-11-22 21:34:47 - GraphTrainer - INFO -   mrr@10: 0.021226
2025-11-22 21:34:47 - GraphTrainer - INFO -   precision@20: 0.004266
2025-11-22 21:34:47 - GraphTrainer - INFO -   recall@20: 0.080564
2025-11-22 21:34:47 - GraphTrainer - INFO -   hit_rate@20: 0.084958
2025-11-22 21:34:47 - GraphTrainer - INFO -   ndcg@20: 0.035264
2025-11-22 21:34:47 - GraphTrainer - INFO -   map@20: 0.022385
2025-11-22 21:34:47 - GraphTrainer - INFO -   mrr@20: 0.023362
2025-11-22 21:34:47 - GraphTrainer - INFO - 第 150 轮训练完成
2025-11-22 21:34:47 - GraphTrainer - INFO - train_loss: 0.259269
2025-11-22 21:34:47 - GraphTrainer - INFO - precision@5: 0.006809
2025-11-22 21:34:47 - GraphTrainer - INFO - recall@5: 0.032485
2025-11-22 21:34:47 - GraphTrainer - INFO - hit_rate@5: 0.034045
2025-11-22 21:34:47 - GraphTrainer - INFO - ndcg@5: 0.021746
2025-11-22 21:34:47 - GraphTrainer - INFO - map@5: 0.017966
2025-11-22 21:34:47 - GraphTrainer - INFO - mrr@5: 0.018687
2025-11-22 21:34:47 - GraphTrainer - INFO - precision@10: 0.005369
2025-11-22 21:34:47 - GraphTrainer - INFO - recall@10: 0.050966
2025-11-22 21:34:47 - GraphTrainer - INFO - hit_rate@10: 0.053638
2025-11-22 21:34:47 - GraphTrainer - INFO - ndcg@10: 0.027721
2025-11-22 21:34:47 - GraphTrainer - INFO - map@10: 0.020362
2025-11-22 21:34:47 - GraphTrainer - INFO - mrr@10: 0.021226
2025-11-22 21:34:47 - GraphTrainer - INFO - precision@20: 0.004266
2025-11-22 21:34:47 - GraphTrainer - INFO - recall@20: 0.080564
2025-11-22 21:34:47 - GraphTrainer - INFO - hit_rate@20: 0.084958
2025-11-22 21:34:47 - GraphTrainer - INFO - ndcg@20: 0.035264
2025-11-22 21:34:47 - GraphTrainer - INFO - map@20: 0.022385
2025-11-22 21:34:47 - GraphTrainer - INFO - mrr@20: 0.023362
2025-11-22 21:34:47 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:34:47 - GraphTrainer - INFO - 检查点已保存: Epoch 150 -> ./checkpoints/checkpoint_epoch_150.pth
2025-11-22 21:34:47 - GraphTrainer - INFO - ============================================================
2025-11-22 21:34:47 - GraphTrainer - INFO - 开始第 151/1000 轮训练
2025-11-22 21:34:47 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2459, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2332, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2669, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2860, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2722, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2730, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2663, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2656, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2646, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2634, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2606, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2596, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2619, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2349, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2602, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2715, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2748, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2649, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2710, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2499, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2462, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2550, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2617, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2425, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2726, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2477, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2543, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2472, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2554, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2581, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2724, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2712, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2898, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2555, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2544, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2406, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2720, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2665, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2808, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2630, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2626, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2484, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2705, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2511, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2500, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2653, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2494, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2351, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2637, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2756, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2631, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2396, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2584, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2546, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2590, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2536, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2412, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2432, device='cuda:0', grad_fn=<AddBackward0>)
The 150 training average loss: 0.2592690263328881
2025-11-22 21:34:58 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:34:58 - GraphTrainer - INFO -   precision@5: 0.006809
2025-11-22 21:34:58 - GraphTrainer - INFO -   recall@5: 0.032527
2025-11-22 21:34:58 - GraphTrainer - INFO -   hit_rate@5: 0.033993
2025-11-22 21:34:58 - GraphTrainer - INFO -   ndcg@5: 0.021610
2025-11-22 21:34:58 - GraphTrainer - INFO -   map@5: 0.017791
2025-11-22 21:34:58 - GraphTrainer - INFO -   mrr@5: 0.018458
2025-11-22 21:34:58 - GraphTrainer - INFO -   precision@10: 0.005420
2025-11-22 21:34:58 - GraphTrainer - INFO -   recall@10: 0.051550
2025-11-22 21:34:58 - GraphTrainer - INFO -   hit_rate@10: 0.054101
2025-11-22 21:34:58 - GraphTrainer - INFO -   ndcg@10: 0.027789
2025-11-22 21:34:58 - GraphTrainer - INFO -   map@10: 0.020288
2025-11-22 21:34:58 - GraphTrainer - INFO -   mrr@10: 0.021098
2025-11-22 21:34:58 - GraphTrainer - INFO -   precision@20: 0.004340
2025-11-22 21:34:58 - GraphTrainer - INFO -   recall@20: 0.082033
2025-11-22 21:34:58 - GraphTrainer - INFO -   hit_rate@20: 0.086295
2025-11-22 21:34:58 - GraphTrainer - INFO -   ndcg@20: 0.035569
2025-11-22 21:34:58 - GraphTrainer - INFO -   map@20: 0.022383
2025-11-22 21:34:58 - GraphTrainer - INFO -   mrr@20: 0.023305
2025-11-22 21:34:58 - GraphTrainer - INFO - 第 151 轮训练完成
2025-11-22 21:34:58 - GraphTrainer - INFO - train_loss: 0.258366
2025-11-22 21:34:58 - GraphTrainer - INFO - precision@5: 0.006809
2025-11-22 21:34:58 - GraphTrainer - INFO - recall@5: 0.032527
2025-11-22 21:34:58 - GraphTrainer - INFO - hit_rate@5: 0.033993
2025-11-22 21:34:58 - GraphTrainer - INFO - ndcg@5: 0.021610
2025-11-22 21:34:58 - GraphTrainer - INFO - map@5: 0.017791
2025-11-22 21:34:58 - GraphTrainer - INFO - mrr@5: 0.018458
2025-11-22 21:34:58 - GraphTrainer - INFO - precision@10: 0.005420
2025-11-22 21:34:58 - GraphTrainer - INFO - recall@10: 0.051550
2025-11-22 21:34:58 - GraphTrainer - INFO - hit_rate@10: 0.054101
2025-11-22 21:34:58 - GraphTrainer - INFO - ndcg@10: 0.027789
2025-11-22 21:34:58 - GraphTrainer - INFO - map@10: 0.020288
2025-11-22 21:34:58 - GraphTrainer - INFO - mrr@10: 0.021098
2025-11-22 21:34:58 - GraphTrainer - INFO - precision@20: 0.004340
2025-11-22 21:34:58 - GraphTrainer - INFO - recall@20: 0.082033
2025-11-22 21:34:58 - GraphTrainer - INFO - hit_rate@20: 0.086295
2025-11-22 21:34:58 - GraphTrainer - INFO - ndcg@20: 0.035569
2025-11-22 21:34:58 - GraphTrainer - INFO - map@20: 0.022383
2025-11-22 21:34:58 - GraphTrainer - INFO - mrr@20: 0.023305
2025-11-22 21:34:58 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:34:58 - GraphTrainer - INFO - ============================================================
2025-11-22 21:34:58 - GraphTrainer - INFO - 开始第 152/1000 轮训练
2025-11-22 21:34:58 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2796, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2359, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2515, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2646, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2559, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2466, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2630, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2743, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2433, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2497, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2801, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2453, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2640, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2729, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2576, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2361, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2584, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2434, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2583, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2648, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2588, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2768, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2540, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2581, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2580, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2760, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2501, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2695, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2605, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2522, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2476, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2619, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2603, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2505, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2622, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2380, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2631, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2599, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2504, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2617, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2497, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2646, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2832, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2572, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2753, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2352, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2477, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2433, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2502, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2349, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2593, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2553, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2673, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2804, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2549, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2663, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2679, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2777, device='cuda:0', grad_fn=<AddBackward0>)
The 151 training average loss: 0.2583663710232439
2025-11-22 21:35:09 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:35:09 - GraphTrainer - INFO -   precision@5: 0.006840
2025-11-22 21:35:09 - GraphTrainer - INFO -   recall@5: 0.032777
2025-11-22 21:35:09 - GraphTrainer - INFO -   hit_rate@5: 0.034199
2025-11-22 21:35:09 - GraphTrainer - INFO -   ndcg@5: 0.021810
2025-11-22 21:35:09 - GraphTrainer - INFO -   map@5: 0.017980
2025-11-22 21:35:09 - GraphTrainer - INFO -   mrr@5: 0.018648
2025-11-22 21:35:09 - GraphTrainer - INFO -   precision@10: 0.005513
2025-11-22 21:35:09 - GraphTrainer - INFO -   recall@10: 0.052372
2025-11-22 21:35:09 - GraphTrainer - INFO -   hit_rate@10: 0.055027
2025-11-22 21:35:09 - GraphTrainer - INFO -   ndcg@10: 0.028169
2025-11-22 21:35:09 - GraphTrainer - INFO -   map@10: 0.020536
2025-11-22 21:35:09 - GraphTrainer - INFO -   mrr@10: 0.021365
2025-11-22 21:35:09 - GraphTrainer - INFO -   precision@20: 0.004348
2025-11-22 21:35:09 - GraphTrainer - INFO -   recall@20: 0.082215
2025-11-22 21:35:09 - GraphTrainer - INFO -   hit_rate@20: 0.086449
2025-11-22 21:35:09 - GraphTrainer - INFO -   ndcg@20: 0.035760
2025-11-22 21:35:09 - GraphTrainer - INFO -   map@20: 0.022567
2025-11-22 21:35:09 - GraphTrainer - INFO -   mrr@20: 0.023502
2025-11-22 21:35:09 - GraphTrainer - INFO - 第 152 轮训练完成
2025-11-22 21:35:09 - GraphTrainer - INFO - train_loss: 0.258386
2025-11-22 21:35:09 - GraphTrainer - INFO - precision@5: 0.006840
2025-11-22 21:35:09 - GraphTrainer - INFO - recall@5: 0.032777
2025-11-22 21:35:09 - GraphTrainer - INFO - hit_rate@5: 0.034199
2025-11-22 21:35:09 - GraphTrainer - INFO - ndcg@5: 0.021810
2025-11-22 21:35:09 - GraphTrainer - INFO - map@5: 0.017980
2025-11-22 21:35:09 - GraphTrainer - INFO - mrr@5: 0.018648
2025-11-22 21:35:09 - GraphTrainer - INFO - precision@10: 0.005513
2025-11-22 21:35:09 - GraphTrainer - INFO - recall@10: 0.052372
2025-11-22 21:35:09 - GraphTrainer - INFO - hit_rate@10: 0.055027
2025-11-22 21:35:09 - GraphTrainer - INFO - ndcg@10: 0.028169
2025-11-22 21:35:09 - GraphTrainer - INFO - map@10: 0.020536
2025-11-22 21:35:09 - GraphTrainer - INFO - mrr@10: 0.021365
2025-11-22 21:35:09 - GraphTrainer - INFO - precision@20: 0.004348
2025-11-22 21:35:09 - GraphTrainer - INFO - recall@20: 0.082215
2025-11-22 21:35:09 - GraphTrainer - INFO - hit_rate@20: 0.086449
2025-11-22 21:35:09 - GraphTrainer - INFO - ndcg@20: 0.035760
2025-11-22 21:35:09 - GraphTrainer - INFO - map@20: 0.022567
2025-11-22 21:35:09 - GraphTrainer - INFO - mrr@20: 0.023502
2025-11-22 21:35:09 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:35:09 - GraphTrainer - INFO - ============================================================
2025-11-22 21:35:09 - GraphTrainer - INFO - 开始第 153/1000 轮训练
2025-11-22 21:35:09 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2638, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2500, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2696, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2591, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2591, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2456, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2601, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2407, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2542, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2482, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2706, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2766, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2723, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2493, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2718, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2716, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2343, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2585, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2543, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2420, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2562, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2636, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2596, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2683, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2370, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2685, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2703, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2564, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2617, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2703, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2669, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2466, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2670, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2664, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2666, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2671, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2505, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2470, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2832, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2608, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2816, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2375, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2796, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2496, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2331, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2402, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2519, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2584, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2566, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2662, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2663, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2485, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2803, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2539, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2566, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2432, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2440, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2532, device='cuda:0', grad_fn=<AddBackward0>)
The 152 training average loss: 0.258386274093184
2025-11-22 21:35:20 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:35:20 - GraphTrainer - INFO -   precision@5: 0.006974
2025-11-22 21:35:20 - GraphTrainer - INFO -   recall@5: 0.033385
2025-11-22 21:35:20 - GraphTrainer - INFO -   hit_rate@5: 0.034868
2025-11-22 21:35:20 - GraphTrainer - INFO -   ndcg@5: 0.021928
2025-11-22 21:35:20 - GraphTrainer - INFO -   map@5: 0.017929
2025-11-22 21:35:20 - GraphTrainer - INFO -   mrr@5: 0.018605
2025-11-22 21:35:20 - GraphTrainer - INFO -   precision@10: 0.005446
2025-11-22 21:35:20 - GraphTrainer - INFO -   recall@10: 0.051565
2025-11-22 21:35:20 - GraphTrainer - INFO -   hit_rate@10: 0.054358
2025-11-22 21:35:20 - GraphTrainer - INFO -   ndcg@10: 0.027817
2025-11-22 21:35:20 - GraphTrainer - INFO -   map@10: 0.020284
2025-11-22 21:35:20 - GraphTrainer - INFO -   mrr@10: 0.021117
2025-11-22 21:35:20 - GraphTrainer - INFO -   precision@20: 0.004315
2025-11-22 21:35:20 - GraphTrainer - INFO -   recall@20: 0.081282
2025-11-22 21:35:20 - GraphTrainer - INFO -   hit_rate@20: 0.085575
2025-11-22 21:35:20 - GraphTrainer - INFO -   ndcg@20: 0.035383
2025-11-22 21:35:20 - GraphTrainer - INFO -   map@20: 0.022314
2025-11-22 21:35:20 - GraphTrainer - INFO -   mrr@20: 0.023236
2025-11-22 21:35:20 - GraphTrainer - INFO - 第 153 轮训练完成
2025-11-22 21:35:20 - GraphTrainer - INFO - train_loss: 0.256554
2025-11-22 21:35:20 - GraphTrainer - INFO - precision@5: 0.006974
2025-11-22 21:35:20 - GraphTrainer - INFO - recall@5: 0.033385
2025-11-22 21:35:20 - GraphTrainer - INFO - hit_rate@5: 0.034868
2025-11-22 21:35:20 - GraphTrainer - INFO - ndcg@5: 0.021928
2025-11-22 21:35:20 - GraphTrainer - INFO - map@5: 0.017929
2025-11-22 21:35:20 - GraphTrainer - INFO - mrr@5: 0.018605
2025-11-22 21:35:20 - GraphTrainer - INFO - precision@10: 0.005446
2025-11-22 21:35:20 - GraphTrainer - INFO - recall@10: 0.051565
2025-11-22 21:35:20 - GraphTrainer - INFO - hit_rate@10: 0.054358
2025-11-22 21:35:20 - GraphTrainer - INFO - ndcg@10: 0.027817
2025-11-22 21:35:20 - GraphTrainer - INFO - map@10: 0.020284
2025-11-22 21:35:20 - GraphTrainer - INFO - mrr@10: 0.021117
2025-11-22 21:35:20 - GraphTrainer - INFO - precision@20: 0.004315
2025-11-22 21:35:20 - GraphTrainer - INFO - recall@20: 0.081282
2025-11-22 21:35:20 - GraphTrainer - INFO - hit_rate@20: 0.085575
2025-11-22 21:35:20 - GraphTrainer - INFO - ndcg@20: 0.035383
2025-11-22 21:35:20 - GraphTrainer - INFO - map@20: 0.022314
2025-11-22 21:35:20 - GraphTrainer - INFO - mrr@20: 0.023236
2025-11-22 21:35:20 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:35:20 - GraphTrainer - INFO - ============================================================
2025-11-22 21:35:20 - GraphTrainer - INFO - 开始第 154/1000 轮训练
2025-11-22 21:35:20 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2446, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2586, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2472, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2665, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2548, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2625, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2541, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2473, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2572, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2591, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2515, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2709, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2662, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2584, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2718, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2502, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2558, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2575, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2563, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2491, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2690, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2445, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2474, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2519, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2492, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2449, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2413, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2477, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2698, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2637, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2658, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2620, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2552, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2734, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2641, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2393, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2562, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2396, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2543, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2427, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2763, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2682, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2554, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2623, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2579, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2429, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2856, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2475, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2418, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2800, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2447, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2355, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2594, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2598, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2406, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2754, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2518, device='cuda:0', grad_fn=<AddBackward0>)
The 153 training average loss: 0.2565536940919942
2025-11-22 21:35:31 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:35:31 - GraphTrainer - INFO -   precision@5: 0.006932
2025-11-22 21:35:31 - GraphTrainer - INFO -   recall@5: 0.033146
2025-11-22 21:35:31 - GraphTrainer - INFO -   hit_rate@5: 0.034662
2025-11-22 21:35:31 - GraphTrainer - INFO -   ndcg@5: 0.021871
2025-11-22 21:35:31 - GraphTrainer - INFO -   map@5: 0.017916
2025-11-22 21:35:31 - GraphTrainer - INFO -   mrr@5: 0.018613
2025-11-22 21:35:31 - GraphTrainer - INFO -   precision@10: 0.005472
2025-11-22 21:35:31 - GraphTrainer - INFO -   recall@10: 0.051874
2025-11-22 21:35:31 - GraphTrainer - INFO -   hit_rate@10: 0.054667
2025-11-22 21:35:31 - GraphTrainer - INFO -   ndcg@10: 0.027943
2025-11-22 21:35:31 - GraphTrainer - INFO -   map@10: 0.020353
2025-11-22 21:35:31 - GraphTrainer - INFO -   mrr@10: 0.021207
2025-11-22 21:35:31 - GraphTrainer - INFO -   precision@20: 0.004304
2025-11-22 21:35:31 - GraphTrainer - INFO -   recall@20: 0.081404
2025-11-22 21:35:31 - GraphTrainer - INFO -   hit_rate@20: 0.085575
2025-11-22 21:35:31 - GraphTrainer - INFO -   ndcg@20: 0.035444
2025-11-22 21:35:31 - GraphTrainer - INFO -   map@20: 0.022361
2025-11-22 21:35:31 - GraphTrainer - INFO -   mrr@20: 0.023308
2025-11-22 21:35:31 - GraphTrainer - INFO - 第 154 轮训练完成
2025-11-22 21:35:31 - GraphTrainer - INFO - train_loss: 0.257739
2025-11-22 21:35:31 - GraphTrainer - INFO - precision@5: 0.006932
2025-11-22 21:35:31 - GraphTrainer - INFO - recall@5: 0.033146
2025-11-22 21:35:31 - GraphTrainer - INFO - hit_rate@5: 0.034662
2025-11-22 21:35:31 - GraphTrainer - INFO - ndcg@5: 0.021871
2025-11-22 21:35:31 - GraphTrainer - INFO - map@5: 0.017916
2025-11-22 21:35:31 - GraphTrainer - INFO - mrr@5: 0.018613
2025-11-22 21:35:31 - GraphTrainer - INFO - precision@10: 0.005472
2025-11-22 21:35:31 - GraphTrainer - INFO - recall@10: 0.051874
2025-11-22 21:35:31 - GraphTrainer - INFO - hit_rate@10: 0.054667
2025-11-22 21:35:31 - GraphTrainer - INFO - ndcg@10: 0.027943
2025-11-22 21:35:31 - GraphTrainer - INFO - map@10: 0.020353
2025-11-22 21:35:31 - GraphTrainer - INFO - mrr@10: 0.021207
2025-11-22 21:35:31 - GraphTrainer - INFO - precision@20: 0.004304
2025-11-22 21:35:31 - GraphTrainer - INFO - recall@20: 0.081404
2025-11-22 21:35:31 - GraphTrainer - INFO - hit_rate@20: 0.085575
2025-11-22 21:35:31 - GraphTrainer - INFO - ndcg@20: 0.035444
2025-11-22 21:35:31 - GraphTrainer - INFO - map@20: 0.022361
2025-11-22 21:35:31 - GraphTrainer - INFO - mrr@20: 0.023308
2025-11-22 21:35:31 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:35:31 - GraphTrainer - INFO - ============================================================
2025-11-22 21:35:31 - GraphTrainer - INFO - 开始第 155/1000 轮训练
2025-11-22 21:35:31 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2515, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2617, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2605, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2591, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2450, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2573, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2418, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2587, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2387, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2674, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2511, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2673, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2528, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2529, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2539, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2805, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2526, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2635, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2551, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2643, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2603, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2680, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2598, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2719, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2431, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2598, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2601, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2517, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2444, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2550, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2560, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2496, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2636, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2602, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2489, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2434, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2406, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2786, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2433, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2741, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2649, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2567, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2717, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2514, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2625, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2728, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2572, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2699, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2458, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2683, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2599, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2554, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2448, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2595, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2590, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2567, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2512, device='cuda:0', grad_fn=<AddBackward0>)
The 154 training average loss: 0.2577391616229353
2025-11-22 21:35:42 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:35:42 - GraphTrainer - INFO -   precision@5: 0.006943
2025-11-22 21:35:42 - GraphTrainer - INFO -   recall@5: 0.033300
2025-11-22 21:35:42 - GraphTrainer - INFO -   hit_rate@5: 0.034713
2025-11-22 21:35:42 - GraphTrainer - INFO -   ndcg@5: 0.022209
2025-11-22 21:35:42 - GraphTrainer - INFO -   map@5: 0.018334
2025-11-22 21:35:42 - GraphTrainer - INFO -   mrr@5: 0.019002
2025-11-22 21:35:42 - GraphTrainer - INFO -   precision@10: 0.005462
2025-11-22 21:35:42 - GraphTrainer - INFO -   recall@10: 0.051892
2025-11-22 21:35:42 - GraphTrainer - INFO -   hit_rate@10: 0.054564
2025-11-22 21:35:42 - GraphTrainer - INFO -   ndcg@10: 0.028250
2025-11-22 21:35:42 - GraphTrainer - INFO -   map@10: 0.020764
2025-11-22 21:35:42 - GraphTrainer - INFO -   mrr@10: 0.021591
2025-11-22 21:35:42 - GraphTrainer - INFO -   precision@20: 0.004284
2025-11-22 21:35:42 - GraphTrainer - INFO -   recall@20: 0.080861
2025-11-22 21:35:42 - GraphTrainer - INFO -   hit_rate@20: 0.085112
2025-11-22 21:35:42 - GraphTrainer - INFO -   ndcg@20: 0.035638
2025-11-22 21:35:42 - GraphTrainer - INFO -   map@20: 0.022749
2025-11-22 21:35:42 - GraphTrainer - INFO -   mrr@20: 0.023674
2025-11-22 21:35:42 - GraphTrainer - INFO - 第 155 轮训练完成
2025-11-22 21:35:42 - GraphTrainer - INFO - train_loss: 0.258345
2025-11-22 21:35:42 - GraphTrainer - INFO - precision@5: 0.006943
2025-11-22 21:35:42 - GraphTrainer - INFO - recall@5: 0.033300
2025-11-22 21:35:42 - GraphTrainer - INFO - hit_rate@5: 0.034713
2025-11-22 21:35:42 - GraphTrainer - INFO - ndcg@5: 0.022209
2025-11-22 21:35:42 - GraphTrainer - INFO - map@5: 0.018334
2025-11-22 21:35:42 - GraphTrainer - INFO - mrr@5: 0.019002
2025-11-22 21:35:42 - GraphTrainer - INFO - precision@10: 0.005462
2025-11-22 21:35:42 - GraphTrainer - INFO - recall@10: 0.051892
2025-11-22 21:35:42 - GraphTrainer - INFO - hit_rate@10: 0.054564
2025-11-22 21:35:42 - GraphTrainer - INFO - ndcg@10: 0.028250
2025-11-22 21:35:42 - GraphTrainer - INFO - map@10: 0.020764
2025-11-22 21:35:42 - GraphTrainer - INFO - mrr@10: 0.021591
2025-11-22 21:35:42 - GraphTrainer - INFO - precision@20: 0.004284
2025-11-22 21:35:42 - GraphTrainer - INFO - recall@20: 0.080861
2025-11-22 21:35:42 - GraphTrainer - INFO - hit_rate@20: 0.085112
2025-11-22 21:35:42 - GraphTrainer - INFO - ndcg@20: 0.035638
2025-11-22 21:35:42 - GraphTrainer - INFO - map@20: 0.022749
2025-11-22 21:35:42 - GraphTrainer - INFO - mrr@20: 0.023674
2025-11-22 21:35:42 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:35:42 - GraphTrainer - INFO - ============================================================
2025-11-22 21:35:42 - GraphTrainer - INFO - 开始第 156/1000 轮训练
2025-11-22 21:35:42 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2602, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2884, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2668, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2622, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2522, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2614, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2476, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2661, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2476, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2379, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2629, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2578, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2563, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2551, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2544, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2610, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2448, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2583, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2417, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2499, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2458, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2397, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2667, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2455, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2785, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2529, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2736, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2525, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2493, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2639, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2599, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2610, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2586, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2825, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2673, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2483, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2435, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2496, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2581, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2581, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2489, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2480, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2694, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2745, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2522, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2843, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2692, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2527, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2838, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2398, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2437, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2624, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2621, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2506, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2423, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2563, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2802, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2755, device='cuda:0', grad_fn=<AddBackward0>)
The 155 training average loss: 0.25834492542620363
2025-11-22 21:35:53 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:35:53 - GraphTrainer - INFO -   precision@5: 0.006963
2025-11-22 21:35:53 - GraphTrainer - INFO -   recall@5: 0.033243
2025-11-22 21:35:53 - GraphTrainer - INFO -   hit_rate@5: 0.034765
2025-11-22 21:35:53 - GraphTrainer - INFO -   ndcg@5: 0.022130
2025-11-22 21:35:53 - GraphTrainer - INFO -   map@5: 0.018218
2025-11-22 21:35:53 - GraphTrainer - INFO -   mrr@5: 0.018933
2025-11-22 21:35:53 - GraphTrainer - INFO -   precision@10: 0.005477
2025-11-22 21:35:53 - GraphTrainer - INFO -   recall@10: 0.051929
2025-11-22 21:35:53 - GraphTrainer - INFO -   hit_rate@10: 0.054667
2025-11-22 21:35:53 - GraphTrainer - INFO -   ndcg@10: 0.028232
2025-11-22 21:35:53 - GraphTrainer - INFO -   map@10: 0.020699
2025-11-22 21:35:53 - GraphTrainer - INFO -   mrr@10: 0.021572
2025-11-22 21:35:53 - GraphTrainer - INFO -   precision@20: 0.004366
2025-11-22 21:35:53 - GraphTrainer - INFO -   recall@20: 0.082632
2025-11-22 21:35:53 - GraphTrainer - INFO -   hit_rate@20: 0.086912
2025-11-22 21:35:53 - GraphTrainer - INFO -   ndcg@20: 0.036002
2025-11-22 21:35:53 - GraphTrainer - INFO -   map@20: 0.022762
2025-11-22 21:35:53 - GraphTrainer - INFO -   mrr@20: 0.023736
2025-11-22 21:35:53 - GraphTrainer - INFO - 第 156 轮训练完成
2025-11-22 21:35:53 - GraphTrainer - INFO - train_loss: 0.257241
2025-11-22 21:35:53 - GraphTrainer - INFO - precision@5: 0.006963
2025-11-22 21:35:53 - GraphTrainer - INFO - recall@5: 0.033243
2025-11-22 21:35:53 - GraphTrainer - INFO - hit_rate@5: 0.034765
2025-11-22 21:35:53 - GraphTrainer - INFO - ndcg@5: 0.022130
2025-11-22 21:35:53 - GraphTrainer - INFO - map@5: 0.018218
2025-11-22 21:35:53 - GraphTrainer - INFO - mrr@5: 0.018933
2025-11-22 21:35:53 - GraphTrainer - INFO - precision@10: 0.005477
2025-11-22 21:35:53 - GraphTrainer - INFO - recall@10: 0.051929
2025-11-22 21:35:53 - GraphTrainer - INFO - hit_rate@10: 0.054667
2025-11-22 21:35:53 - GraphTrainer - INFO - ndcg@10: 0.028232
2025-11-22 21:35:53 - GraphTrainer - INFO - map@10: 0.020699
2025-11-22 21:35:53 - GraphTrainer - INFO - mrr@10: 0.021572
2025-11-22 21:35:53 - GraphTrainer - INFO - precision@20: 0.004366
2025-11-22 21:35:53 - GraphTrainer - INFO - recall@20: 0.082632
2025-11-22 21:35:53 - GraphTrainer - INFO - hit_rate@20: 0.086912
2025-11-22 21:35:53 - GraphTrainer - INFO - ndcg@20: 0.036002
2025-11-22 21:35:53 - GraphTrainer - INFO - map@20: 0.022762
2025-11-22 21:35:53 - GraphTrainer - INFO - mrr@20: 0.023736
2025-11-22 21:35:53 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:35:53 - GraphTrainer - INFO - ============================================================
2025-11-22 21:35:53 - GraphTrainer - INFO - 开始第 157/1000 轮训练
2025-11-22 21:35:53 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2629, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2788, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2271, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2536, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2573, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2643, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2343, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2769, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2451, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2634, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2663, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2263, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2536, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2598, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2356, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2526, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2538, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2553, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2671, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2827, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2428, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2573, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2746, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2552, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2395, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2585, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2662, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2626, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2411, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2707, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2656, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2639, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2499, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2535, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2450, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2755, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2593, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2449, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2787, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2581, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2670, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2482, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2734, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2507, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2541, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2488, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2630, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2699, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2709, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2692, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2735, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2356, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2424, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2551, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2328, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2475, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2618, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2763, device='cuda:0', grad_fn=<AddBackward0>)
The 156 training average loss: 0.25724050145724725
2025-11-22 21:36:04 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:36:04 - GraphTrainer - INFO -   precision@5: 0.006840
2025-11-22 21:36:04 - GraphTrainer - INFO -   recall@5: 0.032810
2025-11-22 21:36:04 - GraphTrainer - INFO -   hit_rate@5: 0.034199
2025-11-22 21:36:04 - GraphTrainer - INFO -   ndcg@5: 0.021760
2025-11-22 21:36:04 - GraphTrainer - INFO -   map@5: 0.017895
2025-11-22 21:36:04 - GraphTrainer - INFO -   mrr@5: 0.018584
2025-11-22 21:36:04 - GraphTrainer - INFO -   precision@10: 0.005426
2025-11-22 21:36:04 - GraphTrainer - INFO -   recall@10: 0.051482
2025-11-22 21:36:04 - GraphTrainer - INFO -   hit_rate@10: 0.054153
2025-11-22 21:36:04 - GraphTrainer - INFO -   ndcg@10: 0.027850
2025-11-22 21:36:04 - GraphTrainer - INFO -   map@10: 0.020357
2025-11-22 21:36:04 - GraphTrainer - INFO -   mrr@10: 0.021211
2025-11-22 21:36:04 - GraphTrainer - INFO -   precision@20: 0.004384
2025-11-22 21:36:04 - GraphTrainer - INFO -   recall@20: 0.082661
2025-11-22 21:36:04 - GraphTrainer - INFO -   hit_rate@20: 0.087169
2025-11-22 21:36:04 - GraphTrainer - INFO -   ndcg@20: 0.035758
2025-11-22 21:36:04 - GraphTrainer - INFO -   map@20: 0.022455
2025-11-22 21:36:04 - GraphTrainer - INFO -   mrr@20: 0.023430
2025-11-22 21:36:04 - GraphTrainer - INFO - 第 157 轮训练完成
2025-11-22 21:36:04 - GraphTrainer - INFO - train_loss: 0.256158
2025-11-22 21:36:04 - GraphTrainer - INFO - precision@5: 0.006840
2025-11-22 21:36:04 - GraphTrainer - INFO - recall@5: 0.032810
2025-11-22 21:36:04 - GraphTrainer - INFO - hit_rate@5: 0.034199
2025-11-22 21:36:04 - GraphTrainer - INFO - ndcg@5: 0.021760
2025-11-22 21:36:04 - GraphTrainer - INFO - map@5: 0.017895
2025-11-22 21:36:04 - GraphTrainer - INFO - mrr@5: 0.018584
2025-11-22 21:36:04 - GraphTrainer - INFO - precision@10: 0.005426
2025-11-22 21:36:04 - GraphTrainer - INFO - recall@10: 0.051482
2025-11-22 21:36:04 - GraphTrainer - INFO - hit_rate@10: 0.054153
2025-11-22 21:36:04 - GraphTrainer - INFO - ndcg@10: 0.027850
2025-11-22 21:36:04 - GraphTrainer - INFO - map@10: 0.020357
2025-11-22 21:36:04 - GraphTrainer - INFO - mrr@10: 0.021211
2025-11-22 21:36:04 - GraphTrainer - INFO - precision@20: 0.004384
2025-11-22 21:36:04 - GraphTrainer - INFO - recall@20: 0.082661
2025-11-22 21:36:04 - GraphTrainer - INFO - hit_rate@20: 0.087169
2025-11-22 21:36:04 - GraphTrainer - INFO - ndcg@20: 0.035758
2025-11-22 21:36:04 - GraphTrainer - INFO - map@20: 0.022455
2025-11-22 21:36:04 - GraphTrainer - INFO - mrr@20: 0.023430
2025-11-22 21:36:04 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:36:04 - GraphTrainer - INFO - ============================================================
2025-11-22 21:36:04 - GraphTrainer - INFO - 开始第 158/1000 轮训练
2025-11-22 21:36:04 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2647, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2624, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2621, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2618, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2491, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2678, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2701, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2495, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2369, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2518, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2550, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2648, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2443, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2456, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2731, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2459, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2581, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2798, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2609, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2502, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2515, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2793, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2567, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2593, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2523, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2449, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2385, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2646, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2581, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2521, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2378, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2591, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2718, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2371, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2526, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2546, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2510, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2601, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2496, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2454, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2667, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2930, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2313, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2532, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2570, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2477, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2553, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2619, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2574, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2709, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2871, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2392, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2354, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2404, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2525, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2522, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2644, device='cuda:0', grad_fn=<AddBackward0>)
The 157 training average loss: 0.2561581751395916
2025-11-22 21:36:15 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:36:15 - GraphTrainer - INFO -   precision@5: 0.006747
2025-11-22 21:36:15 - GraphTrainer - INFO -   recall@5: 0.032465
2025-11-22 21:36:15 - GraphTrainer - INFO -   hit_rate@5: 0.033736
2025-11-22 21:36:15 - GraphTrainer - INFO -   ndcg@5: 0.021804
2025-11-22 21:36:15 - GraphTrainer - INFO -   map@5: 0.018085
2025-11-22 21:36:15 - GraphTrainer - INFO -   mrr@5: 0.018724
2025-11-22 21:36:15 - GraphTrainer - INFO -   precision@10: 0.005420
2025-11-22 21:36:15 - GraphTrainer - INFO -   recall@10: 0.051503
2025-11-22 21:36:15 - GraphTrainer - INFO -   hit_rate@10: 0.054101
2025-11-22 21:36:15 - GraphTrainer - INFO -   ndcg@10: 0.027989
2025-11-22 21:36:15 - GraphTrainer - INFO -   map@10: 0.020568
2025-11-22 21:36:15 - GraphTrainer - INFO -   mrr@10: 0.021379
2025-11-22 21:36:15 - GraphTrainer - INFO -   precision@20: 0.004328
2025-11-22 21:36:15 - GraphTrainer - INFO -   recall@20: 0.081789
2025-11-22 21:36:15 - GraphTrainer - INFO -   hit_rate@20: 0.086038
2025-11-22 21:36:15 - GraphTrainer - INFO -   ndcg@20: 0.035691
2025-11-22 21:36:15 - GraphTrainer - INFO -   map@20: 0.022628
2025-11-22 21:36:15 - GraphTrainer - INFO -   mrr@20: 0.023543
2025-11-22 21:36:15 - GraphTrainer - INFO - 第 158 轮训练完成
2025-11-22 21:36:15 - GraphTrainer - INFO - train_loss: 0.258007
2025-11-22 21:36:15 - GraphTrainer - INFO - precision@5: 0.006747
2025-11-22 21:36:15 - GraphTrainer - INFO - recall@5: 0.032465
2025-11-22 21:36:15 - GraphTrainer - INFO - hit_rate@5: 0.033736
2025-11-22 21:36:15 - GraphTrainer - INFO - ndcg@5: 0.021804
2025-11-22 21:36:15 - GraphTrainer - INFO - map@5: 0.018085
2025-11-22 21:36:15 - GraphTrainer - INFO - mrr@5: 0.018724
2025-11-22 21:36:15 - GraphTrainer - INFO - precision@10: 0.005420
2025-11-22 21:36:15 - GraphTrainer - INFO - recall@10: 0.051503
2025-11-22 21:36:15 - GraphTrainer - INFO - hit_rate@10: 0.054101
2025-11-22 21:36:15 - GraphTrainer - INFO - ndcg@10: 0.027989
2025-11-22 21:36:15 - GraphTrainer - INFO - map@10: 0.020568
2025-11-22 21:36:15 - GraphTrainer - INFO - mrr@10: 0.021379
2025-11-22 21:36:15 - GraphTrainer - INFO - precision@20: 0.004328
2025-11-22 21:36:15 - GraphTrainer - INFO - recall@20: 0.081789
2025-11-22 21:36:15 - GraphTrainer - INFO - hit_rate@20: 0.086038
2025-11-22 21:36:15 - GraphTrainer - INFO - ndcg@20: 0.035691
2025-11-22 21:36:15 - GraphTrainer - INFO - map@20: 0.022628
2025-11-22 21:36:15 - GraphTrainer - INFO - mrr@20: 0.023543
2025-11-22 21:36:15 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:36:15 - GraphTrainer - INFO - ============================================================
2025-11-22 21:36:15 - GraphTrainer - INFO - 开始第 159/1000 轮训练
2025-11-22 21:36:15 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2521, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2641, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2504, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2413, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2496, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2670, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2666, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2537, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2501, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2570, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2379, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2669, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2672, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2574, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2692, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2689, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2662, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2642, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2487, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2488, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2713, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2614, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2611, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2453, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2437, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2651, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2548, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2509, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2407, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2611, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2309, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2439, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2599, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2468, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2619, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2546, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2543, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2761, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2603, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2576, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2654, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2823, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2525, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2729, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2742, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2604, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2668, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2615, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2449, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2781, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2591, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2448, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2707, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2425, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2401, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2492, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2857, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2641, device='cuda:0', grad_fn=<AddBackward0>)
The 158 training average loss: 0.2580071284339346
2025-11-22 21:36:26 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:36:26 - GraphTrainer - INFO -   precision@5: 0.006871
2025-11-22 21:36:26 - GraphTrainer - INFO -   recall@5: 0.032919
2025-11-22 21:36:26 - GraphTrainer - INFO -   hit_rate@5: 0.034353
2025-11-22 21:36:26 - GraphTrainer - INFO -   ndcg@5: 0.021808
2025-11-22 21:36:26 - GraphTrainer - INFO -   map@5: 0.017923
2025-11-22 21:36:26 - GraphTrainer - INFO -   mrr@5: 0.018595
2025-11-22 21:36:26 - GraphTrainer - INFO -   precision@10: 0.005405
2025-11-22 21:36:26 - GraphTrainer - INFO -   recall@10: 0.051432
2025-11-22 21:36:26 - GraphTrainer - INFO -   hit_rate@10: 0.053998
2025-11-22 21:36:26 - GraphTrainer - INFO -   ndcg@10: 0.027833
2025-11-22 21:36:26 - GraphTrainer - INFO -   map@10: 0.020359
2025-11-22 21:36:26 - GraphTrainer - INFO -   mrr@10: 0.021175
2025-11-22 21:36:26 - GraphTrainer - INFO -   precision@20: 0.004353
2025-11-22 21:36:26 - GraphTrainer - INFO -   recall@20: 0.082414
2025-11-22 21:36:26 - GraphTrainer - INFO -   hit_rate@20: 0.086500
2025-11-22 21:36:26 - GraphTrainer - INFO -   ndcg@20: 0.035715
2025-11-22 21:36:26 - GraphTrainer - INFO -   map@20: 0.022476
2025-11-22 21:36:26 - GraphTrainer - INFO -   mrr@20: 0.023387
2025-11-22 21:36:26 - GraphTrainer - INFO - 第 159 轮训练完成
2025-11-22 21:36:26 - GraphTrainer - INFO - train_loss: 0.255850
2025-11-22 21:36:26 - GraphTrainer - INFO - precision@5: 0.006871
2025-11-22 21:36:26 - GraphTrainer - INFO - recall@5: 0.032919
2025-11-22 21:36:26 - GraphTrainer - INFO - hit_rate@5: 0.034353
2025-11-22 21:36:26 - GraphTrainer - INFO - ndcg@5: 0.021808
2025-11-22 21:36:26 - GraphTrainer - INFO - map@5: 0.017923
2025-11-22 21:36:26 - GraphTrainer - INFO - mrr@5: 0.018595
2025-11-22 21:36:26 - GraphTrainer - INFO - precision@10: 0.005405
2025-11-22 21:36:26 - GraphTrainer - INFO - recall@10: 0.051432
2025-11-22 21:36:26 - GraphTrainer - INFO - hit_rate@10: 0.053998
2025-11-22 21:36:26 - GraphTrainer - INFO - ndcg@10: 0.027833
2025-11-22 21:36:26 - GraphTrainer - INFO - map@10: 0.020359
2025-11-22 21:36:26 - GraphTrainer - INFO - mrr@10: 0.021175
2025-11-22 21:36:26 - GraphTrainer - INFO - precision@20: 0.004353
2025-11-22 21:36:26 - GraphTrainer - INFO - recall@20: 0.082414
2025-11-22 21:36:26 - GraphTrainer - INFO - hit_rate@20: 0.086500
2025-11-22 21:36:26 - GraphTrainer - INFO - ndcg@20: 0.035715
2025-11-22 21:36:26 - GraphTrainer - INFO - map@20: 0.022476
2025-11-22 21:36:26 - GraphTrainer - INFO - mrr@20: 0.023387
2025-11-22 21:36:26 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:36:26 - GraphTrainer - WARNING - 早停触发 - 第 159 轮，最佳指标: 0.083109
2025-11-22 21:36:26 - GraphTrainer - INFO - ============================================================
2025-11-22 21:36:26 - GraphTrainer - INFO - 训练完成!
2025-11-22 21:36:26 - GraphTrainer - INFO - 总训练时间: 0.49 hours
2025-11-22 21:36:26 - GraphTrainer - INFO - 最佳指标:
2025-11-22 21:36:26 - GraphTrainer - INFO -   best_precision@5: 0.006871
2025-11-22 21:36:26 - GraphTrainer - INFO -   best_recall@5: 0.032919
2025-11-22 21:36:26 - GraphTrainer - INFO -   best_hit_rate@5: 0.034353
2025-11-22 21:36:26 - GraphTrainer - INFO -   best_ndcg@5: 0.021808
2025-11-22 21:36:26 - GraphTrainer - INFO -   best_map@5: 0.017923
2025-11-22 21:36:26 - GraphTrainer - INFO -   best_mrr@5: 0.018595
2025-11-22 21:36:26 - GraphTrainer - INFO -   best_precision@10: 0.005405
2025-11-22 21:36:26 - GraphTrainer - INFO -   best_recall@10: 0.051432
2025-11-22 21:36:26 - GraphTrainer - INFO -   best_hit_rate@10: 0.053998
2025-11-22 21:36:26 - GraphTrainer - INFO -   best_ndcg@10: 0.027833
2025-11-22 21:36:26 - GraphTrainer - INFO -   best_map@10: 0.020359
2025-11-22 21:36:26 - GraphTrainer - INFO -   best_mrr@10: 0.021175
2025-11-22 21:36:26 - GraphTrainer - INFO -   best_precision@20: 0.004353
2025-11-22 21:36:26 - GraphTrainer - INFO -   best_recall@20: 0.082414
2025-11-22 21:36:26 - GraphTrainer - INFO -   best_hit_rate@20: 0.086500
2025-11-22 21:36:26 - GraphTrainer - INFO -   best_ndcg@20: 0.035715
2025-11-22 21:36:26 - GraphTrainer - INFO -   best_map@20: 0.022476
2025-11-22 21:36:26 - GraphTrainer - INFO -   best_mrr@20: 0.023387
2025-11-22 21:36:26 - GraphTrainer - INFO - ============================================================
2025-11-22 21:36:26 - GraphTrainer - INFO - Loaded best model from epoch 139
[I 2025-11-22 21:36:28,967] Trial 0 finished with value: 0.08310925960540771 and parameters: {'model.layer_num': 3, 'graph.v_k': 9, 'graph.t_k': 3, 'model.gcn_v_k': 7, 'model.gcn_t_k': 3, 'model.k': 4, 'model.alpha': 0.3344256028151724, 'model.hidden_unit': 512}. Best is trial 0 with value: 0.08310925960540771.
2025-11-22 21:36:47 - GraphTrainer - INFO - Starting training...
2025-11-22 21:36:47 - GraphTrainer - INFO - 模型: SGrec
2025-11-22 21:36:47 - GraphTrainer - INFO - 总参数量: 4,056,128
2025-11-22 21:36:47 - GraphTrainer - INFO - 可训练参数量: 4,056,128
2025-11-22 21:36:47 - GraphTrainer - INFO - ============================================================
2025-11-22 21:36:47 - GraphTrainer - INFO - 开始第 1/1000 轮训练
2025-11-22 21:36:47 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2721, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2636, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2552, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2519, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2529, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2506, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2413, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2524, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2587, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2555, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2380, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2451, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2559, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2481, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2588, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2560, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2553, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2577, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2626, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2628, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2566, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2337, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2813, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2772, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2541, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2590, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2370, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2521, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2555, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2589, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2500, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2587, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2508, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2726, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2805, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2610, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2579, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2661, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2758, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2567, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2394, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2708, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2542, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2576, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2477, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2484, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2532, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2420, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2550, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2471, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2483, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2440, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2676, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2416, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2674, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2591, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2685, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2374, device='cuda:0', grad_fn=<AddBackward0>)
The 159 training average loss: 0.2558503294813222

============================================================
FINAL RESULTS
============================================================
Training Results:
  Best epoch: 139
  Best validation metric: 0.0831
  Training time: 0.49 hours

Test Metrics:
  precision@5: 0.0073
  recall@5: 0.0330
  hit_rate@5: 0.0365
  ndcg@5: 0.0217
  map@5: 0.0173
  mrr@5: 0.0192
  precision@10: 0.0059
  recall@10: 0.0537
  hit_rate@10: 0.0588
  ndcg@10: 0.0285
  map@10: 0.0201
  mrr@10: 0.0222
  precision@20: 0.0047
  recall@20: 0.0855
  hit_rate@20: 0.0936
  ndcg@20: 0.0367
  map@20: 0.0223
  mrr@20: 0.0245
Saving results...
Results saved to ./results/results_20251122_2136.json

Training completed successfully!

############################################################
Optuna Trial 1
############################################################
Trial config (partial):
  lr=0.001, wd=0, layer_num=2, graph_v_k=4, graph_t_k=3, gcn_v_k=1, gcn_t_k=7, k=7, alpha=0.49010032836358575, beta=0.5098996716364143, hidden_unit=512
Using GPU: NVIDIA GeForce RTX 3080
============================================================
Graph-based Recommendation System
============================================================
Dataset: baby
Device: cuda
Model: SGrec
Embedding dim: 64
Epochs: 1000
============================================================
Loading data...
Initializing full dataset from ../autodl-tmp/data/ori_data/baby
Loading interaction data from ../autodl-tmp/data/ori_data/baby
Loading features from ../autodl-tmp/data/ori_data/baby
Building user-item interaction index...
Dataset Statistics:
  num_users: 19445
  num_items: 7050
  num_interactions: 160792
  sparsity: 0.9988270827520429
  user_features: []
  item_features_dimensions: {'image_feat': 4096, 'text_feat': 384}
  user_feature_dimensions: {}
  train_ratio: 0.737294143987263
  val_ratio: 0.12786083884770386
  test_ratio: 0.13484501716503308
Full dataset initialized: 160792 interactions, 19445 users, 7050 items
Splitting dataset into train/val/test...
Initializing subset dataset (mode: train) with 118551 interactions
Initializing subset dataset (mode: val) with 20559 interactions
Initializing subset dataset (mode: test) with 21682 interactions
Split results - Train: 118551 interactions, Val: 20559, Test: 21682
Data loaders created - Train batches: 58, Val batches: 11, Test batches: 11
Data loaded: 19445 users, 7050 items
User features: []
Item features: ['image_feat', 'text_feat']
Building graph and model...
Extracting training interactions for graph construction...
Extracted 118551 positive interactions for graph construction
Graph built from training data only: 26495 nodes, 263597 edges
⚠️  Important: Graph constructed using only training data to prevent data leakage
SGrec(
  (user_emb): Embedding(19445, 64)
  (item_emb): Embedding(7050, 64)
  (graph): Graph(
    (input_feat_dropout): Dropout(p=0.1, inplace=False)
    (v_ffn): Sequential(
      (0): Linear(in_features=4096, out_features=512, bias=True)
      (1): Linear(in_features=512, out_features=64, bias=True)
    )
    (t_ffn): Sequential(
      (0): Linear(in_features=384, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=64, bias=True)
    )
    (v_gcn): II_GCN(
      (x_dropout): Dropout(p=0.3, inplace=False)
      (edge_dropout): Dropout(p=0.2, inplace=False)
      (z_dropout): Dropout(p=0.3, inplace=False)
    )
    (t_gcn): II_GCN(
      (x_dropout): Dropout(p=0.3, inplace=False)
      (edge_dropout): Dropout(p=0.2, inplace=False)
      (z_dropout): Dropout(p=0.3, inplace=False)
    )
    (iu_gcn): IU_GCN(
      (x_dropout): Dropout(p=0.3, inplace=False)
      (edge_dropout): Dropout(p=0.2, inplace=False)
      (z_dropout): Dropout(p=0.3, inplace=False)
    )
    (activate): ReLU()
  )
)
Model parameters: 4,056,128
init trainer,verifier,tester
2025-11-22 21:36:58 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:36:58 - GraphTrainer - INFO -   precision@5: 0.002643
2025-11-22 21:36:58 - GraphTrainer - INFO -   recall@5: 0.012650
2025-11-22 21:36:58 - GraphTrainer - INFO -   hit_rate@5: 0.013217
2025-11-22 21:36:58 - GraphTrainer - INFO -   ndcg@5: 0.008396
2025-11-22 21:36:58 - GraphTrainer - INFO -   map@5: 0.006871
2025-11-22 21:36:58 - GraphTrainer - INFO -   mrr@5: 0.007197
2025-11-22 21:36:58 - GraphTrainer - INFO -   precision@10: 0.002088
2025-11-22 21:36:58 - GraphTrainer - INFO -   recall@10: 0.019927
2025-11-22 21:36:58 - GraphTrainer - INFO -   hit_rate@10: 0.020879
2025-11-22 21:36:58 - GraphTrainer - INFO -   ndcg@10: 0.010750
2025-11-22 21:36:58 - GraphTrainer - INFO -   map@10: 0.007822
2025-11-22 21:36:58 - GraphTrainer - INFO -   mrr@10: 0.008195
2025-11-22 21:36:58 - GraphTrainer - INFO -   precision@20: 0.001697
2025-11-22 21:36:58 - GraphTrainer - INFO -   recall@20: 0.031951
2025-11-22 21:36:58 - GraphTrainer - INFO -   hit_rate@20: 0.033839
2025-11-22 21:36:58 - GraphTrainer - INFO -   ndcg@20: 0.013873
2025-11-22 21:36:58 - GraphTrainer - INFO -   map@20: 0.008682
2025-11-22 21:36:58 - GraphTrainer - INFO -   mrr@20: 0.009118
2025-11-22 21:36:58 - GraphTrainer - INFO - 第 1 轮训练完成
2025-11-22 21:36:58 - GraphTrainer - INFO - train_loss: 0.666877
2025-11-22 21:36:58 - GraphTrainer - INFO - precision@5: 0.002643
2025-11-22 21:36:58 - GraphTrainer - INFO - recall@5: 0.012650
2025-11-22 21:36:58 - GraphTrainer - INFO - hit_rate@5: 0.013217
2025-11-22 21:36:58 - GraphTrainer - INFO - ndcg@5: 0.008396
2025-11-22 21:36:58 - GraphTrainer - INFO - map@5: 0.006871
2025-11-22 21:36:58 - GraphTrainer - INFO - mrr@5: 0.007197
2025-11-22 21:36:58 - GraphTrainer - INFO - precision@10: 0.002088
2025-11-22 21:36:58 - GraphTrainer - INFO - recall@10: 0.019927
2025-11-22 21:36:58 - GraphTrainer - INFO - hit_rate@10: 0.020879
2025-11-22 21:36:58 - GraphTrainer - INFO - ndcg@10: 0.010750
2025-11-22 21:36:58 - GraphTrainer - INFO - map@10: 0.007822
2025-11-22 21:36:58 - GraphTrainer - INFO - mrr@10: 0.008195
2025-11-22 21:36:58 - GraphTrainer - INFO - precision@20: 0.001697
2025-11-22 21:36:58 - GraphTrainer - INFO - recall@20: 0.031951
2025-11-22 21:36:58 - GraphTrainer - INFO - hit_rate@20: 0.033839
2025-11-22 21:36:58 - GraphTrainer - INFO - ndcg@20: 0.013873
2025-11-22 21:36:58 - GraphTrainer - INFO - map@20: 0.008682
2025-11-22 21:36:58 - GraphTrainer - INFO - mrr@20: 0.009118
2025-11-22 21:36:58 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:36:58 - GraphTrainer - INFO - ============================================================
2025-11-22 21:36:58 - GraphTrainer - INFO - 开始第 2/1000 轮训练
2025-11-22 21:36:58 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.6952, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.6934, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.6955, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.6922, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.6952, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.6956, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.7016, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.6922, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.6874, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.6910, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.6890, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.6819, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.6943, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.6886, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.6835, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.6831, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.6835, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.6909, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.6737, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.6914, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.6794, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.6813, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.6746, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.6724, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.6716, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.6691, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.6708, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.6652, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.6668, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.6666, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.6577, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.6621, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.6706, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.6464, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.6557, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.6479, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.6591, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.6527, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.6522, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.6539, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.6506, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.6474, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.6557, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.6478, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.6601, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.6324, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.6414, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.6477, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.6449, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.6430, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.6372, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.6387, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.6390, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.6356, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.6473, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.6491, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.6603, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.6257, device='cuda:0', grad_fn=<AddBackward0>)
The 1 training average loss: 0.6668768874530134
2025-11-22 21:37:09 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:37:09 - GraphTrainer - INFO -   precision@5: 0.003024
2025-11-22 21:37:09 - GraphTrainer - INFO -   recall@5: 0.014190
2025-11-22 21:37:09 - GraphTrainer - INFO -   hit_rate@5: 0.015120
2025-11-22 21:37:09 - GraphTrainer - INFO -   ndcg@5: 0.009676
2025-11-22 21:37:09 - GraphTrainer - INFO -   map@5: 0.008094
2025-11-22 21:37:09 - GraphTrainer - INFO -   mrr@5: 0.008462
2025-11-22 21:37:09 - GraphTrainer - INFO -   precision@10: 0.002391
2025-11-22 21:37:09 - GraphTrainer - INFO -   recall@10: 0.022543
2025-11-22 21:37:09 - GraphTrainer - INFO -   hit_rate@10: 0.023811
2025-11-22 21:37:09 - GraphTrainer - INFO -   ndcg@10: 0.012378
2025-11-22 21:37:09 - GraphTrainer - INFO -   map@10: 0.009186
2025-11-22 21:37:09 - GraphTrainer - INFO -   mrr@10: 0.009597
2025-11-22 21:37:09 - GraphTrainer - INFO -   precision@20: 0.002062
2025-11-22 21:37:09 - GraphTrainer - INFO -   recall@20: 0.038835
2025-11-22 21:37:09 - GraphTrainer - INFO -   hit_rate@20: 0.040885
2025-11-22 21:37:09 - GraphTrainer - INFO -   ndcg@20: 0.016481
2025-11-22 21:37:09 - GraphTrainer - INFO -   map@20: 0.010267
2025-11-22 21:37:09 - GraphTrainer - INFO -   mrr@20: 0.010726
2025-11-22 21:37:09 - GraphTrainer - INFO - 第 2 轮训练完成
2025-11-22 21:37:09 - GraphTrainer - INFO - train_loss: 0.609678
2025-11-22 21:37:09 - GraphTrainer - INFO - precision@5: 0.003024
2025-11-22 21:37:09 - GraphTrainer - INFO - recall@5: 0.014190
2025-11-22 21:37:09 - GraphTrainer - INFO - hit_rate@5: 0.015120
2025-11-22 21:37:09 - GraphTrainer - INFO - ndcg@5: 0.009676
2025-11-22 21:37:09 - GraphTrainer - INFO - map@5: 0.008094
2025-11-22 21:37:09 - GraphTrainer - INFO - mrr@5: 0.008462
2025-11-22 21:37:09 - GraphTrainer - INFO - precision@10: 0.002391
2025-11-22 21:37:09 - GraphTrainer - INFO - recall@10: 0.022543
2025-11-22 21:37:09 - GraphTrainer - INFO - hit_rate@10: 0.023811
2025-11-22 21:37:09 - GraphTrainer - INFO - ndcg@10: 0.012378
2025-11-22 21:37:09 - GraphTrainer - INFO - map@10: 0.009186
2025-11-22 21:37:09 - GraphTrainer - INFO - mrr@10: 0.009597
2025-11-22 21:37:09 - GraphTrainer - INFO - precision@20: 0.002062
2025-11-22 21:37:09 - GraphTrainer - INFO - recall@20: 0.038835
2025-11-22 21:37:09 - GraphTrainer - INFO - hit_rate@20: 0.040885
2025-11-22 21:37:09 - GraphTrainer - INFO - ndcg@20: 0.016481
2025-11-22 21:37:09 - GraphTrainer - INFO - map@20: 0.010267
2025-11-22 21:37:09 - GraphTrainer - INFO - mrr@20: 0.010726
2025-11-22 21:37:09 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:37:09 - GraphTrainer - INFO - ============================================================
2025-11-22 21:37:09 - GraphTrainer - INFO - 开始第 3/1000 轮训练
2025-11-22 21:37:09 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.6354, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.6337, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.6378, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.6240, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.6194, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.6363, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.6329, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.6288, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.6183, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.6314, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.6283, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.6090, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.6148, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.6192, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.6167, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.6195, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.6120, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.6234, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.6153, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.6111, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.6176, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.6126, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.6163, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.6223, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.5964, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.6040, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.6185, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.6152, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.6099, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.6122, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.6092, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.6087, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.5910, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.5816, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.5869, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.6088, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.6045, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.6063, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.5989, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.5984, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.6054, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.6078, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.5909, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.5966, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.5899, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.6033, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.6133, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.6004, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.5997, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.6125, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.5934, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.6013, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.5949, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.6010, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.5884, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.5914, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.5814, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.6031, device='cuda:0', grad_fn=<AddBackward0>)
The 2 training average loss: 0.6096779344410732
2025-11-22 21:37:20 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:37:20 - GraphTrainer - INFO -   precision@5: 0.003240
2025-11-22 21:37:20 - GraphTrainer - INFO -   recall@5: 0.015184
2025-11-22 21:37:20 - GraphTrainer - INFO -   hit_rate@5: 0.016148
2025-11-22 21:37:20 - GraphTrainer - INFO -   ndcg@5: 0.010421
2025-11-22 21:37:20 - GraphTrainer - INFO -   map@5: 0.008701
2025-11-22 21:37:20 - GraphTrainer - INFO -   mrr@5: 0.009196
2025-11-22 21:37:20 - GraphTrainer - INFO -   precision@10: 0.002813
2025-11-22 21:37:20 - GraphTrainer - INFO -   recall@10: 0.026412
2025-11-22 21:37:20 - GraphTrainer - INFO -   hit_rate@10: 0.028028
2025-11-22 21:37:20 - GraphTrainer - INFO -   ndcg@10: 0.014021
2025-11-22 21:37:20 - GraphTrainer - INFO -   map@10: 0.010130
2025-11-22 21:37:20 - GraphTrainer - INFO -   mrr@10: 0.010705
2025-11-22 21:37:20 - GraphTrainer - INFO -   precision@20: 0.002451
2025-11-22 21:37:20 - GraphTrainer - INFO -   recall@20: 0.046352
2025-11-22 21:37:20 - GraphTrainer - INFO -   hit_rate@20: 0.048753
2025-11-22 21:37:20 - GraphTrainer - INFO -   ndcg@20: 0.019125
2025-11-22 21:37:20 - GraphTrainer - INFO -   map@20: 0.011527
2025-11-22 21:37:20 - GraphTrainer - INFO -   mrr@20: 0.012152
2025-11-22 21:37:20 - GraphTrainer - INFO - 第 3 轮训练完成
2025-11-22 21:37:20 - GraphTrainer - INFO - train_loss: 0.575256
2025-11-22 21:37:20 - GraphTrainer - INFO - precision@5: 0.003240
2025-11-22 21:37:20 - GraphTrainer - INFO - recall@5: 0.015184
2025-11-22 21:37:20 - GraphTrainer - INFO - hit_rate@5: 0.016148
2025-11-22 21:37:20 - GraphTrainer - INFO - ndcg@5: 0.010421
2025-11-22 21:37:20 - GraphTrainer - INFO - map@5: 0.008701
2025-11-22 21:37:20 - GraphTrainer - INFO - mrr@5: 0.009196
2025-11-22 21:37:20 - GraphTrainer - INFO - precision@10: 0.002813
2025-11-22 21:37:20 - GraphTrainer - INFO - recall@10: 0.026412
2025-11-22 21:37:20 - GraphTrainer - INFO - hit_rate@10: 0.028028
2025-11-22 21:37:20 - GraphTrainer - INFO - ndcg@10: 0.014021
2025-11-22 21:37:20 - GraphTrainer - INFO - map@10: 0.010130
2025-11-22 21:37:20 - GraphTrainer - INFO - mrr@10: 0.010705
2025-11-22 21:37:20 - GraphTrainer - INFO - precision@20: 0.002451
2025-11-22 21:37:20 - GraphTrainer - INFO - recall@20: 0.046352
2025-11-22 21:37:20 - GraphTrainer - INFO - hit_rate@20: 0.048753
2025-11-22 21:37:20 - GraphTrainer - INFO - ndcg@20: 0.019125
2025-11-22 21:37:20 - GraphTrainer - INFO - map@20: 0.011527
2025-11-22 21:37:20 - GraphTrainer - INFO - mrr@20: 0.012152
2025-11-22 21:37:20 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:37:20 - GraphTrainer - INFO - ============================================================
2025-11-22 21:37:20 - GraphTrainer - INFO - 开始第 4/1000 轮训练
2025-11-22 21:37:20 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.5914, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.5781, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.5696, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.5790, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.5773, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.5679, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.5850, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.5876, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.5965, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.5870, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.5968, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.6036, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.5847, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.5826, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.5813, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.5814, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.5653, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.5962, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.5688, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.5856, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.5716, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.5742, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.5819, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.5932, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.5695, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.5526, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.5654, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.5929, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.5662, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.5602, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.5779, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.5656, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.5559, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.5741, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.5809, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.5514, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.5748, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.5674, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.5652, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.5790, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.5688, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.5693, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.5906, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.5743, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.5829, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.5719, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.5628, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.5685, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.5870, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.5540, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.5720, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.5564, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.5699, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.5549, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.5849, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.5573, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.5851, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.5686, device='cuda:0', grad_fn=<AddBackward0>)
The 3 training average loss: 0.5752555316892164
2025-11-22 21:37:31 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:37:31 - GraphTrainer - INFO -   precision@5: 0.003559
2025-11-22 21:37:31 - GraphTrainer - INFO -   recall@5: 0.016821
2025-11-22 21:37:31 - GraphTrainer - INFO -   hit_rate@5: 0.017691
2025-11-22 21:37:31 - GraphTrainer - INFO -   ndcg@5: 0.009969
2025-11-22 21:37:31 - GraphTrainer - INFO -   map@5: 0.007553
2025-11-22 21:37:31 - GraphTrainer - INFO -   mrr@5: 0.008061
2025-11-22 21:37:31 - GraphTrainer - INFO -   precision@10: 0.003152
2025-11-22 21:37:31 - GraphTrainer - INFO -   recall@10: 0.029758
2025-11-22 21:37:31 - GraphTrainer - INFO -   hit_rate@10: 0.031422
2025-11-22 21:37:31 - GraphTrainer - INFO -   ndcg@10: 0.014215
2025-11-22 21:37:31 - GraphTrainer - INFO -   map@10: 0.009300
2025-11-22 21:37:31 - GraphTrainer - INFO -   mrr@10: 0.009913
2025-11-22 21:37:31 - GraphTrainer - INFO -   precision@20: 0.002510
2025-11-22 21:37:31 - GraphTrainer - INFO -   recall@20: 0.047369
2025-11-22 21:37:31 - GraphTrainer - INFO -   hit_rate@20: 0.050039
2025-11-22 21:37:31 - GraphTrainer - INFO -   ndcg@20: 0.018684
2025-11-22 21:37:31 - GraphTrainer - INFO -   map@20: 0.010490
2025-11-22 21:37:31 - GraphTrainer - INFO -   mrr@20: 0.011173
2025-11-22 21:37:31 - GraphTrainer - INFO - 第 4 轮训练完成
2025-11-22 21:37:31 - GraphTrainer - INFO - train_loss: 0.553516
2025-11-22 21:37:31 - GraphTrainer - INFO - precision@5: 0.003559
2025-11-22 21:37:31 - GraphTrainer - INFO - recall@5: 0.016821
2025-11-22 21:37:31 - GraphTrainer - INFO - hit_rate@5: 0.017691
2025-11-22 21:37:31 - GraphTrainer - INFO - ndcg@5: 0.009969
2025-11-22 21:37:31 - GraphTrainer - INFO - map@5: 0.007553
2025-11-22 21:37:31 - GraphTrainer - INFO - mrr@5: 0.008061
2025-11-22 21:37:31 - GraphTrainer - INFO - precision@10: 0.003152
2025-11-22 21:37:31 - GraphTrainer - INFO - recall@10: 0.029758
2025-11-22 21:37:31 - GraphTrainer - INFO - hit_rate@10: 0.031422
2025-11-22 21:37:31 - GraphTrainer - INFO - ndcg@10: 0.014215
2025-11-22 21:37:31 - GraphTrainer - INFO - map@10: 0.009300
2025-11-22 21:37:31 - GraphTrainer - INFO - mrr@10: 0.009913
2025-11-22 21:37:31 - GraphTrainer - INFO - precision@20: 0.002510
2025-11-22 21:37:31 - GraphTrainer - INFO - recall@20: 0.047369
2025-11-22 21:37:31 - GraphTrainer - INFO - hit_rate@20: 0.050039
2025-11-22 21:37:31 - GraphTrainer - INFO - ndcg@20: 0.018684
2025-11-22 21:37:31 - GraphTrainer - INFO - map@20: 0.010490
2025-11-22 21:37:31 - GraphTrainer - INFO - mrr@20: 0.011173
2025-11-22 21:37:31 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:37:31 - GraphTrainer - INFO - ============================================================
2025-11-22 21:37:31 - GraphTrainer - INFO - 开始第 5/1000 轮训练
2025-11-22 21:37:31 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.5565, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.5634, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.5391, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.5443, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.5866, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.5397, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.5631, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.5440, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.5571, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.5743, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.5713, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.5618, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.5501, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.5528, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.5615, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.5556, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.5574, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.5471, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.5616, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.5510, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.5464, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.5521, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.5586, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.5549, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.5420, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.5496, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.5618, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.5616, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.5627, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.5555, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.5556, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.5448, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.5550, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.5538, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.5518, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.5504, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.5820, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.5560, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.5642, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.5512, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.5708, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.5433, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.5721, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.5440, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.5346, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.5520, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.5596, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.5519, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.5492, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.5480, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.5604, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.5434, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.5505, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.5354, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.5434, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.5411, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.5309, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.5251, device='cuda:0', grad_fn=<AddBackward0>)
The 4 training average loss: 0.5535162862004905
2025-11-22 21:37:42 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:37:42 - GraphTrainer - INFO -   precision@5: 0.003507
2025-11-22 21:37:42 - GraphTrainer - INFO -   recall@5: 0.016642
2025-11-22 21:37:42 - GraphTrainer - INFO -   hit_rate@5: 0.017485
2025-11-22 21:37:42 - GraphTrainer - INFO -   ndcg@5: 0.010572
2025-11-22 21:37:42 - GraphTrainer - INFO -   map@5: 0.008451
2025-11-22 21:37:42 - GraphTrainer - INFO -   mrr@5: 0.008845
2025-11-22 21:37:42 - GraphTrainer - INFO -   precision@10: 0.003132
2025-11-22 21:37:42 - GraphTrainer - INFO -   recall@10: 0.029922
2025-11-22 21:37:42 - GraphTrainer - INFO -   hit_rate@10: 0.031216
2025-11-22 21:37:42 - GraphTrainer - INFO -   ndcg@10: 0.014817
2025-11-22 21:37:42 - GraphTrainer - INFO -   map@10: 0.010148
2025-11-22 21:37:42 - GraphTrainer - INFO -   mrr@10: 0.010598
2025-11-22 21:37:42 - GraphTrainer - INFO -   precision@20: 0.002777
2025-11-22 21:37:42 - GraphTrainer - INFO -   recall@20: 0.052687
2025-11-22 21:37:42 - GraphTrainer - INFO -   hit_rate@20: 0.055233
2025-11-22 21:37:42 - GraphTrainer - INFO -   ndcg@20: 0.020591
2025-11-22 21:37:42 - GraphTrainer - INFO -   map@20: 0.011686
2025-11-22 21:37:42 - GraphTrainer - INFO -   mrr@20: 0.012217
2025-11-22 21:37:42 - GraphTrainer - INFO - 第 5 轮训练完成
2025-11-22 21:37:42 - GraphTrainer - INFO - train_loss: 0.534075
2025-11-22 21:37:42 - GraphTrainer - INFO - precision@5: 0.003507
2025-11-22 21:37:42 - GraphTrainer - INFO - recall@5: 0.016642
2025-11-22 21:37:42 - GraphTrainer - INFO - hit_rate@5: 0.017485
2025-11-22 21:37:42 - GraphTrainer - INFO - ndcg@5: 0.010572
2025-11-22 21:37:42 - GraphTrainer - INFO - map@5: 0.008451
2025-11-22 21:37:42 - GraphTrainer - INFO - mrr@5: 0.008845
2025-11-22 21:37:42 - GraphTrainer - INFO - precision@10: 0.003132
2025-11-22 21:37:42 - GraphTrainer - INFO - recall@10: 0.029922
2025-11-22 21:37:42 - GraphTrainer - INFO - hit_rate@10: 0.031216
2025-11-22 21:37:42 - GraphTrainer - INFO - ndcg@10: 0.014817
2025-11-22 21:37:42 - GraphTrainer - INFO - map@10: 0.010148
2025-11-22 21:37:42 - GraphTrainer - INFO - mrr@10: 0.010598
2025-11-22 21:37:42 - GraphTrainer - INFO - precision@20: 0.002777
2025-11-22 21:37:42 - GraphTrainer - INFO - recall@20: 0.052687
2025-11-22 21:37:42 - GraphTrainer - INFO - hit_rate@20: 0.055233
2025-11-22 21:37:42 - GraphTrainer - INFO - ndcg@20: 0.020591
2025-11-22 21:37:42 - GraphTrainer - INFO - map@20: 0.011686
2025-11-22 21:37:42 - GraphTrainer - INFO - mrr@20: 0.012217
2025-11-22 21:37:42 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:37:42 - GraphTrainer - INFO - ============================================================
2025-11-22 21:37:42 - GraphTrainer - INFO - 开始第 6/1000 轮训练
2025-11-22 21:37:42 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.5731, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.5378, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.5490, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.5403, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.5354, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.5435, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.5278, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.5449, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.5321, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.5204, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.5317, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.5152, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.5324, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.5345, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.5413, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.5211, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.5424, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.5393, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.5104, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.5332, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.5169, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.5413, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.5355, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.5253, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.5436, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.5479, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.5704, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.5517, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.5456, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.5253, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.5341, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.5282, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.5278, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.5514, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.5490, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.5310, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.5153, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.5203, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.5413, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.5344, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.5364, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.5125, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.5298, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.5309, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.5378, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.5360, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.5246, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.5358, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.5131, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.5430, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.5242, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.5270, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.5301, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.5299, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.5252, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.5341, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.5340, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.5299, device='cuda:0', grad_fn=<AddBackward0>)
The 5 training average loss: 0.534075311545668
2025-11-22 21:37:53 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:37:53 - GraphTrainer - INFO -   precision@5: 0.003579
2025-11-22 21:37:53 - GraphTrainer - INFO -   recall@5: 0.016951
2025-11-22 21:37:53 - GraphTrainer - INFO -   hit_rate@5: 0.017845
2025-11-22 21:37:53 - GraphTrainer - INFO -   ndcg@5: 0.009903
2025-11-22 21:37:53 - GraphTrainer - INFO -   map@5: 0.007459
2025-11-22 21:37:53 - GraphTrainer - INFO -   mrr@5: 0.007920
2025-11-22 21:37:53 - GraphTrainer - INFO -   precision@10: 0.003276
2025-11-22 21:37:53 - GraphTrainer - INFO -   recall@10: 0.031079
2025-11-22 21:37:53 - GraphTrainer - INFO -   hit_rate@10: 0.032708
2025-11-22 21:37:53 - GraphTrainer - INFO -   ndcg@10: 0.014412
2025-11-22 21:37:53 - GraphTrainer - INFO -   map@10: 0.009244
2025-11-22 21:37:53 - GraphTrainer - INFO -   mrr@10: 0.009791
2025-11-22 21:37:53 - GraphTrainer - INFO -   precision@20: 0.002906
2025-11-22 21:37:53 - GraphTrainer - INFO -   recall@20: 0.055240
2025-11-22 21:37:53 - GraphTrainer - INFO -   hit_rate@20: 0.057907
2025-11-22 21:37:53 - GraphTrainer - INFO -   ndcg@20: 0.020551
2025-11-22 21:37:53 - GraphTrainer - INFO -   map@20: 0.010898
2025-11-22 21:37:53 - GraphTrainer - INFO -   mrr@20: 0.011516
2025-11-22 21:37:53 - GraphTrainer - INFO - 第 6 轮训练完成
2025-11-22 21:37:53 - GraphTrainer - INFO - train_loss: 0.517222
2025-11-22 21:37:53 - GraphTrainer - INFO - precision@5: 0.003579
2025-11-22 21:37:53 - GraphTrainer - INFO - recall@5: 0.016951
2025-11-22 21:37:53 - GraphTrainer - INFO - hit_rate@5: 0.017845
2025-11-22 21:37:53 - GraphTrainer - INFO - ndcg@5: 0.009903
2025-11-22 21:37:53 - GraphTrainer - INFO - map@5: 0.007459
2025-11-22 21:37:53 - GraphTrainer - INFO - mrr@5: 0.007920
2025-11-22 21:37:53 - GraphTrainer - INFO - precision@10: 0.003276
2025-11-22 21:37:53 - GraphTrainer - INFO - recall@10: 0.031079
2025-11-22 21:37:53 - GraphTrainer - INFO - hit_rate@10: 0.032708
2025-11-22 21:37:53 - GraphTrainer - INFO - ndcg@10: 0.014412
2025-11-22 21:37:53 - GraphTrainer - INFO - map@10: 0.009244
2025-11-22 21:37:53 - GraphTrainer - INFO - mrr@10: 0.009791
2025-11-22 21:37:53 - GraphTrainer - INFO - precision@20: 0.002906
2025-11-22 21:37:53 - GraphTrainer - INFO - recall@20: 0.055240
2025-11-22 21:37:53 - GraphTrainer - INFO - hit_rate@20: 0.057907
2025-11-22 21:37:53 - GraphTrainer - INFO - ndcg@20: 0.020551
2025-11-22 21:37:53 - GraphTrainer - INFO - map@20: 0.010898
2025-11-22 21:37:53 - GraphTrainer - INFO - mrr@20: 0.011516
2025-11-22 21:37:53 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:37:53 - GraphTrainer - INFO - ============================================================
2025-11-22 21:37:53 - GraphTrainer - INFO - 开始第 7/1000 轮训练
2025-11-22 21:37:53 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.5360, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.5297, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.5426, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.5159, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.5184, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.5159, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.5173, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.5093, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.5142, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.5217, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.5248, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.5116, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.5186, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.5004, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.5233, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.5232, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.5337, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.5092, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.5220, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.5159, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.5150, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.5347, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.5162, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.5172, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.5154, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.5194, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.5088, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.5070, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.5060, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.5135, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.5302, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.5167, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4843, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4948, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.5368, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.5090, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.5161, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.5352, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.5250, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.5242, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.5189, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.5211, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.5204, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4989, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.5000, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.5157, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.5360, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.5267, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.5038, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.5071, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.5257, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.5137, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.5062, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.5081, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.5051, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.5176, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.5180, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.5262, device='cuda:0', grad_fn=<AddBackward0>)
The 6 training average loss: 0.5172216311610979
2025-11-22 21:38:04 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:38:04 - GraphTrainer - INFO -   precision@5: 0.004238
2025-11-22 21:38:04 - GraphTrainer - INFO -   recall@5: 0.020049
2025-11-22 21:38:04 - GraphTrainer - INFO -   hit_rate@5: 0.021137
2025-11-22 21:38:04 - GraphTrainer - INFO -   ndcg@5: 0.013053
2025-11-22 21:38:04 - GraphTrainer - INFO -   map@5: 0.010602
2025-11-22 21:38:04 - GraphTrainer - INFO -   mrr@5: 0.011145
2025-11-22 21:38:04 - GraphTrainer - INFO -   precision@10: 0.003554
2025-11-22 21:38:04 - GraphTrainer - INFO -   recall@10: 0.033778
2025-11-22 21:38:04 - GraphTrainer - INFO -   hit_rate@10: 0.035433
2025-11-22 21:38:04 - GraphTrainer - INFO -   ndcg@10: 0.017464
2025-11-22 21:38:04 - GraphTrainer - INFO -   map@10: 0.012374
2025-11-22 21:38:04 - GraphTrainer - INFO -   mrr@10: 0.012988
2025-11-22 21:38:04 - GraphTrainer - INFO -   precision@20: 0.002864
2025-11-22 21:38:04 - GraphTrainer - INFO -   recall@20: 0.054497
2025-11-22 21:38:04 - GraphTrainer - INFO -   hit_rate@20: 0.057033
2025-11-22 21:38:04 - GraphTrainer - INFO -   ndcg@20: 0.022720
2025-11-22 21:38:04 - GraphTrainer - INFO -   map@20: 0.013788
2025-11-22 21:38:04 - GraphTrainer - INFO -   mrr@20: 0.014453
2025-11-22 21:38:04 - GraphTrainer - INFO - 第 7 轮训练完成
2025-11-22 21:38:04 - GraphTrainer - INFO - train_loss: 0.507531
2025-11-22 21:38:04 - GraphTrainer - INFO - precision@5: 0.004238
2025-11-22 21:38:04 - GraphTrainer - INFO - recall@5: 0.020049
2025-11-22 21:38:04 - GraphTrainer - INFO - hit_rate@5: 0.021137
2025-11-22 21:38:04 - GraphTrainer - INFO - ndcg@5: 0.013053
2025-11-22 21:38:04 - GraphTrainer - INFO - map@5: 0.010602
2025-11-22 21:38:04 - GraphTrainer - INFO - mrr@5: 0.011145
2025-11-22 21:38:04 - GraphTrainer - INFO - precision@10: 0.003554
2025-11-22 21:38:04 - GraphTrainer - INFO - recall@10: 0.033778
2025-11-22 21:38:04 - GraphTrainer - INFO - hit_rate@10: 0.035433
2025-11-22 21:38:04 - GraphTrainer - INFO - ndcg@10: 0.017464
2025-11-22 21:38:04 - GraphTrainer - INFO - map@10: 0.012374
2025-11-22 21:38:04 - GraphTrainer - INFO - mrr@10: 0.012988
2025-11-22 21:38:04 - GraphTrainer - INFO - precision@20: 0.002864
2025-11-22 21:38:04 - GraphTrainer - INFO - recall@20: 0.054497
2025-11-22 21:38:04 - GraphTrainer - INFO - hit_rate@20: 0.057033
2025-11-22 21:38:04 - GraphTrainer - INFO - ndcg@20: 0.022720
2025-11-22 21:38:04 - GraphTrainer - INFO - map@20: 0.013788
2025-11-22 21:38:04 - GraphTrainer - INFO - mrr@20: 0.014453
2025-11-22 21:38:04 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:38:04 - GraphTrainer - INFO - ============================================================
2025-11-22 21:38:04 - GraphTrainer - INFO - 开始第 8/1000 轮训练
2025-11-22 21:38:04 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.5125, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4981, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4976, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.5093, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.5278, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.5305, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4927, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.5155, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.5124, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.5139, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.5094, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4950, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.5105, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.5243, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.5131, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.5107, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.5038, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4912, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4927, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4813, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.5095, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4916, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.5082, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.5149, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.5098, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.5054, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.5217, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.5187, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.5020, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.5226, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.5094, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.5069, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.5075, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.5044, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.5214, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.5121, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.5188, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.5076, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.5030, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.5010, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.5015, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4956, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.5196, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4906, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.5041, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.5017, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.5013, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.5247, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.5068, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.5199, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4975, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.5095, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.5011, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.5033, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4956, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.5043, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.5198, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.5010, device='cuda:0', grad_fn=<AddBackward0>)
The 7 training average loss: 0.5075312595942925
2025-11-22 21:38:15 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:38:15 - GraphTrainer - INFO -   precision@5: 0.004443
2025-11-22 21:38:15 - GraphTrainer - INFO -   recall@5: 0.021043
2025-11-22 21:38:15 - GraphTrainer - INFO -   hit_rate@5: 0.022114
2025-11-22 21:38:15 - GraphTrainer - INFO -   ndcg@5: 0.014267
2025-11-22 21:38:15 - GraphTrainer - INFO -   map@5: 0.011870
2025-11-22 21:38:15 - GraphTrainer - INFO -   mrr@5: 0.012285
2025-11-22 21:38:15 - GraphTrainer - INFO -   precision@10: 0.003456
2025-11-22 21:38:15 - GraphTrainer - INFO -   recall@10: 0.032803
2025-11-22 21:38:15 - GraphTrainer - INFO -   hit_rate@10: 0.034456
2025-11-22 21:38:15 - GraphTrainer - INFO -   ndcg@10: 0.018070
2025-11-22 21:38:15 - GraphTrainer - INFO -   map@10: 0.013408
2025-11-22 21:38:15 - GraphTrainer - INFO -   mrr@10: 0.013889
2025-11-22 21:38:15 - GraphTrainer - INFO -   precision@20: 0.002872
2025-11-22 21:38:15 - GraphTrainer - INFO -   recall@20: 0.054425
2025-11-22 21:38:15 - GraphTrainer - INFO -   hit_rate@20: 0.057187
2025-11-22 21:38:15 - GraphTrainer - INFO -   ndcg@20: 0.023545
2025-11-22 21:38:15 - GraphTrainer - INFO -   map@20: 0.014866
2025-11-22 21:38:15 - GraphTrainer - INFO -   mrr@20: 0.015421
2025-11-22 21:38:15 - GraphTrainer - INFO - 第 8 轮训练完成
2025-11-22 21:38:15 - GraphTrainer - INFO - train_loss: 0.492096
2025-11-22 21:38:15 - GraphTrainer - INFO - precision@5: 0.004443
2025-11-22 21:38:15 - GraphTrainer - INFO - recall@5: 0.021043
2025-11-22 21:38:15 - GraphTrainer - INFO - hit_rate@5: 0.022114
2025-11-22 21:38:15 - GraphTrainer - INFO - ndcg@5: 0.014267
2025-11-22 21:38:15 - GraphTrainer - INFO - map@5: 0.011870
2025-11-22 21:38:15 - GraphTrainer - INFO - mrr@5: 0.012285
2025-11-22 21:38:15 - GraphTrainer - INFO - precision@10: 0.003456
2025-11-22 21:38:15 - GraphTrainer - INFO - recall@10: 0.032803
2025-11-22 21:38:15 - GraphTrainer - INFO - hit_rate@10: 0.034456
2025-11-22 21:38:15 - GraphTrainer - INFO - ndcg@10: 0.018070
2025-11-22 21:38:15 - GraphTrainer - INFO - map@10: 0.013408
2025-11-22 21:38:15 - GraphTrainer - INFO - mrr@10: 0.013889
2025-11-22 21:38:15 - GraphTrainer - INFO - precision@20: 0.002872
2025-11-22 21:38:15 - GraphTrainer - INFO - recall@20: 0.054425
2025-11-22 21:38:15 - GraphTrainer - INFO - hit_rate@20: 0.057187
2025-11-22 21:38:15 - GraphTrainer - INFO - ndcg@20: 0.023545
2025-11-22 21:38:15 - GraphTrainer - INFO - map@20: 0.014866
2025-11-22 21:38:15 - GraphTrainer - INFO - mrr@20: 0.015421
2025-11-22 21:38:15 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:38:15 - GraphTrainer - INFO - ============================================================
2025-11-22 21:38:15 - GraphTrainer - INFO - 开始第 9/1000 轮训练
2025-11-22 21:38:15 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4913, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.5123, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.5024, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4907, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.5242, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.5019, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4934, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.5095, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4969, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.5021, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4896, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4974, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4816, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4862, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4854, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4768, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.5179, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.5122, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4865, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4756, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.5043, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4829, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4890, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4960, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4936, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.5070, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4871, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4897, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4739, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.5016, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.5008, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4972, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4985, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4720, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.5070, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4928, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4804, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4795, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4830, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4874, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4975, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4836, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.5009, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.5110, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.5021, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4603, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4669, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4870, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4965, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4968, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.5014, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4792, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4856, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4937, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4698, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4861, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4889, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4767, device='cuda:0', grad_fn=<AddBackward0>)
The 8 training average loss: 0.4920963526799761
2025-11-22 21:38:26 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:38:26 - GraphTrainer - INFO -   precision@5: 0.003970
2025-11-22 21:38:26 - GraphTrainer - INFO -   recall@5: 0.019035
2025-11-22 21:38:26 - GraphTrainer - INFO -   hit_rate@5: 0.019851
2025-11-22 21:38:26 - GraphTrainer - INFO -   ndcg@5: 0.011630
2025-11-22 21:38:26 - GraphTrainer - INFO -   map@5: 0.009075
2025-11-22 21:38:26 - GraphTrainer - INFO -   mrr@5: 0.009499
2025-11-22 21:38:26 - GraphTrainer - INFO -   precision@10: 0.003518
2025-11-22 21:38:26 - GraphTrainer - INFO -   recall@10: 0.033555
2025-11-22 21:38:26 - GraphTrainer - INFO -   hit_rate@10: 0.035125
2025-11-22 21:38:26 - GraphTrainer - INFO -   ndcg@10: 0.016289
2025-11-22 21:38:26 - GraphTrainer - INFO -   map@10: 0.010928
2025-11-22 21:38:26 - GraphTrainer - INFO -   mrr@10: 0.011447
2025-11-22 21:38:26 - GraphTrainer - INFO -   precision@20: 0.002970
2025-11-22 21:38:26 - GraphTrainer - INFO -   recall@20: 0.056164
2025-11-22 21:38:26 - GraphTrainer - INFO -   hit_rate@20: 0.058884
2025-11-22 21:38:26 - GraphTrainer - INFO -   ndcg@20: 0.022033
2025-11-22 21:38:26 - GraphTrainer - INFO -   map@20: 0.012463
2025-11-22 21:38:26 - GraphTrainer - INFO -   mrr@20: 0.013050
2025-11-22 21:38:26 - GraphTrainer - INFO - 第 9 轮训练完成
2025-11-22 21:38:26 - GraphTrainer - INFO - train_loss: 0.484695
2025-11-22 21:38:26 - GraphTrainer - INFO - precision@5: 0.003970
2025-11-22 21:38:26 - GraphTrainer - INFO - recall@5: 0.019035
2025-11-22 21:38:26 - GraphTrainer - INFO - hit_rate@5: 0.019851
2025-11-22 21:38:26 - GraphTrainer - INFO - ndcg@5: 0.011630
2025-11-22 21:38:26 - GraphTrainer - INFO - map@5: 0.009075
2025-11-22 21:38:26 - GraphTrainer - INFO - mrr@5: 0.009499
2025-11-22 21:38:26 - GraphTrainer - INFO - precision@10: 0.003518
2025-11-22 21:38:26 - GraphTrainer - INFO - recall@10: 0.033555
2025-11-22 21:38:26 - GraphTrainer - INFO - hit_rate@10: 0.035125
2025-11-22 21:38:26 - GraphTrainer - INFO - ndcg@10: 0.016289
2025-11-22 21:38:26 - GraphTrainer - INFO - map@10: 0.010928
2025-11-22 21:38:26 - GraphTrainer - INFO - mrr@10: 0.011447
2025-11-22 21:38:26 - GraphTrainer - INFO - precision@20: 0.002970
2025-11-22 21:38:26 - GraphTrainer - INFO - recall@20: 0.056164
2025-11-22 21:38:26 - GraphTrainer - INFO - hit_rate@20: 0.058884
2025-11-22 21:38:26 - GraphTrainer - INFO - ndcg@20: 0.022033
2025-11-22 21:38:26 - GraphTrainer - INFO - map@20: 0.012463
2025-11-22 21:38:26 - GraphTrainer - INFO - mrr@20: 0.013050
2025-11-22 21:38:26 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:38:26 - GraphTrainer - INFO - ============================================================
2025-11-22 21:38:26 - GraphTrainer - INFO - 开始第 10/1000 轮训练
2025-11-22 21:38:26 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4785, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4687, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4814, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4904, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4813, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4940, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4975, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4847, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4744, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4819, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4856, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4715, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4853, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4985, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4928, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.5087, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4698, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4600, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4983, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4989, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4649, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4860, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4937, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4943, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4746, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4848, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.5011, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4789, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4814, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4876, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4994, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4841, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4769, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4772, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4836, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4952, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4712, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.5039, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4785, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4981, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4589, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4911, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4843, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.5114, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4853, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4892, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.5034, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4674, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4905, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4694, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4775, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4749, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4821, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4753, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4673, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4727, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4904, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.5036, device='cuda:0', grad_fn=<AddBackward0>)
The 9 training average loss: 0.4846948693538534
2025-11-22 21:38:37 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:38:37 - GraphTrainer - INFO -   precision@5: 0.004587
2025-11-22 21:38:37 - GraphTrainer - INFO -   recall@5: 0.021927
2025-11-22 21:38:37 - GraphTrainer - INFO -   hit_rate@5: 0.022885
2025-11-22 21:38:37 - GraphTrainer - INFO -   ndcg@5: 0.014358
2025-11-22 21:38:37 - GraphTrainer - INFO -   map@5: 0.011711
2025-11-22 21:38:37 - GraphTrainer - INFO -   mrr@5: 0.012199
2025-11-22 21:38:37 - GraphTrainer - INFO -   precision@10: 0.003785
2025-11-22 21:38:37 - GraphTrainer - INFO -   recall@10: 0.036070
2025-11-22 21:38:37 - GraphTrainer - INFO -   hit_rate@10: 0.037747
2025-11-22 21:38:37 - GraphTrainer - INFO -   ndcg@10: 0.018945
2025-11-22 21:38:37 - GraphTrainer - INFO -   map@10: 0.013570
2025-11-22 21:38:37 - GraphTrainer - INFO -   mrr@10: 0.014145
2025-11-22 21:38:37 - GraphTrainer - INFO -   precision@20: 0.003070
2025-11-22 21:38:37 - GraphTrainer - INFO -   recall@20: 0.058489
2025-11-22 21:38:37 - GraphTrainer - INFO -   hit_rate@20: 0.061147
2025-11-22 21:38:37 - GraphTrainer - INFO -   ndcg@20: 0.024608
2025-11-22 21:38:37 - GraphTrainer - INFO -   map@20: 0.015076
2025-11-22 21:38:37 - GraphTrainer - INFO -   mrr@20: 0.015718
2025-11-22 21:38:37 - GraphTrainer - INFO - 第 10 轮训练完成
2025-11-22 21:38:37 - GraphTrainer - INFO - train_loss: 0.474246
2025-11-22 21:38:37 - GraphTrainer - INFO - precision@5: 0.004587
2025-11-22 21:38:37 - GraphTrainer - INFO - recall@5: 0.021927
2025-11-22 21:38:37 - GraphTrainer - INFO - hit_rate@5: 0.022885
2025-11-22 21:38:37 - GraphTrainer - INFO - ndcg@5: 0.014358
2025-11-22 21:38:37 - GraphTrainer - INFO - map@5: 0.011711
2025-11-22 21:38:37 - GraphTrainer - INFO - mrr@5: 0.012199
2025-11-22 21:38:37 - GraphTrainer - INFO - precision@10: 0.003785
2025-11-22 21:38:37 - GraphTrainer - INFO - recall@10: 0.036070
2025-11-22 21:38:37 - GraphTrainer - INFO - hit_rate@10: 0.037747
2025-11-22 21:38:37 - GraphTrainer - INFO - ndcg@10: 0.018945
2025-11-22 21:38:37 - GraphTrainer - INFO - map@10: 0.013570
2025-11-22 21:38:37 - GraphTrainer - INFO - mrr@10: 0.014145
2025-11-22 21:38:37 - GraphTrainer - INFO - precision@20: 0.003070
2025-11-22 21:38:37 - GraphTrainer - INFO - recall@20: 0.058489
2025-11-22 21:38:37 - GraphTrainer - INFO - hit_rate@20: 0.061147
2025-11-22 21:38:37 - GraphTrainer - INFO - ndcg@20: 0.024608
2025-11-22 21:38:37 - GraphTrainer - INFO - map@20: 0.015076
2025-11-22 21:38:37 - GraphTrainer - INFO - mrr@20: 0.015718
2025-11-22 21:38:37 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:38:37 - GraphTrainer - INFO - 检查点已保存: Epoch 10 -> ./checkpoints/checkpoint_epoch_10.pth
2025-11-22 21:38:37 - GraphTrainer - INFO - ============================================================
2025-11-22 21:38:37 - GraphTrainer - INFO - 开始第 11/1000 轮训练
2025-11-22 21:38:37 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4915, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4774, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4734, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4521, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4838, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4645, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4684, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4836, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4810, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4661, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4740, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4786, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4799, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4547, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4592, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4731, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4622, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4654, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4647, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4809, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4755, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4574, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4898, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4864, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4711, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4647, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4744, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4872, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4845, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4867, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4716, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4580, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4795, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4780, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4772, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4749, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4771, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4799, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4681, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4804, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4618, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4884, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4765, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4667, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4688, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4739, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4755, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4568, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4764, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4616, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4616, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4882, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.5121, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4671, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4735, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4732, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4720, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4951, device='cuda:0', grad_fn=<AddBackward0>)
The 10 training average loss: 0.47424560476993693
2025-11-22 21:38:48 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:38:48 - GraphTrainer - INFO -   precision@5: 0.004670
2025-11-22 21:38:48 - GraphTrainer - INFO -   recall@5: 0.022265
2025-11-22 21:38:48 - GraphTrainer - INFO -   hit_rate@5: 0.023296
2025-11-22 21:38:48 - GraphTrainer - INFO -   ndcg@5: 0.014721
2025-11-22 21:38:48 - GraphTrainer - INFO -   map@5: 0.012066
2025-11-22 21:38:48 - GraphTrainer - INFO -   mrr@5: 0.012635
2025-11-22 21:38:48 - GraphTrainer - INFO -   precision@10: 0.003975
2025-11-22 21:38:48 - GraphTrainer - INFO -   recall@10: 0.037923
2025-11-22 21:38:48 - GraphTrainer - INFO -   hit_rate@10: 0.039650
2025-11-22 21:38:48 - GraphTrainer - INFO -   ndcg@10: 0.019762
2025-11-22 21:38:48 - GraphTrainer - INFO -   map@10: 0.014096
2025-11-22 21:38:48 - GraphTrainer - INFO -   mrr@10: 0.014753
2025-11-22 21:38:48 - GraphTrainer - INFO -   precision@20: 0.003209
2025-11-22 21:38:48 - GraphTrainer - INFO -   recall@20: 0.060678
2025-11-22 21:38:48 - GraphTrainer - INFO -   hit_rate@20: 0.063924
2025-11-22 21:38:48 - GraphTrainer - INFO -   ndcg@20: 0.025526
2025-11-22 21:38:48 - GraphTrainer - INFO -   map@20: 0.015618
2025-11-22 21:38:48 - GraphTrainer - INFO -   mrr@20: 0.016378
2025-11-22 21:38:48 - GraphTrainer - INFO - 第 11 轮训练完成
2025-11-22 21:38:48 - GraphTrainer - INFO - train_loss: 0.469828
2025-11-22 21:38:48 - GraphTrainer - INFO - precision@5: 0.004670
2025-11-22 21:38:48 - GraphTrainer - INFO - recall@5: 0.022265
2025-11-22 21:38:48 - GraphTrainer - INFO - hit_rate@5: 0.023296
2025-11-22 21:38:48 - GraphTrainer - INFO - ndcg@5: 0.014721
2025-11-22 21:38:48 - GraphTrainer - INFO - map@5: 0.012066
2025-11-22 21:38:48 - GraphTrainer - INFO - mrr@5: 0.012635
2025-11-22 21:38:48 - GraphTrainer - INFO - precision@10: 0.003975
2025-11-22 21:38:48 - GraphTrainer - INFO - recall@10: 0.037923
2025-11-22 21:38:48 - GraphTrainer - INFO - hit_rate@10: 0.039650
2025-11-22 21:38:48 - GraphTrainer - INFO - ndcg@10: 0.019762
2025-11-22 21:38:48 - GraphTrainer - INFO - map@10: 0.014096
2025-11-22 21:38:48 - GraphTrainer - INFO - mrr@10: 0.014753
2025-11-22 21:38:48 - GraphTrainer - INFO - precision@20: 0.003209
2025-11-22 21:38:48 - GraphTrainer - INFO - recall@20: 0.060678
2025-11-22 21:38:48 - GraphTrainer - INFO - hit_rate@20: 0.063924
2025-11-22 21:38:48 - GraphTrainer - INFO - ndcg@20: 0.025526
2025-11-22 21:38:48 - GraphTrainer - INFO - map@20: 0.015618
2025-11-22 21:38:48 - GraphTrainer - INFO - mrr@20: 0.016378
2025-11-22 21:38:48 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:38:48 - GraphTrainer - INFO - ============================================================
2025-11-22 21:38:48 - GraphTrainer - INFO - 开始第 12/1000 轮训练
2025-11-22 21:38:48 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4899, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4623, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4678, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4639, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4492, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4885, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4735, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4490, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4654, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4542, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4711, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4614, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4651, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4636, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4514, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4881, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4361, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4551, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.5009, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4709, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4854, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4506, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4661, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4850, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4536, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4821, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4562, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4861, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4805, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4683, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4564, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4701, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4650, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4790, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4819, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4630, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4593, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4727, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4920, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4654, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4839, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4546, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4979, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4873, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4593, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4951, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4801, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4885, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4601, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4776, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4436, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4751, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4688, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4305, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4708, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4809, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4781, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4718, device='cuda:0', grad_fn=<AddBackward0>)
The 11 training average loss: 0.4698277372738411
2025-11-22 21:38:59 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:38:59 - GraphTrainer - INFO -   precision@5: 0.004556
2025-11-22 21:38:59 - GraphTrainer - INFO -   recall@5: 0.021803
2025-11-22 21:38:59 - GraphTrainer - INFO -   hit_rate@5: 0.022731
2025-11-22 21:38:59 - GraphTrainer - INFO -   ndcg@5: 0.013868
2025-11-22 21:38:59 - GraphTrainer - INFO -   map@5: 0.011111
2025-11-22 21:38:59 - GraphTrainer - INFO -   mrr@5: 0.011548
2025-11-22 21:38:59 - GraphTrainer - INFO -   precision@10: 0.003831
2025-11-22 21:38:59 - GraphTrainer - INFO -   recall@10: 0.036380
2025-11-22 21:38:59 - GraphTrainer - INFO -   hit_rate@10: 0.038210
2025-11-22 21:38:59 - GraphTrainer - INFO -   ndcg@10: 0.018615
2025-11-22 21:38:59 - GraphTrainer - INFO -   map@10: 0.013034
2025-11-22 21:38:59 - GraphTrainer - INFO -   mrr@10: 0.013589
2025-11-22 21:38:59 - GraphTrainer - INFO -   precision@20: 0.003158
2025-11-22 21:38:59 - GraphTrainer - INFO -   recall@20: 0.059972
2025-11-22 21:38:59 - GraphTrainer - INFO -   hit_rate@20: 0.062792
2025-11-22 21:38:59 - GraphTrainer - INFO -   ndcg@20: 0.024624
2025-11-22 21:38:59 - GraphTrainer - INFO -   map@20: 0.014661
2025-11-22 21:38:59 - GraphTrainer - INFO -   mrr@20: 0.015277
2025-11-22 21:38:59 - GraphTrainer - INFO - 第 12 轮训练完成
2025-11-22 21:38:59 - GraphTrainer - INFO - train_loss: 0.460034
2025-11-22 21:38:59 - GraphTrainer - INFO - precision@5: 0.004556
2025-11-22 21:38:59 - GraphTrainer - INFO - recall@5: 0.021803
2025-11-22 21:38:59 - GraphTrainer - INFO - hit_rate@5: 0.022731
2025-11-22 21:38:59 - GraphTrainer - INFO - ndcg@5: 0.013868
2025-11-22 21:38:59 - GraphTrainer - INFO - map@5: 0.011111
2025-11-22 21:38:59 - GraphTrainer - INFO - mrr@5: 0.011548
2025-11-22 21:38:59 - GraphTrainer - INFO - precision@10: 0.003831
2025-11-22 21:38:59 - GraphTrainer - INFO - recall@10: 0.036380
2025-11-22 21:38:59 - GraphTrainer - INFO - hit_rate@10: 0.038210
2025-11-22 21:38:59 - GraphTrainer - INFO - ndcg@10: 0.018615
2025-11-22 21:38:59 - GraphTrainer - INFO - map@10: 0.013034
2025-11-22 21:38:59 - GraphTrainer - INFO - mrr@10: 0.013589
2025-11-22 21:38:59 - GraphTrainer - INFO - precision@20: 0.003158
2025-11-22 21:38:59 - GraphTrainer - INFO - recall@20: 0.059972
2025-11-22 21:38:59 - GraphTrainer - INFO - hit_rate@20: 0.062792
2025-11-22 21:38:59 - GraphTrainer - INFO - ndcg@20: 0.024624
2025-11-22 21:38:59 - GraphTrainer - INFO - map@20: 0.014661
2025-11-22 21:38:59 - GraphTrainer - INFO - mrr@20: 0.015277
2025-11-22 21:38:59 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:38:59 - GraphTrainer - INFO - ============================================================
2025-11-22 21:38:59 - GraphTrainer - INFO - 开始第 13/1000 轮训练
2025-11-22 21:38:59 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4524, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4475, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4629, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4561, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4882, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4548, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4616, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4689, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4855, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4546, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4699, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4710, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4413, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4524, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4962, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4533, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4631, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4529, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4464, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4594, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4748, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4758, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4623, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4622, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4506, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4658, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4492, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4763, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4387, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4650, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4682, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4683, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4741, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4537, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4680, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4514, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4738, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4435, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4658, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4876, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4847, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4605, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4451, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4526, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4478, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4618, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4557, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4675, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4576, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4500, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4472, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4406, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4674, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4343, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4512, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4570, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4539, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4333, device='cuda:0', grad_fn=<AddBackward0>)
The 12 training average loss: 0.4600337003839427
2025-11-22 21:39:10 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:39:10 - GraphTrainer - INFO -   precision@5: 0.004351
2025-11-22 21:39:10 - GraphTrainer - INFO -   recall@5: 0.020556
2025-11-22 21:39:10 - GraphTrainer - INFO -   hit_rate@5: 0.021702
2025-11-22 21:39:10 - GraphTrainer - INFO -   ndcg@5: 0.012411
2025-11-22 21:39:10 - GraphTrainer - INFO -   map@5: 0.009568
2025-11-22 21:39:10 - GraphTrainer - INFO -   mrr@5: 0.010065
2025-11-22 21:39:10 - GraphTrainer - INFO -   precision@10: 0.003610
2025-11-22 21:39:10 - GraphTrainer - INFO -   recall@10: 0.034279
2025-11-22 21:39:10 - GraphTrainer - INFO -   hit_rate@10: 0.036050
2025-11-22 21:39:10 - GraphTrainer - INFO -   ndcg@10: 0.016814
2025-11-22 21:39:10 - GraphTrainer - INFO -   map@10: 0.011328
2025-11-22 21:39:10 - GraphTrainer - INFO -   mrr@10: 0.011907
2025-11-22 21:39:10 - GraphTrainer - INFO -   precision@20: 0.003019
2025-11-22 21:39:10 - GraphTrainer - INFO -   recall@20: 0.057186
2025-11-22 21:39:10 - GraphTrainer - INFO -   hit_rate@20: 0.060015
2025-11-22 21:39:10 - GraphTrainer - INFO -   ndcg@20: 0.022628
2025-11-22 21:39:10 - GraphTrainer - INFO -   map@20: 0.012886
2025-11-22 21:39:10 - GraphTrainer - INFO -   mrr@20: 0.013531
2025-11-22 21:39:10 - GraphTrainer - INFO - 第 13 轮训练完成
2025-11-22 21:39:10 - GraphTrainer - INFO - train_loss: 0.453798
2025-11-22 21:39:10 - GraphTrainer - INFO - precision@5: 0.004351
2025-11-22 21:39:10 - GraphTrainer - INFO - recall@5: 0.020556
2025-11-22 21:39:10 - GraphTrainer - INFO - hit_rate@5: 0.021702
2025-11-22 21:39:10 - GraphTrainer - INFO - ndcg@5: 0.012411
2025-11-22 21:39:10 - GraphTrainer - INFO - map@5: 0.009568
2025-11-22 21:39:10 - GraphTrainer - INFO - mrr@5: 0.010065
2025-11-22 21:39:10 - GraphTrainer - INFO - precision@10: 0.003610
2025-11-22 21:39:10 - GraphTrainer - INFO - recall@10: 0.034279
2025-11-22 21:39:10 - GraphTrainer - INFO - hit_rate@10: 0.036050
2025-11-22 21:39:10 - GraphTrainer - INFO - ndcg@10: 0.016814
2025-11-22 21:39:10 - GraphTrainer - INFO - map@10: 0.011328
2025-11-22 21:39:10 - GraphTrainer - INFO - mrr@10: 0.011907
2025-11-22 21:39:10 - GraphTrainer - INFO - precision@20: 0.003019
2025-11-22 21:39:10 - GraphTrainer - INFO - recall@20: 0.057186
2025-11-22 21:39:10 - GraphTrainer - INFO - hit_rate@20: 0.060015
2025-11-22 21:39:10 - GraphTrainer - INFO - ndcg@20: 0.022628
2025-11-22 21:39:10 - GraphTrainer - INFO - map@20: 0.012886
2025-11-22 21:39:10 - GraphTrainer - INFO - mrr@20: 0.013531
2025-11-22 21:39:10 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:39:10 - GraphTrainer - INFO - ============================================================
2025-11-22 21:39:10 - GraphTrainer - INFO - 开始第 14/1000 轮训练
2025-11-22 21:39:10 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4546, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4441, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4433, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4321, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4586, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4378, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4830, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4483, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4496, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4342, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4793, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4464, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4491, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4677, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4465, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4818, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4652, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4637, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4392, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4346, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4552, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4381, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4507, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4462, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4371, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4704, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4295, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4475, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4615, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4480, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4748, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4442, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4714, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4435, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4546, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4381, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4519, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4720, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4883, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4383, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4538, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4360, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4679, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4585, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4589, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4527, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4380, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4525, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4664, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4451, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4400, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4397, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4652, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4619, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4522, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4788, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4540, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4782, device='cuda:0', grad_fn=<AddBackward0>)
The 13 training average loss: 0.45379753308049564
2025-11-22 21:39:21 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:39:21 - GraphTrainer - INFO -   precision@5: 0.004865
2025-11-22 21:39:21 - GraphTrainer - INFO -   recall@5: 0.023178
2025-11-22 21:39:21 - GraphTrainer - INFO -   hit_rate@5: 0.024274
2025-11-22 21:39:21 - GraphTrainer - INFO -   ndcg@5: 0.014637
2025-11-22 21:39:21 - GraphTrainer - INFO -   map@5: 0.011637
2025-11-22 21:39:21 - GraphTrainer - INFO -   mrr@5: 0.012268
2025-11-22 21:39:21 - GraphTrainer - INFO -   precision@10: 0.003898
2025-11-22 21:39:21 - GraphTrainer - INFO -   recall@10: 0.036912
2025-11-22 21:39:21 - GraphTrainer - INFO -   hit_rate@10: 0.038776
2025-11-22 21:39:21 - GraphTrainer - INFO -   ndcg@10: 0.019119
2025-11-22 21:39:21 - GraphTrainer - INFO -   map@10: 0.013465
2025-11-22 21:39:21 - GraphTrainer - INFO -   mrr@10: 0.014197
2025-11-22 21:39:21 - GraphTrainer - INFO -   precision@20: 0.003289
2025-11-22 21:39:21 - GraphTrainer - INFO -   recall@20: 0.062275
2025-11-22 21:39:21 - GraphTrainer - INFO -   hit_rate@20: 0.065261
2025-11-22 21:39:21 - GraphTrainer - INFO -   ndcg@20: 0.025552
2025-11-22 21:39:21 - GraphTrainer - INFO -   map@20: 0.015188
2025-11-22 21:39:21 - GraphTrainer - INFO -   mrr@20: 0.015987
2025-11-22 21:39:21 - GraphTrainer - INFO - 第 14 轮训练完成
2025-11-22 21:39:21 - GraphTrainer - INFO - train_loss: 0.450531
2025-11-22 21:39:21 - GraphTrainer - INFO - precision@5: 0.004865
2025-11-22 21:39:21 - GraphTrainer - INFO - recall@5: 0.023178
2025-11-22 21:39:21 - GraphTrainer - INFO - hit_rate@5: 0.024274
2025-11-22 21:39:21 - GraphTrainer - INFO - ndcg@5: 0.014637
2025-11-22 21:39:21 - GraphTrainer - INFO - map@5: 0.011637
2025-11-22 21:39:21 - GraphTrainer - INFO - mrr@5: 0.012268
2025-11-22 21:39:21 - GraphTrainer - INFO - precision@10: 0.003898
2025-11-22 21:39:21 - GraphTrainer - INFO - recall@10: 0.036912
2025-11-22 21:39:21 - GraphTrainer - INFO - hit_rate@10: 0.038776
2025-11-22 21:39:21 - GraphTrainer - INFO - ndcg@10: 0.019119
2025-11-22 21:39:21 - GraphTrainer - INFO - map@10: 0.013465
2025-11-22 21:39:21 - GraphTrainer - INFO - mrr@10: 0.014197
2025-11-22 21:39:21 - GraphTrainer - INFO - precision@20: 0.003289
2025-11-22 21:39:21 - GraphTrainer - INFO - recall@20: 0.062275
2025-11-22 21:39:21 - GraphTrainer - INFO - hit_rate@20: 0.065261
2025-11-22 21:39:21 - GraphTrainer - INFO - ndcg@20: 0.025552
2025-11-22 21:39:21 - GraphTrainer - INFO - map@20: 0.015188
2025-11-22 21:39:21 - GraphTrainer - INFO - mrr@20: 0.015987
2025-11-22 21:39:21 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:39:21 - GraphTrainer - INFO - ============================================================
2025-11-22 21:39:21 - GraphTrainer - INFO - 开始第 15/1000 轮训练
2025-11-22 21:39:21 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4575, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4585, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4556, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4527, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4518, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4496, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4606, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4692, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4465, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4330, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4478, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4387, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4532, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4650, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4598, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4521, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4708, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4435, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4372, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4426, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4480, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4453, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4489, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4659, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4353, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4415, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4572, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4379, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4465, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4642, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4645, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4409, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4315, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4665, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4396, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4314, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4356, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4375, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4586, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4296, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4710, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4483, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4655, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4441, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4390, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4633, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4257, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4203, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4683, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4564, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4793, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4333, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4640, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4661, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4487, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4633, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4466, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4557, device='cuda:0', grad_fn=<AddBackward0>)
The 14 training average loss: 0.4505307155436483
2025-11-22 21:39:32 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:39:32 - GraphTrainer - INFO -   precision@5: 0.004567
2025-11-22 21:39:32 - GraphTrainer - INFO -   recall@5: 0.021670
2025-11-22 21:39:32 - GraphTrainer - INFO -   hit_rate@5: 0.022782
2025-11-22 21:39:32 - GraphTrainer - INFO -   ndcg@5: 0.013881
2025-11-22 21:39:32 - GraphTrainer - INFO -   map@5: 0.011131
2025-11-22 21:39:32 - GraphTrainer - INFO -   mrr@5: 0.011716
2025-11-22 21:39:32 - GraphTrainer - INFO -   precision@10: 0.003878
2025-11-22 21:39:32 - GraphTrainer - INFO -   recall@10: 0.036812
2025-11-22 21:39:32 - GraphTrainer - INFO -   hit_rate@10: 0.038673
2025-11-22 21:39:32 - GraphTrainer - INFO -   ndcg@10: 0.018779
2025-11-22 21:39:32 - GraphTrainer - INFO -   map@10: 0.013110
2025-11-22 21:39:32 - GraphTrainer - INFO -   mrr@10: 0.013792
2025-11-22 21:39:32 - GraphTrainer - INFO -   precision@20: 0.003150
2025-11-22 21:39:32 - GraphTrainer - INFO -   recall@20: 0.059563
2025-11-22 21:39:32 - GraphTrainer - INFO -   hit_rate@20: 0.062638
2025-11-22 21:39:32 - GraphTrainer - INFO -   ndcg@20: 0.024544
2025-11-22 21:39:32 - GraphTrainer - INFO -   map@20: 0.014645
2025-11-22 21:39:32 - GraphTrainer - INFO -   mrr@20: 0.015406
2025-11-22 21:39:32 - GraphTrainer - INFO - 第 15 轮训练完成
2025-11-22 21:39:32 - GraphTrainer - INFO - train_loss: 0.446679
2025-11-22 21:39:32 - GraphTrainer - INFO - precision@5: 0.004567
2025-11-22 21:39:32 - GraphTrainer - INFO - recall@5: 0.021670
2025-11-22 21:39:32 - GraphTrainer - INFO - hit_rate@5: 0.022782
2025-11-22 21:39:32 - GraphTrainer - INFO - ndcg@5: 0.013881
2025-11-22 21:39:32 - GraphTrainer - INFO - map@5: 0.011131
2025-11-22 21:39:32 - GraphTrainer - INFO - mrr@5: 0.011716
2025-11-22 21:39:32 - GraphTrainer - INFO - precision@10: 0.003878
2025-11-22 21:39:32 - GraphTrainer - INFO - recall@10: 0.036812
2025-11-22 21:39:32 - GraphTrainer - INFO - hit_rate@10: 0.038673
2025-11-22 21:39:32 - GraphTrainer - INFO - ndcg@10: 0.018779
2025-11-22 21:39:32 - GraphTrainer - INFO - map@10: 0.013110
2025-11-22 21:39:32 - GraphTrainer - INFO - mrr@10: 0.013792
2025-11-22 21:39:32 - GraphTrainer - INFO - precision@20: 0.003150
2025-11-22 21:39:32 - GraphTrainer - INFO - recall@20: 0.059563
2025-11-22 21:39:32 - GraphTrainer - INFO - hit_rate@20: 0.062638
2025-11-22 21:39:32 - GraphTrainer - INFO - ndcg@20: 0.024544
2025-11-22 21:39:32 - GraphTrainer - INFO - map@20: 0.014645
2025-11-22 21:39:32 - GraphTrainer - INFO - mrr@20: 0.015406
2025-11-22 21:39:32 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:39:32 - GraphTrainer - INFO - ============================================================
2025-11-22 21:39:32 - GraphTrainer - INFO - 开始第 16/1000 轮训练
2025-11-22 21:39:32 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4411, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4451, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4200, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4377, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4227, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4336, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4492, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4652, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4780, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4458, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4355, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4424, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4410, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4557, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4470, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4542, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4655, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4470, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4630, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4372, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4319, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4690, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4358, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4627, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4409, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4492, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4443, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4666, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4550, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4365, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4386, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4511, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4310, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4539, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4681, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4423, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4319, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4574, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4435, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4383, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4410, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4497, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4642, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4620, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4287, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4481, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4378, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4354, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4366, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4450, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4489, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4675, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4330, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4333, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4556, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4393, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4726, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4337, device='cuda:0', grad_fn=<AddBackward0>)
The 15 training average loss: 0.44667876280587293
2025-11-22 21:39:44 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:39:44 - GraphTrainer - INFO -   precision@5: 0.004968
2025-11-22 21:39:44 - GraphTrainer - INFO -   recall@5: 0.023629
2025-11-22 21:39:44 - GraphTrainer - INFO -   hit_rate@5: 0.024788
2025-11-22 21:39:44 - GraphTrainer - INFO -   ndcg@5: 0.015550
2025-11-22 21:39:44 - GraphTrainer - INFO -   map@5: 0.012712
2025-11-22 21:39:44 - GraphTrainer - INFO -   mrr@5: 0.013272
2025-11-22 21:39:44 - GraphTrainer - INFO -   precision@10: 0.004099
2025-11-22 21:39:44 - GraphTrainer - INFO -   recall@10: 0.038767
2025-11-22 21:39:44 - GraphTrainer - INFO -   hit_rate@10: 0.040782
2025-11-22 21:39:44 - GraphTrainer - INFO -   ndcg@10: 0.020472
2025-11-22 21:39:44 - GraphTrainer - INFO -   map@10: 0.014707
2025-11-22 21:39:44 - GraphTrainer - INFO -   mrr@10: 0.015371
2025-11-22 21:39:44 - GraphTrainer - INFO -   precision@20: 0.003338
2025-11-22 21:39:44 - GraphTrainer - INFO -   recall@20: 0.063033
2025-11-22 21:39:44 - GraphTrainer - INFO -   hit_rate@20: 0.066341
2025-11-22 21:39:44 - GraphTrainer - INFO -   ndcg@20: 0.026646
2025-11-22 21:39:44 - GraphTrainer - INFO -   map@20: 0.016365
2025-11-22 21:39:44 - GraphTrainer - INFO -   mrr@20: 0.017108
2025-11-22 21:39:44 - GraphTrainer - INFO - 第 16 轮训练完成
2025-11-22 21:39:44 - GraphTrainer - INFO - train_loss: 0.440703
2025-11-22 21:39:44 - GraphTrainer - INFO - precision@5: 0.004968
2025-11-22 21:39:44 - GraphTrainer - INFO - recall@5: 0.023629
2025-11-22 21:39:44 - GraphTrainer - INFO - hit_rate@5: 0.024788
2025-11-22 21:39:44 - GraphTrainer - INFO - ndcg@5: 0.015550
2025-11-22 21:39:44 - GraphTrainer - INFO - map@5: 0.012712
2025-11-22 21:39:44 - GraphTrainer - INFO - mrr@5: 0.013272
2025-11-22 21:39:44 - GraphTrainer - INFO - precision@10: 0.004099
2025-11-22 21:39:44 - GraphTrainer - INFO - recall@10: 0.038767
2025-11-22 21:39:44 - GraphTrainer - INFO - hit_rate@10: 0.040782
2025-11-22 21:39:44 - GraphTrainer - INFO - ndcg@10: 0.020472
2025-11-22 21:39:44 - GraphTrainer - INFO - map@10: 0.014707
2025-11-22 21:39:44 - GraphTrainer - INFO - mrr@10: 0.015371
2025-11-22 21:39:44 - GraphTrainer - INFO - precision@20: 0.003338
2025-11-22 21:39:44 - GraphTrainer - INFO - recall@20: 0.063033
2025-11-22 21:39:44 - GraphTrainer - INFO - hit_rate@20: 0.066341
2025-11-22 21:39:44 - GraphTrainer - INFO - ndcg@20: 0.026646
2025-11-22 21:39:44 - GraphTrainer - INFO - map@20: 0.016365
2025-11-22 21:39:44 - GraphTrainer - INFO - mrr@20: 0.017108
2025-11-22 21:39:44 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:39:44 - GraphTrainer - INFO - ============================================================
2025-11-22 21:39:44 - GraphTrainer - INFO - 开始第 17/1000 轮训练
2025-11-22 21:39:44 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4472, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4490, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4415, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4209, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4622, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4382, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4512, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4419, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4277, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4446, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4377, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4240, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4311, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4195, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4551, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4468, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4465, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4460, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4511, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4541, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4175, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4459, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4462, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4306, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4340, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4579, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4339, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4602, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4408, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4489, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4302, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4433, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4448, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4438, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4275, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4343, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4465, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4414, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4312, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4344, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4244, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4620, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4435, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4468, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4307, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4397, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4318, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4504, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4386, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4151, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4327, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4327, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4279, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4533, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4789, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4558, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4402, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4267, device='cuda:0', grad_fn=<AddBackward0>)
The 16 training average loss: 0.4407025179986296
2025-11-22 21:39:55 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:39:55 - GraphTrainer - INFO -   precision@5: 0.005235
2025-11-22 21:39:55 - GraphTrainer - INFO -   recall@5: 0.025068
2025-11-22 21:39:55 - GraphTrainer - INFO -   hit_rate@5: 0.026125
2025-11-22 21:39:55 - GraphTrainer - INFO -   ndcg@5: 0.016252
2025-11-22 21:39:55 - GraphTrainer - INFO -   map@5: 0.013187
2025-11-22 21:39:55 - GraphTrainer - INFO -   mrr@5: 0.013740
2025-11-22 21:39:55 - GraphTrainer - INFO -   precision@10: 0.004304
2025-11-22 21:39:55 - GraphTrainer - INFO -   recall@10: 0.040889
2025-11-22 21:39:55 - GraphTrainer - INFO -   hit_rate@10: 0.042839
2025-11-22 21:39:55 - GraphTrainer - INFO -   ndcg@10: 0.021413
2025-11-22 21:39:55 - GraphTrainer - INFO -   map@10: 0.015289
2025-11-22 21:39:55 - GraphTrainer - INFO -   mrr@10: 0.015962
2025-11-22 21:39:55 - GraphTrainer - INFO -   precision@20: 0.003422
2025-11-22 21:39:55 - GraphTrainer - INFO -   recall@20: 0.064548
2025-11-22 21:39:55 - GraphTrainer - INFO -   hit_rate@20: 0.068038
2025-11-22 21:39:55 - GraphTrainer - INFO -   ndcg@20: 0.027428
2025-11-22 21:39:55 - GraphTrainer - INFO -   map@20: 0.016889
2025-11-22 21:39:55 - GraphTrainer - INFO -   mrr@20: 0.017665
2025-11-22 21:39:55 - GraphTrainer - INFO - 第 17 轮训练完成
2025-11-22 21:39:55 - GraphTrainer - INFO - train_loss: 0.435659
2025-11-22 21:39:55 - GraphTrainer - INFO - precision@5: 0.005235
2025-11-22 21:39:55 - GraphTrainer - INFO - recall@5: 0.025068
2025-11-22 21:39:55 - GraphTrainer - INFO - hit_rate@5: 0.026125
2025-11-22 21:39:55 - GraphTrainer - INFO - ndcg@5: 0.016252
2025-11-22 21:39:55 - GraphTrainer - INFO - map@5: 0.013187
2025-11-22 21:39:55 - GraphTrainer - INFO - mrr@5: 0.013740
2025-11-22 21:39:55 - GraphTrainer - INFO - precision@10: 0.004304
2025-11-22 21:39:55 - GraphTrainer - INFO - recall@10: 0.040889
2025-11-22 21:39:55 - GraphTrainer - INFO - hit_rate@10: 0.042839
2025-11-22 21:39:55 - GraphTrainer - INFO - ndcg@10: 0.021413
2025-11-22 21:39:55 - GraphTrainer - INFO - map@10: 0.015289
2025-11-22 21:39:55 - GraphTrainer - INFO - mrr@10: 0.015962
2025-11-22 21:39:55 - GraphTrainer - INFO - precision@20: 0.003422
2025-11-22 21:39:55 - GraphTrainer - INFO - recall@20: 0.064548
2025-11-22 21:39:55 - GraphTrainer - INFO - hit_rate@20: 0.068038
2025-11-22 21:39:55 - GraphTrainer - INFO - ndcg@20: 0.027428
2025-11-22 21:39:55 - GraphTrainer - INFO - map@20: 0.016889
2025-11-22 21:39:55 - GraphTrainer - INFO - mrr@20: 0.017665
2025-11-22 21:39:55 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:39:55 - GraphTrainer - INFO - ============================================================
2025-11-22 21:39:55 - GraphTrainer - INFO - 开始第 18/1000 轮训练
2025-11-22 21:39:55 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4705, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4361, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4079, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4398, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4202, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4444, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4602, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4322, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4360, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4213, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4368, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4470, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4251, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4154, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4455, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4406, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4486, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4401, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4631, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4240, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4386, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4290, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4253, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4309, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4237, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4281, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4479, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4400, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4245, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4373, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4175, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4595, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4611, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4262, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4311, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4228, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4582, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4367, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4257, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4312, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4528, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4685, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4441, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4312, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4255, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4366, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4245, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4303, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4333, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4120, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4258, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4378, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4340, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4051, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4137, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4412, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4540, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4479, device='cuda:0', grad_fn=<AddBackward0>)
The 17 training average loss: 0.4356593294390317
2025-11-22 21:40:06 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:40:06 - GraphTrainer - INFO -   precision@5: 0.005276
2025-11-22 21:40:06 - GraphTrainer - INFO -   recall@5: 0.025532
2025-11-22 21:40:06 - GraphTrainer - INFO -   hit_rate@5: 0.026331
2025-11-22 21:40:06 - GraphTrainer - INFO -   ndcg@5: 0.016247
2025-11-22 21:40:06 - GraphTrainer - INFO -   map@5: 0.013072
2025-11-22 21:40:06 - GraphTrainer - INFO -   mrr@5: 0.013474
2025-11-22 21:40:06 - GraphTrainer - INFO -   precision@10: 0.004227
2025-11-22 21:40:06 - GraphTrainer - INFO -   recall@10: 0.040380
2025-11-22 21:40:06 - GraphTrainer - INFO -   hit_rate@10: 0.042170
2025-11-22 21:40:06 - GraphTrainer - INFO -   ndcg@10: 0.021096
2025-11-22 21:40:06 - GraphTrainer - INFO -   map@10: 0.015038
2025-11-22 21:40:06 - GraphTrainer - INFO -   mrr@10: 0.015568
2025-11-22 21:40:06 - GraphTrainer - INFO -   precision@20: 0.003440
2025-11-22 21:40:06 - GraphTrainer - INFO -   recall@20: 0.065143
2025-11-22 21:40:06 - GraphTrainer - INFO -   hit_rate@20: 0.068347
2025-11-22 21:40:06 - GraphTrainer - INFO -   ndcg@20: 0.027398
2025-11-22 21:40:06 - GraphTrainer - INFO -   map@20: 0.016722
2025-11-22 21:40:06 - GraphTrainer - INFO -   mrr@20: 0.017340
2025-11-22 21:40:06 - GraphTrainer - INFO - 第 18 轮训练完成
2025-11-22 21:40:06 - GraphTrainer - INFO - train_loss: 0.433326
2025-11-22 21:40:06 - GraphTrainer - INFO - precision@5: 0.005276
2025-11-22 21:40:06 - GraphTrainer - INFO - recall@5: 0.025532
2025-11-22 21:40:06 - GraphTrainer - INFO - hit_rate@5: 0.026331
2025-11-22 21:40:06 - GraphTrainer - INFO - ndcg@5: 0.016247
2025-11-22 21:40:06 - GraphTrainer - INFO - map@5: 0.013072
2025-11-22 21:40:06 - GraphTrainer - INFO - mrr@5: 0.013474
2025-11-22 21:40:06 - GraphTrainer - INFO - precision@10: 0.004227
2025-11-22 21:40:06 - GraphTrainer - INFO - recall@10: 0.040380
2025-11-22 21:40:06 - GraphTrainer - INFO - hit_rate@10: 0.042170
2025-11-22 21:40:06 - GraphTrainer - INFO - ndcg@10: 0.021096
2025-11-22 21:40:06 - GraphTrainer - INFO - map@10: 0.015038
2025-11-22 21:40:06 - GraphTrainer - INFO - mrr@10: 0.015568
2025-11-22 21:40:06 - GraphTrainer - INFO - precision@20: 0.003440
2025-11-22 21:40:06 - GraphTrainer - INFO - recall@20: 0.065143
2025-11-22 21:40:06 - GraphTrainer - INFO - hit_rate@20: 0.068347
2025-11-22 21:40:06 - GraphTrainer - INFO - ndcg@20: 0.027398
2025-11-22 21:40:06 - GraphTrainer - INFO - map@20: 0.016722
2025-11-22 21:40:06 - GraphTrainer - INFO - mrr@20: 0.017340
2025-11-22 21:40:06 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:40:06 - GraphTrainer - INFO - ============================================================
2025-11-22 21:40:06 - GraphTrainer - INFO - 开始第 19/1000 轮训练
2025-11-22 21:40:06 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4319, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4278, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4183, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4282, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4161, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4381, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4342, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4166, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4240, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4440, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4177, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4050, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4452, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4293, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4472, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4413, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4414, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4206, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4286, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4221, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4591, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4418, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4395, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4284, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4463, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4119, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4311, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4564, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4385, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4430, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4162, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4255, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4223, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4428, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4138, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4168, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4610, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4384, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4356, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4371, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4419, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4166, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4681, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4328, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4143, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4182, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4191, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4407, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4360, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4604, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4481, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4544, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4324, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4492, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4179, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4500, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4372, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4126, device='cuda:0', grad_fn=<AddBackward0>)
The 18 training average loss: 0.43332623048075314
2025-11-22 21:40:17 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:40:17 - GraphTrainer - INFO -   precision@5: 0.004896
2025-11-22 21:40:17 - GraphTrainer - INFO -   recall@5: 0.023367
2025-11-22 21:40:17 - GraphTrainer - INFO -   hit_rate@5: 0.024428
2025-11-22 21:40:17 - GraphTrainer - INFO -   ndcg@5: 0.014847
2025-11-22 21:40:17 - GraphTrainer - INFO -   map@5: 0.011868
2025-11-22 21:40:17 - GraphTrainer - INFO -   mrr@5: 0.012406
2025-11-22 21:40:17 - GraphTrainer - INFO -   precision@10: 0.004160
2025-11-22 21:40:17 - GraphTrainer - INFO -   recall@10: 0.039370
2025-11-22 21:40:17 - GraphTrainer - INFO -   hit_rate@10: 0.041450
2025-11-22 21:40:17 - GraphTrainer - INFO -   ndcg@10: 0.020060
2025-11-22 21:40:17 - GraphTrainer - INFO -   map@10: 0.013979
2025-11-22 21:40:17 - GraphTrainer - INFO -   mrr@10: 0.014648
2025-11-22 21:40:17 - GraphTrainer - INFO -   precision@20: 0.003343
2025-11-22 21:40:17 - GraphTrainer - INFO -   recall@20: 0.063650
2025-11-22 21:40:17 - GraphTrainer - INFO -   hit_rate@20: 0.066444
2025-11-22 21:40:17 - GraphTrainer - INFO -   ndcg@20: 0.026205
2025-11-22 21:40:17 - GraphTrainer - INFO -   map@20: 0.015636
2025-11-22 21:40:17 - GraphTrainer - INFO -   mrr@20: 0.016346
2025-11-22 21:40:17 - GraphTrainer - INFO - 第 19 轮训练完成
2025-11-22 21:40:17 - GraphTrainer - INFO - train_loss: 0.432003
2025-11-22 21:40:17 - GraphTrainer - INFO - precision@5: 0.004896
2025-11-22 21:40:17 - GraphTrainer - INFO - recall@5: 0.023367
2025-11-22 21:40:17 - GraphTrainer - INFO - hit_rate@5: 0.024428
2025-11-22 21:40:17 - GraphTrainer - INFO - ndcg@5: 0.014847
2025-11-22 21:40:17 - GraphTrainer - INFO - map@5: 0.011868
2025-11-22 21:40:17 - GraphTrainer - INFO - mrr@5: 0.012406
2025-11-22 21:40:17 - GraphTrainer - INFO - precision@10: 0.004160
2025-11-22 21:40:17 - GraphTrainer - INFO - recall@10: 0.039370
2025-11-22 21:40:17 - GraphTrainer - INFO - hit_rate@10: 0.041450
2025-11-22 21:40:17 - GraphTrainer - INFO - ndcg@10: 0.020060
2025-11-22 21:40:17 - GraphTrainer - INFO - map@10: 0.013979
2025-11-22 21:40:17 - GraphTrainer - INFO - mrr@10: 0.014648
2025-11-22 21:40:17 - GraphTrainer - INFO - precision@20: 0.003343
2025-11-22 21:40:17 - GraphTrainer - INFO - recall@20: 0.063650
2025-11-22 21:40:17 - GraphTrainer - INFO - hit_rate@20: 0.066444
2025-11-22 21:40:17 - GraphTrainer - INFO - ndcg@20: 0.026205
2025-11-22 21:40:17 - GraphTrainer - INFO - map@20: 0.015636
2025-11-22 21:40:17 - GraphTrainer - INFO - mrr@20: 0.016346
2025-11-22 21:40:17 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:40:17 - GraphTrainer - INFO - ============================================================
2025-11-22 21:40:17 - GraphTrainer - INFO - 开始第 20/1000 轮训练
2025-11-22 21:40:17 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4389, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4346, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4442, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4152, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4375, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4621, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4398, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4085, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4247, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4169, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4313, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4023, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4043, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4309, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4080, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4241, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4061, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4265, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4373, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4295, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4324, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4363, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4263, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4162, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4217, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4380, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4536, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4573, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4416, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4575, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4406, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4384, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4256, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4239, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4352, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4311, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4480, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4460, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4211, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4316, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4174, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4348, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4620, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4229, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4148, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4179, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4447, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4361, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4396, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4258, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4466, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4258, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4185, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4373, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4665, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4276, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4380, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4348, device='cuda:0', grad_fn=<AddBackward0>)
The 19 training average loss: 0.43200278590465413
2025-11-22 21:40:28 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:40:28 - GraphTrainer - INFO -   precision@5: 0.004999
2025-11-22 21:40:28 - GraphTrainer - INFO -   recall@5: 0.023996
2025-11-22 21:40:28 - GraphTrainer - INFO -   hit_rate@5: 0.024942
2025-11-22 21:40:28 - GraphTrainer - INFO -   ndcg@5: 0.015449
2025-11-22 21:40:28 - GraphTrainer - INFO -   map@5: 0.012495
2025-11-22 21:40:28 - GraphTrainer - INFO -   mrr@5: 0.012922
2025-11-22 21:40:28 - GraphTrainer - INFO -   precision@10: 0.004068
2025-11-22 21:40:28 - GraphTrainer - INFO -   recall@10: 0.038856
2025-11-22 21:40:28 - GraphTrainer - INFO -   hit_rate@10: 0.040473
2025-11-22 21:40:28 - GraphTrainer - INFO -   ndcg@10: 0.020261
2025-11-22 21:40:28 - GraphTrainer - INFO -   map@10: 0.014445
2025-11-22 21:40:28 - GraphTrainer - INFO -   mrr@10: 0.014957
2025-11-22 21:40:28 - GraphTrainer - INFO -   precision@20: 0.003392
2025-11-22 21:40:28 - GraphTrainer - INFO -   recall@20: 0.064352
2025-11-22 21:40:28 - GraphTrainer - INFO -   hit_rate@20: 0.067318
2025-11-22 21:40:28 - GraphTrainer - INFO -   ndcg@20: 0.026735
2025-11-22 21:40:28 - GraphTrainer - INFO -   map@20: 0.016173
2025-11-22 21:40:28 - GraphTrainer - INFO -   mrr@20: 0.016773
2025-11-22 21:40:28 - GraphTrainer - INFO - 第 20 轮训练完成
2025-11-22 21:40:28 - GraphTrainer - INFO - train_loss: 0.424007
2025-11-22 21:40:28 - GraphTrainer - INFO - precision@5: 0.004999
2025-11-22 21:40:28 - GraphTrainer - INFO - recall@5: 0.023996
2025-11-22 21:40:28 - GraphTrainer - INFO - hit_rate@5: 0.024942
2025-11-22 21:40:28 - GraphTrainer - INFO - ndcg@5: 0.015449
2025-11-22 21:40:28 - GraphTrainer - INFO - map@5: 0.012495
2025-11-22 21:40:28 - GraphTrainer - INFO - mrr@5: 0.012922
2025-11-22 21:40:28 - GraphTrainer - INFO - precision@10: 0.004068
2025-11-22 21:40:28 - GraphTrainer - INFO - recall@10: 0.038856
2025-11-22 21:40:28 - GraphTrainer - INFO - hit_rate@10: 0.040473
2025-11-22 21:40:28 - GraphTrainer - INFO - ndcg@10: 0.020261
2025-11-22 21:40:28 - GraphTrainer - INFO - map@10: 0.014445
2025-11-22 21:40:28 - GraphTrainer - INFO - mrr@10: 0.014957
2025-11-22 21:40:28 - GraphTrainer - INFO - precision@20: 0.003392
2025-11-22 21:40:28 - GraphTrainer - INFO - recall@20: 0.064352
2025-11-22 21:40:28 - GraphTrainer - INFO - hit_rate@20: 0.067318
2025-11-22 21:40:28 - GraphTrainer - INFO - ndcg@20: 0.026735
2025-11-22 21:40:28 - GraphTrainer - INFO - map@20: 0.016173
2025-11-22 21:40:28 - GraphTrainer - INFO - mrr@20: 0.016773
2025-11-22 21:40:28 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:40:28 - GraphTrainer - INFO - 检查点已保存: Epoch 20 -> ./checkpoints/checkpoint_epoch_20.pth
2025-11-22 21:40:28 - GraphTrainer - INFO - ============================================================
2025-11-22 21:40:28 - GraphTrainer - INFO - 开始第 21/1000 轮训练
2025-11-22 21:40:28 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4200, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4304, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4254, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4324, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4141, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4013, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4298, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4195, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4192, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4393, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4065, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4276, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4226, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4217, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4053, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4100, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4294, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4411, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4303, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4158, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4251, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4326, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4163, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4454, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4233, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4012, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4417, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4204, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4381, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4286, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4163, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4510, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3901, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4242, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4316, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4677, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4189, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4258, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4145, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4368, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4196, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4056, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4116, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4523, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4232, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4148, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4026, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4184, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4355, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4294, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4255, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4128, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4111, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4296, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4322, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4380, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4295, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4094, device='cuda:0', grad_fn=<AddBackward0>)
The 20 training average loss: 0.4240073212261858
2025-11-22 21:40:39 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:40:39 - GraphTrainer - INFO -   precision@5: 0.004999
2025-11-22 21:40:39 - GraphTrainer - INFO -   recall@5: 0.023970
2025-11-22 21:40:39 - GraphTrainer - INFO -   hit_rate@5: 0.024942
2025-11-22 21:40:39 - GraphTrainer - INFO -   ndcg@5: 0.015133
2025-11-22 21:40:39 - GraphTrainer - INFO -   map@5: 0.012084
2025-11-22 21:40:39 - GraphTrainer - INFO -   mrr@5: 0.012540
2025-11-22 21:40:39 - GraphTrainer - INFO -   precision@10: 0.004232
2025-11-22 21:40:39 - GraphTrainer - INFO -   recall@10: 0.040429
2025-11-22 21:40:39 - GraphTrainer - INFO -   hit_rate@10: 0.042119
2025-11-22 21:40:39 - GraphTrainer - INFO -   ndcg@10: 0.020515
2025-11-22 21:40:39 - GraphTrainer - INFO -   map@10: 0.014297
2025-11-22 21:40:39 - GraphTrainer - INFO -   mrr@10: 0.014840
2025-11-22 21:40:39 - GraphTrainer - INFO -   precision@20: 0.003433
2025-11-22 21:40:39 - GraphTrainer - INFO -   recall@20: 0.064926
2025-11-22 21:40:39 - GraphTrainer - INFO -   hit_rate@20: 0.068089
2025-11-22 21:40:39 - GraphTrainer - INFO -   ndcg@20: 0.026753
2025-11-22 21:40:39 - GraphTrainer - INFO -   map@20: 0.015963
2025-11-22 21:40:39 - GraphTrainer - INFO -   mrr@20: 0.016601
2025-11-22 21:40:39 - GraphTrainer - INFO - 第 21 轮训练完成
2025-11-22 21:40:39 - GraphTrainer - INFO - train_loss: 0.424658
2025-11-22 21:40:39 - GraphTrainer - INFO - precision@5: 0.004999
2025-11-22 21:40:39 - GraphTrainer - INFO - recall@5: 0.023970
2025-11-22 21:40:39 - GraphTrainer - INFO - hit_rate@5: 0.024942
2025-11-22 21:40:39 - GraphTrainer - INFO - ndcg@5: 0.015133
2025-11-22 21:40:39 - GraphTrainer - INFO - map@5: 0.012084
2025-11-22 21:40:39 - GraphTrainer - INFO - mrr@5: 0.012540
2025-11-22 21:40:39 - GraphTrainer - INFO - precision@10: 0.004232
2025-11-22 21:40:39 - GraphTrainer - INFO - recall@10: 0.040429
2025-11-22 21:40:39 - GraphTrainer - INFO - hit_rate@10: 0.042119
2025-11-22 21:40:39 - GraphTrainer - INFO - ndcg@10: 0.020515
2025-11-22 21:40:39 - GraphTrainer - INFO - map@10: 0.014297
2025-11-22 21:40:39 - GraphTrainer - INFO - mrr@10: 0.014840
2025-11-22 21:40:39 - GraphTrainer - INFO - precision@20: 0.003433
2025-11-22 21:40:39 - GraphTrainer - INFO - recall@20: 0.064926
2025-11-22 21:40:39 - GraphTrainer - INFO - hit_rate@20: 0.068089
2025-11-22 21:40:39 - GraphTrainer - INFO - ndcg@20: 0.026753
2025-11-22 21:40:39 - GraphTrainer - INFO - map@20: 0.015963
2025-11-22 21:40:39 - GraphTrainer - INFO - mrr@20: 0.016601
2025-11-22 21:40:39 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:40:39 - GraphTrainer - INFO - ============================================================
2025-11-22 21:40:39 - GraphTrainer - INFO - 开始第 22/1000 轮训练
2025-11-22 21:40:39 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4284, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4311, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4409, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4053, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4335, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4172, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4155, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4290, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4196, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4341, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4212, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4325, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4173, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4291, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4391, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4140, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4237, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4213, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4277, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4198, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4213, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4069, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4117, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4302, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4247, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4422, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4395, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4080, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4325, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4277, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4407, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4326, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4262, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4289, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4274, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4310, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4370, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4139, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4455, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4271, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4254, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4088, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4276, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4386, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4297, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4160, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4314, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4177, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4170, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4230, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4212, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4020, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4299, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4232, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3986, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4416, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4250, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3981, device='cuda:0', grad_fn=<AddBackward0>)
The 21 training average loss: 0.42465784272243234
2025-11-22 21:40:50 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:40:50 - GraphTrainer - INFO -   precision@5: 0.004865
2025-11-22 21:40:50 - GraphTrainer - INFO -   recall@5: 0.023212
2025-11-22 21:40:50 - GraphTrainer - INFO -   hit_rate@5: 0.024274
2025-11-22 21:40:50 - GraphTrainer - INFO -   ndcg@5: 0.014373
2025-11-22 21:40:50 - GraphTrainer - INFO -   map@5: 0.011301
2025-11-22 21:40:50 - GraphTrainer - INFO -   mrr@5: 0.011821
2025-11-22 21:40:50 - GraphTrainer - INFO -   precision@10: 0.004073
2025-11-22 21:40:50 - GraphTrainer - INFO -   recall@10: 0.038662
2025-11-22 21:40:50 - GraphTrainer - INFO -   hit_rate@10: 0.040627
2025-11-22 21:40:50 - GraphTrainer - INFO -   ndcg@10: 0.019381
2025-11-22 21:40:50 - GraphTrainer - INFO -   map@10: 0.013323
2025-11-22 21:40:50 - GraphTrainer - INFO -   mrr@10: 0.013962
2025-11-22 21:40:50 - GraphTrainer - INFO -   precision@20: 0.003402
2025-11-22 21:40:50 - GraphTrainer - INFO -   recall@20: 0.064286
2025-11-22 21:40:50 - GraphTrainer - INFO -   hit_rate@20: 0.067524
2025-11-22 21:40:50 - GraphTrainer - INFO -   ndcg@20: 0.025871
2025-11-22 21:40:50 - GraphTrainer - INFO -   map@20: 0.015049
2025-11-22 21:40:50 - GraphTrainer - INFO -   mrr@20: 0.015763
2025-11-22 21:40:50 - GraphTrainer - INFO - 第 22 轮训练完成
2025-11-22 21:40:50 - GraphTrainer - INFO - train_loss: 0.416446
2025-11-22 21:40:50 - GraphTrainer - INFO - precision@5: 0.004865
2025-11-22 21:40:50 - GraphTrainer - INFO - recall@5: 0.023212
2025-11-22 21:40:50 - GraphTrainer - INFO - hit_rate@5: 0.024274
2025-11-22 21:40:50 - GraphTrainer - INFO - ndcg@5: 0.014373
2025-11-22 21:40:50 - GraphTrainer - INFO - map@5: 0.011301
2025-11-22 21:40:50 - GraphTrainer - INFO - mrr@5: 0.011821
2025-11-22 21:40:50 - GraphTrainer - INFO - precision@10: 0.004073
2025-11-22 21:40:50 - GraphTrainer - INFO - recall@10: 0.038662
2025-11-22 21:40:50 - GraphTrainer - INFO - hit_rate@10: 0.040627
2025-11-22 21:40:50 - GraphTrainer - INFO - ndcg@10: 0.019381
2025-11-22 21:40:50 - GraphTrainer - INFO - map@10: 0.013323
2025-11-22 21:40:50 - GraphTrainer - INFO - mrr@10: 0.013962
2025-11-22 21:40:50 - GraphTrainer - INFO - precision@20: 0.003402
2025-11-22 21:40:50 - GraphTrainer - INFO - recall@20: 0.064286
2025-11-22 21:40:50 - GraphTrainer - INFO - hit_rate@20: 0.067524
2025-11-22 21:40:50 - GraphTrainer - INFO - ndcg@20: 0.025871
2025-11-22 21:40:50 - GraphTrainer - INFO - map@20: 0.015049
2025-11-22 21:40:50 - GraphTrainer - INFO - mrr@20: 0.015763
2025-11-22 21:40:50 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:40:50 - GraphTrainer - INFO - ============================================================
2025-11-22 21:40:50 - GraphTrainer - INFO - 开始第 23/1000 轮训练
2025-11-22 21:40:50 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3839, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4119, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4329, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3978, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4198, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3833, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3976, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4026, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4192, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3987, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4256, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4450, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4167, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4392, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4280, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4263, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3820, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4280, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4283, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4214, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4201, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4283, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4183, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4193, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4193, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4167, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4424, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4200, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3913, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4092, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4432, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4208, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4212, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4372, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4188, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4292, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3993, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4042, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4016, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4151, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4071, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3948, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4257, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4341, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4049, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4277, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4392, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4142, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4284, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4342, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3986, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4185, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3943, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4122, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4167, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4062, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4161, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4171, device='cuda:0', grad_fn=<AddBackward0>)
The 22 training average loss: 0.4164455270972745
2025-11-22 21:41:01 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:41:01 - GraphTrainer - INFO -   precision@5: 0.004721
2025-11-22 21:41:01 - GraphTrainer - INFO -   recall@5: 0.022699
2025-11-22 21:41:01 - GraphTrainer - INFO -   hit_rate@5: 0.023554
2025-11-22 21:41:01 - GraphTrainer - INFO -   ndcg@5: 0.014718
2025-11-22 21:41:01 - GraphTrainer - INFO -   map@5: 0.011941
2025-11-22 21:41:01 - GraphTrainer - INFO -   mrr@5: 0.012397
2025-11-22 21:41:01 - GraphTrainer - INFO -   precision@10: 0.004047
2025-11-22 21:41:01 - GraphTrainer - INFO -   recall@10: 0.038580
2025-11-22 21:41:01 - GraphTrainer - INFO -   hit_rate@10: 0.040319
2025-11-22 21:41:01 - GraphTrainer - INFO -   ndcg@10: 0.019877
2025-11-22 21:41:01 - GraphTrainer - INFO -   map@10: 0.014029
2025-11-22 21:41:01 - GraphTrainer - INFO -   mrr@10: 0.014594
2025-11-22 21:41:01 - GraphTrainer - INFO -   precision@20: 0.003368
2025-11-22 21:41:01 - GraphTrainer - INFO -   recall@20: 0.063858
2025-11-22 21:41:01 - GraphTrainer - INFO -   hit_rate@20: 0.066907
2025-11-22 21:41:01 - GraphTrainer - INFO -   ndcg@20: 0.026282
2025-11-22 21:41:01 - GraphTrainer - INFO -   map@20: 0.015733
2025-11-22 21:41:01 - GraphTrainer - INFO -   mrr@20: 0.016386
2025-11-22 21:41:01 - GraphTrainer - INFO - 第 23 轮训练完成
2025-11-22 21:41:01 - GraphTrainer - INFO - train_loss: 0.417760
2025-11-22 21:41:01 - GraphTrainer - INFO - precision@5: 0.004721
2025-11-22 21:41:01 - GraphTrainer - INFO - recall@5: 0.022699
2025-11-22 21:41:01 - GraphTrainer - INFO - hit_rate@5: 0.023554
2025-11-22 21:41:01 - GraphTrainer - INFO - ndcg@5: 0.014718
2025-11-22 21:41:01 - GraphTrainer - INFO - map@5: 0.011941
2025-11-22 21:41:01 - GraphTrainer - INFO - mrr@5: 0.012397
2025-11-22 21:41:01 - GraphTrainer - INFO - precision@10: 0.004047
2025-11-22 21:41:01 - GraphTrainer - INFO - recall@10: 0.038580
2025-11-22 21:41:01 - GraphTrainer - INFO - hit_rate@10: 0.040319
2025-11-22 21:41:01 - GraphTrainer - INFO - ndcg@10: 0.019877
2025-11-22 21:41:01 - GraphTrainer - INFO - map@10: 0.014029
2025-11-22 21:41:01 - GraphTrainer - INFO - mrr@10: 0.014594
2025-11-22 21:41:01 - GraphTrainer - INFO - precision@20: 0.003368
2025-11-22 21:41:01 - GraphTrainer - INFO - recall@20: 0.063858
2025-11-22 21:41:01 - GraphTrainer - INFO - hit_rate@20: 0.066907
2025-11-22 21:41:01 - GraphTrainer - INFO - ndcg@20: 0.026282
2025-11-22 21:41:01 - GraphTrainer - INFO - map@20: 0.015733
2025-11-22 21:41:01 - GraphTrainer - INFO - mrr@20: 0.016386
2025-11-22 21:41:01 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:41:01 - GraphTrainer - INFO - ============================================================
2025-11-22 21:41:01 - GraphTrainer - INFO - 开始第 24/1000 轮训练
2025-11-22 21:41:01 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3914, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4115, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3881, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4098, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4244, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4079, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4048, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4043, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4110, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4352, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4171, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4178, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4165, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4056, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4307, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3985, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4252, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4139, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4257, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4194, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4253, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4391, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4388, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3992, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4263, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4127, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4122, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4088, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3942, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4068, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4136, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4399, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3967, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4052, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4177, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4322, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4310, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4243, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4425, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4262, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4344, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4232, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4008, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4101, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4378, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4118, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4222, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4343, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4226, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4437, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4126, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4292, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4037, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4185, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4365, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4116, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4237, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4016, device='cuda:0', grad_fn=<AddBackward0>)
The 23 training average loss: 0.4177595243371766
2025-11-22 21:41:12 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:41:12 - GraphTrainer - INFO -   precision@5: 0.005451
2025-11-22 21:41:12 - GraphTrainer - INFO -   recall@5: 0.026041
2025-11-22 21:41:12 - GraphTrainer - INFO -   hit_rate@5: 0.027256
2025-11-22 21:41:12 - GraphTrainer - INFO -   ndcg@5: 0.017042
2025-11-22 21:41:12 - GraphTrainer - INFO -   map@5: 0.013897
2025-11-22 21:41:12 - GraphTrainer - INFO -   mrr@5: 0.014496
2025-11-22 21:41:12 - GraphTrainer - INFO -   precision@10: 0.004484
2025-11-22 21:41:12 - GraphTrainer - INFO -   recall@10: 0.042743
2025-11-22 21:41:12 - GraphTrainer - INFO -   hit_rate@10: 0.044639
2025-11-22 21:41:12 - GraphTrainer - INFO -   ndcg@10: 0.022448
2025-11-22 21:41:12 - GraphTrainer - INFO -   map@10: 0.016084
2025-11-22 21:41:12 - GraphTrainer - INFO -   mrr@10: 0.016763
2025-11-22 21:41:12 - GraphTrainer - INFO -   precision@20: 0.003636
2025-11-22 21:41:12 - GraphTrainer - INFO -   recall@20: 0.068985
2025-11-22 21:41:12 - GraphTrainer - INFO -   hit_rate@20: 0.072255
2025-11-22 21:41:12 - GraphTrainer - INFO -   ndcg@20: 0.029114
2025-11-22 21:41:12 - GraphTrainer - INFO -   map@20: 0.017868
2025-11-22 21:41:12 - GraphTrainer - INFO -   mrr@20: 0.018640
2025-11-22 21:41:12 - GraphTrainer - INFO - 第 24 轮训练完成
2025-11-22 21:41:12 - GraphTrainer - INFO - train_loss: 0.417115
2025-11-22 21:41:12 - GraphTrainer - INFO - precision@5: 0.005451
2025-11-22 21:41:12 - GraphTrainer - INFO - recall@5: 0.026041
2025-11-22 21:41:12 - GraphTrainer - INFO - hit_rate@5: 0.027256
2025-11-22 21:41:12 - GraphTrainer - INFO - ndcg@5: 0.017042
2025-11-22 21:41:12 - GraphTrainer - INFO - map@5: 0.013897
2025-11-22 21:41:12 - GraphTrainer - INFO - mrr@5: 0.014496
2025-11-22 21:41:12 - GraphTrainer - INFO - precision@10: 0.004484
2025-11-22 21:41:12 - GraphTrainer - INFO - recall@10: 0.042743
2025-11-22 21:41:12 - GraphTrainer - INFO - hit_rate@10: 0.044639
2025-11-22 21:41:12 - GraphTrainer - INFO - ndcg@10: 0.022448
2025-11-22 21:41:12 - GraphTrainer - INFO - map@10: 0.016084
2025-11-22 21:41:12 - GraphTrainer - INFO - mrr@10: 0.016763
2025-11-22 21:41:12 - GraphTrainer - INFO - precision@20: 0.003636
2025-11-22 21:41:12 - GraphTrainer - INFO - recall@20: 0.068985
2025-11-22 21:41:12 - GraphTrainer - INFO - hit_rate@20: 0.072255
2025-11-22 21:41:12 - GraphTrainer - INFO - ndcg@20: 0.029114
2025-11-22 21:41:12 - GraphTrainer - INFO - map@20: 0.017868
2025-11-22 21:41:12 - GraphTrainer - INFO - mrr@20: 0.018640
2025-11-22 21:41:12 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:41:12 - GraphTrainer - INFO - ============================================================
2025-11-22 21:41:12 - GraphTrainer - INFO - 开始第 25/1000 轮训练
2025-11-22 21:41:12 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4123, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4217, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4118, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4401, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4087, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4068, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4380, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4338, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4016, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4295, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4089, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4025, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4283, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4229, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4224, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4098, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4072, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4346, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4213, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4301, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4266, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4390, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4111, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4071, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3952, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4346, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4285, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4135, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4147, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3946, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3882, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4368, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4257, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3954, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4114, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4035, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4300, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3984, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3947, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4156, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4292, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4106, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4293, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3979, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4112, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4181, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4294, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4091, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4116, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4270, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4312, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4141, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3950, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4208, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4161, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4122, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4518, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4208, device='cuda:0', grad_fn=<AddBackward0>)
The 24 training average loss: 0.41711515804816934
2025-11-22 21:41:23 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:41:23 - GraphTrainer - INFO -   precision@5: 0.005318
2025-11-22 21:41:23 - GraphTrainer - INFO -   recall@5: 0.025435
2025-11-22 21:41:23 - GraphTrainer - INFO -   hit_rate@5: 0.026536
2025-11-22 21:41:23 - GraphTrainer - INFO -   ndcg@5: 0.016339
2025-11-22 21:41:23 - GraphTrainer - INFO -   map@5: 0.013162
2025-11-22 21:41:23 - GraphTrainer - INFO -   mrr@5: 0.013770
2025-11-22 21:41:23 - GraphTrainer - INFO -   precision@10: 0.004418
2025-11-22 21:41:23 - GraphTrainer - INFO -   recall@10: 0.042076
2025-11-22 21:41:23 - GraphTrainer - INFO -   hit_rate@10: 0.044124
2025-11-22 21:41:23 - GraphTrainer - INFO -   ndcg@10: 0.021746
2025-11-22 21:41:23 - GraphTrainer - INFO -   map@10: 0.015356
2025-11-22 21:41:23 - GraphTrainer - INFO -   mrr@10: 0.016086
2025-11-22 21:41:23 - GraphTrainer - INFO -   precision@20: 0.003579
2025-11-22 21:41:23 - GraphTrainer - INFO -   recall@20: 0.067815
2025-11-22 21:41:23 - GraphTrainer - INFO -   hit_rate@20: 0.071021
2025-11-22 21:41:23 - GraphTrainer - INFO -   ndcg@20: 0.028320
2025-11-22 21:41:23 - GraphTrainer - INFO -   map@20: 0.017137
2025-11-22 21:41:23 - GraphTrainer - INFO -   mrr@20: 0.017938
2025-11-22 21:41:23 - GraphTrainer - INFO - 第 25 轮训练完成
2025-11-22 21:41:23 - GraphTrainer - INFO - train_loss: 0.412967
2025-11-22 21:41:23 - GraphTrainer - INFO - precision@5: 0.005318
2025-11-22 21:41:23 - GraphTrainer - INFO - recall@5: 0.025435
2025-11-22 21:41:23 - GraphTrainer - INFO - hit_rate@5: 0.026536
2025-11-22 21:41:23 - GraphTrainer - INFO - ndcg@5: 0.016339
2025-11-22 21:41:23 - GraphTrainer - INFO - map@5: 0.013162
2025-11-22 21:41:23 - GraphTrainer - INFO - mrr@5: 0.013770
2025-11-22 21:41:23 - GraphTrainer - INFO - precision@10: 0.004418
2025-11-22 21:41:23 - GraphTrainer - INFO - recall@10: 0.042076
2025-11-22 21:41:23 - GraphTrainer - INFO - hit_rate@10: 0.044124
2025-11-22 21:41:23 - GraphTrainer - INFO - ndcg@10: 0.021746
2025-11-22 21:41:23 - GraphTrainer - INFO - map@10: 0.015356
2025-11-22 21:41:23 - GraphTrainer - INFO - mrr@10: 0.016086
2025-11-22 21:41:23 - GraphTrainer - INFO - precision@20: 0.003579
2025-11-22 21:41:23 - GraphTrainer - INFO - recall@20: 0.067815
2025-11-22 21:41:23 - GraphTrainer - INFO - hit_rate@20: 0.071021
2025-11-22 21:41:23 - GraphTrainer - INFO - ndcg@20: 0.028320
2025-11-22 21:41:23 - GraphTrainer - INFO - map@20: 0.017137
2025-11-22 21:41:23 - GraphTrainer - INFO - mrr@20: 0.017938
2025-11-22 21:41:23 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:41:23 - GraphTrainer - INFO - ============================================================
2025-11-22 21:41:23 - GraphTrainer - INFO - 开始第 26/1000 轮训练
2025-11-22 21:41:23 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4111, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4240, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3988, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3936, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4117, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4091, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4292, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4130, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3963, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4017, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4242, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4122, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4068, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4303, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4344, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4128, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4069, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3930, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4390, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4328, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4081, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4192, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4154, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4011, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4110, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4090, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4161, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4270, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4090, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4363, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4251, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4122, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4233, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4093, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4382, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4099, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4156, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3985, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3883, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4070, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4198, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4406, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4045, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4089, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4187, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3932, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4030, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4140, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4433, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3948, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3881, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4084, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4284, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4175, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3777, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4154, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4035, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4118, device='cuda:0', grad_fn=<AddBackward0>)
The 25 training average loss: 0.41296657406050585
2025-11-22 21:41:34 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:41:34 - GraphTrainer - INFO -   precision@5: 0.005451
2025-11-22 21:41:34 - GraphTrainer - INFO -   recall@5: 0.025708
2025-11-22 21:41:34 - GraphTrainer - INFO -   hit_rate@5: 0.027102
2025-11-22 21:41:34 - GraphTrainer - INFO -   ndcg@5: 0.016670
2025-11-22 21:41:34 - GraphTrainer - INFO -   map@5: 0.013464
2025-11-22 21:41:34 - GraphTrainer - INFO -   mrr@5: 0.014197
2025-11-22 21:41:34 - GraphTrainer - INFO -   precision@10: 0.004263
2025-11-22 21:41:34 - GraphTrainer - INFO -   recall@10: 0.040372
2025-11-22 21:41:34 - GraphTrainer - INFO -   hit_rate@10: 0.042376
2025-11-22 21:41:34 - GraphTrainer - INFO -   ndcg@10: 0.021386
2025-11-22 21:41:34 - GraphTrainer - INFO -   map@10: 0.015364
2025-11-22 21:41:34 - GraphTrainer - INFO -   mrr@10: 0.016174
2025-11-22 21:41:34 - GraphTrainer - INFO -   precision@20: 0.003433
2025-11-22 21:41:34 - GraphTrainer - INFO -   recall@20: 0.065049
2025-11-22 21:41:34 - GraphTrainer - INFO -   hit_rate@20: 0.068295
2025-11-22 21:41:34 - GraphTrainer - INFO -   ndcg@20: 0.027665
2025-11-22 21:41:34 - GraphTrainer - INFO -   map@20: 0.017054
2025-11-22 21:41:34 - GraphTrainer - INFO -   mrr@20: 0.017941
2025-11-22 21:41:34 - GraphTrainer - INFO - 第 26 轮训练完成
2025-11-22 21:41:34 - GraphTrainer - INFO - train_loss: 0.410657
2025-11-22 21:41:34 - GraphTrainer - INFO - precision@5: 0.005451
2025-11-22 21:41:34 - GraphTrainer - INFO - recall@5: 0.025708
2025-11-22 21:41:34 - GraphTrainer - INFO - hit_rate@5: 0.027102
2025-11-22 21:41:34 - GraphTrainer - INFO - ndcg@5: 0.016670
2025-11-22 21:41:34 - GraphTrainer - INFO - map@5: 0.013464
2025-11-22 21:41:34 - GraphTrainer - INFO - mrr@5: 0.014197
2025-11-22 21:41:34 - GraphTrainer - INFO - precision@10: 0.004263
2025-11-22 21:41:34 - GraphTrainer - INFO - recall@10: 0.040372
2025-11-22 21:41:34 - GraphTrainer - INFO - hit_rate@10: 0.042376
2025-11-22 21:41:34 - GraphTrainer - INFO - ndcg@10: 0.021386
2025-11-22 21:41:34 - GraphTrainer - INFO - map@10: 0.015364
2025-11-22 21:41:34 - GraphTrainer - INFO - mrr@10: 0.016174
2025-11-22 21:41:34 - GraphTrainer - INFO - precision@20: 0.003433
2025-11-22 21:41:34 - GraphTrainer - INFO - recall@20: 0.065049
2025-11-22 21:41:34 - GraphTrainer - INFO - hit_rate@20: 0.068295
2025-11-22 21:41:34 - GraphTrainer - INFO - ndcg@20: 0.027665
2025-11-22 21:41:34 - GraphTrainer - INFO - map@20: 0.017054
2025-11-22 21:41:34 - GraphTrainer - INFO - mrr@20: 0.017941
2025-11-22 21:41:34 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:41:34 - GraphTrainer - INFO - ============================================================
2025-11-22 21:41:34 - GraphTrainer - INFO - 开始第 27/1000 轮训练
2025-11-22 21:41:34 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4119, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4012, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4129, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4037, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4377, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4085, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4264, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3987, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4005, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4149, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4122, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4118, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4211, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4025, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4078, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3857, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4130, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3824, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4279, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4041, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4156, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4166, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4082, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4014, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4037, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4087, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4159, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4190, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4277, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4002, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4089, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4209, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4085, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4053, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4328, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3897, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3860, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4372, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4314, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3881, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4057, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4563, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4135, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3917, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4163, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4105, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4079, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3906, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4156, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4159, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4019, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3997, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4084, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3996, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4298, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4122, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4176, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4145, device='cuda:0', grad_fn=<AddBackward0>)
The 26 training average loss: 0.4106565251432616
2025-11-22 21:41:46 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:41:46 - GraphTrainer - INFO -   precision@5: 0.005091
2025-11-22 21:41:46 - GraphTrainer - INFO -   recall@5: 0.024650
2025-11-22 21:41:46 - GraphTrainer - INFO -   hit_rate@5: 0.025405
2025-11-22 21:41:46 - GraphTrainer - INFO -   ndcg@5: 0.015608
2025-11-22 21:41:46 - GraphTrainer - INFO -   map@5: 0.012537
2025-11-22 21:41:46 - GraphTrainer - INFO -   mrr@5: 0.012862
2025-11-22 21:41:46 - GraphTrainer - INFO -   precision@10: 0.004315
2025-11-22 21:41:46 - GraphTrainer - INFO -   recall@10: 0.041362
2025-11-22 21:41:46 - GraphTrainer - INFO -   hit_rate@10: 0.043044
2025-11-22 21:41:46 - GraphTrainer - INFO -   ndcg@10: 0.021031
2025-11-22 21:41:46 - GraphTrainer - INFO -   map@10: 0.014729
2025-11-22 21:41:46 - GraphTrainer - INFO -   mrr@10: 0.015168
2025-11-22 21:41:46 - GraphTrainer - INFO -   precision@20: 0.003435
2025-11-22 21:41:46 - GraphTrainer - INFO -   recall@20: 0.065372
2025-11-22 21:41:46 - GraphTrainer - INFO -   hit_rate@20: 0.068347
2025-11-22 21:41:46 - GraphTrainer - INFO -   ndcg@20: 0.027145
2025-11-22 21:41:46 - GraphTrainer - INFO -   map@20: 0.016374
2025-11-22 21:41:46 - GraphTrainer - INFO -   mrr@20: 0.016891
2025-11-22 21:41:46 - GraphTrainer - INFO - 第 27 轮训练完成
2025-11-22 21:41:46 - GraphTrainer - INFO - train_loss: 0.408098
2025-11-22 21:41:46 - GraphTrainer - INFO - precision@5: 0.005091
2025-11-22 21:41:46 - GraphTrainer - INFO - recall@5: 0.024650
2025-11-22 21:41:46 - GraphTrainer - INFO - hit_rate@5: 0.025405
2025-11-22 21:41:46 - GraphTrainer - INFO - ndcg@5: 0.015608
2025-11-22 21:41:46 - GraphTrainer - INFO - map@5: 0.012537
2025-11-22 21:41:46 - GraphTrainer - INFO - mrr@5: 0.012862
2025-11-22 21:41:46 - GraphTrainer - INFO - precision@10: 0.004315
2025-11-22 21:41:46 - GraphTrainer - INFO - recall@10: 0.041362
2025-11-22 21:41:46 - GraphTrainer - INFO - hit_rate@10: 0.043044
2025-11-22 21:41:46 - GraphTrainer - INFO - ndcg@10: 0.021031
2025-11-22 21:41:46 - GraphTrainer - INFO - map@10: 0.014729
2025-11-22 21:41:46 - GraphTrainer - INFO - mrr@10: 0.015168
2025-11-22 21:41:46 - GraphTrainer - INFO - precision@20: 0.003435
2025-11-22 21:41:46 - GraphTrainer - INFO - recall@20: 0.065372
2025-11-22 21:41:46 - GraphTrainer - INFO - hit_rate@20: 0.068347
2025-11-22 21:41:46 - GraphTrainer - INFO - ndcg@20: 0.027145
2025-11-22 21:41:46 - GraphTrainer - INFO - map@20: 0.016374
2025-11-22 21:41:46 - GraphTrainer - INFO - mrr@20: 0.016891
2025-11-22 21:41:46 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:41:46 - GraphTrainer - INFO - ============================================================
2025-11-22 21:41:46 - GraphTrainer - INFO - 开始第 28/1000 轮训练
2025-11-22 21:41:46 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4313, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3983, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4107, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4204, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4249, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3880, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4112, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4045, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4057, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4263, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3942, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4190, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3968, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3969, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3853, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4078, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4162, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4091, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4008, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3970, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4311, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4114, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3928, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4181, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4107, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4215, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3989, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3997, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3928, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3802, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3970, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4023, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3896, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4208, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3969, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4257, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4142, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3966, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4173, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4154, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4209, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3944, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4227, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3935, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4369, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4102, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4057, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4399, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4109, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4071, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3982, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4193, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4219, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3984, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3836, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4132, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4166, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3988, device='cuda:0', grad_fn=<AddBackward0>)
The 27 training average loss: 0.408097668968398
2025-11-22 21:41:56 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:41:56 - GraphTrainer - INFO -   precision@5: 0.005420
2025-11-22 21:41:56 - GraphTrainer - INFO -   recall@5: 0.025955
2025-11-22 21:41:56 - GraphTrainer - INFO -   hit_rate@5: 0.027051
2025-11-22 21:41:56 - GraphTrainer - INFO -   ndcg@5: 0.016842
2025-11-22 21:41:56 - GraphTrainer - INFO -   map@5: 0.013673
2025-11-22 21:41:56 - GraphTrainer - INFO -   mrr@5: 0.014258
2025-11-22 21:41:56 - GraphTrainer - INFO -   precision@10: 0.004340
2025-11-22 21:41:56 - GraphTrainer - INFO -   recall@10: 0.041470
2025-11-22 21:41:56 - GraphTrainer - INFO -   hit_rate@10: 0.043250
2025-11-22 21:41:56 - GraphTrainer - INFO -   ndcg@10: 0.021893
2025-11-22 21:41:56 - GraphTrainer - INFO -   map@10: 0.015738
2025-11-22 21:41:56 - GraphTrainer - INFO -   mrr@10: 0.016408
2025-11-22 21:41:56 - GraphTrainer - INFO -   precision@20: 0.003543
2025-11-22 21:41:56 - GraphTrainer - INFO -   recall@20: 0.067490
2025-11-22 21:41:56 - GraphTrainer - INFO -   hit_rate@20: 0.070455
2025-11-22 21:41:56 - GraphTrainer - INFO -   ndcg@20: 0.028468
2025-11-22 21:41:56 - GraphTrainer - INFO -   map@20: 0.017486
2025-11-22 21:41:56 - GraphTrainer - INFO -   mrr@20: 0.018231
2025-11-22 21:41:56 - GraphTrainer - INFO - 第 28 轮训练完成
2025-11-22 21:41:56 - GraphTrainer - INFO - train_loss: 0.404373
2025-11-22 21:41:56 - GraphTrainer - INFO - precision@5: 0.005420
2025-11-22 21:41:56 - GraphTrainer - INFO - recall@5: 0.025955
2025-11-22 21:41:56 - GraphTrainer - INFO - hit_rate@5: 0.027051
2025-11-22 21:41:56 - GraphTrainer - INFO - ndcg@5: 0.016842
2025-11-22 21:41:56 - GraphTrainer - INFO - map@5: 0.013673
2025-11-22 21:41:56 - GraphTrainer - INFO - mrr@5: 0.014258
2025-11-22 21:41:56 - GraphTrainer - INFO - precision@10: 0.004340
2025-11-22 21:41:56 - GraphTrainer - INFO - recall@10: 0.041470
2025-11-22 21:41:56 - GraphTrainer - INFO - hit_rate@10: 0.043250
2025-11-22 21:41:56 - GraphTrainer - INFO - ndcg@10: 0.021893
2025-11-22 21:41:56 - GraphTrainer - INFO - map@10: 0.015738
2025-11-22 21:41:56 - GraphTrainer - INFO - mrr@10: 0.016408
2025-11-22 21:41:56 - GraphTrainer - INFO - precision@20: 0.003543
2025-11-22 21:41:56 - GraphTrainer - INFO - recall@20: 0.067490
2025-11-22 21:41:56 - GraphTrainer - INFO - hit_rate@20: 0.070455
2025-11-22 21:41:56 - GraphTrainer - INFO - ndcg@20: 0.028468
2025-11-22 21:41:56 - GraphTrainer - INFO - map@20: 0.017486
2025-11-22 21:41:56 - GraphTrainer - INFO - mrr@20: 0.018231
2025-11-22 21:41:56 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:41:56 - GraphTrainer - INFO - ============================================================
2025-11-22 21:41:56 - GraphTrainer - INFO - 开始第 29/1000 轮训练
2025-11-22 21:41:56 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3818, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4024, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3844, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4205, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4185, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4049, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3929, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4146, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3927, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4305, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3840, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3900, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4080, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3978, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4039, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4302, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3836, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4353, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4125, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4155, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3980, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4070, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3879, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3897, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3912, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4004, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4124, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3785, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4186, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4042, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4007, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4070, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3984, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4054, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4123, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4164, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4244, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3951, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4004, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4050, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4131, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4077, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4153, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4137, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4053, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3984, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4057, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4120, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3813, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4009, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4027, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4093, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4060, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4021, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4009, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4082, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4082, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4055, device='cuda:0', grad_fn=<AddBackward0>)
The 28 training average loss: 0.40437329072376776
2025-11-22 21:42:08 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:42:08 - GraphTrainer - INFO -   precision@5: 0.005451
2025-11-22 21:42:08 - GraphTrainer - INFO -   recall@5: 0.026028
2025-11-22 21:42:08 - GraphTrainer - INFO -   hit_rate@5: 0.027205
2025-11-22 21:42:08 - GraphTrainer - INFO -   ndcg@5: 0.017887
2025-11-22 21:42:08 - GraphTrainer - INFO -   map@5: 0.015004
2025-11-22 21:42:08 - GraphTrainer - INFO -   mrr@5: 0.015571
2025-11-22 21:42:08 - GraphTrainer - INFO -   precision@10: 0.004423
2025-11-22 21:42:08 - GraphTrainer - INFO -   recall@10: 0.042024
2025-11-22 21:42:08 - GraphTrainer - INFO -   hit_rate@10: 0.044124
2025-11-22 21:42:08 - GraphTrainer - INFO -   ndcg@10: 0.023050
2025-11-22 21:42:08 - GraphTrainer - INFO -   map@10: 0.017077
2025-11-22 21:42:08 - GraphTrainer - INFO -   mrr@10: 0.017764
2025-11-22 21:42:08 - GraphTrainer - INFO -   precision@20: 0.003541
2025-11-22 21:42:08 - GraphTrainer - INFO -   recall@20: 0.066911
2025-11-22 21:42:08 - GraphTrainer - INFO -   hit_rate@20: 0.070301
2025-11-22 21:42:08 - GraphTrainer - INFO -   ndcg@20: 0.029344
2025-11-22 21:42:08 - GraphTrainer - INFO -   map@20: 0.018744
2025-11-22 21:42:08 - GraphTrainer - INFO -   mrr@20: 0.019512
2025-11-22 21:42:08 - GraphTrainer - INFO - 第 29 轮训练完成
2025-11-22 21:42:08 - GraphTrainer - INFO - train_loss: 0.405337
2025-11-22 21:42:08 - GraphTrainer - INFO - precision@5: 0.005451
2025-11-22 21:42:08 - GraphTrainer - INFO - recall@5: 0.026028
2025-11-22 21:42:08 - GraphTrainer - INFO - hit_rate@5: 0.027205
2025-11-22 21:42:08 - GraphTrainer - INFO - ndcg@5: 0.017887
2025-11-22 21:42:08 - GraphTrainer - INFO - map@5: 0.015004
2025-11-22 21:42:08 - GraphTrainer - INFO - mrr@5: 0.015571
2025-11-22 21:42:08 - GraphTrainer - INFO - precision@10: 0.004423
2025-11-22 21:42:08 - GraphTrainer - INFO - recall@10: 0.042024
2025-11-22 21:42:08 - GraphTrainer - INFO - hit_rate@10: 0.044124
2025-11-22 21:42:08 - GraphTrainer - INFO - ndcg@10: 0.023050
2025-11-22 21:42:08 - GraphTrainer - INFO - map@10: 0.017077
2025-11-22 21:42:08 - GraphTrainer - INFO - mrr@10: 0.017764
2025-11-22 21:42:08 - GraphTrainer - INFO - precision@20: 0.003541
2025-11-22 21:42:08 - GraphTrainer - INFO - recall@20: 0.066911
2025-11-22 21:42:08 - GraphTrainer - INFO - hit_rate@20: 0.070301
2025-11-22 21:42:08 - GraphTrainer - INFO - ndcg@20: 0.029344
2025-11-22 21:42:08 - GraphTrainer - INFO - map@20: 0.018744
2025-11-22 21:42:08 - GraphTrainer - INFO - mrr@20: 0.019512
2025-11-22 21:42:08 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:42:08 - GraphTrainer - INFO - ============================================================
2025-11-22 21:42:08 - GraphTrainer - INFO - 开始第 30/1000 轮训练
2025-11-22 21:42:08 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4183, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4091, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4008, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3873, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4009, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4001, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3850, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4017, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3931, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4021, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3917, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3817, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4169, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4253, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4146, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3944, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3977, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4235, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3942, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3987, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3849, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4279, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3999, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3910, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4170, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4358, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4087, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4155, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4284, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3901, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3918, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3880, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4260, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4312, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3904, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4177, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3926, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4262, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4017, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4223, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4122, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4090, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3869, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4182, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3918, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4065, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4111, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4227, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3892, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3903, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4057, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4071, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3997, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3972, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4045, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4151, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3983, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4197, device='cuda:0', grad_fn=<AddBackward0>)
The 29 training average loss: 0.4053370752211275
2025-11-22 21:42:19 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:42:19 - GraphTrainer - INFO -   precision@5: 0.004844
2025-11-22 21:42:19 - GraphTrainer - INFO -   recall@5: 0.023053
2025-11-22 21:42:19 - GraphTrainer - INFO -   hit_rate@5: 0.024171
2025-11-22 21:42:19 - GraphTrainer - INFO -   ndcg@5: 0.015169
2025-11-22 21:42:19 - GraphTrainer - INFO -   map@5: 0.012391
2025-11-22 21:42:19 - GraphTrainer - INFO -   mrr@5: 0.012945
2025-11-22 21:42:19 - GraphTrainer - INFO -   precision@10: 0.004181
2025-11-22 21:42:19 - GraphTrainer - INFO -   recall@10: 0.039559
2025-11-22 21:42:19 - GraphTrainer - INFO -   hit_rate@10: 0.041656
2025-11-22 21:42:19 - GraphTrainer - INFO -   ndcg@10: 0.020520
2025-11-22 21:42:19 - GraphTrainer - INFO -   map@10: 0.014550
2025-11-22 21:42:19 - GraphTrainer - INFO -   mrr@10: 0.015225
2025-11-22 21:42:19 - GraphTrainer - INFO -   precision@20: 0.003494
2025-11-22 21:42:19 - GraphTrainer - INFO -   recall@20: 0.066143
2025-11-22 21:42:19 - GraphTrainer - INFO -   hit_rate@20: 0.069581
2025-11-22 21:42:19 - GraphTrainer - INFO -   ndcg@20: 0.027304
2025-11-22 21:42:19 - GraphTrainer - INFO -   map@20: 0.016387
2025-11-22 21:42:19 - GraphTrainer - INFO -   mrr@20: 0.017146
2025-11-22 21:42:19 - GraphTrainer - INFO - 第 30 轮训练完成
2025-11-22 21:42:19 - GraphTrainer - INFO - train_loss: 0.403053
2025-11-22 21:42:19 - GraphTrainer - INFO - precision@5: 0.004844
2025-11-22 21:42:19 - GraphTrainer - INFO - recall@5: 0.023053
2025-11-22 21:42:19 - GraphTrainer - INFO - hit_rate@5: 0.024171
2025-11-22 21:42:19 - GraphTrainer - INFO - ndcg@5: 0.015169
2025-11-22 21:42:19 - GraphTrainer - INFO - map@5: 0.012391
2025-11-22 21:42:19 - GraphTrainer - INFO - mrr@5: 0.012945
2025-11-22 21:42:19 - GraphTrainer - INFO - precision@10: 0.004181
2025-11-22 21:42:19 - GraphTrainer - INFO - recall@10: 0.039559
2025-11-22 21:42:19 - GraphTrainer - INFO - hit_rate@10: 0.041656
2025-11-22 21:42:19 - GraphTrainer - INFO - ndcg@10: 0.020520
2025-11-22 21:42:19 - GraphTrainer - INFO - map@10: 0.014550
2025-11-22 21:42:19 - GraphTrainer - INFO - mrr@10: 0.015225
2025-11-22 21:42:19 - GraphTrainer - INFO - precision@20: 0.003494
2025-11-22 21:42:19 - GraphTrainer - INFO - recall@20: 0.066143
2025-11-22 21:42:19 - GraphTrainer - INFO - hit_rate@20: 0.069581
2025-11-22 21:42:19 - GraphTrainer - INFO - ndcg@20: 0.027304
2025-11-22 21:42:19 - GraphTrainer - INFO - map@20: 0.016387
2025-11-22 21:42:19 - GraphTrainer - INFO - mrr@20: 0.017146
2025-11-22 21:42:19 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:42:19 - GraphTrainer - INFO - 检查点已保存: Epoch 30 -> ./checkpoints/checkpoint_epoch_30.pth
2025-11-22 21:42:19 - GraphTrainer - INFO - ============================================================
2025-11-22 21:42:19 - GraphTrainer - INFO - 开始第 31/1000 轮训练
2025-11-22 21:42:19 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3824, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3716, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3861, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4095, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4160, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4033, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4224, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4009, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4072, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3952, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4337, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4005, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3632, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4035, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4178, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4017, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3907, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4344, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3839, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4040, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4100, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4277, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3915, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3963, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4208, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4030, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3945, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4019, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4081, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4036, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4199, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4029, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4089, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4130, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3899, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4155, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4165, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3841, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3967, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3996, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3924, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4155, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4268, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3904, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4225, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4035, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4078, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3897, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4038, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4107, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4099, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3814, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4240, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4000, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3860, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3866, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4159, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3780, device='cuda:0', grad_fn=<AddBackward0>)
The 30 training average loss: 0.40305317784177846
2025-11-22 21:42:30 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:42:30 - GraphTrainer - INFO -   precision@5: 0.005235
2025-11-22 21:42:30 - GraphTrainer - INFO -   recall@5: 0.025110
2025-11-22 21:42:30 - GraphTrainer - INFO -   hit_rate@5: 0.026125
2025-11-22 21:42:30 - GraphTrainer - INFO -   ndcg@5: 0.016092
2025-11-22 21:42:30 - GraphTrainer - INFO -   map@5: 0.012969
2025-11-22 21:42:30 - GraphTrainer - INFO -   mrr@5: 0.013486
2025-11-22 21:42:30 - GraphTrainer - INFO -   precision@10: 0.004299
2025-11-22 21:42:30 - GraphTrainer - INFO -   recall@10: 0.041190
2025-11-22 21:42:30 - GraphTrainer - INFO -   hit_rate@10: 0.042942
2025-11-22 21:42:30 - GraphTrainer - INFO -   ndcg@10: 0.021311
2025-11-22 21:42:30 - GraphTrainer - INFO -   map@10: 0.015091
2025-11-22 21:42:30 - GraphTrainer - INFO -   mrr@10: 0.015707
2025-11-22 21:42:30 - GraphTrainer - INFO -   precision@20: 0.003546
2025-11-22 21:42:30 - GraphTrainer - INFO -   recall@20: 0.067448
2025-11-22 21:42:30 - GraphTrainer - INFO -   hit_rate@20: 0.070609
2025-11-22 21:42:30 - GraphTrainer - INFO -   ndcg@20: 0.027965
2025-11-22 21:42:30 - GraphTrainer - INFO -   map@20: 0.016860
2025-11-22 21:42:30 - GraphTrainer - INFO -   mrr@20: 0.017569
2025-11-22 21:42:30 - GraphTrainer - INFO - 第 31 轮训练完成
2025-11-22 21:42:30 - GraphTrainer - INFO - train_loss: 0.397269
2025-11-22 21:42:30 - GraphTrainer - INFO - precision@5: 0.005235
2025-11-22 21:42:30 - GraphTrainer - INFO - recall@5: 0.025110
2025-11-22 21:42:30 - GraphTrainer - INFO - hit_rate@5: 0.026125
2025-11-22 21:42:30 - GraphTrainer - INFO - ndcg@5: 0.016092
2025-11-22 21:42:30 - GraphTrainer - INFO - map@5: 0.012969
2025-11-22 21:42:30 - GraphTrainer - INFO - mrr@5: 0.013486
2025-11-22 21:42:30 - GraphTrainer - INFO - precision@10: 0.004299
2025-11-22 21:42:30 - GraphTrainer - INFO - recall@10: 0.041190
2025-11-22 21:42:30 - GraphTrainer - INFO - hit_rate@10: 0.042942
2025-11-22 21:42:30 - GraphTrainer - INFO - ndcg@10: 0.021311
2025-11-22 21:42:30 - GraphTrainer - INFO - map@10: 0.015091
2025-11-22 21:42:30 - GraphTrainer - INFO - mrr@10: 0.015707
2025-11-22 21:42:30 - GraphTrainer - INFO - precision@20: 0.003546
2025-11-22 21:42:30 - GraphTrainer - INFO - recall@20: 0.067448
2025-11-22 21:42:30 - GraphTrainer - INFO - hit_rate@20: 0.070609
2025-11-22 21:42:30 - GraphTrainer - INFO - ndcg@20: 0.027965
2025-11-22 21:42:30 - GraphTrainer - INFO - map@20: 0.016860
2025-11-22 21:42:30 - GraphTrainer - INFO - mrr@20: 0.017569
2025-11-22 21:42:30 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:42:30 - GraphTrainer - INFO - ============================================================
2025-11-22 21:42:30 - GraphTrainer - INFO - 开始第 32/1000 轮训练
2025-11-22 21:42:30 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3828, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3913, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4168, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4139, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3911, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3756, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3899, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4255, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3996, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4021, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4086, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3914, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3941, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3991, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3915, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4106, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3961, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3979, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3956, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3824, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3971, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4129, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3869, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3960, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3860, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4097, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3795, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3874, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3887, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4026, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3979, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3991, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4029, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3876, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4128, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4152, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3907, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3857, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4033, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3915, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4011, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3936, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3957, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3826, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3950, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3948, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4137, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4154, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3749, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3857, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3921, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4042, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3910, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3891, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4155, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4233, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3945, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3899, device='cuda:0', grad_fn=<AddBackward0>)
The 31 training average loss: 0.39726874848891947
2025-11-22 21:42:41 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:42:41 - GraphTrainer - INFO -   precision@5: 0.005534
2025-11-22 21:42:41 - GraphTrainer - INFO -   recall@5: 0.026405
2025-11-22 21:42:41 - GraphTrainer - INFO -   hit_rate@5: 0.027616
2025-11-22 21:42:41 - GraphTrainer - INFO -   ndcg@5: 0.017514
2025-11-22 21:42:41 - GraphTrainer - INFO -   map@5: 0.014394
2025-11-22 21:42:41 - GraphTrainer - INFO -   mrr@5: 0.015039
2025-11-22 21:42:41 - GraphTrainer - INFO -   precision@10: 0.004510
2025-11-22 21:42:41 - GraphTrainer - INFO -   recall@10: 0.042882
2025-11-22 21:42:41 - GraphTrainer - INFO -   hit_rate@10: 0.044947
2025-11-22 21:42:41 - GraphTrainer - INFO -   ndcg@10: 0.022839
2025-11-22 21:42:41 - GraphTrainer - INFO -   map@10: 0.016538
2025-11-22 21:42:41 - GraphTrainer - INFO -   mrr@10: 0.017290
2025-11-22 21:42:41 - GraphTrainer - INFO -   precision@20: 0.003618
2025-11-22 21:42:41 - GraphTrainer - INFO -   recall@20: 0.068521
2025-11-22 21:42:41 - GraphTrainer - INFO -   hit_rate@20: 0.072049
2025-11-22 21:42:41 - GraphTrainer - INFO -   ndcg@20: 0.029368
2025-11-22 21:42:41 - GraphTrainer - INFO -   map@20: 0.018292
2025-11-22 21:42:41 - GraphTrainer - INFO -   mrr@20: 0.019142
2025-11-22 21:42:41 - GraphTrainer - INFO - 第 32 轮训练完成
2025-11-22 21:42:41 - GraphTrainer - INFO - train_loss: 0.397239
2025-11-22 21:42:41 - GraphTrainer - INFO - precision@5: 0.005534
2025-11-22 21:42:41 - GraphTrainer - INFO - recall@5: 0.026405
2025-11-22 21:42:41 - GraphTrainer - INFO - hit_rate@5: 0.027616
2025-11-22 21:42:41 - GraphTrainer - INFO - ndcg@5: 0.017514
2025-11-22 21:42:41 - GraphTrainer - INFO - map@5: 0.014394
2025-11-22 21:42:41 - GraphTrainer - INFO - mrr@5: 0.015039
2025-11-22 21:42:41 - GraphTrainer - INFO - precision@10: 0.004510
2025-11-22 21:42:41 - GraphTrainer - INFO - recall@10: 0.042882
2025-11-22 21:42:41 - GraphTrainer - INFO - hit_rate@10: 0.044947
2025-11-22 21:42:41 - GraphTrainer - INFO - ndcg@10: 0.022839
2025-11-22 21:42:41 - GraphTrainer - INFO - map@10: 0.016538
2025-11-22 21:42:41 - GraphTrainer - INFO - mrr@10: 0.017290
2025-11-22 21:42:41 - GraphTrainer - INFO - precision@20: 0.003618
2025-11-22 21:42:41 - GraphTrainer - INFO - recall@20: 0.068521
2025-11-22 21:42:41 - GraphTrainer - INFO - hit_rate@20: 0.072049
2025-11-22 21:42:41 - GraphTrainer - INFO - ndcg@20: 0.029368
2025-11-22 21:42:41 - GraphTrainer - INFO - map@20: 0.018292
2025-11-22 21:42:41 - GraphTrainer - INFO - mrr@20: 0.019142
2025-11-22 21:42:41 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:42:41 - GraphTrainer - INFO - ============================================================
2025-11-22 21:42:41 - GraphTrainer - INFO - 开始第 33/1000 轮训练
2025-11-22 21:42:41 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3957, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4139, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4181, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3894, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3916, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3814, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3856, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3929, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3979, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4247, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3887, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3938, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3848, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3725, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3845, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3927, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3913, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3956, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4189, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3815, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3814, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3784, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3996, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3746, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4151, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4112, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3914, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4053, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3997, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3934, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4062, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4059, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4217, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4152, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3815, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3908, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4055, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4201, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3980, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3977, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4074, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4188, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4067, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4089, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4167, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3836, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3819, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4005, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3941, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3933, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4116, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3692, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3986, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4090, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4027, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3947, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3855, device='cuda:0', grad_fn=<AddBackward0>)
The 32 training average loss: 0.397239462055009
2025-11-22 21:42:52 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:42:52 - GraphTrainer - INFO -   precision@5: 0.005256
2025-11-22 21:42:52 - GraphTrainer - INFO -   recall@5: 0.025102
2025-11-22 21:42:52 - GraphTrainer - INFO -   hit_rate@5: 0.026228
2025-11-22 21:42:52 - GraphTrainer - INFO -   ndcg@5: 0.016637
2025-11-22 21:42:52 - GraphTrainer - INFO -   map@5: 0.013665
2025-11-22 21:42:52 - GraphTrainer - INFO -   mrr@5: 0.014189
2025-11-22 21:42:52 - GraphTrainer - INFO -   precision@10: 0.004335
2025-11-22 21:42:52 - GraphTrainer - INFO -   recall@10: 0.041277
2025-11-22 21:42:52 - GraphTrainer - INFO -   hit_rate@10: 0.043250
2025-11-22 21:42:52 - GraphTrainer - INFO -   ndcg@10: 0.021866
2025-11-22 21:42:52 - GraphTrainer - INFO -   map@10: 0.015773
2025-11-22 21:42:52 - GraphTrainer - INFO -   mrr@10: 0.016406
2025-11-22 21:42:52 - GraphTrainer - INFO -   precision@20: 0.003582
2025-11-22 21:42:52 - GraphTrainer - INFO -   recall@20: 0.067942
2025-11-22 21:42:52 - GraphTrainer - INFO -   hit_rate@20: 0.071381
2025-11-22 21:42:52 - GraphTrainer - INFO -   ndcg@20: 0.028664
2025-11-22 21:42:52 - GraphTrainer - INFO -   map@20: 0.017605
2025-11-22 21:42:52 - GraphTrainer - INFO -   mrr@20: 0.018332
2025-11-22 21:42:52 - GraphTrainer - INFO - 第 33 轮训练完成
2025-11-22 21:42:52 - GraphTrainer - INFO - train_loss: 0.395932
2025-11-22 21:42:52 - GraphTrainer - INFO - precision@5: 0.005256
2025-11-22 21:42:52 - GraphTrainer - INFO - recall@5: 0.025102
2025-11-22 21:42:52 - GraphTrainer - INFO - hit_rate@5: 0.026228
2025-11-22 21:42:52 - GraphTrainer - INFO - ndcg@5: 0.016637
2025-11-22 21:42:52 - GraphTrainer - INFO - map@5: 0.013665
2025-11-22 21:42:52 - GraphTrainer - INFO - mrr@5: 0.014189
2025-11-22 21:42:52 - GraphTrainer - INFO - precision@10: 0.004335
2025-11-22 21:42:52 - GraphTrainer - INFO - recall@10: 0.041277
2025-11-22 21:42:52 - GraphTrainer - INFO - hit_rate@10: 0.043250
2025-11-22 21:42:52 - GraphTrainer - INFO - ndcg@10: 0.021866
2025-11-22 21:42:52 - GraphTrainer - INFO - map@10: 0.015773
2025-11-22 21:42:52 - GraphTrainer - INFO - mrr@10: 0.016406
2025-11-22 21:42:52 - GraphTrainer - INFO - precision@20: 0.003582
2025-11-22 21:42:52 - GraphTrainer - INFO - recall@20: 0.067942
2025-11-22 21:42:52 - GraphTrainer - INFO - hit_rate@20: 0.071381
2025-11-22 21:42:52 - GraphTrainer - INFO - ndcg@20: 0.028664
2025-11-22 21:42:52 - GraphTrainer - INFO - map@20: 0.017605
2025-11-22 21:42:52 - GraphTrainer - INFO - mrr@20: 0.018332
2025-11-22 21:42:52 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:42:52 - GraphTrainer - INFO - ============================================================
2025-11-22 21:42:52 - GraphTrainer - INFO - 开始第 34/1000 轮训练
2025-11-22 21:42:52 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3969, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3729, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3725, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3888, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4012, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3800, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4238, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3907, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3971, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3804, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3926, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4275, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3953, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3877, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3997, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4021, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3939, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4086, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3967, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4039, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4137, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4130, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3989, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4049, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4178, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4034, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3778, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3949, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3938, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3827, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3870, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4036, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3991, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4165, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4160, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4005, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3993, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4057, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3921, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3897, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3878, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3935, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4059, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3860, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4000, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3938, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3788, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3788, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3937, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4028, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4027, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3783, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3741, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3850, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4251, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3746, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3891, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3911, device='cuda:0', grad_fn=<AddBackward0>)
The 33 training average loss: 0.39593209017967357
2025-11-22 21:43:04 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:43:04 - GraphTrainer - INFO -   precision@5: 0.005359
2025-11-22 21:43:04 - GraphTrainer - INFO -   recall@5: 0.025496
2025-11-22 21:43:04 - GraphTrainer - INFO -   hit_rate@5: 0.026691
2025-11-22 21:43:04 - GraphTrainer - INFO -   ndcg@5: 0.015909
2025-11-22 21:43:04 - GraphTrainer - INFO -   map@5: 0.012550
2025-11-22 21:43:04 - GraphTrainer - INFO -   mrr@5: 0.013142
2025-11-22 21:43:04 - GraphTrainer - INFO -   precision@10: 0.004505
2025-11-22 21:43:04 - GraphTrainer - INFO -   recall@10: 0.042737
2025-11-22 21:43:04 - GraphTrainer - INFO -   hit_rate@10: 0.044947
2025-11-22 21:43:04 - GraphTrainer - INFO -   ndcg@10: 0.021513
2025-11-22 21:43:04 - GraphTrainer - INFO -   map@10: 0.014821
2025-11-22 21:43:04 - GraphTrainer - INFO -   mrr@10: 0.015554
2025-11-22 21:43:04 - GraphTrainer - INFO -   precision@20: 0.003597
2025-11-22 21:43:04 - GraphTrainer - INFO -   recall@20: 0.068200
2025-11-22 21:43:04 - GraphTrainer - INFO -   hit_rate@20: 0.071689
2025-11-22 21:43:04 - GraphTrainer - INFO -   ndcg@20: 0.027987
2025-11-22 21:43:04 - GraphTrainer - INFO -   map@20: 0.016561
2025-11-22 21:43:04 - GraphTrainer - INFO -   mrr@20: 0.017376
2025-11-22 21:43:04 - GraphTrainer - INFO - 第 34 轮训练完成
2025-11-22 21:43:04 - GraphTrainer - INFO - train_loss: 0.395169
2025-11-22 21:43:04 - GraphTrainer - INFO - precision@5: 0.005359
2025-11-22 21:43:04 - GraphTrainer - INFO - recall@5: 0.025496
2025-11-22 21:43:04 - GraphTrainer - INFO - hit_rate@5: 0.026691
2025-11-22 21:43:04 - GraphTrainer - INFO - ndcg@5: 0.015909
2025-11-22 21:43:04 - GraphTrainer - INFO - map@5: 0.012550
2025-11-22 21:43:04 - GraphTrainer - INFO - mrr@5: 0.013142
2025-11-22 21:43:04 - GraphTrainer - INFO - precision@10: 0.004505
2025-11-22 21:43:04 - GraphTrainer - INFO - recall@10: 0.042737
2025-11-22 21:43:04 - GraphTrainer - INFO - hit_rate@10: 0.044947
2025-11-22 21:43:04 - GraphTrainer - INFO - ndcg@10: 0.021513
2025-11-22 21:43:04 - GraphTrainer - INFO - map@10: 0.014821
2025-11-22 21:43:04 - GraphTrainer - INFO - mrr@10: 0.015554
2025-11-22 21:43:04 - GraphTrainer - INFO - precision@20: 0.003597
2025-11-22 21:43:04 - GraphTrainer - INFO - recall@20: 0.068200
2025-11-22 21:43:04 - GraphTrainer - INFO - hit_rate@20: 0.071689
2025-11-22 21:43:04 - GraphTrainer - INFO - ndcg@20: 0.027987
2025-11-22 21:43:04 - GraphTrainer - INFO - map@20: 0.016561
2025-11-22 21:43:04 - GraphTrainer - INFO - mrr@20: 0.017376
2025-11-22 21:43:04 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:43:04 - GraphTrainer - INFO - ============================================================
2025-11-22 21:43:04 - GraphTrainer - INFO - 开始第 35/1000 轮训练
2025-11-22 21:43:04 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4077, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3954, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4091, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3905, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3997, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3924, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4007, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4004, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3982, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4002, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3776, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4033, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4066, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3936, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4020, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3784, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3971, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3800, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3943, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3709, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3900, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4009, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3903, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3794, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4258, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4104, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3811, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3905, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3955, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3924, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3823, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4018, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3886, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3766, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4270, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3926, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3868, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4014, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4128, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3930, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4071, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3936, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3657, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4058, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3912, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3912, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3986, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3676, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4042, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4002, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4081, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3899, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4139, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3836, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3986, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3832, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4117, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3883, device='cuda:0', grad_fn=<AddBackward0>)
The 34 training average loss: 0.3951692622283409
2025-11-22 21:43:15 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:43:15 - GraphTrainer - INFO -   precision@5: 0.005091
2025-11-22 21:43:15 - GraphTrainer - INFO -   recall@5: 0.024561
2025-11-22 21:43:15 - GraphTrainer - INFO -   hit_rate@5: 0.025405
2025-11-22 21:43:15 - GraphTrainer - INFO -   ndcg@5: 0.015246
2025-11-22 21:43:15 - GraphTrainer - INFO -   map@5: 0.012060
2025-11-22 21:43:15 - GraphTrainer - INFO -   mrr@5: 0.012419
2025-11-22 21:43:15 - GraphTrainer - INFO -   precision@10: 0.004351
2025-11-22 21:43:15 - GraphTrainer - INFO -   recall@10: 0.041594
2025-11-22 21:43:15 - GraphTrainer - INFO -   hit_rate@10: 0.043404
2025-11-22 21:43:15 - GraphTrainer - INFO -   ndcg@10: 0.020725
2025-11-22 21:43:15 - GraphTrainer - INFO -   map@10: 0.014249
2025-11-22 21:43:15 - GraphTrainer - INFO -   mrr@10: 0.014726
2025-11-22 21:43:15 - GraphTrainer - INFO -   precision@20: 0.003592
2025-11-22 21:43:15 - GraphTrainer - INFO -   recall@20: 0.068314
2025-11-22 21:43:15 - GraphTrainer - INFO -   hit_rate@20: 0.071484
2025-11-22 21:43:15 - GraphTrainer - INFO -   ndcg@20: 0.027523
2025-11-22 21:43:15 - GraphTrainer - INFO -   map@20: 0.016074
2025-11-22 21:43:15 - GraphTrainer - INFO -   mrr@20: 0.016646
2025-11-22 21:43:15 - GraphTrainer - INFO - 第 35 轮训练完成
2025-11-22 21:43:15 - GraphTrainer - INFO - train_loss: 0.392198
2025-11-22 21:43:15 - GraphTrainer - INFO - precision@5: 0.005091
2025-11-22 21:43:15 - GraphTrainer - INFO - recall@5: 0.024561
2025-11-22 21:43:15 - GraphTrainer - INFO - hit_rate@5: 0.025405
2025-11-22 21:43:15 - GraphTrainer - INFO - ndcg@5: 0.015246
2025-11-22 21:43:15 - GraphTrainer - INFO - map@5: 0.012060
2025-11-22 21:43:15 - GraphTrainer - INFO - mrr@5: 0.012419
2025-11-22 21:43:15 - GraphTrainer - INFO - precision@10: 0.004351
2025-11-22 21:43:15 - GraphTrainer - INFO - recall@10: 0.041594
2025-11-22 21:43:15 - GraphTrainer - INFO - hit_rate@10: 0.043404
2025-11-22 21:43:15 - GraphTrainer - INFO - ndcg@10: 0.020725
2025-11-22 21:43:15 - GraphTrainer - INFO - map@10: 0.014249
2025-11-22 21:43:15 - GraphTrainer - INFO - mrr@10: 0.014726
2025-11-22 21:43:15 - GraphTrainer - INFO - precision@20: 0.003592
2025-11-22 21:43:15 - GraphTrainer - INFO - recall@20: 0.068314
2025-11-22 21:43:15 - GraphTrainer - INFO - hit_rate@20: 0.071484
2025-11-22 21:43:15 - GraphTrainer - INFO - ndcg@20: 0.027523
2025-11-22 21:43:15 - GraphTrainer - INFO - map@20: 0.016074
2025-11-22 21:43:15 - GraphTrainer - INFO - mrr@20: 0.016646
2025-11-22 21:43:15 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:43:15 - GraphTrainer - INFO - ============================================================
2025-11-22 21:43:15 - GraphTrainer - INFO - 开始第 36/1000 轮训练
2025-11-22 21:43:15 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3808, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4148, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4226, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3813, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4057, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3868, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3964, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3908, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3642, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3905, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4045, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3851, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3892, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3918, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3718, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3832, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4147, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4161, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3919, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3857, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4177, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3907, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3996, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4036, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3749, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3784, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4172, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3850, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4179, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3744, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3633, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3870, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3967, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4291, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3939, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3796, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4082, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3858, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3793, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3670, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3953, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3937, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3970, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3996, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3873, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3937, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3891, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3930, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3815, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3892, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3838, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4061, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3740, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4043, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3664, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4187, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3994, device='cuda:0', grad_fn=<AddBackward0>)
The 35 training average loss: 0.3921980765359155
2025-11-22 21:43:25 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:43:25 - GraphTrainer - INFO -   precision@5: 0.005338
2025-11-22 21:43:25 - GraphTrainer - INFO -   recall@5: 0.025484
2025-11-22 21:43:25 - GraphTrainer - INFO -   hit_rate@5: 0.026639
2025-11-22 21:43:25 - GraphTrainer - INFO -   ndcg@5: 0.016879
2025-11-22 21:43:25 - GraphTrainer - INFO -   map@5: 0.013861
2025-11-22 21:43:25 - GraphTrainer - INFO -   mrr@5: 0.014422
2025-11-22 21:43:25 - GraphTrainer - INFO -   precision@10: 0.004536
2025-11-22 21:43:25 - GraphTrainer - INFO -   recall@10: 0.043236
2025-11-22 21:43:25 - GraphTrainer - INFO -   hit_rate@10: 0.045307
2025-11-22 21:43:25 - GraphTrainer - INFO -   ndcg@10: 0.022644
2025-11-22 21:43:25 - GraphTrainer - INFO -   map@10: 0.016202
2025-11-22 21:43:25 - GraphTrainer - INFO -   mrr@10: 0.016887
2025-11-22 21:43:25 - GraphTrainer - INFO -   precision@20: 0.003705
2025-11-22 21:43:25 - GraphTrainer - INFO -   recall@20: 0.070412
2025-11-22 21:43:25 - GraphTrainer - INFO -   hit_rate@20: 0.073901
2025-11-22 21:43:25 - GraphTrainer - INFO -   ndcg@20: 0.029561
2025-11-22 21:43:25 - GraphTrainer - INFO -   map@20: 0.018062
2025-11-22 21:43:25 - GraphTrainer - INFO -   mrr@20: 0.018841
2025-11-22 21:43:25 - GraphTrainer - INFO - 第 36 轮训练完成
2025-11-22 21:43:25 - GraphTrainer - INFO - train_loss: 0.387914
2025-11-22 21:43:25 - GraphTrainer - INFO - precision@5: 0.005338
2025-11-22 21:43:25 - GraphTrainer - INFO - recall@5: 0.025484
2025-11-22 21:43:25 - GraphTrainer - INFO - hit_rate@5: 0.026639
2025-11-22 21:43:25 - GraphTrainer - INFO - ndcg@5: 0.016879
2025-11-22 21:43:25 - GraphTrainer - INFO - map@5: 0.013861
2025-11-22 21:43:25 - GraphTrainer - INFO - mrr@5: 0.014422
2025-11-22 21:43:25 - GraphTrainer - INFO - precision@10: 0.004536
2025-11-22 21:43:25 - GraphTrainer - INFO - recall@10: 0.043236
2025-11-22 21:43:25 - GraphTrainer - INFO - hit_rate@10: 0.045307
2025-11-22 21:43:25 - GraphTrainer - INFO - ndcg@10: 0.022644
2025-11-22 21:43:25 - GraphTrainer - INFO - map@10: 0.016202
2025-11-22 21:43:25 - GraphTrainer - INFO - mrr@10: 0.016887
2025-11-22 21:43:25 - GraphTrainer - INFO - precision@20: 0.003705
2025-11-22 21:43:25 - GraphTrainer - INFO - recall@20: 0.070412
2025-11-22 21:43:25 - GraphTrainer - INFO - hit_rate@20: 0.073901
2025-11-22 21:43:25 - GraphTrainer - INFO - ndcg@20: 0.029561
2025-11-22 21:43:25 - GraphTrainer - INFO - map@20: 0.018062
2025-11-22 21:43:25 - GraphTrainer - INFO - mrr@20: 0.018841
2025-11-22 21:43:25 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:43:25 - GraphTrainer - INFO - ============================================================
2025-11-22 21:43:25 - GraphTrainer - INFO - 开始第 37/1000 轮训练
2025-11-22 21:43:25 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4006, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4109, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4031, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3861, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3822, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3828, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3877, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3736, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3665, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4026, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3934, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3763, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4048, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4026, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4004, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4007, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3849, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3764, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3969, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3796, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3643, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4180, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3830, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3889, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3974, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3910, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3827, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3967, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4050, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4332, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3842, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3892, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3748, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3880, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4054, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3718, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3695, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3834, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3911, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3781, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3754, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3939, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3868, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3754, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3856, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3897, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3890, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3818, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3927, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3914, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3853, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3839, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3809, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3759, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3906, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3921, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)
The 36 training average loss: 0.387914236763428
2025-11-22 21:43:36 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:43:36 - GraphTrainer - INFO -   precision@5: 0.006110
2025-11-22 21:43:36 - GraphTrainer - INFO -   recall@5: 0.029230
2025-11-22 21:43:36 - GraphTrainer - INFO -   hit_rate@5: 0.030496
2025-11-22 21:43:36 - GraphTrainer - INFO -   ndcg@5: 0.019088
2025-11-22 21:43:36 - GraphTrainer - INFO -   map@5: 0.015565
2025-11-22 21:43:36 - GraphTrainer - INFO -   mrr@5: 0.016177
2025-11-22 21:43:36 - GraphTrainer - INFO -   precision@10: 0.004788
2025-11-22 21:43:36 - GraphTrainer - INFO -   recall@10: 0.045584
2025-11-22 21:43:36 - GraphTrainer - INFO -   hit_rate@10: 0.047827
2025-11-22 21:43:36 - GraphTrainer - INFO -   ndcg@10: 0.024344
2025-11-22 21:43:36 - GraphTrainer - INFO -   map@10: 0.017659
2025-11-22 21:43:36 - GraphTrainer - INFO -   mrr@10: 0.018396
2025-11-22 21:43:36 - GraphTrainer - INFO -   precision@20: 0.003767
2025-11-22 21:43:36 - GraphTrainer - INFO -   recall@20: 0.071349
2025-11-22 21:43:36 - GraphTrainer - INFO -   hit_rate@20: 0.074929
2025-11-22 21:43:36 - GraphTrainer - INFO -   ndcg@20: 0.030887
2025-11-22 21:43:36 - GraphTrainer - INFO -   map@20: 0.019409
2025-11-22 21:43:36 - GraphTrainer - INFO -   mrr@20: 0.020228
2025-11-22 21:43:36 - GraphTrainer - INFO - 第 37 轮训练完成
2025-11-22 21:43:36 - GraphTrainer - INFO - train_loss: 0.381972
2025-11-22 21:43:36 - GraphTrainer - INFO - precision@5: 0.006110
2025-11-22 21:43:36 - GraphTrainer - INFO - recall@5: 0.029230
2025-11-22 21:43:36 - GraphTrainer - INFO - hit_rate@5: 0.030496
2025-11-22 21:43:36 - GraphTrainer - INFO - ndcg@5: 0.019088
2025-11-22 21:43:36 - GraphTrainer - INFO - map@5: 0.015565
2025-11-22 21:43:36 - GraphTrainer - INFO - mrr@5: 0.016177
2025-11-22 21:43:36 - GraphTrainer - INFO - precision@10: 0.004788
2025-11-22 21:43:36 - GraphTrainer - INFO - recall@10: 0.045584
2025-11-22 21:43:36 - GraphTrainer - INFO - hit_rate@10: 0.047827
2025-11-22 21:43:36 - GraphTrainer - INFO - ndcg@10: 0.024344
2025-11-22 21:43:36 - GraphTrainer - INFO - map@10: 0.017659
2025-11-22 21:43:36 - GraphTrainer - INFO - mrr@10: 0.018396
2025-11-22 21:43:36 - GraphTrainer - INFO - precision@20: 0.003767
2025-11-22 21:43:36 - GraphTrainer - INFO - recall@20: 0.071349
2025-11-22 21:43:36 - GraphTrainer - INFO - hit_rate@20: 0.074929
2025-11-22 21:43:36 - GraphTrainer - INFO - ndcg@20: 0.030887
2025-11-22 21:43:36 - GraphTrainer - INFO - map@20: 0.019409
2025-11-22 21:43:36 - GraphTrainer - INFO - mrr@20: 0.020228
2025-11-22 21:43:36 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:43:36 - GraphTrainer - INFO - ============================================================
2025-11-22 21:43:36 - GraphTrainer - INFO - 开始第 38/1000 轮训练
2025-11-22 21:43:36 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3856, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3858, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3765, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3691, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3775, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3856, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3939, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3789, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3945, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3733, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3723, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3534, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3650, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3833, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3855, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3860, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3655, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3703, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4155, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3959, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3802, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3701, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3726, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3826, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3890, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3798, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3780, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3785, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3885, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3978, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3851, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3807, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3752, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4037, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3873, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3774, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3717, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3758, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3671, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3772, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3767, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3889, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3791, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3976, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3791, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3783, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3720, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3737, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3891, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3840, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3929, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3892, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3793, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3969, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3890, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3918, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3948, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3705, device='cuda:0', grad_fn=<AddBackward0>)
The 37 training average loss: 0.3819718283825907
2025-11-22 21:43:48 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:43:48 - GraphTrainer - INFO -   precision@5: 0.005739
2025-11-22 21:43:48 - GraphTrainer - INFO -   recall@5: 0.027467
2025-11-22 21:43:48 - GraphTrainer - INFO -   hit_rate@5: 0.028645
2025-11-22 21:43:48 - GraphTrainer - INFO -   ndcg@5: 0.017792
2025-11-22 21:43:48 - GraphTrainer - INFO -   map@5: 0.014415
2025-11-22 21:43:48 - GraphTrainer - INFO -   mrr@5: 0.014956
2025-11-22 21:43:48 - GraphTrainer - INFO -   precision@10: 0.004747
2025-11-22 21:43:48 - GraphTrainer - INFO -   recall@10: 0.045310
2025-11-22 21:43:48 - GraphTrainer - INFO -   hit_rate@10: 0.047364
2025-11-22 21:43:48 - GraphTrainer - INFO -   ndcg@10: 0.023557
2025-11-22 21:43:48 - GraphTrainer - INFO -   map@10: 0.016742
2025-11-22 21:43:48 - GraphTrainer - INFO -   mrr@10: 0.017397
2025-11-22 21:43:48 - GraphTrainer - INFO -   precision@20: 0.003718
2025-11-22 21:43:48 - GraphTrainer - INFO -   recall@20: 0.070718
2025-11-22 21:43:48 - GraphTrainer - INFO -   hit_rate@20: 0.074004
2025-11-22 21:43:48 - GraphTrainer - INFO -   ndcg@20: 0.030006
2025-11-22 21:43:48 - GraphTrainer - INFO -   map@20: 0.018467
2025-11-22 21:43:48 - GraphTrainer - INFO -   mrr@20: 0.019207
2025-11-22 21:43:48 - GraphTrainer - INFO - 第 38 轮训练完成
2025-11-22 21:43:48 - GraphTrainer - INFO - train_loss: 0.382533
2025-11-22 21:43:48 - GraphTrainer - INFO - precision@5: 0.005739
2025-11-22 21:43:48 - GraphTrainer - INFO - recall@5: 0.027467
2025-11-22 21:43:48 - GraphTrainer - INFO - hit_rate@5: 0.028645
2025-11-22 21:43:48 - GraphTrainer - INFO - ndcg@5: 0.017792
2025-11-22 21:43:48 - GraphTrainer - INFO - map@5: 0.014415
2025-11-22 21:43:48 - GraphTrainer - INFO - mrr@5: 0.014956
2025-11-22 21:43:48 - GraphTrainer - INFO - precision@10: 0.004747
2025-11-22 21:43:48 - GraphTrainer - INFO - recall@10: 0.045310
2025-11-22 21:43:48 - GraphTrainer - INFO - hit_rate@10: 0.047364
2025-11-22 21:43:48 - GraphTrainer - INFO - ndcg@10: 0.023557
2025-11-22 21:43:48 - GraphTrainer - INFO - map@10: 0.016742
2025-11-22 21:43:48 - GraphTrainer - INFO - mrr@10: 0.017397
2025-11-22 21:43:48 - GraphTrainer - INFO - precision@20: 0.003718
2025-11-22 21:43:48 - GraphTrainer - INFO - recall@20: 0.070718
2025-11-22 21:43:48 - GraphTrainer - INFO - hit_rate@20: 0.074004
2025-11-22 21:43:48 - GraphTrainer - INFO - ndcg@20: 0.030006
2025-11-22 21:43:48 - GraphTrainer - INFO - map@20: 0.018467
2025-11-22 21:43:48 - GraphTrainer - INFO - mrr@20: 0.019207
2025-11-22 21:43:48 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:43:48 - GraphTrainer - INFO - ============================================================
2025-11-22 21:43:48 - GraphTrainer - INFO - 开始第 39/1000 轮训练
2025-11-22 21:43:48 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3994, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3938, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3850, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3766, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3869, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3878, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3681, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3941, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3723, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3974, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3810, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3850, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3835, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3781, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3648, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3654, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3994, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3706, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3981, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3870, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3597, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4154, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3812, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3740, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3576, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3742, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3948, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3725, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3974, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3865, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3870, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3949, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3756, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3826, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3866, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3742, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3869, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3848, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3710, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3851, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3837, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3763, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3816, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3906, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3620, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3853, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3925, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3826, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3728, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4165, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3830, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3669, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3779, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3906, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3973, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3948, device='cuda:0', grad_fn=<AddBackward0>)
The 38 training average loss: 0.38253300970998305
2025-11-22 21:43:59 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:43:59 - GraphTrainer - INFO -   precision@5: 0.005986
2025-11-22 21:43:59 - GraphTrainer - INFO -   recall@5: 0.028488
2025-11-22 21:43:59 - GraphTrainer - INFO -   hit_rate@5: 0.029879
2025-11-22 21:43:59 - GraphTrainer - INFO -   ndcg@5: 0.018693
2025-11-22 21:43:59 - GraphTrainer - INFO -   map@5: 0.015275
2025-11-22 21:43:59 - GraphTrainer - INFO -   mrr@5: 0.015895
2025-11-22 21:43:59 - GraphTrainer - INFO -   precision@10: 0.004978
2025-11-22 21:43:59 - GraphTrainer - INFO -   recall@10: 0.047249
2025-11-22 21:43:59 - GraphTrainer - INFO -   hit_rate@10: 0.049679
2025-11-22 21:43:59 - GraphTrainer - INFO -   ndcg@10: 0.024789
2025-11-22 21:43:59 - GraphTrainer - INFO -   map@10: 0.017743
2025-11-22 21:43:59 - GraphTrainer - INFO -   mrr@10: 0.018504
2025-11-22 21:43:59 - GraphTrainer - INFO -   precision@20: 0.003836
2025-11-22 21:43:59 - GraphTrainer - INFO -   recall@20: 0.072514
2025-11-22 21:43:59 - GraphTrainer - INFO -   hit_rate@20: 0.076318
2025-11-22 21:43:59 - GraphTrainer - INFO -   ndcg@20: 0.031199
2025-11-22 21:43:59 - GraphTrainer - INFO -   map@20: 0.019451
2025-11-22 21:43:59 - GraphTrainer - INFO -   mrr@20: 0.020299
2025-11-22 21:43:59 - GraphTrainer - INFO - 第 39 轮训练完成
2025-11-22 21:43:59 - GraphTrainer - INFO - train_loss: 0.381026
2025-11-22 21:43:59 - GraphTrainer - INFO - precision@5: 0.005986
2025-11-22 21:43:59 - GraphTrainer - INFO - recall@5: 0.028488
2025-11-22 21:43:59 - GraphTrainer - INFO - hit_rate@5: 0.029879
2025-11-22 21:43:59 - GraphTrainer - INFO - ndcg@5: 0.018693
2025-11-22 21:43:59 - GraphTrainer - INFO - map@5: 0.015275
2025-11-22 21:43:59 - GraphTrainer - INFO - mrr@5: 0.015895
2025-11-22 21:43:59 - GraphTrainer - INFO - precision@10: 0.004978
2025-11-22 21:43:59 - GraphTrainer - INFO - recall@10: 0.047249
2025-11-22 21:43:59 - GraphTrainer - INFO - hit_rate@10: 0.049679
2025-11-22 21:43:59 - GraphTrainer - INFO - ndcg@10: 0.024789
2025-11-22 21:43:59 - GraphTrainer - INFO - map@10: 0.017743
2025-11-22 21:43:59 - GraphTrainer - INFO - mrr@10: 0.018504
2025-11-22 21:43:59 - GraphTrainer - INFO - precision@20: 0.003836
2025-11-22 21:43:59 - GraphTrainer - INFO - recall@20: 0.072514
2025-11-22 21:43:59 - GraphTrainer - INFO - hit_rate@20: 0.076318
2025-11-22 21:43:59 - GraphTrainer - INFO - ndcg@20: 0.031199
2025-11-22 21:43:59 - GraphTrainer - INFO - map@20: 0.019451
2025-11-22 21:43:59 - GraphTrainer - INFO - mrr@20: 0.020299
2025-11-22 21:43:59 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:43:59 - GraphTrainer - INFO - ============================================================
2025-11-22 21:43:59 - GraphTrainer - INFO - 开始第 40/1000 轮训练
2025-11-22 21:43:59 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4007, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3822, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3640, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3909, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3664, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4028, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3839, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3919, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3669, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3604, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3802, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3744, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3547, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3868, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3857, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3668, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3705, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3976, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3733, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3949, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3811, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3667, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3869, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3811, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3797, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3772, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3922, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3979, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3713, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3882, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3812, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3643, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3930, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3791, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3866, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3990, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3981, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3872, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3682, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3933, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3725, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3814, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3963, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3806, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3654, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3700, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4056, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3781, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3822, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3881, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3636, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3854, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3783, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3885, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3742, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3935, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3692, device='cuda:0', grad_fn=<AddBackward0>)
The 39 training average loss: 0.3810257212869052
2025-11-22 21:44:10 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:44:10 - GraphTrainer - INFO -   precision@5: 0.005719
2025-11-22 21:44:10 - GraphTrainer - INFO -   recall@5: 0.027469
2025-11-22 21:44:10 - GraphTrainer - INFO -   hit_rate@5: 0.028542
2025-11-22 21:44:10 - GraphTrainer - INFO -   ndcg@5: 0.017291
2025-11-22 21:44:10 - GraphTrainer - INFO -   map@5: 0.013769
2025-11-22 21:44:10 - GraphTrainer - INFO -   mrr@5: 0.014316
2025-11-22 21:44:10 - GraphTrainer - INFO -   precision@10: 0.004695
2025-11-22 21:44:10 - GraphTrainer - INFO -   recall@10: 0.044686
2025-11-22 21:44:10 - GraphTrainer - INFO -   hit_rate@10: 0.046850
2025-11-22 21:44:10 - GraphTrainer - INFO -   ndcg@10: 0.022893
2025-11-22 21:44:10 - GraphTrainer - INFO -   map@10: 0.016035
2025-11-22 21:44:10 - GraphTrainer - INFO -   mrr@10: 0.016719
2025-11-22 21:44:10 - GraphTrainer - INFO -   precision@20: 0.003741
2025-11-22 21:44:10 - GraphTrainer - INFO -   recall@20: 0.070768
2025-11-22 21:44:10 - GraphTrainer - INFO -   hit_rate@20: 0.074518
2025-11-22 21:44:10 - GraphTrainer - INFO -   ndcg@20: 0.029523
2025-11-22 21:44:10 - GraphTrainer - INFO -   map@20: 0.017804
2025-11-22 21:44:10 - GraphTrainer - INFO -   mrr@20: 0.018596
2025-11-22 21:44:10 - GraphTrainer - INFO - 第 40 轮训练完成
2025-11-22 21:44:10 - GraphTrainer - INFO - train_loss: 0.378606
2025-11-22 21:44:10 - GraphTrainer - INFO - precision@5: 0.005719
2025-11-22 21:44:10 - GraphTrainer - INFO - recall@5: 0.027469
2025-11-22 21:44:10 - GraphTrainer - INFO - hit_rate@5: 0.028542
2025-11-22 21:44:10 - GraphTrainer - INFO - ndcg@5: 0.017291
2025-11-22 21:44:10 - GraphTrainer - INFO - map@5: 0.013769
2025-11-22 21:44:10 - GraphTrainer - INFO - mrr@5: 0.014316
2025-11-22 21:44:10 - GraphTrainer - INFO - precision@10: 0.004695
2025-11-22 21:44:10 - GraphTrainer - INFO - recall@10: 0.044686
2025-11-22 21:44:10 - GraphTrainer - INFO - hit_rate@10: 0.046850
2025-11-22 21:44:10 - GraphTrainer - INFO - ndcg@10: 0.022893
2025-11-22 21:44:10 - GraphTrainer - INFO - map@10: 0.016035
2025-11-22 21:44:10 - GraphTrainer - INFO - mrr@10: 0.016719
2025-11-22 21:44:10 - GraphTrainer - INFO - precision@20: 0.003741
2025-11-22 21:44:10 - GraphTrainer - INFO - recall@20: 0.070768
2025-11-22 21:44:10 - GraphTrainer - INFO - hit_rate@20: 0.074518
2025-11-22 21:44:10 - GraphTrainer - INFO - ndcg@20: 0.029523
2025-11-22 21:44:10 - GraphTrainer - INFO - map@20: 0.017804
2025-11-22 21:44:10 - GraphTrainer - INFO - mrr@20: 0.018596
2025-11-22 21:44:10 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:44:10 - GraphTrainer - INFO - 检查点已保存: Epoch 40 -> ./checkpoints/checkpoint_epoch_40.pth
2025-11-22 21:44:10 - GraphTrainer - INFO - ============================================================
2025-11-22 21:44:10 - GraphTrainer - INFO - 开始第 41/1000 轮训练
2025-11-22 21:44:10 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3795, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4144, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3759, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3824, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4073, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3747, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4040, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3820, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3762, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3638, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3913, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3705, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3679, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3595, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3680, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3822, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3641, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3825, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3744, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3718, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3806, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3700, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3607, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3744, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3529, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3798, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3758, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3763, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3800, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4002, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3851, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4000, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3764, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3867, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3772, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3657, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3744, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3983, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3808, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3649, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3873, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3670, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3947, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3754, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3626, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3760, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3650, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3893, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3897, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3633, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3811, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3672, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3817, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4088, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3785, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3909, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3693, device='cuda:0', grad_fn=<AddBackward0>)
The 40 training average loss: 0.3786057310885397
2025-11-22 21:44:21 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:44:21 - GraphTrainer - INFO -   precision@5: 0.006017
2025-11-22 21:44:21 - GraphTrainer - INFO -   recall@5: 0.028740
2025-11-22 21:44:21 - GraphTrainer - INFO -   hit_rate@5: 0.030033
2025-11-22 21:44:21 - GraphTrainer - INFO -   ndcg@5: 0.018644
2025-11-22 21:44:21 - GraphTrainer - INFO -   map@5: 0.015136
2025-11-22 21:44:21 - GraphTrainer - INFO -   mrr@5: 0.015757
2025-11-22 21:44:21 - GraphTrainer - INFO -   precision@10: 0.004850
2025-11-22 21:44:21 - GraphTrainer - INFO -   recall@10: 0.046113
2025-11-22 21:44:21 - GraphTrainer - INFO -   hit_rate@10: 0.048341
2025-11-22 21:44:21 - GraphTrainer - INFO -   ndcg@10: 0.024273
2025-11-22 21:44:21 - GraphTrainer - INFO -   map@10: 0.017409
2025-11-22 21:44:21 - GraphTrainer - INFO -   mrr@10: 0.018150
2025-11-22 21:44:21 - GraphTrainer - INFO -   precision@20: 0.003813
2025-11-22 21:44:21 - GraphTrainer - INFO -   recall@20: 0.072267
2025-11-22 21:44:21 - GraphTrainer - INFO -   hit_rate@20: 0.075804
2025-11-22 21:44:21 - GraphTrainer - INFO -   ndcg@20: 0.030920
2025-11-22 21:44:21 - GraphTrainer - INFO -   map@20: 0.019194
2025-11-22 21:44:21 - GraphTrainer - INFO -   mrr@20: 0.020013
2025-11-22 21:44:21 - GraphTrainer - INFO - 第 41 轮训练完成
2025-11-22 21:44:21 - GraphTrainer - INFO - train_loss: 0.379398
2025-11-22 21:44:21 - GraphTrainer - INFO - precision@5: 0.006017
2025-11-22 21:44:21 - GraphTrainer - INFO - recall@5: 0.028740
2025-11-22 21:44:21 - GraphTrainer - INFO - hit_rate@5: 0.030033
2025-11-22 21:44:21 - GraphTrainer - INFO - ndcg@5: 0.018644
2025-11-22 21:44:21 - GraphTrainer - INFO - map@5: 0.015136
2025-11-22 21:44:21 - GraphTrainer - INFO - mrr@5: 0.015757
2025-11-22 21:44:21 - GraphTrainer - INFO - precision@10: 0.004850
2025-11-22 21:44:21 - GraphTrainer - INFO - recall@10: 0.046113
2025-11-22 21:44:21 - GraphTrainer - INFO - hit_rate@10: 0.048341
2025-11-22 21:44:21 - GraphTrainer - INFO - ndcg@10: 0.024273
2025-11-22 21:44:21 - GraphTrainer - INFO - map@10: 0.017409
2025-11-22 21:44:21 - GraphTrainer - INFO - mrr@10: 0.018150
2025-11-22 21:44:21 - GraphTrainer - INFO - precision@20: 0.003813
2025-11-22 21:44:21 - GraphTrainer - INFO - recall@20: 0.072267
2025-11-22 21:44:21 - GraphTrainer - INFO - hit_rate@20: 0.075804
2025-11-22 21:44:21 - GraphTrainer - INFO - ndcg@20: 0.030920
2025-11-22 21:44:21 - GraphTrainer - INFO - map@20: 0.019194
2025-11-22 21:44:21 - GraphTrainer - INFO - mrr@20: 0.020013
2025-11-22 21:44:21 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:44:21 - GraphTrainer - INFO - ============================================================
2025-11-22 21:44:21 - GraphTrainer - INFO - 开始第 42/1000 轮训练
2025-11-22 21:44:21 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3723, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3910, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3566, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3874, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3960, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3851, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3873, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3953, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3907, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4122, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3862, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3750, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3574, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3574, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3888, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3731, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3815, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3790, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3776, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3657, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3667, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3796, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3702, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3824, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3588, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3770, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3930, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3743, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3872, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3984, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3932, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3842, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3877, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3877, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3841, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3782, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3855, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3779, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3743, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3760, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3664, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3930, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3792, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3740, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3783, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3867, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3776, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3947, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3803, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3884, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3810, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3981, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3746, device='cuda:0', grad_fn=<AddBackward0>)
The 41 training average loss: 0.3793975366600629
2025-11-22 21:44:32 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:44:32 - GraphTrainer - INFO -   precision@5: 0.005719
2025-11-22 21:44:32 - GraphTrainer - INFO -   recall@5: 0.027339
2025-11-22 21:44:32 - GraphTrainer - INFO -   hit_rate@5: 0.028542
2025-11-22 21:44:32 - GraphTrainer - INFO -   ndcg@5: 0.017521
2025-11-22 21:44:32 - GraphTrainer - INFO -   map@5: 0.014096
2025-11-22 21:44:32 - GraphTrainer - INFO -   mrr@5: 0.014730
2025-11-22 21:44:32 - GraphTrainer - INFO -   precision@10: 0.004819
2025-11-22 21:44:32 - GraphTrainer - INFO -   recall@10: 0.045879
2025-11-22 21:44:32 - GraphTrainer - INFO -   hit_rate@10: 0.048084
2025-11-22 21:44:32 - GraphTrainer - INFO -   ndcg@10: 0.023551
2025-11-22 21:44:32 - GraphTrainer - INFO -   map@10: 0.016546
2025-11-22 21:44:32 - GraphTrainer - INFO -   mrr@10: 0.017305
2025-11-22 21:44:32 - GraphTrainer - INFO -   precision@20: 0.003800
2025-11-22 21:44:32 - GraphTrainer - INFO -   recall@20: 0.071947
2025-11-22 21:44:32 - GraphTrainer - INFO -   hit_rate@20: 0.075701
2025-11-22 21:44:32 - GraphTrainer - INFO -   ndcg@20: 0.030208
2025-11-22 21:44:32 - GraphTrainer - INFO -   map@20: 0.018340
2025-11-22 21:44:32 - GraphTrainer - INFO -   mrr@20: 0.019202
2025-11-22 21:44:32 - GraphTrainer - INFO - 第 42 轮训练完成
2025-11-22 21:44:32 - GraphTrainer - INFO - train_loss: 0.377387
2025-11-22 21:44:32 - GraphTrainer - INFO - precision@5: 0.005719
2025-11-22 21:44:32 - GraphTrainer - INFO - recall@5: 0.027339
2025-11-22 21:44:32 - GraphTrainer - INFO - hit_rate@5: 0.028542
2025-11-22 21:44:32 - GraphTrainer - INFO - ndcg@5: 0.017521
2025-11-22 21:44:32 - GraphTrainer - INFO - map@5: 0.014096
2025-11-22 21:44:32 - GraphTrainer - INFO - mrr@5: 0.014730
2025-11-22 21:44:32 - GraphTrainer - INFO - precision@10: 0.004819
2025-11-22 21:44:32 - GraphTrainer - INFO - recall@10: 0.045879
2025-11-22 21:44:32 - GraphTrainer - INFO - hit_rate@10: 0.048084
2025-11-22 21:44:32 - GraphTrainer - INFO - ndcg@10: 0.023551
2025-11-22 21:44:32 - GraphTrainer - INFO - map@10: 0.016546
2025-11-22 21:44:32 - GraphTrainer - INFO - mrr@10: 0.017305
2025-11-22 21:44:32 - GraphTrainer - INFO - precision@20: 0.003800
2025-11-22 21:44:32 - GraphTrainer - INFO - recall@20: 0.071947
2025-11-22 21:44:32 - GraphTrainer - INFO - hit_rate@20: 0.075701
2025-11-22 21:44:32 - GraphTrainer - INFO - ndcg@20: 0.030208
2025-11-22 21:44:32 - GraphTrainer - INFO - map@20: 0.018340
2025-11-22 21:44:32 - GraphTrainer - INFO - mrr@20: 0.019202
2025-11-22 21:44:32 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:44:32 - GraphTrainer - INFO - ============================================================
2025-11-22 21:44:32 - GraphTrainer - INFO - 开始第 43/1000 轮训练
2025-11-22 21:44:32 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3543, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3852, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3894, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3646, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3797, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3741, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3749, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3729, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3681, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3741, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3908, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3687, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3773, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3889, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3924, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3877, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3706, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3510, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3811, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3692, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3794, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3822, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3723, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3928, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3817, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3561, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3734, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3863, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3679, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3977, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3697, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3886, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3737, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3749, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3664, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3860, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3885, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3804, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3788, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3802, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3931, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3689, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3787, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3870, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3747, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3964, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3761, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3807, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3850, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3839, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3728, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3986, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3651, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3723, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3721, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3685, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3717, device='cuda:0', grad_fn=<AddBackward0>)
The 42 training average loss: 0.37738672001608486
2025-11-22 21:44:43 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:44:43 - GraphTrainer - INFO -   precision@5: 0.005678
2025-11-22 21:44:43 - GraphTrainer - INFO -   recall@5: 0.027119
2025-11-22 21:44:43 - GraphTrainer - INFO -   hit_rate@5: 0.028336
2025-11-22 21:44:43 - GraphTrainer - INFO -   ndcg@5: 0.017400
2025-11-22 21:44:43 - GraphTrainer - INFO -   map@5: 0.014014
2025-11-22 21:44:43 - GraphTrainer - INFO -   mrr@5: 0.014591
2025-11-22 21:44:43 - GraphTrainer - INFO -   precision@10: 0.004742
2025-11-22 21:44:43 - GraphTrainer - INFO -   recall@10: 0.045169
2025-11-22 21:44:43 - GraphTrainer - INFO -   hit_rate@10: 0.047313
2025-11-22 21:44:43 - GraphTrainer - INFO -   ndcg@10: 0.023270
2025-11-22 21:44:43 - GraphTrainer - INFO -   map@10: 0.016402
2025-11-22 21:44:43 - GraphTrainer - INFO -   mrr@10: 0.017096
2025-11-22 21:44:43 - GraphTrainer - INFO -   precision@20: 0.003865
2025-11-22 21:44:43 - GraphTrainer - INFO -   recall@20: 0.073132
2025-11-22 21:44:43 - GraphTrainer - INFO -   hit_rate@20: 0.077038
2025-11-22 21:44:43 - GraphTrainer - INFO -   ndcg@20: 0.030403
2025-11-22 21:44:43 - GraphTrainer - INFO -   map@20: 0.018316
2025-11-22 21:44:43 - GraphTrainer - INFO -   mrr@20: 0.019128
2025-11-22 21:44:43 - GraphTrainer - INFO - 第 43 轮训练完成
2025-11-22 21:44:43 - GraphTrainer - INFO - train_loss: 0.372628
2025-11-22 21:44:43 - GraphTrainer - INFO - precision@5: 0.005678
2025-11-22 21:44:43 - GraphTrainer - INFO - recall@5: 0.027119
2025-11-22 21:44:43 - GraphTrainer - INFO - hit_rate@5: 0.028336
2025-11-22 21:44:43 - GraphTrainer - INFO - ndcg@5: 0.017400
2025-11-22 21:44:43 - GraphTrainer - INFO - map@5: 0.014014
2025-11-22 21:44:43 - GraphTrainer - INFO - mrr@5: 0.014591
2025-11-22 21:44:43 - GraphTrainer - INFO - precision@10: 0.004742
2025-11-22 21:44:43 - GraphTrainer - INFO - recall@10: 0.045169
2025-11-22 21:44:43 - GraphTrainer - INFO - hit_rate@10: 0.047313
2025-11-22 21:44:43 - GraphTrainer - INFO - ndcg@10: 0.023270
2025-11-22 21:44:43 - GraphTrainer - INFO - map@10: 0.016402
2025-11-22 21:44:43 - GraphTrainer - INFO - mrr@10: 0.017096
2025-11-22 21:44:43 - GraphTrainer - INFO - precision@20: 0.003865
2025-11-22 21:44:43 - GraphTrainer - INFO - recall@20: 0.073132
2025-11-22 21:44:43 - GraphTrainer - INFO - hit_rate@20: 0.077038
2025-11-22 21:44:43 - GraphTrainer - INFO - ndcg@20: 0.030403
2025-11-22 21:44:43 - GraphTrainer - INFO - map@20: 0.018316
2025-11-22 21:44:43 - GraphTrainer - INFO - mrr@20: 0.019128
2025-11-22 21:44:43 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:44:43 - GraphTrainer - INFO - ============================================================
2025-11-22 21:44:43 - GraphTrainer - INFO - 开始第 44/1000 轮训练
2025-11-22 21:44:43 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3670, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3667, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3779, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3847, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3830, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3653, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3747, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3738, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3554, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3510, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3976, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3706, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3621, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3919, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3572, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3798, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3894, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3677, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3674, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3614, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3612, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3733, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3898, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3858, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3837, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3759, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3560, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3663, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3636, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3946, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3677, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3965, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3698, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3742, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3607, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3799, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3569, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3685, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3607, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3666, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3837, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3870, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3916, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3854, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3894, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3698, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3870, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3620, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3763, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3752, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3688, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3883, device='cuda:0', grad_fn=<AddBackward0>)
The 43 training average loss: 0.3726278379045684
2025-11-22 21:44:55 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:44:55 - GraphTrainer - INFO -   precision@5: 0.005894
2025-11-22 21:44:55 - GraphTrainer - INFO -   recall@5: 0.028246
2025-11-22 21:44:55 - GraphTrainer - INFO -   hit_rate@5: 0.029365
2025-11-22 21:44:55 - GraphTrainer - INFO -   ndcg@5: 0.018102
2025-11-22 21:44:55 - GraphTrainer - INFO -   map@5: 0.014615
2025-11-22 21:44:55 - GraphTrainer - INFO -   mrr@5: 0.015141
2025-11-22 21:44:55 - GraphTrainer - INFO -   precision@10: 0.004772
2025-11-22 21:44:55 - GraphTrainer - INFO -   recall@10: 0.045459
2025-11-22 21:44:55 - GraphTrainer - INFO -   hit_rate@10: 0.047570
2025-11-22 21:44:55 - GraphTrainer - INFO -   ndcg@10: 0.023669
2025-11-22 21:44:55 - GraphTrainer - INFO -   map@10: 0.016853
2025-11-22 21:44:55 - GraphTrainer - INFO -   mrr@10: 0.017503
2025-11-22 21:44:55 - GraphTrainer - INFO -   precision@20: 0.003793
2025-11-22 21:44:55 - GraphTrainer - INFO -   recall@20: 0.072022
2025-11-22 21:44:55 - GraphTrainer - INFO -   hit_rate@20: 0.075598
2025-11-22 21:44:55 - GraphTrainer - INFO -   ndcg@20: 0.030384
2025-11-22 21:44:55 - GraphTrainer - INFO -   map@20: 0.018632
2025-11-22 21:44:55 - GraphTrainer - INFO -   mrr@20: 0.019379
2025-11-22 21:44:55 - GraphTrainer - INFO - 第 44 轮训练完成
2025-11-22 21:44:55 - GraphTrainer - INFO - train_loss: 0.372583
2025-11-22 21:44:55 - GraphTrainer - INFO - precision@5: 0.005894
2025-11-22 21:44:55 - GraphTrainer - INFO - recall@5: 0.028246
2025-11-22 21:44:55 - GraphTrainer - INFO - hit_rate@5: 0.029365
2025-11-22 21:44:55 - GraphTrainer - INFO - ndcg@5: 0.018102
2025-11-22 21:44:55 - GraphTrainer - INFO - map@5: 0.014615
2025-11-22 21:44:55 - GraphTrainer - INFO - mrr@5: 0.015141
2025-11-22 21:44:55 - GraphTrainer - INFO - precision@10: 0.004772
2025-11-22 21:44:55 - GraphTrainer - INFO - recall@10: 0.045459
2025-11-22 21:44:55 - GraphTrainer - INFO - hit_rate@10: 0.047570
2025-11-22 21:44:55 - GraphTrainer - INFO - ndcg@10: 0.023669
2025-11-22 21:44:55 - GraphTrainer - INFO - map@10: 0.016853
2025-11-22 21:44:55 - GraphTrainer - INFO - mrr@10: 0.017503
2025-11-22 21:44:55 - GraphTrainer - INFO - precision@20: 0.003793
2025-11-22 21:44:55 - GraphTrainer - INFO - recall@20: 0.072022
2025-11-22 21:44:55 - GraphTrainer - INFO - hit_rate@20: 0.075598
2025-11-22 21:44:55 - GraphTrainer - INFO - ndcg@20: 0.030384
2025-11-22 21:44:55 - GraphTrainer - INFO - map@20: 0.018632
2025-11-22 21:44:55 - GraphTrainer - INFO - mrr@20: 0.019379
2025-11-22 21:44:55 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:44:55 - GraphTrainer - INFO - ============================================================
2025-11-22 21:44:55 - GraphTrainer - INFO - 开始第 45/1000 轮训练
2025-11-22 21:44:55 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3880, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3847, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3655, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3762, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3733, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3608, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3750, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3759, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3620, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3722, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3878, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3660, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3710, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3742, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3565, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3884, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3729, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3661, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3753, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3749, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3661, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3726, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3811, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3818, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3881, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3702, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3951, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3702, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3612, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3690, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3866, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3565, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3866, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3874, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3631, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3782, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3876, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3905, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3772, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3634, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3616, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3924, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3572, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3743, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3815, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3743, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3822, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3786, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3718, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3737, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3758, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3732, device='cuda:0', grad_fn=<AddBackward0>)
The 44 training average loss: 0.37258318837346704
2025-11-22 21:45:05 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:45:05 - GraphTrainer - INFO -   precision@5: 0.005729
2025-11-22 21:45:05 - GraphTrainer - INFO -   recall@5: 0.027434
2025-11-22 21:45:05 - GraphTrainer - INFO -   hit_rate@5: 0.028593
2025-11-22 21:45:05 - GraphTrainer - INFO -   ndcg@5: 0.018219
2025-11-22 21:45:05 - GraphTrainer - INFO -   map@5: 0.014983
2025-11-22 21:45:05 - GraphTrainer - INFO -   mrr@5: 0.015612
2025-11-22 21:45:05 - GraphTrainer - INFO -   precision@10: 0.004937
2025-11-22 21:45:05 - GraphTrainer - INFO -   recall@10: 0.046663
2025-11-22 21:45:05 - GraphTrainer - INFO -   hit_rate@10: 0.049267
2025-11-22 21:45:05 - GraphTrainer - INFO -   ndcg@10: 0.024513
2025-11-22 21:45:05 - GraphTrainer - INFO -   map@10: 0.017536
2025-11-22 21:45:05 - GraphTrainer - INFO -   mrr@10: 0.018350
2025-11-22 21:45:05 - GraphTrainer - INFO -   precision@20: 0.003878
2025-11-22 21:45:05 - GraphTrainer - INFO -   recall@20: 0.073390
2025-11-22 21:45:05 - GraphTrainer - INFO -   hit_rate@20: 0.077192
2025-11-22 21:45:05 - GraphTrainer - INFO -   ndcg@20: 0.031312
2025-11-22 21:45:05 - GraphTrainer - INFO -   map@20: 0.019368
2025-11-22 21:45:05 - GraphTrainer - INFO -   mrr@20: 0.020259
2025-11-22 21:45:05 - GraphTrainer - INFO - 第 45 轮训练完成
2025-11-22 21:45:05 - GraphTrainer - INFO - train_loss: 0.375298
2025-11-22 21:45:05 - GraphTrainer - INFO - precision@5: 0.005729
2025-11-22 21:45:05 - GraphTrainer - INFO - recall@5: 0.027434
2025-11-22 21:45:05 - GraphTrainer - INFO - hit_rate@5: 0.028593
2025-11-22 21:45:05 - GraphTrainer - INFO - ndcg@5: 0.018219
2025-11-22 21:45:05 - GraphTrainer - INFO - map@5: 0.014983
2025-11-22 21:45:05 - GraphTrainer - INFO - mrr@5: 0.015612
2025-11-22 21:45:05 - GraphTrainer - INFO - precision@10: 0.004937
2025-11-22 21:45:05 - GraphTrainer - INFO - recall@10: 0.046663
2025-11-22 21:45:05 - GraphTrainer - INFO - hit_rate@10: 0.049267
2025-11-22 21:45:05 - GraphTrainer - INFO - ndcg@10: 0.024513
2025-11-22 21:45:05 - GraphTrainer - INFO - map@10: 0.017536
2025-11-22 21:45:05 - GraphTrainer - INFO - mrr@10: 0.018350
2025-11-22 21:45:05 - GraphTrainer - INFO - precision@20: 0.003878
2025-11-22 21:45:05 - GraphTrainer - INFO - recall@20: 0.073390
2025-11-22 21:45:05 - GraphTrainer - INFO - hit_rate@20: 0.077192
2025-11-22 21:45:05 - GraphTrainer - INFO - ndcg@20: 0.031312
2025-11-22 21:45:05 - GraphTrainer - INFO - map@20: 0.019368
2025-11-22 21:45:05 - GraphTrainer - INFO - mrr@20: 0.020259
2025-11-22 21:45:05 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:45:05 - GraphTrainer - INFO - ============================================================
2025-11-22 21:45:05 - GraphTrainer - INFO - 开始第 46/1000 轮训练
2025-11-22 21:45:05 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3784, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3797, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4083, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3872, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3754, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3767, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3689, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3872, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3780, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3987, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3580, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3697, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3560, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3799, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3939, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3861, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3507, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3796, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3760, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3817, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3906, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4076, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3736, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3781, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3882, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3929, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3752, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3780, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3836, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4004, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3666, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3642, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3838, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3657, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3761, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3830, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3662, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3680, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3714, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3629, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3755, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3701, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3728, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3727, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3687, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3739, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3650, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3669, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3951, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3645, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3792, device='cuda:0', grad_fn=<AddBackward0>)
The 45 training average loss: 0.3752981665833243
2025-11-22 21:45:16 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:45:16 - GraphTrainer - INFO -   precision@5: 0.006130
2025-11-22 21:45:16 - GraphTrainer - INFO -   recall@5: 0.029010
2025-11-22 21:45:16 - GraphTrainer - INFO -   hit_rate@5: 0.030548
2025-11-22 21:45:16 - GraphTrainer - INFO -   ndcg@5: 0.018459
2025-11-22 21:45:16 - GraphTrainer - INFO -   map@5: 0.014765
2025-11-22 21:45:16 - GraphTrainer - INFO -   mrr@5: 0.015395
2025-11-22 21:45:16 - GraphTrainer - INFO -   precision@10: 0.004927
2025-11-22 21:45:16 - GraphTrainer - INFO -   recall@10: 0.046740
2025-11-22 21:45:16 - GraphTrainer - INFO -   hit_rate@10: 0.049113
2025-11-22 21:45:16 - GraphTrainer - INFO -   ndcg@10: 0.024241
2025-11-22 21:45:16 - GraphTrainer - INFO -   map@10: 0.017134
2025-11-22 21:45:16 - GraphTrainer - INFO -   mrr@10: 0.017862
2025-11-22 21:45:16 - GraphTrainer - INFO -   precision@20: 0.003875
2025-11-22 21:45:16 - GraphTrainer - INFO -   recall@20: 0.073393
2025-11-22 21:45:16 - GraphTrainer - INFO -   hit_rate@20: 0.077192
2025-11-22 21:45:16 - GraphTrainer - INFO -   ndcg@20: 0.031015
2025-11-22 21:45:16 - GraphTrainer - INFO -   map@20: 0.018951
2025-11-22 21:45:16 - GraphTrainer - INFO -   mrr@20: 0.019770
2025-11-22 21:45:16 - GraphTrainer - INFO - 第 46 轮训练完成
2025-11-22 21:45:16 - GraphTrainer - INFO - train_loss: 0.374528
2025-11-22 21:45:16 - GraphTrainer - INFO - precision@5: 0.006130
2025-11-22 21:45:16 - GraphTrainer - INFO - recall@5: 0.029010
2025-11-22 21:45:16 - GraphTrainer - INFO - hit_rate@5: 0.030548
2025-11-22 21:45:16 - GraphTrainer - INFO - ndcg@5: 0.018459
2025-11-22 21:45:16 - GraphTrainer - INFO - map@5: 0.014765
2025-11-22 21:45:16 - GraphTrainer - INFO - mrr@5: 0.015395
2025-11-22 21:45:16 - GraphTrainer - INFO - precision@10: 0.004927
2025-11-22 21:45:16 - GraphTrainer - INFO - recall@10: 0.046740
2025-11-22 21:45:16 - GraphTrainer - INFO - hit_rate@10: 0.049113
2025-11-22 21:45:16 - GraphTrainer - INFO - ndcg@10: 0.024241
2025-11-22 21:45:16 - GraphTrainer - INFO - map@10: 0.017134
2025-11-22 21:45:16 - GraphTrainer - INFO - mrr@10: 0.017862
2025-11-22 21:45:16 - GraphTrainer - INFO - precision@20: 0.003875
2025-11-22 21:45:16 - GraphTrainer - INFO - recall@20: 0.073393
2025-11-22 21:45:16 - GraphTrainer - INFO - hit_rate@20: 0.077192
2025-11-22 21:45:16 - GraphTrainer - INFO - ndcg@20: 0.031015
2025-11-22 21:45:16 - GraphTrainer - INFO - map@20: 0.018951
2025-11-22 21:45:16 - GraphTrainer - INFO - mrr@20: 0.019770
2025-11-22 21:45:16 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:45:16 - GraphTrainer - INFO - ============================================================
2025-11-22 21:45:16 - GraphTrainer - INFO - 开始第 47/1000 轮训练
2025-11-22 21:45:16 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3771, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3771, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3923, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3736, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3863, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3897, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3623, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3616, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3865, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3860, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3574, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3723, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4000, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3787, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3755, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3723, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3663, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3787, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3615, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3863, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3680, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3804, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3778, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3815, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3713, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3758, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3791, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3704, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3576, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3837, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3923, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3727, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3738, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3699, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3840, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3849, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3680, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3754, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3643, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3701, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3731, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3770, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3931, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3805, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3850, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3650, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3747, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3747, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3886, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3787, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3774, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3824, device='cuda:0', grad_fn=<AddBackward0>)
The 46 training average loss: 0.3745283905802102
2025-11-22 21:45:28 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:45:28 - GraphTrainer - INFO -   precision@5: 0.006027
2025-11-22 21:45:28 - GraphTrainer - INFO -   recall@5: 0.028965
2025-11-22 21:45:28 - GraphTrainer - INFO -   hit_rate@5: 0.030085
2025-11-22 21:45:28 - GraphTrainer - INFO -   ndcg@5: 0.018691
2025-11-22 21:45:28 - GraphTrainer - INFO -   map@5: 0.015138
2025-11-22 21:45:28 - GraphTrainer - INFO -   mrr@5: 0.015672
2025-11-22 21:45:28 - GraphTrainer - INFO -   precision@10: 0.004963
2025-11-22 21:45:28 - GraphTrainer - INFO -   recall@10: 0.047428
2025-11-22 21:45:28 - GraphTrainer - INFO -   hit_rate@10: 0.049524
2025-11-22 21:45:28 - GraphTrainer - INFO -   ndcg@10: 0.024664
2025-11-22 21:45:28 - GraphTrainer - INFO -   map@10: 0.017548
2025-11-22 21:45:28 - GraphTrainer - INFO -   mrr@10: 0.018209
2025-11-22 21:45:28 - GraphTrainer - INFO -   precision@20: 0.003962
2025-11-22 21:45:28 - GraphTrainer - INFO -   recall@20: 0.075006
2025-11-22 21:45:28 - GraphTrainer - INFO -   hit_rate@20: 0.078992
2025-11-22 21:45:28 - GraphTrainer - INFO -   ndcg@20: 0.031701
2025-11-22 21:45:28 - GraphTrainer - INFO -   map@20: 0.019430
2025-11-22 21:45:28 - GraphTrainer - INFO -   mrr@20: 0.020216
2025-11-22 21:45:28 - GraphTrainer - INFO - 第 47 轮训练完成
2025-11-22 21:45:28 - GraphTrainer - INFO - train_loss: 0.370342
2025-11-22 21:45:28 - GraphTrainer - INFO - precision@5: 0.006027
2025-11-22 21:45:28 - GraphTrainer - INFO - recall@5: 0.028965
2025-11-22 21:45:28 - GraphTrainer - INFO - hit_rate@5: 0.030085
2025-11-22 21:45:28 - GraphTrainer - INFO - ndcg@5: 0.018691
2025-11-22 21:45:28 - GraphTrainer - INFO - map@5: 0.015138
2025-11-22 21:45:28 - GraphTrainer - INFO - mrr@5: 0.015672
2025-11-22 21:45:28 - GraphTrainer - INFO - precision@10: 0.004963
2025-11-22 21:45:28 - GraphTrainer - INFO - recall@10: 0.047428
2025-11-22 21:45:28 - GraphTrainer - INFO - hit_rate@10: 0.049524
2025-11-22 21:45:28 - GraphTrainer - INFO - ndcg@10: 0.024664
2025-11-22 21:45:28 - GraphTrainer - INFO - map@10: 0.017548
2025-11-22 21:45:28 - GraphTrainer - INFO - mrr@10: 0.018209
2025-11-22 21:45:28 - GraphTrainer - INFO - precision@20: 0.003962
2025-11-22 21:45:28 - GraphTrainer - INFO - recall@20: 0.075006
2025-11-22 21:45:28 - GraphTrainer - INFO - hit_rate@20: 0.078992
2025-11-22 21:45:28 - GraphTrainer - INFO - ndcg@20: 0.031701
2025-11-22 21:45:28 - GraphTrainer - INFO - map@20: 0.019430
2025-11-22 21:45:28 - GraphTrainer - INFO - mrr@20: 0.020216
2025-11-22 21:45:28 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:45:28 - GraphTrainer - INFO - ============================================================
2025-11-22 21:45:28 - GraphTrainer - INFO - 开始第 48/1000 轮训练
2025-11-22 21:45:28 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3616, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3633, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3879, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3687, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3741, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3775, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3617, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3735, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3916, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3480, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3621, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3667, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3760, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3761, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3889, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3823, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3766, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3693, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3640, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3473, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3690, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3908, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3817, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3627, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3616, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3658, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3657, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3680, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3544, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3965, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3658, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3784, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3874, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3756, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3741, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3712, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3651, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3816, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3868, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3754, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3696, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3845, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3701, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3737, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3565, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3652, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3728, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3562, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3666, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3839, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3707, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3896, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3586, device='cuda:0', grad_fn=<AddBackward0>)
The 47 training average loss: 0.3703420475639146
2025-11-22 21:45:39 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:45:39 - GraphTrainer - INFO -   precision@5: 0.006274
2025-11-22 21:45:39 - GraphTrainer - INFO -   recall@5: 0.029987
2025-11-22 21:45:39 - GraphTrainer - INFO -   hit_rate@5: 0.031268
2025-11-22 21:45:39 - GraphTrainer - INFO -   ndcg@5: 0.019355
2025-11-22 21:45:39 - GraphTrainer - INFO -   map@5: 0.015657
2025-11-22 21:45:39 - GraphTrainer - INFO -   mrr@5: 0.016283
2025-11-22 21:45:39 - GraphTrainer - INFO -   precision@10: 0.005004
2025-11-22 21:45:39 - GraphTrainer - INFO -   recall@10: 0.047556
2025-11-22 21:45:39 - GraphTrainer - INFO -   hit_rate@10: 0.049884
2025-11-22 21:45:39 - GraphTrainer - INFO -   ndcg@10: 0.025095
2025-11-22 21:45:39 - GraphTrainer - INFO -   map@10: 0.017999
2025-11-22 21:45:39 - GraphTrainer - INFO -   mrr@10: 0.018760
2025-11-22 21:45:39 - GraphTrainer - INFO -   precision@20: 0.003921
2025-11-22 21:45:39 - GraphTrainer - INFO -   recall@20: 0.074061
2025-11-22 21:45:39 - GraphTrainer - INFO -   hit_rate@20: 0.078118
2025-11-22 21:45:39 - GraphTrainer - INFO -   ndcg@20: 0.031882
2025-11-22 21:45:39 - GraphTrainer - INFO -   map@20: 0.019833
2025-11-22 21:45:39 - GraphTrainer - INFO -   mrr@20: 0.020709
2025-11-22 21:45:39 - GraphTrainer - INFO - 第 48 轮训练完成
2025-11-22 21:45:39 - GraphTrainer - INFO - train_loss: 0.371568
2025-11-22 21:45:39 - GraphTrainer - INFO - precision@5: 0.006274
2025-11-22 21:45:39 - GraphTrainer - INFO - recall@5: 0.029987
2025-11-22 21:45:39 - GraphTrainer - INFO - hit_rate@5: 0.031268
2025-11-22 21:45:39 - GraphTrainer - INFO - ndcg@5: 0.019355
2025-11-22 21:45:39 - GraphTrainer - INFO - map@5: 0.015657
2025-11-22 21:45:39 - GraphTrainer - INFO - mrr@5: 0.016283
2025-11-22 21:45:39 - GraphTrainer - INFO - precision@10: 0.005004
2025-11-22 21:45:39 - GraphTrainer - INFO - recall@10: 0.047556
2025-11-22 21:45:39 - GraphTrainer - INFO - hit_rate@10: 0.049884
2025-11-22 21:45:39 - GraphTrainer - INFO - ndcg@10: 0.025095
2025-11-22 21:45:39 - GraphTrainer - INFO - map@10: 0.017999
2025-11-22 21:45:39 - GraphTrainer - INFO - mrr@10: 0.018760
2025-11-22 21:45:39 - GraphTrainer - INFO - precision@20: 0.003921
2025-11-22 21:45:39 - GraphTrainer - INFO - recall@20: 0.074061
2025-11-22 21:45:39 - GraphTrainer - INFO - hit_rate@20: 0.078118
2025-11-22 21:45:39 - GraphTrainer - INFO - ndcg@20: 0.031882
2025-11-22 21:45:39 - GraphTrainer - INFO - map@20: 0.019833
2025-11-22 21:45:39 - GraphTrainer - INFO - mrr@20: 0.020709
2025-11-22 21:45:39 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:45:39 - GraphTrainer - INFO - ============================================================
2025-11-22 21:45:39 - GraphTrainer - INFO - 开始第 49/1000 轮训练
2025-11-22 21:45:39 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3874, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3637, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3719, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3643, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3729, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3746, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3876, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3755, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3697, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3807, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3648, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3681, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3760, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3682, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3933, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3633, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3814, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3750, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3742, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3886, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3836, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3716, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3575, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3911, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3759, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3731, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3753, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3641, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3616, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3602, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3601, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3574, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3756, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3703, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3911, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3747, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3831, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3780, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3640, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3621, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3711, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3943, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3633, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3752, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3878, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3638, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3658, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3818, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3707, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3693, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3643, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3732, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3827, device='cuda:0', grad_fn=<AddBackward0>)
The 48 training average loss: 0.3715675164913309
2025-11-22 21:45:50 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:45:50 - GraphTrainer - INFO -   precision@5: 0.006110
2025-11-22 21:45:50 - GraphTrainer - INFO -   recall@5: 0.029083
2025-11-22 21:45:50 - GraphTrainer - INFO -   hit_rate@5: 0.030445
2025-11-22 21:45:50 - GraphTrainer - INFO -   ndcg@5: 0.018863
2025-11-22 21:45:50 - GraphTrainer - INFO -   map@5: 0.015283
2025-11-22 21:45:50 - GraphTrainer - INFO -   mrr@5: 0.015924
2025-11-22 21:45:50 - GraphTrainer - INFO -   precision@10: 0.004963
2025-11-22 21:45:50 - GraphTrainer - INFO -   recall@10: 0.047346
2025-11-22 21:45:50 - GraphTrainer - INFO -   hit_rate@10: 0.049524
2025-11-22 21:45:50 - GraphTrainer - INFO -   ndcg@10: 0.024736
2025-11-22 21:45:50 - GraphTrainer - INFO -   map@10: 0.017644
2025-11-22 21:45:50 - GraphTrainer - INFO -   mrr@10: 0.018395
2025-11-22 21:45:50 - GraphTrainer - INFO -   precision@20: 0.003875
2025-11-22 21:45:50 - GraphTrainer - INFO -   recall@20: 0.073515
2025-11-22 21:45:50 - GraphTrainer - INFO -   hit_rate@20: 0.077089
2025-11-22 21:45:50 - GraphTrainer - INFO -   ndcg@20: 0.031404
2025-11-22 21:45:50 - GraphTrainer - INFO -   map@20: 0.019437
2025-11-22 21:45:50 - GraphTrainer - INFO -   mrr@20: 0.020279
2025-11-22 21:45:50 - GraphTrainer - INFO - 第 49 轮训练完成
2025-11-22 21:45:50 - GraphTrainer - INFO - train_loss: 0.368921
2025-11-22 21:45:50 - GraphTrainer - INFO - precision@5: 0.006110
2025-11-22 21:45:50 - GraphTrainer - INFO - recall@5: 0.029083
2025-11-22 21:45:50 - GraphTrainer - INFO - hit_rate@5: 0.030445
2025-11-22 21:45:50 - GraphTrainer - INFO - ndcg@5: 0.018863
2025-11-22 21:45:50 - GraphTrainer - INFO - map@5: 0.015283
2025-11-22 21:45:50 - GraphTrainer - INFO - mrr@5: 0.015924
2025-11-22 21:45:50 - GraphTrainer - INFO - precision@10: 0.004963
2025-11-22 21:45:50 - GraphTrainer - INFO - recall@10: 0.047346
2025-11-22 21:45:50 - GraphTrainer - INFO - hit_rate@10: 0.049524
2025-11-22 21:45:50 - GraphTrainer - INFO - ndcg@10: 0.024736
2025-11-22 21:45:50 - GraphTrainer - INFO - map@10: 0.017644
2025-11-22 21:45:50 - GraphTrainer - INFO - mrr@10: 0.018395
2025-11-22 21:45:50 - GraphTrainer - INFO - precision@20: 0.003875
2025-11-22 21:45:50 - GraphTrainer - INFO - recall@20: 0.073515
2025-11-22 21:45:50 - GraphTrainer - INFO - hit_rate@20: 0.077089
2025-11-22 21:45:50 - GraphTrainer - INFO - ndcg@20: 0.031404
2025-11-22 21:45:50 - GraphTrainer - INFO - map@20: 0.019437
2025-11-22 21:45:50 - GraphTrainer - INFO - mrr@20: 0.020279
2025-11-22 21:45:50 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:45:50 - GraphTrainer - INFO - ============================================================
2025-11-22 21:45:50 - GraphTrainer - INFO - 开始第 50/1000 轮训练
2025-11-22 21:45:50 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3676, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3788, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3743, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3749, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3635, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3815, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3865, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3743, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3767, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3673, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3720, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3728, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3732, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3800, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3795, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3647, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3731, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3897, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3734, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3473, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3668, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3596, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3554, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3667, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3763, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3681, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3731, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3793, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3627, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3719, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3831, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3802, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3779, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3568, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3670, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3754, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3664, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4020, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3592, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3923, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3783, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3697, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3570, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3783, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3580, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3732, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3745, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3665, device='cuda:0', grad_fn=<AddBackward0>)
The 49 training average loss: 0.36892062220080146
2025-11-22 21:46:01 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:46:01 - GraphTrainer - INFO -   precision@5: 0.005966
2025-11-22 21:46:01 - GraphTrainer - INFO -   recall@5: 0.028319
2025-11-22 21:46:01 - GraphTrainer - INFO -   hit_rate@5: 0.029725
2025-11-22 21:46:01 - GraphTrainer - INFO -   ndcg@5: 0.018251
2025-11-22 21:46:01 - GraphTrainer - INFO -   map@5: 0.014728
2025-11-22 21:46:01 - GraphTrainer - INFO -   mrr@5: 0.015378
2025-11-22 21:46:01 - GraphTrainer - INFO -   precision@10: 0.004932
2025-11-22 21:46:01 - GraphTrainer - INFO -   recall@10: 0.046876
2025-11-22 21:46:01 - GraphTrainer - INFO -   hit_rate@10: 0.049164
2025-11-22 21:46:01 - GraphTrainer - INFO -   ndcg@10: 0.024257
2025-11-22 21:46:01 - GraphTrainer - INFO -   map@10: 0.017162
2025-11-22 21:46:01 - GraphTrainer - INFO -   mrr@10: 0.017918
2025-11-22 21:46:01 - GraphTrainer - INFO -   precision@20: 0.003865
2025-11-22 21:46:01 - GraphTrainer - INFO -   recall@20: 0.073275
2025-11-22 21:46:01 - GraphTrainer - INFO -   hit_rate@20: 0.076986
2025-11-22 21:46:01 - GraphTrainer - INFO -   ndcg@20: 0.030969
2025-11-22 21:46:01 - GraphTrainer - INFO -   map@20: 0.018961
2025-11-22 21:46:01 - GraphTrainer - INFO -   mrr@20: 0.019814
2025-11-22 21:46:01 - GraphTrainer - INFO - 第 50 轮训练完成
2025-11-22 21:46:01 - GraphTrainer - INFO - train_loss: 0.368410
2025-11-22 21:46:01 - GraphTrainer - INFO - precision@5: 0.005966
2025-11-22 21:46:01 - GraphTrainer - INFO - recall@5: 0.028319
2025-11-22 21:46:01 - GraphTrainer - INFO - hit_rate@5: 0.029725
2025-11-22 21:46:01 - GraphTrainer - INFO - ndcg@5: 0.018251
2025-11-22 21:46:01 - GraphTrainer - INFO - map@5: 0.014728
2025-11-22 21:46:01 - GraphTrainer - INFO - mrr@5: 0.015378
2025-11-22 21:46:01 - GraphTrainer - INFO - precision@10: 0.004932
2025-11-22 21:46:01 - GraphTrainer - INFO - recall@10: 0.046876
2025-11-22 21:46:01 - GraphTrainer - INFO - hit_rate@10: 0.049164
2025-11-22 21:46:01 - GraphTrainer - INFO - ndcg@10: 0.024257
2025-11-22 21:46:01 - GraphTrainer - INFO - map@10: 0.017162
2025-11-22 21:46:01 - GraphTrainer - INFO - mrr@10: 0.017918
2025-11-22 21:46:01 - GraphTrainer - INFO - precision@20: 0.003865
2025-11-22 21:46:01 - GraphTrainer - INFO - recall@20: 0.073275
2025-11-22 21:46:01 - GraphTrainer - INFO - hit_rate@20: 0.076986
2025-11-22 21:46:01 - GraphTrainer - INFO - ndcg@20: 0.030969
2025-11-22 21:46:01 - GraphTrainer - INFO - map@20: 0.018961
2025-11-22 21:46:01 - GraphTrainer - INFO - mrr@20: 0.019814
2025-11-22 21:46:01 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:46:01 - GraphTrainer - INFO - 检查点已保存: Epoch 50 -> ./checkpoints/checkpoint_epoch_50.pth
2025-11-22 21:46:01 - GraphTrainer - INFO - ============================================================
2025-11-22 21:46:01 - GraphTrainer - INFO - 开始第 51/1000 轮训练
2025-11-22 21:46:01 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3667, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3729, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3780, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3591, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3734, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3770, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3612, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3588, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3751, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3700, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3655, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3658, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3782, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3539, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3723, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3644, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3547, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3771, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3616, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3627, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3840, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3644, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3605, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3811, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3625, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3867, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3854, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3793, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3898, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3571, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3510, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3896, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3656, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3934, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3732, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3645, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3715, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3849, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3741, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3740, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3895, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3610, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3642, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3795, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3590, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3716, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3732, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3574, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3982, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3569, device='cuda:0', grad_fn=<AddBackward0>)
The 50 training average loss: 0.36840953549434396
2025-11-22 21:46:12 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:46:12 - GraphTrainer - INFO -   precision@5: 0.005883
2025-11-22 21:46:12 - GraphTrainer - INFO -   recall@5: 0.028028
2025-11-22 21:46:12 - GraphTrainer - INFO -   hit_rate@5: 0.029365
2025-11-22 21:46:12 - GraphTrainer - INFO -   ndcg@5: 0.018343
2025-11-22 21:46:12 - GraphTrainer - INFO -   map@5: 0.014973
2025-11-22 21:46:12 - GraphTrainer - INFO -   mrr@5: 0.015540
2025-11-22 21:46:12 - GraphTrainer - INFO -   precision@10: 0.005009
2025-11-22 21:46:12 - GraphTrainer - INFO -   recall@10: 0.047447
2025-11-22 21:46:12 - GraphTrainer - INFO -   hit_rate@10: 0.049936
2025-11-22 21:46:12 - GraphTrainer - INFO -   ndcg@10: 0.024657
2025-11-22 21:46:12 - GraphTrainer - INFO -   map@10: 0.017530
2025-11-22 21:46:12 - GraphTrainer - INFO -   mrr@10: 0.018239
2025-11-22 21:46:12 - GraphTrainer - INFO -   precision@20: 0.003955
2025-11-22 21:46:12 - GraphTrainer - INFO -   recall@20: 0.074931
2025-11-22 21:46:12 - GraphTrainer - INFO -   hit_rate@20: 0.078735
2025-11-22 21:46:12 - GraphTrainer - INFO -   ndcg@20: 0.031637
2025-11-22 21:46:12 - GraphTrainer - INFO -   map@20: 0.019404
2025-11-22 21:46:12 - GraphTrainer - INFO -   mrr@20: 0.020203
2025-11-22 21:46:12 - GraphTrainer - INFO - 第 51 轮训练完成
2025-11-22 21:46:12 - GraphTrainer - INFO - train_loss: 0.369495
2025-11-22 21:46:12 - GraphTrainer - INFO - precision@5: 0.005883
2025-11-22 21:46:12 - GraphTrainer - INFO - recall@5: 0.028028
2025-11-22 21:46:12 - GraphTrainer - INFO - hit_rate@5: 0.029365
2025-11-22 21:46:12 - GraphTrainer - INFO - ndcg@5: 0.018343
2025-11-22 21:46:12 - GraphTrainer - INFO - map@5: 0.014973
2025-11-22 21:46:12 - GraphTrainer - INFO - mrr@5: 0.015540
2025-11-22 21:46:12 - GraphTrainer - INFO - precision@10: 0.005009
2025-11-22 21:46:12 - GraphTrainer - INFO - recall@10: 0.047447
2025-11-22 21:46:12 - GraphTrainer - INFO - hit_rate@10: 0.049936
2025-11-22 21:46:12 - GraphTrainer - INFO - ndcg@10: 0.024657
2025-11-22 21:46:12 - GraphTrainer - INFO - map@10: 0.017530
2025-11-22 21:46:12 - GraphTrainer - INFO - mrr@10: 0.018239
2025-11-22 21:46:12 - GraphTrainer - INFO - precision@20: 0.003955
2025-11-22 21:46:12 - GraphTrainer - INFO - recall@20: 0.074931
2025-11-22 21:46:12 - GraphTrainer - INFO - hit_rate@20: 0.078735
2025-11-22 21:46:12 - GraphTrainer - INFO - ndcg@20: 0.031637
2025-11-22 21:46:12 - GraphTrainer - INFO - map@20: 0.019404
2025-11-22 21:46:12 - GraphTrainer - INFO - mrr@20: 0.020203
2025-11-22 21:46:12 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:46:12 - GraphTrainer - INFO - ============================================================
2025-11-22 21:46:12 - GraphTrainer - INFO - 开始第 52/1000 轮训练
2025-11-22 21:46:12 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3893, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3767, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3684, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3512, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4001, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3735, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3636, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3756, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3782, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3694, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3602, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3643, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3726, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3660, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3783, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3556, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3818, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3573, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3804, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3669, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3788, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3701, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3824, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3727, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3871, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3810, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3925, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3706, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3569, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3561, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3658, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3565, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3866, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3595, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3628, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3661, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3699, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3754, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3636, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3588, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3766, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3722, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3785, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3545, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3867, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3656, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3556, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3897, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3889, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3610, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3819, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3789, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3610, device='cuda:0', grad_fn=<AddBackward0>)
The 51 training average loss: 0.36949479579925537
2025-11-22 21:46:23 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:46:23 - GraphTrainer - INFO -   precision@5: 0.006315
2025-11-22 21:46:23 - GraphTrainer - INFO -   recall@5: 0.030098
2025-11-22 21:46:23 - GraphTrainer - INFO -   hit_rate@5: 0.031473
2025-11-22 21:46:23 - GraphTrainer - INFO -   ndcg@5: 0.019221
2025-11-22 21:46:23 - GraphTrainer - INFO -   map@5: 0.015472
2025-11-22 21:46:23 - GraphTrainer - INFO -   mrr@5: 0.016062
2025-11-22 21:46:23 - GraphTrainer - INFO -   precision@10: 0.004947
2025-11-22 21:46:23 - GraphTrainer - INFO -   recall@10: 0.047119
2025-11-22 21:46:23 - GraphTrainer - INFO -   hit_rate@10: 0.049319
2025-11-22 21:46:23 - GraphTrainer - INFO -   ndcg@10: 0.024727
2025-11-22 21:46:23 - GraphTrainer - INFO -   map@10: 0.017698
2025-11-22 21:46:23 - GraphTrainer - INFO -   mrr@10: 0.018392
2025-11-22 21:46:23 - GraphTrainer - INFO -   precision@20: 0.003878
2025-11-22 21:46:23 - GraphTrainer - INFO -   recall@20: 0.073342
2025-11-22 21:46:23 - GraphTrainer - INFO -   hit_rate@20: 0.077089
2025-11-22 21:46:23 - GraphTrainer - INFO -   ndcg@20: 0.031415
2025-11-22 21:46:23 - GraphTrainer - INFO -   map@20: 0.019495
2025-11-22 21:46:23 - GraphTrainer - INFO -   mrr@20: 0.020294
2025-11-22 21:46:23 - GraphTrainer - INFO - 第 52 轮训练完成
2025-11-22 21:46:23 - GraphTrainer - INFO - train_loss: 0.365941
2025-11-22 21:46:23 - GraphTrainer - INFO - precision@5: 0.006315
2025-11-22 21:46:23 - GraphTrainer - INFO - recall@5: 0.030098
2025-11-22 21:46:23 - GraphTrainer - INFO - hit_rate@5: 0.031473
2025-11-22 21:46:23 - GraphTrainer - INFO - ndcg@5: 0.019221
2025-11-22 21:46:23 - GraphTrainer - INFO - map@5: 0.015472
2025-11-22 21:46:23 - GraphTrainer - INFO - mrr@5: 0.016062
2025-11-22 21:46:23 - GraphTrainer - INFO - precision@10: 0.004947
2025-11-22 21:46:23 - GraphTrainer - INFO - recall@10: 0.047119
2025-11-22 21:46:23 - GraphTrainer - INFO - hit_rate@10: 0.049319
2025-11-22 21:46:23 - GraphTrainer - INFO - ndcg@10: 0.024727
2025-11-22 21:46:23 - GraphTrainer - INFO - map@10: 0.017698
2025-11-22 21:46:23 - GraphTrainer - INFO - mrr@10: 0.018392
2025-11-22 21:46:23 - GraphTrainer - INFO - precision@20: 0.003878
2025-11-22 21:46:23 - GraphTrainer - INFO - recall@20: 0.073342
2025-11-22 21:46:23 - GraphTrainer - INFO - hit_rate@20: 0.077089
2025-11-22 21:46:23 - GraphTrainer - INFO - ndcg@20: 0.031415
2025-11-22 21:46:23 - GraphTrainer - INFO - map@20: 0.019495
2025-11-22 21:46:23 - GraphTrainer - INFO - mrr@20: 0.020294
2025-11-22 21:46:23 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:46:23 - GraphTrainer - INFO - ============================================================
2025-11-22 21:46:23 - GraphTrainer - INFO - 开始第 53/1000 轮训练
2025-11-22 21:46:23 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3502, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3698, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3798, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3709, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3605, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3664, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3796, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3810, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3632, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3629, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3737, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3702, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3695, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3602, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3634, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3915, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3781, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3676, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3643, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3774, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3726, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3696, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3693, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3663, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3592, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3814, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3664, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3560, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3708, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3793, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3699, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3656, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3905, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3819, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3714, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3870, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3627, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3977, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3830, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3584, device='cuda:0', grad_fn=<AddBackward0>)
The 52 training average loss: 0.3659410846644434
2025-11-22 21:46:34 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:46:34 - GraphTrainer - INFO -   precision@5: 0.005935
2025-11-22 21:46:34 - GraphTrainer - INFO -   recall@5: 0.028257
2025-11-22 21:46:34 - GraphTrainer - INFO -   hit_rate@5: 0.029622
2025-11-22 21:46:34 - GraphTrainer - INFO -   ndcg@5: 0.018582
2025-11-22 21:46:34 - GraphTrainer - INFO -   map@5: 0.015181
2025-11-22 21:46:34 - GraphTrainer - INFO -   mrr@5: 0.015852
2025-11-22 21:46:34 - GraphTrainer - INFO -   precision@10: 0.004988
2025-11-22 21:46:34 - GraphTrainer - INFO -   recall@10: 0.047468
2025-11-22 21:46:34 - GraphTrainer - INFO -   hit_rate@10: 0.049679
2025-11-22 21:46:34 - GraphTrainer - INFO -   ndcg@10: 0.024813
2025-11-22 21:46:34 - GraphTrainer - INFO -   map@10: 0.017709
2025-11-22 21:46:34 - GraphTrainer - INFO -   mrr@10: 0.018486
2025-11-22 21:46:34 - GraphTrainer - INFO -   precision@20: 0.003788
2025-11-22 21:46:34 - GraphTrainer - INFO -   recall@20: 0.071802
2025-11-22 21:46:34 - GraphTrainer - INFO -   hit_rate@20: 0.075392
2025-11-22 21:46:34 - GraphTrainer - INFO -   ndcg@20: 0.031004
2025-11-22 21:46:34 - GraphTrainer - INFO -   map@20: 0.019370
2025-11-22 21:46:34 - GraphTrainer - INFO -   mrr@20: 0.020240
2025-11-22 21:46:34 - GraphTrainer - INFO - 第 53 轮训练完成
2025-11-22 21:46:34 - GraphTrainer - INFO - train_loss: 0.368325
2025-11-22 21:46:34 - GraphTrainer - INFO - precision@5: 0.005935
2025-11-22 21:46:34 - GraphTrainer - INFO - recall@5: 0.028257
2025-11-22 21:46:34 - GraphTrainer - INFO - hit_rate@5: 0.029622
2025-11-22 21:46:34 - GraphTrainer - INFO - ndcg@5: 0.018582
2025-11-22 21:46:34 - GraphTrainer - INFO - map@5: 0.015181
2025-11-22 21:46:34 - GraphTrainer - INFO - mrr@5: 0.015852
2025-11-22 21:46:34 - GraphTrainer - INFO - precision@10: 0.004988
2025-11-22 21:46:34 - GraphTrainer - INFO - recall@10: 0.047468
2025-11-22 21:46:34 - GraphTrainer - INFO - hit_rate@10: 0.049679
2025-11-22 21:46:34 - GraphTrainer - INFO - ndcg@10: 0.024813
2025-11-22 21:46:34 - GraphTrainer - INFO - map@10: 0.017709
2025-11-22 21:46:34 - GraphTrainer - INFO - mrr@10: 0.018486
2025-11-22 21:46:34 - GraphTrainer - INFO - precision@20: 0.003788
2025-11-22 21:46:34 - GraphTrainer - INFO - recall@20: 0.071802
2025-11-22 21:46:34 - GraphTrainer - INFO - hit_rate@20: 0.075392
2025-11-22 21:46:34 - GraphTrainer - INFO - ndcg@20: 0.031004
2025-11-22 21:46:34 - GraphTrainer - INFO - map@20: 0.019370
2025-11-22 21:46:34 - GraphTrainer - INFO - mrr@20: 0.020240
2025-11-22 21:46:34 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:46:34 - GraphTrainer - INFO - ============================================================
2025-11-22 21:46:34 - GraphTrainer - INFO - 开始第 54/1000 轮训练
2025-11-22 21:46:34 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3462, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3751, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3494, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3574, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3842, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3797, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3536, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3805, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3684, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3876, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3815, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3616, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3692, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3747, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3887, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3629, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3645, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3763, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3780, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3736, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3761, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3687, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3647, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3479, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3468, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3842, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3921, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3795, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3610, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3847, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3635, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3963, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3852, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3742, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3754, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3622, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3757, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3746, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3764, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4029, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3931, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3755, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3727, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3614, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3605, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3643, device='cuda:0', grad_fn=<AddBackward0>)
The 53 training average loss: 0.36832519081132165
2025-11-22 21:46:45 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:46:45 - GraphTrainer - INFO -   precision@5: 0.006151
2025-11-22 21:46:45 - GraphTrainer - INFO -   recall@5: 0.029329
2025-11-22 21:46:45 - GraphTrainer - INFO -   hit_rate@5: 0.030702
2025-11-22 21:46:45 - GraphTrainer - INFO -   ndcg@5: 0.019210
2025-11-22 21:46:45 - GraphTrainer - INFO -   map@5: 0.015683
2025-11-22 21:46:45 - GraphTrainer - INFO -   mrr@5: 0.016326
2025-11-22 21:46:45 - GraphTrainer - INFO -   precision@10: 0.004927
2025-11-22 21:46:45 - GraphTrainer - INFO -   recall@10: 0.046683
2025-11-22 21:46:45 - GraphTrainer - INFO -   hit_rate@10: 0.049113
2025-11-22 21:46:45 - GraphTrainer - INFO -   ndcg@10: 0.024825
2025-11-22 21:46:45 - GraphTrainer - INFO -   map@10: 0.017936
2025-11-22 21:46:45 - GraphTrainer - INFO -   mrr@10: 0.018713
2025-11-22 21:46:45 - GraphTrainer - INFO -   precision@20: 0.003952
2025-11-22 21:46:45 - GraphTrainer - INFO -   recall@20: 0.074799
2025-11-22 21:46:45 - GraphTrainer - INFO -   hit_rate@20: 0.078581
2025-11-22 21:46:45 - GraphTrainer - INFO -   ndcg@20: 0.031975
2025-11-22 21:46:45 - GraphTrainer - INFO -   map@20: 0.019861
2025-11-22 21:46:45 - GraphTrainer - INFO -   mrr@20: 0.020722
2025-11-22 21:46:45 - GraphTrainer - INFO - 第 54 轮训练完成
2025-11-22 21:46:45 - GraphTrainer - INFO - train_loss: 0.368851
2025-11-22 21:46:45 - GraphTrainer - INFO - precision@5: 0.006151
2025-11-22 21:46:45 - GraphTrainer - INFO - recall@5: 0.029329
2025-11-22 21:46:45 - GraphTrainer - INFO - hit_rate@5: 0.030702
2025-11-22 21:46:45 - GraphTrainer - INFO - ndcg@5: 0.019210
2025-11-22 21:46:45 - GraphTrainer - INFO - map@5: 0.015683
2025-11-22 21:46:45 - GraphTrainer - INFO - mrr@5: 0.016326
2025-11-22 21:46:45 - GraphTrainer - INFO - precision@10: 0.004927
2025-11-22 21:46:45 - GraphTrainer - INFO - recall@10: 0.046683
2025-11-22 21:46:45 - GraphTrainer - INFO - hit_rate@10: 0.049113
2025-11-22 21:46:45 - GraphTrainer - INFO - ndcg@10: 0.024825
2025-11-22 21:46:45 - GraphTrainer - INFO - map@10: 0.017936
2025-11-22 21:46:45 - GraphTrainer - INFO - mrr@10: 0.018713
2025-11-22 21:46:45 - GraphTrainer - INFO - precision@20: 0.003952
2025-11-22 21:46:45 - GraphTrainer - INFO - recall@20: 0.074799
2025-11-22 21:46:45 - GraphTrainer - INFO - hit_rate@20: 0.078581
2025-11-22 21:46:45 - GraphTrainer - INFO - ndcg@20: 0.031975
2025-11-22 21:46:45 - GraphTrainer - INFO - map@20: 0.019861
2025-11-22 21:46:45 - GraphTrainer - INFO - mrr@20: 0.020722
2025-11-22 21:46:45 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:46:45 - GraphTrainer - INFO - ============================================================
2025-11-22 21:46:45 - GraphTrainer - INFO - 开始第 55/1000 轮训练
2025-11-22 21:46:45 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3712, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3685, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3608, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3983, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3894, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3670, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3655, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3711, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3555, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3849, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3644, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3725, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3621, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3625, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3617, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3550, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3835, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3645, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3605, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3561, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3709, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3792, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3743, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3712, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3722, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3706, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3731, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3596, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3611, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3601, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3565, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3455, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3776, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3785, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3737, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3700, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3923, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3627, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3664, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3652, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3680, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3608, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3830, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3909, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4004, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3763, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3642, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3588, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3807, device='cuda:0', grad_fn=<AddBackward0>)
The 54 training average loss: 0.36885059136768866
2025-11-22 21:46:56 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:46:56 - GraphTrainer - INFO -   precision@5: 0.005996
2025-11-22 21:46:56 - GraphTrainer - INFO -   recall@5: 0.028587
2025-11-22 21:46:56 - GraphTrainer - INFO -   hit_rate@5: 0.029931
2025-11-22 21:46:56 - GraphTrainer - INFO -   ndcg@5: 0.018507
2025-11-22 21:46:56 - GraphTrainer - INFO -   map@5: 0.014963
2025-11-22 21:46:56 - GraphTrainer - INFO -   mrr@5: 0.015654
2025-11-22 21:46:56 - GraphTrainer - INFO -   precision@10: 0.004916
2025-11-22 21:46:56 - GraphTrainer - INFO -   recall@10: 0.046545
2025-11-22 21:46:56 - GraphTrainer - INFO -   hit_rate@10: 0.048959
2025-11-22 21:46:56 - GraphTrainer - INFO -   ndcg@10: 0.024350
2025-11-22 21:46:56 - GraphTrainer - INFO -   map@10: 0.017328
2025-11-22 21:46:56 - GraphTrainer - INFO -   mrr@10: 0.018155
2025-11-22 21:46:56 - GraphTrainer - INFO -   precision@20: 0.003860
2025-11-22 21:46:56 - GraphTrainer - INFO -   recall@20: 0.073219
2025-11-22 21:46:56 - GraphTrainer - INFO -   hit_rate@20: 0.076678
2025-11-22 21:46:56 - GraphTrainer - INFO -   ndcg@20: 0.031116
2025-11-22 21:46:56 - GraphTrainer - INFO -   map@20: 0.019149
2025-11-22 21:46:56 - GraphTrainer - INFO -   mrr@20: 0.020042
2025-11-22 21:46:56 - GraphTrainer - INFO - 第 55 轮训练完成
2025-11-22 21:46:56 - GraphTrainer - INFO - train_loss: 0.365432
2025-11-22 21:46:56 - GraphTrainer - INFO - precision@5: 0.005996
2025-11-22 21:46:56 - GraphTrainer - INFO - recall@5: 0.028587
2025-11-22 21:46:56 - GraphTrainer - INFO - hit_rate@5: 0.029931
2025-11-22 21:46:56 - GraphTrainer - INFO - ndcg@5: 0.018507
2025-11-22 21:46:56 - GraphTrainer - INFO - map@5: 0.014963
2025-11-22 21:46:56 - GraphTrainer - INFO - mrr@5: 0.015654
2025-11-22 21:46:56 - GraphTrainer - INFO - precision@10: 0.004916
2025-11-22 21:46:56 - GraphTrainer - INFO - recall@10: 0.046545
2025-11-22 21:46:56 - GraphTrainer - INFO - hit_rate@10: 0.048959
2025-11-22 21:46:56 - GraphTrainer - INFO - ndcg@10: 0.024350
2025-11-22 21:46:56 - GraphTrainer - INFO - map@10: 0.017328
2025-11-22 21:46:56 - GraphTrainer - INFO - mrr@10: 0.018155
2025-11-22 21:46:56 - GraphTrainer - INFO - precision@20: 0.003860
2025-11-22 21:46:56 - GraphTrainer - INFO - recall@20: 0.073219
2025-11-22 21:46:56 - GraphTrainer - INFO - hit_rate@20: 0.076678
2025-11-22 21:46:56 - GraphTrainer - INFO - ndcg@20: 0.031116
2025-11-22 21:46:56 - GraphTrainer - INFO - map@20: 0.019149
2025-11-22 21:46:56 - GraphTrainer - INFO - mrr@20: 0.020042
2025-11-22 21:46:56 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:46:56 - GraphTrainer - INFO - ============================================================
2025-11-22 21:46:56 - GraphTrainer - INFO - 开始第 56/1000 轮训练
2025-11-22 21:46:56 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3762, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3828, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3551, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3697, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3790, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3631, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3965, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3629, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3758, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3857, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3746, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3665, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3529, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3760, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3790, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3617, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3661, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3719, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3510, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3715, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3708, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3670, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3641, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3617, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3626, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3584, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3749, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3575, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3635, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3626, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3630, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3660, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3897, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3798, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3655, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3775, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3682, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3720, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3632, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3640, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3929, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3868, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3689, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3836, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>)
The 55 training average loss: 0.3654322372428302
2025-11-22 21:47:07 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:47:07 - GraphTrainer - INFO -   precision@5: 0.006140
2025-11-22 21:47:07 - GraphTrainer - INFO -   recall@5: 0.029362
2025-11-22 21:47:07 - GraphTrainer - INFO -   hit_rate@5: 0.030651
2025-11-22 21:47:07 - GraphTrainer - INFO -   ndcg@5: 0.019191
2025-11-22 21:47:07 - GraphTrainer - INFO -   map@5: 0.015651
2025-11-22 21:47:07 - GraphTrainer - INFO -   mrr@5: 0.016303
2025-11-22 21:47:07 - GraphTrainer - INFO -   precision@10: 0.004880
2025-11-22 21:47:07 - GraphTrainer - INFO -   recall@10: 0.046378
2025-11-22 21:47:07 - GraphTrainer - INFO -   hit_rate@10: 0.048701
2025-11-22 21:47:07 - GraphTrainer - INFO -   ndcg@10: 0.024754
2025-11-22 21:47:07 - GraphTrainer - INFO -   map@10: 0.017919
2025-11-22 21:47:07 - GraphTrainer - INFO -   mrr@10: 0.018707
2025-11-22 21:47:07 - GraphTrainer - INFO -   precision@20: 0.003867
2025-11-22 21:47:07 - GraphTrainer - INFO -   recall@20: 0.073287
2025-11-22 21:47:07 - GraphTrainer - INFO -   hit_rate@20: 0.077089
2025-11-22 21:47:07 - GraphTrainer - INFO -   ndcg@20: 0.031571
2025-11-22 21:47:07 - GraphTrainer - INFO -   map@20: 0.019734
2025-11-22 21:47:07 - GraphTrainer - INFO -   mrr@20: 0.020619
2025-11-22 21:47:07 - GraphTrainer - INFO - 第 56 轮训练完成
2025-11-22 21:47:07 - GraphTrainer - INFO - train_loss: 0.362453
2025-11-22 21:47:07 - GraphTrainer - INFO - precision@5: 0.006140
2025-11-22 21:47:07 - GraphTrainer - INFO - recall@5: 0.029362
2025-11-22 21:47:07 - GraphTrainer - INFO - hit_rate@5: 0.030651
2025-11-22 21:47:07 - GraphTrainer - INFO - ndcg@5: 0.019191
2025-11-22 21:47:07 - GraphTrainer - INFO - map@5: 0.015651
2025-11-22 21:47:07 - GraphTrainer - INFO - mrr@5: 0.016303
2025-11-22 21:47:07 - GraphTrainer - INFO - precision@10: 0.004880
2025-11-22 21:47:07 - GraphTrainer - INFO - recall@10: 0.046378
2025-11-22 21:47:07 - GraphTrainer - INFO - hit_rate@10: 0.048701
2025-11-22 21:47:07 - GraphTrainer - INFO - ndcg@10: 0.024754
2025-11-22 21:47:07 - GraphTrainer - INFO - map@10: 0.017919
2025-11-22 21:47:07 - GraphTrainer - INFO - mrr@10: 0.018707
2025-11-22 21:47:07 - GraphTrainer - INFO - precision@20: 0.003867
2025-11-22 21:47:07 - GraphTrainer - INFO - recall@20: 0.073287
2025-11-22 21:47:07 - GraphTrainer - INFO - hit_rate@20: 0.077089
2025-11-22 21:47:07 - GraphTrainer - INFO - ndcg@20: 0.031571
2025-11-22 21:47:07 - GraphTrainer - INFO - map@20: 0.019734
2025-11-22 21:47:07 - GraphTrainer - INFO - mrr@20: 0.020619
2025-11-22 21:47:07 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:47:07 - GraphTrainer - INFO - ============================================================
2025-11-22 21:47:07 - GraphTrainer - INFO - 开始第 57/1000 轮训练
2025-11-22 21:47:07 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3717, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3624, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3572, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3879, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3662, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3693, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3655, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3570, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3616, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3833, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3740, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3760, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3737, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3644, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3811, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3655, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3833, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3551, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3621, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3667, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3575, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3731, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3226, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3687, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3623, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3781, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3689, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3632, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3648, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3599, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3705, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3591, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3700, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3595, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3586, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3773, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3689, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3640, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3729, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3676, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3610, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3718, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3434, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3894, device='cuda:0', grad_fn=<AddBackward0>)
The 56 training average loss: 0.36245298334236803
2025-11-22 21:47:19 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:47:19 - GraphTrainer - INFO -   precision@5: 0.006243
2025-11-22 21:47:19 - GraphTrainer - INFO -   recall@5: 0.029489
2025-11-22 21:47:19 - GraphTrainer - INFO -   hit_rate@5: 0.031165
2025-11-22 21:47:19 - GraphTrainer - INFO -   ndcg@5: 0.019405
2025-11-22 21:47:19 - GraphTrainer - INFO -   map@5: 0.015831
2025-11-22 21:47:19 - GraphTrainer - INFO -   mrr@5: 0.016618
2025-11-22 21:47:19 - GraphTrainer - INFO -   precision@10: 0.004901
2025-11-22 21:47:19 - GraphTrainer - INFO -   recall@10: 0.046591
2025-11-22 21:47:19 - GraphTrainer - INFO -   hit_rate@10: 0.048907
2025-11-22 21:47:19 - GraphTrainer - INFO -   ndcg@10: 0.024932
2025-11-22 21:47:19 - GraphTrainer - INFO -   map@10: 0.018074
2025-11-22 21:47:19 - GraphTrainer - INFO -   mrr@10: 0.018943
2025-11-22 21:47:19 - GraphTrainer - INFO -   precision@20: 0.003934
2025-11-22 21:47:19 - GraphTrainer - INFO -   recall@20: 0.074173
2025-11-22 21:47:19 - GraphTrainer - INFO -   hit_rate@20: 0.078118
2025-11-22 21:47:19 - GraphTrainer - INFO -   ndcg@20: 0.031939
2025-11-22 21:47:19 - GraphTrainer - INFO -   map@20: 0.019939
2025-11-22 21:47:19 - GraphTrainer - INFO -   mrr@20: 0.020911
2025-11-22 21:47:19 - GraphTrainer - INFO - 第 57 轮训练完成
2025-11-22 21:47:19 - GraphTrainer - INFO - train_loss: 0.363549
2025-11-22 21:47:19 - GraphTrainer - INFO - precision@5: 0.006243
2025-11-22 21:47:19 - GraphTrainer - INFO - recall@5: 0.029489
2025-11-22 21:47:19 - GraphTrainer - INFO - hit_rate@5: 0.031165
2025-11-22 21:47:19 - GraphTrainer - INFO - ndcg@5: 0.019405
2025-11-22 21:47:19 - GraphTrainer - INFO - map@5: 0.015831
2025-11-22 21:47:19 - GraphTrainer - INFO - mrr@5: 0.016618
2025-11-22 21:47:19 - GraphTrainer - INFO - precision@10: 0.004901
2025-11-22 21:47:19 - GraphTrainer - INFO - recall@10: 0.046591
2025-11-22 21:47:19 - GraphTrainer - INFO - hit_rate@10: 0.048907
2025-11-22 21:47:19 - GraphTrainer - INFO - ndcg@10: 0.024932
2025-11-22 21:47:19 - GraphTrainer - INFO - map@10: 0.018074
2025-11-22 21:47:19 - GraphTrainer - INFO - mrr@10: 0.018943
2025-11-22 21:47:19 - GraphTrainer - INFO - precision@20: 0.003934
2025-11-22 21:47:19 - GraphTrainer - INFO - recall@20: 0.074173
2025-11-22 21:47:19 - GraphTrainer - INFO - hit_rate@20: 0.078118
2025-11-22 21:47:19 - GraphTrainer - INFO - ndcg@20: 0.031939
2025-11-22 21:47:19 - GraphTrainer - INFO - map@20: 0.019939
2025-11-22 21:47:19 - GraphTrainer - INFO - mrr@20: 0.020911
2025-11-22 21:47:19 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:47:19 - GraphTrainer - INFO - ============================================================
2025-11-22 21:47:19 - GraphTrainer - INFO - 开始第 58/1000 轮训练
2025-11-22 21:47:19 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3586, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3506, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3699, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3633, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3856, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3561, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3713, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3727, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3755, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4046, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3650, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3701, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3761, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3690, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3580, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3726, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3691, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3668, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3622, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3726, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3811, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3571, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3782, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3303, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3554, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3525, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3657, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3574, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3648, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3754, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3714, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3749, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3759, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3596, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3728, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3640, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3563, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3574, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3584, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3621, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3635, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3859, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3681, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3654, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3737, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3821, device='cuda:0', grad_fn=<AddBackward0>)
The 57 training average loss: 0.3635494118106776
2025-11-22 21:47:29 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:47:29 - GraphTrainer - INFO -   precision@5: 0.006110
2025-11-22 21:47:29 - GraphTrainer - INFO -   recall@5: 0.028901
2025-11-22 21:47:29 - GraphTrainer - INFO -   hit_rate@5: 0.030496
2025-11-22 21:47:29 - GraphTrainer - INFO -   ndcg@5: 0.018972
2025-11-22 21:47:29 - GraphTrainer - INFO -   map@5: 0.015467
2025-11-22 21:47:29 - GraphTrainer - INFO -   mrr@5: 0.016200
2025-11-22 21:47:29 - GraphTrainer - INFO -   precision@10: 0.004865
2025-11-22 21:47:29 - GraphTrainer - INFO -   recall@10: 0.046135
2025-11-22 21:47:29 - GraphTrainer - INFO -   hit_rate@10: 0.048547
2025-11-22 21:47:29 - GraphTrainer - INFO -   ndcg@10: 0.024612
2025-11-22 21:47:29 - GraphTrainer - INFO -   map@10: 0.017788
2025-11-22 21:47:29 - GraphTrainer - INFO -   mrr@10: 0.018624
2025-11-22 21:47:29 - GraphTrainer - INFO -   precision@20: 0.003919
2025-11-22 21:47:29 - GraphTrainer - INFO -   recall@20: 0.073782
2025-11-22 21:47:29 - GraphTrainer - INFO -   hit_rate@20: 0.077963
2025-11-22 21:47:29 - GraphTrainer - INFO -   ndcg@20: 0.031637
2025-11-22 21:47:29 - GraphTrainer - INFO -   map@20: 0.019656
2025-11-22 21:47:29 - GraphTrainer - INFO -   mrr@20: 0.020605
2025-11-22 21:47:29 - GraphTrainer - INFO - 第 58 轮训练完成
2025-11-22 21:47:29 - GraphTrainer - INFO - train_loss: 0.365296
2025-11-22 21:47:29 - GraphTrainer - INFO - precision@5: 0.006110
2025-11-22 21:47:29 - GraphTrainer - INFO - recall@5: 0.028901
2025-11-22 21:47:29 - GraphTrainer - INFO - hit_rate@5: 0.030496
2025-11-22 21:47:29 - GraphTrainer - INFO - ndcg@5: 0.018972
2025-11-22 21:47:29 - GraphTrainer - INFO - map@5: 0.015467
2025-11-22 21:47:29 - GraphTrainer - INFO - mrr@5: 0.016200
2025-11-22 21:47:29 - GraphTrainer - INFO - precision@10: 0.004865
2025-11-22 21:47:29 - GraphTrainer - INFO - recall@10: 0.046135
2025-11-22 21:47:29 - GraphTrainer - INFO - hit_rate@10: 0.048547
2025-11-22 21:47:29 - GraphTrainer - INFO - ndcg@10: 0.024612
2025-11-22 21:47:29 - GraphTrainer - INFO - map@10: 0.017788
2025-11-22 21:47:29 - GraphTrainer - INFO - mrr@10: 0.018624
2025-11-22 21:47:29 - GraphTrainer - INFO - precision@20: 0.003919
2025-11-22 21:47:29 - GraphTrainer - INFO - recall@20: 0.073782
2025-11-22 21:47:29 - GraphTrainer - INFO - hit_rate@20: 0.077963
2025-11-22 21:47:29 - GraphTrainer - INFO - ndcg@20: 0.031637
2025-11-22 21:47:29 - GraphTrainer - INFO - map@20: 0.019656
2025-11-22 21:47:29 - GraphTrainer - INFO - mrr@20: 0.020605
2025-11-22 21:47:29 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:47:29 - GraphTrainer - INFO - ============================================================
2025-11-22 21:47:29 - GraphTrainer - INFO - 开始第 59/1000 轮训练
2025-11-22 21:47:29 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3554, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3652, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3708, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3480, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3582, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3610, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3641, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4010, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3768, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3759, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3664, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3584, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3555, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3660, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3820, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3548, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3798, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3734, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3878, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3669, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3780, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3758, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3717, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3646, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3616, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4007, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3685, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3627, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3494, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3624, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3588, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3784, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3647, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3835, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3558, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3588, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3516, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3831, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3706, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3614, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3632, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3547, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3579, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3671, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3904, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3742, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3839, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3598, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
The 58 training average loss: 0.36529606375200996
2025-11-22 21:47:40 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:47:40 - GraphTrainer - INFO -   precision@5: 0.006449
2025-11-22 21:47:40 - GraphTrainer - INFO -   recall@5: 0.030727
2025-11-22 21:47:40 - GraphTrainer - INFO -   hit_rate@5: 0.032193
2025-11-22 21:47:40 - GraphTrainer - INFO -   ndcg@5: 0.019863
2025-11-22 21:47:40 - GraphTrainer - INFO -   map@5: 0.016066
2025-11-22 21:47:40 - GraphTrainer - INFO -   mrr@5: 0.016786
2025-11-22 21:47:40 - GraphTrainer - INFO -   precision@10: 0.005174
2025-11-22 21:47:40 - GraphTrainer - INFO -   recall@10: 0.049142
2025-11-22 21:47:40 - GraphTrainer - INFO -   hit_rate@10: 0.051581
2025-11-22 21:47:40 - GraphTrainer - INFO -   ndcg@10: 0.025835
2025-11-22 21:47:40 - GraphTrainer - INFO -   map@10: 0.018483
2025-11-22 21:47:40 - GraphTrainer - INFO -   mrr@10: 0.019323
2025-11-22 21:47:40 - GraphTrainer - INFO -   precision@20: 0.003980
2025-11-22 21:47:40 - GraphTrainer - INFO -   recall@20: 0.075267
2025-11-22 21:47:40 - GraphTrainer - INFO -   hit_rate@20: 0.079198
2025-11-22 21:47:40 - GraphTrainer - INFO -   ndcg@20: 0.032466
2025-11-22 21:47:40 - GraphTrainer - INFO -   map@20: 0.020249
2025-11-22 21:47:40 - GraphTrainer - INFO -   mrr@20: 0.021185
2025-11-22 21:47:40 - GraphTrainer - INFO - 第 59 轮训练完成
2025-11-22 21:47:40 - GraphTrainer - INFO - train_loss: 0.360755
2025-11-22 21:47:40 - GraphTrainer - INFO - precision@5: 0.006449
2025-11-22 21:47:40 - GraphTrainer - INFO - recall@5: 0.030727
2025-11-22 21:47:40 - GraphTrainer - INFO - hit_rate@5: 0.032193
2025-11-22 21:47:40 - GraphTrainer - INFO - ndcg@5: 0.019863
2025-11-22 21:47:40 - GraphTrainer - INFO - map@5: 0.016066
2025-11-22 21:47:40 - GraphTrainer - INFO - mrr@5: 0.016786
2025-11-22 21:47:40 - GraphTrainer - INFO - precision@10: 0.005174
2025-11-22 21:47:40 - GraphTrainer - INFO - recall@10: 0.049142
2025-11-22 21:47:40 - GraphTrainer - INFO - hit_rate@10: 0.051581
2025-11-22 21:47:40 - GraphTrainer - INFO - ndcg@10: 0.025835
2025-11-22 21:47:40 - GraphTrainer - INFO - map@10: 0.018483
2025-11-22 21:47:40 - GraphTrainer - INFO - mrr@10: 0.019323
2025-11-22 21:47:40 - GraphTrainer - INFO - precision@20: 0.003980
2025-11-22 21:47:40 - GraphTrainer - INFO - recall@20: 0.075267
2025-11-22 21:47:40 - GraphTrainer - INFO - hit_rate@20: 0.079198
2025-11-22 21:47:40 - GraphTrainer - INFO - ndcg@20: 0.032466
2025-11-22 21:47:40 - GraphTrainer - INFO - map@20: 0.020249
2025-11-22 21:47:40 - GraphTrainer - INFO - mrr@20: 0.021185
2025-11-22 21:47:40 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:47:40 - GraphTrainer - INFO - ============================================================
2025-11-22 21:47:40 - GraphTrainer - INFO - 开始第 60/1000 轮训练
2025-11-22 21:47:40 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3741, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3669, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3269, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3623, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3764, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3652, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3742, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3733, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3688, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3718, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3715, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3562, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3605, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3800, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3561, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3532, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3559, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3931, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3293, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3558, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3632, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3558, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3679, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3769, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3610, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3591, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3842, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3752, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3534, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3722, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3507, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3659, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3607, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3707, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3780, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3577, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3810, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3254, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3759, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3643, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3875, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3633, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
The 59 training average loss: 0.3607551547987708
2025-11-22 21:47:52 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:47:52 - GraphTrainer - INFO -   precision@5: 0.006449
2025-11-22 21:47:52 - GraphTrainer - INFO -   recall@5: 0.030643
2025-11-22 21:47:52 - GraphTrainer - INFO -   hit_rate@5: 0.032193
2025-11-22 21:47:52 - GraphTrainer - INFO -   ndcg@5: 0.019936
2025-11-22 21:47:52 - GraphTrainer - INFO -   map@5: 0.016187
2025-11-22 21:47:52 - GraphTrainer - INFO -   mrr@5: 0.016870
2025-11-22 21:47:52 - GraphTrainer - INFO -   precision@10: 0.005122
2025-11-22 21:47:52 - GraphTrainer - INFO -   recall@10: 0.048591
2025-11-22 21:47:52 - GraphTrainer - INFO -   hit_rate@10: 0.051067
2025-11-22 21:47:52 - GraphTrainer - INFO -   ndcg@10: 0.025742
2025-11-22 21:47:52 - GraphTrainer - INFO -   map@10: 0.018530
2025-11-22 21:47:52 - GraphTrainer - INFO -   mrr@10: 0.019327
2025-11-22 21:47:52 - GraphTrainer - INFO -   precision@20: 0.003914
2025-11-22 21:47:52 - GraphTrainer - INFO -   recall@20: 0.073918
2025-11-22 21:47:52 - GraphTrainer - INFO -   hit_rate@20: 0.077912
2025-11-22 21:47:52 - GraphTrainer - INFO -   ndcg@20: 0.032209
2025-11-22 21:47:52 - GraphTrainer - INFO -   map@20: 0.020272
2025-11-22 21:47:52 - GraphTrainer - INFO -   mrr@20: 0.021166
2025-11-22 21:47:52 - GraphTrainer - INFO - 第 60 轮训练完成
2025-11-22 21:47:52 - GraphTrainer - INFO - train_loss: 0.357820
2025-11-22 21:47:52 - GraphTrainer - INFO - precision@5: 0.006449
2025-11-22 21:47:52 - GraphTrainer - INFO - recall@5: 0.030643
2025-11-22 21:47:52 - GraphTrainer - INFO - hit_rate@5: 0.032193
2025-11-22 21:47:52 - GraphTrainer - INFO - ndcg@5: 0.019936
2025-11-22 21:47:52 - GraphTrainer - INFO - map@5: 0.016187
2025-11-22 21:47:52 - GraphTrainer - INFO - mrr@5: 0.016870
2025-11-22 21:47:52 - GraphTrainer - INFO - precision@10: 0.005122
2025-11-22 21:47:52 - GraphTrainer - INFO - recall@10: 0.048591
2025-11-22 21:47:52 - GraphTrainer - INFO - hit_rate@10: 0.051067
2025-11-22 21:47:52 - GraphTrainer - INFO - ndcg@10: 0.025742
2025-11-22 21:47:52 - GraphTrainer - INFO - map@10: 0.018530
2025-11-22 21:47:52 - GraphTrainer - INFO - mrr@10: 0.019327
2025-11-22 21:47:52 - GraphTrainer - INFO - precision@20: 0.003914
2025-11-22 21:47:52 - GraphTrainer - INFO - recall@20: 0.073918
2025-11-22 21:47:52 - GraphTrainer - INFO - hit_rate@20: 0.077912
2025-11-22 21:47:52 - GraphTrainer - INFO - ndcg@20: 0.032209
2025-11-22 21:47:52 - GraphTrainer - INFO - map@20: 0.020272
2025-11-22 21:47:52 - GraphTrainer - INFO - mrr@20: 0.021166
2025-11-22 21:47:52 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:47:52 - GraphTrainer - INFO - 检查点已保存: Epoch 60 -> ./checkpoints/checkpoint_epoch_60.pth
2025-11-22 21:47:52 - GraphTrainer - INFO - ============================================================
2025-11-22 21:47:52 - GraphTrainer - INFO - 开始第 61/1000 轮训练
2025-11-22 21:47:52 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3502, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3780, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3668, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3656, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3646, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3641, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3663, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3632, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3747, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3647, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3517, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3596, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3750, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3640, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3613, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3645, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3706, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3616, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3662, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3613, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3635, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3781, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3643, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3679, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3580, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3628, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3745, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3521, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3663, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3620, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3586, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3718, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3544, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3549, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3568, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3536, device='cuda:0', grad_fn=<AddBackward0>)
The 60 training average loss: 0.3578204322477867
2025-11-22 21:48:03 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:48:03 - GraphTrainer - INFO -   precision@5: 0.006346
2025-11-22 21:48:03 - GraphTrainer - INFO -   recall@5: 0.030193
2025-11-22 21:48:03 - GraphTrainer - INFO -   hit_rate@5: 0.031679
2025-11-22 21:48:03 - GraphTrainer - INFO -   ndcg@5: 0.019455
2025-11-22 21:48:03 - GraphTrainer - INFO -   map@5: 0.015698
2025-11-22 21:48:03 - GraphTrainer - INFO -   mrr@5: 0.016359
2025-11-22 21:48:03 - GraphTrainer - INFO -   precision@10: 0.005153
2025-11-22 21:48:03 - GraphTrainer - INFO -   recall@10: 0.048758
2025-11-22 21:48:03 - GraphTrainer - INFO -   hit_rate@10: 0.051324
2025-11-22 21:48:03 - GraphTrainer - INFO -   ndcg@10: 0.025480
2025-11-22 21:48:03 - GraphTrainer - INFO -   map@10: 0.018128
2025-11-22 21:48:03 - GraphTrainer - INFO -   mrr@10: 0.018927
2025-11-22 21:48:03 - GraphTrainer - INFO -   precision@20: 0.003962
2025-11-22 21:48:03 - GraphTrainer - INFO -   recall@20: 0.074954
2025-11-22 21:48:03 - GraphTrainer - INFO -   hit_rate@20: 0.078889
2025-11-22 21:48:03 - GraphTrainer - INFO -   ndcg@20: 0.032143
2025-11-22 21:48:03 - GraphTrainer - INFO -   map@20: 0.019917
2025-11-22 21:48:03 - GraphTrainer - INFO -   mrr@20: 0.020810
2025-11-22 21:48:03 - GraphTrainer - INFO - 第 61 轮训练完成
2025-11-22 21:48:03 - GraphTrainer - INFO - train_loss: 0.358459
2025-11-22 21:48:03 - GraphTrainer - INFO - precision@5: 0.006346
2025-11-22 21:48:03 - GraphTrainer - INFO - recall@5: 0.030193
2025-11-22 21:48:03 - GraphTrainer - INFO - hit_rate@5: 0.031679
2025-11-22 21:48:03 - GraphTrainer - INFO - ndcg@5: 0.019455
2025-11-22 21:48:03 - GraphTrainer - INFO - map@5: 0.015698
2025-11-22 21:48:03 - GraphTrainer - INFO - mrr@5: 0.016359
2025-11-22 21:48:03 - GraphTrainer - INFO - precision@10: 0.005153
2025-11-22 21:48:03 - GraphTrainer - INFO - recall@10: 0.048758
2025-11-22 21:48:03 - GraphTrainer - INFO - hit_rate@10: 0.051324
2025-11-22 21:48:03 - GraphTrainer - INFO - ndcg@10: 0.025480
2025-11-22 21:48:03 - GraphTrainer - INFO - map@10: 0.018128
2025-11-22 21:48:03 - GraphTrainer - INFO - mrr@10: 0.018927
2025-11-22 21:48:03 - GraphTrainer - INFO - precision@20: 0.003962
2025-11-22 21:48:03 - GraphTrainer - INFO - recall@20: 0.074954
2025-11-22 21:48:03 - GraphTrainer - INFO - hit_rate@20: 0.078889
2025-11-22 21:48:03 - GraphTrainer - INFO - ndcg@20: 0.032143
2025-11-22 21:48:03 - GraphTrainer - INFO - map@20: 0.019917
2025-11-22 21:48:03 - GraphTrainer - INFO - mrr@20: 0.020810
2025-11-22 21:48:03 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:48:03 - GraphTrainer - INFO - ============================================================
2025-11-22 21:48:03 - GraphTrainer - INFO - 开始第 62/1000 轮训练
2025-11-22 21:48:03 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3732, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3757, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3650, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3700, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3623, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3558, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3663, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3744, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3732, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3831, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3727, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3551, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3616, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3628, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3619, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3656, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3665, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3560, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3596, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3838, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3738, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3716, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3732, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3716, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3561, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3462, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3617, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3623, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3625, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3566, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3925, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)
The 61 training average loss: 0.3584590374395765
2025-11-22 21:48:14 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:48:14 - GraphTrainer - INFO -   precision@5: 0.006377
2025-11-22 21:48:14 - GraphTrainer - INFO -   recall@5: 0.030314
2025-11-22 21:48:14 - GraphTrainer - INFO -   hit_rate@5: 0.031833
2025-11-22 21:48:14 - GraphTrainer - INFO -   ndcg@5: 0.019745
2025-11-22 21:48:14 - GraphTrainer - INFO -   map@5: 0.016050
2025-11-22 21:48:14 - GraphTrainer - INFO -   mrr@5: 0.016740
2025-11-22 21:48:14 - GraphTrainer - INFO -   precision@10: 0.005050
2025-11-22 21:48:14 - GraphTrainer - INFO -   recall@10: 0.047907
2025-11-22 21:48:14 - GraphTrainer - INFO -   hit_rate@10: 0.050399
2025-11-22 21:48:14 - GraphTrainer - INFO -   ndcg@10: 0.025505
2025-11-22 21:48:14 - GraphTrainer - INFO -   map@10: 0.018411
2025-11-22 21:48:14 - GraphTrainer - INFO -   mrr@10: 0.019224
2025-11-22 21:48:14 - GraphTrainer - INFO -   precision@20: 0.003883
2025-11-22 21:48:14 - GraphTrainer - INFO -   recall@20: 0.073638
2025-11-22 21:48:14 - GraphTrainer - INFO -   hit_rate@20: 0.077398
2025-11-22 21:48:14 - GraphTrainer - INFO -   ndcg@20: 0.032045
2025-11-22 21:48:14 - GraphTrainer - INFO -   map@20: 0.020169
2025-11-22 21:48:14 - GraphTrainer - INFO -   mrr@20: 0.021066
2025-11-22 21:48:14 - GraphTrainer - INFO - 第 62 轮训练完成
2025-11-22 21:48:14 - GraphTrainer - INFO - train_loss: 0.358240
2025-11-22 21:48:14 - GraphTrainer - INFO - precision@5: 0.006377
2025-11-22 21:48:14 - GraphTrainer - INFO - recall@5: 0.030314
2025-11-22 21:48:14 - GraphTrainer - INFO - hit_rate@5: 0.031833
2025-11-22 21:48:14 - GraphTrainer - INFO - ndcg@5: 0.019745
2025-11-22 21:48:14 - GraphTrainer - INFO - map@5: 0.016050
2025-11-22 21:48:14 - GraphTrainer - INFO - mrr@5: 0.016740
2025-11-22 21:48:14 - GraphTrainer - INFO - precision@10: 0.005050
2025-11-22 21:48:14 - GraphTrainer - INFO - recall@10: 0.047907
2025-11-22 21:48:14 - GraphTrainer - INFO - hit_rate@10: 0.050399
2025-11-22 21:48:14 - GraphTrainer - INFO - ndcg@10: 0.025505
2025-11-22 21:48:14 - GraphTrainer - INFO - map@10: 0.018411
2025-11-22 21:48:14 - GraphTrainer - INFO - mrr@10: 0.019224
2025-11-22 21:48:14 - GraphTrainer - INFO - precision@20: 0.003883
2025-11-22 21:48:14 - GraphTrainer - INFO - recall@20: 0.073638
2025-11-22 21:48:14 - GraphTrainer - INFO - hit_rate@20: 0.077398
2025-11-22 21:48:14 - GraphTrainer - INFO - ndcg@20: 0.032045
2025-11-22 21:48:14 - GraphTrainer - INFO - map@20: 0.020169
2025-11-22 21:48:14 - GraphTrainer - INFO - mrr@20: 0.021066
2025-11-22 21:48:14 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:48:14 - GraphTrainer - INFO - ============================================================
2025-11-22 21:48:14 - GraphTrainer - INFO - 开始第 63/1000 轮训练
2025-11-22 21:48:14 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3554, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3666, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3757, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3814, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3659, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3610, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3548, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3499, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3788, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3691, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3643, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3539, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3688, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3775, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3617, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3761, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3598, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3744, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3562, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3630, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3620, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3782, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3839, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3607, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3652, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3539, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3614, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3580, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3612, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3302, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3621, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3649, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3625, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3850, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3604, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3723, device='cuda:0', grad_fn=<AddBackward0>)
The 62 training average loss: 0.3582397550344467
2025-11-22 21:48:26 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:48:26 - GraphTrainer - INFO -   precision@5: 0.006377
2025-11-22 21:48:26 - GraphTrainer - INFO -   recall@5: 0.030425
2025-11-22 21:48:26 - GraphTrainer - INFO -   hit_rate@5: 0.031833
2025-11-22 21:48:26 - GraphTrainer - INFO -   ndcg@5: 0.019462
2025-11-22 21:48:26 - GraphTrainer - INFO -   map@5: 0.015654
2025-11-22 21:48:26 - GraphTrainer - INFO -   mrr@5: 0.016313
2025-11-22 21:48:26 - GraphTrainer - INFO -   precision@10: 0.005060
2025-11-22 21:48:26 - GraphTrainer - INFO -   recall@10: 0.048152
2025-11-22 21:48:26 - GraphTrainer - INFO -   hit_rate@10: 0.050501
2025-11-22 21:48:26 - GraphTrainer - INFO -   ndcg@10: 0.025185
2025-11-22 21:48:26 - GraphTrainer - INFO -   map@10: 0.017956
2025-11-22 21:48:26 - GraphTrainer - INFO -   mrr@10: 0.018740
2025-11-22 21:48:26 - GraphTrainer - INFO -   precision@20: 0.003993
2025-11-22 21:48:26 - GraphTrainer - INFO -   recall@20: 0.075588
2025-11-22 21:48:26 - GraphTrainer - INFO -   hit_rate@20: 0.079455
2025-11-22 21:48:26 - GraphTrainer - INFO -   ndcg@20: 0.032186
2025-11-22 21:48:26 - GraphTrainer - INFO -   map@20: 0.019841
2025-11-22 21:48:26 - GraphTrainer - INFO -   mrr@20: 0.020727
2025-11-22 21:48:26 - GraphTrainer - INFO - 第 63 轮训练完成
2025-11-22 21:48:26 - GraphTrainer - INFO - train_loss: 0.357102
2025-11-22 21:48:26 - GraphTrainer - INFO - precision@5: 0.006377
2025-11-22 21:48:26 - GraphTrainer - INFO - recall@5: 0.030425
2025-11-22 21:48:26 - GraphTrainer - INFO - hit_rate@5: 0.031833
2025-11-22 21:48:26 - GraphTrainer - INFO - ndcg@5: 0.019462
2025-11-22 21:48:26 - GraphTrainer - INFO - map@5: 0.015654
2025-11-22 21:48:26 - GraphTrainer - INFO - mrr@5: 0.016313
2025-11-22 21:48:26 - GraphTrainer - INFO - precision@10: 0.005060
2025-11-22 21:48:26 - GraphTrainer - INFO - recall@10: 0.048152
2025-11-22 21:48:26 - GraphTrainer - INFO - hit_rate@10: 0.050501
2025-11-22 21:48:26 - GraphTrainer - INFO - ndcg@10: 0.025185
2025-11-22 21:48:26 - GraphTrainer - INFO - map@10: 0.017956
2025-11-22 21:48:26 - GraphTrainer - INFO - mrr@10: 0.018740
2025-11-22 21:48:26 - GraphTrainer - INFO - precision@20: 0.003993
2025-11-22 21:48:26 - GraphTrainer - INFO - recall@20: 0.075588
2025-11-22 21:48:26 - GraphTrainer - INFO - hit_rate@20: 0.079455
2025-11-22 21:48:26 - GraphTrainer - INFO - ndcg@20: 0.032186
2025-11-22 21:48:26 - GraphTrainer - INFO - map@20: 0.019841
2025-11-22 21:48:26 - GraphTrainer - INFO - mrr@20: 0.020727
2025-11-22 21:48:26 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:48:26 - GraphTrainer - INFO - ============================================================
2025-11-22 21:48:26 - GraphTrainer - INFO - 开始第 64/1000 轮训练
2025-11-22 21:48:26 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3182, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3662, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3621, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3562, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3702, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3816, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3722, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3569, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3659, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3591, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3704, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3657, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3682, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3716, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3464, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3512, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3621, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3649, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3547, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3554, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3580, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3674, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3560, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3612, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3570, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3718, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3637, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3662, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3662, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3468, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3753, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3856, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
The 63 training average loss: 0.35710222608056563
2025-11-22 21:48:37 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:48:37 - GraphTrainer - INFO -   precision@5: 0.006521
2025-11-22 21:48:37 - GraphTrainer - INFO -   recall@5: 0.030979
2025-11-22 21:48:37 - GraphTrainer - INFO -   hit_rate@5: 0.032502
2025-11-22 21:48:37 - GraphTrainer - INFO -   ndcg@5: 0.020175
2025-11-22 21:48:37 - GraphTrainer - INFO -   map@5: 0.016402
2025-11-22 21:48:37 - GraphTrainer - INFO -   mrr@5: 0.017097
2025-11-22 21:48:37 - GraphTrainer - INFO -   precision@10: 0.005066
2025-11-22 21:48:37 - GraphTrainer - INFO -   recall@10: 0.048086
2025-11-22 21:48:37 - GraphTrainer - INFO -   hit_rate@10: 0.050553
2025-11-22 21:48:37 - GraphTrainer - INFO -   ndcg@10: 0.025743
2025-11-22 21:48:37 - GraphTrainer - INFO -   map@10: 0.018667
2025-11-22 21:48:37 - GraphTrainer - INFO -   mrr@10: 0.019483
2025-11-22 21:48:37 - GraphTrainer - INFO -   precision@20: 0.003924
2025-11-22 21:48:37 - GraphTrainer - INFO -   recall@20: 0.074232
2025-11-22 21:48:37 - GraphTrainer - INFO -   hit_rate@20: 0.078066
2025-11-22 21:48:37 - GraphTrainer - INFO -   ndcg@20: 0.032381
2025-11-22 21:48:37 - GraphTrainer - INFO -   map@20: 0.020439
2025-11-22 21:48:37 - GraphTrainer - INFO -   mrr@20: 0.021349
2025-11-22 21:48:37 - GraphTrainer - INFO - 第 64 轮训练完成
2025-11-22 21:48:37 - GraphTrainer - INFO - train_loss: 0.353934
2025-11-22 21:48:37 - GraphTrainer - INFO - precision@5: 0.006521
2025-11-22 21:48:37 - GraphTrainer - INFO - recall@5: 0.030979
2025-11-22 21:48:37 - GraphTrainer - INFO - hit_rate@5: 0.032502
2025-11-22 21:48:37 - GraphTrainer - INFO - ndcg@5: 0.020175
2025-11-22 21:48:37 - GraphTrainer - INFO - map@5: 0.016402
2025-11-22 21:48:37 - GraphTrainer - INFO - mrr@5: 0.017097
2025-11-22 21:48:37 - GraphTrainer - INFO - precision@10: 0.005066
2025-11-22 21:48:37 - GraphTrainer - INFO - recall@10: 0.048086
2025-11-22 21:48:37 - GraphTrainer - INFO - hit_rate@10: 0.050553
2025-11-22 21:48:37 - GraphTrainer - INFO - ndcg@10: 0.025743
2025-11-22 21:48:37 - GraphTrainer - INFO - map@10: 0.018667
2025-11-22 21:48:37 - GraphTrainer - INFO - mrr@10: 0.019483
2025-11-22 21:48:37 - GraphTrainer - INFO - precision@20: 0.003924
2025-11-22 21:48:37 - GraphTrainer - INFO - recall@20: 0.074232
2025-11-22 21:48:37 - GraphTrainer - INFO - hit_rate@20: 0.078066
2025-11-22 21:48:37 - GraphTrainer - INFO - ndcg@20: 0.032381
2025-11-22 21:48:37 - GraphTrainer - INFO - map@20: 0.020439
2025-11-22 21:48:37 - GraphTrainer - INFO - mrr@20: 0.021349
2025-11-22 21:48:37 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:48:37 - GraphTrainer - INFO - ============================================================
2025-11-22 21:48:37 - GraphTrainer - INFO - 开始第 65/1000 轮训练
2025-11-22 21:48:37 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3588, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3599, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3605, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3595, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3739, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3604, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3823, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3333, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3612, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3729, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3584, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3549, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3701, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3713, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3421, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3462, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3757, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3559, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3601, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3625, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3690, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3673, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3792, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3680, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3521, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3373, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3595, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3804, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3545, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3549, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3582, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3556, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3559, device='cuda:0', grad_fn=<AddBackward0>)
The 64 training average loss: 0.3539335907533251
2025-11-22 21:48:48 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:48:48 - GraphTrainer - INFO -   precision@5: 0.006233
2025-11-22 21:48:48 - GraphTrainer - INFO -   recall@5: 0.029766
2025-11-22 21:48:48 - GraphTrainer - INFO -   hit_rate@5: 0.031113
2025-11-22 21:48:48 - GraphTrainer - INFO -   ndcg@5: 0.019656
2025-11-22 21:48:48 - GraphTrainer - INFO -   map@5: 0.016126
2025-11-22 21:48:48 - GraphTrainer - INFO -   mrr@5: 0.016769
2025-11-22 21:48:48 - GraphTrainer - INFO -   precision@10: 0.004994
2025-11-22 21:48:48 - GraphTrainer - INFO -   recall@10: 0.047414
2025-11-22 21:48:48 - GraphTrainer - INFO -   hit_rate@10: 0.049833
2025-11-22 21:48:48 - GraphTrainer - INFO -   ndcg@10: 0.025388
2025-11-22 21:48:48 - GraphTrainer - INFO -   map@10: 0.018442
2025-11-22 21:48:48 - GraphTrainer - INFO -   mrr@10: 0.019223
2025-11-22 21:48:48 - GraphTrainer - INFO -   precision@20: 0.003854
2025-11-22 21:48:48 - GraphTrainer - INFO -   recall@20: 0.073096
2025-11-22 21:48:48 - GraphTrainer - INFO -   hit_rate@20: 0.076678
2025-11-22 21:48:48 - GraphTrainer - INFO -   ndcg@20: 0.031947
2025-11-22 21:48:48 - GraphTrainer - INFO -   map@20: 0.020223
2025-11-22 21:48:48 - GraphTrainer - INFO -   mrr@20: 0.021075
2025-11-22 21:48:48 - GraphTrainer - INFO - 第 65 轮训练完成
2025-11-22 21:48:48 - GraphTrainer - INFO - train_loss: 0.358967
2025-11-22 21:48:48 - GraphTrainer - INFO - precision@5: 0.006233
2025-11-22 21:48:48 - GraphTrainer - INFO - recall@5: 0.029766
2025-11-22 21:48:48 - GraphTrainer - INFO - hit_rate@5: 0.031113
2025-11-22 21:48:48 - GraphTrainer - INFO - ndcg@5: 0.019656
2025-11-22 21:48:48 - GraphTrainer - INFO - map@5: 0.016126
2025-11-22 21:48:48 - GraphTrainer - INFO - mrr@5: 0.016769
2025-11-22 21:48:48 - GraphTrainer - INFO - precision@10: 0.004994
2025-11-22 21:48:48 - GraphTrainer - INFO - recall@10: 0.047414
2025-11-22 21:48:48 - GraphTrainer - INFO - hit_rate@10: 0.049833
2025-11-22 21:48:48 - GraphTrainer - INFO - ndcg@10: 0.025388
2025-11-22 21:48:48 - GraphTrainer - INFO - map@10: 0.018442
2025-11-22 21:48:48 - GraphTrainer - INFO - mrr@10: 0.019223
2025-11-22 21:48:48 - GraphTrainer - INFO - precision@20: 0.003854
2025-11-22 21:48:48 - GraphTrainer - INFO - recall@20: 0.073096
2025-11-22 21:48:48 - GraphTrainer - INFO - hit_rate@20: 0.076678
2025-11-22 21:48:48 - GraphTrainer - INFO - ndcg@20: 0.031947
2025-11-22 21:48:48 - GraphTrainer - INFO - map@20: 0.020223
2025-11-22 21:48:48 - GraphTrainer - INFO - mrr@20: 0.021075
2025-11-22 21:48:48 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:48:48 - GraphTrainer - INFO - ============================================================
2025-11-22 21:48:48 - GraphTrainer - INFO - 开始第 66/1000 轮训练
2025-11-22 21:48:48 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3708, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3548, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3794, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3697, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3662, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3677, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3652, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3737, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3545, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3626, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3473, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3696, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3736, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3237, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3547, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3706, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3744, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3646, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3756, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3682, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3732, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3697, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3639, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3697, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3607, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3687, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3648, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3797, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3790, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3539, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3758, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3599, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3742, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3484, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3499, device='cuda:0', grad_fn=<AddBackward0>)
The 65 training average loss: 0.3589671177083048
2025-11-22 21:48:59 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:48:59 - GraphTrainer - INFO -   precision@5: 0.006418
2025-11-22 21:48:59 - GraphTrainer - INFO -   recall@5: 0.030580
2025-11-22 21:48:59 - GraphTrainer - INFO -   hit_rate@5: 0.032039
2025-11-22 21:48:59 - GraphTrainer - INFO -   ndcg@5: 0.020115
2025-11-22 21:48:59 - GraphTrainer - INFO -   map@5: 0.016450
2025-11-22 21:48:59 - GraphTrainer - INFO -   mrr@5: 0.017156
2025-11-22 21:48:59 - GraphTrainer - INFO -   precision@10: 0.005102
2025-11-22 21:48:59 - GraphTrainer - INFO -   recall@10: 0.048406
2025-11-22 21:48:59 - GraphTrainer - INFO -   hit_rate@10: 0.050861
2025-11-22 21:48:59 - GraphTrainer - INFO -   ndcg@10: 0.025911
2025-11-22 21:48:59 - GraphTrainer - INFO -   map@10: 0.018798
2025-11-22 21:48:59 - GraphTrainer - INFO -   mrr@10: 0.019633
2025-11-22 21:48:59 - GraphTrainer - INFO -   precision@20: 0.004027
2025-11-22 21:48:59 - GraphTrainer - INFO -   recall@20: 0.076252
2025-11-22 21:48:59 - GraphTrainer - INFO -   hit_rate@20: 0.080021
2025-11-22 21:48:59 - GraphTrainer - INFO -   ndcg@20: 0.032941
2025-11-22 21:48:59 - GraphTrainer - INFO -   map@20: 0.020661
2025-11-22 21:48:59 - GraphTrainer - INFO -   mrr@20: 0.021580
2025-11-22 21:48:59 - GraphTrainer - INFO - 第 66 轮训练完成
2025-11-22 21:48:59 - GraphTrainer - INFO - train_loss: 0.356345
2025-11-22 21:48:59 - GraphTrainer - INFO - precision@5: 0.006418
2025-11-22 21:48:59 - GraphTrainer - INFO - recall@5: 0.030580
2025-11-22 21:48:59 - GraphTrainer - INFO - hit_rate@5: 0.032039
2025-11-22 21:48:59 - GraphTrainer - INFO - ndcg@5: 0.020115
2025-11-22 21:48:59 - GraphTrainer - INFO - map@5: 0.016450
2025-11-22 21:48:59 - GraphTrainer - INFO - mrr@5: 0.017156
2025-11-22 21:48:59 - GraphTrainer - INFO - precision@10: 0.005102
2025-11-22 21:48:59 - GraphTrainer - INFO - recall@10: 0.048406
2025-11-22 21:48:59 - GraphTrainer - INFO - hit_rate@10: 0.050861
2025-11-22 21:48:59 - GraphTrainer - INFO - ndcg@10: 0.025911
2025-11-22 21:48:59 - GraphTrainer - INFO - map@10: 0.018798
2025-11-22 21:48:59 - GraphTrainer - INFO - mrr@10: 0.019633
2025-11-22 21:48:59 - GraphTrainer - INFO - precision@20: 0.004027
2025-11-22 21:48:59 - GraphTrainer - INFO - recall@20: 0.076252
2025-11-22 21:48:59 - GraphTrainer - INFO - hit_rate@20: 0.080021
2025-11-22 21:48:59 - GraphTrainer - INFO - ndcg@20: 0.032941
2025-11-22 21:48:59 - GraphTrainer - INFO - map@20: 0.020661
2025-11-22 21:48:59 - GraphTrainer - INFO - mrr@20: 0.021580
2025-11-22 21:48:59 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:48:59 - GraphTrainer - INFO - ============================================================
2025-11-22 21:48:59 - GraphTrainer - INFO - 开始第 67/1000 轮训练
2025-11-22 21:48:59 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3554, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3607, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3735, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3633, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3551, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3435, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3551, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3532, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3517, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3663, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3490, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3615, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3661, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3643, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3612, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3561, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3656, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3555, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3656, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3457, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3502, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3895, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3545, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3597, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3638, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3467, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3648, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3712, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3670, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3654, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3864, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3687, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3627, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3701, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3653, device='cuda:0', grad_fn=<AddBackward0>)
The 66 training average loss: 0.3563446464209721
2025-11-22 21:49:10 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:49:10 - GraphTrainer - INFO -   precision@5: 0.006500
2025-11-22 21:49:10 - GraphTrainer - INFO -   recall@5: 0.030685
2025-11-22 21:49:10 - GraphTrainer - INFO -   hit_rate@5: 0.032399
2025-11-22 21:49:10 - GraphTrainer - INFO -   ndcg@5: 0.020104
2025-11-22 21:49:10 - GraphTrainer - INFO -   map@5: 0.016366
2025-11-22 21:49:10 - GraphTrainer - INFO -   mrr@5: 0.017092
2025-11-22 21:49:10 - GraphTrainer - INFO -   precision@10: 0.005040
2025-11-22 21:49:10 - GraphTrainer - INFO -   recall@10: 0.047908
2025-11-22 21:49:10 - GraphTrainer - INFO -   hit_rate@10: 0.050296
2025-11-22 21:49:10 - GraphTrainer - INFO -   ndcg@10: 0.025661
2025-11-22 21:49:10 - GraphTrainer - INFO -   map@10: 0.018615
2025-11-22 21:49:10 - GraphTrainer - INFO -   mrr@10: 0.019431
2025-11-22 21:49:10 - GraphTrainer - INFO -   precision@20: 0.003957
2025-11-22 21:49:10 - GraphTrainer - INFO -   recall@20: 0.074961
2025-11-22 21:49:10 - GraphTrainer - INFO -   hit_rate@20: 0.078786
2025-11-22 21:49:10 - GraphTrainer - INFO -   ndcg@20: 0.032545
2025-11-22 21:49:10 - GraphTrainer - INFO -   map@20: 0.020464
2025-11-22 21:49:10 - GraphTrainer - INFO -   mrr@20: 0.021373
2025-11-22 21:49:10 - GraphTrainer - INFO - 第 67 轮训练完成
2025-11-22 21:49:10 - GraphTrainer - INFO - train_loss: 0.356320
2025-11-22 21:49:10 - GraphTrainer - INFO - precision@5: 0.006500
2025-11-22 21:49:10 - GraphTrainer - INFO - recall@5: 0.030685
2025-11-22 21:49:10 - GraphTrainer - INFO - hit_rate@5: 0.032399
2025-11-22 21:49:10 - GraphTrainer - INFO - ndcg@5: 0.020104
2025-11-22 21:49:10 - GraphTrainer - INFO - map@5: 0.016366
2025-11-22 21:49:10 - GraphTrainer - INFO - mrr@5: 0.017092
2025-11-22 21:49:10 - GraphTrainer - INFO - precision@10: 0.005040
2025-11-22 21:49:10 - GraphTrainer - INFO - recall@10: 0.047908
2025-11-22 21:49:10 - GraphTrainer - INFO - hit_rate@10: 0.050296
2025-11-22 21:49:10 - GraphTrainer - INFO - ndcg@10: 0.025661
2025-11-22 21:49:10 - GraphTrainer - INFO - map@10: 0.018615
2025-11-22 21:49:10 - GraphTrainer - INFO - mrr@10: 0.019431
2025-11-22 21:49:10 - GraphTrainer - INFO - precision@20: 0.003957
2025-11-22 21:49:10 - GraphTrainer - INFO - recall@20: 0.074961
2025-11-22 21:49:10 - GraphTrainer - INFO - hit_rate@20: 0.078786
2025-11-22 21:49:10 - GraphTrainer - INFO - ndcg@20: 0.032545
2025-11-22 21:49:10 - GraphTrainer - INFO - map@20: 0.020464
2025-11-22 21:49:10 - GraphTrainer - INFO - mrr@20: 0.021373
2025-11-22 21:49:10 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:49:10 - GraphTrainer - INFO - ============================================================
2025-11-22 21:49:10 - GraphTrainer - INFO - 开始第 68/1000 轮训练
2025-11-22 21:49:10 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3766, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3685, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3577, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3739, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3715, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3509, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3697, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3689, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3614, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3570, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3787, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3551, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3780, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3557, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3533, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3624, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3479, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3490, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3712, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3632, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3961, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3651, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3584, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3556, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3556, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3537, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3654, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3572, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3710, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3558, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3549, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3539, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3653, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>)
The 67 training average loss: 0.35632018847712155
2025-11-22 21:49:21 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:49:21 - GraphTrainer - INFO -   precision@5: 0.006223
2025-11-22 21:49:21 - GraphTrainer - INFO -   recall@5: 0.029536
2025-11-22 21:49:21 - GraphTrainer - INFO -   hit_rate@5: 0.031062
2025-11-22 21:49:21 - GraphTrainer - INFO -   ndcg@5: 0.019817
2025-11-22 21:49:21 - GraphTrainer - INFO -   map@5: 0.016375
2025-11-22 21:49:21 - GraphTrainer - INFO -   mrr@5: 0.017153
2025-11-22 21:49:21 - GraphTrainer - INFO -   precision@10: 0.005019
2025-11-22 21:49:21 - GraphTrainer - INFO -   recall@10: 0.047331
2025-11-22 21:49:21 - GraphTrainer - INFO -   hit_rate@10: 0.050039
2025-11-22 21:49:21 - GraphTrainer - INFO -   ndcg@10: 0.025648
2025-11-22 21:49:21 - GraphTrainer - INFO -   map@10: 0.018752
2025-11-22 21:49:21 - GraphTrainer - INFO -   mrr@10: 0.019682
2025-11-22 21:49:21 - GraphTrainer - INFO -   precision@20: 0.003957
2025-11-22 21:49:21 - GraphTrainer - INFO -   recall@20: 0.074982
2025-11-22 21:49:21 - GraphTrainer - INFO -   hit_rate@20: 0.078786
2025-11-22 21:49:21 - GraphTrainer - INFO -   ndcg@20: 0.032640
2025-11-22 21:49:21 - GraphTrainer - INFO -   map@20: 0.020623
2025-11-22 21:49:21 - GraphTrainer - INFO -   mrr@20: 0.021621
2025-11-22 21:49:21 - GraphTrainer - INFO - 第 68 轮训练完成
2025-11-22 21:49:21 - GraphTrainer - INFO - train_loss: 0.353335
2025-11-22 21:49:21 - GraphTrainer - INFO - precision@5: 0.006223
2025-11-22 21:49:21 - GraphTrainer - INFO - recall@5: 0.029536
2025-11-22 21:49:21 - GraphTrainer - INFO - hit_rate@5: 0.031062
2025-11-22 21:49:21 - GraphTrainer - INFO - ndcg@5: 0.019817
2025-11-22 21:49:21 - GraphTrainer - INFO - map@5: 0.016375
2025-11-22 21:49:21 - GraphTrainer - INFO - mrr@5: 0.017153
2025-11-22 21:49:21 - GraphTrainer - INFO - precision@10: 0.005019
2025-11-22 21:49:21 - GraphTrainer - INFO - recall@10: 0.047331
2025-11-22 21:49:21 - GraphTrainer - INFO - hit_rate@10: 0.050039
2025-11-22 21:49:21 - GraphTrainer - INFO - ndcg@10: 0.025648
2025-11-22 21:49:21 - GraphTrainer - INFO - map@10: 0.018752
2025-11-22 21:49:21 - GraphTrainer - INFO - mrr@10: 0.019682
2025-11-22 21:49:21 - GraphTrainer - INFO - precision@20: 0.003957
2025-11-22 21:49:21 - GraphTrainer - INFO - recall@20: 0.074982
2025-11-22 21:49:21 - GraphTrainer - INFO - hit_rate@20: 0.078786
2025-11-22 21:49:21 - GraphTrainer - INFO - ndcg@20: 0.032640
2025-11-22 21:49:21 - GraphTrainer - INFO - map@20: 0.020623
2025-11-22 21:49:21 - GraphTrainer - INFO - mrr@20: 0.021621
2025-11-22 21:49:21 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:49:21 - GraphTrainer - INFO - ============================================================
2025-11-22 21:49:21 - GraphTrainer - INFO - 开始第 69/1000 轮训练
2025-11-22 21:49:21 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3684, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3622, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3918, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3637, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3409, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3293, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3655, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3718, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3297, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3506, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3569, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3262, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3566, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3571, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3543, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3550, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3539, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3745, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3637, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3709, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3560, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3754, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3649, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3434, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3659, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3833, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
The 68 training average loss: 0.353335354862542
2025-11-22 21:49:32 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:49:32 - GraphTrainer - INFO -   precision@5: 0.006377
2025-11-22 21:49:32 - GraphTrainer - INFO -   recall@5: 0.030410
2025-11-22 21:49:32 - GraphTrainer - INFO -   hit_rate@5: 0.031833
2025-11-22 21:49:32 - GraphTrainer - INFO -   ndcg@5: 0.019921
2025-11-22 21:49:32 - GraphTrainer - INFO -   map@5: 0.016255
2025-11-22 21:49:32 - GraphTrainer - INFO -   mrr@5: 0.016931
2025-11-22 21:49:32 - GraphTrainer - INFO -   precision@10: 0.005030
2025-11-22 21:49:32 - GraphTrainer - INFO -   recall@10: 0.047801
2025-11-22 21:49:32 - GraphTrainer - INFO -   hit_rate@10: 0.050141
2025-11-22 21:49:32 - GraphTrainer - INFO -   ndcg@10: 0.025570
2025-11-22 21:49:32 - GraphTrainer - INFO -   map@10: 0.018545
2025-11-22 21:49:32 - GraphTrainer - INFO -   mrr@10: 0.019337
2025-11-22 21:49:32 - GraphTrainer - INFO -   precision@20: 0.003983
2025-11-22 21:49:32 - GraphTrainer - INFO -   recall@20: 0.075352
2025-11-22 21:49:32 - GraphTrainer - INFO -   hit_rate@20: 0.079301
2025-11-22 21:49:32 - GraphTrainer - INFO -   ndcg@20: 0.032566
2025-11-22 21:49:32 - GraphTrainer - INFO -   map@20: 0.020409
2025-11-22 21:49:32 - GraphTrainer - INFO -   mrr@20: 0.021311
2025-11-22 21:49:32 - GraphTrainer - INFO - 第 69 轮训练完成
2025-11-22 21:49:32 - GraphTrainer - INFO - train_loss: 0.356676
2025-11-22 21:49:32 - GraphTrainer - INFO - precision@5: 0.006377
2025-11-22 21:49:32 - GraphTrainer - INFO - recall@5: 0.030410
2025-11-22 21:49:32 - GraphTrainer - INFO - hit_rate@5: 0.031833
2025-11-22 21:49:32 - GraphTrainer - INFO - ndcg@5: 0.019921
2025-11-22 21:49:32 - GraphTrainer - INFO - map@5: 0.016255
2025-11-22 21:49:32 - GraphTrainer - INFO - mrr@5: 0.016931
2025-11-22 21:49:32 - GraphTrainer - INFO - precision@10: 0.005030
2025-11-22 21:49:32 - GraphTrainer - INFO - recall@10: 0.047801
2025-11-22 21:49:32 - GraphTrainer - INFO - hit_rate@10: 0.050141
2025-11-22 21:49:32 - GraphTrainer - INFO - ndcg@10: 0.025570
2025-11-22 21:49:32 - GraphTrainer - INFO - map@10: 0.018545
2025-11-22 21:49:32 - GraphTrainer - INFO - mrr@10: 0.019337
2025-11-22 21:49:32 - GraphTrainer - INFO - precision@20: 0.003983
2025-11-22 21:49:32 - GraphTrainer - INFO - recall@20: 0.075352
2025-11-22 21:49:32 - GraphTrainer - INFO - hit_rate@20: 0.079301
2025-11-22 21:49:32 - GraphTrainer - INFO - ndcg@20: 0.032566
2025-11-22 21:49:32 - GraphTrainer - INFO - map@20: 0.020409
2025-11-22 21:49:32 - GraphTrainer - INFO - mrr@20: 0.021311
2025-11-22 21:49:32 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:49:32 - GraphTrainer - INFO - ============================================================
2025-11-22 21:49:32 - GraphTrainer - INFO - 开始第 70/1000 轮训练
2025-11-22 21:49:32 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3604, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3700, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3635, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3599, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3631, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3704, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3421, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3677, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3752, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3584, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3722, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3947, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3659, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3763, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3782, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3571, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3894, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3864, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3634, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3174, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3639, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3559, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3462, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3900, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3596, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3479, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3379, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3633, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3556, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3842, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3615, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3534, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)
The 69 training average loss: 0.35667605852258616
2025-11-22 21:49:43 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:49:43 - GraphTrainer - INFO -   precision@5: 0.006202
2025-11-22 21:49:43 - GraphTrainer - INFO -   recall@5: 0.029590
2025-11-22 21:49:43 - GraphTrainer - INFO -   hit_rate@5: 0.030959
2025-11-22 21:49:43 - GraphTrainer - INFO -   ndcg@5: 0.019175
2025-11-22 21:49:43 - GraphTrainer - INFO -   map@5: 0.015533
2025-11-22 21:49:43 - GraphTrainer - INFO -   mrr@5: 0.016181
2025-11-22 21:49:43 - GraphTrainer - INFO -   precision@10: 0.004978
2025-11-22 21:49:43 - GraphTrainer - INFO -   recall@10: 0.047466
2025-11-22 21:49:43 - GraphTrainer - INFO -   hit_rate@10: 0.049679
2025-11-22 21:49:43 - GraphTrainer - INFO -   ndcg@10: 0.024988
2025-11-22 21:49:43 - GraphTrainer - INFO -   map@10: 0.017902
2025-11-22 21:49:43 - GraphTrainer - INFO -   mrr@10: 0.018666
2025-11-22 21:49:43 - GraphTrainer - INFO -   precision@20: 0.003998
2025-11-22 21:49:43 - GraphTrainer - INFO -   recall@20: 0.075606
2025-11-22 21:49:43 - GraphTrainer - INFO -   hit_rate@20: 0.079558
2025-11-22 21:49:43 - GraphTrainer - INFO -   ndcg@20: 0.032165
2025-11-22 21:49:43 - GraphTrainer - INFO -   map@20: 0.019827
2025-11-22 21:49:43 - GraphTrainer - INFO -   mrr@20: 0.020704
2025-11-22 21:49:43 - GraphTrainer - INFO - 第 70 轮训练完成
2025-11-22 21:49:43 - GraphTrainer - INFO - train_loss: 0.356264
2025-11-22 21:49:43 - GraphTrainer - INFO - precision@5: 0.006202
2025-11-22 21:49:43 - GraphTrainer - INFO - recall@5: 0.029590
2025-11-22 21:49:43 - GraphTrainer - INFO - hit_rate@5: 0.030959
2025-11-22 21:49:43 - GraphTrainer - INFO - ndcg@5: 0.019175
2025-11-22 21:49:43 - GraphTrainer - INFO - map@5: 0.015533
2025-11-22 21:49:43 - GraphTrainer - INFO - mrr@5: 0.016181
2025-11-22 21:49:43 - GraphTrainer - INFO - precision@10: 0.004978
2025-11-22 21:49:43 - GraphTrainer - INFO - recall@10: 0.047466
2025-11-22 21:49:43 - GraphTrainer - INFO - hit_rate@10: 0.049679
2025-11-22 21:49:43 - GraphTrainer - INFO - ndcg@10: 0.024988
2025-11-22 21:49:43 - GraphTrainer - INFO - map@10: 0.017902
2025-11-22 21:49:43 - GraphTrainer - INFO - mrr@10: 0.018666
2025-11-22 21:49:43 - GraphTrainer - INFO - precision@20: 0.003998
2025-11-22 21:49:43 - GraphTrainer - INFO - recall@20: 0.075606
2025-11-22 21:49:43 - GraphTrainer - INFO - hit_rate@20: 0.079558
2025-11-22 21:49:43 - GraphTrainer - INFO - ndcg@20: 0.032165
2025-11-22 21:49:43 - GraphTrainer - INFO - map@20: 0.019827
2025-11-22 21:49:43 - GraphTrainer - INFO - mrr@20: 0.020704
2025-11-22 21:49:43 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:49:43 - GraphTrainer - INFO - 检查点已保存: Epoch 70 -> ./checkpoints/checkpoint_epoch_70.pth
2025-11-22 21:49:43 - GraphTrainer - INFO - ============================================================
2025-11-22 21:49:43 - GraphTrainer - INFO - 开始第 71/1000 轮训练
2025-11-22 21:49:43 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3556, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3545, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3576, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3749, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3717, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3628, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3494, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3509, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3714, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3825, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3480, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3455, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3533, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3455, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3689, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3516, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3787, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3467, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3579, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3655, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3598, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3640, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3467, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3760, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3623, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3781, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3494, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3561, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3691, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3629, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3466, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3604, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3810, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3857, device='cuda:0', grad_fn=<AddBackward0>)
The 70 training average loss: 0.3562638944592969
2025-11-22 21:49:54 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:49:54 - GraphTrainer - INFO -   precision@5: 0.006171
2025-11-22 21:49:54 - GraphTrainer - INFO -   recall@5: 0.029315
2025-11-22 21:49:54 - GraphTrainer - INFO -   hit_rate@5: 0.030805
2025-11-22 21:49:54 - GraphTrainer - INFO -   ndcg@5: 0.019247
2025-11-22 21:49:54 - GraphTrainer - INFO -   map@5: 0.015699
2025-11-22 21:49:54 - GraphTrainer - INFO -   mrr@5: 0.016374
2025-11-22 21:49:54 - GraphTrainer - INFO -   precision@10: 0.005030
2025-11-22 21:49:54 - GraphTrainer - INFO -   recall@10: 0.047753
2025-11-22 21:49:54 - GraphTrainer - INFO -   hit_rate@10: 0.050090
2025-11-22 21:49:54 - GraphTrainer - INFO -   ndcg@10: 0.025268
2025-11-22 21:49:54 - GraphTrainer - INFO -   map@10: 0.018164
2025-11-22 21:49:54 - GraphTrainer - INFO -   mrr@10: 0.018949
2025-11-22 21:49:54 - GraphTrainer - INFO -   precision@20: 0.003983
2025-11-22 21:49:54 - GraphTrainer - INFO -   recall@20: 0.075357
2025-11-22 21:49:54 - GraphTrainer - INFO -   hit_rate@20: 0.079198
2025-11-22 21:49:54 - GraphTrainer - INFO -   ndcg@20: 0.032270
2025-11-22 21:49:54 - GraphTrainer - INFO -   map@20: 0.020032
2025-11-22 21:49:54 - GraphTrainer - INFO -   mrr@20: 0.020915
2025-11-22 21:49:54 - GraphTrainer - INFO - 第 71 轮训练完成
2025-11-22 21:49:54 - GraphTrainer - INFO - train_loss: 0.353757
2025-11-22 21:49:54 - GraphTrainer - INFO - precision@5: 0.006171
2025-11-22 21:49:54 - GraphTrainer - INFO - recall@5: 0.029315
2025-11-22 21:49:54 - GraphTrainer - INFO - hit_rate@5: 0.030805
2025-11-22 21:49:54 - GraphTrainer - INFO - ndcg@5: 0.019247
2025-11-22 21:49:54 - GraphTrainer - INFO - map@5: 0.015699
2025-11-22 21:49:54 - GraphTrainer - INFO - mrr@5: 0.016374
2025-11-22 21:49:54 - GraphTrainer - INFO - precision@10: 0.005030
2025-11-22 21:49:54 - GraphTrainer - INFO - recall@10: 0.047753
2025-11-22 21:49:54 - GraphTrainer - INFO - hit_rate@10: 0.050090
2025-11-22 21:49:54 - GraphTrainer - INFO - ndcg@10: 0.025268
2025-11-22 21:49:54 - GraphTrainer - INFO - map@10: 0.018164
2025-11-22 21:49:54 - GraphTrainer - INFO - mrr@10: 0.018949
2025-11-22 21:49:54 - GraphTrainer - INFO - precision@20: 0.003983
2025-11-22 21:49:54 - GraphTrainer - INFO - recall@20: 0.075357
2025-11-22 21:49:54 - GraphTrainer - INFO - hit_rate@20: 0.079198
2025-11-22 21:49:54 - GraphTrainer - INFO - ndcg@20: 0.032270
2025-11-22 21:49:54 - GraphTrainer - INFO - map@20: 0.020032
2025-11-22 21:49:54 - GraphTrainer - INFO - mrr@20: 0.020915
2025-11-22 21:49:54 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:49:54 - GraphTrainer - INFO - ============================================================
2025-11-22 21:49:54 - GraphTrainer - INFO - 开始第 72/1000 轮训练
2025-11-22 21:49:54 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3539, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3574, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3571, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3532, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3706, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3595, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3216, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3254, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3556, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3651, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3556, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3631, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3562, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3539, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3547, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3434, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3730, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3584, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3599, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3750, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3603, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3729, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3691, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3464, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3710, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3661, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3525, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3434, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3409, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3531, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3683, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3695, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3759, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3625, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3575, device='cuda:0', grad_fn=<AddBackward0>)
The 71 training average loss: 0.3537570387125015
2025-11-22 21:50:06 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:50:06 - GraphTrainer - INFO -   precision@5: 0.006305
2025-11-22 21:50:06 - GraphTrainer - INFO -   recall@5: 0.029963
2025-11-22 21:50:06 - GraphTrainer - INFO -   hit_rate@5: 0.031422
2025-11-22 21:50:06 - GraphTrainer - INFO -   ndcg@5: 0.019640
2025-11-22 21:50:06 - GraphTrainer - INFO -   map@5: 0.016006
2025-11-22 21:50:06 - GraphTrainer - INFO -   mrr@5: 0.016672
2025-11-22 21:50:06 - GraphTrainer - INFO -   precision@10: 0.005071
2025-11-22 21:50:06 - GraphTrainer - INFO -   recall@10: 0.047995
2025-11-22 21:50:06 - GraphTrainer - INFO -   hit_rate@10: 0.050501
2025-11-22 21:50:06 - GraphTrainer - INFO -   ndcg@10: 0.025508
2025-11-22 21:50:06 - GraphTrainer - INFO -   map@10: 0.018388
2025-11-22 21:50:06 - GraphTrainer - INFO -   mrr@10: 0.019187
2025-11-22 21:50:06 - GraphTrainer - INFO -   precision@20: 0.003962
2025-11-22 21:50:06 - GraphTrainer - INFO -   recall@20: 0.074940
2025-11-22 21:50:06 - GraphTrainer - INFO -   hit_rate@20: 0.078786
2025-11-22 21:50:06 - GraphTrainer - INFO -   ndcg@20: 0.032344
2025-11-22 21:50:06 - GraphTrainer - INFO -   map@20: 0.020215
2025-11-22 21:50:06 - GraphTrainer - INFO -   mrr@20: 0.021100
2025-11-22 21:50:06 - GraphTrainer - INFO - 第 72 轮训练完成
2025-11-22 21:50:06 - GraphTrainer - INFO - train_loss: 0.351645
2025-11-22 21:50:06 - GraphTrainer - INFO - precision@5: 0.006305
2025-11-22 21:50:06 - GraphTrainer - INFO - recall@5: 0.029963
2025-11-22 21:50:06 - GraphTrainer - INFO - hit_rate@5: 0.031422
2025-11-22 21:50:06 - GraphTrainer - INFO - ndcg@5: 0.019640
2025-11-22 21:50:06 - GraphTrainer - INFO - map@5: 0.016006
2025-11-22 21:50:06 - GraphTrainer - INFO - mrr@5: 0.016672
2025-11-22 21:50:06 - GraphTrainer - INFO - precision@10: 0.005071
2025-11-22 21:50:06 - GraphTrainer - INFO - recall@10: 0.047995
2025-11-22 21:50:06 - GraphTrainer - INFO - hit_rate@10: 0.050501
2025-11-22 21:50:06 - GraphTrainer - INFO - ndcg@10: 0.025508
2025-11-22 21:50:06 - GraphTrainer - INFO - map@10: 0.018388
2025-11-22 21:50:06 - GraphTrainer - INFO - mrr@10: 0.019187
2025-11-22 21:50:06 - GraphTrainer - INFO - precision@20: 0.003962
2025-11-22 21:50:06 - GraphTrainer - INFO - recall@20: 0.074940
2025-11-22 21:50:06 - GraphTrainer - INFO - hit_rate@20: 0.078786
2025-11-22 21:50:06 - GraphTrainer - INFO - ndcg@20: 0.032344
2025-11-22 21:50:06 - GraphTrainer - INFO - map@20: 0.020215
2025-11-22 21:50:06 - GraphTrainer - INFO - mrr@20: 0.021100
2025-11-22 21:50:06 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:50:06 - GraphTrainer - INFO - ============================================================
2025-11-22 21:50:06 - GraphTrainer - INFO - 开始第 73/1000 轮训练
2025-11-22 21:50:06 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3641, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3782, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3509, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3623, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3561, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3532, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3722, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3719, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3648, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3624, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3466, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3502, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3580, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3644, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3536, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3624, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3650, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3616, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3715, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3570, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3531, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3556, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3628, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)
The 72 training average loss: 0.3516448099037697
2025-11-22 21:50:17 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:50:17 - GraphTrainer - INFO -   precision@5: 0.006593
2025-11-22 21:50:17 - GraphTrainer - INFO -   recall@5: 0.031510
2025-11-22 21:50:17 - GraphTrainer - INFO -   hit_rate@5: 0.032913
2025-11-22 21:50:17 - GraphTrainer - INFO -   ndcg@5: 0.020412
2025-11-22 21:50:17 - GraphTrainer - INFO -   map@5: 0.016556
2025-11-22 21:50:17 - GraphTrainer - INFO -   mrr@5: 0.017232
2025-11-22 21:50:17 - GraphTrainer - INFO -   precision@10: 0.005024
2025-11-22 21:50:17 - GraphTrainer - INFO -   recall@10: 0.047738
2025-11-22 21:50:17 - GraphTrainer - INFO -   hit_rate@10: 0.050090
2025-11-22 21:50:17 - GraphTrainer - INFO -   ndcg@10: 0.025676
2025-11-22 21:50:17 - GraphTrainer - INFO -   map@10: 0.018682
2025-11-22 21:50:17 - GraphTrainer - INFO -   mrr@10: 0.019484
2025-11-22 21:50:17 - GraphTrainer - INFO -   precision@20: 0.003957
2025-11-22 21:50:17 - GraphTrainer - INFO -   recall@20: 0.074732
2025-11-22 21:50:17 - GraphTrainer - INFO -   hit_rate@20: 0.078683
2025-11-22 21:50:17 - GraphTrainer - INFO -   ndcg@20: 0.032571
2025-11-22 21:50:17 - GraphTrainer - INFO -   map@20: 0.020537
2025-11-22 21:50:17 - GraphTrainer - INFO -   mrr@20: 0.021446
2025-11-22 21:50:17 - GraphTrainer - INFO - 第 73 轮训练完成
2025-11-22 21:50:17 - GraphTrainer - INFO - train_loss: 0.351230
2025-11-22 21:50:17 - GraphTrainer - INFO - precision@5: 0.006593
2025-11-22 21:50:17 - GraphTrainer - INFO - recall@5: 0.031510
2025-11-22 21:50:17 - GraphTrainer - INFO - hit_rate@5: 0.032913
2025-11-22 21:50:17 - GraphTrainer - INFO - ndcg@5: 0.020412
2025-11-22 21:50:17 - GraphTrainer - INFO - map@5: 0.016556
2025-11-22 21:50:17 - GraphTrainer - INFO - mrr@5: 0.017232
2025-11-22 21:50:17 - GraphTrainer - INFO - precision@10: 0.005024
2025-11-22 21:50:17 - GraphTrainer - INFO - recall@10: 0.047738
2025-11-22 21:50:17 - GraphTrainer - INFO - hit_rate@10: 0.050090
2025-11-22 21:50:17 - GraphTrainer - INFO - ndcg@10: 0.025676
2025-11-22 21:50:17 - GraphTrainer - INFO - map@10: 0.018682
2025-11-22 21:50:17 - GraphTrainer - INFO - mrr@10: 0.019484
2025-11-22 21:50:17 - GraphTrainer - INFO - precision@20: 0.003957
2025-11-22 21:50:17 - GraphTrainer - INFO - recall@20: 0.074732
2025-11-22 21:50:17 - GraphTrainer - INFO - hit_rate@20: 0.078683
2025-11-22 21:50:17 - GraphTrainer - INFO - ndcg@20: 0.032571
2025-11-22 21:50:17 - GraphTrainer - INFO - map@20: 0.020537
2025-11-22 21:50:17 - GraphTrainer - INFO - mrr@20: 0.021446
2025-11-22 21:50:17 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:50:17 - GraphTrainer - INFO - ============================================================
2025-11-22 21:50:17 - GraphTrainer - INFO - 开始第 74/1000 轮训练
2025-11-22 21:50:17 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3510, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3695, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3342, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3572, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3560, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3656, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3268, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3509, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3655, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3226, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3779, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3555, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3551, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3602, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3708, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3268, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3502, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3708, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3256, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3680, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3590, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3543, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3591, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3574, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3662, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3577, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3780, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3622, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3603, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3575, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
The 73 training average loss: 0.3512297534737094
2025-11-22 21:50:28 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:50:28 - GraphTrainer - INFO -   precision@5: 0.006356
2025-11-22 21:50:28 - GraphTrainer - INFO -   recall@5: 0.030213
2025-11-22 21:50:28 - GraphTrainer - INFO -   hit_rate@5: 0.031731
2025-11-22 21:50:28 - GraphTrainer - INFO -   ndcg@5: 0.019864
2025-11-22 21:50:28 - GraphTrainer - INFO -   map@5: 0.016229
2025-11-22 21:50:28 - GraphTrainer - INFO -   mrr@5: 0.016906
2025-11-22 21:50:28 - GraphTrainer - INFO -   precision@10: 0.005040
2025-11-22 21:50:28 - GraphTrainer - INFO -   recall@10: 0.047948
2025-11-22 21:50:28 - GraphTrainer - INFO -   hit_rate@10: 0.050244
2025-11-22 21:50:28 - GraphTrainer - INFO -   ndcg@10: 0.025617
2025-11-22 21:50:28 - GraphTrainer - INFO -   map@10: 0.018566
2025-11-22 21:50:28 - GraphTrainer - INFO -   mrr@10: 0.019347
2025-11-22 21:50:28 - GraphTrainer - INFO -   precision@20: 0.004040
2025-11-22 21:50:28 - GraphTrainer - INFO -   recall@20: 0.076485
2025-11-22 21:50:28 - GraphTrainer - INFO -   hit_rate@20: 0.080329
2025-11-22 21:50:28 - GraphTrainer - INFO -   ndcg@20: 0.032892
2025-11-22 21:50:28 - GraphTrainer - INFO -   map@20: 0.020523
2025-11-22 21:50:28 - GraphTrainer - INFO -   mrr@20: 0.021407
2025-11-22 21:50:28 - GraphTrainer - INFO - 第 74 轮训练完成
2025-11-22 21:50:28 - GraphTrainer - INFO - train_loss: 0.351834
2025-11-22 21:50:28 - GraphTrainer - INFO - precision@5: 0.006356
2025-11-22 21:50:28 - GraphTrainer - INFO - recall@5: 0.030213
2025-11-22 21:50:28 - GraphTrainer - INFO - hit_rate@5: 0.031731
2025-11-22 21:50:28 - GraphTrainer - INFO - ndcg@5: 0.019864
2025-11-22 21:50:28 - GraphTrainer - INFO - map@5: 0.016229
2025-11-22 21:50:28 - GraphTrainer - INFO - mrr@5: 0.016906
2025-11-22 21:50:28 - GraphTrainer - INFO - precision@10: 0.005040
2025-11-22 21:50:28 - GraphTrainer - INFO - recall@10: 0.047948
2025-11-22 21:50:28 - GraphTrainer - INFO - hit_rate@10: 0.050244
2025-11-22 21:50:28 - GraphTrainer - INFO - ndcg@10: 0.025617
2025-11-22 21:50:28 - GraphTrainer - INFO - map@10: 0.018566
2025-11-22 21:50:28 - GraphTrainer - INFO - mrr@10: 0.019347
2025-11-22 21:50:28 - GraphTrainer - INFO - precision@20: 0.004040
2025-11-22 21:50:28 - GraphTrainer - INFO - recall@20: 0.076485
2025-11-22 21:50:28 - GraphTrainer - INFO - hit_rate@20: 0.080329
2025-11-22 21:50:28 - GraphTrainer - INFO - ndcg@20: 0.032892
2025-11-22 21:50:28 - GraphTrainer - INFO - map@20: 0.020523
2025-11-22 21:50:28 - GraphTrainer - INFO - mrr@20: 0.021407
2025-11-22 21:50:28 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:50:28 - GraphTrainer - INFO - ============================================================
2025-11-22 21:50:28 - GraphTrainer - INFO - 开始第 75/1000 轮训练
2025-11-22 21:50:28 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3643, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3612, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3550, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3455, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3462, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3551, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3596, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3545, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3575, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3663, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3733, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3729, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3595, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3640, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3623, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3342, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3466, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3623, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3599, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3806, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3601, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3745, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3700, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3409, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3588, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3532, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3646, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3627, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3610, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3624, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3576, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)
The 74 training average loss: 0.3518335572604475
2025-11-22 21:50:39 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:50:39 - GraphTrainer - INFO -   precision@5: 0.006264
2025-11-22 21:50:39 - GraphTrainer - INFO -   recall@5: 0.029786
2025-11-22 21:50:39 - GraphTrainer - INFO -   hit_rate@5: 0.031268
2025-11-22 21:50:39 - GraphTrainer - INFO -   ndcg@5: 0.019642
2025-11-22 21:50:39 - GraphTrainer - INFO -   map@5: 0.016071
2025-11-22 21:50:39 - GraphTrainer - INFO -   mrr@5: 0.016736
2025-11-22 21:50:39 - GraphTrainer - INFO -   precision@10: 0.005091
2025-11-22 21:50:39 - GraphTrainer - INFO -   recall@10: 0.048172
2025-11-22 21:50:39 - GraphTrainer - INFO -   hit_rate@10: 0.050810
2025-11-22 21:50:39 - GraphTrainer - INFO -   ndcg@10: 0.025598
2025-11-22 21:50:39 - GraphTrainer - INFO -   map@10: 0.018465
2025-11-22 21:50:39 - GraphTrainer - INFO -   mrr@10: 0.019285
2025-11-22 21:50:39 - GraphTrainer - INFO -   precision@20: 0.003991
2025-11-22 21:50:39 - GraphTrainer - INFO -   recall@20: 0.075338
2025-11-22 21:50:39 - GraphTrainer - INFO -   hit_rate@20: 0.079249
2025-11-22 21:50:39 - GraphTrainer - INFO -   ndcg@20: 0.032482
2025-11-22 21:50:39 - GraphTrainer - INFO -   map@20: 0.020300
2025-11-22 21:50:39 - GraphTrainer - INFO -   mrr@20: 0.021197
2025-11-22 21:50:39 - GraphTrainer - INFO - 第 75 轮训练完成
2025-11-22 21:50:39 - GraphTrainer - INFO - train_loss: 0.350445
2025-11-22 21:50:39 - GraphTrainer - INFO - precision@5: 0.006264
2025-11-22 21:50:39 - GraphTrainer - INFO - recall@5: 0.029786
2025-11-22 21:50:39 - GraphTrainer - INFO - hit_rate@5: 0.031268
2025-11-22 21:50:39 - GraphTrainer - INFO - ndcg@5: 0.019642
2025-11-22 21:50:39 - GraphTrainer - INFO - map@5: 0.016071
2025-11-22 21:50:39 - GraphTrainer - INFO - mrr@5: 0.016736
2025-11-22 21:50:39 - GraphTrainer - INFO - precision@10: 0.005091
2025-11-22 21:50:39 - GraphTrainer - INFO - recall@10: 0.048172
2025-11-22 21:50:39 - GraphTrainer - INFO - hit_rate@10: 0.050810
2025-11-22 21:50:39 - GraphTrainer - INFO - ndcg@10: 0.025598
2025-11-22 21:50:39 - GraphTrainer - INFO - map@10: 0.018465
2025-11-22 21:50:39 - GraphTrainer - INFO - mrr@10: 0.019285
2025-11-22 21:50:39 - GraphTrainer - INFO - precision@20: 0.003991
2025-11-22 21:50:39 - GraphTrainer - INFO - recall@20: 0.075338
2025-11-22 21:50:39 - GraphTrainer - INFO - hit_rate@20: 0.079249
2025-11-22 21:50:39 - GraphTrainer - INFO - ndcg@20: 0.032482
2025-11-22 21:50:39 - GraphTrainer - INFO - map@20: 0.020300
2025-11-22 21:50:39 - GraphTrainer - INFO - mrr@20: 0.021197
2025-11-22 21:50:39 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:50:39 - GraphTrainer - INFO - ============================================================
2025-11-22 21:50:39 - GraphTrainer - INFO - 开始第 76/1000 轮训练
2025-11-22 21:50:39 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3580, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3274, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3563, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3605, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3568, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3545, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3544, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3532, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3194, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3561, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3559, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3669, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3729, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3739, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3616, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3628, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3492, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3480, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3557, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3644, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3539, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3562, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3331, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3630, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3635, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3639, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3572, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3557, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
The 75 training average loss: 0.3504451580088714
2025-11-22 21:50:50 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:50:50 - GraphTrainer - INFO -   precision@5: 0.006367
2025-11-22 21:50:50 - GraphTrainer - INFO -   recall@5: 0.030353
2025-11-22 21:50:50 - GraphTrainer - INFO -   hit_rate@5: 0.031782
2025-11-22 21:50:50 - GraphTrainer - INFO -   ndcg@5: 0.019824
2025-11-22 21:50:50 - GraphTrainer - INFO -   map@5: 0.016140
2025-11-22 21:50:50 - GraphTrainer - INFO -   mrr@5: 0.016831
2025-11-22 21:50:50 - GraphTrainer - INFO -   precision@10: 0.005045
2025-11-22 21:50:50 - GraphTrainer - INFO -   recall@10: 0.047842
2025-11-22 21:50:50 - GraphTrainer - INFO -   hit_rate@10: 0.050296
2025-11-22 21:50:50 - GraphTrainer - INFO -   ndcg@10: 0.025529
2025-11-22 21:50:50 - GraphTrainer - INFO -   map@10: 0.018457
2025-11-22 21:50:50 - GraphTrainer - INFO -   mrr@10: 0.019289
2025-11-22 21:50:50 - GraphTrainer - INFO -   precision@20: 0.003970
2025-11-22 21:50:50 - GraphTrainer - INFO -   recall@20: 0.075063
2025-11-22 21:50:50 - GraphTrainer - INFO -   hit_rate@20: 0.078941
2025-11-22 21:50:50 - GraphTrainer - INFO -   ndcg@20: 0.032420
2025-11-22 21:50:50 - GraphTrainer - INFO -   map@20: 0.020287
2025-11-22 21:50:50 - GraphTrainer - INFO -   mrr@20: 0.021211
2025-11-22 21:50:50 - GraphTrainer - INFO - 第 76 轮训练完成
2025-11-22 21:50:50 - GraphTrainer - INFO - train_loss: 0.352657
2025-11-22 21:50:50 - GraphTrainer - INFO - precision@5: 0.006367
2025-11-22 21:50:50 - GraphTrainer - INFO - recall@5: 0.030353
2025-11-22 21:50:50 - GraphTrainer - INFO - hit_rate@5: 0.031782
2025-11-22 21:50:50 - GraphTrainer - INFO - ndcg@5: 0.019824
2025-11-22 21:50:50 - GraphTrainer - INFO - map@5: 0.016140
2025-11-22 21:50:50 - GraphTrainer - INFO - mrr@5: 0.016831
2025-11-22 21:50:50 - GraphTrainer - INFO - precision@10: 0.005045
2025-11-22 21:50:50 - GraphTrainer - INFO - recall@10: 0.047842
2025-11-22 21:50:50 - GraphTrainer - INFO - hit_rate@10: 0.050296
2025-11-22 21:50:50 - GraphTrainer - INFO - ndcg@10: 0.025529
2025-11-22 21:50:50 - GraphTrainer - INFO - map@10: 0.018457
2025-11-22 21:50:50 - GraphTrainer - INFO - mrr@10: 0.019289
2025-11-22 21:50:50 - GraphTrainer - INFO - precision@20: 0.003970
2025-11-22 21:50:50 - GraphTrainer - INFO - recall@20: 0.075063
2025-11-22 21:50:50 - GraphTrainer - INFO - hit_rate@20: 0.078941
2025-11-22 21:50:50 - GraphTrainer - INFO - ndcg@20: 0.032420
2025-11-22 21:50:50 - GraphTrainer - INFO - map@20: 0.020287
2025-11-22 21:50:50 - GraphTrainer - INFO - mrr@20: 0.021211
2025-11-22 21:50:50 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:50:50 - GraphTrainer - INFO - ============================================================
2025-11-22 21:50:50 - GraphTrainer - INFO - 开始第 77/1000 轮训练
2025-11-22 21:50:50 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3641, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3653, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3619, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3668, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3695, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3435, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3688, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3665, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3698, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3613, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3739, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3624, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3659, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3624, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3635, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3200, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3625, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3466, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3580, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3545, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3529, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3611, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3634, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3490, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3663, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3654, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3641, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
The 76 training average loss: 0.35265711309580966
2025-11-22 21:51:01 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:51:01 - GraphTrainer - INFO -   precision@5: 0.006295
2025-11-22 21:51:01 - GraphTrainer - INFO -   recall@5: 0.030012
2025-11-22 21:51:01 - GraphTrainer - INFO -   hit_rate@5: 0.031422
2025-11-22 21:51:01 - GraphTrainer - INFO -   ndcg@5: 0.019782
2025-11-22 21:51:01 - GraphTrainer - INFO -   map@5: 0.016209
2025-11-22 21:51:01 - GraphTrainer - INFO -   mrr@5: 0.016799
2025-11-22 21:51:01 - GraphTrainer - INFO -   precision@10: 0.005060
2025-11-22 21:51:01 - GraphTrainer - INFO -   recall@10: 0.048189
2025-11-22 21:51:01 - GraphTrainer - INFO -   hit_rate@10: 0.050450
2025-11-22 21:51:01 - GraphTrainer - INFO -   ndcg@10: 0.025660
2025-11-22 21:51:01 - GraphTrainer - INFO -   map@10: 0.018584
2025-11-22 21:51:01 - GraphTrainer - INFO -   mrr@10: 0.019284
2025-11-22 21:51:01 - GraphTrainer - INFO -   precision@20: 0.003937
2025-11-22 21:51:01 - GraphTrainer - INFO -   recall@20: 0.074467
2025-11-22 21:51:01 - GraphTrainer - INFO -   hit_rate@20: 0.078272
2025-11-22 21:51:01 - GraphTrainer - INFO -   ndcg@20: 0.032367
2025-11-22 21:51:01 - GraphTrainer - INFO -   map@20: 0.020387
2025-11-22 21:51:01 - GraphTrainer - INFO -   mrr@20: 0.021190
2025-11-22 21:51:01 - GraphTrainer - INFO - 第 77 轮训练完成
2025-11-22 21:51:01 - GraphTrainer - INFO - train_loss: 0.351819
2025-11-22 21:51:01 - GraphTrainer - INFO - precision@5: 0.006295
2025-11-22 21:51:01 - GraphTrainer - INFO - recall@5: 0.030012
2025-11-22 21:51:01 - GraphTrainer - INFO - hit_rate@5: 0.031422
2025-11-22 21:51:01 - GraphTrainer - INFO - ndcg@5: 0.019782
2025-11-22 21:51:01 - GraphTrainer - INFO - map@5: 0.016209
2025-11-22 21:51:01 - GraphTrainer - INFO - mrr@5: 0.016799
2025-11-22 21:51:01 - GraphTrainer - INFO - precision@10: 0.005060
2025-11-22 21:51:01 - GraphTrainer - INFO - recall@10: 0.048189
2025-11-22 21:51:01 - GraphTrainer - INFO - hit_rate@10: 0.050450
2025-11-22 21:51:01 - GraphTrainer - INFO - ndcg@10: 0.025660
2025-11-22 21:51:01 - GraphTrainer - INFO - map@10: 0.018584
2025-11-22 21:51:01 - GraphTrainer - INFO - mrr@10: 0.019284
2025-11-22 21:51:01 - GraphTrainer - INFO - precision@20: 0.003937
2025-11-22 21:51:01 - GraphTrainer - INFO - recall@20: 0.074467
2025-11-22 21:51:01 - GraphTrainer - INFO - hit_rate@20: 0.078272
2025-11-22 21:51:01 - GraphTrainer - INFO - ndcg@20: 0.032367
2025-11-22 21:51:01 - GraphTrainer - INFO - map@20: 0.020387
2025-11-22 21:51:01 - GraphTrainer - INFO - mrr@20: 0.021190
2025-11-22 21:51:01 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:51:01 - GraphTrainer - INFO - ============================================================
2025-11-22 21:51:01 - GraphTrainer - INFO - 开始第 78/1000 轮训练
2025-11-22 21:51:01 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3499, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3502, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3468, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3792, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3263, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3597, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3599, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3655, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3302, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3556, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3529, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3534, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3725, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3576, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3379, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3563, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3739, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3584, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3694, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3597, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3621, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3331, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3775, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3579, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3841, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3604, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3679, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3285, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3492, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3741, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3845, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3562, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3259, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3654, device='cuda:0', grad_fn=<AddBackward0>)
The 77 training average loss: 0.351819406809478
2025-11-22 21:51:12 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:51:12 - GraphTrainer - INFO -   precision@5: 0.006747
2025-11-22 21:51:12 - GraphTrainer - INFO -   recall@5: 0.032166
2025-11-22 21:51:12 - GraphTrainer - INFO -   hit_rate@5: 0.033685
2025-11-22 21:51:12 - GraphTrainer - INFO -   ndcg@5: 0.020809
2025-11-22 21:51:12 - GraphTrainer - INFO -   map@5: 0.016863
2025-11-22 21:51:12 - GraphTrainer - INFO -   mrr@5: 0.017530
2025-11-22 21:51:12 - GraphTrainer - INFO -   precision@10: 0.005035
2025-11-22 21:51:12 - GraphTrainer - INFO -   recall@10: 0.047858
2025-11-22 21:51:12 - GraphTrainer - INFO -   hit_rate@10: 0.050244
2025-11-22 21:51:12 - GraphTrainer - INFO -   ndcg@10: 0.025906
2025-11-22 21:51:12 - GraphTrainer - INFO -   map@10: 0.018928
2025-11-22 21:51:12 - GraphTrainer - INFO -   mrr@10: 0.019711
2025-11-22 21:51:12 - GraphTrainer - INFO -   precision@20: 0.003960
2025-11-22 21:51:12 - GraphTrainer - INFO -   recall@20: 0.075007
2025-11-22 21:51:12 - GraphTrainer - INFO -   hit_rate@20: 0.078889
2025-11-22 21:51:12 - GraphTrainer - INFO -   ndcg@20: 0.032835
2025-11-22 21:51:12 - GraphTrainer - INFO -   map@20: 0.020798
2025-11-22 21:51:12 - GraphTrainer - INFO -   mrr@20: 0.021678
2025-11-22 21:51:12 - GraphTrainer - INFO - 第 78 轮训练完成
2025-11-22 21:51:12 - GraphTrainer - INFO - train_loss: 0.349987
2025-11-22 21:51:12 - GraphTrainer - INFO - precision@5: 0.006747
2025-11-22 21:51:12 - GraphTrainer - INFO - recall@5: 0.032166
2025-11-22 21:51:12 - GraphTrainer - INFO - hit_rate@5: 0.033685
2025-11-22 21:51:12 - GraphTrainer - INFO - ndcg@5: 0.020809
2025-11-22 21:51:12 - GraphTrainer - INFO - map@5: 0.016863
2025-11-22 21:51:12 - GraphTrainer - INFO - mrr@5: 0.017530
2025-11-22 21:51:12 - GraphTrainer - INFO - precision@10: 0.005035
2025-11-22 21:51:12 - GraphTrainer - INFO - recall@10: 0.047858
2025-11-22 21:51:12 - GraphTrainer - INFO - hit_rate@10: 0.050244
2025-11-22 21:51:12 - GraphTrainer - INFO - ndcg@10: 0.025906
2025-11-22 21:51:12 - GraphTrainer - INFO - map@10: 0.018928
2025-11-22 21:51:12 - GraphTrainer - INFO - mrr@10: 0.019711
2025-11-22 21:51:12 - GraphTrainer - INFO - precision@20: 0.003960
2025-11-22 21:51:12 - GraphTrainer - INFO - recall@20: 0.075007
2025-11-22 21:51:12 - GraphTrainer - INFO - hit_rate@20: 0.078889
2025-11-22 21:51:12 - GraphTrainer - INFO - ndcg@20: 0.032835
2025-11-22 21:51:12 - GraphTrainer - INFO - map@20: 0.020798
2025-11-22 21:51:12 - GraphTrainer - INFO - mrr@20: 0.021678
2025-11-22 21:51:12 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:51:12 - GraphTrainer - INFO - ============================================================
2025-11-22 21:51:12 - GraphTrainer - INFO - 开始第 79/1000 轮训练
2025-11-22 21:51:12 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3640, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3644, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3582, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3693, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3612, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3536, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3457, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3551, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3467, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3278, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3702, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3725, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3516, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3608, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3613, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3562, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3702, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3588, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3558, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3494, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3545, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
The 78 training average loss: 0.34998670014841804
2025-11-22 21:51:24 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:51:24 - GraphTrainer - INFO -   precision@5: 0.006439
2025-11-22 21:51:24 - GraphTrainer - INFO -   recall@5: 0.030753
2025-11-22 21:51:24 - GraphTrainer - INFO -   hit_rate@5: 0.032142
2025-11-22 21:51:24 - GraphTrainer - INFO -   ndcg@5: 0.019953
2025-11-22 21:51:24 - GraphTrainer - INFO -   map@5: 0.016198
2025-11-22 21:51:24 - GraphTrainer - INFO -   mrr@5: 0.016811
2025-11-22 21:51:24 - GraphTrainer - INFO -   precision@10: 0.005030
2025-11-22 21:51:24 - GraphTrainer - INFO -   recall@10: 0.047813
2025-11-22 21:51:24 - GraphTrainer - INFO -   hit_rate@10: 0.050141
2025-11-22 21:51:24 - GraphTrainer - INFO -   ndcg@10: 0.025497
2025-11-22 21:51:24 - GraphTrainer - INFO -   map@10: 0.018445
2025-11-22 21:51:24 - GraphTrainer - INFO -   mrr@10: 0.019179
2025-11-22 21:51:24 - GraphTrainer - INFO -   precision@20: 0.003993
2025-11-22 21:51:24 - GraphTrainer - INFO -   recall@20: 0.075716
2025-11-22 21:51:24 - GraphTrainer - INFO -   hit_rate@20: 0.079558
2025-11-22 21:51:24 - GraphTrainer - INFO -   ndcg@20: 0.032588
2025-11-22 21:51:24 - GraphTrainer - INFO -   map@20: 0.020344
2025-11-22 21:51:24 - GraphTrainer - INFO -   mrr@20: 0.021177
2025-11-22 21:51:24 - GraphTrainer - INFO - 第 79 轮训练完成
2025-11-22 21:51:24 - GraphTrainer - INFO - train_loss: 0.350068
2025-11-22 21:51:24 - GraphTrainer - INFO - precision@5: 0.006439
2025-11-22 21:51:24 - GraphTrainer - INFO - recall@5: 0.030753
2025-11-22 21:51:24 - GraphTrainer - INFO - hit_rate@5: 0.032142
2025-11-22 21:51:24 - GraphTrainer - INFO - ndcg@5: 0.019953
2025-11-22 21:51:24 - GraphTrainer - INFO - map@5: 0.016198
2025-11-22 21:51:24 - GraphTrainer - INFO - mrr@5: 0.016811
2025-11-22 21:51:24 - GraphTrainer - INFO - precision@10: 0.005030
2025-11-22 21:51:24 - GraphTrainer - INFO - recall@10: 0.047813
2025-11-22 21:51:24 - GraphTrainer - INFO - hit_rate@10: 0.050141
2025-11-22 21:51:24 - GraphTrainer - INFO - ndcg@10: 0.025497
2025-11-22 21:51:24 - GraphTrainer - INFO - map@10: 0.018445
2025-11-22 21:51:24 - GraphTrainer - INFO - mrr@10: 0.019179
2025-11-22 21:51:24 - GraphTrainer - INFO - precision@20: 0.003993
2025-11-22 21:51:24 - GraphTrainer - INFO - recall@20: 0.075716
2025-11-22 21:51:24 - GraphTrainer - INFO - hit_rate@20: 0.079558
2025-11-22 21:51:24 - GraphTrainer - INFO - ndcg@20: 0.032588
2025-11-22 21:51:24 - GraphTrainer - INFO - map@20: 0.020344
2025-11-22 21:51:24 - GraphTrainer - INFO - mrr@20: 0.021177
2025-11-22 21:51:24 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:51:24 - GraphTrainer - INFO - ============================================================
2025-11-22 21:51:24 - GraphTrainer - INFO - 开始第 80/1000 轮训练
2025-11-22 21:51:24 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3707, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3695, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3613, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3313, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3596, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3577, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3506, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3612, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3278, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3518, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3727, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3246, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3479, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3669, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3468, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3613, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3548, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3676, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3562, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3597, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3467, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3683, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3544, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3786, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3826, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3556, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3861, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3376, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3183, device='cuda:0', grad_fn=<AddBackward0>)
The 79 training average loss: 0.35006820025115176
2025-11-22 21:51:35 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:51:35 - GraphTrainer - INFO -   precision@5: 0.006449
2025-11-22 21:51:35 - GraphTrainer - INFO -   recall@5: 0.030806
2025-11-22 21:51:35 - GraphTrainer - INFO -   hit_rate@5: 0.032193
2025-11-22 21:51:35 - GraphTrainer - INFO -   ndcg@5: 0.019689
2025-11-22 21:51:35 - GraphTrainer - INFO -   map@5: 0.015819
2025-11-22 21:51:35 - GraphTrainer - INFO -   mrr@5: 0.016454
2025-11-22 21:51:35 - GraphTrainer - INFO -   precision@10: 0.005102
2025-11-22 21:51:35 - GraphTrainer - INFO -   recall@10: 0.048436
2025-11-22 21:51:35 - GraphTrainer - INFO -   hit_rate@10: 0.050861
2025-11-22 21:51:35 - GraphTrainer - INFO -   ndcg@10: 0.025419
2025-11-22 21:51:35 - GraphTrainer - INFO -   map@10: 0.018139
2025-11-22 21:51:35 - GraphTrainer - INFO -   mrr@10: 0.018905
2025-11-22 21:51:35 - GraphTrainer - INFO -   precision@20: 0.003978
2025-11-22 21:51:35 - GraphTrainer - INFO -   recall@20: 0.075234
2025-11-22 21:51:35 - GraphTrainer - INFO -   hit_rate@20: 0.079146
2025-11-22 21:51:35 - GraphTrainer - INFO -   ndcg@20: 0.032200
2025-11-22 21:51:35 - GraphTrainer - INFO -   map@20: 0.019935
2025-11-22 21:51:35 - GraphTrainer - INFO -   mrr@20: 0.020801
2025-11-22 21:51:35 - GraphTrainer - INFO - 第 80 轮训练完成
2025-11-22 21:51:35 - GraphTrainer - INFO - train_loss: 0.351555
2025-11-22 21:51:35 - GraphTrainer - INFO - precision@5: 0.006449
2025-11-22 21:51:35 - GraphTrainer - INFO - recall@5: 0.030806
2025-11-22 21:51:35 - GraphTrainer - INFO - hit_rate@5: 0.032193
2025-11-22 21:51:35 - GraphTrainer - INFO - ndcg@5: 0.019689
2025-11-22 21:51:35 - GraphTrainer - INFO - map@5: 0.015819
2025-11-22 21:51:35 - GraphTrainer - INFO - mrr@5: 0.016454
2025-11-22 21:51:35 - GraphTrainer - INFO - precision@10: 0.005102
2025-11-22 21:51:35 - GraphTrainer - INFO - recall@10: 0.048436
2025-11-22 21:51:35 - GraphTrainer - INFO - hit_rate@10: 0.050861
2025-11-22 21:51:35 - GraphTrainer - INFO - ndcg@10: 0.025419
2025-11-22 21:51:35 - GraphTrainer - INFO - map@10: 0.018139
2025-11-22 21:51:35 - GraphTrainer - INFO - mrr@10: 0.018905
2025-11-22 21:51:35 - GraphTrainer - INFO - precision@20: 0.003978
2025-11-22 21:51:35 - GraphTrainer - INFO - recall@20: 0.075234
2025-11-22 21:51:35 - GraphTrainer - INFO - hit_rate@20: 0.079146
2025-11-22 21:51:35 - GraphTrainer - INFO - ndcg@20: 0.032200
2025-11-22 21:51:35 - GraphTrainer - INFO - map@20: 0.019935
2025-11-22 21:51:35 - GraphTrainer - INFO - mrr@20: 0.020801
2025-11-22 21:51:35 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:51:35 - GraphTrainer - INFO - 检查点已保存: Epoch 80 -> ./checkpoints/checkpoint_epoch_80.pth
2025-11-22 21:51:35 - GraphTrainer - INFO - ============================================================
2025-11-22 21:51:35 - GraphTrainer - INFO - 开始第 81/1000 轮训练
2025-11-22 21:51:35 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3636, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3746, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3517, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3586, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3582, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3510, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3759, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3615, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3689, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3671, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3684, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3826, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3576, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3721, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3221, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3544, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3602, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3750, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3605, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3617, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3518, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3757, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3611, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3596, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3689, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3569, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3556, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
The 80 training average loss: 0.3515550083127515
2025-11-22 21:51:46 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:51:46 - GraphTrainer - INFO -   precision@5: 0.006500
2025-11-22 21:51:46 - GraphTrainer - INFO -   recall@5: 0.030956
2025-11-22 21:51:46 - GraphTrainer - INFO -   hit_rate@5: 0.032399
2025-11-22 21:51:46 - GraphTrainer - INFO -   ndcg@5: 0.020099
2025-11-22 21:51:46 - GraphTrainer - INFO -   map@5: 0.016292
2025-11-22 21:51:46 - GraphTrainer - INFO -   mrr@5: 0.016987
2025-11-22 21:51:46 - GraphTrainer - INFO -   precision@10: 0.005030
2025-11-22 21:51:46 - GraphTrainer - INFO -   recall@10: 0.047603
2025-11-22 21:51:46 - GraphTrainer - INFO -   hit_rate@10: 0.050193
2025-11-22 21:51:46 - GraphTrainer - INFO -   ndcg@10: 0.025520
2025-11-22 21:51:46 - GraphTrainer - INFO -   map@10: 0.018481
2025-11-22 21:51:46 - GraphTrainer - INFO -   mrr@10: 0.019325
2025-11-22 21:51:46 - GraphTrainer - INFO -   precision@20: 0.003975
2025-11-22 21:51:46 - GraphTrainer - INFO -   recall@20: 0.075148
2025-11-22 21:51:46 - GraphTrainer - INFO -   hit_rate@20: 0.079043
2025-11-22 21:51:46 - GraphTrainer - INFO -   ndcg@20: 0.032508
2025-11-22 21:51:46 - GraphTrainer - INFO -   map@20: 0.020352
2025-11-22 21:51:46 - GraphTrainer - INFO -   mrr@20: 0.021279
2025-11-22 21:51:46 - GraphTrainer - INFO - 第 81 轮训练完成
2025-11-22 21:51:46 - GraphTrainer - INFO - train_loss: 0.348301
2025-11-22 21:51:46 - GraphTrainer - INFO - precision@5: 0.006500
2025-11-22 21:51:46 - GraphTrainer - INFO - recall@5: 0.030956
2025-11-22 21:51:46 - GraphTrainer - INFO - hit_rate@5: 0.032399
2025-11-22 21:51:46 - GraphTrainer - INFO - ndcg@5: 0.020099
2025-11-22 21:51:46 - GraphTrainer - INFO - map@5: 0.016292
2025-11-22 21:51:46 - GraphTrainer - INFO - mrr@5: 0.016987
2025-11-22 21:51:46 - GraphTrainer - INFO - precision@10: 0.005030
2025-11-22 21:51:46 - GraphTrainer - INFO - recall@10: 0.047603
2025-11-22 21:51:46 - GraphTrainer - INFO - hit_rate@10: 0.050193
2025-11-22 21:51:46 - GraphTrainer - INFO - ndcg@10: 0.025520
2025-11-22 21:51:46 - GraphTrainer - INFO - map@10: 0.018481
2025-11-22 21:51:46 - GraphTrainer - INFO - mrr@10: 0.019325
2025-11-22 21:51:46 - GraphTrainer - INFO - precision@20: 0.003975
2025-11-22 21:51:46 - GraphTrainer - INFO - recall@20: 0.075148
2025-11-22 21:51:46 - GraphTrainer - INFO - hit_rate@20: 0.079043
2025-11-22 21:51:46 - GraphTrainer - INFO - ndcg@20: 0.032508
2025-11-22 21:51:46 - GraphTrainer - INFO - map@20: 0.020352
2025-11-22 21:51:46 - GraphTrainer - INFO - mrr@20: 0.021279
2025-11-22 21:51:46 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:51:46 - GraphTrainer - INFO - ============================================================
2025-11-22 21:51:46 - GraphTrainer - INFO - 开始第 82/1000 轮训练
2025-11-22 21:51:46 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3517, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3525, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3702, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3605, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3633, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3573, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3537, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3635, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3565, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3502, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3534, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3555, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3517, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3604, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3563, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3599, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3729, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3137, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3574, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3506, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3648, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3656, device='cuda:0', grad_fn=<AddBackward0>)
The 81 training average loss: 0.34830072676313334
2025-11-22 21:51:57 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:51:57 - GraphTrainer - INFO -   precision@5: 0.006747
2025-11-22 21:51:57 - GraphTrainer - INFO -   recall@5: 0.032189
2025-11-22 21:51:57 - GraphTrainer - INFO -   hit_rate@5: 0.033685
2025-11-22 21:51:57 - GraphTrainer - INFO -   ndcg@5: 0.020802
2025-11-22 21:51:57 - GraphTrainer - INFO -   map@5: 0.016828
2025-11-22 21:51:57 - GraphTrainer - INFO -   mrr@5: 0.017546
2025-11-22 21:51:57 - GraphTrainer - INFO -   precision@10: 0.005215
2025-11-22 21:51:57 - GraphTrainer - INFO -   recall@10: 0.049756
2025-11-22 21:51:57 - GraphTrainer - INFO -   hit_rate@10: 0.052044
2025-11-22 21:51:57 - GraphTrainer - INFO -   ndcg@10: 0.026458
2025-11-22 21:51:57 - GraphTrainer - INFO -   map@10: 0.019099
2025-11-22 21:51:57 - GraphTrainer - INFO -   mrr@10: 0.019925
2025-11-22 21:51:57 - GraphTrainer - INFO -   precision@20: 0.004024
2025-11-22 21:51:57 - GraphTrainer - INFO -   recall@20: 0.076102
2025-11-22 21:51:57 - GraphTrainer - INFO -   hit_rate@20: 0.080175
2025-11-22 21:51:57 - GraphTrainer - INFO -   ndcg@20: 0.033184
2025-11-22 21:51:57 - GraphTrainer - INFO -   map@20: 0.020900
2025-11-22 21:51:57 - GraphTrainer - INFO -   mrr@20: 0.021845
2025-11-22 21:51:57 - GraphTrainer - INFO - 第 82 轮训练完成
2025-11-22 21:51:57 - GraphTrainer - INFO - train_loss: 0.351214
2025-11-22 21:51:57 - GraphTrainer - INFO - precision@5: 0.006747
2025-11-22 21:51:57 - GraphTrainer - INFO - recall@5: 0.032189
2025-11-22 21:51:57 - GraphTrainer - INFO - hit_rate@5: 0.033685
2025-11-22 21:51:57 - GraphTrainer - INFO - ndcg@5: 0.020802
2025-11-22 21:51:57 - GraphTrainer - INFO - map@5: 0.016828
2025-11-22 21:51:57 - GraphTrainer - INFO - mrr@5: 0.017546
2025-11-22 21:51:57 - GraphTrainer - INFO - precision@10: 0.005215
2025-11-22 21:51:57 - GraphTrainer - INFO - recall@10: 0.049756
2025-11-22 21:51:57 - GraphTrainer - INFO - hit_rate@10: 0.052044
2025-11-22 21:51:57 - GraphTrainer - INFO - ndcg@10: 0.026458
2025-11-22 21:51:57 - GraphTrainer - INFO - map@10: 0.019099
2025-11-22 21:51:57 - GraphTrainer - INFO - mrr@10: 0.019925
2025-11-22 21:51:57 - GraphTrainer - INFO - precision@20: 0.004024
2025-11-22 21:51:57 - GraphTrainer - INFO - recall@20: 0.076102
2025-11-22 21:51:57 - GraphTrainer - INFO - hit_rate@20: 0.080175
2025-11-22 21:51:57 - GraphTrainer - INFO - ndcg@20: 0.033184
2025-11-22 21:51:57 - GraphTrainer - INFO - map@20: 0.020900
2025-11-22 21:51:57 - GraphTrainer - INFO - mrr@20: 0.021845
2025-11-22 21:51:57 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:51:57 - GraphTrainer - INFO - ============================================================
2025-11-22 21:51:57 - GraphTrainer - INFO - 开始第 83/1000 轮训练
2025-11-22 21:51:57 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3257, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3479, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3548, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3557, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3549, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3659, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3748, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3106, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3518, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3464, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3788, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3263, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3510, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3577, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3555, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3636, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3575, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3619, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3734, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3643, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3677, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3699, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3646, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3455, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3637, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3506, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3467, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3688, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3815, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3656, device='cuda:0', grad_fn=<AddBackward0>)
The 82 training average loss: 0.3512143903765185
2025-11-22 21:52:08 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:52:08 - GraphTrainer - INFO -   precision@5: 0.006367
2025-11-22 21:52:08 - GraphTrainer - INFO -   recall@5: 0.030454
2025-11-22 21:52:08 - GraphTrainer - INFO -   hit_rate@5: 0.031782
2025-11-22 21:52:08 - GraphTrainer - INFO -   ndcg@5: 0.019699
2025-11-22 21:52:08 - GraphTrainer - INFO -   map@5: 0.015952
2025-11-22 21:52:08 - GraphTrainer - INFO -   mrr@5: 0.016572
2025-11-22 21:52:08 - GraphTrainer - INFO -   precision@10: 0.005060
2025-11-22 21:52:08 - GraphTrainer - INFO -   recall@10: 0.048158
2025-11-22 21:52:08 - GraphTrainer - INFO -   hit_rate@10: 0.050450
2025-11-22 21:52:08 - GraphTrainer - INFO -   ndcg@10: 0.025464
2025-11-22 21:52:08 - GraphTrainer - INFO -   map@10: 0.018297
2025-11-22 21:52:08 - GraphTrainer - INFO -   mrr@10: 0.019035
2025-11-22 21:52:08 - GraphTrainer - INFO -   precision@20: 0.003973
2025-11-22 21:52:08 - GraphTrainer - INFO -   recall@20: 0.075174
2025-11-22 21:52:08 - GraphTrainer - INFO -   hit_rate@20: 0.079095
2025-11-22 21:52:08 - GraphTrainer - INFO -   ndcg@20: 0.032308
2025-11-22 21:52:08 - GraphTrainer - INFO -   map@20: 0.020109
2025-11-22 21:52:08 - GraphTrainer - INFO -   mrr@20: 0.020958
2025-11-22 21:52:08 - GraphTrainer - INFO - 第 83 轮训练完成
2025-11-22 21:52:08 - GraphTrainer - INFO - train_loss: 0.351422
2025-11-22 21:52:08 - GraphTrainer - INFO - precision@5: 0.006367
2025-11-22 21:52:08 - GraphTrainer - INFO - recall@5: 0.030454
2025-11-22 21:52:08 - GraphTrainer - INFO - hit_rate@5: 0.031782
2025-11-22 21:52:08 - GraphTrainer - INFO - ndcg@5: 0.019699
2025-11-22 21:52:08 - GraphTrainer - INFO - map@5: 0.015952
2025-11-22 21:52:08 - GraphTrainer - INFO - mrr@5: 0.016572
2025-11-22 21:52:08 - GraphTrainer - INFO - precision@10: 0.005060
2025-11-22 21:52:08 - GraphTrainer - INFO - recall@10: 0.048158
2025-11-22 21:52:08 - GraphTrainer - INFO - hit_rate@10: 0.050450
2025-11-22 21:52:08 - GraphTrainer - INFO - ndcg@10: 0.025464
2025-11-22 21:52:08 - GraphTrainer - INFO - map@10: 0.018297
2025-11-22 21:52:08 - GraphTrainer - INFO - mrr@10: 0.019035
2025-11-22 21:52:08 - GraphTrainer - INFO - precision@20: 0.003973
2025-11-22 21:52:08 - GraphTrainer - INFO - recall@20: 0.075174
2025-11-22 21:52:08 - GraphTrainer - INFO - hit_rate@20: 0.079095
2025-11-22 21:52:08 - GraphTrainer - INFO - ndcg@20: 0.032308
2025-11-22 21:52:08 - GraphTrainer - INFO - map@20: 0.020109
2025-11-22 21:52:08 - GraphTrainer - INFO - mrr@20: 0.020958
2025-11-22 21:52:08 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:52:08 - GraphTrainer - INFO - ============================================================
2025-11-22 21:52:08 - GraphTrainer - INFO - 开始第 84/1000 轮训练
2025-11-22 21:52:08 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3555, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3637, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3547, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3650, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3525, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3534, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3435, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3569, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3683, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3741, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3568, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3559, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3683, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3626, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3664, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3685, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3518, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3531, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3592, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3717, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3518, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3466, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3694, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3494, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3555, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3566, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3603, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
The 83 training average loss: 0.3514215175447793
2025-11-22 21:52:19 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:52:19 - GraphTrainer - INFO -   precision@5: 0.006336
2025-11-22 21:52:19 - GraphTrainer - INFO -   recall@5: 0.030145
2025-11-22 21:52:19 - GraphTrainer - INFO -   hit_rate@5: 0.031628
2025-11-22 21:52:19 - GraphTrainer - INFO -   ndcg@5: 0.019446
2025-11-22 21:52:19 - GraphTrainer - INFO -   map@5: 0.015695
2025-11-22 21:52:19 - GraphTrainer - INFO -   mrr@5: 0.016380
2025-11-22 21:52:19 - GraphTrainer - INFO -   precision@10: 0.005050
2025-11-22 21:52:19 - GraphTrainer - INFO -   recall@10: 0.047921
2025-11-22 21:52:19 - GraphTrainer - INFO -   hit_rate@10: 0.050399
2025-11-22 21:52:19 - GraphTrainer - INFO -   ndcg@10: 0.025189
2025-11-22 21:52:19 - GraphTrainer - INFO -   map@10: 0.018002
2025-11-22 21:52:19 - GraphTrainer - INFO -   mrr@10: 0.018815
2025-11-22 21:52:19 - GraphTrainer - INFO -   precision@20: 0.004029
2025-11-22 21:52:19 - GraphTrainer - INFO -   recall@20: 0.076148
2025-11-22 21:52:19 - GraphTrainer - INFO -   hit_rate@20: 0.079969
2025-11-22 21:52:19 - GraphTrainer - INFO -   ndcg@20: 0.032363
2025-11-22 21:52:19 - GraphTrainer - INFO -   map@20: 0.019925
2025-11-22 21:52:19 - GraphTrainer - INFO -   mrr@20: 0.020828
2025-11-22 21:52:19 - GraphTrainer - INFO - 第 84 轮训练完成
2025-11-22 21:52:19 - GraphTrainer - INFO - train_loss: 0.349303
2025-11-22 21:52:19 - GraphTrainer - INFO - precision@5: 0.006336
2025-11-22 21:52:19 - GraphTrainer - INFO - recall@5: 0.030145
2025-11-22 21:52:19 - GraphTrainer - INFO - hit_rate@5: 0.031628
2025-11-22 21:52:19 - GraphTrainer - INFO - ndcg@5: 0.019446
2025-11-22 21:52:19 - GraphTrainer - INFO - map@5: 0.015695
2025-11-22 21:52:19 - GraphTrainer - INFO - mrr@5: 0.016380
2025-11-22 21:52:19 - GraphTrainer - INFO - precision@10: 0.005050
2025-11-22 21:52:19 - GraphTrainer - INFO - recall@10: 0.047921
2025-11-22 21:52:19 - GraphTrainer - INFO - hit_rate@10: 0.050399
2025-11-22 21:52:19 - GraphTrainer - INFO - ndcg@10: 0.025189
2025-11-22 21:52:19 - GraphTrainer - INFO - map@10: 0.018002
2025-11-22 21:52:19 - GraphTrainer - INFO - mrr@10: 0.018815
2025-11-22 21:52:19 - GraphTrainer - INFO - precision@20: 0.004029
2025-11-22 21:52:19 - GraphTrainer - INFO - recall@20: 0.076148
2025-11-22 21:52:19 - GraphTrainer - INFO - hit_rate@20: 0.079969
2025-11-22 21:52:19 - GraphTrainer - INFO - ndcg@20: 0.032363
2025-11-22 21:52:19 - GraphTrainer - INFO - map@20: 0.019925
2025-11-22 21:52:19 - GraphTrainer - INFO - mrr@20: 0.020828
2025-11-22 21:52:19 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:52:19 - GraphTrainer - INFO - ============================================================
2025-11-22 21:52:19 - GraphTrainer - INFO - 开始第 85/1000 轮训练
2025-11-22 21:52:19 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3539, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3557, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3642, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3549, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3223, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3668, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3510, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3708, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3466, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3571, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3561, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3626, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3536, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3532, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3549, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3492, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3632, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3619, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3692, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3596, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3279, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3468, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3462, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3627, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3612, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3293, device='cuda:0', grad_fn=<AddBackward0>)
The 84 training average loss: 0.3493028103277601
2025-11-22 21:52:30 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:52:30 - GraphTrainer - INFO -   precision@5: 0.006305
2025-11-22 21:52:30 - GraphTrainer - INFO -   recall@5: 0.029986
2025-11-22 21:52:30 - GraphTrainer - INFO -   hit_rate@5: 0.031473
2025-11-22 21:52:30 - GraphTrainer - INFO -   ndcg@5: 0.019483
2025-11-22 21:52:30 - GraphTrainer - INFO -   map@5: 0.015814
2025-11-22 21:52:30 - GraphTrainer - INFO -   mrr@5: 0.016466
2025-11-22 21:52:30 - GraphTrainer - INFO -   precision@10: 0.005107
2025-11-22 21:52:30 - GraphTrainer - INFO -   recall@10: 0.048631
2025-11-22 21:52:30 - GraphTrainer - INFO -   hit_rate@10: 0.050964
2025-11-22 21:52:30 - GraphTrainer - INFO -   ndcg@10: 0.025532
2025-11-22 21:52:30 - GraphTrainer - INFO -   map@10: 0.018273
2025-11-22 21:52:30 - GraphTrainer - INFO -   mrr@10: 0.019030
2025-11-22 21:52:30 - GraphTrainer - INFO -   precision@20: 0.003934
2025-11-22 21:52:30 - GraphTrainer - INFO -   recall@20: 0.074492
2025-11-22 21:52:30 - GraphTrainer - INFO -   hit_rate@20: 0.078375
2025-11-22 21:52:30 - GraphTrainer - INFO -   ndcg@20: 0.032127
2025-11-22 21:52:30 - GraphTrainer - INFO -   map@20: 0.020045
2025-11-22 21:52:30 - GraphTrainer - INFO -   mrr@20: 0.020906
2025-11-22 21:52:30 - GraphTrainer - INFO - 第 85 轮训练完成
2025-11-22 21:52:30 - GraphTrainer - INFO - train_loss: 0.348150
2025-11-22 21:52:30 - GraphTrainer - INFO - precision@5: 0.006305
2025-11-22 21:52:30 - GraphTrainer - INFO - recall@5: 0.029986
2025-11-22 21:52:30 - GraphTrainer - INFO - hit_rate@5: 0.031473
2025-11-22 21:52:30 - GraphTrainer - INFO - ndcg@5: 0.019483
2025-11-22 21:52:30 - GraphTrainer - INFO - map@5: 0.015814
2025-11-22 21:52:30 - GraphTrainer - INFO - mrr@5: 0.016466
2025-11-22 21:52:30 - GraphTrainer - INFO - precision@10: 0.005107
2025-11-22 21:52:30 - GraphTrainer - INFO - recall@10: 0.048631
2025-11-22 21:52:30 - GraphTrainer - INFO - hit_rate@10: 0.050964
2025-11-22 21:52:30 - GraphTrainer - INFO - ndcg@10: 0.025532
2025-11-22 21:52:30 - GraphTrainer - INFO - map@10: 0.018273
2025-11-22 21:52:30 - GraphTrainer - INFO - mrr@10: 0.019030
2025-11-22 21:52:30 - GraphTrainer - INFO - precision@20: 0.003934
2025-11-22 21:52:30 - GraphTrainer - INFO - recall@20: 0.074492
2025-11-22 21:52:30 - GraphTrainer - INFO - hit_rate@20: 0.078375
2025-11-22 21:52:30 - GraphTrainer - INFO - ndcg@20: 0.032127
2025-11-22 21:52:30 - GraphTrainer - INFO - map@20: 0.020045
2025-11-22 21:52:30 - GraphTrainer - INFO - mrr@20: 0.020906
2025-11-22 21:52:30 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:52:30 - GraphTrainer - INFO - ============================================================
2025-11-22 21:52:30 - GraphTrainer - INFO - 开始第 86/1000 轮训练
2025-11-22 21:52:30 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3179, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3464, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3612, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3457, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3783, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3103, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3342, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3331, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3637, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3586, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3568, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3554, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3467, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3712, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3509, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3534, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3643, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3574, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3466, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3860, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3531, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3718, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3492, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3563, device='cuda:0', grad_fn=<AddBackward0>)
The 85 training average loss: 0.34814989618186293
2025-11-22 21:52:41 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:52:41 - GraphTrainer - INFO -   precision@5: 0.006295
2025-11-22 21:52:41 - GraphTrainer - INFO -   recall@5: 0.029995
2025-11-22 21:52:41 - GraphTrainer - INFO -   hit_rate@5: 0.031422
2025-11-22 21:52:41 - GraphTrainer - INFO -   ndcg@5: 0.019274
2025-11-22 21:52:41 - GraphTrainer - INFO -   map@5: 0.015550
2025-11-22 21:52:41 - GraphTrainer - INFO -   mrr@5: 0.016165
2025-11-22 21:52:41 - GraphTrainer - INFO -   precision@10: 0.005174
2025-11-22 21:52:41 - GraphTrainer - INFO -   recall@10: 0.049173
2025-11-22 21:52:41 - GraphTrainer - INFO -   hit_rate@10: 0.051633
2025-11-22 21:52:41 - GraphTrainer - INFO -   ndcg@10: 0.025499
2025-11-22 21:52:41 - GraphTrainer - INFO -   map@10: 0.018071
2025-11-22 21:52:41 - GraphTrainer - INFO -   mrr@10: 0.018819
2025-11-22 21:52:41 - GraphTrainer - INFO -   precision@20: 0.003983
2025-11-22 21:52:41 - GraphTrainer - INFO -   recall@20: 0.075444
2025-11-22 21:52:41 - GraphTrainer - INFO -   hit_rate@20: 0.079249
2025-11-22 21:52:41 - GraphTrainer - INFO -   ndcg@20: 0.032169
2025-11-22 21:52:41 - GraphTrainer - INFO -   map@20: 0.019854
2025-11-22 21:52:41 - GraphTrainer - INFO -   mrr@20: 0.020693
2025-11-22 21:52:41 - GraphTrainer - INFO - 第 86 轮训练完成
2025-11-22 21:52:41 - GraphTrainer - INFO - train_loss: 0.349782
2025-11-22 21:52:41 - GraphTrainer - INFO - precision@5: 0.006295
2025-11-22 21:52:41 - GraphTrainer - INFO - recall@5: 0.029995
2025-11-22 21:52:41 - GraphTrainer - INFO - hit_rate@5: 0.031422
2025-11-22 21:52:41 - GraphTrainer - INFO - ndcg@5: 0.019274
2025-11-22 21:52:41 - GraphTrainer - INFO - map@5: 0.015550
2025-11-22 21:52:41 - GraphTrainer - INFO - mrr@5: 0.016165
2025-11-22 21:52:41 - GraphTrainer - INFO - precision@10: 0.005174
2025-11-22 21:52:41 - GraphTrainer - INFO - recall@10: 0.049173
2025-11-22 21:52:41 - GraphTrainer - INFO - hit_rate@10: 0.051633
2025-11-22 21:52:41 - GraphTrainer - INFO - ndcg@10: 0.025499
2025-11-22 21:52:41 - GraphTrainer - INFO - map@10: 0.018071
2025-11-22 21:52:41 - GraphTrainer - INFO - mrr@10: 0.018819
2025-11-22 21:52:41 - GraphTrainer - INFO - precision@20: 0.003983
2025-11-22 21:52:41 - GraphTrainer - INFO - recall@20: 0.075444
2025-11-22 21:52:41 - GraphTrainer - INFO - hit_rate@20: 0.079249
2025-11-22 21:52:41 - GraphTrainer - INFO - ndcg@20: 0.032169
2025-11-22 21:52:41 - GraphTrainer - INFO - map@20: 0.019854
2025-11-22 21:52:41 - GraphTrainer - INFO - mrr@20: 0.020693
2025-11-22 21:52:41 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:52:41 - GraphTrainer - INFO - ============================================================
2025-11-22 21:52:41 - GraphTrainer - INFO - 开始第 87/1000 轮训练
2025-11-22 21:52:41 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3259, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3628, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3579, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3312, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3290, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3559, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3634, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3599, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3714, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3331, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3764, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3865, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3376, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3529, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3573, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3565, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3592, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3556, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3595, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3186, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3658, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3506, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3824, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3631, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3685, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3502, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3651, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3516, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3632, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
The 86 training average loss: 0.3497822983511563
2025-11-22 21:52:52 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:52:52 - GraphTrainer - INFO -   precision@5: 0.006449
2025-11-22 21:52:52 - GraphTrainer - INFO -   recall@5: 0.030914
2025-11-22 21:52:52 - GraphTrainer - INFO -   hit_rate@5: 0.032193
2025-11-22 21:52:52 - GraphTrainer - INFO -   ndcg@5: 0.019662
2025-11-22 21:52:52 - GraphTrainer - INFO -   map@5: 0.015791
2025-11-22 21:52:52 - GraphTrainer - INFO -   mrr@5: 0.016371
2025-11-22 21:52:52 - GraphTrainer - INFO -   precision@10: 0.005179
2025-11-22 21:52:52 - GraphTrainer - INFO -   recall@10: 0.049122
2025-11-22 21:52:52 - GraphTrainer - INFO -   hit_rate@10: 0.051684
2025-11-22 21:52:52 - GraphTrainer - INFO -   ndcg@10: 0.025598
2025-11-22 21:52:52 - GraphTrainer - INFO -   map@10: 0.018192
2025-11-22 21:52:52 - GraphTrainer - INFO -   mrr@10: 0.018932
2025-11-22 21:52:52 - GraphTrainer - INFO -   precision@20: 0.003980
2025-11-22 21:52:52 - GraphTrainer - INFO -   recall@20: 0.075331
2025-11-22 21:52:52 - GraphTrainer - INFO -   hit_rate@20: 0.079249
2025-11-22 21:52:52 - GraphTrainer - INFO -   ndcg@20: 0.032235
2025-11-22 21:52:52 - GraphTrainer - INFO -   map@20: 0.019957
2025-11-22 21:52:52 - GraphTrainer - INFO -   mrr@20: 0.020787
2025-11-22 21:52:52 - GraphTrainer - INFO - 第 87 轮训练完成
2025-11-22 21:52:52 - GraphTrainer - INFO - train_loss: 0.346562
2025-11-22 21:52:52 - GraphTrainer - INFO - precision@5: 0.006449
2025-11-22 21:52:52 - GraphTrainer - INFO - recall@5: 0.030914
2025-11-22 21:52:52 - GraphTrainer - INFO - hit_rate@5: 0.032193
2025-11-22 21:52:52 - GraphTrainer - INFO - ndcg@5: 0.019662
2025-11-22 21:52:52 - GraphTrainer - INFO - map@5: 0.015791
2025-11-22 21:52:52 - GraphTrainer - INFO - mrr@5: 0.016371
2025-11-22 21:52:52 - GraphTrainer - INFO - precision@10: 0.005179
2025-11-22 21:52:52 - GraphTrainer - INFO - recall@10: 0.049122
2025-11-22 21:52:52 - GraphTrainer - INFO - hit_rate@10: 0.051684
2025-11-22 21:52:52 - GraphTrainer - INFO - ndcg@10: 0.025598
2025-11-22 21:52:52 - GraphTrainer - INFO - map@10: 0.018192
2025-11-22 21:52:52 - GraphTrainer - INFO - mrr@10: 0.018932
2025-11-22 21:52:52 - GraphTrainer - INFO - precision@20: 0.003980
2025-11-22 21:52:52 - GraphTrainer - INFO - recall@20: 0.075331
2025-11-22 21:52:52 - GraphTrainer - INFO - hit_rate@20: 0.079249
2025-11-22 21:52:52 - GraphTrainer - INFO - ndcg@20: 0.032235
2025-11-22 21:52:52 - GraphTrainer - INFO - map@20: 0.019957
2025-11-22 21:52:52 - GraphTrainer - INFO - mrr@20: 0.020787
2025-11-22 21:52:52 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:52:52 - GraphTrainer - INFO - ============================================================
2025-11-22 21:52:52 - GraphTrainer - INFO - 开始第 88/1000 轮训练
2025-11-22 21:52:52 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3730, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3484, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3554, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3554, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3689, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3209, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3494, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3200, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3464, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3279, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3661, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3680, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3761, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3137, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3702, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3619, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3605, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3577, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3597, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3531, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
The 87 training average loss: 0.3465622992351137
2025-11-22 21:53:04 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:53:04 - GraphTrainer - INFO -   precision@5: 0.006531
2025-11-22 21:53:04 - GraphTrainer - INFO -   recall@5: 0.031091
2025-11-22 21:53:04 - GraphTrainer - INFO -   hit_rate@5: 0.032605
2025-11-22 21:53:04 - GraphTrainer - INFO -   ndcg@5: 0.020063
2025-11-22 21:53:04 - GraphTrainer - INFO -   map@5: 0.016211
2025-11-22 21:53:04 - GraphTrainer - INFO -   mrr@5: 0.016917
2025-11-22 21:53:04 - GraphTrainer - INFO -   precision@10: 0.005230
2025-11-22 21:53:04 - GraphTrainer - INFO -   recall@10: 0.049606
2025-11-22 21:53:04 - GraphTrainer - INFO -   hit_rate@10: 0.052199
2025-11-22 21:53:04 - GraphTrainer - INFO -   ndcg@10: 0.026068
2025-11-22 21:53:04 - GraphTrainer - INFO -   map@10: 0.018637
2025-11-22 21:53:04 - GraphTrainer - INFO -   mrr@10: 0.019476
2025-11-22 21:53:04 - GraphTrainer - INFO -   precision@20: 0.004042
2025-11-22 21:53:04 - GraphTrainer - INFO -   recall@20: 0.076468
2025-11-22 21:53:04 - GraphTrainer - INFO -   hit_rate@20: 0.080483
2025-11-22 21:53:04 - GraphTrainer - INFO -   ndcg@20: 0.032870
2025-11-22 21:53:04 - GraphTrainer - INFO -   map@20: 0.020446
2025-11-22 21:53:04 - GraphTrainer - INFO -   mrr@20: 0.021377
2025-11-22 21:53:04 - GraphTrainer - INFO - 第 88 轮训练完成
2025-11-22 21:53:04 - GraphTrainer - INFO - train_loss: 0.344527
2025-11-22 21:53:04 - GraphTrainer - INFO - precision@5: 0.006531
2025-11-22 21:53:04 - GraphTrainer - INFO - recall@5: 0.031091
2025-11-22 21:53:04 - GraphTrainer - INFO - hit_rate@5: 0.032605
2025-11-22 21:53:04 - GraphTrainer - INFO - ndcg@5: 0.020063
2025-11-22 21:53:04 - GraphTrainer - INFO - map@5: 0.016211
2025-11-22 21:53:04 - GraphTrainer - INFO - mrr@5: 0.016917
2025-11-22 21:53:04 - GraphTrainer - INFO - precision@10: 0.005230
2025-11-22 21:53:04 - GraphTrainer - INFO - recall@10: 0.049606
2025-11-22 21:53:04 - GraphTrainer - INFO - hit_rate@10: 0.052199
2025-11-22 21:53:04 - GraphTrainer - INFO - ndcg@10: 0.026068
2025-11-22 21:53:04 - GraphTrainer - INFO - map@10: 0.018637
2025-11-22 21:53:04 - GraphTrainer - INFO - mrr@10: 0.019476
2025-11-22 21:53:04 - GraphTrainer - INFO - precision@20: 0.004042
2025-11-22 21:53:04 - GraphTrainer - INFO - recall@20: 0.076468
2025-11-22 21:53:04 - GraphTrainer - INFO - hit_rate@20: 0.080483
2025-11-22 21:53:04 - GraphTrainer - INFO - ndcg@20: 0.032870
2025-11-22 21:53:04 - GraphTrainer - INFO - map@20: 0.020446
2025-11-22 21:53:04 - GraphTrainer - INFO - mrr@20: 0.021377
2025-11-22 21:53:04 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:53:04 - GraphTrainer - INFO - ============================================================
2025-11-22 21:53:04 - GraphTrainer - INFO - 开始第 89/1000 轮训练
2025-11-22 21:53:04 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3565, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3521, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3795, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3626, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3575, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3648, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3273, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3616, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3211, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3534, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3302, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3566, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3516, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3720, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3204, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3560, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3480, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3490, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3613, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3506, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3554, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3129, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3639, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3580, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
The 88 training average loss: 0.34452695733514327
2025-11-22 21:53:15 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:53:15 - GraphTrainer - INFO -   precision@5: 0.006398
2025-11-22 21:53:15 - GraphTrainer - INFO -   recall@5: 0.030559
2025-11-22 21:53:15 - GraphTrainer - INFO -   hit_rate@5: 0.031936
2025-11-22 21:53:15 - GraphTrainer - INFO -   ndcg@5: 0.020162
2025-11-22 21:53:15 - GraphTrainer - INFO -   map@5: 0.016547
2025-11-22 21:53:15 - GraphTrainer - INFO -   mrr@5: 0.017206
2025-11-22 21:53:15 - GraphTrainer - INFO -   precision@10: 0.005199
2025-11-22 21:53:15 - GraphTrainer - INFO -   recall@10: 0.049385
2025-11-22 21:53:15 - GraphTrainer - INFO -   hit_rate@10: 0.051890
2025-11-22 21:53:15 - GraphTrainer - INFO -   ndcg@10: 0.026282
2025-11-22 21:53:15 - GraphTrainer - INFO -   map@10: 0.019023
2025-11-22 21:53:15 - GraphTrainer - INFO -   mrr@10: 0.019832
2025-11-22 21:53:15 - GraphTrainer - INFO -   precision@20: 0.004027
2025-11-22 21:53:15 - GraphTrainer - INFO -   recall@20: 0.076185
2025-11-22 21:53:15 - GraphTrainer - INFO -   hit_rate@20: 0.080226
2025-11-22 21:53:15 - GraphTrainer - INFO -   ndcg@20: 0.033075
2025-11-22 21:53:15 - GraphTrainer - INFO -   map@20: 0.020830
2025-11-22 21:53:15 - GraphTrainer - INFO -   mrr@20: 0.021739
2025-11-22 21:53:15 - GraphTrainer - INFO - 第 89 轮训练完成
2025-11-22 21:53:15 - GraphTrainer - INFO - train_loss: 0.347351
2025-11-22 21:53:15 - GraphTrainer - INFO - precision@5: 0.006398
2025-11-22 21:53:15 - GraphTrainer - INFO - recall@5: 0.030559
2025-11-22 21:53:15 - GraphTrainer - INFO - hit_rate@5: 0.031936
2025-11-22 21:53:15 - GraphTrainer - INFO - ndcg@5: 0.020162
2025-11-22 21:53:15 - GraphTrainer - INFO - map@5: 0.016547
2025-11-22 21:53:15 - GraphTrainer - INFO - mrr@5: 0.017206
2025-11-22 21:53:15 - GraphTrainer - INFO - precision@10: 0.005199
2025-11-22 21:53:15 - GraphTrainer - INFO - recall@10: 0.049385
2025-11-22 21:53:15 - GraphTrainer - INFO - hit_rate@10: 0.051890
2025-11-22 21:53:15 - GraphTrainer - INFO - ndcg@10: 0.026282
2025-11-22 21:53:15 - GraphTrainer - INFO - map@10: 0.019023
2025-11-22 21:53:15 - GraphTrainer - INFO - mrr@10: 0.019832
2025-11-22 21:53:15 - GraphTrainer - INFO - precision@20: 0.004027
2025-11-22 21:53:15 - GraphTrainer - INFO - recall@20: 0.076185
2025-11-22 21:53:15 - GraphTrainer - INFO - hit_rate@20: 0.080226
2025-11-22 21:53:15 - GraphTrainer - INFO - ndcg@20: 0.033075
2025-11-22 21:53:15 - GraphTrainer - INFO - map@20: 0.020830
2025-11-22 21:53:15 - GraphTrainer - INFO - mrr@20: 0.021739
2025-11-22 21:53:15 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:53:15 - GraphTrainer - INFO - ============================================================
2025-11-22 21:53:15 - GraphTrainer - INFO - 开始第 90/1000 轮训练
2025-11-22 21:53:15 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3536, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3263, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3702, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3272, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3644, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3612, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3512, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3695, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3647, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3521, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3457, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3551, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3517, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3234, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3223, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3665, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3556, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3607, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3607, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3635, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3637, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3539, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
The 89 training average loss: 0.3473510844954129
2025-11-22 21:53:26 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:53:26 - GraphTrainer - INFO -   precision@5: 0.006408
2025-11-22 21:53:26 - GraphTrainer - INFO -   recall@5: 0.030492
2025-11-22 21:53:26 - GraphTrainer - INFO -   hit_rate@5: 0.031988
2025-11-22 21:53:26 - GraphTrainer - INFO -   ndcg@5: 0.019855
2025-11-22 21:53:26 - GraphTrainer - INFO -   map@5: 0.016143
2025-11-22 21:53:26 - GraphTrainer - INFO -   mrr@5: 0.016824
2025-11-22 21:53:26 - GraphTrainer - INFO -   precision@10: 0.005179
2025-11-22 21:53:26 - GraphTrainer - INFO -   recall@10: 0.049143
2025-11-22 21:53:26 - GraphTrainer - INFO -   hit_rate@10: 0.051684
2025-11-22 21:53:26 - GraphTrainer - INFO -   ndcg@10: 0.025914
2025-11-22 21:53:26 - GraphTrainer - INFO -   map@10: 0.018599
2025-11-22 21:53:26 - GraphTrainer - INFO -   mrr@10: 0.019408
2025-11-22 21:53:26 - GraphTrainer - INFO -   precision@20: 0.004032
2025-11-22 21:53:26 - GraphTrainer - INFO -   recall@20: 0.076210
2025-11-22 21:53:26 - GraphTrainer - INFO -   hit_rate@20: 0.080278
2025-11-22 21:53:26 - GraphTrainer - INFO -   ndcg@20: 0.032813
2025-11-22 21:53:26 - GraphTrainer - INFO -   map@20: 0.020453
2025-11-22 21:53:26 - GraphTrainer - INFO -   mrr@20: 0.021365
2025-11-22 21:53:26 - GraphTrainer - INFO - 第 90 轮训练完成
2025-11-22 21:53:26 - GraphTrainer - INFO - train_loss: 0.345846
2025-11-22 21:53:26 - GraphTrainer - INFO - precision@5: 0.006408
2025-11-22 21:53:26 - GraphTrainer - INFO - recall@5: 0.030492
2025-11-22 21:53:26 - GraphTrainer - INFO - hit_rate@5: 0.031988
2025-11-22 21:53:26 - GraphTrainer - INFO - ndcg@5: 0.019855
2025-11-22 21:53:26 - GraphTrainer - INFO - map@5: 0.016143
2025-11-22 21:53:26 - GraphTrainer - INFO - mrr@5: 0.016824
2025-11-22 21:53:26 - GraphTrainer - INFO - precision@10: 0.005179
2025-11-22 21:53:26 - GraphTrainer - INFO - recall@10: 0.049143
2025-11-22 21:53:26 - GraphTrainer - INFO - hit_rate@10: 0.051684
2025-11-22 21:53:26 - GraphTrainer - INFO - ndcg@10: 0.025914
2025-11-22 21:53:26 - GraphTrainer - INFO - map@10: 0.018599
2025-11-22 21:53:26 - GraphTrainer - INFO - mrr@10: 0.019408
2025-11-22 21:53:26 - GraphTrainer - INFO - precision@20: 0.004032
2025-11-22 21:53:26 - GraphTrainer - INFO - recall@20: 0.076210
2025-11-22 21:53:26 - GraphTrainer - INFO - hit_rate@20: 0.080278
2025-11-22 21:53:26 - GraphTrainer - INFO - ndcg@20: 0.032813
2025-11-22 21:53:26 - GraphTrainer - INFO - map@20: 0.020453
2025-11-22 21:53:26 - GraphTrainer - INFO - mrr@20: 0.021365
2025-11-22 21:53:26 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:53:26 - GraphTrainer - INFO - 检查点已保存: Epoch 90 -> ./checkpoints/checkpoint_epoch_90.pth
2025-11-22 21:53:26 - GraphTrainer - INFO - ============================================================
2025-11-22 21:53:26 - GraphTrainer - INFO - 开始第 91/1000 轮训练
2025-11-22 21:53:26 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3545, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3565, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3532, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3539, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3554, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3462, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3281, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3784, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3775, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3657, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3499, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3557, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3521, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3543, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3657, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3588, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3547, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3633, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3499, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3499, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3139, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3621, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3316, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)
The 90 training average loss: 0.34584569468580445
2025-11-22 21:53:37 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:53:37 - GraphTrainer - INFO -   precision@5: 0.006459
2025-11-22 21:53:37 - GraphTrainer - INFO -   recall@5: 0.030750
2025-11-22 21:53:37 - GraphTrainer - INFO -   hit_rate@5: 0.032245
2025-11-22 21:53:37 - GraphTrainer - INFO -   ndcg@5: 0.020063
2025-11-22 21:53:37 - GraphTrainer - INFO -   map@5: 0.016313
2025-11-22 21:53:37 - GraphTrainer - INFO -   mrr@5: 0.017028
2025-11-22 21:53:37 - GraphTrainer - INFO -   precision@10: 0.005112
2025-11-22 21:53:37 - GraphTrainer - INFO -   recall@10: 0.048532
2025-11-22 21:53:37 - GraphTrainer - INFO -   hit_rate@10: 0.051016
2025-11-22 21:53:37 - GraphTrainer - INFO -   ndcg@10: 0.025841
2025-11-22 21:53:37 - GraphTrainer - INFO -   map@10: 0.018656
2025-11-22 21:53:37 - GraphTrainer - INFO -   mrr@10: 0.019495
2025-11-22 21:53:37 - GraphTrainer - INFO -   precision@20: 0.004060
2025-11-22 21:53:37 - GraphTrainer - INFO -   recall@20: 0.076702
2025-11-22 21:53:37 - GraphTrainer - INFO -   hit_rate@20: 0.080792
2025-11-22 21:53:37 - GraphTrainer - INFO -   ndcg@20: 0.032994
2025-11-22 21:53:37 - GraphTrainer - INFO -   map@20: 0.020563
2025-11-22 21:53:37 - GraphTrainer - INFO -   mrr@20: 0.021508
2025-11-22 21:53:37 - GraphTrainer - INFO - 第 91 轮训练完成
2025-11-22 21:53:37 - GraphTrainer - INFO - train_loss: 0.345274
2025-11-22 21:53:37 - GraphTrainer - INFO - precision@5: 0.006459
2025-11-22 21:53:37 - GraphTrainer - INFO - recall@5: 0.030750
2025-11-22 21:53:37 - GraphTrainer - INFO - hit_rate@5: 0.032245
2025-11-22 21:53:37 - GraphTrainer - INFO - ndcg@5: 0.020063
2025-11-22 21:53:37 - GraphTrainer - INFO - map@5: 0.016313
2025-11-22 21:53:37 - GraphTrainer - INFO - mrr@5: 0.017028
2025-11-22 21:53:37 - GraphTrainer - INFO - precision@10: 0.005112
2025-11-22 21:53:37 - GraphTrainer - INFO - recall@10: 0.048532
2025-11-22 21:53:37 - GraphTrainer - INFO - hit_rate@10: 0.051016
2025-11-22 21:53:37 - GraphTrainer - INFO - ndcg@10: 0.025841
2025-11-22 21:53:37 - GraphTrainer - INFO - map@10: 0.018656
2025-11-22 21:53:37 - GraphTrainer - INFO - mrr@10: 0.019495
2025-11-22 21:53:37 - GraphTrainer - INFO - precision@20: 0.004060
2025-11-22 21:53:37 - GraphTrainer - INFO - recall@20: 0.076702
2025-11-22 21:53:37 - GraphTrainer - INFO - hit_rate@20: 0.080792
2025-11-22 21:53:37 - GraphTrainer - INFO - ndcg@20: 0.032994
2025-11-22 21:53:37 - GraphTrainer - INFO - map@20: 0.020563
2025-11-22 21:53:37 - GraphTrainer - INFO - mrr@20: 0.021508
2025-11-22 21:53:37 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:53:37 - GraphTrainer - INFO - ============================================================
2025-11-22 21:53:37 - GraphTrainer - INFO - 开始第 92/1000 轮训练
2025-11-22 21:53:37 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3274, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3557, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3662, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3576, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3706, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3562, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3318, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3467, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3279, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3525, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3548, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3556, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3555, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3627, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3595, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
The 91 training average loss: 0.3452739006486432
2025-11-22 21:53:48 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:53:48 - GraphTrainer - INFO -   precision@5: 0.006521
2025-11-22 21:53:48 - GraphTrainer - INFO -   recall@5: 0.030959
2025-11-22 21:53:48 - GraphTrainer - INFO -   hit_rate@5: 0.032502
2025-11-22 21:53:48 - GraphTrainer - INFO -   ndcg@5: 0.019977
2025-11-22 21:53:48 - GraphTrainer - INFO -   map@5: 0.016134
2025-11-22 21:53:48 - GraphTrainer - INFO -   mrr@5: 0.016862
2025-11-22 21:53:48 - GraphTrainer - INFO -   precision@10: 0.005071
2025-11-22 21:53:48 - GraphTrainer - INFO -   recall@10: 0.048191
2025-11-22 21:53:48 - GraphTrainer - INFO -   hit_rate@10: 0.050604
2025-11-22 21:53:48 - GraphTrainer - INFO -   ndcg@10: 0.025582
2025-11-22 21:53:48 - GraphTrainer - INFO -   map@10: 0.018416
2025-11-22 21:53:48 - GraphTrainer - INFO -   mrr@10: 0.019258
2025-11-22 21:53:48 - GraphTrainer - INFO -   precision@20: 0.004047
2025-11-22 21:53:48 - GraphTrainer - INFO -   recall@20: 0.076533
2025-11-22 21:53:48 - GraphTrainer - INFO -   hit_rate@20: 0.080535
2025-11-22 21:53:48 - GraphTrainer - INFO -   ndcg@20: 0.032806
2025-11-22 21:53:48 - GraphTrainer - INFO -   map@20: 0.020357
2025-11-22 21:53:48 - GraphTrainer - INFO -   mrr@20: 0.021305
2025-11-22 21:53:48 - GraphTrainer - INFO - 第 92 轮训练完成
2025-11-22 21:53:48 - GraphTrainer - INFO - train_loss: 0.345328
2025-11-22 21:53:48 - GraphTrainer - INFO - precision@5: 0.006521
2025-11-22 21:53:48 - GraphTrainer - INFO - recall@5: 0.030959
2025-11-22 21:53:48 - GraphTrainer - INFO - hit_rate@5: 0.032502
2025-11-22 21:53:48 - GraphTrainer - INFO - ndcg@5: 0.019977
2025-11-22 21:53:48 - GraphTrainer - INFO - map@5: 0.016134
2025-11-22 21:53:48 - GraphTrainer - INFO - mrr@5: 0.016862
2025-11-22 21:53:48 - GraphTrainer - INFO - precision@10: 0.005071
2025-11-22 21:53:48 - GraphTrainer - INFO - recall@10: 0.048191
2025-11-22 21:53:48 - GraphTrainer - INFO - hit_rate@10: 0.050604
2025-11-22 21:53:48 - GraphTrainer - INFO - ndcg@10: 0.025582
2025-11-22 21:53:48 - GraphTrainer - INFO - map@10: 0.018416
2025-11-22 21:53:48 - GraphTrainer - INFO - mrr@10: 0.019258
2025-11-22 21:53:48 - GraphTrainer - INFO - precision@20: 0.004047
2025-11-22 21:53:48 - GraphTrainer - INFO - recall@20: 0.076533
2025-11-22 21:53:48 - GraphTrainer - INFO - hit_rate@20: 0.080535
2025-11-22 21:53:48 - GraphTrainer - INFO - ndcg@20: 0.032806
2025-11-22 21:53:48 - GraphTrainer - INFO - map@20: 0.020357
2025-11-22 21:53:48 - GraphTrainer - INFO - mrr@20: 0.021305
2025-11-22 21:53:48 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:53:48 - GraphTrainer - INFO - ============================================================
2025-11-22 21:53:48 - GraphTrainer - INFO - 开始第 93/1000 轮训练
2025-11-22 21:53:48 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3262, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3473, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3637, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3433, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3590, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3689, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3713, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3619, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3840, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3036, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3543, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3409, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3569, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3136, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3656, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3571, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3521, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3510, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3258, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3509, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)
The 92 training average loss: 0.3453284430092779
2025-11-22 21:53:59 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:53:59 - GraphTrainer - INFO -   precision@5: 0.006696
2025-11-22 21:53:59 - GraphTrainer - INFO -   recall@5: 0.031866
2025-11-22 21:53:59 - GraphTrainer - INFO -   hit_rate@5: 0.033428
2025-11-22 21:53:59 - GraphTrainer - INFO -   ndcg@5: 0.020852
2025-11-22 21:53:59 - GraphTrainer - INFO -   map@5: 0.016998
2025-11-22 21:53:59 - GraphTrainer - INFO -   mrr@5: 0.017707
2025-11-22 21:53:59 - GraphTrainer - INFO -   precision@10: 0.005199
2025-11-22 21:53:59 - GraphTrainer - INFO -   recall@10: 0.049386
2025-11-22 21:53:59 - GraphTrainer - INFO -   hit_rate@10: 0.051890
2025-11-22 21:53:59 - GraphTrainer - INFO -   ndcg@10: 0.026498
2025-11-22 21:53:59 - GraphTrainer - INFO -   map@10: 0.019259
2025-11-22 21:53:59 - GraphTrainer - INFO -   mrr@10: 0.020093
2025-11-22 21:53:59 - GraphTrainer - INFO -   precision@20: 0.004083
2025-11-22 21:53:59 - GraphTrainer - INFO -   recall@20: 0.077277
2025-11-22 21:53:59 - GraphTrainer - INFO -   hit_rate@20: 0.081306
2025-11-22 21:53:59 - GraphTrainer - INFO -   ndcg@20: 0.033573
2025-11-22 21:53:59 - GraphTrainer - INFO -   map@20: 0.021142
2025-11-22 21:53:59 - GraphTrainer - INFO -   mrr@20: 0.022080
2025-11-22 21:53:59 - GraphTrainer - INFO - 第 93 轮训练完成
2025-11-22 21:53:59 - GraphTrainer - INFO - train_loss: 0.344591
2025-11-22 21:53:59 - GraphTrainer - INFO - precision@5: 0.006696
2025-11-22 21:53:59 - GraphTrainer - INFO - recall@5: 0.031866
2025-11-22 21:53:59 - GraphTrainer - INFO - hit_rate@5: 0.033428
2025-11-22 21:53:59 - GraphTrainer - INFO - ndcg@5: 0.020852
2025-11-22 21:53:59 - GraphTrainer - INFO - map@5: 0.016998
2025-11-22 21:53:59 - GraphTrainer - INFO - mrr@5: 0.017707
2025-11-22 21:53:59 - GraphTrainer - INFO - precision@10: 0.005199
2025-11-22 21:53:59 - GraphTrainer - INFO - recall@10: 0.049386
2025-11-22 21:53:59 - GraphTrainer - INFO - hit_rate@10: 0.051890
2025-11-22 21:53:59 - GraphTrainer - INFO - ndcg@10: 0.026498
2025-11-22 21:53:59 - GraphTrainer - INFO - map@10: 0.019259
2025-11-22 21:53:59 - GraphTrainer - INFO - mrr@10: 0.020093
2025-11-22 21:53:59 - GraphTrainer - INFO - precision@20: 0.004083
2025-11-22 21:53:59 - GraphTrainer - INFO - recall@20: 0.077277
2025-11-22 21:53:59 - GraphTrainer - INFO - hit_rate@20: 0.081306
2025-11-22 21:53:59 - GraphTrainer - INFO - ndcg@20: 0.033573
2025-11-22 21:53:59 - GraphTrainer - INFO - map@20: 0.021142
2025-11-22 21:53:59 - GraphTrainer - INFO - mrr@20: 0.022080
2025-11-22 21:53:59 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:53:59 - GraphTrainer - INFO - ============================================================
2025-11-22 21:53:59 - GraphTrainer - INFO - 开始第 94/1000 轮训练
2025-11-22 21:53:59 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3138, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3658, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3577, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3545, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3164, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3579, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3297, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3512, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3373, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3641, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3695, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3263, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3316, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3181, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3464, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3614, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3669, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3623, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3650, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3228, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3269, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3312, device='cuda:0', grad_fn=<AddBackward0>)
The 93 training average loss: 0.34459102718994533
2025-11-22 21:54:10 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:54:10 - GraphTrainer - INFO -   precision@5: 0.006470
2025-11-22 21:54:10 - GraphTrainer - INFO -   recall@5: 0.030787
2025-11-22 21:54:10 - GraphTrainer - INFO -   hit_rate@5: 0.032245
2025-11-22 21:54:10 - GraphTrainer - INFO -   ndcg@5: 0.020165
2025-11-22 21:54:10 - GraphTrainer - INFO -   map@5: 0.016444
2025-11-22 21:54:10 - GraphTrainer - INFO -   mrr@5: 0.017100
2025-11-22 21:54:10 - GraphTrainer - INFO -   precision@10: 0.005235
2025-11-22 21:54:10 - GraphTrainer - INFO -   recall@10: 0.049427
2025-11-22 21:54:10 - GraphTrainer - INFO -   hit_rate@10: 0.052199
2025-11-22 21:54:10 - GraphTrainer - INFO -   ndcg@10: 0.026267
2025-11-22 21:54:10 - GraphTrainer - INFO -   map@10: 0.018924
2025-11-22 21:54:10 - GraphTrainer - INFO -   mrr@10: 0.019752
2025-11-22 21:54:10 - GraphTrainer - INFO -   precision@20: 0.004045
2025-11-22 21:54:10 - GraphTrainer - INFO -   recall@20: 0.076660
2025-11-22 21:54:10 - GraphTrainer - INFO -   hit_rate@20: 0.080586
2025-11-22 21:54:10 - GraphTrainer - INFO -   ndcg@20: 0.033166
2025-11-22 21:54:10 - GraphTrainer - INFO -   map@20: 0.020773
2025-11-22 21:54:10 - GraphTrainer - INFO -   mrr@20: 0.021676
2025-11-22 21:54:10 - GraphTrainer - INFO - 第 94 轮训练完成
2025-11-22 21:54:10 - GraphTrainer - INFO - train_loss: 0.345226
2025-11-22 21:54:10 - GraphTrainer - INFO - precision@5: 0.006470
2025-11-22 21:54:10 - GraphTrainer - INFO - recall@5: 0.030787
2025-11-22 21:54:10 - GraphTrainer - INFO - hit_rate@5: 0.032245
2025-11-22 21:54:10 - GraphTrainer - INFO - ndcg@5: 0.020165
2025-11-22 21:54:10 - GraphTrainer - INFO - map@5: 0.016444
2025-11-22 21:54:10 - GraphTrainer - INFO - mrr@5: 0.017100
2025-11-22 21:54:10 - GraphTrainer - INFO - precision@10: 0.005235
2025-11-22 21:54:10 - GraphTrainer - INFO - recall@10: 0.049427
2025-11-22 21:54:10 - GraphTrainer - INFO - hit_rate@10: 0.052199
2025-11-22 21:54:10 - GraphTrainer - INFO - ndcg@10: 0.026267
2025-11-22 21:54:10 - GraphTrainer - INFO - map@10: 0.018924
2025-11-22 21:54:10 - GraphTrainer - INFO - mrr@10: 0.019752
2025-11-22 21:54:10 - GraphTrainer - INFO - precision@20: 0.004045
2025-11-22 21:54:10 - GraphTrainer - INFO - recall@20: 0.076660
2025-11-22 21:54:10 - GraphTrainer - INFO - hit_rate@20: 0.080586
2025-11-22 21:54:10 - GraphTrainer - INFO - ndcg@20: 0.033166
2025-11-22 21:54:10 - GraphTrainer - INFO - map@20: 0.020773
2025-11-22 21:54:10 - GraphTrainer - INFO - mrr@20: 0.021676
2025-11-22 21:54:10 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:54:10 - GraphTrainer - INFO - ============================================================
2025-11-22 21:54:10 - GraphTrainer - INFO - 开始第 95/1000 轮训练
2025-11-22 21:54:10 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3554, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3494, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3000, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3062, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3704, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3545, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3692, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3517, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3269, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3719, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3196, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3210, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3680, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3772, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3598, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3214, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3421, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3299, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3464, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3210, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3176, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3655, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3492, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3468, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3703, device='cuda:0', grad_fn=<AddBackward0>)
The 94 training average loss: 0.3452255756690584
2025-11-22 21:54:21 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:54:21 - GraphTrainer - INFO -   precision@5: 0.006398
2025-11-22 21:54:21 - GraphTrainer - INFO -   recall@5: 0.030595
2025-11-22 21:54:21 - GraphTrainer - INFO -   hit_rate@5: 0.031936
2025-11-22 21:54:21 - GraphTrainer - INFO -   ndcg@5: 0.020003
2025-11-22 21:54:21 - GraphTrainer - INFO -   map@5: 0.016309
2025-11-22 21:54:21 - GraphTrainer - INFO -   mrr@5: 0.016932
2025-11-22 21:54:21 - GraphTrainer - INFO -   precision@10: 0.005312
2025-11-22 21:54:21 - GraphTrainer - INFO -   recall@10: 0.050372
2025-11-22 21:54:21 - GraphTrainer - INFO -   hit_rate@10: 0.052970
2025-11-22 21:54:21 - GraphTrainer - INFO -   ndcg@10: 0.026475
2025-11-22 21:54:21 - GraphTrainer - INFO -   map@10: 0.018946
2025-11-22 21:54:21 - GraphTrainer - INFO -   mrr@10: 0.019735
2025-11-22 21:54:21 - GraphTrainer - INFO -   precision@20: 0.004063
2025-11-22 21:54:21 - GraphTrainer - INFO -   recall@20: 0.076894
2025-11-22 21:54:21 - GraphTrainer - INFO -   hit_rate@20: 0.080843
2025-11-22 21:54:21 - GraphTrainer - INFO -   ndcg@20: 0.033196
2025-11-22 21:54:21 - GraphTrainer - INFO -   map@20: 0.020737
2025-11-22 21:54:21 - GraphTrainer - INFO -   mrr@20: 0.021612
2025-11-22 21:54:21 - GraphTrainer - INFO - 第 95 轮训练完成
2025-11-22 21:54:21 - GraphTrainer - INFO - train_loss: 0.344091
2025-11-22 21:54:21 - GraphTrainer - INFO - precision@5: 0.006398
2025-11-22 21:54:21 - GraphTrainer - INFO - recall@5: 0.030595
2025-11-22 21:54:21 - GraphTrainer - INFO - hit_rate@5: 0.031936
2025-11-22 21:54:21 - GraphTrainer - INFO - ndcg@5: 0.020003
2025-11-22 21:54:21 - GraphTrainer - INFO - map@5: 0.016309
2025-11-22 21:54:21 - GraphTrainer - INFO - mrr@5: 0.016932
2025-11-22 21:54:21 - GraphTrainer - INFO - precision@10: 0.005312
2025-11-22 21:54:21 - GraphTrainer - INFO - recall@10: 0.050372
2025-11-22 21:54:21 - GraphTrainer - INFO - hit_rate@10: 0.052970
2025-11-22 21:54:21 - GraphTrainer - INFO - ndcg@10: 0.026475
2025-11-22 21:54:21 - GraphTrainer - INFO - map@10: 0.018946
2025-11-22 21:54:21 - GraphTrainer - INFO - mrr@10: 0.019735
2025-11-22 21:54:21 - GraphTrainer - INFO - precision@20: 0.004063
2025-11-22 21:54:21 - GraphTrainer - INFO - recall@20: 0.076894
2025-11-22 21:54:21 - GraphTrainer - INFO - hit_rate@20: 0.080843
2025-11-22 21:54:21 - GraphTrainer - INFO - ndcg@20: 0.033196
2025-11-22 21:54:21 - GraphTrainer - INFO - map@20: 0.020737
2025-11-22 21:54:21 - GraphTrainer - INFO - mrr@20: 0.021612
2025-11-22 21:54:21 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:54:21 - GraphTrainer - INFO - ============================================================
2025-11-22 21:54:21 - GraphTrainer - INFO - 开始第 96/1000 轮训练
2025-11-22 21:54:21 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3537, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3559, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3236, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3507, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3565, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3309, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3136, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3512, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3703, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3760, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3155, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3563, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3190, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3576, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3490, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3602, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3492, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3525, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3653, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3492, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3342, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3529, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3547, device='cuda:0', grad_fn=<AddBackward0>)
The 95 training average loss: 0.3440905449719265
2025-11-22 21:54:32 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:54:32 - GraphTrainer - INFO -   precision@5: 0.006521
2025-11-22 21:54:32 - GraphTrainer - INFO -   recall@5: 0.031072
2025-11-22 21:54:32 - GraphTrainer - INFO -   hit_rate@5: 0.032553
2025-11-22 21:54:32 - GraphTrainer - INFO -   ndcg@5: 0.020045
2025-11-22 21:54:32 - GraphTrainer - INFO -   map@5: 0.016186
2025-11-22 21:54:32 - GraphTrainer - INFO -   mrr@5: 0.016862
2025-11-22 21:54:32 - GraphTrainer - INFO -   precision@10: 0.005215
2025-11-22 21:54:32 - GraphTrainer - INFO -   recall@10: 0.049558
2025-11-22 21:54:32 - GraphTrainer - INFO -   hit_rate@10: 0.051993
2025-11-22 21:54:32 - GraphTrainer - INFO -   ndcg@10: 0.026035
2025-11-22 21:54:32 - GraphTrainer - INFO -   map@10: 0.018609
2025-11-22 21:54:32 - GraphTrainer - INFO -   mrr@10: 0.019405
2025-11-22 21:54:32 - GraphTrainer - INFO -   precision@20: 0.004042
2025-11-22 21:54:32 - GraphTrainer - INFO -   recall@20: 0.076468
2025-11-22 21:54:32 - GraphTrainer - INFO -   hit_rate@20: 0.080483
2025-11-22 21:54:32 - GraphTrainer - INFO -   ndcg@20: 0.032870
2025-11-22 21:54:32 - GraphTrainer - INFO -   map@20: 0.020431
2025-11-22 21:54:32 - GraphTrainer - INFO -   mrr@20: 0.021331
2025-11-22 21:54:32 - GraphTrainer - INFO - 第 96 轮训练完成
2025-11-22 21:54:32 - GraphTrainer - INFO - train_loss: 0.343144
2025-11-22 21:54:32 - GraphTrainer - INFO - precision@5: 0.006521
2025-11-22 21:54:32 - GraphTrainer - INFO - recall@5: 0.031072
2025-11-22 21:54:32 - GraphTrainer - INFO - hit_rate@5: 0.032553
2025-11-22 21:54:32 - GraphTrainer - INFO - ndcg@5: 0.020045
2025-11-22 21:54:32 - GraphTrainer - INFO - map@5: 0.016186
2025-11-22 21:54:32 - GraphTrainer - INFO - mrr@5: 0.016862
2025-11-22 21:54:32 - GraphTrainer - INFO - precision@10: 0.005215
2025-11-22 21:54:32 - GraphTrainer - INFO - recall@10: 0.049558
2025-11-22 21:54:32 - GraphTrainer - INFO - hit_rate@10: 0.051993
2025-11-22 21:54:32 - GraphTrainer - INFO - ndcg@10: 0.026035
2025-11-22 21:54:32 - GraphTrainer - INFO - map@10: 0.018609
2025-11-22 21:54:32 - GraphTrainer - INFO - mrr@10: 0.019405
2025-11-22 21:54:32 - GraphTrainer - INFO - precision@20: 0.004042
2025-11-22 21:54:32 - GraphTrainer - INFO - recall@20: 0.076468
2025-11-22 21:54:32 - GraphTrainer - INFO - hit_rate@20: 0.080483
2025-11-22 21:54:32 - GraphTrainer - INFO - ndcg@20: 0.032870
2025-11-22 21:54:32 - GraphTrainer - INFO - map@20: 0.020431
2025-11-22 21:54:32 - GraphTrainer - INFO - mrr@20: 0.021331
2025-11-22 21:54:32 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:54:32 - GraphTrainer - INFO - ============================================================
2025-11-22 21:54:32 - GraphTrainer - INFO - 开始第 97/1000 轮训练
2025-11-22 21:54:32 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3601, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3588, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3521, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3590, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3316, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3558, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3579, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3257, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3466, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3276, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3318, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3577, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3575, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3281, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3547, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3245, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3654, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3646, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3646, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3156, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3521, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3607, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3551, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3199, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3178, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3480, device='cuda:0', grad_fn=<AddBackward0>)
The 96 training average loss: 0.34314395898375016
2025-11-22 21:54:43 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:54:43 - GraphTrainer - INFO -   precision@5: 0.006418
2025-11-22 21:54:43 - GraphTrainer - INFO -   recall@5: 0.030637
2025-11-22 21:54:43 - GraphTrainer - INFO -   hit_rate@5: 0.031988
2025-11-22 21:54:43 - GraphTrainer - INFO -   ndcg@5: 0.020263
2025-11-22 21:54:43 - GraphTrainer - INFO -   map@5: 0.016638
2025-11-22 21:54:43 - GraphTrainer - INFO -   mrr@5: 0.017301
2025-11-22 21:54:43 - GraphTrainer - INFO -   precision@10: 0.005143
2025-11-22 21:54:43 - GraphTrainer - INFO -   recall@10: 0.048879
2025-11-22 21:54:43 - GraphTrainer - INFO -   hit_rate@10: 0.051324
2025-11-22 21:54:43 - GraphTrainer - INFO -   ndcg@10: 0.026197
2025-11-22 21:54:43 - GraphTrainer - INFO -   map@10: 0.019043
2025-11-22 21:54:43 - GraphTrainer - INFO -   mrr@10: 0.019843
2025-11-22 21:54:43 - GraphTrainer - INFO -   precision@20: 0.004047
2025-11-22 21:54:43 - GraphTrainer - INFO -   recall@20: 0.076601
2025-11-22 21:54:43 - GraphTrainer - INFO -   hit_rate@20: 0.080535
2025-11-22 21:54:43 - GraphTrainer - INFO -   ndcg@20: 0.033249
2025-11-22 21:54:43 - GraphTrainer - INFO -   map@20: 0.020936
2025-11-22 21:54:43 - GraphTrainer - INFO -   mrr@20: 0.021829
2025-11-22 21:54:43 - GraphTrainer - INFO - 第 97 轮训练完成
2025-11-22 21:54:43 - GraphTrainer - INFO - train_loss: 0.348335
2025-11-22 21:54:43 - GraphTrainer - INFO - precision@5: 0.006418
2025-11-22 21:54:43 - GraphTrainer - INFO - recall@5: 0.030637
2025-11-22 21:54:43 - GraphTrainer - INFO - hit_rate@5: 0.031988
2025-11-22 21:54:43 - GraphTrainer - INFO - ndcg@5: 0.020263
2025-11-22 21:54:43 - GraphTrainer - INFO - map@5: 0.016638
2025-11-22 21:54:43 - GraphTrainer - INFO - mrr@5: 0.017301
2025-11-22 21:54:43 - GraphTrainer - INFO - precision@10: 0.005143
2025-11-22 21:54:43 - GraphTrainer - INFO - recall@10: 0.048879
2025-11-22 21:54:43 - GraphTrainer - INFO - hit_rate@10: 0.051324
2025-11-22 21:54:43 - GraphTrainer - INFO - ndcg@10: 0.026197
2025-11-22 21:54:43 - GraphTrainer - INFO - map@10: 0.019043
2025-11-22 21:54:43 - GraphTrainer - INFO - mrr@10: 0.019843
2025-11-22 21:54:43 - GraphTrainer - INFO - precision@20: 0.004047
2025-11-22 21:54:43 - GraphTrainer - INFO - recall@20: 0.076601
2025-11-22 21:54:43 - GraphTrainer - INFO - hit_rate@20: 0.080535
2025-11-22 21:54:43 - GraphTrainer - INFO - ndcg@20: 0.033249
2025-11-22 21:54:43 - GraphTrainer - INFO - map@20: 0.020936
2025-11-22 21:54:43 - GraphTrainer - INFO - mrr@20: 0.021829
2025-11-22 21:54:43 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:54:43 - GraphTrainer - INFO - ============================================================
2025-11-22 21:54:43 - GraphTrainer - INFO - 开始第 98/1000 轮训练
2025-11-22 21:54:43 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3668, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3494, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3230, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3235, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3571, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3241, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3572, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3575, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3278, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3771, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3712, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3614, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3696, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3516, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3576, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3531, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3563, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3603, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3682, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3560, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3506, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3745, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3568, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3601, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3517, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3610, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3689, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3573, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3379, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)
The 97 training average loss: 0.3483347034659879
2025-11-22 21:54:54 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:54:54 - GraphTrainer - INFO -   precision@5: 0.006603
2025-11-22 21:54:54 - GraphTrainer - INFO -   recall@5: 0.031529
2025-11-22 21:54:54 - GraphTrainer - INFO -   hit_rate@5: 0.032913
2025-11-22 21:54:54 - GraphTrainer - INFO -   ndcg@5: 0.020560
2025-11-22 21:54:54 - GraphTrainer - INFO -   map@5: 0.016735
2025-11-22 21:54:54 - GraphTrainer - INFO -   mrr@5: 0.017418
2025-11-22 21:54:54 - GraphTrainer - INFO -   precision@10: 0.005235
2025-11-22 21:54:54 - GraphTrainer - INFO -   recall@10: 0.049894
2025-11-22 21:54:54 - GraphTrainer - INFO -   hit_rate@10: 0.052250
2025-11-22 21:54:54 - GraphTrainer - INFO -   ndcg@10: 0.026481
2025-11-22 21:54:54 - GraphTrainer - INFO -   map@10: 0.019110
2025-11-22 21:54:54 - GraphTrainer - INFO -   mrr@10: 0.019926
2025-11-22 21:54:54 - GraphTrainer - INFO -   precision@20: 0.004014
2025-11-22 21:54:54 - GraphTrainer - INFO -   recall@20: 0.076068
2025-11-22 21:54:54 - GraphTrainer - INFO -   hit_rate@20: 0.079969
2025-11-22 21:54:54 - GraphTrainer - INFO -   ndcg@20: 0.033132
2025-11-22 21:54:54 - GraphTrainer - INFO -   map@20: 0.020884
2025-11-22 21:54:54 - GraphTrainer - INFO -   mrr@20: 0.021802
2025-11-22 21:54:54 - GraphTrainer - INFO - 第 98 轮训练完成
2025-11-22 21:54:54 - GraphTrainer - INFO - train_loss: 0.339410
2025-11-22 21:54:54 - GraphTrainer - INFO - precision@5: 0.006603
2025-11-22 21:54:54 - GraphTrainer - INFO - recall@5: 0.031529
2025-11-22 21:54:54 - GraphTrainer - INFO - hit_rate@5: 0.032913
2025-11-22 21:54:54 - GraphTrainer - INFO - ndcg@5: 0.020560
2025-11-22 21:54:54 - GraphTrainer - INFO - map@5: 0.016735
2025-11-22 21:54:54 - GraphTrainer - INFO - mrr@5: 0.017418
2025-11-22 21:54:54 - GraphTrainer - INFO - precision@10: 0.005235
2025-11-22 21:54:54 - GraphTrainer - INFO - recall@10: 0.049894
2025-11-22 21:54:54 - GraphTrainer - INFO - hit_rate@10: 0.052250
2025-11-22 21:54:54 - GraphTrainer - INFO - ndcg@10: 0.026481
2025-11-22 21:54:54 - GraphTrainer - INFO - map@10: 0.019110
2025-11-22 21:54:54 - GraphTrainer - INFO - mrr@10: 0.019926
2025-11-22 21:54:54 - GraphTrainer - INFO - precision@20: 0.004014
2025-11-22 21:54:54 - GraphTrainer - INFO - recall@20: 0.076068
2025-11-22 21:54:54 - GraphTrainer - INFO - hit_rate@20: 0.079969
2025-11-22 21:54:54 - GraphTrainer - INFO - ndcg@20: 0.033132
2025-11-22 21:54:54 - GraphTrainer - INFO - map@20: 0.020884
2025-11-22 21:54:54 - GraphTrainer - INFO - mrr@20: 0.021802
2025-11-22 21:54:54 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:54:54 - GraphTrainer - INFO - ============================================================
2025-11-22 21:54:54 - GraphTrainer - INFO - 开始第 99/1000 轮训练
2025-11-22 21:54:54 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3299, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3288, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3342, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3549, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3464, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3633, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3462, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3619, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3236, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3590, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3201, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3560, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3195, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3421, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3677, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3200, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3174, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3284, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3557, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3676, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3187, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
The 98 training average loss: 0.33941034510217866
2025-11-22 21:55:05 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:55:05 - GraphTrainer - INFO -   precision@5: 0.006624
2025-11-22 21:55:05 - GraphTrainer - INFO -   recall@5: 0.031593
2025-11-22 21:55:05 - GraphTrainer - INFO -   hit_rate@5: 0.033068
2025-11-22 21:55:05 - GraphTrainer - INFO -   ndcg@5: 0.020618
2025-11-22 21:55:05 - GraphTrainer - INFO -   map@5: 0.016774
2025-11-22 21:55:05 - GraphTrainer - INFO -   mrr@5: 0.017463
2025-11-22 21:55:05 - GraphTrainer - INFO -   precision@10: 0.005271
2025-11-22 21:55:05 - GraphTrainer - INFO -   recall@10: 0.050103
2025-11-22 21:55:05 - GraphTrainer - INFO -   hit_rate@10: 0.052558
2025-11-22 21:55:05 - GraphTrainer - INFO -   ndcg@10: 0.026605
2025-11-22 21:55:05 - GraphTrainer - INFO -   map@10: 0.019186
2025-11-22 21:55:05 - GraphTrainer - INFO -   mrr@10: 0.019997
2025-11-22 21:55:05 - GraphTrainer - INFO -   precision@20: 0.004137
2025-11-22 21:55:05 - GraphTrainer - INFO -   recall@20: 0.078298
2025-11-22 21:55:05 - GraphTrainer - INFO -   hit_rate@20: 0.082283
2025-11-22 21:55:05 - GraphTrainer - INFO -   ndcg@20: 0.033725
2025-11-22 21:55:05 - GraphTrainer - INFO -   map@20: 0.021065
2025-11-22 21:55:05 - GraphTrainer - INFO -   mrr@20: 0.021977
2025-11-22 21:55:05 - GraphTrainer - INFO - 第 99 轮训练完成
2025-11-22 21:55:05 - GraphTrainer - INFO - train_loss: 0.342961
2025-11-22 21:55:05 - GraphTrainer - INFO - precision@5: 0.006624
2025-11-22 21:55:05 - GraphTrainer - INFO - recall@5: 0.031593
2025-11-22 21:55:05 - GraphTrainer - INFO - hit_rate@5: 0.033068
2025-11-22 21:55:05 - GraphTrainer - INFO - ndcg@5: 0.020618
2025-11-22 21:55:05 - GraphTrainer - INFO - map@5: 0.016774
2025-11-22 21:55:05 - GraphTrainer - INFO - mrr@5: 0.017463
2025-11-22 21:55:05 - GraphTrainer - INFO - precision@10: 0.005271
2025-11-22 21:55:05 - GraphTrainer - INFO - recall@10: 0.050103
2025-11-22 21:55:05 - GraphTrainer - INFO - hit_rate@10: 0.052558
2025-11-22 21:55:05 - GraphTrainer - INFO - ndcg@10: 0.026605
2025-11-22 21:55:05 - GraphTrainer - INFO - map@10: 0.019186
2025-11-22 21:55:05 - GraphTrainer - INFO - mrr@10: 0.019997
2025-11-22 21:55:05 - GraphTrainer - INFO - precision@20: 0.004137
2025-11-22 21:55:05 - GraphTrainer - INFO - recall@20: 0.078298
2025-11-22 21:55:05 - GraphTrainer - INFO - hit_rate@20: 0.082283
2025-11-22 21:55:05 - GraphTrainer - INFO - ndcg@20: 0.033725
2025-11-22 21:55:05 - GraphTrainer - INFO - map@20: 0.021065
2025-11-22 21:55:05 - GraphTrainer - INFO - mrr@20: 0.021977
2025-11-22 21:55:05 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:55:05 - GraphTrainer - INFO - ============================================================
2025-11-22 21:55:05 - GraphTrainer - INFO - 开始第 100/1000 轮训练
2025-11-22 21:55:05 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3670, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3421, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3506, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3729, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3281, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3492, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3263, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3468, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3531, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3576, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3241, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3333, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3507, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3464, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3479, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3145, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3490, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3466, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3462, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3569, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3484, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3206, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3273, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3268, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)
The 99 training average loss: 0.34296126920601416
2025-11-22 21:55:16 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:55:16 - GraphTrainer - INFO -   precision@5: 0.006819
2025-11-22 21:55:16 - GraphTrainer - INFO -   recall@5: 0.032545
2025-11-22 21:55:16 - GraphTrainer - INFO -   hit_rate@5: 0.034045
2025-11-22 21:55:16 - GraphTrainer - INFO -   ndcg@5: 0.021205
2025-11-22 21:55:16 - GraphTrainer - INFO -   map@5: 0.017253
2025-11-22 21:55:16 - GraphTrainer - INFO -   mrr@5: 0.017951
2025-11-22 21:55:16 - GraphTrainer - INFO -   precision@10: 0.005168
2025-11-22 21:55:16 - GraphTrainer - INFO -   recall@10: 0.049100
2025-11-22 21:55:16 - GraphTrainer - INFO -   hit_rate@10: 0.051581
2025-11-22 21:55:16 - GraphTrainer - INFO -   ndcg@10: 0.026564
2025-11-22 21:55:16 - GraphTrainer - INFO -   map@10: 0.019412
2025-11-22 21:55:16 - GraphTrainer - INFO -   mrr@10: 0.020232
2025-11-22 21:55:16 - GraphTrainer - INFO -   precision@20: 0.004076
2025-11-22 21:55:16 - GraphTrainer - INFO -   recall@20: 0.077149
2025-11-22 21:55:16 - GraphTrainer - INFO -   hit_rate@20: 0.081152
2025-11-22 21:55:16 - GraphTrainer - INFO -   ndcg@20: 0.033664
2025-11-22 21:55:16 - GraphTrainer - INFO -   map@20: 0.021296
2025-11-22 21:55:16 - GraphTrainer - INFO -   mrr@20: 0.022216
2025-11-22 21:55:16 - GraphTrainer - INFO - 第 100 轮训练完成
2025-11-22 21:55:16 - GraphTrainer - INFO - train_loss: 0.342718
2025-11-22 21:55:16 - GraphTrainer - INFO - precision@5: 0.006819
2025-11-22 21:55:16 - GraphTrainer - INFO - recall@5: 0.032545
2025-11-22 21:55:16 - GraphTrainer - INFO - hit_rate@5: 0.034045
2025-11-22 21:55:16 - GraphTrainer - INFO - ndcg@5: 0.021205
2025-11-22 21:55:16 - GraphTrainer - INFO - map@5: 0.017253
2025-11-22 21:55:16 - GraphTrainer - INFO - mrr@5: 0.017951
2025-11-22 21:55:16 - GraphTrainer - INFO - precision@10: 0.005168
2025-11-22 21:55:16 - GraphTrainer - INFO - recall@10: 0.049100
2025-11-22 21:55:16 - GraphTrainer - INFO - hit_rate@10: 0.051581
2025-11-22 21:55:16 - GraphTrainer - INFO - ndcg@10: 0.026564
2025-11-22 21:55:16 - GraphTrainer - INFO - map@10: 0.019412
2025-11-22 21:55:16 - GraphTrainer - INFO - mrr@10: 0.020232
2025-11-22 21:55:16 - GraphTrainer - INFO - precision@20: 0.004076
2025-11-22 21:55:16 - GraphTrainer - INFO - recall@20: 0.077149
2025-11-22 21:55:16 - GraphTrainer - INFO - hit_rate@20: 0.081152
2025-11-22 21:55:16 - GraphTrainer - INFO - ndcg@20: 0.033664
2025-11-22 21:55:16 - GraphTrainer - INFO - map@20: 0.021296
2025-11-22 21:55:16 - GraphTrainer - INFO - mrr@20: 0.022216
2025-11-22 21:55:16 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:55:16 - GraphTrainer - INFO - 检查点已保存: Epoch 100 -> ./checkpoints/checkpoint_epoch_100.pth
2025-11-22 21:55:16 - GraphTrainer - INFO - ============================================================
2025-11-22 21:55:16 - GraphTrainer - INFO - 开始第 101/1000 轮训练
2025-11-22 21:55:16 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3285, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3544, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3257, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3549, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3627, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3537, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3409, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3580, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3159, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3592, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3467, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3373, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3559, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3473, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>)
The 100 training average loss: 0.3427184974325114
2025-11-22 21:55:27 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:55:27 - GraphTrainer - INFO -   precision@5: 0.006593
2025-11-22 21:55:27 - GraphTrainer - INFO -   recall@5: 0.031383
2025-11-22 21:55:27 - GraphTrainer - INFO -   hit_rate@5: 0.032913
2025-11-22 21:55:27 - GraphTrainer - INFO -   ndcg@5: 0.020569
2025-11-22 21:55:27 - GraphTrainer - INFO -   map@5: 0.016777
2025-11-22 21:55:27 - GraphTrainer - INFO -   mrr@5: 0.017476
2025-11-22 21:55:27 - GraphTrainer - INFO -   precision@10: 0.005261
2025-11-22 21:55:27 - GraphTrainer - INFO -   recall@10: 0.049912
2025-11-22 21:55:27 - GraphTrainer - INFO -   hit_rate@10: 0.052507
2025-11-22 21:55:27 - GraphTrainer - INFO -   ndcg@10: 0.026564
2025-11-22 21:55:27 - GraphTrainer - INFO -   map@10: 0.019192
2025-11-22 21:55:27 - GraphTrainer - INFO -   mrr@10: 0.020016
2025-11-22 21:55:27 - GraphTrainer - INFO -   precision@20: 0.004032
2025-11-22 21:55:27 - GraphTrainer - INFO -   recall@20: 0.076335
2025-11-22 21:55:27 - GraphTrainer - INFO -   hit_rate@20: 0.080329
2025-11-22 21:55:27 - GraphTrainer - INFO -   ndcg@20: 0.033273
2025-11-22 21:55:27 - GraphTrainer - INFO -   map@20: 0.020986
2025-11-22 21:55:27 - GraphTrainer - INFO -   mrr@20: 0.021900
2025-11-22 21:55:27 - GraphTrainer - INFO - 第 101 轮训练完成
2025-11-22 21:55:27 - GraphTrainer - INFO - train_loss: 0.341767
2025-11-22 21:55:27 - GraphTrainer - INFO - precision@5: 0.006593
2025-11-22 21:55:27 - GraphTrainer - INFO - recall@5: 0.031383
2025-11-22 21:55:27 - GraphTrainer - INFO - hit_rate@5: 0.032913
2025-11-22 21:55:27 - GraphTrainer - INFO - ndcg@5: 0.020569
2025-11-22 21:55:27 - GraphTrainer - INFO - map@5: 0.016777
2025-11-22 21:55:27 - GraphTrainer - INFO - mrr@5: 0.017476
2025-11-22 21:55:27 - GraphTrainer - INFO - precision@10: 0.005261
2025-11-22 21:55:27 - GraphTrainer - INFO - recall@10: 0.049912
2025-11-22 21:55:27 - GraphTrainer - INFO - hit_rate@10: 0.052507
2025-11-22 21:55:27 - GraphTrainer - INFO - ndcg@10: 0.026564
2025-11-22 21:55:27 - GraphTrainer - INFO - map@10: 0.019192
2025-11-22 21:55:27 - GraphTrainer - INFO - mrr@10: 0.020016
2025-11-22 21:55:27 - GraphTrainer - INFO - precision@20: 0.004032
2025-11-22 21:55:27 - GraphTrainer - INFO - recall@20: 0.076335
2025-11-22 21:55:27 - GraphTrainer - INFO - hit_rate@20: 0.080329
2025-11-22 21:55:27 - GraphTrainer - INFO - ndcg@20: 0.033273
2025-11-22 21:55:27 - GraphTrainer - INFO - map@20: 0.020986
2025-11-22 21:55:27 - GraphTrainer - INFO - mrr@20: 0.021900
2025-11-22 21:55:27 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:55:27 - GraphTrainer - INFO - ============================================================
2025-11-22 21:55:27 - GraphTrainer - INFO - 开始第 102/1000 轮训练
2025-11-22 21:55:27 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3592, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3146, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3529, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3601, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3644, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3152, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3506, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3376, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3492, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3473, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3263, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3236, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3713, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3639, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)
The 101 training average loss: 0.3417672972226965
2025-11-22 21:55:39 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:55:39 - GraphTrainer - INFO -   precision@5: 0.006634
2025-11-22 21:55:39 - GraphTrainer - INFO -   recall@5: 0.031589
2025-11-22 21:55:39 - GraphTrainer - INFO -   hit_rate@5: 0.033119
2025-11-22 21:55:39 - GraphTrainer - INFO -   ndcg@5: 0.020368
2025-11-22 21:55:39 - GraphTrainer - INFO -   map@5: 0.016453
2025-11-22 21:55:39 - GraphTrainer - INFO -   mrr@5: 0.017103
2025-11-22 21:55:39 - GraphTrainer - INFO -   precision@10: 0.005210
2025-11-22 21:55:39 - GraphTrainer - INFO -   recall@10: 0.049511
2025-11-22 21:55:39 - GraphTrainer - INFO -   hit_rate@10: 0.051941
2025-11-22 21:55:39 - GraphTrainer - INFO -   ndcg@10: 0.026161
2025-11-22 21:55:39 - GraphTrainer - INFO -   map@10: 0.018789
2025-11-22 21:55:39 - GraphTrainer - INFO -   mrr@10: 0.019553
2025-11-22 21:55:39 - GraphTrainer - INFO -   precision@20: 0.004027
2025-11-22 21:55:39 - GraphTrainer - INFO -   recall@20: 0.076200
2025-11-22 21:55:39 - GraphTrainer - INFO -   hit_rate@20: 0.080175
2025-11-22 21:55:39 - GraphTrainer - INFO -   ndcg@20: 0.032956
2025-11-22 21:55:39 - GraphTrainer - INFO -   map@20: 0.020610
2025-11-22 21:55:39 - GraphTrainer - INFO -   mrr@20: 0.021475
2025-11-22 21:55:39 - GraphTrainer - INFO - 第 102 轮训练完成
2025-11-22 21:55:39 - GraphTrainer - INFO - train_loss: 0.342905
2025-11-22 21:55:39 - GraphTrainer - INFO - precision@5: 0.006634
2025-11-22 21:55:39 - GraphTrainer - INFO - recall@5: 0.031589
2025-11-22 21:55:39 - GraphTrainer - INFO - hit_rate@5: 0.033119
2025-11-22 21:55:39 - GraphTrainer - INFO - ndcg@5: 0.020368
2025-11-22 21:55:39 - GraphTrainer - INFO - map@5: 0.016453
2025-11-22 21:55:39 - GraphTrainer - INFO - mrr@5: 0.017103
2025-11-22 21:55:39 - GraphTrainer - INFO - precision@10: 0.005210
2025-11-22 21:55:39 - GraphTrainer - INFO - recall@10: 0.049511
2025-11-22 21:55:39 - GraphTrainer - INFO - hit_rate@10: 0.051941
2025-11-22 21:55:39 - GraphTrainer - INFO - ndcg@10: 0.026161
2025-11-22 21:55:39 - GraphTrainer - INFO - map@10: 0.018789
2025-11-22 21:55:39 - GraphTrainer - INFO - mrr@10: 0.019553
2025-11-22 21:55:39 - GraphTrainer - INFO - precision@20: 0.004027
2025-11-22 21:55:39 - GraphTrainer - INFO - recall@20: 0.076200
2025-11-22 21:55:39 - GraphTrainer - INFO - hit_rate@20: 0.080175
2025-11-22 21:55:39 - GraphTrainer - INFO - ndcg@20: 0.032956
2025-11-22 21:55:39 - GraphTrainer - INFO - map@20: 0.020610
2025-11-22 21:55:39 - GraphTrainer - INFO - mrr@20: 0.021475
2025-11-22 21:55:39 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:55:39 - GraphTrainer - INFO - ============================================================
2025-11-22 21:55:39 - GraphTrainer - INFO - 开始第 103/1000 轮训练
2025-11-22 21:55:39 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3697, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3222, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3457, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3288, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3494, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3607, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3655, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3236, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3548, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3785, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3608, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3269, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3331, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3122, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3209, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3768, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3521, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3309, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3516, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
The 102 training average loss: 0.34290537751954175
2025-11-22 21:55:50 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:55:50 - GraphTrainer - INFO -   precision@5: 0.006511
2025-11-22 21:55:50 - GraphTrainer - INFO -   recall@5: 0.030945
2025-11-22 21:55:50 - GraphTrainer - INFO -   hit_rate@5: 0.032502
2025-11-22 21:55:50 - GraphTrainer - INFO -   ndcg@5: 0.020166
2025-11-22 21:55:50 - GraphTrainer - INFO -   map@5: 0.016383
2025-11-22 21:55:50 - GraphTrainer - INFO -   mrr@5: 0.017086
2025-11-22 21:55:50 - GraphTrainer - INFO -   precision@10: 0.005230
2025-11-22 21:55:50 - GraphTrainer - INFO -   recall@10: 0.049735
2025-11-22 21:55:50 - GraphTrainer - INFO -   hit_rate@10: 0.052199
2025-11-22 21:55:50 - GraphTrainer - INFO -   ndcg@10: 0.026271
2025-11-22 21:55:50 - GraphTrainer - INFO -   map@10: 0.018868
2025-11-22 21:55:50 - GraphTrainer - INFO -   mrr@10: 0.019686
2025-11-22 21:55:50 - GraphTrainer - INFO -   precision@20: 0.004114
2025-11-22 21:55:50 - GraphTrainer - INFO -   recall@20: 0.077912
2025-11-22 21:55:50 - GraphTrainer - INFO -   hit_rate@20: 0.081975
2025-11-22 21:55:50 - GraphTrainer - INFO -   ndcg@20: 0.033416
2025-11-22 21:55:50 - GraphTrainer - INFO -   map@20: 0.020767
2025-11-22 21:55:50 - GraphTrainer - INFO -   mrr@20: 0.021695
2025-11-22 21:55:50 - GraphTrainer - INFO - 第 103 轮训练完成
2025-11-22 21:55:50 - GraphTrainer - INFO - train_loss: 0.343299
2025-11-22 21:55:50 - GraphTrainer - INFO - precision@5: 0.006511
2025-11-22 21:55:50 - GraphTrainer - INFO - recall@5: 0.030945
2025-11-22 21:55:50 - GraphTrainer - INFO - hit_rate@5: 0.032502
2025-11-22 21:55:50 - GraphTrainer - INFO - ndcg@5: 0.020166
2025-11-22 21:55:50 - GraphTrainer - INFO - map@5: 0.016383
2025-11-22 21:55:50 - GraphTrainer - INFO - mrr@5: 0.017086
2025-11-22 21:55:50 - GraphTrainer - INFO - precision@10: 0.005230
2025-11-22 21:55:50 - GraphTrainer - INFO - recall@10: 0.049735
2025-11-22 21:55:50 - GraphTrainer - INFO - hit_rate@10: 0.052199
2025-11-22 21:55:50 - GraphTrainer - INFO - ndcg@10: 0.026271
2025-11-22 21:55:50 - GraphTrainer - INFO - map@10: 0.018868
2025-11-22 21:55:50 - GraphTrainer - INFO - mrr@10: 0.019686
2025-11-22 21:55:50 - GraphTrainer - INFO - precision@20: 0.004114
2025-11-22 21:55:50 - GraphTrainer - INFO - recall@20: 0.077912
2025-11-22 21:55:50 - GraphTrainer - INFO - hit_rate@20: 0.081975
2025-11-22 21:55:50 - GraphTrainer - INFO - ndcg@20: 0.033416
2025-11-22 21:55:50 - GraphTrainer - INFO - map@20: 0.020767
2025-11-22 21:55:50 - GraphTrainer - INFO - mrr@20: 0.021695
2025-11-22 21:55:50 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:55:50 - GraphTrainer - INFO - ============================================================
2025-11-22 21:55:50 - GraphTrainer - INFO - 开始第 104/1000 轮训练
2025-11-22 21:55:50 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3281, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3653, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3642, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3549, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3619, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3545, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3235, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3676, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3225, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3303, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3551, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3531, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3543, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3216, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3780, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3571, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3211, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3263, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3584, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3109, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3574, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3284, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3665, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3699, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3234, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
The 103 training average loss: 0.343299125802928
2025-11-22 21:56:01 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:56:01 - GraphTrainer - INFO -   precision@5: 0.006593
2025-11-22 21:56:01 - GraphTrainer - INFO -   recall@5: 0.031468
2025-11-22 21:56:01 - GraphTrainer - INFO -   hit_rate@5: 0.032913
2025-11-22 21:56:01 - GraphTrainer - INFO -   ndcg@5: 0.020280
2025-11-22 21:56:01 - GraphTrainer - INFO -   map@5: 0.016366
2025-11-22 21:56:01 - GraphTrainer - INFO -   mrr@5: 0.017028
2025-11-22 21:56:01 - GraphTrainer - INFO -   precision@10: 0.005251
2025-11-22 21:56:01 - GraphTrainer - INFO -   recall@10: 0.049766
2025-11-22 21:56:01 - GraphTrainer - INFO -   hit_rate@10: 0.052301
2025-11-22 21:56:01 - GraphTrainer - INFO -   ndcg@10: 0.026235
2025-11-22 21:56:01 - GraphTrainer - INFO -   map@10: 0.018777
2025-11-22 21:56:01 - GraphTrainer - INFO -   mrr@10: 0.019582
2025-11-22 21:56:01 - GraphTrainer - INFO -   precision@20: 0.004117
2025-11-22 21:56:01 - GraphTrainer - INFO -   recall@20: 0.078082
2025-11-22 21:56:01 - GraphTrainer - INFO -   hit_rate@20: 0.081975
2025-11-22 21:56:01 - GraphTrainer - INFO -   ndcg@20: 0.033400
2025-11-22 21:56:01 - GraphTrainer - INFO -   map@20: 0.020687
2025-11-22 21:56:01 - GraphTrainer - INFO -   mrr@20: 0.021583
2025-11-22 21:56:01 - GraphTrainer - INFO - 第 104 轮训练完成
2025-11-22 21:56:01 - GraphTrainer - INFO - train_loss: 0.342375
2025-11-22 21:56:01 - GraphTrainer - INFO - precision@5: 0.006593
2025-11-22 21:56:01 - GraphTrainer - INFO - recall@5: 0.031468
2025-11-22 21:56:01 - GraphTrainer - INFO - hit_rate@5: 0.032913
2025-11-22 21:56:01 - GraphTrainer - INFO - ndcg@5: 0.020280
2025-11-22 21:56:01 - GraphTrainer - INFO - map@5: 0.016366
2025-11-22 21:56:01 - GraphTrainer - INFO - mrr@5: 0.017028
2025-11-22 21:56:01 - GraphTrainer - INFO - precision@10: 0.005251
2025-11-22 21:56:01 - GraphTrainer - INFO - recall@10: 0.049766
2025-11-22 21:56:01 - GraphTrainer - INFO - hit_rate@10: 0.052301
2025-11-22 21:56:01 - GraphTrainer - INFO - ndcg@10: 0.026235
2025-11-22 21:56:01 - GraphTrainer - INFO - map@10: 0.018777
2025-11-22 21:56:01 - GraphTrainer - INFO - mrr@10: 0.019582
2025-11-22 21:56:01 - GraphTrainer - INFO - precision@20: 0.004117
2025-11-22 21:56:01 - GraphTrainer - INFO - recall@20: 0.078082
2025-11-22 21:56:01 - GraphTrainer - INFO - hit_rate@20: 0.081975
2025-11-22 21:56:01 - GraphTrainer - INFO - ndcg@20: 0.033400
2025-11-22 21:56:01 - GraphTrainer - INFO - map@20: 0.020687
2025-11-22 21:56:01 - GraphTrainer - INFO - mrr@20: 0.021583
2025-11-22 21:56:01 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:56:01 - GraphTrainer - INFO - ============================================================
2025-11-22 21:56:01 - GraphTrainer - INFO - 开始第 105/1000 轮训练
2025-11-22 21:56:01 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3517, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3293, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3199, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3209, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3628, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3602, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3236, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3421, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3620, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3272, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3281, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3545, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3629, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3195, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3586, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3721, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3313, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3649, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3333, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
The 104 training average loss: 0.34237467369128916
2025-11-22 21:56:12 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:56:12 - GraphTrainer - INFO -   precision@5: 0.006696
2025-11-22 21:56:12 - GraphTrainer - INFO -   recall@5: 0.031784
2025-11-22 21:56:12 - GraphTrainer - INFO -   hit_rate@5: 0.033428
2025-11-22 21:56:12 - GraphTrainer - INFO -   ndcg@5: 0.020418
2025-11-22 21:56:12 - GraphTrainer - INFO -   map@5: 0.016440
2025-11-22 21:56:12 - GraphTrainer - INFO -   mrr@5: 0.017090
2025-11-22 21:56:12 - GraphTrainer - INFO -   precision@10: 0.005138
2025-11-22 21:56:12 - GraphTrainer - INFO -   recall@10: 0.048766
2025-11-22 21:56:12 - GraphTrainer - INFO -   hit_rate@10: 0.051273
2025-11-22 21:56:12 - GraphTrainer - INFO -   ndcg@10: 0.025930
2025-11-22 21:56:12 - GraphTrainer - INFO -   map@10: 0.018676
2025-11-22 21:56:12 - GraphTrainer - INFO -   mrr@10: 0.019438
2025-11-22 21:56:12 - GraphTrainer - INFO -   precision@20: 0.004096
2025-11-22 21:56:12 - GraphTrainer - INFO -   recall@20: 0.077487
2025-11-22 21:56:12 - GraphTrainer - INFO -   hit_rate@20: 0.081512
2025-11-22 21:56:12 - GraphTrainer - INFO -   ndcg@20: 0.033217
2025-11-22 21:56:12 - GraphTrainer - INFO -   map@20: 0.020619
2025-11-22 21:56:12 - GraphTrainer - INFO -   mrr@20: 0.021480
2025-11-22 21:56:12 - GraphTrainer - INFO - 第 105 轮训练完成
2025-11-22 21:56:12 - GraphTrainer - INFO - train_loss: 0.342374
2025-11-22 21:56:12 - GraphTrainer - INFO - precision@5: 0.006696
2025-11-22 21:56:12 - GraphTrainer - INFO - recall@5: 0.031784
2025-11-22 21:56:12 - GraphTrainer - INFO - hit_rate@5: 0.033428
2025-11-22 21:56:12 - GraphTrainer - INFO - ndcg@5: 0.020418
2025-11-22 21:56:12 - GraphTrainer - INFO - map@5: 0.016440
2025-11-22 21:56:12 - GraphTrainer - INFO - mrr@5: 0.017090
2025-11-22 21:56:12 - GraphTrainer - INFO - precision@10: 0.005138
2025-11-22 21:56:12 - GraphTrainer - INFO - recall@10: 0.048766
2025-11-22 21:56:12 - GraphTrainer - INFO - hit_rate@10: 0.051273
2025-11-22 21:56:12 - GraphTrainer - INFO - ndcg@10: 0.025930
2025-11-22 21:56:12 - GraphTrainer - INFO - map@10: 0.018676
2025-11-22 21:56:12 - GraphTrainer - INFO - mrr@10: 0.019438
2025-11-22 21:56:12 - GraphTrainer - INFO - precision@20: 0.004096
2025-11-22 21:56:12 - GraphTrainer - INFO - recall@20: 0.077487
2025-11-22 21:56:12 - GraphTrainer - INFO - hit_rate@20: 0.081512
2025-11-22 21:56:12 - GraphTrainer - INFO - ndcg@20: 0.033217
2025-11-22 21:56:12 - GraphTrainer - INFO - map@20: 0.020619
2025-11-22 21:56:12 - GraphTrainer - INFO - mrr@20: 0.021480
2025-11-22 21:56:12 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:56:12 - GraphTrainer - INFO - ============================================================
2025-11-22 21:56:12 - GraphTrainer - INFO - 开始第 106/1000 轮训练
2025-11-22 21:56:12 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3306, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3304, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3555, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3152, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3561, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3545, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3751, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3558, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3723, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3598, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3252, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3223, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3573, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3467, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3591, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3544, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3373, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3263, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3254, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3652, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3102, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3668, device='cuda:0', grad_fn=<AddBackward0>)
The 105 training average loss: 0.342373831004932
2025-11-22 21:56:23 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:56:23 - GraphTrainer - INFO -   precision@5: 0.006552
2025-11-22 21:56:23 - GraphTrainer - INFO -   recall@5: 0.031185
2025-11-22 21:56:23 - GraphTrainer - INFO -   hit_rate@5: 0.032708
2025-11-22 21:56:23 - GraphTrainer - INFO -   ndcg@5: 0.020029
2025-11-22 21:56:23 - GraphTrainer - INFO -   map@5: 0.016118
2025-11-22 21:56:23 - GraphTrainer - INFO -   mrr@5: 0.016787
2025-11-22 21:56:23 - GraphTrainer - INFO -   precision@10: 0.005261
2025-11-22 21:56:23 - GraphTrainer - INFO -   recall@10: 0.049766
2025-11-22 21:56:23 - GraphTrainer - INFO -   hit_rate@10: 0.052507
2025-11-22 21:56:23 - GraphTrainer - INFO -   ndcg@10: 0.026058
2025-11-22 21:56:23 - GraphTrainer - INFO -   map@10: 0.018545
2025-11-22 21:56:23 - GraphTrainer - INFO -   mrr@10: 0.019362
2025-11-22 21:56:23 - GraphTrainer - INFO -   precision@20: 0.004104
2025-11-22 21:56:23 - GraphTrainer - INFO -   recall@20: 0.077740
2025-11-22 21:56:23 - GraphTrainer - INFO -   hit_rate@20: 0.081615
2025-11-22 21:56:23 - GraphTrainer - INFO -   ndcg@20: 0.033142
2025-11-22 21:56:23 - GraphTrainer - INFO -   map@20: 0.020441
2025-11-22 21:56:23 - GraphTrainer - INFO -   mrr@20: 0.021332
2025-11-22 21:56:23 - GraphTrainer - INFO - 第 106 轮训练完成
2025-11-22 21:56:23 - GraphTrainer - INFO - train_loss: 0.343265
2025-11-22 21:56:23 - GraphTrainer - INFO - precision@5: 0.006552
2025-11-22 21:56:23 - GraphTrainer - INFO - recall@5: 0.031185
2025-11-22 21:56:23 - GraphTrainer - INFO - hit_rate@5: 0.032708
2025-11-22 21:56:23 - GraphTrainer - INFO - ndcg@5: 0.020029
2025-11-22 21:56:23 - GraphTrainer - INFO - map@5: 0.016118
2025-11-22 21:56:23 - GraphTrainer - INFO - mrr@5: 0.016787
2025-11-22 21:56:23 - GraphTrainer - INFO - precision@10: 0.005261
2025-11-22 21:56:23 - GraphTrainer - INFO - recall@10: 0.049766
2025-11-22 21:56:23 - GraphTrainer - INFO - hit_rate@10: 0.052507
2025-11-22 21:56:23 - GraphTrainer - INFO - ndcg@10: 0.026058
2025-11-22 21:56:23 - GraphTrainer - INFO - map@10: 0.018545
2025-11-22 21:56:23 - GraphTrainer - INFO - mrr@10: 0.019362
2025-11-22 21:56:23 - GraphTrainer - INFO - precision@20: 0.004104
2025-11-22 21:56:23 - GraphTrainer - INFO - recall@20: 0.077740
2025-11-22 21:56:23 - GraphTrainer - INFO - hit_rate@20: 0.081615
2025-11-22 21:56:23 - GraphTrainer - INFO - ndcg@20: 0.033142
2025-11-22 21:56:23 - GraphTrainer - INFO - map@20: 0.020441
2025-11-22 21:56:23 - GraphTrainer - INFO - mrr@20: 0.021332
2025-11-22 21:56:23 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:56:23 - GraphTrainer - INFO - ============================================================
2025-11-22 21:56:23 - GraphTrainer - INFO - 开始第 107/1000 轮训练
2025-11-22 21:56:23 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3543, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3248, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3435, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3626, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3221, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3550, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3549, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3681, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3143, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3304, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3608, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3644, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3617, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3559, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3604, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3568, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3506, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3257, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3312, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3717, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3192, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3561, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3639, device='cuda:0', grad_fn=<AddBackward0>)
The 106 training average loss: 0.34326480945636484
2025-11-22 21:56:34 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:56:34 - GraphTrainer - INFO -   precision@5: 0.006686
2025-11-22 21:56:34 - GraphTrainer - INFO -   recall@5: 0.031771
2025-11-22 21:56:34 - GraphTrainer - INFO -   hit_rate@5: 0.033376
2025-11-22 21:56:34 - GraphTrainer - INFO -   ndcg@5: 0.020776
2025-11-22 21:56:34 - GraphTrainer - INFO -   map@5: 0.016932
2025-11-22 21:56:34 - GraphTrainer - INFO -   mrr@5: 0.017617
2025-11-22 21:56:34 - GraphTrainer - INFO -   precision@10: 0.005287
2025-11-22 21:56:34 - GraphTrainer - INFO -   recall@10: 0.050221
2025-11-22 21:56:34 - GraphTrainer - INFO -   hit_rate@10: 0.052764
2025-11-22 21:56:34 - GraphTrainer - INFO -   ndcg@10: 0.026725
2025-11-22 21:56:34 - GraphTrainer - INFO -   map@10: 0.019323
2025-11-22 21:56:34 - GraphTrainer - INFO -   mrr@10: 0.020126
2025-11-22 21:56:34 - GraphTrainer - INFO -   precision@20: 0.004099
2025-11-22 21:56:34 - GraphTrainer - INFO -   recall@20: 0.077578
2025-11-22 21:56:34 - GraphTrainer - INFO -   hit_rate@20: 0.081615
2025-11-22 21:56:34 - GraphTrainer - INFO -   ndcg@20: 0.033679
2025-11-22 21:56:34 - GraphTrainer - INFO -   map@20: 0.021184
2025-11-22 21:56:34 - GraphTrainer - INFO -   mrr@20: 0.022086
2025-11-22 21:56:34 - GraphTrainer - INFO - 第 107 轮训练完成
2025-11-22 21:56:34 - GraphTrainer - INFO - train_loss: 0.342996
2025-11-22 21:56:34 - GraphTrainer - INFO - precision@5: 0.006686
2025-11-22 21:56:34 - GraphTrainer - INFO - recall@5: 0.031771
2025-11-22 21:56:34 - GraphTrainer - INFO - hit_rate@5: 0.033376
2025-11-22 21:56:34 - GraphTrainer - INFO - ndcg@5: 0.020776
2025-11-22 21:56:34 - GraphTrainer - INFO - map@5: 0.016932
2025-11-22 21:56:34 - GraphTrainer - INFO - mrr@5: 0.017617
2025-11-22 21:56:34 - GraphTrainer - INFO - precision@10: 0.005287
2025-11-22 21:56:34 - GraphTrainer - INFO - recall@10: 0.050221
2025-11-22 21:56:34 - GraphTrainer - INFO - hit_rate@10: 0.052764
2025-11-22 21:56:34 - GraphTrainer - INFO - ndcg@10: 0.026725
2025-11-22 21:56:34 - GraphTrainer - INFO - map@10: 0.019323
2025-11-22 21:56:34 - GraphTrainer - INFO - mrr@10: 0.020126
2025-11-22 21:56:34 - GraphTrainer - INFO - precision@20: 0.004099
2025-11-22 21:56:34 - GraphTrainer - INFO - recall@20: 0.077578
2025-11-22 21:56:34 - GraphTrainer - INFO - hit_rate@20: 0.081615
2025-11-22 21:56:34 - GraphTrainer - INFO - ndcg@20: 0.033679
2025-11-22 21:56:34 - GraphTrainer - INFO - map@20: 0.021184
2025-11-22 21:56:34 - GraphTrainer - INFO - mrr@20: 0.022086
2025-11-22 21:56:34 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:56:34 - GraphTrainer - INFO - ============================================================
2025-11-22 21:56:34 - GraphTrainer - INFO - 开始第 108/1000 轮训练
2025-11-22 21:56:34 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3512, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3654, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3536, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3525, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3285, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3529, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3656, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3569, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3607, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3279, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3064, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3554, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3455, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3187, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3193, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3169, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3313, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3559, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3284, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3582, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3648, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3641, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3331, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3468, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
The 107 training average loss: 0.34299553776609487
2025-11-22 21:56:45 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:56:45 - GraphTrainer - INFO -   precision@5: 0.006593
2025-11-22 21:56:45 - GraphTrainer - INFO -   recall@5: 0.031442
2025-11-22 21:56:45 - GraphTrainer - INFO -   hit_rate@5: 0.032913
2025-11-22 21:56:45 - GraphTrainer - INFO -   ndcg@5: 0.020474
2025-11-22 21:56:45 - GraphTrainer - INFO -   map@5: 0.016629
2025-11-22 21:56:45 - GraphTrainer - INFO -   mrr@5: 0.017313
2025-11-22 21:56:45 - GraphTrainer - INFO -   precision@10: 0.005220
2025-11-22 21:56:45 - GraphTrainer - INFO -   recall@10: 0.049568
2025-11-22 21:56:45 - GraphTrainer - INFO -   hit_rate@10: 0.052096
2025-11-22 21:56:45 - GraphTrainer - INFO -   ndcg@10: 0.026336
2025-11-22 21:56:45 - GraphTrainer - INFO -   map@10: 0.018984
2025-11-22 21:56:45 - GraphTrainer - INFO -   mrr@10: 0.019805
2025-11-22 21:56:45 - GraphTrainer - INFO -   precision@20: 0.004148
2025-11-22 21:56:45 - GraphTrainer - INFO -   recall@20: 0.078451
2025-11-22 21:56:45 - GraphTrainer - INFO -   hit_rate@20: 0.082489
2025-11-22 21:56:45 - GraphTrainer - INFO -   ndcg@20: 0.033673
2025-11-22 21:56:45 - GraphTrainer - INFO -   map@20: 0.020948
2025-11-22 21:56:45 - GraphTrainer - INFO -   mrr@20: 0.021864
2025-11-22 21:56:45 - GraphTrainer - INFO - 第 108 轮训练完成
2025-11-22 21:56:45 - GraphTrainer - INFO - train_loss: 0.343358
2025-11-22 21:56:45 - GraphTrainer - INFO - precision@5: 0.006593
2025-11-22 21:56:45 - GraphTrainer - INFO - recall@5: 0.031442
2025-11-22 21:56:45 - GraphTrainer - INFO - hit_rate@5: 0.032913
2025-11-22 21:56:45 - GraphTrainer - INFO - ndcg@5: 0.020474
2025-11-22 21:56:45 - GraphTrainer - INFO - map@5: 0.016629
2025-11-22 21:56:45 - GraphTrainer - INFO - mrr@5: 0.017313
2025-11-22 21:56:45 - GraphTrainer - INFO - precision@10: 0.005220
2025-11-22 21:56:45 - GraphTrainer - INFO - recall@10: 0.049568
2025-11-22 21:56:45 - GraphTrainer - INFO - hit_rate@10: 0.052096
2025-11-22 21:56:45 - GraphTrainer - INFO - ndcg@10: 0.026336
2025-11-22 21:56:45 - GraphTrainer - INFO - map@10: 0.018984
2025-11-22 21:56:45 - GraphTrainer - INFO - mrr@10: 0.019805
2025-11-22 21:56:45 - GraphTrainer - INFO - precision@20: 0.004148
2025-11-22 21:56:45 - GraphTrainer - INFO - recall@20: 0.078451
2025-11-22 21:56:45 - GraphTrainer - INFO - hit_rate@20: 0.082489
2025-11-22 21:56:45 - GraphTrainer - INFO - ndcg@20: 0.033673
2025-11-22 21:56:45 - GraphTrainer - INFO - map@20: 0.020948
2025-11-22 21:56:45 - GraphTrainer - INFO - mrr@20: 0.021864
2025-11-22 21:56:45 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:56:45 - GraphTrainer - INFO - ============================================================
2025-11-22 21:56:45 - GraphTrainer - INFO - 开始第 109/1000 轮训练
2025-11-22 21:56:45 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3467, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3149, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3714, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3257, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3722, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3342, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3560, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3518, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3641, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3490, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3473, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3580, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3216, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3327, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3547, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3376, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3584, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3455, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
The 108 training average loss: 0.3433578399748638
2025-11-22 21:56:56 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:56:56 - GraphTrainer - INFO -   precision@5: 0.006572
2025-11-22 21:56:56 - GraphTrainer - INFO -   recall@5: 0.031262
2025-11-22 21:56:56 - GraphTrainer - INFO -   hit_rate@5: 0.032810
2025-11-22 21:56:56 - GraphTrainer - INFO -   ndcg@5: 0.020381
2025-11-22 21:56:56 - GraphTrainer - INFO -   map@5: 0.016560
2025-11-22 21:56:56 - GraphTrainer - INFO -   mrr@5: 0.017256
2025-11-22 21:56:56 - GraphTrainer - INFO -   precision@10: 0.005251
2025-11-22 21:56:56 - GraphTrainer - INFO -   recall@10: 0.049691
2025-11-22 21:56:56 - GraphTrainer - INFO -   hit_rate@10: 0.052301
2025-11-22 21:56:56 - GraphTrainer - INFO -   ndcg@10: 0.026362
2025-11-22 21:56:56 - GraphTrainer - INFO -   map@10: 0.018975
2025-11-22 21:56:56 - GraphTrainer - INFO -   mrr@10: 0.019805
2025-11-22 21:56:56 - GraphTrainer - INFO -   precision@20: 0.004094
2025-11-22 21:56:56 - GraphTrainer - INFO -   recall@20: 0.077492
2025-11-22 21:56:56 - GraphTrainer - INFO -   hit_rate@20: 0.081615
2025-11-22 21:56:56 - GraphTrainer - INFO -   ndcg@20: 0.033407
2025-11-22 21:56:56 - GraphTrainer - INFO -   map@20: 0.020854
2025-11-22 21:56:56 - GraphTrainer - INFO -   mrr@20: 0.021782
2025-11-22 21:56:56 - GraphTrainer - INFO - 第 109 轮训练完成
2025-11-22 21:56:56 - GraphTrainer - INFO - train_loss: 0.342248
2025-11-22 21:56:56 - GraphTrainer - INFO - precision@5: 0.006572
2025-11-22 21:56:56 - GraphTrainer - INFO - recall@5: 0.031262
2025-11-22 21:56:56 - GraphTrainer - INFO - hit_rate@5: 0.032810
2025-11-22 21:56:56 - GraphTrainer - INFO - ndcg@5: 0.020381
2025-11-22 21:56:56 - GraphTrainer - INFO - map@5: 0.016560
2025-11-22 21:56:56 - GraphTrainer - INFO - mrr@5: 0.017256
2025-11-22 21:56:56 - GraphTrainer - INFO - precision@10: 0.005251
2025-11-22 21:56:56 - GraphTrainer - INFO - recall@10: 0.049691
2025-11-22 21:56:56 - GraphTrainer - INFO - hit_rate@10: 0.052301
2025-11-22 21:56:56 - GraphTrainer - INFO - ndcg@10: 0.026362
2025-11-22 21:56:56 - GraphTrainer - INFO - map@10: 0.018975
2025-11-22 21:56:56 - GraphTrainer - INFO - mrr@10: 0.019805
2025-11-22 21:56:56 - GraphTrainer - INFO - precision@20: 0.004094
2025-11-22 21:56:56 - GraphTrainer - INFO - recall@20: 0.077492
2025-11-22 21:56:56 - GraphTrainer - INFO - hit_rate@20: 0.081615
2025-11-22 21:56:56 - GraphTrainer - INFO - ndcg@20: 0.033407
2025-11-22 21:56:56 - GraphTrainer - INFO - map@20: 0.020854
2025-11-22 21:56:56 - GraphTrainer - INFO - mrr@20: 0.021782
2025-11-22 21:56:56 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:56:56 - GraphTrainer - INFO - ============================================================
2025-11-22 21:56:56 - GraphTrainer - INFO - 开始第 110/1000 轮训练
2025-11-22 21:56:56 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3273, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3591, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3165, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3604, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3127, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3598, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3621, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3258, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3596, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3213, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3457, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3194, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3203, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3565, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3590, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3680, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3236, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3304, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3680, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3642, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3207, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3160, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
The 109 training average loss: 0.3422475693554714
2025-11-22 21:57:07 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:57:07 - GraphTrainer - INFO -   precision@5: 0.006593
2025-11-22 21:57:07 - GraphTrainer - INFO -   recall@5: 0.031540
2025-11-22 21:57:07 - GraphTrainer - INFO -   hit_rate@5: 0.032913
2025-11-22 21:57:07 - GraphTrainer - INFO -   ndcg@5: 0.020315
2025-11-22 21:57:07 - GraphTrainer - INFO -   map@5: 0.016404
2025-11-22 21:57:07 - GraphTrainer - INFO -   mrr@5: 0.017055
2025-11-22 21:57:07 - GraphTrainer - INFO -   precision@10: 0.005204
2025-11-22 21:57:07 - GraphTrainer - INFO -   recall@10: 0.049518
2025-11-22 21:57:07 - GraphTrainer - INFO -   hit_rate@10: 0.051941
2025-11-22 21:57:07 - GraphTrainer - INFO -   ndcg@10: 0.026171
2025-11-22 21:57:07 - GraphTrainer - INFO -   map@10: 0.018781
2025-11-22 21:57:07 - GraphTrainer - INFO -   mrr@10: 0.019576
2025-11-22 21:57:07 - GraphTrainer - INFO -   precision@20: 0.004124
2025-11-22 21:57:07 - GraphTrainer - INFO -   recall@20: 0.078032
2025-11-22 21:57:07 - GraphTrainer - INFO -   hit_rate@20: 0.082026
2025-11-22 21:57:07 - GraphTrainer - INFO -   ndcg@20: 0.033446
2025-11-22 21:57:07 - GraphTrainer - INFO -   map@20: 0.020738
2025-11-22 21:57:07 - GraphTrainer - INFO -   mrr@20: 0.021640
2025-11-22 21:57:07 - GraphTrainer - INFO - 第 110 轮训练完成
2025-11-22 21:57:07 - GraphTrainer - INFO - train_loss: 0.341048
2025-11-22 21:57:07 - GraphTrainer - INFO - precision@5: 0.006593
2025-11-22 21:57:07 - GraphTrainer - INFO - recall@5: 0.031540
2025-11-22 21:57:07 - GraphTrainer - INFO - hit_rate@5: 0.032913
2025-11-22 21:57:07 - GraphTrainer - INFO - ndcg@5: 0.020315
2025-11-22 21:57:07 - GraphTrainer - INFO - map@5: 0.016404
2025-11-22 21:57:07 - GraphTrainer - INFO - mrr@5: 0.017055
2025-11-22 21:57:07 - GraphTrainer - INFO - precision@10: 0.005204
2025-11-22 21:57:07 - GraphTrainer - INFO - recall@10: 0.049518
2025-11-22 21:57:07 - GraphTrainer - INFO - hit_rate@10: 0.051941
2025-11-22 21:57:07 - GraphTrainer - INFO - ndcg@10: 0.026171
2025-11-22 21:57:07 - GraphTrainer - INFO - map@10: 0.018781
2025-11-22 21:57:07 - GraphTrainer - INFO - mrr@10: 0.019576
2025-11-22 21:57:07 - GraphTrainer - INFO - precision@20: 0.004124
2025-11-22 21:57:07 - GraphTrainer - INFO - recall@20: 0.078032
2025-11-22 21:57:07 - GraphTrainer - INFO - hit_rate@20: 0.082026
2025-11-22 21:57:07 - GraphTrainer - INFO - ndcg@20: 0.033446
2025-11-22 21:57:07 - GraphTrainer - INFO - map@20: 0.020738
2025-11-22 21:57:07 - GraphTrainer - INFO - mrr@20: 0.021640
2025-11-22 21:57:07 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:57:07 - GraphTrainer - INFO - 检查点已保存: Epoch 110 -> ./checkpoints/checkpoint_epoch_110.pth
2025-11-22 21:57:07 - GraphTrainer - INFO - ============================================================
2025-11-22 21:57:07 - GraphTrainer - INFO - 开始第 111/1000 轮训练
2025-11-22 21:57:07 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3284, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3262, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3580, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3094, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3537, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3191, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3248, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3274, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3135, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3615, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3276, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3176, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3246, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3333, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3620, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3574, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3607, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3132, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3494, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3599, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3154, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3742, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3561, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3573, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3626, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
The 110 training average loss: 0.3410479708992202
2025-11-22 21:57:18 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:57:18 - GraphTrainer - INFO -   precision@5: 0.006583
2025-11-22 21:57:18 - GraphTrainer - INFO -   recall@5: 0.031365
2025-11-22 21:57:18 - GraphTrainer - INFO -   hit_rate@5: 0.032862
2025-11-22 21:57:18 - GraphTrainer - INFO -   ndcg@5: 0.020235
2025-11-22 21:57:18 - GraphTrainer - INFO -   map@5: 0.016348
2025-11-22 21:57:18 - GraphTrainer - INFO -   mrr@5: 0.016990
2025-11-22 21:57:18 - GraphTrainer - INFO -   precision@10: 0.005194
2025-11-22 21:57:18 - GraphTrainer - INFO -   recall@10: 0.049659
2025-11-22 21:57:18 - GraphTrainer - INFO -   hit_rate@10: 0.051839
2025-11-22 21:57:18 - GraphTrainer - INFO -   ndcg@10: 0.026173
2025-11-22 21:57:18 - GraphTrainer - INFO -   map@10: 0.018772
2025-11-22 21:57:18 - GraphTrainer - INFO -   mrr@10: 0.019500
2025-11-22 21:57:18 - GraphTrainer - INFO -   precision@20: 0.004073
2025-11-22 21:57:18 - GraphTrainer - INFO -   recall@20: 0.077055
2025-11-22 21:57:18 - GraphTrainer - INFO -   hit_rate@20: 0.081101
2025-11-22 21:57:18 - GraphTrainer - INFO -   ndcg@20: 0.033152
2025-11-22 21:57:18 - GraphTrainer - INFO -   map@20: 0.020631
2025-11-22 21:57:18 - GraphTrainer - INFO -   mrr@20: 0.021486
2025-11-22 21:57:18 - GraphTrainer - INFO - 第 111 轮训练完成
2025-11-22 21:57:18 - GraphTrainer - INFO - train_loss: 0.343264
2025-11-22 21:57:18 - GraphTrainer - INFO - precision@5: 0.006583
2025-11-22 21:57:18 - GraphTrainer - INFO - recall@5: 0.031365
2025-11-22 21:57:18 - GraphTrainer - INFO - hit_rate@5: 0.032862
2025-11-22 21:57:18 - GraphTrainer - INFO - ndcg@5: 0.020235
2025-11-22 21:57:18 - GraphTrainer - INFO - map@5: 0.016348
2025-11-22 21:57:18 - GraphTrainer - INFO - mrr@5: 0.016990
2025-11-22 21:57:18 - GraphTrainer - INFO - precision@10: 0.005194
2025-11-22 21:57:18 - GraphTrainer - INFO - recall@10: 0.049659
2025-11-22 21:57:18 - GraphTrainer - INFO - hit_rate@10: 0.051839
2025-11-22 21:57:18 - GraphTrainer - INFO - ndcg@10: 0.026173
2025-11-22 21:57:18 - GraphTrainer - INFO - map@10: 0.018772
2025-11-22 21:57:18 - GraphTrainer - INFO - mrr@10: 0.019500
2025-11-22 21:57:18 - GraphTrainer - INFO - precision@20: 0.004073
2025-11-22 21:57:18 - GraphTrainer - INFO - recall@20: 0.077055
2025-11-22 21:57:18 - GraphTrainer - INFO - hit_rate@20: 0.081101
2025-11-22 21:57:18 - GraphTrainer - INFO - ndcg@20: 0.033152
2025-11-22 21:57:18 - GraphTrainer - INFO - map@20: 0.020631
2025-11-22 21:57:18 - GraphTrainer - INFO - mrr@20: 0.021486
2025-11-22 21:57:18 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:57:18 - GraphTrainer - INFO - ============================================================
2025-11-22 21:57:18 - GraphTrainer - INFO - 开始第 112/1000 轮训练
2025-11-22 21:57:18 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3537, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3200, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3510, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3306, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3490, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3626, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3195, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3421, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3128, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3479, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3607, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3261, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3373, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3260, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3573, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3731, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3558, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3591, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3556, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3673, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3213, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3601, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3639, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3632, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3302, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3533, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
The 111 training average loss: 0.34326426427939843
2025-11-22 21:57:29 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:57:29 - GraphTrainer - INFO -   precision@5: 0.006624
2025-11-22 21:57:29 - GraphTrainer - INFO -   recall@5: 0.031705
2025-11-22 21:57:29 - GraphTrainer - INFO -   hit_rate@5: 0.033068
2025-11-22 21:57:29 - GraphTrainer - INFO -   ndcg@5: 0.020490
2025-11-22 21:57:29 - GraphTrainer - INFO -   map@5: 0.016595
2025-11-22 21:57:29 - GraphTrainer - INFO -   mrr@5: 0.017222
2025-11-22 21:57:29 - GraphTrainer - INFO -   precision@10: 0.005204
2025-11-22 21:57:29 - GraphTrainer - INFO -   recall@10: 0.049356
2025-11-22 21:57:29 - GraphTrainer - INFO -   hit_rate@10: 0.051941
2025-11-22 21:57:29 - GraphTrainer - INFO -   ndcg@10: 0.026269
2025-11-22 21:57:29 - GraphTrainer - INFO -   map@10: 0.018947
2025-11-22 21:57:29 - GraphTrainer - INFO -   mrr@10: 0.019725
2025-11-22 21:57:29 - GraphTrainer - INFO -   precision@20: 0.004073
2025-11-22 21:57:29 - GraphTrainer - INFO -   recall@20: 0.077129
2025-11-22 21:57:29 - GraphTrainer - INFO -   hit_rate@20: 0.081101
2025-11-22 21:57:29 - GraphTrainer - INFO -   ndcg@20: 0.033335
2025-11-22 21:57:29 - GraphTrainer - INFO -   map@20: 0.020846
2025-11-22 21:57:29 - GraphTrainer - INFO -   mrr@20: 0.021717
2025-11-22 21:57:29 - GraphTrainer - INFO - 第 112 轮训练完成
2025-11-22 21:57:29 - GraphTrainer - INFO - train_loss: 0.341881
2025-11-22 21:57:29 - GraphTrainer - INFO - precision@5: 0.006624
2025-11-22 21:57:29 - GraphTrainer - INFO - recall@5: 0.031705
2025-11-22 21:57:29 - GraphTrainer - INFO - hit_rate@5: 0.033068
2025-11-22 21:57:29 - GraphTrainer - INFO - ndcg@5: 0.020490
2025-11-22 21:57:29 - GraphTrainer - INFO - map@5: 0.016595
2025-11-22 21:57:29 - GraphTrainer - INFO - mrr@5: 0.017222
2025-11-22 21:57:29 - GraphTrainer - INFO - precision@10: 0.005204
2025-11-22 21:57:29 - GraphTrainer - INFO - recall@10: 0.049356
2025-11-22 21:57:29 - GraphTrainer - INFO - hit_rate@10: 0.051941
2025-11-22 21:57:29 - GraphTrainer - INFO - ndcg@10: 0.026269
2025-11-22 21:57:29 - GraphTrainer - INFO - map@10: 0.018947
2025-11-22 21:57:29 - GraphTrainer - INFO - mrr@10: 0.019725
2025-11-22 21:57:29 - GraphTrainer - INFO - precision@20: 0.004073
2025-11-22 21:57:29 - GraphTrainer - INFO - recall@20: 0.077129
2025-11-22 21:57:29 - GraphTrainer - INFO - hit_rate@20: 0.081101
2025-11-22 21:57:29 - GraphTrainer - INFO - ndcg@20: 0.033335
2025-11-22 21:57:29 - GraphTrainer - INFO - map@20: 0.020846
2025-11-22 21:57:29 - GraphTrainer - INFO - mrr@20: 0.021717
2025-11-22 21:57:29 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:57:29 - GraphTrainer - INFO - ============================================================
2025-11-22 21:57:29 - GraphTrainer - INFO - 开始第 113/1000 轮训练
2025-11-22 21:57:29 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3537, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3331, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3228, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3273, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3279, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3304, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3302, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3708, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3729, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3276, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3290, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3556, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3492, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3663, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3234, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3217, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3622, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3502, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3628, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3574, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3698, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3517, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3254, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3529, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3318, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3525, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3333, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3521, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3221, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
The 112 training average loss: 0.3418808404741616
2025-11-22 21:57:40 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:57:40 - GraphTrainer - INFO -   precision@5: 0.006572
2025-11-22 21:57:40 - GraphTrainer - INFO -   recall@5: 0.031345
2025-11-22 21:57:40 - GraphTrainer - INFO -   hit_rate@5: 0.032810
2025-11-22 21:57:40 - GraphTrainer - INFO -   ndcg@5: 0.020581
2025-11-22 21:57:40 - GraphTrainer - INFO -   map@5: 0.016803
2025-11-22 21:57:40 - GraphTrainer - INFO -   mrr@5: 0.017486
2025-11-22 21:57:40 - GraphTrainer - INFO -   precision@10: 0.005204
2025-11-22 21:57:40 - GraphTrainer - INFO -   recall@10: 0.049586
2025-11-22 21:57:40 - GraphTrainer - INFO -   hit_rate@10: 0.051941
2025-11-22 21:57:40 - GraphTrainer - INFO -   ndcg@10: 0.026421
2025-11-22 21:57:40 - GraphTrainer - INFO -   map@10: 0.019127
2025-11-22 21:57:40 - GraphTrainer - INFO -   mrr@10: 0.019920
2025-11-22 21:57:40 - GraphTrainer - INFO -   precision@20: 0.004135
2025-11-22 21:57:40 - GraphTrainer - INFO -   recall@20: 0.078226
2025-11-22 21:57:40 - GraphTrainer - INFO -   hit_rate@20: 0.082181
2025-11-22 21:57:40 - GraphTrainer - INFO -   ndcg@20: 0.033703
2025-11-22 21:57:40 - GraphTrainer - INFO -   map@20: 0.021071
2025-11-22 21:57:40 - GraphTrainer - INFO -   mrr@20: 0.021971
2025-11-22 21:57:40 - GraphTrainer - INFO - 第 113 轮训练完成
2025-11-22 21:57:40 - GraphTrainer - INFO - train_loss: 0.341860
2025-11-22 21:57:40 - GraphTrainer - INFO - precision@5: 0.006572
2025-11-22 21:57:40 - GraphTrainer - INFO - recall@5: 0.031345
2025-11-22 21:57:40 - GraphTrainer - INFO - hit_rate@5: 0.032810
2025-11-22 21:57:40 - GraphTrainer - INFO - ndcg@5: 0.020581
2025-11-22 21:57:40 - GraphTrainer - INFO - map@5: 0.016803
2025-11-22 21:57:40 - GraphTrainer - INFO - mrr@5: 0.017486
2025-11-22 21:57:40 - GraphTrainer - INFO - precision@10: 0.005204
2025-11-22 21:57:40 - GraphTrainer - INFO - recall@10: 0.049586
2025-11-22 21:57:40 - GraphTrainer - INFO - hit_rate@10: 0.051941
2025-11-22 21:57:40 - GraphTrainer - INFO - ndcg@10: 0.026421
2025-11-22 21:57:40 - GraphTrainer - INFO - map@10: 0.019127
2025-11-22 21:57:40 - GraphTrainer - INFO - mrr@10: 0.019920
2025-11-22 21:57:40 - GraphTrainer - INFO - precision@20: 0.004135
2025-11-22 21:57:40 - GraphTrainer - INFO - recall@20: 0.078226
2025-11-22 21:57:40 - GraphTrainer - INFO - hit_rate@20: 0.082181
2025-11-22 21:57:40 - GraphTrainer - INFO - ndcg@20: 0.033703
2025-11-22 21:57:40 - GraphTrainer - INFO - map@20: 0.021071
2025-11-22 21:57:40 - GraphTrainer - INFO - mrr@20: 0.021971
2025-11-22 21:57:40 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:57:40 - GraphTrainer - INFO - ============================================================
2025-11-22 21:57:40 - GraphTrainer - INFO - 开始第 114/1000 轮训练
2025-11-22 21:57:40 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3653, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3516, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3468, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3240, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3659, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3285, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3591, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3492, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3818, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3276, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3159, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3208, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3480, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3518, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3543, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3638, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3240, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3272, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3201, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3644, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3558, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3379, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3290, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3636, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3232, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3631, device='cuda:0', grad_fn=<AddBackward0>)
The 113 training average loss: 0.34185978924405985
2025-11-22 21:57:51 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:57:51 - GraphTrainer - INFO -   precision@5: 0.006593
2025-11-22 21:57:51 - GraphTrainer - INFO -   recall@5: 0.031452
2025-11-22 21:57:51 - GraphTrainer - INFO -   hit_rate@5: 0.032913
2025-11-22 21:57:51 - GraphTrainer - INFO -   ndcg@5: 0.020687
2025-11-22 21:57:51 - GraphTrainer - INFO -   map@5: 0.016932
2025-11-22 21:57:51 - GraphTrainer - INFO -   mrr@5: 0.017568
2025-11-22 21:57:51 - GraphTrainer - INFO -   precision@10: 0.005132
2025-11-22 21:57:51 - GraphTrainer - INFO -   recall@10: 0.048949
2025-11-22 21:57:51 - GraphTrainer - INFO -   hit_rate@10: 0.051221
2025-11-22 21:57:51 - GraphTrainer - INFO -   ndcg@10: 0.026356
2025-11-22 21:57:51 - GraphTrainer - INFO -   map@10: 0.019229
2025-11-22 21:57:51 - GraphTrainer - INFO -   mrr@10: 0.019975
2025-11-22 21:57:51 - GraphTrainer - INFO -   precision@20: 0.004088
2025-11-22 21:57:51 - GraphTrainer - INFO -   recall@20: 0.077424
2025-11-22 21:57:51 - GraphTrainer - INFO -   hit_rate@20: 0.081358
2025-11-22 21:57:51 - GraphTrainer - INFO -   ndcg@20: 0.033616
2025-11-22 21:57:51 - GraphTrainer - INFO -   map@20: 0.021179
2025-11-22 21:57:51 - GraphTrainer - INFO -   mrr@20: 0.022034
2025-11-22 21:57:51 - GraphTrainer - INFO - 第 114 轮训练完成
2025-11-22 21:57:51 - GraphTrainer - INFO - train_loss: 0.339898
2025-11-22 21:57:51 - GraphTrainer - INFO - precision@5: 0.006593
2025-11-22 21:57:51 - GraphTrainer - INFO - recall@5: 0.031452
2025-11-22 21:57:51 - GraphTrainer - INFO - hit_rate@5: 0.032913
2025-11-22 21:57:51 - GraphTrainer - INFO - ndcg@5: 0.020687
2025-11-22 21:57:51 - GraphTrainer - INFO - map@5: 0.016932
2025-11-22 21:57:51 - GraphTrainer - INFO - mrr@5: 0.017568
2025-11-22 21:57:51 - GraphTrainer - INFO - precision@10: 0.005132
2025-11-22 21:57:51 - GraphTrainer - INFO - recall@10: 0.048949
2025-11-22 21:57:51 - GraphTrainer - INFO - hit_rate@10: 0.051221
2025-11-22 21:57:51 - GraphTrainer - INFO - ndcg@10: 0.026356
2025-11-22 21:57:51 - GraphTrainer - INFO - map@10: 0.019229
2025-11-22 21:57:51 - GraphTrainer - INFO - mrr@10: 0.019975
2025-11-22 21:57:51 - GraphTrainer - INFO - precision@20: 0.004088
2025-11-22 21:57:51 - GraphTrainer - INFO - recall@20: 0.077424
2025-11-22 21:57:51 - GraphTrainer - INFO - hit_rate@20: 0.081358
2025-11-22 21:57:51 - GraphTrainer - INFO - ndcg@20: 0.033616
2025-11-22 21:57:51 - GraphTrainer - INFO - map@20: 0.021179
2025-11-22 21:57:51 - GraphTrainer - INFO - mrr@20: 0.022034
2025-11-22 21:57:51 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:57:51 - GraphTrainer - INFO - ============================================================
2025-11-22 21:57:51 - GraphTrainer - INFO - 开始第 115/1000 轮训练
2025-11-22 21:57:51 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3584, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3219, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3507, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3205, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3228, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3215, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3636, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3533, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3184, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3682, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3532, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3625, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3333, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3156, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3258, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3241, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3186, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3200, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3634, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3293, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3509, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3529, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3570, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3210, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3569, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>)
The 114 training average loss: 0.3398977142983469
2025-11-22 21:58:02 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:58:02 - GraphTrainer - INFO -   precision@5: 0.006716
2025-11-22 21:58:02 - GraphTrainer - INFO -   recall@5: 0.032099
2025-11-22 21:58:02 - GraphTrainer - INFO -   hit_rate@5: 0.033530
2025-11-22 21:58:02 - GraphTrainer - INFO -   ndcg@5: 0.020809
2025-11-22 21:58:02 - GraphTrainer - INFO -   map@5: 0.016886
2025-11-22 21:58:02 - GraphTrainer - INFO -   mrr@5: 0.017535
2025-11-22 21:58:02 - GraphTrainer - INFO -   precision@10: 0.005225
2025-11-22 21:58:02 - GraphTrainer - INFO -   recall@10: 0.049760
2025-11-22 21:58:02 - GraphTrainer - INFO -   hit_rate@10: 0.052147
2025-11-22 21:58:02 - GraphTrainer - INFO -   ndcg@10: 0.026507
2025-11-22 21:58:02 - GraphTrainer - INFO -   map@10: 0.019174
2025-11-22 21:58:02 - GraphTrainer - INFO -   mrr@10: 0.019943
2025-11-22 21:58:02 - GraphTrainer - INFO -   precision@20: 0.004150
2025-11-22 21:58:02 - GraphTrainer - INFO -   recall@20: 0.078632
2025-11-22 21:58:02 - GraphTrainer - INFO -   hit_rate@20: 0.082592
2025-11-22 21:58:02 - GraphTrainer - INFO -   ndcg@20: 0.033813
2025-11-22 21:58:02 - GraphTrainer - INFO -   map@20: 0.021111
2025-11-22 21:58:02 - GraphTrainer - INFO -   mrr@20: 0.021983
2025-11-22 21:58:02 - GraphTrainer - INFO - 第 115 轮训练完成
2025-11-22 21:58:02 - GraphTrainer - INFO - train_loss: 0.342811
2025-11-22 21:58:02 - GraphTrainer - INFO - precision@5: 0.006716
2025-11-22 21:58:02 - GraphTrainer - INFO - recall@5: 0.032099
2025-11-22 21:58:02 - GraphTrainer - INFO - hit_rate@5: 0.033530
2025-11-22 21:58:02 - GraphTrainer - INFO - ndcg@5: 0.020809
2025-11-22 21:58:02 - GraphTrainer - INFO - map@5: 0.016886
2025-11-22 21:58:02 - GraphTrainer - INFO - mrr@5: 0.017535
2025-11-22 21:58:02 - GraphTrainer - INFO - precision@10: 0.005225
2025-11-22 21:58:02 - GraphTrainer - INFO - recall@10: 0.049760
2025-11-22 21:58:02 - GraphTrainer - INFO - hit_rate@10: 0.052147
2025-11-22 21:58:02 - GraphTrainer - INFO - ndcg@10: 0.026507
2025-11-22 21:58:02 - GraphTrainer - INFO - map@10: 0.019174
2025-11-22 21:58:02 - GraphTrainer - INFO - mrr@10: 0.019943
2025-11-22 21:58:02 - GraphTrainer - INFO - precision@20: 0.004150
2025-11-22 21:58:02 - GraphTrainer - INFO - recall@20: 0.078632
2025-11-22 21:58:02 - GraphTrainer - INFO - hit_rate@20: 0.082592
2025-11-22 21:58:02 - GraphTrainer - INFO - ndcg@20: 0.033813
2025-11-22 21:58:02 - GraphTrainer - INFO - map@20: 0.021111
2025-11-22 21:58:02 - GraphTrainer - INFO - mrr@20: 0.021983
2025-11-22 21:58:02 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:58:02 - GraphTrainer - INFO - ============================================================
2025-11-22 21:58:02 - GraphTrainer - INFO - 开始第 116/1000 轮训练
2025-11-22 21:58:02 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3490, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3502, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3379, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3318, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3517, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3252, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3521, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3543, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3312, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3240, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3629, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3823, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3512, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3290, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3484, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3547, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3421, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3499, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3327, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3516, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3537, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
The 115 training average loss: 0.3428106719049914
2025-11-22 21:58:13 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:58:13 - GraphTrainer - INFO -   precision@5: 0.006747
2025-11-22 21:58:13 - GraphTrainer - INFO -   recall@5: 0.032112
2025-11-22 21:58:13 - GraphTrainer - INFO -   hit_rate@5: 0.033685
2025-11-22 21:58:13 - GraphTrainer - INFO -   ndcg@5: 0.020809
2025-11-22 21:58:13 - GraphTrainer - INFO -   map@5: 0.016864
2025-11-22 21:58:13 - GraphTrainer - INFO -   mrr@5: 0.017543
2025-11-22 21:58:13 - GraphTrainer - INFO -   precision@10: 0.005276
2025-11-22 21:58:13 - GraphTrainer - INFO -   recall@10: 0.049991
2025-11-22 21:58:13 - GraphTrainer - INFO -   hit_rate@10: 0.052661
2025-11-22 21:58:13 - GraphTrainer - INFO -   ndcg@10: 0.026575
2025-11-22 21:58:13 - GraphTrainer - INFO -   map@10: 0.019173
2025-11-22 21:58:13 - GraphTrainer - INFO -   mrr@10: 0.019979
2025-11-22 21:58:13 - GraphTrainer - INFO -   precision@20: 0.004137
2025-11-22 21:58:13 - GraphTrainer - INFO -   recall@20: 0.078222
2025-11-22 21:58:13 - GraphTrainer - INFO -   hit_rate@20: 0.082335
2025-11-22 21:58:13 - GraphTrainer - INFO -   ndcg@20: 0.033741
2025-11-22 21:58:13 - GraphTrainer - INFO -   map@20: 0.021089
2025-11-22 21:58:13 - GraphTrainer - INFO -   mrr@20: 0.021986
2025-11-22 21:58:13 - GraphTrainer - INFO - 第 116 轮训练完成
2025-11-22 21:58:13 - GraphTrainer - INFO - train_loss: 0.342908
2025-11-22 21:58:13 - GraphTrainer - INFO - precision@5: 0.006747
2025-11-22 21:58:13 - GraphTrainer - INFO - recall@5: 0.032112
2025-11-22 21:58:13 - GraphTrainer - INFO - hit_rate@5: 0.033685
2025-11-22 21:58:13 - GraphTrainer - INFO - ndcg@5: 0.020809
2025-11-22 21:58:13 - GraphTrainer - INFO - map@5: 0.016864
2025-11-22 21:58:13 - GraphTrainer - INFO - mrr@5: 0.017543
2025-11-22 21:58:13 - GraphTrainer - INFO - precision@10: 0.005276
2025-11-22 21:58:13 - GraphTrainer - INFO - recall@10: 0.049991
2025-11-22 21:58:13 - GraphTrainer - INFO - hit_rate@10: 0.052661
2025-11-22 21:58:13 - GraphTrainer - INFO - ndcg@10: 0.026575
2025-11-22 21:58:13 - GraphTrainer - INFO - map@10: 0.019173
2025-11-22 21:58:13 - GraphTrainer - INFO - mrr@10: 0.019979
2025-11-22 21:58:13 - GraphTrainer - INFO - precision@20: 0.004137
2025-11-22 21:58:13 - GraphTrainer - INFO - recall@20: 0.078222
2025-11-22 21:58:13 - GraphTrainer - INFO - hit_rate@20: 0.082335
2025-11-22 21:58:13 - GraphTrainer - INFO - ndcg@20: 0.033741
2025-11-22 21:58:13 - GraphTrainer - INFO - map@20: 0.021089
2025-11-22 21:58:13 - GraphTrainer - INFO - mrr@20: 0.021986
2025-11-22 21:58:13 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:58:13 - GraphTrainer - INFO - ============================================================
2025-11-22 21:58:13 - GraphTrainer - INFO - 开始第 117/1000 轮训练
2025-11-22 21:58:13 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3281, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3376, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3565, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3518, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3176, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3570, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3653, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3655, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3773, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3632, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3626, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3220, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3256, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3684, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3293, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3580, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3468, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3457, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3276, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3502, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3197, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)
The 116 training average loss: 0.3429079266457722
2025-11-22 21:58:24 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:58:24 - GraphTrainer - INFO -   precision@5: 0.006747
2025-11-22 21:58:24 - GraphTrainer - INFO -   recall@5: 0.032123
2025-11-22 21:58:24 - GraphTrainer - INFO -   hit_rate@5: 0.033685
2025-11-22 21:58:24 - GraphTrainer - INFO -   ndcg@5: 0.021074
2025-11-22 21:58:24 - GraphTrainer - INFO -   map@5: 0.017210
2025-11-22 21:58:24 - GraphTrainer - INFO -   mrr@5: 0.017886
2025-11-22 21:58:24 - GraphTrainer - INFO -   precision@10: 0.005323
2025-11-22 21:58:24 - GraphTrainer - INFO -   recall@10: 0.050436
2025-11-22 21:58:24 - GraphTrainer - INFO -   hit_rate@10: 0.053021
2025-11-22 21:58:24 - GraphTrainer - INFO -   ndcg@10: 0.026947
2025-11-22 21:58:24 - GraphTrainer - INFO -   map@10: 0.019545
2025-11-22 21:58:24 - GraphTrainer - INFO -   mrr@10: 0.020343
2025-11-22 21:58:24 - GraphTrainer - INFO -   precision@20: 0.004137
2025-11-22 21:58:24 - GraphTrainer - INFO -   recall@20: 0.078456
2025-11-22 21:58:24 - GraphTrainer - INFO -   hit_rate@20: 0.082335
2025-11-22 21:58:24 - GraphTrainer - INFO -   ndcg@20: 0.034044
2025-11-22 21:58:24 - GraphTrainer - INFO -   map@20: 0.021441
2025-11-22 21:58:24 - GraphTrainer - INFO -   mrr@20: 0.022323
2025-11-22 21:58:24 - GraphTrainer - INFO - 第 117 轮训练完成
2025-11-22 21:58:24 - GraphTrainer - INFO - train_loss: 0.337363
2025-11-22 21:58:24 - GraphTrainer - INFO - precision@5: 0.006747
2025-11-22 21:58:24 - GraphTrainer - INFO - recall@5: 0.032123
2025-11-22 21:58:24 - GraphTrainer - INFO - hit_rate@5: 0.033685
2025-11-22 21:58:24 - GraphTrainer - INFO - ndcg@5: 0.021074
2025-11-22 21:58:24 - GraphTrainer - INFO - map@5: 0.017210
2025-11-22 21:58:24 - GraphTrainer - INFO - mrr@5: 0.017886
2025-11-22 21:58:24 - GraphTrainer - INFO - precision@10: 0.005323
2025-11-22 21:58:24 - GraphTrainer - INFO - recall@10: 0.050436
2025-11-22 21:58:24 - GraphTrainer - INFO - hit_rate@10: 0.053021
2025-11-22 21:58:24 - GraphTrainer - INFO - ndcg@10: 0.026947
2025-11-22 21:58:24 - GraphTrainer - INFO - map@10: 0.019545
2025-11-22 21:58:24 - GraphTrainer - INFO - mrr@10: 0.020343
2025-11-22 21:58:24 - GraphTrainer - INFO - precision@20: 0.004137
2025-11-22 21:58:24 - GraphTrainer - INFO - recall@20: 0.078456
2025-11-22 21:58:24 - GraphTrainer - INFO - hit_rate@20: 0.082335
2025-11-22 21:58:24 - GraphTrainer - INFO - ndcg@20: 0.034044
2025-11-22 21:58:24 - GraphTrainer - INFO - map@20: 0.021441
2025-11-22 21:58:24 - GraphTrainer - INFO - mrr@20: 0.022323
2025-11-22 21:58:24 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:58:24 - GraphTrainer - INFO - ============================================================
2025-11-22 21:58:24 - GraphTrainer - INFO - 开始第 118/1000 轮训练
2025-11-22 21:58:24 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3261, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3261, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3303, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3190, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3318, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3146, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3244, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3163, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3573, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3533, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3197, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3262, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3309, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3218, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3580, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3303, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
The 117 training average loss: 0.33736322203586844
2025-11-22 21:58:35 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:58:35 - GraphTrainer - INFO -   precision@5: 0.006624
2025-11-22 21:58:35 - GraphTrainer - INFO -   recall@5: 0.031506
2025-11-22 21:58:35 - GraphTrainer - INFO -   hit_rate@5: 0.033016
2025-11-22 21:58:35 - GraphTrainer - INFO -   ndcg@5: 0.020259
2025-11-22 21:58:35 - GraphTrainer - INFO -   map@5: 0.016326
2025-11-22 21:58:35 - GraphTrainer - INFO -   mrr@5: 0.017021
2025-11-22 21:58:35 - GraphTrainer - INFO -   precision@10: 0.005184
2025-11-22 21:58:35 - GraphTrainer - INFO -   recall@10: 0.049184
2025-11-22 21:58:35 - GraphTrainer - INFO -   hit_rate@10: 0.051736
2025-11-22 21:58:35 - GraphTrainer - INFO -   ndcg@10: 0.026004
2025-11-22 21:58:35 - GraphTrainer - INFO -   map@10: 0.018653
2025-11-22 21:58:35 - GraphTrainer - INFO -   mrr@10: 0.019479
2025-11-22 21:58:35 - GraphTrainer - INFO -   precision@20: 0.004114
2025-11-22 21:58:35 - GraphTrainer - INFO -   recall@20: 0.077818
2025-11-22 21:58:35 - GraphTrainer - INFO -   hit_rate@20: 0.081872
2025-11-22 21:58:35 - GraphTrainer - INFO -   ndcg@20: 0.033292
2025-11-22 21:58:35 - GraphTrainer - INFO -   map@20: 0.020613
2025-11-22 21:58:35 - GraphTrainer - INFO -   mrr@20: 0.021534
2025-11-22 21:58:35 - GraphTrainer - INFO - 第 118 轮训练完成
2025-11-22 21:58:35 - GraphTrainer - INFO - train_loss: 0.340410
2025-11-22 21:58:35 - GraphTrainer - INFO - precision@5: 0.006624
2025-11-22 21:58:35 - GraphTrainer - INFO - recall@5: 0.031506
2025-11-22 21:58:35 - GraphTrainer - INFO - hit_rate@5: 0.033016
2025-11-22 21:58:35 - GraphTrainer - INFO - ndcg@5: 0.020259
2025-11-22 21:58:35 - GraphTrainer - INFO - map@5: 0.016326
2025-11-22 21:58:35 - GraphTrainer - INFO - mrr@5: 0.017021
2025-11-22 21:58:35 - GraphTrainer - INFO - precision@10: 0.005184
2025-11-22 21:58:35 - GraphTrainer - INFO - recall@10: 0.049184
2025-11-22 21:58:35 - GraphTrainer - INFO - hit_rate@10: 0.051736
2025-11-22 21:58:35 - GraphTrainer - INFO - ndcg@10: 0.026004
2025-11-22 21:58:35 - GraphTrainer - INFO - map@10: 0.018653
2025-11-22 21:58:35 - GraphTrainer - INFO - mrr@10: 0.019479
2025-11-22 21:58:35 - GraphTrainer - INFO - precision@20: 0.004114
2025-11-22 21:58:35 - GraphTrainer - INFO - recall@20: 0.077818
2025-11-22 21:58:35 - GraphTrainer - INFO - hit_rate@20: 0.081872
2025-11-22 21:58:35 - GraphTrainer - INFO - ndcg@20: 0.033292
2025-11-22 21:58:35 - GraphTrainer - INFO - map@20: 0.020613
2025-11-22 21:58:35 - GraphTrainer - INFO - mrr@20: 0.021534
2025-11-22 21:58:35 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:58:35 - GraphTrainer - INFO - ============================================================
2025-11-22 21:58:35 - GraphTrainer - INFO - 开始第 119/1000 轮训练
2025-11-22 21:58:35 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3468, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3201, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3611, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3569, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3202, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3710, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3306, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3316, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3611, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3117, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3539, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3794, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3480, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3217, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3306, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3622, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3260, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3579, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3610, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3531, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3318, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3153, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3235, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3258, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)
The 118 training average loss: 0.34040974594395734
2025-11-22 21:58:46 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:58:46 - GraphTrainer - INFO -   precision@5: 0.006593
2025-11-22 21:58:46 - GraphTrainer - INFO -   recall@5: 0.031460
2025-11-22 21:58:46 - GraphTrainer - INFO -   hit_rate@5: 0.032862
2025-11-22 21:58:46 - GraphTrainer - INFO -   ndcg@5: 0.020254
2025-11-22 21:58:46 - GraphTrainer - INFO -   map@5: 0.016347
2025-11-22 21:58:46 - GraphTrainer - INFO -   mrr@5: 0.017015
2025-11-22 21:58:46 - GraphTrainer - INFO -   precision@10: 0.005194
2025-11-22 21:58:46 - GraphTrainer - INFO -   recall@10: 0.049460
2025-11-22 21:58:46 - GraphTrainer - INFO -   hit_rate@10: 0.051787
2025-11-22 21:58:46 - GraphTrainer - INFO -   ndcg@10: 0.026082
2025-11-22 21:58:46 - GraphTrainer - INFO -   map@10: 0.018703
2025-11-22 21:58:46 - GraphTrainer - INFO -   mrr@10: 0.019492
2025-11-22 21:58:46 - GraphTrainer - INFO -   precision@20: 0.004130
2025-11-22 21:58:46 - GraphTrainer - INFO -   recall@20: 0.078251
2025-11-22 21:58:46 - GraphTrainer - INFO -   hit_rate@20: 0.082181
2025-11-22 21:58:46 - GraphTrainer - INFO -   ndcg@20: 0.033384
2025-11-22 21:58:46 - GraphTrainer - INFO -   map@20: 0.020647
2025-11-22 21:58:46 - GraphTrainer - INFO -   mrr@20: 0.021546
2025-11-22 21:58:46 - GraphTrainer - INFO - 第 119 轮训练完成
2025-11-22 21:58:46 - GraphTrainer - INFO - train_loss: 0.339022
2025-11-22 21:58:46 - GraphTrainer - INFO - precision@5: 0.006593
2025-11-22 21:58:46 - GraphTrainer - INFO - recall@5: 0.031460
2025-11-22 21:58:46 - GraphTrainer - INFO - hit_rate@5: 0.032862
2025-11-22 21:58:46 - GraphTrainer - INFO - ndcg@5: 0.020254
2025-11-22 21:58:46 - GraphTrainer - INFO - map@5: 0.016347
2025-11-22 21:58:46 - GraphTrainer - INFO - mrr@5: 0.017015
2025-11-22 21:58:46 - GraphTrainer - INFO - precision@10: 0.005194
2025-11-22 21:58:46 - GraphTrainer - INFO - recall@10: 0.049460
2025-11-22 21:58:46 - GraphTrainer - INFO - hit_rate@10: 0.051787
2025-11-22 21:58:46 - GraphTrainer - INFO - ndcg@10: 0.026082
2025-11-22 21:58:46 - GraphTrainer - INFO - map@10: 0.018703
2025-11-22 21:58:46 - GraphTrainer - INFO - mrr@10: 0.019492
2025-11-22 21:58:46 - GraphTrainer - INFO - precision@20: 0.004130
2025-11-22 21:58:46 - GraphTrainer - INFO - recall@20: 0.078251
2025-11-22 21:58:46 - GraphTrainer - INFO - hit_rate@20: 0.082181
2025-11-22 21:58:46 - GraphTrainer - INFO - ndcg@20: 0.033384
2025-11-22 21:58:46 - GraphTrainer - INFO - map@20: 0.020647
2025-11-22 21:58:46 - GraphTrainer - INFO - mrr@20: 0.021546
2025-11-22 21:58:46 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:58:46 - GraphTrainer - INFO - ============================================================
2025-11-22 21:58:46 - GraphTrainer - INFO - 开始第 120/1000 轮训练
2025-11-22 21:58:46 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3333, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3274, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3240, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3545, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3557, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3409, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3595, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3479, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3107, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3543, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3534, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3544, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3632, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3480, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3213, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3306, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3297, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3248, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3312, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3189, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3704, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3252, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3561, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3167, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3039, device='cuda:0', grad_fn=<AddBackward0>)
The 119 training average loss: 0.3390215224233167
2025-11-22 21:58:57 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:58:57 - GraphTrainer - INFO -   precision@5: 0.006531
2025-11-22 21:58:57 - GraphTrainer - INFO -   recall@5: 0.031255
2025-11-22 21:58:57 - GraphTrainer - INFO -   hit_rate@5: 0.032605
2025-11-22 21:58:57 - GraphTrainer - INFO -   ndcg@5: 0.020154
2025-11-22 21:58:57 - GraphTrainer - INFO -   map@5: 0.016288
2025-11-22 21:58:57 - GraphTrainer - INFO -   mrr@5: 0.016926
2025-11-22 21:58:57 - GraphTrainer - INFO -   precision@10: 0.005117
2025-11-22 21:58:57 - GraphTrainer - INFO -   recall@10: 0.048554
2025-11-22 21:58:57 - GraphTrainer - INFO -   hit_rate@10: 0.050964
2025-11-22 21:58:57 - GraphTrainer - INFO -   ndcg@10: 0.025795
2025-11-22 21:58:57 - GraphTrainer - INFO -   map@10: 0.018577
2025-11-22 21:58:57 - GraphTrainer - INFO -   mrr@10: 0.019348
2025-11-22 21:58:57 - GraphTrainer - INFO -   precision@20: 0.004070
2025-11-22 21:58:57 - GraphTrainer - INFO -   recall@20: 0.077122
2025-11-22 21:58:57 - GraphTrainer - INFO -   hit_rate@20: 0.080946
2025-11-22 21:58:57 - GraphTrainer - INFO -   ndcg@20: 0.033056
2025-11-22 21:58:57 - GraphTrainer - INFO -   map@20: 0.020525
2025-11-22 21:58:57 - GraphTrainer - INFO -   mrr@20: 0.021388
2025-11-22 21:58:57 - GraphTrainer - INFO - 第 120 轮训练完成
2025-11-22 21:58:57 - GraphTrainer - INFO - train_loss: 0.337713
2025-11-22 21:58:57 - GraphTrainer - INFO - precision@5: 0.006531
2025-11-22 21:58:57 - GraphTrainer - INFO - recall@5: 0.031255
2025-11-22 21:58:57 - GraphTrainer - INFO - hit_rate@5: 0.032605
2025-11-22 21:58:57 - GraphTrainer - INFO - ndcg@5: 0.020154
2025-11-22 21:58:57 - GraphTrainer - INFO - map@5: 0.016288
2025-11-22 21:58:57 - GraphTrainer - INFO - mrr@5: 0.016926
2025-11-22 21:58:57 - GraphTrainer - INFO - precision@10: 0.005117
2025-11-22 21:58:57 - GraphTrainer - INFO - recall@10: 0.048554
2025-11-22 21:58:57 - GraphTrainer - INFO - hit_rate@10: 0.050964
2025-11-22 21:58:57 - GraphTrainer - INFO - ndcg@10: 0.025795
2025-11-22 21:58:57 - GraphTrainer - INFO - map@10: 0.018577
2025-11-22 21:58:57 - GraphTrainer - INFO - mrr@10: 0.019348
2025-11-22 21:58:57 - GraphTrainer - INFO - precision@20: 0.004070
2025-11-22 21:58:57 - GraphTrainer - INFO - recall@20: 0.077122
2025-11-22 21:58:57 - GraphTrainer - INFO - hit_rate@20: 0.080946
2025-11-22 21:58:57 - GraphTrainer - INFO - ndcg@20: 0.033056
2025-11-22 21:58:57 - GraphTrainer - INFO - map@20: 0.020525
2025-11-22 21:58:57 - GraphTrainer - INFO - mrr@20: 0.021388
2025-11-22 21:58:57 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:58:57 - GraphTrainer - INFO - 检查点已保存: Epoch 120 -> ./checkpoints/checkpoint_epoch_120.pth
2025-11-22 21:58:57 - GraphTrainer - INFO - ============================================================
2025-11-22 21:58:57 - GraphTrainer - INFO - 开始第 121/1000 轮训练
2025-11-22 21:58:57 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3177, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3749, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3466, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3165, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3312, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3187, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3309, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3152, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3484, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3297, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3230, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3204, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3433, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3650, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3221, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3282, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3276, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3573, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3836, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3274, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3148, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3621, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3492, device='cuda:0', grad_fn=<AddBackward0>)
The 120 training average loss: 0.3377134296400794
2025-11-22 21:59:08 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:59:08 - GraphTrainer - INFO -   precision@5: 0.006819
2025-11-22 21:59:08 - GraphTrainer - INFO -   recall@5: 0.032406
2025-11-22 21:59:08 - GraphTrainer - INFO -   hit_rate@5: 0.033993
2025-11-22 21:59:08 - GraphTrainer - INFO -   ndcg@5: 0.020976
2025-11-22 21:59:08 - GraphTrainer - INFO -   map@5: 0.016987
2025-11-22 21:59:08 - GraphTrainer - INFO -   mrr@5: 0.017712
2025-11-22 21:59:08 - GraphTrainer - INFO -   precision@10: 0.005220
2025-11-22 21:59:08 - GraphTrainer - INFO -   recall@10: 0.049835
2025-11-22 21:59:08 - GraphTrainer - INFO -   hit_rate@10: 0.052096
2025-11-22 21:59:08 - GraphTrainer - INFO -   ndcg@10: 0.026585
2025-11-22 21:59:08 - GraphTrainer - INFO -   map@10: 0.019252
2025-11-22 21:59:08 - GraphTrainer - INFO -   mrr@10: 0.020067
2025-11-22 21:59:08 - GraphTrainer - INFO -   precision@20: 0.004119
2025-11-22 21:59:08 - GraphTrainer - INFO -   recall@20: 0.078062
2025-11-22 21:59:08 - GraphTrainer - INFO -   hit_rate@20: 0.081923
2025-11-22 21:59:08 - GraphTrainer - INFO -   ndcg@20: 0.033757
2025-11-22 21:59:08 - GraphTrainer - INFO -   map@20: 0.021164
2025-11-22 21:59:08 - GraphTrainer - INFO -   mrr@20: 0.022087
2025-11-22 21:59:08 - GraphTrainer - INFO - 第 121 轮训练完成
2025-11-22 21:59:08 - GraphTrainer - INFO - train_loss: 0.339018
2025-11-22 21:59:08 - GraphTrainer - INFO - precision@5: 0.006819
2025-11-22 21:59:08 - GraphTrainer - INFO - recall@5: 0.032406
2025-11-22 21:59:08 - GraphTrainer - INFO - hit_rate@5: 0.033993
2025-11-22 21:59:08 - GraphTrainer - INFO - ndcg@5: 0.020976
2025-11-22 21:59:08 - GraphTrainer - INFO - map@5: 0.016987
2025-11-22 21:59:08 - GraphTrainer - INFO - mrr@5: 0.017712
2025-11-22 21:59:08 - GraphTrainer - INFO - precision@10: 0.005220
2025-11-22 21:59:08 - GraphTrainer - INFO - recall@10: 0.049835
2025-11-22 21:59:08 - GraphTrainer - INFO - hit_rate@10: 0.052096
2025-11-22 21:59:08 - GraphTrainer - INFO - ndcg@10: 0.026585
2025-11-22 21:59:08 - GraphTrainer - INFO - map@10: 0.019252
2025-11-22 21:59:08 - GraphTrainer - INFO - mrr@10: 0.020067
2025-11-22 21:59:08 - GraphTrainer - INFO - precision@20: 0.004119
2025-11-22 21:59:08 - GraphTrainer - INFO - recall@20: 0.078062
2025-11-22 21:59:08 - GraphTrainer - INFO - hit_rate@20: 0.081923
2025-11-22 21:59:08 - GraphTrainer - INFO - ndcg@20: 0.033757
2025-11-22 21:59:08 - GraphTrainer - INFO - map@20: 0.021164
2025-11-22 21:59:08 - GraphTrainer - INFO - mrr@20: 0.022087
2025-11-22 21:59:08 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:59:08 - GraphTrainer - INFO - ============================================================
2025-11-22 21:59:08 - GraphTrainer - INFO - 开始第 122/1000 轮训练
2025-11-22 21:59:08 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3484, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3288, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3532, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3202, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3484, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3261, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3671, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3191, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3173, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3190, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3531, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3570, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3568, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3215, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3709, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3237, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3342, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3288, device='cuda:0', grad_fn=<AddBackward0>)
The 121 training average loss: 0.33901794100629873
2025-11-22 21:59:19 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:59:19 - GraphTrainer - INFO -   precision@5: 0.006624
2025-11-22 21:59:19 - GraphTrainer - INFO -   recall@5: 0.031592
2025-11-22 21:59:19 - GraphTrainer - INFO -   hit_rate@5: 0.033068
2025-11-22 21:59:19 - GraphTrainer - INFO -   ndcg@5: 0.020785
2025-11-22 21:59:19 - GraphTrainer - INFO -   map@5: 0.017003
2025-11-22 21:59:19 - GraphTrainer - INFO -   mrr@5: 0.017666
2025-11-22 21:59:19 - GraphTrainer - INFO -   precision@10: 0.005204
2025-11-22 21:59:19 - GraphTrainer - INFO -   recall@10: 0.049446
2025-11-22 21:59:19 - GraphTrainer - INFO -   hit_rate@10: 0.051941
2025-11-22 21:59:19 - GraphTrainer - INFO -   ndcg@10: 0.026581
2025-11-22 21:59:19 - GraphTrainer - INFO -   map@10: 0.019350
2025-11-22 21:59:19 - GraphTrainer - INFO -   mrr@10: 0.020141
2025-11-22 21:59:19 - GraphTrainer - INFO -   precision@20: 0.004050
2025-11-22 21:59:19 - GraphTrainer - INFO -   recall@20: 0.076841
2025-11-22 21:59:19 - GraphTrainer - INFO -   hit_rate@20: 0.080741
2025-11-22 21:59:19 - GraphTrainer - INFO -   ndcg@20: 0.033554
2025-11-22 21:59:19 - GraphTrainer - INFO -   map@20: 0.021227
2025-11-22 21:59:19 - GraphTrainer - INFO -   mrr@20: 0.022109
2025-11-22 21:59:19 - GraphTrainer - INFO - 第 122 轮训练完成
2025-11-22 21:59:19 - GraphTrainer - INFO - train_loss: 0.337047
2025-11-22 21:59:19 - GraphTrainer - INFO - precision@5: 0.006624
2025-11-22 21:59:19 - GraphTrainer - INFO - recall@5: 0.031592
2025-11-22 21:59:19 - GraphTrainer - INFO - hit_rate@5: 0.033068
2025-11-22 21:59:19 - GraphTrainer - INFO - ndcg@5: 0.020785
2025-11-22 21:59:19 - GraphTrainer - INFO - map@5: 0.017003
2025-11-22 21:59:19 - GraphTrainer - INFO - mrr@5: 0.017666
2025-11-22 21:59:19 - GraphTrainer - INFO - precision@10: 0.005204
2025-11-22 21:59:19 - GraphTrainer - INFO - recall@10: 0.049446
2025-11-22 21:59:19 - GraphTrainer - INFO - hit_rate@10: 0.051941
2025-11-22 21:59:19 - GraphTrainer - INFO - ndcg@10: 0.026581
2025-11-22 21:59:19 - GraphTrainer - INFO - map@10: 0.019350
2025-11-22 21:59:19 - GraphTrainer - INFO - mrr@10: 0.020141
2025-11-22 21:59:19 - GraphTrainer - INFO - precision@20: 0.004050
2025-11-22 21:59:19 - GraphTrainer - INFO - recall@20: 0.076841
2025-11-22 21:59:19 - GraphTrainer - INFO - hit_rate@20: 0.080741
2025-11-22 21:59:19 - GraphTrainer - INFO - ndcg@20: 0.033554
2025-11-22 21:59:19 - GraphTrainer - INFO - map@20: 0.021227
2025-11-22 21:59:19 - GraphTrainer - INFO - mrr@20: 0.022109
2025-11-22 21:59:19 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:59:19 - GraphTrainer - INFO - ============================================================
2025-11-22 21:59:19 - GraphTrainer - INFO - 开始第 123/1000 轮训练
2025-11-22 21:59:19 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3204, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3167, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3499, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3302, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3543, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3506, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3156, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3239, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3434, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3666, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3435, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3551, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3290, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3228, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3213, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3218, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3196, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3433, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3285, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3539, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3203, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3327, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3272, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3612, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3256, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3260, device='cuda:0', grad_fn=<AddBackward0>)
The 122 training average loss: 0.33704724496808547
2025-11-22 21:59:30 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:59:30 - GraphTrainer - INFO -   precision@5: 0.006675
2025-11-22 21:59:30 - GraphTrainer - INFO -   recall@5: 0.031829
2025-11-22 21:59:30 - GraphTrainer - INFO -   hit_rate@5: 0.033325
2025-11-22 21:59:30 - GraphTrainer - INFO -   ndcg@5: 0.020849
2025-11-22 21:59:30 - GraphTrainer - INFO -   map@5: 0.017002
2025-11-22 21:59:30 - GraphTrainer - INFO -   mrr@5: 0.017675
2025-11-22 21:59:30 - GraphTrainer - INFO -   precision@10: 0.005225
2025-11-22 21:59:30 - GraphTrainer - INFO -   recall@10: 0.049615
2025-11-22 21:59:30 - GraphTrainer - INFO -   hit_rate@10: 0.052096
2025-11-22 21:59:30 - GraphTrainer - INFO -   ndcg@10: 0.026616
2025-11-22 21:59:30 - GraphTrainer - INFO -   map@10: 0.019330
2025-11-22 21:59:30 - GraphTrainer - INFO -   mrr@10: 0.020127
2025-11-22 21:59:30 - GraphTrainer - INFO -   precision@20: 0.004142
2025-11-22 21:59:30 - GraphTrainer - INFO -   recall@20: 0.078649
2025-11-22 21:59:30 - GraphTrainer - INFO -   hit_rate@20: 0.082489
2025-11-22 21:59:30 - GraphTrainer - INFO -   ndcg@20: 0.033956
2025-11-22 21:59:30 - GraphTrainer - INFO -   map@20: 0.021283
2025-11-22 21:59:30 - GraphTrainer - INFO -   mrr@20: 0.022172
2025-11-22 21:59:30 - GraphTrainer - INFO - 第 123 轮训练完成
2025-11-22 21:59:30 - GraphTrainer - INFO - train_loss: 0.338374
2025-11-22 21:59:30 - GraphTrainer - INFO - precision@5: 0.006675
2025-11-22 21:59:30 - GraphTrainer - INFO - recall@5: 0.031829
2025-11-22 21:59:30 - GraphTrainer - INFO - hit_rate@5: 0.033325
2025-11-22 21:59:30 - GraphTrainer - INFO - ndcg@5: 0.020849
2025-11-22 21:59:30 - GraphTrainer - INFO - map@5: 0.017002
2025-11-22 21:59:30 - GraphTrainer - INFO - mrr@5: 0.017675
2025-11-22 21:59:30 - GraphTrainer - INFO - precision@10: 0.005225
2025-11-22 21:59:30 - GraphTrainer - INFO - recall@10: 0.049615
2025-11-22 21:59:30 - GraphTrainer - INFO - hit_rate@10: 0.052096
2025-11-22 21:59:30 - GraphTrainer - INFO - ndcg@10: 0.026616
2025-11-22 21:59:30 - GraphTrainer - INFO - map@10: 0.019330
2025-11-22 21:59:30 - GraphTrainer - INFO - mrr@10: 0.020127
2025-11-22 21:59:30 - GraphTrainer - INFO - precision@20: 0.004142
2025-11-22 21:59:30 - GraphTrainer - INFO - recall@20: 0.078649
2025-11-22 21:59:30 - GraphTrainer - INFO - hit_rate@20: 0.082489
2025-11-22 21:59:30 - GraphTrainer - INFO - ndcg@20: 0.033956
2025-11-22 21:59:30 - GraphTrainer - INFO - map@20: 0.021283
2025-11-22 21:59:30 - GraphTrainer - INFO - mrr@20: 0.022172
2025-11-22 21:59:30 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:59:30 - GraphTrainer - INFO - ============================================================
2025-11-22 21:59:30 - GraphTrainer - INFO - 开始第 124/1000 轮训练
2025-11-22 21:59:30 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3109, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3373, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3342, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3539, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3644, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3214, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3468, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3543, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3235, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3261, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3175, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3551, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3262, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3313, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3227, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3558, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3563, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3304, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3176, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3257, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3172, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
The 123 training average loss: 0.33837353515213936
2025-11-22 21:59:41 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:59:41 - GraphTrainer - INFO -   precision@5: 0.006871
2025-11-22 21:59:41 - GraphTrainer - INFO -   recall@5: 0.032696
2025-11-22 21:59:41 - GraphTrainer - INFO -   hit_rate@5: 0.034302
2025-11-22 21:59:41 - GraphTrainer - INFO -   ndcg@5: 0.021133
2025-11-22 21:59:41 - GraphTrainer - INFO -   map@5: 0.017087
2025-11-22 21:59:41 - GraphTrainer - INFO -   mrr@5: 0.017807
2025-11-22 21:59:41 - GraphTrainer - INFO -   precision@10: 0.005225
2025-11-22 21:59:41 - GraphTrainer - INFO -   recall@10: 0.049416
2025-11-22 21:59:41 - GraphTrainer - INFO -   hit_rate@10: 0.052044
2025-11-22 21:59:41 - GraphTrainer - INFO -   ndcg@10: 0.026539
2025-11-22 21:59:41 - GraphTrainer - INFO -   map@10: 0.019259
2025-11-22 21:59:41 - GraphTrainer - INFO -   mrr@10: 0.020101
2025-11-22 21:59:41 - GraphTrainer - INFO -   precision@20: 0.004086
2025-11-22 21:59:41 - GraphTrainer - INFO -   recall@20: 0.077251
2025-11-22 21:59:41 - GraphTrainer - INFO -   hit_rate@20: 0.081255
2025-11-22 21:59:41 - GraphTrainer - INFO -   ndcg@20: 0.033575
2025-11-22 21:59:41 - GraphTrainer - INFO -   map@20: 0.021126
2025-11-22 21:59:41 - GraphTrainer - INFO -   mrr@20: 0.022055
2025-11-22 21:59:41 - GraphTrainer - INFO - 第 124 轮训练完成
2025-11-22 21:59:41 - GraphTrainer - INFO - train_loss: 0.338289
2025-11-22 21:59:41 - GraphTrainer - INFO - precision@5: 0.006871
2025-11-22 21:59:41 - GraphTrainer - INFO - recall@5: 0.032696
2025-11-22 21:59:41 - GraphTrainer - INFO - hit_rate@5: 0.034302
2025-11-22 21:59:41 - GraphTrainer - INFO - ndcg@5: 0.021133
2025-11-22 21:59:41 - GraphTrainer - INFO - map@5: 0.017087
2025-11-22 21:59:41 - GraphTrainer - INFO - mrr@5: 0.017807
2025-11-22 21:59:41 - GraphTrainer - INFO - precision@10: 0.005225
2025-11-22 21:59:41 - GraphTrainer - INFO - recall@10: 0.049416
2025-11-22 21:59:41 - GraphTrainer - INFO - hit_rate@10: 0.052044
2025-11-22 21:59:41 - GraphTrainer - INFO - ndcg@10: 0.026539
2025-11-22 21:59:41 - GraphTrainer - INFO - map@10: 0.019259
2025-11-22 21:59:41 - GraphTrainer - INFO - mrr@10: 0.020101
2025-11-22 21:59:41 - GraphTrainer - INFO - precision@20: 0.004086
2025-11-22 21:59:41 - GraphTrainer - INFO - recall@20: 0.077251
2025-11-22 21:59:41 - GraphTrainer - INFO - hit_rate@20: 0.081255
2025-11-22 21:59:41 - GraphTrainer - INFO - ndcg@20: 0.033575
2025-11-22 21:59:41 - GraphTrainer - INFO - map@20: 0.021126
2025-11-22 21:59:41 - GraphTrainer - INFO - mrr@20: 0.022055
2025-11-22 21:59:41 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:59:41 - GraphTrainer - INFO - ============================================================
2025-11-22 21:59:41 - GraphTrainer - INFO - 开始第 125/1000 轮训练
2025-11-22 21:59:41 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3507, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3624, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3304, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3304, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3245, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3230, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3262, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3313, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3548, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3626, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3611, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3342, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3241, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3204, device='cuda:0', grad_fn=<AddBackward0>)
The 124 training average loss: 0.33828862473882476
2025-11-22 21:59:52 - GraphTrainer - INFO - 验证结果:
2025-11-22 21:59:52 - GraphTrainer - INFO -   precision@5: 0.006686
2025-11-22 21:59:52 - GraphTrainer - INFO -   recall@5: 0.031930
2025-11-22 21:59:52 - GraphTrainer - INFO -   hit_rate@5: 0.033376
2025-11-22 21:59:52 - GraphTrainer - INFO -   ndcg@5: 0.020713
2025-11-22 21:59:52 - GraphTrainer - INFO -   map@5: 0.016790
2025-11-22 21:59:52 - GraphTrainer - INFO -   mrr@5: 0.017485
2025-11-22 21:59:52 - GraphTrainer - INFO -   precision@10: 0.005127
2025-11-22 21:59:52 - GraphTrainer - INFO -   recall@10: 0.048646
2025-11-22 21:59:52 - GraphTrainer - INFO -   hit_rate@10: 0.051170
2025-11-22 21:59:52 - GraphTrainer - INFO -   ndcg@10: 0.026152
2025-11-22 21:59:52 - GraphTrainer - INFO -   map@10: 0.018991
2025-11-22 21:59:52 - GraphTrainer - INFO -   mrr@10: 0.019825
2025-11-22 21:59:52 - GraphTrainer - INFO -   precision@20: 0.004119
2025-11-22 21:59:52 - GraphTrainer - INFO -   recall@20: 0.077780
2025-11-22 21:59:52 - GraphTrainer - INFO -   hit_rate@20: 0.081821
2025-11-22 21:59:52 - GraphTrainer - INFO -   ndcg@20: 0.033568
2025-11-22 21:59:52 - GraphTrainer - INFO -   map@20: 0.020981
2025-11-22 21:59:52 - GraphTrainer - INFO -   mrr@20: 0.021912
2025-11-22 21:59:52 - GraphTrainer - INFO - 第 125 轮训练完成
2025-11-22 21:59:52 - GraphTrainer - INFO - train_loss: 0.337741
2025-11-22 21:59:52 - GraphTrainer - INFO - precision@5: 0.006686
2025-11-22 21:59:52 - GraphTrainer - INFO - recall@5: 0.031930
2025-11-22 21:59:52 - GraphTrainer - INFO - hit_rate@5: 0.033376
2025-11-22 21:59:52 - GraphTrainer - INFO - ndcg@5: 0.020713
2025-11-22 21:59:52 - GraphTrainer - INFO - map@5: 0.016790
2025-11-22 21:59:52 - GraphTrainer - INFO - mrr@5: 0.017485
2025-11-22 21:59:52 - GraphTrainer - INFO - precision@10: 0.005127
2025-11-22 21:59:52 - GraphTrainer - INFO - recall@10: 0.048646
2025-11-22 21:59:52 - GraphTrainer - INFO - hit_rate@10: 0.051170
2025-11-22 21:59:52 - GraphTrainer - INFO - ndcg@10: 0.026152
2025-11-22 21:59:52 - GraphTrainer - INFO - map@10: 0.018991
2025-11-22 21:59:52 - GraphTrainer - INFO - mrr@10: 0.019825
2025-11-22 21:59:52 - GraphTrainer - INFO - precision@20: 0.004119
2025-11-22 21:59:52 - GraphTrainer - INFO - recall@20: 0.077780
2025-11-22 21:59:52 - GraphTrainer - INFO - hit_rate@20: 0.081821
2025-11-22 21:59:52 - GraphTrainer - INFO - ndcg@20: 0.033568
2025-11-22 21:59:52 - GraphTrainer - INFO - map@20: 0.020981
2025-11-22 21:59:52 - GraphTrainer - INFO - mrr@20: 0.021912
2025-11-22 21:59:52 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 21:59:52 - GraphTrainer - INFO - ============================================================
2025-11-22 21:59:52 - GraphTrainer - INFO - 开始第 126/1000 轮训练
2025-11-22 21:59:52 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3260, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3177, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3219, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3151, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3623, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3601, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3547, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3257, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3167, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3512, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3434, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3626, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3379, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3145, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3245, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3568, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3468, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3580, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3655, device='cuda:0', grad_fn=<AddBackward0>)
The 125 training average loss: 0.3377414854436085
2025-11-22 22:00:02 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:00:02 - GraphTrainer - INFO -   precision@5: 0.006768
2025-11-22 22:00:02 - GraphTrainer - INFO -   recall@5: 0.032569
2025-11-22 22:00:02 - GraphTrainer - INFO -   hit_rate@5: 0.033788
2025-11-22 22:00:02 - GraphTrainer - INFO -   ndcg@5: 0.021052
2025-11-22 22:00:02 - GraphTrainer - INFO -   map@5: 0.017069
2025-11-22 22:00:02 - GraphTrainer - INFO -   mrr@5: 0.017639
2025-11-22 22:00:02 - GraphTrainer - INFO -   precision@10: 0.005179
2025-11-22 22:00:02 - GraphTrainer - INFO -   recall@10: 0.049250
2025-11-22 22:00:02 - GraphTrainer - INFO -   hit_rate@10: 0.051684
2025-11-22 22:00:02 - GraphTrainer - INFO -   ndcg@10: 0.026435
2025-11-22 22:00:02 - GraphTrainer - INFO -   map@10: 0.019211
2025-11-22 22:00:02 - GraphTrainer - INFO -   mrr@10: 0.019935
2025-11-22 22:00:02 - GraphTrainer - INFO -   precision@20: 0.004140
2025-11-22 22:00:02 - GraphTrainer - INFO -   recall@20: 0.078507
2025-11-22 22:00:02 - GraphTrainer - INFO -   hit_rate@20: 0.082335
2025-11-22 22:00:02 - GraphTrainer - INFO -   ndcg@20: 0.033871
2025-11-22 22:00:02 - GraphTrainer - INFO -   map@20: 0.021207
2025-11-22 22:00:02 - GraphTrainer - INFO -   mrr@20: 0.022022
2025-11-22 22:00:03 - GraphTrainer - INFO - 第 126 轮训练完成
2025-11-22 22:00:03 - GraphTrainer - INFO - train_loss: 0.340735
2025-11-22 22:00:03 - GraphTrainer - INFO - precision@5: 0.006768
2025-11-22 22:00:03 - GraphTrainer - INFO - recall@5: 0.032569
2025-11-22 22:00:03 - GraphTrainer - INFO - hit_rate@5: 0.033788
2025-11-22 22:00:03 - GraphTrainer - INFO - ndcg@5: 0.021052
2025-11-22 22:00:03 - GraphTrainer - INFO - map@5: 0.017069
2025-11-22 22:00:03 - GraphTrainer - INFO - mrr@5: 0.017639
2025-11-22 22:00:03 - GraphTrainer - INFO - precision@10: 0.005179
2025-11-22 22:00:03 - GraphTrainer - INFO - recall@10: 0.049250
2025-11-22 22:00:03 - GraphTrainer - INFO - hit_rate@10: 0.051684
2025-11-22 22:00:03 - GraphTrainer - INFO - ndcg@10: 0.026435
2025-11-22 22:00:03 - GraphTrainer - INFO - map@10: 0.019211
2025-11-22 22:00:03 - GraphTrainer - INFO - mrr@10: 0.019935
2025-11-22 22:00:03 - GraphTrainer - INFO - precision@20: 0.004140
2025-11-22 22:00:03 - GraphTrainer - INFO - recall@20: 0.078507
2025-11-22 22:00:03 - GraphTrainer - INFO - hit_rate@20: 0.082335
2025-11-22 22:00:03 - GraphTrainer - INFO - ndcg@20: 0.033871
2025-11-22 22:00:03 - GraphTrainer - INFO - map@20: 0.021207
2025-11-22 22:00:03 - GraphTrainer - INFO - mrr@20: 0.022022
2025-11-22 22:00:03 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:00:03 - GraphTrainer - INFO - ============================================================
2025-11-22 22:00:03 - GraphTrainer - INFO - 开始第 127/1000 轮训练
2025-11-22 22:00:03 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3192, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3226, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3181, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3167, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3421, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3433, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3479, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3548, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3479, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3316, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3435, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3376, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3634, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3499, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3506, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3630, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
The 126 training average loss: 0.3407346909416133
2025-11-22 22:00:14 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:00:14 - GraphTrainer - INFO -   precision@5: 0.006603
2025-11-22 22:00:14 - GraphTrainer - INFO -   recall@5: 0.031531
2025-11-22 22:00:14 - GraphTrainer - INFO -   hit_rate@5: 0.032965
2025-11-22 22:00:14 - GraphTrainer - INFO -   ndcg@5: 0.020791
2025-11-22 22:00:14 - GraphTrainer - INFO -   map@5: 0.017030
2025-11-22 22:00:14 - GraphTrainer - INFO -   mrr@5: 0.017712
2025-11-22 22:00:14 - GraphTrainer - INFO -   precision@10: 0.005235
2025-11-22 22:00:14 - GraphTrainer - INFO -   recall@10: 0.049762
2025-11-22 22:00:14 - GraphTrainer - INFO -   hit_rate@10: 0.052250
2025-11-22 22:00:14 - GraphTrainer - INFO -   ndcg@10: 0.026704
2025-11-22 22:00:14 - GraphTrainer - INFO -   map@10: 0.019418
2025-11-22 22:00:14 - GraphTrainer - INFO -   mrr@10: 0.020235
2025-11-22 22:00:14 - GraphTrainer - INFO -   precision@20: 0.004094
2025-11-22 22:00:14 - GraphTrainer - INFO -   recall@20: 0.077555
2025-11-22 22:00:14 - GraphTrainer - INFO -   hit_rate@20: 0.081512
2025-11-22 22:00:14 - GraphTrainer - INFO -   ndcg@20: 0.033768
2025-11-22 22:00:14 - GraphTrainer - INFO -   map@20: 0.021310
2025-11-22 22:00:14 - GraphTrainer - INFO -   mrr@20: 0.022222
2025-11-22 22:00:14 - GraphTrainer - INFO - 第 127 轮训练完成
2025-11-22 22:00:14 - GraphTrainer - INFO - train_loss: 0.336984
2025-11-22 22:00:14 - GraphTrainer - INFO - precision@5: 0.006603
2025-11-22 22:00:14 - GraphTrainer - INFO - recall@5: 0.031531
2025-11-22 22:00:14 - GraphTrainer - INFO - hit_rate@5: 0.032965
2025-11-22 22:00:14 - GraphTrainer - INFO - ndcg@5: 0.020791
2025-11-22 22:00:14 - GraphTrainer - INFO - map@5: 0.017030
2025-11-22 22:00:14 - GraphTrainer - INFO - mrr@5: 0.017712
2025-11-22 22:00:14 - GraphTrainer - INFO - precision@10: 0.005235
2025-11-22 22:00:14 - GraphTrainer - INFO - recall@10: 0.049762
2025-11-22 22:00:14 - GraphTrainer - INFO - hit_rate@10: 0.052250
2025-11-22 22:00:14 - GraphTrainer - INFO - ndcg@10: 0.026704
2025-11-22 22:00:14 - GraphTrainer - INFO - map@10: 0.019418
2025-11-22 22:00:14 - GraphTrainer - INFO - mrr@10: 0.020235
2025-11-22 22:00:14 - GraphTrainer - INFO - precision@20: 0.004094
2025-11-22 22:00:14 - GraphTrainer - INFO - recall@20: 0.077555
2025-11-22 22:00:14 - GraphTrainer - INFO - hit_rate@20: 0.081512
2025-11-22 22:00:14 - GraphTrainer - INFO - ndcg@20: 0.033768
2025-11-22 22:00:14 - GraphTrainer - INFO - map@20: 0.021310
2025-11-22 22:00:14 - GraphTrainer - INFO - mrr@20: 0.022222
2025-11-22 22:00:14 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:00:14 - GraphTrainer - INFO - ============================================================
2025-11-22 22:00:14 - GraphTrainer - INFO - 开始第 128/1000 轮训练
2025-11-22 22:00:14 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3210, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3316, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3043, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3215, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3729, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3060, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3573, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3261, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3189, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3703, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3462, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3204, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3228, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3507, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3212, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3635, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3063, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3183, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3284, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3272, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3288, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3574, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3124, device='cuda:0', grad_fn=<AddBackward0>)
The 127 training average loss: 0.3369839083531807
2025-11-22 22:00:25 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:00:25 - GraphTrainer - INFO -   precision@5: 0.006593
2025-11-22 22:00:25 - GraphTrainer - INFO -   recall@5: 0.031437
2025-11-22 22:00:25 - GraphTrainer - INFO -   hit_rate@5: 0.032913
2025-11-22 22:00:25 - GraphTrainer - INFO -   ndcg@5: 0.020393
2025-11-22 22:00:25 - GraphTrainer - INFO -   map@5: 0.016525
2025-11-22 22:00:25 - GraphTrainer - INFO -   mrr@5: 0.017223
2025-11-22 22:00:25 - GraphTrainer - INFO -   precision@10: 0.005225
2025-11-22 22:00:25 - GraphTrainer - INFO -   recall@10: 0.049698
2025-11-22 22:00:25 - GraphTrainer - INFO -   hit_rate@10: 0.052147
2025-11-22 22:00:25 - GraphTrainer - INFO -   ndcg@10: 0.026304
2025-11-22 22:00:25 - GraphTrainer - INFO -   map@10: 0.018911
2025-11-22 22:00:25 - GraphTrainer - INFO -   mrr@10: 0.019731
2025-11-22 22:00:25 - GraphTrainer - INFO -   precision@20: 0.004114
2025-11-22 22:00:25 - GraphTrainer - INFO -   recall@20: 0.077918
2025-11-22 22:00:25 - GraphTrainer - INFO -   hit_rate@20: 0.081769
2025-11-22 22:00:25 - GraphTrainer - INFO -   ndcg@20: 0.033487
2025-11-22 22:00:25 - GraphTrainer - INFO -   map@20: 0.020841
2025-11-22 22:00:25 - GraphTrainer - INFO -   mrr@20: 0.021752
2025-11-22 22:00:25 - GraphTrainer - INFO - 第 128 轮训练完成
2025-11-22 22:00:25 - GraphTrainer - INFO - train_loss: 0.336149
2025-11-22 22:00:25 - GraphTrainer - INFO - precision@5: 0.006593
2025-11-22 22:00:25 - GraphTrainer - INFO - recall@5: 0.031437
2025-11-22 22:00:25 - GraphTrainer - INFO - hit_rate@5: 0.032913
2025-11-22 22:00:25 - GraphTrainer - INFO - ndcg@5: 0.020393
2025-11-22 22:00:25 - GraphTrainer - INFO - map@5: 0.016525
2025-11-22 22:00:25 - GraphTrainer - INFO - mrr@5: 0.017223
2025-11-22 22:00:25 - GraphTrainer - INFO - precision@10: 0.005225
2025-11-22 22:00:25 - GraphTrainer - INFO - recall@10: 0.049698
2025-11-22 22:00:25 - GraphTrainer - INFO - hit_rate@10: 0.052147
2025-11-22 22:00:25 - GraphTrainer - INFO - ndcg@10: 0.026304
2025-11-22 22:00:25 - GraphTrainer - INFO - map@10: 0.018911
2025-11-22 22:00:25 - GraphTrainer - INFO - mrr@10: 0.019731
2025-11-22 22:00:25 - GraphTrainer - INFO - precision@20: 0.004114
2025-11-22 22:00:25 - GraphTrainer - INFO - recall@20: 0.077918
2025-11-22 22:00:25 - GraphTrainer - INFO - hit_rate@20: 0.081769
2025-11-22 22:00:25 - GraphTrainer - INFO - ndcg@20: 0.033487
2025-11-22 22:00:25 - GraphTrainer - INFO - map@20: 0.020841
2025-11-22 22:00:25 - GraphTrainer - INFO - mrr@20: 0.021752
2025-11-22 22:00:25 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:00:25 - GraphTrainer - INFO - ============================================================
2025-11-22 22:00:25 - GraphTrainer - INFO - 开始第 129/1000 轮训练
2025-11-22 22:00:25 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3525, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3736, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3284, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3262, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3281, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3158, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3195, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3288, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3184, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3223, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3087, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3233, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3595, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3545, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3195, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3119, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3109, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3582, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3205, device='cuda:0', grad_fn=<AddBackward0>)
The 128 training average loss: 0.33614890071852455
2025-11-22 22:00:35 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:00:35 - GraphTrainer - INFO -   precision@5: 0.006480
2025-11-22 22:00:35 - GraphTrainer - INFO -   recall@5: 0.030810
2025-11-22 22:00:35 - GraphTrainer - INFO -   hit_rate@5: 0.032296
2025-11-22 22:00:35 - GraphTrainer - INFO -   ndcg@5: 0.020242
2025-11-22 22:00:35 - GraphTrainer - INFO -   map@5: 0.016521
2025-11-22 22:00:35 - GraphTrainer - INFO -   mrr@5: 0.017209
2025-11-22 22:00:35 - GraphTrainer - INFO -   precision@10: 0.005117
2025-11-22 22:00:35 - GraphTrainer - INFO -   recall@10: 0.048802
2025-11-22 22:00:35 - GraphTrainer - INFO -   hit_rate@10: 0.051067
2025-11-22 22:00:35 - GraphTrainer - INFO -   ndcg@10: 0.026093
2025-11-22 22:00:35 - GraphTrainer - INFO -   map@10: 0.018911
2025-11-22 22:00:35 - GraphTrainer - INFO -   mrr@10: 0.019697
2025-11-22 22:00:35 - GraphTrainer - INFO -   precision@20: 0.004076
2025-11-22 22:00:35 - GraphTrainer - INFO -   recall@20: 0.077069
2025-11-22 22:00:35 - GraphTrainer - INFO -   hit_rate@20: 0.081049
2025-11-22 22:00:35 - GraphTrainer - INFO -   ndcg@20: 0.033316
2025-11-22 22:00:35 - GraphTrainer - INFO -   map@20: 0.020854
2025-11-22 22:00:35 - GraphTrainer - INFO -   mrr@20: 0.021756
2025-11-22 22:00:35 - GraphTrainer - INFO - 第 129 轮训练完成
2025-11-22 22:00:35 - GraphTrainer - INFO - train_loss: 0.340961
2025-11-22 22:00:35 - GraphTrainer - INFO - precision@5: 0.006480
2025-11-22 22:00:35 - GraphTrainer - INFO - recall@5: 0.030810
2025-11-22 22:00:35 - GraphTrainer - INFO - hit_rate@5: 0.032296
2025-11-22 22:00:35 - GraphTrainer - INFO - ndcg@5: 0.020242
2025-11-22 22:00:35 - GraphTrainer - INFO - map@5: 0.016521
2025-11-22 22:00:35 - GraphTrainer - INFO - mrr@5: 0.017209
2025-11-22 22:00:35 - GraphTrainer - INFO - precision@10: 0.005117
2025-11-22 22:00:35 - GraphTrainer - INFO - recall@10: 0.048802
2025-11-22 22:00:35 - GraphTrainer - INFO - hit_rate@10: 0.051067
2025-11-22 22:00:35 - GraphTrainer - INFO - ndcg@10: 0.026093
2025-11-22 22:00:35 - GraphTrainer - INFO - map@10: 0.018911
2025-11-22 22:00:35 - GraphTrainer - INFO - mrr@10: 0.019697
2025-11-22 22:00:35 - GraphTrainer - INFO - precision@20: 0.004076
2025-11-22 22:00:35 - GraphTrainer - INFO - recall@20: 0.077069
2025-11-22 22:00:35 - GraphTrainer - INFO - hit_rate@20: 0.081049
2025-11-22 22:00:35 - GraphTrainer - INFO - ndcg@20: 0.033316
2025-11-22 22:00:35 - GraphTrainer - INFO - map@20: 0.020854
2025-11-22 22:00:35 - GraphTrainer - INFO - mrr@20: 0.021756
2025-11-22 22:00:35 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:00:35 - GraphTrainer - INFO - ============================================================
2025-11-22 22:00:35 - GraphTrainer - INFO - 开始第 130/1000 轮训练
2025-11-22 22:00:35 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3584, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3290, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3659, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3672, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3281, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3466, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3480, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3548, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3190, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3537, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3293, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3088, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3616, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3626, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3571, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3120, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3162, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3688, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3170, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3592, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3272, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3306, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
The 129 training average loss: 0.34096135301836605
2025-11-22 22:00:46 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:00:46 - GraphTrainer - INFO -   precision@5: 0.006531
2025-11-22 22:00:46 - GraphTrainer - INFO -   recall@5: 0.030992
2025-11-22 22:00:46 - GraphTrainer - INFO -   hit_rate@5: 0.032605
2025-11-22 22:00:46 - GraphTrainer - INFO -   ndcg@5: 0.019984
2025-11-22 22:00:46 - GraphTrainer - INFO -   map@5: 0.016137
2025-11-22 22:00:46 - GraphTrainer - INFO -   mrr@5: 0.016823
2025-11-22 22:00:46 - GraphTrainer - INFO -   precision@10: 0.005199
2025-11-22 22:00:46 - GraphTrainer - INFO -   recall@10: 0.049412
2025-11-22 22:00:46 - GraphTrainer - INFO -   hit_rate@10: 0.051839
2025-11-22 22:00:46 - GraphTrainer - INFO -   ndcg@10: 0.025991
2025-11-22 22:00:46 - GraphTrainer - INFO -   map@10: 0.018595
2025-11-22 22:00:46 - GraphTrainer - INFO -   mrr@10: 0.019384
2025-11-22 22:00:46 - GraphTrainer - INFO -   precision@20: 0.004117
2025-11-22 22:00:46 - GraphTrainer - INFO -   recall@20: 0.077830
2025-11-22 22:00:46 - GraphTrainer - INFO -   hit_rate@20: 0.081872
2025-11-22 22:00:46 - GraphTrainer - INFO -   ndcg@20: 0.033218
2025-11-22 22:00:46 - GraphTrainer - INFO -   map@20: 0.020528
2025-11-22 22:00:46 - GraphTrainer - INFO -   mrr@20: 0.021426
2025-11-22 22:00:46 - GraphTrainer - INFO - 第 130 轮训练完成
2025-11-22 22:00:46 - GraphTrainer - INFO - train_loss: 0.342741
2025-11-22 22:00:46 - GraphTrainer - INFO - precision@5: 0.006531
2025-11-22 22:00:46 - GraphTrainer - INFO - recall@5: 0.030992
2025-11-22 22:00:46 - GraphTrainer - INFO - hit_rate@5: 0.032605
2025-11-22 22:00:46 - GraphTrainer - INFO - ndcg@5: 0.019984
2025-11-22 22:00:46 - GraphTrainer - INFO - map@5: 0.016137
2025-11-22 22:00:46 - GraphTrainer - INFO - mrr@5: 0.016823
2025-11-22 22:00:46 - GraphTrainer - INFO - precision@10: 0.005199
2025-11-22 22:00:46 - GraphTrainer - INFO - recall@10: 0.049412
2025-11-22 22:00:46 - GraphTrainer - INFO - hit_rate@10: 0.051839
2025-11-22 22:00:46 - GraphTrainer - INFO - ndcg@10: 0.025991
2025-11-22 22:00:46 - GraphTrainer - INFO - map@10: 0.018595
2025-11-22 22:00:46 - GraphTrainer - INFO - mrr@10: 0.019384
2025-11-22 22:00:46 - GraphTrainer - INFO - precision@20: 0.004117
2025-11-22 22:00:46 - GraphTrainer - INFO - recall@20: 0.077830
2025-11-22 22:00:46 - GraphTrainer - INFO - hit_rate@20: 0.081872
2025-11-22 22:00:46 - GraphTrainer - INFO - ndcg@20: 0.033218
2025-11-22 22:00:46 - GraphTrainer - INFO - map@20: 0.020528
2025-11-22 22:00:46 - GraphTrainer - INFO - mrr@20: 0.021426
2025-11-22 22:00:46 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:00:46 - GraphTrainer - INFO - 检查点已保存: Epoch 130 -> ./checkpoints/checkpoint_epoch_130.pth
2025-11-22 22:00:46 - GraphTrainer - INFO - ============================================================
2025-11-22 22:00:46 - GraphTrainer - INFO - 开始第 131/1000 轮训练
2025-11-22 22:00:46 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3700, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3155, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3214, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3636, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3688, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3284, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3548, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3622, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3342, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3605, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3656, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3209, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3274, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3200, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3629, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3186, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3331, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3466, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3736, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3506, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3331, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3685, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3632, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
The 130 training average loss: 0.3427407232851818
2025-11-22 22:00:57 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:00:57 - GraphTrainer - INFO -   precision@5: 0.006655
2025-11-22 22:00:57 - GraphTrainer - INFO -   recall@5: 0.031677
2025-11-22 22:00:57 - GraphTrainer - INFO -   hit_rate@5: 0.033222
2025-11-22 22:00:57 - GraphTrainer - INFO -   ndcg@5: 0.020324
2025-11-22 22:00:57 - GraphTrainer - INFO -   map@5: 0.016357
2025-11-22 22:00:57 - GraphTrainer - INFO -   mrr@5: 0.017005
2025-11-22 22:00:57 - GraphTrainer - INFO -   precision@10: 0.005230
2025-11-22 22:00:57 - GraphTrainer - INFO -   recall@10: 0.049735
2025-11-22 22:00:57 - GraphTrainer - INFO -   hit_rate@10: 0.052147
2025-11-22 22:00:57 - GraphTrainer - INFO -   ndcg@10: 0.026192
2025-11-22 22:00:57 - GraphTrainer - INFO -   map@10: 0.018744
2025-11-22 22:00:57 - GraphTrainer - INFO -   mrr@10: 0.019500
2025-11-22 22:00:57 - GraphTrainer - INFO -   precision@20: 0.004155
2025-11-22 22:00:57 - GraphTrainer - INFO -   recall@20: 0.078434
2025-11-22 22:00:57 - GraphTrainer - INFO -   hit_rate@20: 0.082592
2025-11-22 22:00:57 - GraphTrainer - INFO -   ndcg@20: 0.033504
2025-11-22 22:00:57 - GraphTrainer - INFO -   map@20: 0.020700
2025-11-22 22:00:57 - GraphTrainer - INFO -   mrr@20: 0.021572
2025-11-22 22:00:57 - GraphTrainer - INFO - 第 131 轮训练完成
2025-11-22 22:00:57 - GraphTrainer - INFO - train_loss: 0.340135
2025-11-22 22:00:57 - GraphTrainer - INFO - precision@5: 0.006655
2025-11-22 22:00:57 - GraphTrainer - INFO - recall@5: 0.031677
2025-11-22 22:00:57 - GraphTrainer - INFO - hit_rate@5: 0.033222
2025-11-22 22:00:57 - GraphTrainer - INFO - ndcg@5: 0.020324
2025-11-22 22:00:57 - GraphTrainer - INFO - map@5: 0.016357
2025-11-22 22:00:57 - GraphTrainer - INFO - mrr@5: 0.017005
2025-11-22 22:00:57 - GraphTrainer - INFO - precision@10: 0.005230
2025-11-22 22:00:57 - GraphTrainer - INFO - recall@10: 0.049735
2025-11-22 22:00:57 - GraphTrainer - INFO - hit_rate@10: 0.052147
2025-11-22 22:00:57 - GraphTrainer - INFO - ndcg@10: 0.026192
2025-11-22 22:00:57 - GraphTrainer - INFO - map@10: 0.018744
2025-11-22 22:00:57 - GraphTrainer - INFO - mrr@10: 0.019500
2025-11-22 22:00:57 - GraphTrainer - INFO - precision@20: 0.004155
2025-11-22 22:00:57 - GraphTrainer - INFO - recall@20: 0.078434
2025-11-22 22:00:57 - GraphTrainer - INFO - hit_rate@20: 0.082592
2025-11-22 22:00:57 - GraphTrainer - INFO - ndcg@20: 0.033504
2025-11-22 22:00:57 - GraphTrainer - INFO - map@20: 0.020700
2025-11-22 22:00:57 - GraphTrainer - INFO - mrr@20: 0.021572
2025-11-22 22:00:57 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:00:57 - GraphTrainer - INFO - ============================================================
2025-11-22 22:00:57 - GraphTrainer - INFO - 开始第 132/1000 轮训练
2025-11-22 22:00:57 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3607, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3141, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3333, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3457, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3468, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3499, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3180, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3160, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3679, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3492, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3137, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3473, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3525, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3169, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3839, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3409, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3141, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3588, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3299, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3176, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3510, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3228, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>)
The 131 training average loss: 0.3401348667925802
2025-11-22 22:01:08 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:01:08 - GraphTrainer - INFO -   precision@5: 0.006819
2025-11-22 22:01:08 - GraphTrainer - INFO -   recall@5: 0.032452
2025-11-22 22:01:08 - GraphTrainer - INFO -   hit_rate@5: 0.033993
2025-11-22 22:01:08 - GraphTrainer - INFO -   ndcg@5: 0.021234
2025-11-22 22:01:08 - GraphTrainer - INFO -   map@5: 0.017302
2025-11-22 22:01:08 - GraphTrainer - INFO -   mrr@5: 0.017991
2025-11-22 22:01:08 - GraphTrainer - INFO -   precision@10: 0.005282
2025-11-22 22:01:08 - GraphTrainer - INFO -   recall@10: 0.050208
2025-11-22 22:01:08 - GraphTrainer - INFO -   hit_rate@10: 0.052713
2025-11-22 22:01:08 - GraphTrainer - INFO -   ndcg@10: 0.026947
2025-11-22 22:01:08 - GraphTrainer - INFO -   map@10: 0.019590
2025-11-22 22:01:08 - GraphTrainer - INFO -   mrr@10: 0.020405
2025-11-22 22:01:08 - GraphTrainer - INFO -   precision@20: 0.004127
2025-11-22 22:01:08 - GraphTrainer - INFO -   recall@20: 0.078255
2025-11-22 22:01:08 - GraphTrainer - INFO -   hit_rate@20: 0.082026
2025-11-22 22:01:08 - GraphTrainer - INFO -   ndcg@20: 0.034081
2025-11-22 22:01:08 - GraphTrainer - INFO -   map@20: 0.021507
2025-11-22 22:01:08 - GraphTrainer - INFO -   mrr@20: 0.022406
2025-11-22 22:01:08 - GraphTrainer - INFO - 第 132 轮训练完成
2025-11-22 22:01:08 - GraphTrainer - INFO - train_loss: 0.339800
2025-11-22 22:01:08 - GraphTrainer - INFO - precision@5: 0.006819
2025-11-22 22:01:08 - GraphTrainer - INFO - recall@5: 0.032452
2025-11-22 22:01:08 - GraphTrainer - INFO - hit_rate@5: 0.033993
2025-11-22 22:01:08 - GraphTrainer - INFO - ndcg@5: 0.021234
2025-11-22 22:01:08 - GraphTrainer - INFO - map@5: 0.017302
2025-11-22 22:01:08 - GraphTrainer - INFO - mrr@5: 0.017991
2025-11-22 22:01:08 - GraphTrainer - INFO - precision@10: 0.005282
2025-11-22 22:01:08 - GraphTrainer - INFO - recall@10: 0.050208
2025-11-22 22:01:08 - GraphTrainer - INFO - hit_rate@10: 0.052713
2025-11-22 22:01:08 - GraphTrainer - INFO - ndcg@10: 0.026947
2025-11-22 22:01:08 - GraphTrainer - INFO - map@10: 0.019590
2025-11-22 22:01:08 - GraphTrainer - INFO - mrr@10: 0.020405
2025-11-22 22:01:08 - GraphTrainer - INFO - precision@20: 0.004127
2025-11-22 22:01:08 - GraphTrainer - INFO - recall@20: 0.078255
2025-11-22 22:01:08 - GraphTrainer - INFO - hit_rate@20: 0.082026
2025-11-22 22:01:08 - GraphTrainer - INFO - ndcg@20: 0.034081
2025-11-22 22:01:08 - GraphTrainer - INFO - map@20: 0.021507
2025-11-22 22:01:08 - GraphTrainer - INFO - mrr@20: 0.022406
2025-11-22 22:01:08 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:01:08 - GraphTrainer - INFO - ============================================================
2025-11-22 22:01:08 - GraphTrainer - INFO - 开始第 133/1000 轮训练
2025-11-22 22:01:08 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3248, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3221, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3537, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3259, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3494, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3331, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3738, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3534, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3433, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3278, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3318, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3656, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3534, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3574, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3537, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3507, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3318, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3189, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3197, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3342, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3190, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3318, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3537, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3131, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3708, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3284, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3548, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3435, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3177, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
The 132 training average loss: 0.33980025607964087
2025-11-22 22:01:19 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:01:19 - GraphTrainer - INFO -   precision@5: 0.006562
2025-11-22 22:01:19 - GraphTrainer - INFO -   recall@5: 0.031196
2025-11-22 22:01:19 - GraphTrainer - INFO -   hit_rate@5: 0.032708
2025-11-22 22:01:19 - GraphTrainer - INFO -   ndcg@5: 0.020623
2025-11-22 22:01:19 - GraphTrainer - INFO -   map@5: 0.016913
2025-11-22 22:01:19 - GraphTrainer - INFO -   mrr@5: 0.017561
2025-11-22 22:01:19 - GraphTrainer - INFO -   precision@10: 0.005163
2025-11-22 22:01:19 - GraphTrainer - INFO -   recall@10: 0.049039
2025-11-22 22:01:19 - GraphTrainer - INFO -   hit_rate@10: 0.051427
2025-11-22 22:01:19 - GraphTrainer - INFO -   ndcg@10: 0.026455
2025-11-22 22:01:19 - GraphTrainer - INFO -   map@10: 0.019303
2025-11-22 22:01:19 - GraphTrainer - INFO -   mrr@10: 0.020066
2025-11-22 22:01:19 - GraphTrainer - INFO -   precision@20: 0.004155
2025-11-22 22:01:19 - GraphTrainer - INFO -   recall@20: 0.078900
2025-11-22 22:01:19 - GraphTrainer - INFO -   hit_rate@20: 0.082695
2025-11-22 22:01:19 - GraphTrainer - INFO -   ndcg@20: 0.034014
2025-11-22 22:01:19 - GraphTrainer - INFO -   map@20: 0.021320
2025-11-22 22:01:19 - GraphTrainer - INFO -   mrr@20: 0.022181
2025-11-22 22:01:19 - GraphTrainer - INFO - 第 133 轮训练完成
2025-11-22 22:01:19 - GraphTrainer - INFO - train_loss: 0.341290
2025-11-22 22:01:19 - GraphTrainer - INFO - precision@5: 0.006562
2025-11-22 22:01:19 - GraphTrainer - INFO - recall@5: 0.031196
2025-11-22 22:01:19 - GraphTrainer - INFO - hit_rate@5: 0.032708
2025-11-22 22:01:19 - GraphTrainer - INFO - ndcg@5: 0.020623
2025-11-22 22:01:19 - GraphTrainer - INFO - map@5: 0.016913
2025-11-22 22:01:19 - GraphTrainer - INFO - mrr@5: 0.017561
2025-11-22 22:01:19 - GraphTrainer - INFO - precision@10: 0.005163
2025-11-22 22:01:19 - GraphTrainer - INFO - recall@10: 0.049039
2025-11-22 22:01:19 - GraphTrainer - INFO - hit_rate@10: 0.051427
2025-11-22 22:01:19 - GraphTrainer - INFO - ndcg@10: 0.026455
2025-11-22 22:01:19 - GraphTrainer - INFO - map@10: 0.019303
2025-11-22 22:01:19 - GraphTrainer - INFO - mrr@10: 0.020066
2025-11-22 22:01:19 - GraphTrainer - INFO - precision@20: 0.004155
2025-11-22 22:01:19 - GraphTrainer - INFO - recall@20: 0.078900
2025-11-22 22:01:19 - GraphTrainer - INFO - hit_rate@20: 0.082695
2025-11-22 22:01:19 - GraphTrainer - INFO - ndcg@20: 0.034014
2025-11-22 22:01:19 - GraphTrainer - INFO - map@20: 0.021320
2025-11-22 22:01:19 - GraphTrainer - INFO - mrr@20: 0.022181
2025-11-22 22:01:19 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:01:19 - GraphTrainer - INFO - ============================================================
2025-11-22 22:01:19 - GraphTrainer - INFO - 开始第 134/1000 轮训练
2025-11-22 22:01:19 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3156, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3457, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3549, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3492, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3285, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3630, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3246, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3168, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3177, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3625, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3171, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3131, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3539, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3707, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3200, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3602, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3596, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3274, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3557, device='cuda:0', grad_fn=<AddBackward0>)
The 133 training average loss: 0.34128982548055975
2025-11-22 22:01:30 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:01:30 - GraphTrainer - INFO -   precision@5: 0.006593
2025-11-22 22:01:30 - GraphTrainer - INFO -   recall@5: 0.031269
2025-11-22 22:01:30 - GraphTrainer - INFO -   hit_rate@5: 0.032862
2025-11-22 22:01:30 - GraphTrainer - INFO -   ndcg@5: 0.020330
2025-11-22 22:01:30 - GraphTrainer - INFO -   map@5: 0.016488
2025-11-22 22:01:30 - GraphTrainer - INFO -   mrr@5: 0.017154
2025-11-22 22:01:30 - GraphTrainer - INFO -   precision@10: 0.005271
2025-11-22 22:01:30 - GraphTrainer - INFO -   recall@10: 0.049958
2025-11-22 22:01:30 - GraphTrainer - INFO -   hit_rate@10: 0.052558
2025-11-22 22:01:30 - GraphTrainer - INFO -   ndcg@10: 0.026397
2025-11-22 22:01:30 - GraphTrainer - INFO -   map@10: 0.018949
2025-11-22 22:01:30 - GraphTrainer - INFO -   mrr@10: 0.019738
2025-11-22 22:01:30 - GraphTrainer - INFO -   precision@20: 0.004065
2025-11-22 22:01:30 - GraphTrainer - INFO -   recall@20: 0.077174
2025-11-22 22:01:30 - GraphTrainer - INFO -   hit_rate@20: 0.080895
2025-11-22 22:01:30 - GraphTrainer - INFO -   ndcg@20: 0.033291
2025-11-22 22:01:30 - GraphTrainer - INFO -   map@20: 0.020796
2025-11-22 22:01:30 - GraphTrainer - INFO -   mrr@20: 0.021656
2025-11-22 22:01:30 - GraphTrainer - INFO - 第 134 轮训练完成
2025-11-22 22:01:30 - GraphTrainer - INFO - train_loss: 0.338238
2025-11-22 22:01:30 - GraphTrainer - INFO - precision@5: 0.006593
2025-11-22 22:01:30 - GraphTrainer - INFO - recall@5: 0.031269
2025-11-22 22:01:30 - GraphTrainer - INFO - hit_rate@5: 0.032862
2025-11-22 22:01:30 - GraphTrainer - INFO - ndcg@5: 0.020330
2025-11-22 22:01:30 - GraphTrainer - INFO - map@5: 0.016488
2025-11-22 22:01:30 - GraphTrainer - INFO - mrr@5: 0.017154
2025-11-22 22:01:30 - GraphTrainer - INFO - precision@10: 0.005271
2025-11-22 22:01:30 - GraphTrainer - INFO - recall@10: 0.049958
2025-11-22 22:01:30 - GraphTrainer - INFO - hit_rate@10: 0.052558
2025-11-22 22:01:30 - GraphTrainer - INFO - ndcg@10: 0.026397
2025-11-22 22:01:30 - GraphTrainer - INFO - map@10: 0.018949
2025-11-22 22:01:30 - GraphTrainer - INFO - mrr@10: 0.019738
2025-11-22 22:01:30 - GraphTrainer - INFO - precision@20: 0.004065
2025-11-22 22:01:30 - GraphTrainer - INFO - recall@20: 0.077174
2025-11-22 22:01:30 - GraphTrainer - INFO - hit_rate@20: 0.080895
2025-11-22 22:01:30 - GraphTrainer - INFO - ndcg@20: 0.033291
2025-11-22 22:01:30 - GraphTrainer - INFO - map@20: 0.020796
2025-11-22 22:01:30 - GraphTrainer - INFO - mrr@20: 0.021656
2025-11-22 22:01:30 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:01:30 - GraphTrainer - INFO - ============================================================
2025-11-22 22:01:30 - GraphTrainer - INFO - 开始第 135/1000 轮训练
2025-11-22 22:01:30 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3225, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3212, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3602, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3545, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3296, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3223, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3490, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3244, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3234, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3175, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3525, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3379, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3379, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3421, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3572, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3373, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3316, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3258, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
The 134 training average loss: 0.3382384766792429
2025-11-22 22:01:41 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:01:41 - GraphTrainer - INFO -   precision@5: 0.006788
2025-11-22 22:01:41 - GraphTrainer - INFO -   recall@5: 0.032339
2025-11-22 22:01:41 - GraphTrainer - INFO -   hit_rate@5: 0.033839
2025-11-22 22:01:41 - GraphTrainer - INFO -   ndcg@5: 0.020724
2025-11-22 22:01:41 - GraphTrainer - INFO -   map@5: 0.016689
2025-11-22 22:01:41 - GraphTrainer - INFO -   mrr@5: 0.017334
2025-11-22 22:01:41 - GraphTrainer - INFO -   precision@10: 0.005199
2025-11-22 22:01:41 - GraphTrainer - INFO -   recall@10: 0.049379
2025-11-22 22:01:41 - GraphTrainer - INFO -   hit_rate@10: 0.051787
2025-11-22 22:01:41 - GraphTrainer - INFO -   ndcg@10: 0.026268
2025-11-22 22:01:41 - GraphTrainer - INFO -   map@10: 0.018941
2025-11-22 22:01:41 - GraphTrainer - INFO -   mrr@10: 0.019702
2025-11-22 22:01:41 - GraphTrainer - INFO -   precision@20: 0.004094
2025-11-22 22:01:41 - GraphTrainer - INFO -   recall@20: 0.077514
2025-11-22 22:01:41 - GraphTrainer - INFO -   hit_rate@20: 0.081461
2025-11-22 22:01:41 - GraphTrainer - INFO -   ndcg@20: 0.033426
2025-11-22 22:01:41 - GraphTrainer - INFO -   map@20: 0.020862
2025-11-22 22:01:41 - GraphTrainer - INFO -   mrr@20: 0.021725
2025-11-22 22:01:41 - GraphTrainer - INFO - 第 135 轮训练完成
2025-11-22 22:01:41 - GraphTrainer - INFO - train_loss: 0.337896
2025-11-22 22:01:41 - GraphTrainer - INFO - precision@5: 0.006788
2025-11-22 22:01:41 - GraphTrainer - INFO - recall@5: 0.032339
2025-11-22 22:01:41 - GraphTrainer - INFO - hit_rate@5: 0.033839
2025-11-22 22:01:41 - GraphTrainer - INFO - ndcg@5: 0.020724
2025-11-22 22:01:41 - GraphTrainer - INFO - map@5: 0.016689
2025-11-22 22:01:41 - GraphTrainer - INFO - mrr@5: 0.017334
2025-11-22 22:01:41 - GraphTrainer - INFO - precision@10: 0.005199
2025-11-22 22:01:41 - GraphTrainer - INFO - recall@10: 0.049379
2025-11-22 22:01:41 - GraphTrainer - INFO - hit_rate@10: 0.051787
2025-11-22 22:01:41 - GraphTrainer - INFO - ndcg@10: 0.026268
2025-11-22 22:01:41 - GraphTrainer - INFO - map@10: 0.018941
2025-11-22 22:01:41 - GraphTrainer - INFO - mrr@10: 0.019702
2025-11-22 22:01:41 - GraphTrainer - INFO - precision@20: 0.004094
2025-11-22 22:01:41 - GraphTrainer - INFO - recall@20: 0.077514
2025-11-22 22:01:41 - GraphTrainer - INFO - hit_rate@20: 0.081461
2025-11-22 22:01:41 - GraphTrainer - INFO - ndcg@20: 0.033426
2025-11-22 22:01:41 - GraphTrainer - INFO - map@20: 0.020862
2025-11-22 22:01:41 - GraphTrainer - INFO - mrr@20: 0.021725
2025-11-22 22:01:41 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:01:41 - GraphTrainer - INFO - ============================================================
2025-11-22 22:01:41 - GraphTrainer - INFO - 开始第 136/1000 轮训练
2025-11-22 22:01:41 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3605, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3222, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3192, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3466, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3188, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3220, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3302, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3479, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3125, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3468, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3484, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3577, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3249, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3342, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3282, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3164, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3517, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3312, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3628, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3256, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3172, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3284, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
The 135 training average loss: 0.3378957222247946
2025-11-22 22:01:52 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:01:52 - GraphTrainer - INFO -   precision@5: 0.006758
2025-11-22 22:01:52 - GraphTrainer - INFO -   recall@5: 0.032253
2025-11-22 22:01:52 - GraphTrainer - INFO -   hit_rate@5: 0.033685
2025-11-22 22:01:52 - GraphTrainer - INFO -   ndcg@5: 0.021089
2025-11-22 22:01:52 - GraphTrainer - INFO -   map@5: 0.017193
2025-11-22 22:01:52 - GraphTrainer - INFO -   mrr@5: 0.017857
2025-11-22 22:01:52 - GraphTrainer - INFO -   precision@10: 0.005210
2025-11-22 22:01:52 - GraphTrainer - INFO -   recall@10: 0.049559
2025-11-22 22:01:52 - GraphTrainer - INFO -   hit_rate@10: 0.051941
2025-11-22 22:01:52 - GraphTrainer - INFO -   ndcg@10: 0.026721
2025-11-22 22:01:52 - GraphTrainer - INFO -   map@10: 0.019481
2025-11-22 22:01:52 - GraphTrainer - INFO -   mrr@10: 0.020271
2025-11-22 22:01:52 - GraphTrainer - INFO -   precision@20: 0.004140
2025-11-22 22:01:52 - GraphTrainer - INFO -   recall@20: 0.078185
2025-11-22 22:01:52 - GraphTrainer - INFO -   hit_rate@20: 0.082232
2025-11-22 22:01:52 - GraphTrainer - INFO -   ndcg@20: 0.034007
2025-11-22 22:01:52 - GraphTrainer - INFO -   map@20: 0.021428
2025-11-22 22:01:52 - GraphTrainer - INFO -   mrr@20: 0.022326
2025-11-22 22:01:52 - GraphTrainer - INFO - 第 136 轮训练完成
2025-11-22 22:01:52 - GraphTrainer - INFO - train_loss: 0.338074
2025-11-22 22:01:52 - GraphTrainer - INFO - precision@5: 0.006758
2025-11-22 22:01:52 - GraphTrainer - INFO - recall@5: 0.032253
2025-11-22 22:01:52 - GraphTrainer - INFO - hit_rate@5: 0.033685
2025-11-22 22:01:52 - GraphTrainer - INFO - ndcg@5: 0.021089
2025-11-22 22:01:52 - GraphTrainer - INFO - map@5: 0.017193
2025-11-22 22:01:52 - GraphTrainer - INFO - mrr@5: 0.017857
2025-11-22 22:01:52 - GraphTrainer - INFO - precision@10: 0.005210
2025-11-22 22:01:52 - GraphTrainer - INFO - recall@10: 0.049559
2025-11-22 22:01:52 - GraphTrainer - INFO - hit_rate@10: 0.051941
2025-11-22 22:01:52 - GraphTrainer - INFO - ndcg@10: 0.026721
2025-11-22 22:01:52 - GraphTrainer - INFO - map@10: 0.019481
2025-11-22 22:01:52 - GraphTrainer - INFO - mrr@10: 0.020271
2025-11-22 22:01:52 - GraphTrainer - INFO - precision@20: 0.004140
2025-11-22 22:01:52 - GraphTrainer - INFO - recall@20: 0.078185
2025-11-22 22:01:52 - GraphTrainer - INFO - hit_rate@20: 0.082232
2025-11-22 22:01:52 - GraphTrainer - INFO - ndcg@20: 0.034007
2025-11-22 22:01:52 - GraphTrainer - INFO - map@20: 0.021428
2025-11-22 22:01:52 - GraphTrainer - INFO - mrr@20: 0.022326
2025-11-22 22:01:52 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:01:52 - GraphTrainer - INFO - ============================================================
2025-11-22 22:01:52 - GraphTrainer - INFO - 开始第 137/1000 轮训练
2025-11-22 22:01:52 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3184, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3588, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3509, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3568, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3506, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3304, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3207, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3138, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3577, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3272, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3043, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3543, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3468, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3376, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3218, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3409, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3193, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3284, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3631, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3455, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3435, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3484, device='cuda:0', grad_fn=<AddBackward0>)
The 136 training average loss: 0.33807430030970737
2025-11-22 22:02:03 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:02:03 - GraphTrainer - INFO -   precision@5: 0.006644
2025-11-22 22:02:03 - GraphTrainer - INFO -   recall@5: 0.031683
2025-11-22 22:02:03 - GraphTrainer - INFO -   hit_rate@5: 0.033170
2025-11-22 22:02:03 - GraphTrainer - INFO -   ndcg@5: 0.020722
2025-11-22 22:02:03 - GraphTrainer - INFO -   map@5: 0.016884
2025-11-22 22:02:03 - GraphTrainer - INFO -   mrr@5: 0.017573
2025-11-22 22:02:03 - GraphTrainer - INFO -   precision@10: 0.005179
2025-11-22 22:02:03 - GraphTrainer - INFO -   recall@10: 0.049021
2025-11-22 22:02:03 - GraphTrainer - INFO -   hit_rate@10: 0.051581
2025-11-22 22:02:03 - GraphTrainer - INFO -   ndcg@10: 0.026386
2025-11-22 22:02:03 - GraphTrainer - INFO -   map@10: 0.019189
2025-11-22 22:02:03 - GraphTrainer - INFO -   mrr@10: 0.020013
2025-11-22 22:02:03 - GraphTrainer - INFO -   precision@20: 0.004122
2025-11-22 22:02:03 - GraphTrainer - INFO -   recall@20: 0.077880
2025-11-22 22:02:03 - GraphTrainer - INFO -   hit_rate@20: 0.081975
2025-11-22 22:02:03 - GraphTrainer - INFO -   ndcg@20: 0.033713
2025-11-22 22:02:03 - GraphTrainer - INFO -   map@20: 0.021145
2025-11-22 22:02:03 - GraphTrainer - INFO -   mrr@20: 0.022072
2025-11-22 22:02:03 - GraphTrainer - INFO - 第 137 轮训练完成
2025-11-22 22:02:03 - GraphTrainer - INFO - train_loss: 0.338740
2025-11-22 22:02:03 - GraphTrainer - INFO - precision@5: 0.006644
2025-11-22 22:02:03 - GraphTrainer - INFO - recall@5: 0.031683
2025-11-22 22:02:03 - GraphTrainer - INFO - hit_rate@5: 0.033170
2025-11-22 22:02:03 - GraphTrainer - INFO - ndcg@5: 0.020722
2025-11-22 22:02:03 - GraphTrainer - INFO - map@5: 0.016884
2025-11-22 22:02:03 - GraphTrainer - INFO - mrr@5: 0.017573
2025-11-22 22:02:03 - GraphTrainer - INFO - precision@10: 0.005179
2025-11-22 22:02:03 - GraphTrainer - INFO - recall@10: 0.049021
2025-11-22 22:02:03 - GraphTrainer - INFO - hit_rate@10: 0.051581
2025-11-22 22:02:03 - GraphTrainer - INFO - ndcg@10: 0.026386
2025-11-22 22:02:03 - GraphTrainer - INFO - map@10: 0.019189
2025-11-22 22:02:03 - GraphTrainer - INFO - mrr@10: 0.020013
2025-11-22 22:02:03 - GraphTrainer - INFO - precision@20: 0.004122
2025-11-22 22:02:03 - GraphTrainer - INFO - recall@20: 0.077880
2025-11-22 22:02:03 - GraphTrainer - INFO - hit_rate@20: 0.081975
2025-11-22 22:02:03 - GraphTrainer - INFO - ndcg@20: 0.033713
2025-11-22 22:02:03 - GraphTrainer - INFO - map@20: 0.021145
2025-11-22 22:02:03 - GraphTrainer - INFO - mrr@20: 0.022072
2025-11-22 22:02:03 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:02:03 - GraphTrainer - INFO - ============================================================
2025-11-22 22:02:03 - GraphTrainer - INFO - 开始第 138/1000 轮训练
2025-11-22 22:02:03 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3103, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3421, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3492, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3102, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3663, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3190, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3231, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3595, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3234, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3282, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3602, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3141, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3601, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3187, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3549, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3313, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3273, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3331, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3278, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3239, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3123, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3288, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3554, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3184, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3582, device='cuda:0', grad_fn=<AddBackward0>)
The 137 training average loss: 0.33874018387547855
2025-11-22 22:02:15 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:02:15 - GraphTrainer - INFO -   precision@5: 0.006634
2025-11-22 22:02:15 - GraphTrainer - INFO -   recall@5: 0.031717
2025-11-22 22:02:15 - GraphTrainer - INFO -   hit_rate@5: 0.033119
2025-11-22 22:02:15 - GraphTrainer - INFO -   ndcg@5: 0.020452
2025-11-22 22:02:15 - GraphTrainer - INFO -   map@5: 0.016529
2025-11-22 22:02:15 - GraphTrainer - INFO -   mrr@5: 0.017182
2025-11-22 22:02:15 - GraphTrainer - INFO -   precision@10: 0.005210
2025-11-22 22:02:15 - GraphTrainer - INFO -   recall@10: 0.049388
2025-11-22 22:02:15 - GraphTrainer - INFO -   hit_rate@10: 0.051890
2025-11-22 22:02:15 - GraphTrainer - INFO -   ndcg@10: 0.026198
2025-11-22 22:02:15 - GraphTrainer - INFO -   map@10: 0.018849
2025-11-22 22:02:15 - GraphTrainer - INFO -   mrr@10: 0.019642
2025-11-22 22:02:15 - GraphTrainer - INFO -   precision@20: 0.004132
2025-11-22 22:02:15 - GraphTrainer - INFO -   recall@20: 0.078370
2025-11-22 22:02:15 - GraphTrainer - INFO -   hit_rate@20: 0.082232
2025-11-22 22:02:15 - GraphTrainer - INFO -   ndcg@20: 0.033565
2025-11-22 22:02:15 - GraphTrainer - INFO -   map@20: 0.020831
2025-11-22 22:02:15 - GraphTrainer - INFO -   mrr@20: 0.021717
2025-11-22 22:02:15 - GraphTrainer - INFO - 第 138 轮训练完成
2025-11-22 22:02:15 - GraphTrainer - INFO - train_loss: 0.334504
2025-11-22 22:02:15 - GraphTrainer - INFO - precision@5: 0.006634
2025-11-22 22:02:15 - GraphTrainer - INFO - recall@5: 0.031717
2025-11-22 22:02:15 - GraphTrainer - INFO - hit_rate@5: 0.033119
2025-11-22 22:02:15 - GraphTrainer - INFO - ndcg@5: 0.020452
2025-11-22 22:02:15 - GraphTrainer - INFO - map@5: 0.016529
2025-11-22 22:02:15 - GraphTrainer - INFO - mrr@5: 0.017182
2025-11-22 22:02:15 - GraphTrainer - INFO - precision@10: 0.005210
2025-11-22 22:02:15 - GraphTrainer - INFO - recall@10: 0.049388
2025-11-22 22:02:15 - GraphTrainer - INFO - hit_rate@10: 0.051890
2025-11-22 22:02:15 - GraphTrainer - INFO - ndcg@10: 0.026198
2025-11-22 22:02:15 - GraphTrainer - INFO - map@10: 0.018849
2025-11-22 22:02:15 - GraphTrainer - INFO - mrr@10: 0.019642
2025-11-22 22:02:15 - GraphTrainer - INFO - precision@20: 0.004132
2025-11-22 22:02:15 - GraphTrainer - INFO - recall@20: 0.078370
2025-11-22 22:02:15 - GraphTrainer - INFO - hit_rate@20: 0.082232
2025-11-22 22:02:15 - GraphTrainer - INFO - ndcg@20: 0.033565
2025-11-22 22:02:15 - GraphTrainer - INFO - map@20: 0.020831
2025-11-22 22:02:15 - GraphTrainer - INFO - mrr@20: 0.021717
2025-11-22 22:02:15 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:02:15 - GraphTrainer - INFO - ============================================================
2025-11-22 22:02:15 - GraphTrainer - INFO - 开始第 139/1000 轮训练
2025-11-22 22:02:15 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3297, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3207, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3181, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3278, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3290, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3285, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3299, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3276, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3176, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3094, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3152, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3467, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3435, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3296, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3212, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3237, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3619, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3590, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3261, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3210, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
The 138 training average loss: 0.3345041310992734
2025-11-22 22:02:26 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:02:26 - GraphTrainer - INFO -   precision@5: 0.006655
2025-11-22 22:02:26 - GraphTrainer - INFO -   recall@5: 0.031738
2025-11-22 22:02:26 - GraphTrainer - INFO -   hit_rate@5: 0.033170
2025-11-22 22:02:26 - GraphTrainer - INFO -   ndcg@5: 0.020728
2025-11-22 22:02:26 - GraphTrainer - INFO -   map@5: 0.016883
2025-11-22 22:02:26 - GraphTrainer - INFO -   mrr@5: 0.017552
2025-11-22 22:02:26 - GraphTrainer - INFO -   precision@10: 0.005287
2025-11-22 22:02:26 - GraphTrainer - INFO -   recall@10: 0.050158
2025-11-22 22:02:26 - GraphTrainer - INFO -   hit_rate@10: 0.052713
2025-11-22 22:02:26 - GraphTrainer - INFO -   ndcg@10: 0.026724
2025-11-22 22:02:26 - GraphTrainer - INFO -   map@10: 0.019314
2025-11-22 22:02:26 - GraphTrainer - INFO -   mrr@10: 0.020124
2025-11-22 22:02:26 - GraphTrainer - INFO -   precision@20: 0.004099
2025-11-22 22:02:26 - GraphTrainer - INFO -   recall@20: 0.077686
2025-11-22 22:02:26 - GraphTrainer - INFO -   hit_rate@20: 0.081666
2025-11-22 22:02:26 - GraphTrainer - INFO -   ndcg@20: 0.033702
2025-11-22 22:02:26 - GraphTrainer - INFO -   map@20: 0.021176
2025-11-22 22:02:26 - GraphTrainer - INFO -   mrr@20: 0.022080
2025-11-22 22:02:26 - GraphTrainer - INFO - 第 139 轮训练完成
2025-11-22 22:02:26 - GraphTrainer - INFO - train_loss: 0.336609
2025-11-22 22:02:26 - GraphTrainer - INFO - precision@5: 0.006655
2025-11-22 22:02:26 - GraphTrainer - INFO - recall@5: 0.031738
2025-11-22 22:02:26 - GraphTrainer - INFO - hit_rate@5: 0.033170
2025-11-22 22:02:26 - GraphTrainer - INFO - ndcg@5: 0.020728
2025-11-22 22:02:26 - GraphTrainer - INFO - map@5: 0.016883
2025-11-22 22:02:26 - GraphTrainer - INFO - mrr@5: 0.017552
2025-11-22 22:02:26 - GraphTrainer - INFO - precision@10: 0.005287
2025-11-22 22:02:26 - GraphTrainer - INFO - recall@10: 0.050158
2025-11-22 22:02:26 - GraphTrainer - INFO - hit_rate@10: 0.052713
2025-11-22 22:02:26 - GraphTrainer - INFO - ndcg@10: 0.026724
2025-11-22 22:02:26 - GraphTrainer - INFO - map@10: 0.019314
2025-11-22 22:02:26 - GraphTrainer - INFO - mrr@10: 0.020124
2025-11-22 22:02:26 - GraphTrainer - INFO - precision@20: 0.004099
2025-11-22 22:02:26 - GraphTrainer - INFO - recall@20: 0.077686
2025-11-22 22:02:26 - GraphTrainer - INFO - hit_rate@20: 0.081666
2025-11-22 22:02:26 - GraphTrainer - INFO - ndcg@20: 0.033702
2025-11-22 22:02:26 - GraphTrainer - INFO - map@20: 0.021176
2025-11-22 22:02:26 - GraphTrainer - INFO - mrr@20: 0.022080
2025-11-22 22:02:26 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:02:26 - GraphTrainer - INFO - ============================================================
2025-11-22 22:02:26 - GraphTrainer - INFO - 开始第 140/1000 轮训练
2025-11-22 22:02:26 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3608, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3205, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3596, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3205, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3186, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3278, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3084, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3531, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3268, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3273, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3173, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3219, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3274, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3506, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3101, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3521, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3079, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3227, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3654, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3434, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3187, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3560, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3509, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3529, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
The 139 training average loss: 0.3366085630038689
2025-11-22 22:02:37 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:02:37 - GraphTrainer - INFO -   precision@5: 0.006593
2025-11-22 22:02:37 - GraphTrainer - INFO -   recall@5: 0.031537
2025-11-22 22:02:37 - GraphTrainer - INFO -   hit_rate@5: 0.032862
2025-11-22 22:02:37 - GraphTrainer - INFO -   ndcg@5: 0.020726
2025-11-22 22:02:37 - GraphTrainer - INFO -   map@5: 0.016962
2025-11-22 22:02:37 - GraphTrainer - INFO -   mrr@5: 0.017589
2025-11-22 22:02:37 - GraphTrainer - INFO -   precision@10: 0.005230
2025-11-22 22:02:37 - GraphTrainer - INFO -   recall@10: 0.049661
2025-11-22 22:02:37 - GraphTrainer - INFO -   hit_rate@10: 0.052096
2025-11-22 22:02:37 - GraphTrainer - INFO -   ndcg@10: 0.026655
2025-11-22 22:02:37 - GraphTrainer - INFO -   map@10: 0.019381
2025-11-22 22:02:37 - GraphTrainer - INFO -   mrr@10: 0.020155
2025-11-22 22:02:37 - GraphTrainer - INFO -   precision@20: 0.004060
2025-11-22 22:02:37 - GraphTrainer - INFO -   recall@20: 0.076926
2025-11-22 22:02:37 - GraphTrainer - INFO -   hit_rate@20: 0.080792
2025-11-22 22:02:37 - GraphTrainer - INFO -   ndcg@20: 0.033609
2025-11-22 22:02:37 - GraphTrainer - INFO -   map@20: 0.021256
2025-11-22 22:02:37 - GraphTrainer - INFO -   mrr@20: 0.022125
2025-11-22 22:02:37 - GraphTrainer - INFO - 第 140 轮训练完成
2025-11-22 22:02:37 - GraphTrainer - INFO - train_loss: 0.335802
2025-11-22 22:02:37 - GraphTrainer - INFO - precision@5: 0.006593
2025-11-22 22:02:37 - GraphTrainer - INFO - recall@5: 0.031537
2025-11-22 22:02:37 - GraphTrainer - INFO - hit_rate@5: 0.032862
2025-11-22 22:02:37 - GraphTrainer - INFO - ndcg@5: 0.020726
2025-11-22 22:02:37 - GraphTrainer - INFO - map@5: 0.016962
2025-11-22 22:02:37 - GraphTrainer - INFO - mrr@5: 0.017589
2025-11-22 22:02:37 - GraphTrainer - INFO - precision@10: 0.005230
2025-11-22 22:02:37 - GraphTrainer - INFO - recall@10: 0.049661
2025-11-22 22:02:37 - GraphTrainer - INFO - hit_rate@10: 0.052096
2025-11-22 22:02:37 - GraphTrainer - INFO - ndcg@10: 0.026655
2025-11-22 22:02:37 - GraphTrainer - INFO - map@10: 0.019381
2025-11-22 22:02:37 - GraphTrainer - INFO - mrr@10: 0.020155
2025-11-22 22:02:37 - GraphTrainer - INFO - precision@20: 0.004060
2025-11-22 22:02:37 - GraphTrainer - INFO - recall@20: 0.076926
2025-11-22 22:02:37 - GraphTrainer - INFO - hit_rate@20: 0.080792
2025-11-22 22:02:37 - GraphTrainer - INFO - ndcg@20: 0.033609
2025-11-22 22:02:37 - GraphTrainer - INFO - map@20: 0.021256
2025-11-22 22:02:37 - GraphTrainer - INFO - mrr@20: 0.022125
2025-11-22 22:02:37 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:02:37 - GraphTrainer - INFO - 检查点已保存: Epoch 140 -> ./checkpoints/checkpoint_epoch_140.pth
2025-11-22 22:02:37 - GraphTrainer - INFO - ============================================================
2025-11-22 22:02:37 - GraphTrainer - INFO - 开始第 141/1000 轮训练
2025-11-22 22:02:37 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3216, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3212, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3312, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3373, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3220, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3174, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3592, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3133, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3162, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3235, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3198, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3639, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3204, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3282, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3558, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3166, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3194, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3309, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3655, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3281, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3299, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3214, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3195, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3655, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3236, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3245, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3499, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3166, device='cuda:0', grad_fn=<AddBackward0>)
The 140 training average loss: 0.3358023074166528
2025-11-22 22:02:48 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:02:48 - GraphTrainer - INFO -   precision@5: 0.006747
2025-11-22 22:02:48 - GraphTrainer - INFO -   recall@5: 0.032354
2025-11-22 22:02:48 - GraphTrainer - INFO -   hit_rate@5: 0.033633
2025-11-22 22:02:48 - GraphTrainer - INFO -   ndcg@5: 0.020967
2025-11-22 22:02:48 - GraphTrainer - INFO -   map@5: 0.017008
2025-11-22 22:02:48 - GraphTrainer - INFO -   mrr@5: 0.017631
2025-11-22 22:02:48 - GraphTrainer - INFO -   precision@10: 0.005287
2025-11-22 22:02:48 - GraphTrainer - INFO -   recall@10: 0.050330
2025-11-22 22:02:48 - GraphTrainer - INFO -   hit_rate@10: 0.052713
2025-11-22 22:02:48 - GraphTrainer - INFO -   ndcg@10: 0.026773
2025-11-22 22:02:48 - GraphTrainer - INFO -   map@10: 0.019331
2025-11-22 22:02:48 - GraphTrainer - INFO -   mrr@10: 0.020099
2025-11-22 22:02:48 - GraphTrainer - INFO -   precision@20: 0.004104
2025-11-22 22:02:48 - GraphTrainer - INFO -   recall@20: 0.077620
2025-11-22 22:02:48 - GraphTrainer - INFO -   hit_rate@20: 0.081666
2025-11-22 22:02:48 - GraphTrainer - INFO -   ndcg@20: 0.033702
2025-11-22 22:02:48 - GraphTrainer - INFO -   map@20: 0.021175
2025-11-22 22:02:48 - GraphTrainer - INFO -   mrr@20: 0.022050
2025-11-22 22:02:48 - GraphTrainer - INFO - 第 141 轮训练完成
2025-11-22 22:02:48 - GraphTrainer - INFO - train_loss: 0.336012
2025-11-22 22:02:48 - GraphTrainer - INFO - precision@5: 0.006747
2025-11-22 22:02:48 - GraphTrainer - INFO - recall@5: 0.032354
2025-11-22 22:02:48 - GraphTrainer - INFO - hit_rate@5: 0.033633
2025-11-22 22:02:48 - GraphTrainer - INFO - ndcg@5: 0.020967
2025-11-22 22:02:48 - GraphTrainer - INFO - map@5: 0.017008
2025-11-22 22:02:48 - GraphTrainer - INFO - mrr@5: 0.017631
2025-11-22 22:02:48 - GraphTrainer - INFO - precision@10: 0.005287
2025-11-22 22:02:48 - GraphTrainer - INFO - recall@10: 0.050330
2025-11-22 22:02:48 - GraphTrainer - INFO - hit_rate@10: 0.052713
2025-11-22 22:02:48 - GraphTrainer - INFO - ndcg@10: 0.026773
2025-11-22 22:02:48 - GraphTrainer - INFO - map@10: 0.019331
2025-11-22 22:02:48 - GraphTrainer - INFO - mrr@10: 0.020099
2025-11-22 22:02:48 - GraphTrainer - INFO - precision@20: 0.004104
2025-11-22 22:02:48 - GraphTrainer - INFO - recall@20: 0.077620
2025-11-22 22:02:48 - GraphTrainer - INFO - hit_rate@20: 0.081666
2025-11-22 22:02:48 - GraphTrainer - INFO - ndcg@20: 0.033702
2025-11-22 22:02:48 - GraphTrainer - INFO - map@20: 0.021175
2025-11-22 22:02:48 - GraphTrainer - INFO - mrr@20: 0.022050
2025-11-22 22:02:48 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:02:48 - GraphTrainer - INFO - ============================================================
2025-11-22 22:02:48 - GraphTrainer - INFO - 开始第 142/1000 轮训练
2025-11-22 22:02:48 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3517, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3233, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3521, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3373, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3654, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3092, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3435, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3214, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3306, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3128, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3433, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3670, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3274, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3509, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3145, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3254, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3555, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3186, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3327, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3184, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3136, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3409, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3433, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3183, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3455, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3125, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
The 141 training average loss: 0.33601246157596854
2025-11-22 22:02:59 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:02:59 - GraphTrainer - INFO -   precision@5: 0.006768
2025-11-22 22:02:59 - GraphTrainer - INFO -   recall@5: 0.032278
2025-11-22 22:02:59 - GraphTrainer - INFO -   hit_rate@5: 0.033736
2025-11-22 22:02:59 - GraphTrainer - INFO -   ndcg@5: 0.021034
2025-11-22 22:02:59 - GraphTrainer - INFO -   map@5: 0.017119
2025-11-22 22:02:59 - GraphTrainer - INFO -   mrr@5: 0.017786
2025-11-22 22:02:59 - GraphTrainer - INFO -   precision@10: 0.005210
2025-11-22 22:02:59 - GraphTrainer - INFO -   recall@10: 0.049639
2025-11-22 22:02:59 - GraphTrainer - INFO -   hit_rate@10: 0.051941
2025-11-22 22:02:59 - GraphTrainer - INFO -   ndcg@10: 0.026663
2025-11-22 22:02:59 - GraphTrainer - INFO -   map@10: 0.019401
2025-11-22 22:02:59 - GraphTrainer - INFO -   mrr@10: 0.020178
2025-11-22 22:02:59 - GraphTrainer - INFO -   precision@20: 0.004099
2025-11-22 22:02:59 - GraphTrainer - INFO -   recall@20: 0.077731
2025-11-22 22:02:59 - GraphTrainer - INFO -   hit_rate@20: 0.081512
2025-11-22 22:02:59 - GraphTrainer - INFO -   ndcg@20: 0.033792
2025-11-22 22:02:59 - GraphTrainer - INFO -   map@20: 0.021303
2025-11-22 22:02:59 - GraphTrainer - INFO -   mrr@20: 0.022177
2025-11-22 22:02:59 - GraphTrainer - INFO - 第 142 轮训练完成
2025-11-22 22:02:59 - GraphTrainer - INFO - train_loss: 0.336134
2025-11-22 22:02:59 - GraphTrainer - INFO - precision@5: 0.006768
2025-11-22 22:02:59 - GraphTrainer - INFO - recall@5: 0.032278
2025-11-22 22:02:59 - GraphTrainer - INFO - hit_rate@5: 0.033736
2025-11-22 22:02:59 - GraphTrainer - INFO - ndcg@5: 0.021034
2025-11-22 22:02:59 - GraphTrainer - INFO - map@5: 0.017119
2025-11-22 22:02:59 - GraphTrainer - INFO - mrr@5: 0.017786
2025-11-22 22:02:59 - GraphTrainer - INFO - precision@10: 0.005210
2025-11-22 22:02:59 - GraphTrainer - INFO - recall@10: 0.049639
2025-11-22 22:02:59 - GraphTrainer - INFO - hit_rate@10: 0.051941
2025-11-22 22:02:59 - GraphTrainer - INFO - ndcg@10: 0.026663
2025-11-22 22:02:59 - GraphTrainer - INFO - map@10: 0.019401
2025-11-22 22:02:59 - GraphTrainer - INFO - mrr@10: 0.020178
2025-11-22 22:02:59 - GraphTrainer - INFO - precision@20: 0.004099
2025-11-22 22:02:59 - GraphTrainer - INFO - recall@20: 0.077731
2025-11-22 22:02:59 - GraphTrainer - INFO - hit_rate@20: 0.081512
2025-11-22 22:02:59 - GraphTrainer - INFO - ndcg@20: 0.033792
2025-11-22 22:02:59 - GraphTrainer - INFO - map@20: 0.021303
2025-11-22 22:02:59 - GraphTrainer - INFO - mrr@20: 0.022177
2025-11-22 22:02:59 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:02:59 - GraphTrainer - INFO - ============================================================
2025-11-22 22:02:59 - GraphTrainer - INFO - 开始第 143/1000 轮训练
2025-11-22 22:02:59 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3142, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3258, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3490, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3080, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3175, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3139, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3171, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3252, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3063, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3114, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3539, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3230, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3580, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3285, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3373, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3467, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3502, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3499, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3707, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3302, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3547, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3120, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3136, device='cuda:0', grad_fn=<AddBackward0>)
The 142 training average loss: 0.3361338459212205
2025-11-22 22:03:10 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:03:10 - GraphTrainer - INFO -   precision@5: 0.006758
2025-11-22 22:03:10 - GraphTrainer - INFO -   recall@5: 0.032287
2025-11-22 22:03:10 - GraphTrainer - INFO -   hit_rate@5: 0.033685
2025-11-22 22:03:10 - GraphTrainer - INFO -   ndcg@5: 0.021320
2025-11-22 22:03:10 - GraphTrainer - INFO -   map@5: 0.017492
2025-11-22 22:03:10 - GraphTrainer - INFO -   mrr@5: 0.018144
2025-11-22 22:03:10 - GraphTrainer - INFO -   precision@10: 0.005271
2025-11-22 22:03:10 - GraphTrainer - INFO -   recall@10: 0.050231
2025-11-22 22:03:10 - GraphTrainer - INFO -   hit_rate@10: 0.052558
2025-11-22 22:03:10 - GraphTrainer - INFO -   ndcg@10: 0.027150
2025-11-22 22:03:10 - GraphTrainer - INFO -   map@10: 0.019855
2025-11-22 22:03:10 - GraphTrainer - INFO -   mrr@10: 0.020639
2025-11-22 22:03:10 - GraphTrainer - INFO -   precision@20: 0.004142
2025-11-22 22:03:10 - GraphTrainer - INFO -   recall@20: 0.078580
2025-11-22 22:03:10 - GraphTrainer - INFO -   hit_rate@20: 0.082386
2025-11-22 22:03:10 - GraphTrainer - INFO -   ndcg@20: 0.034341
2025-11-22 22:03:10 - GraphTrainer - INFO -   map@20: 0.021774
2025-11-22 22:03:10 - GraphTrainer - INFO -   mrr@20: 0.022655
2025-11-22 22:03:10 - GraphTrainer - INFO - 第 143 轮训练完成
2025-11-22 22:03:10 - GraphTrainer - INFO - train_loss: 0.337193
2025-11-22 22:03:10 - GraphTrainer - INFO - precision@5: 0.006758
2025-11-22 22:03:10 - GraphTrainer - INFO - recall@5: 0.032287
2025-11-22 22:03:10 - GraphTrainer - INFO - hit_rate@5: 0.033685
2025-11-22 22:03:10 - GraphTrainer - INFO - ndcg@5: 0.021320
2025-11-22 22:03:10 - GraphTrainer - INFO - map@5: 0.017492
2025-11-22 22:03:10 - GraphTrainer - INFO - mrr@5: 0.018144
2025-11-22 22:03:10 - GraphTrainer - INFO - precision@10: 0.005271
2025-11-22 22:03:10 - GraphTrainer - INFO - recall@10: 0.050231
2025-11-22 22:03:10 - GraphTrainer - INFO - hit_rate@10: 0.052558
2025-11-22 22:03:10 - GraphTrainer - INFO - ndcg@10: 0.027150
2025-11-22 22:03:10 - GraphTrainer - INFO - map@10: 0.019855
2025-11-22 22:03:10 - GraphTrainer - INFO - mrr@10: 0.020639
2025-11-22 22:03:10 - GraphTrainer - INFO - precision@20: 0.004142
2025-11-22 22:03:10 - GraphTrainer - INFO - recall@20: 0.078580
2025-11-22 22:03:10 - GraphTrainer - INFO - hit_rate@20: 0.082386
2025-11-22 22:03:10 - GraphTrainer - INFO - ndcg@20: 0.034341
2025-11-22 22:03:10 - GraphTrainer - INFO - map@20: 0.021774
2025-11-22 22:03:10 - GraphTrainer - INFO - mrr@20: 0.022655
2025-11-22 22:03:10 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:03:10 - GraphTrainer - INFO - ============================================================
2025-11-22 22:03:10 - GraphTrainer - INFO - 开始第 144/1000 轮训练
2025-11-22 22:03:10 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3492, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3574, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3582, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3261, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3601, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3179, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3139, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3555, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3117, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3462, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3516, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3531, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3252, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3473, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3189, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3166, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3024, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3617, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3539, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3245, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3139, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3168, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3124, device='cuda:0', grad_fn=<AddBackward0>)
The 143 training average loss: 0.33719336935158434
2025-11-22 22:03:21 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:03:21 - GraphTrainer - INFO -   precision@5: 0.006675
2025-11-22 22:03:21 - GraphTrainer - INFO -   recall@5: 0.031829
2025-11-22 22:03:21 - GraphTrainer - INFO -   hit_rate@5: 0.033273
2025-11-22 22:03:21 - GraphTrainer - INFO -   ndcg@5: 0.021236
2025-11-22 22:03:21 - GraphTrainer - INFO -   map@5: 0.017524
2025-11-22 22:03:21 - GraphTrainer - INFO -   mrr@5: 0.018185
2025-11-22 22:03:21 - GraphTrainer - INFO -   precision@10: 0.005292
2025-11-22 22:03:21 - GraphTrainer - INFO -   recall@10: 0.050245
2025-11-22 22:03:21 - GraphTrainer - INFO -   hit_rate@10: 0.052764
2025-11-22 22:03:21 - GraphTrainer - INFO -   ndcg@10: 0.027210
2025-11-22 22:03:21 - GraphTrainer - INFO -   map@10: 0.019935
2025-11-22 22:03:21 - GraphTrainer - INFO -   mrr@10: 0.020736
2025-11-22 22:03:21 - GraphTrainer - INFO -   precision@20: 0.004122
2025-11-22 22:03:21 - GraphTrainer - INFO -   recall@20: 0.078078
2025-11-22 22:03:21 - GraphTrainer - INFO -   hit_rate@20: 0.082078
2025-11-22 22:03:21 - GraphTrainer - INFO -   ndcg@20: 0.034294
2025-11-22 22:03:21 - GraphTrainer - INFO -   map@20: 0.021838
2025-11-22 22:03:21 - GraphTrainer - INFO -   mrr@20: 0.022736
2025-11-22 22:03:21 - GraphTrainer - INFO - 第 144 轮训练完成
2025-11-22 22:03:21 - GraphTrainer - INFO - train_loss: 0.336985
2025-11-22 22:03:21 - GraphTrainer - INFO - precision@5: 0.006675
2025-11-22 22:03:21 - GraphTrainer - INFO - recall@5: 0.031829
2025-11-22 22:03:21 - GraphTrainer - INFO - hit_rate@5: 0.033273
2025-11-22 22:03:21 - GraphTrainer - INFO - ndcg@5: 0.021236
2025-11-22 22:03:21 - GraphTrainer - INFO - map@5: 0.017524
2025-11-22 22:03:21 - GraphTrainer - INFO - mrr@5: 0.018185
2025-11-22 22:03:21 - GraphTrainer - INFO - precision@10: 0.005292
2025-11-22 22:03:21 - GraphTrainer - INFO - recall@10: 0.050245
2025-11-22 22:03:21 - GraphTrainer - INFO - hit_rate@10: 0.052764
2025-11-22 22:03:21 - GraphTrainer - INFO - ndcg@10: 0.027210
2025-11-22 22:03:21 - GraphTrainer - INFO - map@10: 0.019935
2025-11-22 22:03:21 - GraphTrainer - INFO - mrr@10: 0.020736
2025-11-22 22:03:21 - GraphTrainer - INFO - precision@20: 0.004122
2025-11-22 22:03:21 - GraphTrainer - INFO - recall@20: 0.078078
2025-11-22 22:03:21 - GraphTrainer - INFO - hit_rate@20: 0.082078
2025-11-22 22:03:21 - GraphTrainer - INFO - ndcg@20: 0.034294
2025-11-22 22:03:21 - GraphTrainer - INFO - map@20: 0.021838
2025-11-22 22:03:21 - GraphTrainer - INFO - mrr@20: 0.022736
2025-11-22 22:03:21 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:03:21 - GraphTrainer - INFO - ============================================================
2025-11-22 22:03:21 - GraphTrainer - INFO - 开始第 145/1000 轮训练
2025-11-22 22:03:21 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3237, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3237, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3284, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3254, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3084, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3072, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3716, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3143, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3272, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3318, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3610, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3327, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3683, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3537, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3188, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3525, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3199, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3327, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3258, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3494, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3586, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3182, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3248, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3183, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3284, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
The 144 training average loss: 0.33698512819306603
2025-11-22 22:03:32 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:03:32 - GraphTrainer - INFO -   precision@5: 0.006655
2025-11-22 22:03:32 - GraphTrainer - INFO -   recall@5: 0.031683
2025-11-22 22:03:32 - GraphTrainer - INFO -   hit_rate@5: 0.033170
2025-11-22 22:03:32 - GraphTrainer - INFO -   ndcg@5: 0.021093
2025-11-22 22:03:32 - GraphTrainer - INFO -   map@5: 0.017383
2025-11-22 22:03:32 - GraphTrainer - INFO -   mrr@5: 0.018045
2025-11-22 22:03:32 - GraphTrainer - INFO -   precision@10: 0.005297
2025-11-22 22:03:32 - GraphTrainer - INFO -   recall@10: 0.050291
2025-11-22 22:03:32 - GraphTrainer - INFO -   hit_rate@10: 0.052816
2025-11-22 22:03:32 - GraphTrainer - INFO -   ndcg@10: 0.027131
2025-11-22 22:03:32 - GraphTrainer - INFO -   map@10: 0.019825
2025-11-22 22:03:32 - GraphTrainer - INFO -   mrr@10: 0.020619
2025-11-22 22:03:32 - GraphTrainer - INFO -   precision@20: 0.004181
2025-11-22 22:03:32 - GraphTrainer - INFO -   recall@20: 0.079090
2025-11-22 22:03:32 - GraphTrainer - INFO -   hit_rate@20: 0.083158
2025-11-22 22:03:32 - GraphTrainer - INFO -   ndcg@20: 0.034451
2025-11-22 22:03:32 - GraphTrainer - INFO -   map@20: 0.021783
2025-11-22 22:03:32 - GraphTrainer - INFO -   mrr@20: 0.022679
2025-11-22 22:03:32 - GraphTrainer - INFO - 第 145 轮训练完成
2025-11-22 22:03:32 - GraphTrainer - INFO - train_loss: 0.335281
2025-11-22 22:03:32 - GraphTrainer - INFO - precision@5: 0.006655
2025-11-22 22:03:32 - GraphTrainer - INFO - recall@5: 0.031683
2025-11-22 22:03:32 - GraphTrainer - INFO - hit_rate@5: 0.033170
2025-11-22 22:03:32 - GraphTrainer - INFO - ndcg@5: 0.021093
2025-11-22 22:03:32 - GraphTrainer - INFO - map@5: 0.017383
2025-11-22 22:03:32 - GraphTrainer - INFO - mrr@5: 0.018045
2025-11-22 22:03:32 - GraphTrainer - INFO - precision@10: 0.005297
2025-11-22 22:03:32 - GraphTrainer - INFO - recall@10: 0.050291
2025-11-22 22:03:32 - GraphTrainer - INFO - hit_rate@10: 0.052816
2025-11-22 22:03:32 - GraphTrainer - INFO - ndcg@10: 0.027131
2025-11-22 22:03:32 - GraphTrainer - INFO - map@10: 0.019825
2025-11-22 22:03:32 - GraphTrainer - INFO - mrr@10: 0.020619
2025-11-22 22:03:32 - GraphTrainer - INFO - precision@20: 0.004181
2025-11-22 22:03:32 - GraphTrainer - INFO - recall@20: 0.079090
2025-11-22 22:03:32 - GraphTrainer - INFO - hit_rate@20: 0.083158
2025-11-22 22:03:32 - GraphTrainer - INFO - ndcg@20: 0.034451
2025-11-22 22:03:32 - GraphTrainer - INFO - map@20: 0.021783
2025-11-22 22:03:32 - GraphTrainer - INFO - mrr@20: 0.022679
2025-11-22 22:03:32 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:03:32 - GraphTrainer - INFO - ============================================================
2025-11-22 22:03:32 - GraphTrainer - INFO - 开始第 146/1000 轮训练
2025-11-22 22:03:32 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3190, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3479, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3196, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3554, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3213, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3276, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3274, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3313, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3455, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3554, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3284, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3331, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3142, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3200, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3222, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3207, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3125, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3112, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3127, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3484, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3704, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3533, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3376, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3290, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3671, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3316, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3125, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3598, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)
The 145 training average loss: 0.3352808777628274
2025-11-22 22:03:44 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:03:44 - GraphTrainer - INFO -   precision@5: 0.006614
2025-11-22 22:03:44 - GraphTrainer - INFO -   recall@5: 0.031609
2025-11-22 22:03:44 - GraphTrainer - INFO -   hit_rate@5: 0.033016
2025-11-22 22:03:44 - GraphTrainer - INFO -   ndcg@5: 0.020916
2025-11-22 22:03:44 - GraphTrainer - INFO -   map@5: 0.017178
2025-11-22 22:03:44 - GraphTrainer - INFO -   mrr@5: 0.017839
2025-11-22 22:03:44 - GraphTrainer - INFO -   precision@10: 0.005307
2025-11-22 22:03:44 - GraphTrainer - INFO -   recall@10: 0.050423
2025-11-22 22:03:44 - GraphTrainer - INFO -   hit_rate@10: 0.052918
2025-11-22 22:03:44 - GraphTrainer - INFO -   ndcg@10: 0.027032
2025-11-22 22:03:44 - GraphTrainer - INFO -   map@10: 0.019654
2025-11-22 22:03:44 - GraphTrainer - INFO -   mrr@10: 0.020452
2025-11-22 22:03:44 - GraphTrainer - INFO -   precision@20: 0.004158
2025-11-22 22:03:44 - GraphTrainer - INFO -   recall@20: 0.078687
2025-11-22 22:03:44 - GraphTrainer - INFO -   hit_rate@20: 0.082643
2025-11-22 22:03:44 - GraphTrainer - INFO -   ndcg@20: 0.034221
2025-11-22 22:03:44 - GraphTrainer - INFO -   map@20: 0.021580
2025-11-22 22:03:44 - GraphTrainer - INFO -   mrr@20: 0.022476
2025-11-22 22:03:44 - GraphTrainer - INFO - 第 146 轮训练完成
2025-11-22 22:03:44 - GraphTrainer - INFO - train_loss: 0.333985
2025-11-22 22:03:44 - GraphTrainer - INFO - precision@5: 0.006614
2025-11-22 22:03:44 - GraphTrainer - INFO - recall@5: 0.031609
2025-11-22 22:03:44 - GraphTrainer - INFO - hit_rate@5: 0.033016
2025-11-22 22:03:44 - GraphTrainer - INFO - ndcg@5: 0.020916
2025-11-22 22:03:44 - GraphTrainer - INFO - map@5: 0.017178
2025-11-22 22:03:44 - GraphTrainer - INFO - mrr@5: 0.017839
2025-11-22 22:03:44 - GraphTrainer - INFO - precision@10: 0.005307
2025-11-22 22:03:44 - GraphTrainer - INFO - recall@10: 0.050423
2025-11-22 22:03:44 - GraphTrainer - INFO - hit_rate@10: 0.052918
2025-11-22 22:03:44 - GraphTrainer - INFO - ndcg@10: 0.027032
2025-11-22 22:03:44 - GraphTrainer - INFO - map@10: 0.019654
2025-11-22 22:03:44 - GraphTrainer - INFO - mrr@10: 0.020452
2025-11-22 22:03:44 - GraphTrainer - INFO - precision@20: 0.004158
2025-11-22 22:03:44 - GraphTrainer - INFO - recall@20: 0.078687
2025-11-22 22:03:44 - GraphTrainer - INFO - hit_rate@20: 0.082643
2025-11-22 22:03:44 - GraphTrainer - INFO - ndcg@20: 0.034221
2025-11-22 22:03:44 - GraphTrainer - INFO - map@20: 0.021580
2025-11-22 22:03:44 - GraphTrainer - INFO - mrr@20: 0.022476
2025-11-22 22:03:44 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:03:44 - GraphTrainer - INFO - ============================================================
2025-11-22 22:03:44 - GraphTrainer - INFO - 开始第 147/1000 轮训练
2025-11-22 22:03:44 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3284, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3306, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3226, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3211, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3140, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3125, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3575, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3433, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3252, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3188, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3554, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3173, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3494, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3143, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3171, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3190, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3201, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3549, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3252, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3218, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3033, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3231, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3223, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3316, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
The 146 training average loss: 0.33398524697484644
2025-11-22 22:03:55 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:03:55 - GraphTrainer - INFO -   precision@5: 0.006716
2025-11-22 22:03:55 - GraphTrainer - INFO -   recall@5: 0.032005
2025-11-22 22:03:55 - GraphTrainer - INFO -   hit_rate@5: 0.033479
2025-11-22 22:03:55 - GraphTrainer - INFO -   ndcg@5: 0.021199
2025-11-22 22:03:55 - GraphTrainer - INFO -   map@5: 0.017422
2025-11-22 22:03:55 - GraphTrainer - INFO -   mrr@5: 0.018094
2025-11-22 22:03:55 - GraphTrainer - INFO -   precision@10: 0.005256
2025-11-22 22:03:55 - GraphTrainer - INFO -   recall@10: 0.050025
2025-11-22 22:03:55 - GraphTrainer - INFO -   hit_rate@10: 0.052404
2025-11-22 22:03:55 - GraphTrainer - INFO -   ndcg@10: 0.027035
2025-11-22 22:03:55 - GraphTrainer - INFO -   map@10: 0.019782
2025-11-22 22:03:55 - GraphTrainer - INFO -   mrr@10: 0.020573
2025-11-22 22:03:55 - GraphTrainer - INFO -   precision@20: 0.004153
2025-11-22 22:03:55 - GraphTrainer - INFO -   recall@20: 0.078704
2025-11-22 22:03:55 - GraphTrainer - INFO -   hit_rate@20: 0.082592
2025-11-22 22:03:55 - GraphTrainer - INFO -   ndcg@20: 0.034316
2025-11-22 22:03:55 - GraphTrainer - INFO -   map@20: 0.021726
2025-11-22 22:03:55 - GraphTrainer - INFO -   mrr@20: 0.022619
2025-11-22 22:03:55 - GraphTrainer - INFO - 第 147 轮训练完成
2025-11-22 22:03:55 - GraphTrainer - INFO - train_loss: 0.335766
2025-11-22 22:03:55 - GraphTrainer - INFO - precision@5: 0.006716
2025-11-22 22:03:55 - GraphTrainer - INFO - recall@5: 0.032005
2025-11-22 22:03:55 - GraphTrainer - INFO - hit_rate@5: 0.033479
2025-11-22 22:03:55 - GraphTrainer - INFO - ndcg@5: 0.021199
2025-11-22 22:03:55 - GraphTrainer - INFO - map@5: 0.017422
2025-11-22 22:03:55 - GraphTrainer - INFO - mrr@5: 0.018094
2025-11-22 22:03:55 - GraphTrainer - INFO - precision@10: 0.005256
2025-11-22 22:03:55 - GraphTrainer - INFO - recall@10: 0.050025
2025-11-22 22:03:55 - GraphTrainer - INFO - hit_rate@10: 0.052404
2025-11-22 22:03:55 - GraphTrainer - INFO - ndcg@10: 0.027035
2025-11-22 22:03:55 - GraphTrainer - INFO - map@10: 0.019782
2025-11-22 22:03:55 - GraphTrainer - INFO - mrr@10: 0.020573
2025-11-22 22:03:55 - GraphTrainer - INFO - precision@20: 0.004153
2025-11-22 22:03:55 - GraphTrainer - INFO - recall@20: 0.078704
2025-11-22 22:03:55 - GraphTrainer - INFO - hit_rate@20: 0.082592
2025-11-22 22:03:55 - GraphTrainer - INFO - ndcg@20: 0.034316
2025-11-22 22:03:55 - GraphTrainer - INFO - map@20: 0.021726
2025-11-22 22:03:55 - GraphTrainer - INFO - mrr@20: 0.022619
2025-11-22 22:03:55 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:03:55 - GraphTrainer - INFO - ============================================================
2025-11-22 22:03:55 - GraphTrainer - INFO - 开始第 148/1000 轮训练
2025-11-22 22:03:55 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3318, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3278, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3455, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3466, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3512, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3376, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3127, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3176, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3268, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3273, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3598, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3187, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3216, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3257, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3547, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3084, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3125, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3233, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3464, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3066, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3652, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3591, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3095, device='cuda:0', grad_fn=<AddBackward0>)
The 147 training average loss: 0.3357659537216713
2025-11-22 22:04:06 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:04:06 - GraphTrainer - INFO -   precision@5: 0.006696
2025-11-22 22:04:06 - GraphTrainer - INFO -   recall@5: 0.031940
2025-11-22 22:04:06 - GraphTrainer - INFO -   hit_rate@5: 0.033428
2025-11-22 22:04:06 - GraphTrainer - INFO -   ndcg@5: 0.021297
2025-11-22 22:04:06 - GraphTrainer - INFO -   map@5: 0.017569
2025-11-22 22:04:06 - GraphTrainer - INFO -   mrr@5: 0.018226
2025-11-22 22:04:06 - GraphTrainer - INFO -   precision@10: 0.005235
2025-11-22 22:04:06 - GraphTrainer - INFO -   recall@10: 0.049733
2025-11-22 22:04:06 - GraphTrainer - INFO -   hit_rate@10: 0.052199
2025-11-22 22:04:06 - GraphTrainer - INFO -   ndcg@10: 0.027073
2025-11-22 22:04:06 - GraphTrainer - INFO -   map@10: 0.019905
2025-11-22 22:04:06 - GraphTrainer - INFO -   mrr@10: 0.020685
2025-11-22 22:04:06 - GraphTrainer - INFO -   precision@20: 0.004173
2025-11-22 22:04:06 - GraphTrainer - INFO -   recall@20: 0.079051
2025-11-22 22:04:06 - GraphTrainer - INFO -   hit_rate@20: 0.083055
2025-11-22 22:04:06 - GraphTrainer - INFO -   ndcg@20: 0.034515
2025-11-22 22:04:06 - GraphTrainer - INFO -   map@20: 0.021893
2025-11-22 22:04:06 - GraphTrainer - INFO -   mrr@20: 0.022772
2025-11-22 22:04:06 - GraphTrainer - INFO - 第 148 轮训练完成
2025-11-22 22:04:06 - GraphTrainer - INFO - train_loss: 0.335385
2025-11-22 22:04:06 - GraphTrainer - INFO - precision@5: 0.006696
2025-11-22 22:04:06 - GraphTrainer - INFO - recall@5: 0.031940
2025-11-22 22:04:06 - GraphTrainer - INFO - hit_rate@5: 0.033428
2025-11-22 22:04:06 - GraphTrainer - INFO - ndcg@5: 0.021297
2025-11-22 22:04:06 - GraphTrainer - INFO - map@5: 0.017569
2025-11-22 22:04:06 - GraphTrainer - INFO - mrr@5: 0.018226
2025-11-22 22:04:06 - GraphTrainer - INFO - precision@10: 0.005235
2025-11-22 22:04:06 - GraphTrainer - INFO - recall@10: 0.049733
2025-11-22 22:04:06 - GraphTrainer - INFO - hit_rate@10: 0.052199
2025-11-22 22:04:06 - GraphTrainer - INFO - ndcg@10: 0.027073
2025-11-22 22:04:06 - GraphTrainer - INFO - map@10: 0.019905
2025-11-22 22:04:06 - GraphTrainer - INFO - mrr@10: 0.020685
2025-11-22 22:04:06 - GraphTrainer - INFO - precision@20: 0.004173
2025-11-22 22:04:06 - GraphTrainer - INFO - recall@20: 0.079051
2025-11-22 22:04:06 - GraphTrainer - INFO - hit_rate@20: 0.083055
2025-11-22 22:04:06 - GraphTrainer - INFO - ndcg@20: 0.034515
2025-11-22 22:04:06 - GraphTrainer - INFO - map@20: 0.021893
2025-11-22 22:04:06 - GraphTrainer - INFO - mrr@20: 0.022772
2025-11-22 22:04:06 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:04:06 - GraphTrainer - INFO - ============================================================
2025-11-22 22:04:06 - GraphTrainer - INFO - 开始第 149/1000 轮训练
2025-11-22 22:04:06 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3135, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3160, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3262, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3056, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3379, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3569, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3562, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3455, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3556, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3187, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3219, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3299, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3169, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3302, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3187, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3237, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3256, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3549, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3561, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3313, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3539, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3211, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3480, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3069, device='cuda:0', grad_fn=<AddBackward0>)
The 148 training average loss: 0.33538545565358524
2025-11-22 22:04:17 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:04:17 - GraphTrainer - INFO -   precision@5: 0.006706
2025-11-22 22:04:17 - GraphTrainer - INFO -   recall@5: 0.032103
2025-11-22 22:04:17 - GraphTrainer - INFO -   hit_rate@5: 0.033479
2025-11-22 22:04:17 - GraphTrainer - INFO -   ndcg@5: 0.021583
2025-11-22 22:04:17 - GraphTrainer - INFO -   map@5: 0.017909
2025-11-22 22:04:17 - GraphTrainer - INFO -   mrr@5: 0.018549
2025-11-22 22:04:17 - GraphTrainer - INFO -   precision@10: 0.005251
2025-11-22 22:04:17 - GraphTrainer - INFO -   recall@10: 0.050008
2025-11-22 22:04:17 - GraphTrainer - INFO -   hit_rate@10: 0.052301
2025-11-22 22:04:17 - GraphTrainer - INFO -   ndcg@10: 0.027393
2025-11-22 22:04:17 - GraphTrainer - INFO -   map@10: 0.020262
2025-11-22 22:04:17 - GraphTrainer - INFO -   mrr@10: 0.021019
2025-11-22 22:04:17 - GraphTrainer - INFO -   precision@20: 0.004145
2025-11-22 22:04:17 - GraphTrainer - INFO -   recall@20: 0.078537
2025-11-22 22:04:17 - GraphTrainer - INFO -   hit_rate@20: 0.082489
2025-11-22 22:04:17 - GraphTrainer - INFO -   ndcg@20: 0.034644
2025-11-22 22:04:17 - GraphTrainer - INFO -   map@20: 0.022196
2025-11-22 22:04:17 - GraphTrainer - INFO -   mrr@20: 0.023069
2025-11-22 22:04:17 - GraphTrainer - INFO - 第 149 轮训练完成
2025-11-22 22:04:17 - GraphTrainer - INFO - train_loss: 0.333873
2025-11-22 22:04:17 - GraphTrainer - INFO - precision@5: 0.006706
2025-11-22 22:04:17 - GraphTrainer - INFO - recall@5: 0.032103
2025-11-22 22:04:17 - GraphTrainer - INFO - hit_rate@5: 0.033479
2025-11-22 22:04:17 - GraphTrainer - INFO - ndcg@5: 0.021583
2025-11-22 22:04:17 - GraphTrainer - INFO - map@5: 0.017909
2025-11-22 22:04:17 - GraphTrainer - INFO - mrr@5: 0.018549
2025-11-22 22:04:17 - GraphTrainer - INFO - precision@10: 0.005251
2025-11-22 22:04:17 - GraphTrainer - INFO - recall@10: 0.050008
2025-11-22 22:04:17 - GraphTrainer - INFO - hit_rate@10: 0.052301
2025-11-22 22:04:17 - GraphTrainer - INFO - ndcg@10: 0.027393
2025-11-22 22:04:17 - GraphTrainer - INFO - map@10: 0.020262
2025-11-22 22:04:17 - GraphTrainer - INFO - mrr@10: 0.021019
2025-11-22 22:04:17 - GraphTrainer - INFO - precision@20: 0.004145
2025-11-22 22:04:17 - GraphTrainer - INFO - recall@20: 0.078537
2025-11-22 22:04:17 - GraphTrainer - INFO - hit_rate@20: 0.082489
2025-11-22 22:04:17 - GraphTrainer - INFO - ndcg@20: 0.034644
2025-11-22 22:04:17 - GraphTrainer - INFO - map@20: 0.022196
2025-11-22 22:04:17 - GraphTrainer - INFO - mrr@20: 0.023069
2025-11-22 22:04:17 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:04:17 - GraphTrainer - INFO - ============================================================
2025-11-22 22:04:17 - GraphTrainer - INFO - 开始第 150/1000 轮训练
2025-11-22 22:04:17 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3103, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3176, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3226, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3194, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3455, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3256, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3167, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3342, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3258, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3303, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3257, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3517, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3181, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3464, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3173, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3050, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3233, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3258, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3502, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3180, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3236, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3525, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3210, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3462, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3510, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3140, device='cuda:0', grad_fn=<AddBackward0>)
The 149 training average loss: 0.3338727478323312
2025-11-22 22:04:29 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:04:29 - GraphTrainer - INFO -   precision@5: 0.006830
2025-11-22 22:04:29 - GraphTrainer - INFO -   recall@5: 0.032635
2025-11-22 22:04:29 - GraphTrainer - INFO -   hit_rate@5: 0.034096
2025-11-22 22:04:29 - GraphTrainer - INFO -   ndcg@5: 0.021637
2025-11-22 22:04:29 - GraphTrainer - INFO -   map@5: 0.017806
2025-11-22 22:04:29 - GraphTrainer - INFO -   mrr@5: 0.018467
2025-11-22 22:04:29 - GraphTrainer - INFO -   precision@10: 0.005179
2025-11-22 22:04:29 - GraphTrainer - INFO -   recall@10: 0.049202
2025-11-22 22:04:29 - GraphTrainer - INFO -   hit_rate@10: 0.051581
2025-11-22 22:04:29 - GraphTrainer - INFO -   ndcg@10: 0.027024
2025-11-22 22:04:29 - GraphTrainer - INFO -   map@10: 0.019989
2025-11-22 22:04:29 - GraphTrainer - INFO -   mrr@10: 0.020765
2025-11-22 22:04:29 - GraphTrainer - INFO -   precision@20: 0.004153
2025-11-22 22:04:29 - GraphTrainer - INFO -   recall@20: 0.078661
2025-11-22 22:04:29 - GraphTrainer - INFO -   hit_rate@20: 0.082592
2025-11-22 22:04:29 - GraphTrainer - INFO -   ndcg@20: 0.034502
2025-11-22 22:04:29 - GraphTrainer - INFO -   map@20: 0.021986
2025-11-22 22:04:29 - GraphTrainer - INFO -   mrr@20: 0.022868
2025-11-22 22:04:29 - GraphTrainer - INFO - 第 150 轮训练完成
2025-11-22 22:04:29 - GraphTrainer - INFO - train_loss: 0.334973
2025-11-22 22:04:29 - GraphTrainer - INFO - precision@5: 0.006830
2025-11-22 22:04:29 - GraphTrainer - INFO - recall@5: 0.032635
2025-11-22 22:04:29 - GraphTrainer - INFO - hit_rate@5: 0.034096
2025-11-22 22:04:29 - GraphTrainer - INFO - ndcg@5: 0.021637
2025-11-22 22:04:29 - GraphTrainer - INFO - map@5: 0.017806
2025-11-22 22:04:29 - GraphTrainer - INFO - mrr@5: 0.018467
2025-11-22 22:04:29 - GraphTrainer - INFO - precision@10: 0.005179
2025-11-22 22:04:29 - GraphTrainer - INFO - recall@10: 0.049202
2025-11-22 22:04:29 - GraphTrainer - INFO - hit_rate@10: 0.051581
2025-11-22 22:04:29 - GraphTrainer - INFO - ndcg@10: 0.027024
2025-11-22 22:04:29 - GraphTrainer - INFO - map@10: 0.019989
2025-11-22 22:04:29 - GraphTrainer - INFO - mrr@10: 0.020765
2025-11-22 22:04:29 - GraphTrainer - INFO - precision@20: 0.004153
2025-11-22 22:04:29 - GraphTrainer - INFO - recall@20: 0.078661
2025-11-22 22:04:29 - GraphTrainer - INFO - hit_rate@20: 0.082592
2025-11-22 22:04:29 - GraphTrainer - INFO - ndcg@20: 0.034502
2025-11-22 22:04:29 - GraphTrainer - INFO - map@20: 0.021986
2025-11-22 22:04:29 - GraphTrainer - INFO - mrr@20: 0.022868
2025-11-22 22:04:29 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:04:29 - GraphTrainer - INFO - 检查点已保存: Epoch 150 -> ./checkpoints/checkpoint_epoch_150.pth
2025-11-22 22:04:29 - GraphTrainer - INFO - ============================================================
2025-11-22 22:04:29 - GraphTrainer - INFO - 开始第 151/1000 轮训练
2025-11-22 22:04:29 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3073, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3464, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3662, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3293, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3169, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3189, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3137, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3521, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3509, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3622, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3636, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3318, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3198, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3379, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3168, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3333, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3285, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3153, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3259, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3189, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3039, device='cuda:0', grad_fn=<AddBackward0>)
The 150 training average loss: 0.3349734529339034
2025-11-22 22:04:40 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:04:40 - GraphTrainer - INFO -   precision@5: 0.006768
2025-11-22 22:04:40 - GraphTrainer - INFO -   recall@5: 0.032339
2025-11-22 22:04:40 - GraphTrainer - INFO -   hit_rate@5: 0.033736
2025-11-22 22:04:40 - GraphTrainer - INFO -   ndcg@5: 0.021420
2025-11-22 22:04:40 - GraphTrainer - INFO -   map@5: 0.017614
2025-11-22 22:04:40 - GraphTrainer - INFO -   mrr@5: 0.018261
2025-11-22 22:04:40 - GraphTrainer - INFO -   precision@10: 0.005189
2025-11-22 22:04:40 - GraphTrainer - INFO -   recall@10: 0.049248
2025-11-22 22:04:40 - GraphTrainer - INFO -   hit_rate@10: 0.051684
2025-11-22 22:04:40 - GraphTrainer - INFO -   ndcg@10: 0.026955
2025-11-22 22:04:40 - GraphTrainer - INFO -   map@10: 0.019871
2025-11-22 22:04:40 - GraphTrainer - INFO -   mrr@10: 0.020658
2025-11-22 22:04:40 - GraphTrainer - INFO -   precision@20: 0.004114
2025-11-22 22:04:40 - GraphTrainer - INFO -   recall@20: 0.077950
2025-11-22 22:04:40 - GraphTrainer - INFO -   hit_rate@20: 0.081872
2025-11-22 22:04:40 - GraphTrainer - INFO -   ndcg@20: 0.034243
2025-11-22 22:04:40 - GraphTrainer - INFO -   map@20: 0.021821
2025-11-22 22:04:40 - GraphTrainer - INFO -   mrr@20: 0.022711
2025-11-22 22:04:40 - GraphTrainer - INFO - 第 151 轮训练完成
2025-11-22 22:04:40 - GraphTrainer - INFO - train_loss: 0.332134
2025-11-22 22:04:40 - GraphTrainer - INFO - precision@5: 0.006768
2025-11-22 22:04:40 - GraphTrainer - INFO - recall@5: 0.032339
2025-11-22 22:04:40 - GraphTrainer - INFO - hit_rate@5: 0.033736
2025-11-22 22:04:40 - GraphTrainer - INFO - ndcg@5: 0.021420
2025-11-22 22:04:40 - GraphTrainer - INFO - map@5: 0.017614
2025-11-22 22:04:40 - GraphTrainer - INFO - mrr@5: 0.018261
2025-11-22 22:04:40 - GraphTrainer - INFO - precision@10: 0.005189
2025-11-22 22:04:40 - GraphTrainer - INFO - recall@10: 0.049248
2025-11-22 22:04:40 - GraphTrainer - INFO - hit_rate@10: 0.051684
2025-11-22 22:04:40 - GraphTrainer - INFO - ndcg@10: 0.026955
2025-11-22 22:04:40 - GraphTrainer - INFO - map@10: 0.019871
2025-11-22 22:04:40 - GraphTrainer - INFO - mrr@10: 0.020658
2025-11-22 22:04:40 - GraphTrainer - INFO - precision@20: 0.004114
2025-11-22 22:04:40 - GraphTrainer - INFO - recall@20: 0.077950
2025-11-22 22:04:40 - GraphTrainer - INFO - hit_rate@20: 0.081872
2025-11-22 22:04:40 - GraphTrainer - INFO - ndcg@20: 0.034243
2025-11-22 22:04:40 - GraphTrainer - INFO - map@20: 0.021821
2025-11-22 22:04:40 - GraphTrainer - INFO - mrr@20: 0.022711
2025-11-22 22:04:40 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:04:40 - GraphTrainer - INFO - ============================================================
2025-11-22 22:04:40 - GraphTrainer - INFO - 开始第 152/1000 轮训练
2025-11-22 22:04:40 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3268, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3281, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3285, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3230, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3246, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3093, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3148, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3038, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3189, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3163, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3480, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3214, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3259, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3272, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3144, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3186, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3172, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3202, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3222, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3135, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3681, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3379, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3099, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3318, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3288, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3142, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3306, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)
The 151 training average loss: 0.33213424528467245
2025-11-22 22:04:51 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:04:51 - GraphTrainer - INFO -   precision@5: 0.006788
2025-11-22 22:04:51 - GraphTrainer - INFO -   recall@5: 0.032412
2025-11-22 22:04:51 - GraphTrainer - INFO -   hit_rate@5: 0.033839
2025-11-22 22:04:51 - GraphTrainer - INFO -   ndcg@5: 0.021247
2025-11-22 22:04:51 - GraphTrainer - INFO -   map@5: 0.017352
2025-11-22 22:04:51 - GraphTrainer - INFO -   mrr@5: 0.018025
2025-11-22 22:04:51 - GraphTrainer - INFO -   precision@10: 0.005204
2025-11-22 22:04:51 - GraphTrainer - INFO -   recall@10: 0.049287
2025-11-22 22:04:51 - GraphTrainer - INFO -   hit_rate@10: 0.051839
2025-11-22 22:04:51 - GraphTrainer - INFO -   ndcg@10: 0.026740
2025-11-22 22:04:51 - GraphTrainer - INFO -   map@10: 0.019570
2025-11-22 22:04:51 - GraphTrainer - INFO -   mrr@10: 0.020388
2025-11-22 22:04:51 - GraphTrainer - INFO -   precision@20: 0.004142
2025-11-22 22:04:51 - GraphTrainer - INFO -   recall@20: 0.078487
2025-11-22 22:04:51 - GraphTrainer - INFO -   hit_rate@20: 0.082386
2025-11-22 22:04:51 - GraphTrainer - INFO -   ndcg@20: 0.034141
2025-11-22 22:04:51 - GraphTrainer - INFO -   map@20: 0.021549
2025-11-22 22:04:51 - GraphTrainer - INFO -   mrr@20: 0.022455
2025-11-22 22:04:51 - GraphTrainer - INFO - 第 152 轮训练完成
2025-11-22 22:04:51 - GraphTrainer - INFO - train_loss: 0.334724
2025-11-22 22:04:51 - GraphTrainer - INFO - precision@5: 0.006788
2025-11-22 22:04:51 - GraphTrainer - INFO - recall@5: 0.032412
2025-11-22 22:04:51 - GraphTrainer - INFO - hit_rate@5: 0.033839
2025-11-22 22:04:51 - GraphTrainer - INFO - ndcg@5: 0.021247
2025-11-22 22:04:51 - GraphTrainer - INFO - map@5: 0.017352
2025-11-22 22:04:51 - GraphTrainer - INFO - mrr@5: 0.018025
2025-11-22 22:04:51 - GraphTrainer - INFO - precision@10: 0.005204
2025-11-22 22:04:51 - GraphTrainer - INFO - recall@10: 0.049287
2025-11-22 22:04:51 - GraphTrainer - INFO - hit_rate@10: 0.051839
2025-11-22 22:04:51 - GraphTrainer - INFO - ndcg@10: 0.026740
2025-11-22 22:04:51 - GraphTrainer - INFO - map@10: 0.019570
2025-11-22 22:04:51 - GraphTrainer - INFO - mrr@10: 0.020388
2025-11-22 22:04:51 - GraphTrainer - INFO - precision@20: 0.004142
2025-11-22 22:04:51 - GraphTrainer - INFO - recall@20: 0.078487
2025-11-22 22:04:51 - GraphTrainer - INFO - hit_rate@20: 0.082386
2025-11-22 22:04:51 - GraphTrainer - INFO - ndcg@20: 0.034141
2025-11-22 22:04:51 - GraphTrainer - INFO - map@20: 0.021549
2025-11-22 22:04:51 - GraphTrainer - INFO - mrr@20: 0.022455
2025-11-22 22:04:51 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:04:51 - GraphTrainer - INFO - ============================================================
2025-11-22 22:04:51 - GraphTrainer - INFO - 开始第 153/1000 轮训练
2025-11-22 22:04:51 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3278, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3490, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3490, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3306, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3316, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3154, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3150, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3169, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3174, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3231, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3327, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3145, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3299, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3260, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3124, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3648, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3037, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3490, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3202, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3241, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3140, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3091, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3555, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3327, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3281, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
The 152 training average loss: 0.3347238065867588
2025-11-22 22:05:02 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:05:02 - GraphTrainer - INFO -   precision@5: 0.006809
2025-11-22 22:05:02 - GraphTrainer - INFO -   recall@5: 0.032515
2025-11-22 22:05:02 - GraphTrainer - INFO -   hit_rate@5: 0.033942
2025-11-22 22:05:02 - GraphTrainer - INFO -   ndcg@5: 0.021372
2025-11-22 22:05:02 - GraphTrainer - INFO -   map@5: 0.017488
2025-11-22 22:05:02 - GraphTrainer - INFO -   mrr@5: 0.018144
2025-11-22 22:05:02 - GraphTrainer - INFO -   precision@10: 0.005189
2025-11-22 22:05:02 - GraphTrainer - INFO -   recall@10: 0.049392
2025-11-22 22:05:02 - GraphTrainer - INFO -   hit_rate@10: 0.051736
2025-11-22 22:05:02 - GraphTrainer - INFO -   ndcg@10: 0.026832
2025-11-22 22:05:02 - GraphTrainer - INFO -   map@10: 0.019687
2025-11-22 22:05:02 - GraphTrainer - INFO -   mrr@10: 0.020463
2025-11-22 22:05:02 - GraphTrainer - INFO -   precision@20: 0.004202
2025-11-22 22:05:02 - GraphTrainer - INFO -   recall@20: 0.079612
2025-11-22 22:05:02 - GraphTrainer - INFO -   hit_rate@20: 0.083620
2025-11-22 22:05:02 - GraphTrainer - INFO -   ndcg@20: 0.034497
2025-11-22 22:05:02 - GraphTrainer - INFO -   map@20: 0.021728
2025-11-22 22:05:02 - GraphTrainer - INFO -   mrr@20: 0.022618
2025-11-22 22:05:02 - GraphTrainer - INFO - 第 153 轮训练完成
2025-11-22 22:05:02 - GraphTrainer - INFO - train_loss: 0.333685
2025-11-22 22:05:02 - GraphTrainer - INFO - precision@5: 0.006809
2025-11-22 22:05:02 - GraphTrainer - INFO - recall@5: 0.032515
2025-11-22 22:05:02 - GraphTrainer - INFO - hit_rate@5: 0.033942
2025-11-22 22:05:02 - GraphTrainer - INFO - ndcg@5: 0.021372
2025-11-22 22:05:02 - GraphTrainer - INFO - map@5: 0.017488
2025-11-22 22:05:02 - GraphTrainer - INFO - mrr@5: 0.018144
2025-11-22 22:05:02 - GraphTrainer - INFO - precision@10: 0.005189
2025-11-22 22:05:02 - GraphTrainer - INFO - recall@10: 0.049392
2025-11-22 22:05:02 - GraphTrainer - INFO - hit_rate@10: 0.051736
2025-11-22 22:05:02 - GraphTrainer - INFO - ndcg@10: 0.026832
2025-11-22 22:05:02 - GraphTrainer - INFO - map@10: 0.019687
2025-11-22 22:05:02 - GraphTrainer - INFO - mrr@10: 0.020463
2025-11-22 22:05:02 - GraphTrainer - INFO - precision@20: 0.004202
2025-11-22 22:05:02 - GraphTrainer - INFO - recall@20: 0.079612
2025-11-22 22:05:02 - GraphTrainer - INFO - hit_rate@20: 0.083620
2025-11-22 22:05:02 - GraphTrainer - INFO - ndcg@20: 0.034497
2025-11-22 22:05:02 - GraphTrainer - INFO - map@20: 0.021728
2025-11-22 22:05:02 - GraphTrainer - INFO - mrr@20: 0.022618
2025-11-22 22:05:02 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:05:02 - GraphTrainer - INFO - ============================================================
2025-11-22 22:05:02 - GraphTrainer - INFO - 开始第 154/1000 轮训练
2025-11-22 22:05:02 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3545, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3179, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3256, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3624, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3312, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3473, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3144, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3146, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3099, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3082, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3241, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3373, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3139, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3302, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3257, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3211, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3210, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3252, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3150, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3433, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
The 153 training average loss: 0.3336848847824952
2025-11-22 22:05:13 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:05:13 - GraphTrainer - INFO -   precision@5: 0.006830
2025-11-22 22:05:13 - GraphTrainer - INFO -   recall@5: 0.032579
2025-11-22 22:05:13 - GraphTrainer - INFO -   hit_rate@5: 0.034096
2025-11-22 22:05:13 - GraphTrainer - INFO -   ndcg@5: 0.021423
2025-11-22 22:05:13 - GraphTrainer - INFO -   map@5: 0.017522
2025-11-22 22:05:13 - GraphTrainer - INFO -   mrr@5: 0.018203
2025-11-22 22:05:13 - GraphTrainer - INFO -   precision@10: 0.005230
2025-11-22 22:05:13 - GraphTrainer - INFO -   recall@10: 0.049778
2025-11-22 22:05:13 - GraphTrainer - INFO -   hit_rate@10: 0.052147
2025-11-22 22:05:13 - GraphTrainer - INFO -   ndcg@10: 0.026953
2025-11-22 22:05:13 - GraphTrainer - INFO -   map@10: 0.019735
2025-11-22 22:05:13 - GraphTrainer - INFO -   mrr@10: 0.020522
2025-11-22 22:05:13 - GraphTrainer - INFO -   precision@20: 0.004168
2025-11-22 22:05:13 - GraphTrainer - INFO -   recall@20: 0.079125
2025-11-22 22:05:13 - GraphTrainer - INFO -   hit_rate@20: 0.082952
2025-11-22 22:05:13 - GraphTrainer - INFO -   ndcg@20: 0.034413
2025-11-22 22:05:13 - GraphTrainer - INFO -   map@20: 0.021736
2025-11-22 22:05:13 - GraphTrainer - INFO -   mrr@20: 0.022622
2025-11-22 22:05:13 - GraphTrainer - INFO - 第 154 轮训练完成
2025-11-22 22:05:13 - GraphTrainer - INFO - train_loss: 0.331469
2025-11-22 22:05:13 - GraphTrainer - INFO - precision@5: 0.006830
2025-11-22 22:05:13 - GraphTrainer - INFO - recall@5: 0.032579
2025-11-22 22:05:13 - GraphTrainer - INFO - hit_rate@5: 0.034096
2025-11-22 22:05:13 - GraphTrainer - INFO - ndcg@5: 0.021423
2025-11-22 22:05:13 - GraphTrainer - INFO - map@5: 0.017522
2025-11-22 22:05:13 - GraphTrainer - INFO - mrr@5: 0.018203
2025-11-22 22:05:13 - GraphTrainer - INFO - precision@10: 0.005230
2025-11-22 22:05:13 - GraphTrainer - INFO - recall@10: 0.049778
2025-11-22 22:05:13 - GraphTrainer - INFO - hit_rate@10: 0.052147
2025-11-22 22:05:13 - GraphTrainer - INFO - ndcg@10: 0.026953
2025-11-22 22:05:13 - GraphTrainer - INFO - map@10: 0.019735
2025-11-22 22:05:13 - GraphTrainer - INFO - mrr@10: 0.020522
2025-11-22 22:05:13 - GraphTrainer - INFO - precision@20: 0.004168
2025-11-22 22:05:13 - GraphTrainer - INFO - recall@20: 0.079125
2025-11-22 22:05:13 - GraphTrainer - INFO - hit_rate@20: 0.082952
2025-11-22 22:05:13 - GraphTrainer - INFO - ndcg@20: 0.034413
2025-11-22 22:05:13 - GraphTrainer - INFO - map@20: 0.021736
2025-11-22 22:05:13 - GraphTrainer - INFO - mrr@20: 0.022622
2025-11-22 22:05:13 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:05:13 - GraphTrainer - INFO - ============================================================
2025-11-22 22:05:13 - GraphTrainer - INFO - 开始第 155/1000 轮训练
2025-11-22 22:05:13 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3159, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3331, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3189, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3281, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3281, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3042, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3183, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3536, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3457, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3162, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3536, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3164, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3466, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3331, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3223, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3276, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3211, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3260, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3093, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3155, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3316, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3227, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3228, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3103, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3217, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3213, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3171, device='cuda:0', grad_fn=<AddBackward0>)
The 154 training average loss: 0.33146858266715346
2025-11-22 22:05:24 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:05:24 - GraphTrainer - INFO -   precision@5: 0.006727
2025-11-22 22:05:24 - GraphTrainer - INFO -   recall@5: 0.032176
2025-11-22 22:05:24 - GraphTrainer - INFO -   hit_rate@5: 0.033582
2025-11-22 22:05:24 - GraphTrainer - INFO -   ndcg@5: 0.021170
2025-11-22 22:05:24 - GraphTrainer - INFO -   map@5: 0.017341
2025-11-22 22:05:24 - GraphTrainer - INFO -   mrr@5: 0.017981
2025-11-22 22:05:24 - GraphTrainer - INFO -   precision@10: 0.005225
2025-11-22 22:05:24 - GraphTrainer - INFO -   recall@10: 0.049739
2025-11-22 22:05:24 - GraphTrainer - INFO -   hit_rate@10: 0.052096
2025-11-22 22:05:24 - GraphTrainer - INFO -   ndcg@10: 0.026883
2025-11-22 22:05:24 - GraphTrainer - INFO -   map@10: 0.019661
2025-11-22 22:05:24 - GraphTrainer - INFO -   mrr@10: 0.020423
2025-11-22 22:05:24 - GraphTrainer - INFO -   precision@20: 0.004173
2025-11-22 22:05:24 - GraphTrainer - INFO -   recall@20: 0.079164
2025-11-22 22:05:24 - GraphTrainer - INFO -   hit_rate@20: 0.083055
2025-11-22 22:05:24 - GraphTrainer - INFO -   ndcg@20: 0.034350
2025-11-22 22:05:24 - GraphTrainer - INFO -   map@20: 0.021654
2025-11-22 22:05:24 - GraphTrainer - INFO -   mrr@20: 0.022521
2025-11-22 22:05:24 - GraphTrainer - INFO - 第 155 轮训练完成
2025-11-22 22:05:24 - GraphTrainer - INFO - train_loss: 0.334884
2025-11-22 22:05:24 - GraphTrainer - INFO - precision@5: 0.006727
2025-11-22 22:05:24 - GraphTrainer - INFO - recall@5: 0.032176
2025-11-22 22:05:24 - GraphTrainer - INFO - hit_rate@5: 0.033582
2025-11-22 22:05:24 - GraphTrainer - INFO - ndcg@5: 0.021170
2025-11-22 22:05:24 - GraphTrainer - INFO - map@5: 0.017341
2025-11-22 22:05:24 - GraphTrainer - INFO - mrr@5: 0.017981
2025-11-22 22:05:24 - GraphTrainer - INFO - precision@10: 0.005225
2025-11-22 22:05:24 - GraphTrainer - INFO - recall@10: 0.049739
2025-11-22 22:05:24 - GraphTrainer - INFO - hit_rate@10: 0.052096
2025-11-22 22:05:24 - GraphTrainer - INFO - ndcg@10: 0.026883
2025-11-22 22:05:24 - GraphTrainer - INFO - map@10: 0.019661
2025-11-22 22:05:24 - GraphTrainer - INFO - mrr@10: 0.020423
2025-11-22 22:05:24 - GraphTrainer - INFO - precision@20: 0.004173
2025-11-22 22:05:24 - GraphTrainer - INFO - recall@20: 0.079164
2025-11-22 22:05:24 - GraphTrainer - INFO - hit_rate@20: 0.083055
2025-11-22 22:05:24 - GraphTrainer - INFO - ndcg@20: 0.034350
2025-11-22 22:05:24 - GraphTrainer - INFO - map@20: 0.021654
2025-11-22 22:05:24 - GraphTrainer - INFO - mrr@20: 0.022521
2025-11-22 22:05:24 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:05:24 - GraphTrainer - INFO - ============================================================
2025-11-22 22:05:24 - GraphTrainer - INFO - 开始第 156/1000 轮训练
2025-11-22 22:05:24 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3517, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3186, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3161, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3213, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3128, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2967, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3473, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3143, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3260, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3679, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3236, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3241, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3151, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3185, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3512, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3614, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3214, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3171, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3220, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3081, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3537, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3507, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3709, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3235, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3532, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3643, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3126, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3313, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3198, device='cuda:0', grad_fn=<AddBackward0>)
The 155 training average loss: 0.33488367189621104
2025-11-22 22:05:35 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:05:35 - GraphTrainer - INFO -   precision@5: 0.006747
2025-11-22 22:05:35 - GraphTrainer - INFO -   recall@5: 0.032219
2025-11-22 22:05:35 - GraphTrainer - INFO -   hit_rate@5: 0.033685
2025-11-22 22:05:35 - GraphTrainer - INFO -   ndcg@5: 0.021243
2025-11-22 22:05:35 - GraphTrainer - INFO -   map@5: 0.017414
2025-11-22 22:05:35 - GraphTrainer - INFO -   mrr@5: 0.018101
2025-11-22 22:05:35 - GraphTrainer - INFO -   precision@10: 0.005240
2025-11-22 22:05:35 - GraphTrainer - INFO -   recall@10: 0.049967
2025-11-22 22:05:35 - GraphTrainer - INFO -   hit_rate@10: 0.052301
2025-11-22 22:05:35 - GraphTrainer - INFO -   ndcg@10: 0.026971
2025-11-22 22:05:35 - GraphTrainer - INFO -   map@10: 0.019718
2025-11-22 22:05:35 - GraphTrainer - INFO -   mrr@10: 0.020517
2025-11-22 22:05:35 - GraphTrainer - INFO -   precision@20: 0.004160
2025-11-22 22:05:35 - GraphTrainer - INFO -   recall@20: 0.078962
2025-11-22 22:05:35 - GraphTrainer - INFO -   hit_rate@20: 0.082798
2025-11-22 22:05:35 - GraphTrainer - INFO -   ndcg@20: 0.034327
2025-11-22 22:05:35 - GraphTrainer - INFO -   map@20: 0.021682
2025-11-22 22:05:35 - GraphTrainer - INFO -   mrr@20: 0.022585
2025-11-22 22:05:35 - GraphTrainer - INFO - 第 156 轮训练完成
2025-11-22 22:05:35 - GraphTrainer - INFO - train_loss: 0.333760
2025-11-22 22:05:35 - GraphTrainer - INFO - precision@5: 0.006747
2025-11-22 22:05:35 - GraphTrainer - INFO - recall@5: 0.032219
2025-11-22 22:05:35 - GraphTrainer - INFO - hit_rate@5: 0.033685
2025-11-22 22:05:35 - GraphTrainer - INFO - ndcg@5: 0.021243
2025-11-22 22:05:35 - GraphTrainer - INFO - map@5: 0.017414
2025-11-22 22:05:35 - GraphTrainer - INFO - mrr@5: 0.018101
2025-11-22 22:05:35 - GraphTrainer - INFO - precision@10: 0.005240
2025-11-22 22:05:35 - GraphTrainer - INFO - recall@10: 0.049967
2025-11-22 22:05:35 - GraphTrainer - INFO - hit_rate@10: 0.052301
2025-11-22 22:05:35 - GraphTrainer - INFO - ndcg@10: 0.026971
2025-11-22 22:05:35 - GraphTrainer - INFO - map@10: 0.019718
2025-11-22 22:05:35 - GraphTrainer - INFO - mrr@10: 0.020517
2025-11-22 22:05:35 - GraphTrainer - INFO - precision@20: 0.004160
2025-11-22 22:05:35 - GraphTrainer - INFO - recall@20: 0.078962
2025-11-22 22:05:35 - GraphTrainer - INFO - hit_rate@20: 0.082798
2025-11-22 22:05:35 - GraphTrainer - INFO - ndcg@20: 0.034327
2025-11-22 22:05:35 - GraphTrainer - INFO - map@20: 0.021682
2025-11-22 22:05:35 - GraphTrainer - INFO - mrr@20: 0.022585
2025-11-22 22:05:35 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:05:35 - GraphTrainer - INFO - ============================================================
2025-11-22 22:05:35 - GraphTrainer - INFO - 开始第 157/1000 轮训练
2025-11-22 22:05:35 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3373, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3146, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3218, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3576, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3220, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3163, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3282, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3252, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3121, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3625, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3303, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3409, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3190, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3174, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3269, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3234, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3211, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3604, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3210, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3534, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3246, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3131, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3157, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3318, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3145, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3149, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3158, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3178, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3636, device='cuda:0', grad_fn=<AddBackward0>)
The 156 training average loss: 0.33375975284083137
2025-11-22 22:05:46 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:05:46 - GraphTrainer - INFO -   precision@5: 0.006840
2025-11-22 22:05:46 - GraphTrainer - INFO -   recall@5: 0.032660
2025-11-22 22:05:46 - GraphTrainer - INFO -   hit_rate@5: 0.034148
2025-11-22 22:05:46 - GraphTrainer - INFO -   ndcg@5: 0.021321
2025-11-22 22:05:46 - GraphTrainer - INFO -   map@5: 0.017373
2025-11-22 22:05:46 - GraphTrainer - INFO -   mrr@5: 0.018091
2025-11-22 22:05:46 - GraphTrainer - INFO -   precision@10: 0.005174
2025-11-22 22:05:46 - GraphTrainer - INFO -   recall@10: 0.049229
2025-11-22 22:05:46 - GraphTrainer - INFO -   hit_rate@10: 0.051633
2025-11-22 22:05:46 - GraphTrainer - INFO -   ndcg@10: 0.026683
2025-11-22 22:05:46 - GraphTrainer - INFO -   map@10: 0.019532
2025-11-22 22:05:46 - GraphTrainer - INFO -   mrr@10: 0.020368
2025-11-22 22:05:46 - GraphTrainer - INFO -   precision@20: 0.004186
2025-11-22 22:05:46 - GraphTrainer - INFO -   recall@20: 0.079395
2025-11-22 22:05:46 - GraphTrainer - INFO -   hit_rate@20: 0.083312
2025-11-22 22:05:46 - GraphTrainer - INFO -   ndcg@20: 0.034342
2025-11-22 22:05:46 - GraphTrainer - INFO -   map@20: 0.021582
2025-11-22 22:05:46 - GraphTrainer - INFO -   mrr@20: 0.022519
2025-11-22 22:05:46 - GraphTrainer - INFO - 第 157 轮训练完成
2025-11-22 22:05:46 - GraphTrainer - INFO - train_loss: 0.333106
2025-11-22 22:05:46 - GraphTrainer - INFO - precision@5: 0.006840
2025-11-22 22:05:46 - GraphTrainer - INFO - recall@5: 0.032660
2025-11-22 22:05:46 - GraphTrainer - INFO - hit_rate@5: 0.034148
2025-11-22 22:05:46 - GraphTrainer - INFO - ndcg@5: 0.021321
2025-11-22 22:05:46 - GraphTrainer - INFO - map@5: 0.017373
2025-11-22 22:05:46 - GraphTrainer - INFO - mrr@5: 0.018091
2025-11-22 22:05:46 - GraphTrainer - INFO - precision@10: 0.005174
2025-11-22 22:05:46 - GraphTrainer - INFO - recall@10: 0.049229
2025-11-22 22:05:46 - GraphTrainer - INFO - hit_rate@10: 0.051633
2025-11-22 22:05:46 - GraphTrainer - INFO - ndcg@10: 0.026683
2025-11-22 22:05:46 - GraphTrainer - INFO - map@10: 0.019532
2025-11-22 22:05:46 - GraphTrainer - INFO - mrr@10: 0.020368
2025-11-22 22:05:46 - GraphTrainer - INFO - precision@20: 0.004186
2025-11-22 22:05:46 - GraphTrainer - INFO - recall@20: 0.079395
2025-11-22 22:05:46 - GraphTrainer - INFO - hit_rate@20: 0.083312
2025-11-22 22:05:46 - GraphTrainer - INFO - ndcg@20: 0.034342
2025-11-22 22:05:46 - GraphTrainer - INFO - map@20: 0.021582
2025-11-22 22:05:46 - GraphTrainer - INFO - mrr@20: 0.022519
2025-11-22 22:05:46 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:05:46 - GraphTrainer - INFO - ============================================================
2025-11-22 22:05:46 - GraphTrainer - INFO - 开始第 158/1000 轮训练
2025-11-22 22:05:46 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3517, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3479, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3239, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3038, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3306, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3174, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3545, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3239, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3145, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3512, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3239, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3067, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3409, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3467, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3257, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3158, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3240, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3143, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3563, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3085, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3135, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3195, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3219, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3218, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3183, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3331, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3196, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)
The 157 training average loss: 0.3331064689775993
2025-11-22 22:05:57 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:05:57 - GraphTrainer - INFO -   precision@5: 0.006644
2025-11-22 22:05:57 - GraphTrainer - INFO -   recall@5: 0.031782
2025-11-22 22:05:57 - GraphTrainer - INFO -   hit_rate@5: 0.033170
2025-11-22 22:05:57 - GraphTrainer - INFO -   ndcg@5: 0.021056
2025-11-22 22:05:57 - GraphTrainer - INFO -   map@5: 0.017312
2025-11-22 22:05:57 - GraphTrainer - INFO -   mrr@5: 0.017963
2025-11-22 22:05:57 - GraphTrainer - INFO -   precision@10: 0.005261
2025-11-22 22:05:57 - GraphTrainer - INFO -   recall@10: 0.050095
2025-11-22 22:05:57 - GraphTrainer - INFO -   hit_rate@10: 0.052456
2025-11-22 22:05:57 - GraphTrainer - INFO -   ndcg@10: 0.026994
2025-11-22 22:05:57 - GraphTrainer - INFO -   map@10: 0.019713
2025-11-22 22:05:57 - GraphTrainer - INFO -   mrr@10: 0.020485
2025-11-22 22:05:57 - GraphTrainer - INFO -   precision@20: 0.004160
2025-11-22 22:05:57 - GraphTrainer - INFO -   recall@20: 0.078842
2025-11-22 22:05:57 - GraphTrainer - INFO -   hit_rate@20: 0.082798
2025-11-22 22:05:57 - GraphTrainer - INFO -   ndcg@20: 0.034279
2025-11-22 22:05:57 - GraphTrainer - INFO -   map@20: 0.021650
2025-11-22 22:05:57 - GraphTrainer - INFO -   mrr@20: 0.022529
2025-11-22 22:05:57 - GraphTrainer - INFO - 第 158 轮训练完成
2025-11-22 22:05:57 - GraphTrainer - INFO - train_loss: 0.332698
2025-11-22 22:05:57 - GraphTrainer - INFO - precision@5: 0.006644
2025-11-22 22:05:57 - GraphTrainer - INFO - recall@5: 0.031782
2025-11-22 22:05:57 - GraphTrainer - INFO - hit_rate@5: 0.033170
2025-11-22 22:05:57 - GraphTrainer - INFO - ndcg@5: 0.021056
2025-11-22 22:05:57 - GraphTrainer - INFO - map@5: 0.017312
2025-11-22 22:05:57 - GraphTrainer - INFO - mrr@5: 0.017963
2025-11-22 22:05:57 - GraphTrainer - INFO - precision@10: 0.005261
2025-11-22 22:05:57 - GraphTrainer - INFO - recall@10: 0.050095
2025-11-22 22:05:57 - GraphTrainer - INFO - hit_rate@10: 0.052456
2025-11-22 22:05:57 - GraphTrainer - INFO - ndcg@10: 0.026994
2025-11-22 22:05:57 - GraphTrainer - INFO - map@10: 0.019713
2025-11-22 22:05:57 - GraphTrainer - INFO - mrr@10: 0.020485
2025-11-22 22:05:57 - GraphTrainer - INFO - precision@20: 0.004160
2025-11-22 22:05:57 - GraphTrainer - INFO - recall@20: 0.078842
2025-11-22 22:05:57 - GraphTrainer - INFO - hit_rate@20: 0.082798
2025-11-22 22:05:57 - GraphTrainer - INFO - ndcg@20: 0.034279
2025-11-22 22:05:57 - GraphTrainer - INFO - map@20: 0.021650
2025-11-22 22:05:57 - GraphTrainer - INFO - mrr@20: 0.022529
2025-11-22 22:05:57 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:05:57 - GraphTrainer - INFO - ============================================================
2025-11-22 22:05:57 - GraphTrainer - INFO - 开始第 159/1000 轮训练
2025-11-22 22:05:57 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3144, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3104, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3111, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3175, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3638, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3421, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3536, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3189, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3259, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3457, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3174, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3111, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3174, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3080, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3276, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3703, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3248, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3409, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3262, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3196, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3184, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3226, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3269, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3309, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3016, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3285, device='cuda:0', grad_fn=<AddBackward0>)
The 158 training average loss: 0.3326983503226576
2025-11-22 22:06:09 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:06:09 - GraphTrainer - INFO -   precision@5: 0.006758
2025-11-22 22:06:09 - GraphTrainer - INFO -   recall@5: 0.032382
2025-11-22 22:06:09 - GraphTrainer - INFO -   hit_rate@5: 0.033736
2025-11-22 22:06:09 - GraphTrainer - INFO -   ndcg@5: 0.021141
2025-11-22 22:06:09 - GraphTrainer - INFO -   map@5: 0.017229
2025-11-22 22:06:09 - GraphTrainer - INFO -   mrr@5: 0.017884
2025-11-22 22:06:09 - GraphTrainer - INFO -   precision@10: 0.005163
2025-11-22 22:06:09 - GraphTrainer - INFO -   recall@10: 0.049100
2025-11-22 22:06:09 - GraphTrainer - INFO -   hit_rate@10: 0.051530
2025-11-22 22:06:09 - GraphTrainer - INFO -   ndcg@10: 0.026585
2025-11-22 22:06:09 - GraphTrainer - INFO -   map@10: 0.019431
2025-11-22 22:06:09 - GraphTrainer - INFO -   mrr@10: 0.020225
2025-11-22 22:06:09 - GraphTrainer - INFO -   precision@20: 0.004142
2025-11-22 22:06:09 - GraphTrainer - INFO -   recall@20: 0.078581
2025-11-22 22:06:09 - GraphTrainer - INFO -   hit_rate@20: 0.082540
2025-11-22 22:06:09 - GraphTrainer - INFO -   ndcg@20: 0.034071
2025-11-22 22:06:09 - GraphTrainer - INFO -   map@20: 0.021435
2025-11-22 22:06:09 - GraphTrainer - INFO -   mrr@20: 0.022333
2025-11-22 22:06:09 - GraphTrainer - INFO - 第 159 轮训练完成
2025-11-22 22:06:09 - GraphTrainer - INFO - train_loss: 0.334943
2025-11-22 22:06:09 - GraphTrainer - INFO - precision@5: 0.006758
2025-11-22 22:06:09 - GraphTrainer - INFO - recall@5: 0.032382
2025-11-22 22:06:09 - GraphTrainer - INFO - hit_rate@5: 0.033736
2025-11-22 22:06:09 - GraphTrainer - INFO - ndcg@5: 0.021141
2025-11-22 22:06:09 - GraphTrainer - INFO - map@5: 0.017229
2025-11-22 22:06:09 - GraphTrainer - INFO - mrr@5: 0.017884
2025-11-22 22:06:09 - GraphTrainer - INFO - precision@10: 0.005163
2025-11-22 22:06:09 - GraphTrainer - INFO - recall@10: 0.049100
2025-11-22 22:06:09 - GraphTrainer - INFO - hit_rate@10: 0.051530
2025-11-22 22:06:09 - GraphTrainer - INFO - ndcg@10: 0.026585
2025-11-22 22:06:09 - GraphTrainer - INFO - map@10: 0.019431
2025-11-22 22:06:09 - GraphTrainer - INFO - mrr@10: 0.020225
2025-11-22 22:06:09 - GraphTrainer - INFO - precision@20: 0.004142
2025-11-22 22:06:09 - GraphTrainer - INFO - recall@20: 0.078581
2025-11-22 22:06:09 - GraphTrainer - INFO - hit_rate@20: 0.082540
2025-11-22 22:06:09 - GraphTrainer - INFO - ndcg@20: 0.034071
2025-11-22 22:06:09 - GraphTrainer - INFO - map@20: 0.021435
2025-11-22 22:06:09 - GraphTrainer - INFO - mrr@20: 0.022333
2025-11-22 22:06:09 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:06:09 - GraphTrainer - INFO - ============================================================
2025-11-22 22:06:09 - GraphTrainer - INFO - 开始第 160/1000 轮训练
2025-11-22 22:06:09 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3228, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3211, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3203, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3227, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3130, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3509, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3155, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3313, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3089, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3376, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3197, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3210, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3144, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3183, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3281, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3302, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3467, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3217, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3210, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3680, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3195, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3480, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3112, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
The 159 training average loss: 0.3349429512846059
2025-11-22 22:06:20 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:06:20 - GraphTrainer - INFO -   precision@5: 0.006788
2025-11-22 22:06:20 - GraphTrainer - INFO -   recall@5: 0.032437
2025-11-22 22:06:20 - GraphTrainer - INFO -   hit_rate@5: 0.033839
2025-11-22 22:06:20 - GraphTrainer - INFO -   ndcg@5: 0.021327
2025-11-22 22:06:20 - GraphTrainer - INFO -   map@5: 0.017443
2025-11-22 22:06:20 - GraphTrainer - INFO -   mrr@5: 0.018108
2025-11-22 22:06:20 - GraphTrainer - INFO -   precision@10: 0.005230
2025-11-22 22:06:20 - GraphTrainer - INFO -   recall@10: 0.049752
2025-11-22 22:06:20 - GraphTrainer - INFO -   hit_rate@10: 0.052147
2025-11-22 22:06:20 - GraphTrainer - INFO -   ndcg@10: 0.026940
2025-11-22 22:06:20 - GraphTrainer - INFO -   map@10: 0.019709
2025-11-22 22:06:20 - GraphTrainer - INFO -   mrr@10: 0.020502
2025-11-22 22:06:20 - GraphTrainer - INFO -   precision@20: 0.004181
2025-11-22 22:06:20 - GraphTrainer - INFO -   recall@20: 0.079195
2025-11-22 22:06:20 - GraphTrainer - INFO -   hit_rate@20: 0.083158
2025-11-22 22:06:20 - GraphTrainer - INFO -   ndcg@20: 0.034396
2025-11-22 22:06:20 - GraphTrainer - INFO -   map@20: 0.021689
2025-11-22 22:06:20 - GraphTrainer - INFO -   mrr@20: 0.022588
2025-11-22 22:06:20 - GraphTrainer - INFO - 第 160 轮训练完成
2025-11-22 22:06:20 - GraphTrainer - INFO - train_loss: 0.334151
2025-11-22 22:06:20 - GraphTrainer - INFO - precision@5: 0.006788
2025-11-22 22:06:20 - GraphTrainer - INFO - recall@5: 0.032437
2025-11-22 22:06:20 - GraphTrainer - INFO - hit_rate@5: 0.033839
2025-11-22 22:06:20 - GraphTrainer - INFO - ndcg@5: 0.021327
2025-11-22 22:06:20 - GraphTrainer - INFO - map@5: 0.017443
2025-11-22 22:06:20 - GraphTrainer - INFO - mrr@5: 0.018108
2025-11-22 22:06:20 - GraphTrainer - INFO - precision@10: 0.005230
2025-11-22 22:06:20 - GraphTrainer - INFO - recall@10: 0.049752
2025-11-22 22:06:20 - GraphTrainer - INFO - hit_rate@10: 0.052147
2025-11-22 22:06:20 - GraphTrainer - INFO - ndcg@10: 0.026940
2025-11-22 22:06:20 - GraphTrainer - INFO - map@10: 0.019709
2025-11-22 22:06:20 - GraphTrainer - INFO - mrr@10: 0.020502
2025-11-22 22:06:20 - GraphTrainer - INFO - precision@20: 0.004181
2025-11-22 22:06:20 - GraphTrainer - INFO - recall@20: 0.079195
2025-11-22 22:06:20 - GraphTrainer - INFO - hit_rate@20: 0.083158
2025-11-22 22:06:20 - GraphTrainer - INFO - ndcg@20: 0.034396
2025-11-22 22:06:20 - GraphTrainer - INFO - map@20: 0.021689
2025-11-22 22:06:20 - GraphTrainer - INFO - mrr@20: 0.022588
2025-11-22 22:06:20 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:06:20 - GraphTrainer - INFO - 检查点已保存: Epoch 160 -> ./checkpoints/checkpoint_epoch_160.pth
2025-11-22 22:06:20 - GraphTrainer - INFO - ============================================================
2025-11-22 22:06:20 - GraphTrainer - INFO - 开始第 161/1000 轮训练
2025-11-22 22:06:20 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3254, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3236, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3260, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3241, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3297, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3165, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3550, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3577, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3297, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3257, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3272, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3303, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3112, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3628, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3288, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3143, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3268, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3193, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3232, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3502, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3246, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3196, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3306, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3232, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3544, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3057, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
The 160 training average loss: 0.3341505136983148
2025-11-22 22:06:31 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:06:31 - GraphTrainer - INFO -   precision@5: 0.006830
2025-11-22 22:06:31 - GraphTrainer - INFO -   recall@5: 0.032579
2025-11-22 22:06:31 - GraphTrainer - INFO -   hit_rate@5: 0.034045
2025-11-22 22:06:31 - GraphTrainer - INFO -   ndcg@5: 0.021482
2025-11-22 22:06:31 - GraphTrainer - INFO -   map@5: 0.017608
2025-11-22 22:06:31 - GraphTrainer - INFO -   mrr@5: 0.018254
2025-11-22 22:06:31 - GraphTrainer - INFO -   precision@10: 0.005256
2025-11-22 22:06:31 - GraphTrainer - INFO -   recall@10: 0.049864
2025-11-22 22:06:31 - GraphTrainer - INFO -   hit_rate@10: 0.052404
2025-11-22 22:06:31 - GraphTrainer - INFO -   ndcg@10: 0.027095
2025-11-22 22:06:31 - GraphTrainer - INFO -   map@10: 0.019872
2025-11-22 22:06:31 - GraphTrainer - INFO -   mrr@10: 0.020654
2025-11-22 22:06:31 - GraphTrainer - INFO -   precision@20: 0.004137
2025-11-22 22:06:31 - GraphTrainer - INFO -   recall@20: 0.078347
2025-11-22 22:06:31 - GraphTrainer - INFO -   hit_rate@20: 0.082283
2025-11-22 22:06:31 - GraphTrainer - INFO -   ndcg@20: 0.034338
2025-11-22 22:06:31 - GraphTrainer - INFO -   map@20: 0.021818
2025-11-22 22:06:31 - GraphTrainer - INFO -   mrr@20: 0.022694
2025-11-22 22:06:31 - GraphTrainer - INFO - 第 161 轮训练完成
2025-11-22 22:06:31 - GraphTrainer - INFO - train_loss: 0.334377
2025-11-22 22:06:31 - GraphTrainer - INFO - precision@5: 0.006830
2025-11-22 22:06:31 - GraphTrainer - INFO - recall@5: 0.032579
2025-11-22 22:06:31 - GraphTrainer - INFO - hit_rate@5: 0.034045
2025-11-22 22:06:31 - GraphTrainer - INFO - ndcg@5: 0.021482
2025-11-22 22:06:31 - GraphTrainer - INFO - map@5: 0.017608
2025-11-22 22:06:31 - GraphTrainer - INFO - mrr@5: 0.018254
2025-11-22 22:06:31 - GraphTrainer - INFO - precision@10: 0.005256
2025-11-22 22:06:31 - GraphTrainer - INFO - recall@10: 0.049864
2025-11-22 22:06:31 - GraphTrainer - INFO - hit_rate@10: 0.052404
2025-11-22 22:06:31 - GraphTrainer - INFO - ndcg@10: 0.027095
2025-11-22 22:06:31 - GraphTrainer - INFO - map@10: 0.019872
2025-11-22 22:06:31 - GraphTrainer - INFO - mrr@10: 0.020654
2025-11-22 22:06:31 - GraphTrainer - INFO - precision@20: 0.004137
2025-11-22 22:06:31 - GraphTrainer - INFO - recall@20: 0.078347
2025-11-22 22:06:31 - GraphTrainer - INFO - hit_rate@20: 0.082283
2025-11-22 22:06:31 - GraphTrainer - INFO - ndcg@20: 0.034338
2025-11-22 22:06:31 - GraphTrainer - INFO - map@20: 0.021818
2025-11-22 22:06:31 - GraphTrainer - INFO - mrr@20: 0.022694
2025-11-22 22:06:31 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:06:31 - GraphTrainer - INFO - ============================================================
2025-11-22 22:06:31 - GraphTrainer - INFO - 开始第 162/1000 轮训练
2025-11-22 22:06:31 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3669, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3517, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3621, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3101, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3227, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3218, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3534, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3246, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3635, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3244, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3269, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3231, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3620, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3208, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3120, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3197, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3274, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3261, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3254, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3615, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3060, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3176, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3279, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3252, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3214, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3331, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3279, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3281, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3193, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3241, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3196, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)
The 161 training average loss: 0.33437727237569875
2025-11-22 22:06:42 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:06:42 - GraphTrainer - INFO -   precision@5: 0.006799
2025-11-22 22:06:42 - GraphTrainer - INFO -   recall@5: 0.032412
2025-11-22 22:06:42 - GraphTrainer - INFO -   hit_rate@5: 0.033890
2025-11-22 22:06:42 - GraphTrainer - INFO -   ndcg@5: 0.021193
2025-11-22 22:06:42 - GraphTrainer - INFO -   map@5: 0.017272
2025-11-22 22:06:42 - GraphTrainer - INFO -   mrr@5: 0.017970
2025-11-22 22:06:42 - GraphTrainer - INFO -   precision@10: 0.005204
2025-11-22 22:06:42 - GraphTrainer - INFO -   recall@10: 0.049413
2025-11-22 22:06:42 - GraphTrainer - INFO -   hit_rate@10: 0.051890
2025-11-22 22:06:42 - GraphTrainer - INFO -   ndcg@10: 0.026738
2025-11-22 22:06:42 - GraphTrainer - INFO -   map@10: 0.019526
2025-11-22 22:06:42 - GraphTrainer - INFO -   mrr@10: 0.020354
2025-11-22 22:06:42 - GraphTrainer - INFO -   precision@20: 0.004186
2025-11-22 22:06:42 - GraphTrainer - INFO -   recall@20: 0.079408
2025-11-22 22:06:42 - GraphTrainer - INFO -   hit_rate@20: 0.083209
2025-11-22 22:06:42 - GraphTrainer - INFO -   ndcg@20: 0.034360
2025-11-22 22:06:42 - GraphTrainer - INFO -   map@20: 0.021577
2025-11-22 22:06:42 - GraphTrainer - INFO -   mrr@20: 0.022493
2025-11-22 22:06:42 - GraphTrainer - INFO - 第 162 轮训练完成
2025-11-22 22:06:42 - GraphTrainer - INFO - train_loss: 0.333639
2025-11-22 22:06:42 - GraphTrainer - INFO - precision@5: 0.006799
2025-11-22 22:06:42 - GraphTrainer - INFO - recall@5: 0.032412
2025-11-22 22:06:42 - GraphTrainer - INFO - hit_rate@5: 0.033890
2025-11-22 22:06:42 - GraphTrainer - INFO - ndcg@5: 0.021193
2025-11-22 22:06:42 - GraphTrainer - INFO - map@5: 0.017272
2025-11-22 22:06:42 - GraphTrainer - INFO - mrr@5: 0.017970
2025-11-22 22:06:42 - GraphTrainer - INFO - precision@10: 0.005204
2025-11-22 22:06:42 - GraphTrainer - INFO - recall@10: 0.049413
2025-11-22 22:06:42 - GraphTrainer - INFO - hit_rate@10: 0.051890
2025-11-22 22:06:42 - GraphTrainer - INFO - ndcg@10: 0.026738
2025-11-22 22:06:42 - GraphTrainer - INFO - map@10: 0.019526
2025-11-22 22:06:42 - GraphTrainer - INFO - mrr@10: 0.020354
2025-11-22 22:06:42 - GraphTrainer - INFO - precision@20: 0.004186
2025-11-22 22:06:42 - GraphTrainer - INFO - recall@20: 0.079408
2025-11-22 22:06:42 - GraphTrainer - INFO - hit_rate@20: 0.083209
2025-11-22 22:06:42 - GraphTrainer - INFO - ndcg@20: 0.034360
2025-11-22 22:06:42 - GraphTrainer - INFO - map@20: 0.021577
2025-11-22 22:06:42 - GraphTrainer - INFO - mrr@20: 0.022493
2025-11-22 22:06:42 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:06:42 - GraphTrainer - INFO - ============================================================
2025-11-22 22:06:42 - GraphTrainer - INFO - 开始第 163/1000 轮训练
2025-11-22 22:06:42 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3628, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3793, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3073, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3182, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3376, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3216, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3211, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3165, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3293, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3233, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3160, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3536, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3120, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3627, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3262, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3144, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3303, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3143, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3143, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3376, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3462, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3239, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3217, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3586, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3313, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3144, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3227, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3376, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3570, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3258, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3268, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3268, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3539, device='cuda:0', grad_fn=<AddBackward0>)
The 162 training average loss: 0.33363876723009966
2025-11-22 22:06:54 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:06:54 - GraphTrainer - INFO -   precision@5: 0.006850
2025-11-22 22:06:54 - GraphTrainer - INFO -   recall@5: 0.032669
2025-11-22 22:06:54 - GraphTrainer - INFO -   hit_rate@5: 0.034148
2025-11-22 22:06:54 - GraphTrainer - INFO -   ndcg@5: 0.021387
2025-11-22 22:06:54 - GraphTrainer - INFO -   map@5: 0.017455
2025-11-22 22:06:54 - GraphTrainer - INFO -   mrr@5: 0.018126
2025-11-22 22:06:54 - GraphTrainer - INFO -   precision@10: 0.005163
2025-11-22 22:06:54 - GraphTrainer - INFO -   recall@10: 0.049040
2025-11-22 22:06:54 - GraphTrainer - INFO -   hit_rate@10: 0.051479
2025-11-22 22:06:54 - GraphTrainer - INFO -   ndcg@10: 0.026716
2025-11-22 22:06:54 - GraphTrainer - INFO -   map@10: 0.019617
2025-11-22 22:06:54 - GraphTrainer - INFO -   mrr@10: 0.020412
2025-11-22 22:06:54 - GraphTrainer - INFO -   precision@20: 0.004176
2025-11-22 22:06:54 - GraphTrainer - INFO -   recall@20: 0.079062
2025-11-22 22:06:54 - GraphTrainer - INFO -   hit_rate@20: 0.083055
2025-11-22 22:06:54 - GraphTrainer - INFO -   ndcg@20: 0.034372
2025-11-22 22:06:54 - GraphTrainer - INFO -   map@20: 0.021680
2025-11-22 22:06:54 - GraphTrainer - INFO -   mrr@20: 0.022581
2025-11-22 22:06:54 - GraphTrainer - INFO - 第 163 轮训练完成
2025-11-22 22:06:54 - GraphTrainer - INFO - train_loss: 0.332741
2025-11-22 22:06:54 - GraphTrainer - INFO - precision@5: 0.006850
2025-11-22 22:06:54 - GraphTrainer - INFO - recall@5: 0.032669
2025-11-22 22:06:54 - GraphTrainer - INFO - hit_rate@5: 0.034148
2025-11-22 22:06:54 - GraphTrainer - INFO - ndcg@5: 0.021387
2025-11-22 22:06:54 - GraphTrainer - INFO - map@5: 0.017455
2025-11-22 22:06:54 - GraphTrainer - INFO - mrr@5: 0.018126
2025-11-22 22:06:54 - GraphTrainer - INFO - precision@10: 0.005163
2025-11-22 22:06:54 - GraphTrainer - INFO - recall@10: 0.049040
2025-11-22 22:06:54 - GraphTrainer - INFO - hit_rate@10: 0.051479
2025-11-22 22:06:54 - GraphTrainer - INFO - ndcg@10: 0.026716
2025-11-22 22:06:54 - GraphTrainer - INFO - map@10: 0.019617
2025-11-22 22:06:54 - GraphTrainer - INFO - mrr@10: 0.020412
2025-11-22 22:06:54 - GraphTrainer - INFO - precision@20: 0.004176
2025-11-22 22:06:54 - GraphTrainer - INFO - recall@20: 0.079062
2025-11-22 22:06:54 - GraphTrainer - INFO - hit_rate@20: 0.083055
2025-11-22 22:06:54 - GraphTrainer - INFO - ndcg@20: 0.034372
2025-11-22 22:06:54 - GraphTrainer - INFO - map@20: 0.021680
2025-11-22 22:06:54 - GraphTrainer - INFO - mrr@20: 0.022581
2025-11-22 22:06:54 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:06:54 - GraphTrainer - INFO - ============================================================
2025-11-22 22:06:54 - GraphTrainer - INFO - 开始第 164/1000 轮训练
2025-11-22 22:06:54 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3191, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3284, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3109, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3101, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3237, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3610, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3039, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3246, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3136, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3624, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3433, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3342, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3210, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3083, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3468, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3254, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3268, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3220, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3507, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3467, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3279, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3258, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3183, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3259, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3139, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3455, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3194, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3191, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3591, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3071, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
The 163 training average loss: 0.3327412240464112
2025-11-22 22:07:05 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:07:05 - GraphTrainer - INFO -   precision@5: 0.006819
2025-11-22 22:07:05 - GraphTrainer - INFO -   recall@5: 0.032532
2025-11-22 22:07:05 - GraphTrainer - INFO -   hit_rate@5: 0.034045
2025-11-22 22:07:05 - GraphTrainer - INFO -   ndcg@5: 0.021468
2025-11-22 22:07:05 - GraphTrainer - INFO -   map@5: 0.017602
2025-11-22 22:07:05 - GraphTrainer - INFO -   mrr@5: 0.018294
2025-11-22 22:07:05 - GraphTrainer - INFO -   precision@10: 0.005266
2025-11-22 22:07:05 - GraphTrainer - INFO -   recall@10: 0.049932
2025-11-22 22:07:05 - GraphTrainer - INFO -   hit_rate@10: 0.052558
2025-11-22 22:07:05 - GraphTrainer - INFO -   ndcg@10: 0.027136
2025-11-22 22:07:05 - GraphTrainer - INFO -   map@10: 0.019899
2025-11-22 22:07:05 - GraphTrainer - INFO -   mrr@10: 0.020730
2025-11-22 22:07:05 - GraphTrainer - INFO -   precision@20: 0.004217
2025-11-22 22:07:05 - GraphTrainer - INFO -   recall@20: 0.079932
2025-11-22 22:07:05 - GraphTrainer - INFO -   hit_rate@20: 0.083826
2025-11-22 22:07:05 - GraphTrainer - INFO -   ndcg@20: 0.034717
2025-11-22 22:07:05 - GraphTrainer - INFO -   map@20: 0.021916
2025-11-22 22:07:05 - GraphTrainer - INFO -   mrr@20: 0.022831
2025-11-22 22:07:05 - GraphTrainer - INFO - 第 164 轮训练完成
2025-11-22 22:07:05 - GraphTrainer - INFO - train_loss: 0.333145
2025-11-22 22:07:05 - GraphTrainer - INFO - precision@5: 0.006819
2025-11-22 22:07:05 - GraphTrainer - INFO - recall@5: 0.032532
2025-11-22 22:07:05 - GraphTrainer - INFO - hit_rate@5: 0.034045
2025-11-22 22:07:05 - GraphTrainer - INFO - ndcg@5: 0.021468
2025-11-22 22:07:05 - GraphTrainer - INFO - map@5: 0.017602
2025-11-22 22:07:05 - GraphTrainer - INFO - mrr@5: 0.018294
2025-11-22 22:07:05 - GraphTrainer - INFO - precision@10: 0.005266
2025-11-22 22:07:05 - GraphTrainer - INFO - recall@10: 0.049932
2025-11-22 22:07:05 - GraphTrainer - INFO - hit_rate@10: 0.052558
2025-11-22 22:07:05 - GraphTrainer - INFO - ndcg@10: 0.027136
2025-11-22 22:07:05 - GraphTrainer - INFO - map@10: 0.019899
2025-11-22 22:07:05 - GraphTrainer - INFO - mrr@10: 0.020730
2025-11-22 22:07:05 - GraphTrainer - INFO - precision@20: 0.004217
2025-11-22 22:07:05 - GraphTrainer - INFO - recall@20: 0.079932
2025-11-22 22:07:05 - GraphTrainer - INFO - hit_rate@20: 0.083826
2025-11-22 22:07:05 - GraphTrainer - INFO - ndcg@20: 0.034717
2025-11-22 22:07:05 - GraphTrainer - INFO - map@20: 0.021916
2025-11-22 22:07:05 - GraphTrainer - INFO - mrr@20: 0.022831
2025-11-22 22:07:05 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:07:05 - GraphTrainer - INFO - ============================================================
2025-11-22 22:07:05 - GraphTrainer - INFO - 开始第 165/1000 轮训练
2025-11-22 22:07:05 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3220, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3212, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3049, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3331, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3249, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3316, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3421, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3262, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3191, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3249, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3244, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3557, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3167, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3223, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3274, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3302, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3278, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3095, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3502, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3547, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3276, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3217, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
The 164 training average loss: 0.333144617491755
2025-11-22 22:07:16 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:07:16 - GraphTrainer - INFO -   precision@5: 0.006747
2025-11-22 22:07:16 - GraphTrainer - INFO -   recall@5: 0.032142
2025-11-22 22:07:16 - GraphTrainer - INFO -   hit_rate@5: 0.033633
2025-11-22 22:07:16 - GraphTrainer - INFO -   ndcg@5: 0.021346
2025-11-22 22:07:16 - GraphTrainer - INFO -   map@5: 0.017561
2025-11-22 22:07:16 - GraphTrainer - INFO -   mrr@5: 0.018258
2025-11-22 22:07:16 - GraphTrainer - INFO -   precision@10: 0.005246
2025-11-22 22:07:16 - GraphTrainer - INFO -   recall@10: 0.049816
2025-11-22 22:07:16 - GraphTrainer - INFO -   hit_rate@10: 0.052353
2025-11-22 22:07:16 - GraphTrainer - INFO -   ndcg@10: 0.027097
2025-11-22 22:07:16 - GraphTrainer - INFO -   map@10: 0.019895
2025-11-22 22:07:16 - GraphTrainer - INFO -   mrr@10: 0.020728
2025-11-22 22:07:16 - GraphTrainer - INFO -   precision@20: 0.004176
2025-11-22 22:07:16 - GraphTrainer - INFO -   recall@20: 0.079153
2025-11-22 22:07:16 - GraphTrainer - INFO -   hit_rate@20: 0.083055
2025-11-22 22:07:16 - GraphTrainer - INFO -   ndcg@20: 0.034523
2025-11-22 22:07:16 - GraphTrainer - INFO -   map@20: 0.021872
2025-11-22 22:07:16 - GraphTrainer - INFO -   mrr@20: 0.022796
2025-11-22 22:07:16 - GraphTrainer - INFO - 第 165 轮训练完成
2025-11-22 22:07:16 - GraphTrainer - INFO - train_loss: 0.332291
2025-11-22 22:07:16 - GraphTrainer - INFO - precision@5: 0.006747
2025-11-22 22:07:16 - GraphTrainer - INFO - recall@5: 0.032142
2025-11-22 22:07:16 - GraphTrainer - INFO - hit_rate@5: 0.033633
2025-11-22 22:07:16 - GraphTrainer - INFO - ndcg@5: 0.021346
2025-11-22 22:07:16 - GraphTrainer - INFO - map@5: 0.017561
2025-11-22 22:07:16 - GraphTrainer - INFO - mrr@5: 0.018258
2025-11-22 22:07:16 - GraphTrainer - INFO - precision@10: 0.005246
2025-11-22 22:07:16 - GraphTrainer - INFO - recall@10: 0.049816
2025-11-22 22:07:16 - GraphTrainer - INFO - hit_rate@10: 0.052353
2025-11-22 22:07:16 - GraphTrainer - INFO - ndcg@10: 0.027097
2025-11-22 22:07:16 - GraphTrainer - INFO - map@10: 0.019895
2025-11-22 22:07:16 - GraphTrainer - INFO - mrr@10: 0.020728
2025-11-22 22:07:16 - GraphTrainer - INFO - precision@20: 0.004176
2025-11-22 22:07:16 - GraphTrainer - INFO - recall@20: 0.079153
2025-11-22 22:07:16 - GraphTrainer - INFO - hit_rate@20: 0.083055
2025-11-22 22:07:16 - GraphTrainer - INFO - ndcg@20: 0.034523
2025-11-22 22:07:16 - GraphTrainer - INFO - map@20: 0.021872
2025-11-22 22:07:16 - GraphTrainer - INFO - mrr@20: 0.022796
2025-11-22 22:07:16 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:07:16 - GraphTrainer - INFO - ============================================================
2025-11-22 22:07:16 - GraphTrainer - INFO - 开始第 166/1000 轮训练
2025-11-22 22:07:16 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3221, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3259, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3162, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3128, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3197, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3303, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3145, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3236, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3626, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3666, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3296, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3166, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3288, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3261, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3590, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3078, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3159, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3257, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3141, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3210, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3570, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3106, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3646, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3268, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3174, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3293, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)
The 165 training average loss: 0.33229112419588813
2025-11-22 22:07:27 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:07:27 - GraphTrainer - INFO -   precision@5: 0.006747
2025-11-22 22:07:27 - GraphTrainer - INFO -   recall@5: 0.032185
2025-11-22 22:07:27 - GraphTrainer - INFO -   hit_rate@5: 0.033633
2025-11-22 22:07:27 - GraphTrainer - INFO -   ndcg@5: 0.021621
2025-11-22 22:07:27 - GraphTrainer - INFO -   map@5: 0.017913
2025-11-22 22:07:27 - GraphTrainer - INFO -   mrr@5: 0.018582
2025-11-22 22:07:27 - GraphTrainer - INFO -   precision@10: 0.005261
2025-11-22 22:07:27 - GraphTrainer - INFO -   recall@10: 0.049939
2025-11-22 22:07:27 - GraphTrainer - INFO -   hit_rate@10: 0.052456
2025-11-22 22:07:27 - GraphTrainer - INFO -   ndcg@10: 0.027370
2025-11-22 22:07:27 - GraphTrainer - INFO -   map@10: 0.020227
2025-11-22 22:07:27 - GraphTrainer - INFO -   mrr@10: 0.021030
2025-11-22 22:07:27 - GraphTrainer - INFO -   precision@20: 0.004173
2025-11-22 22:07:27 - GraphTrainer - INFO -   recall@20: 0.078972
2025-11-22 22:07:27 - GraphTrainer - INFO -   hit_rate@20: 0.082952
2025-11-22 22:07:27 - GraphTrainer - INFO -   ndcg@20: 0.034737
2025-11-22 22:07:27 - GraphTrainer - INFO -   map@20: 0.022194
2025-11-22 22:07:27 - GraphTrainer - INFO -   mrr@20: 0.023094
2025-11-22 22:07:27 - GraphTrainer - INFO - 第 166 轮训练完成
2025-11-22 22:07:27 - GraphTrainer - INFO - train_loss: 0.330942
2025-11-22 22:07:27 - GraphTrainer - INFO - precision@5: 0.006747
2025-11-22 22:07:27 - GraphTrainer - INFO - recall@5: 0.032185
2025-11-22 22:07:27 - GraphTrainer - INFO - hit_rate@5: 0.033633
2025-11-22 22:07:27 - GraphTrainer - INFO - ndcg@5: 0.021621
2025-11-22 22:07:27 - GraphTrainer - INFO - map@5: 0.017913
2025-11-22 22:07:27 - GraphTrainer - INFO - mrr@5: 0.018582
2025-11-22 22:07:27 - GraphTrainer - INFO - precision@10: 0.005261
2025-11-22 22:07:27 - GraphTrainer - INFO - recall@10: 0.049939
2025-11-22 22:07:27 - GraphTrainer - INFO - hit_rate@10: 0.052456
2025-11-22 22:07:27 - GraphTrainer - INFO - ndcg@10: 0.027370
2025-11-22 22:07:27 - GraphTrainer - INFO - map@10: 0.020227
2025-11-22 22:07:27 - GraphTrainer - INFO - mrr@10: 0.021030
2025-11-22 22:07:27 - GraphTrainer - INFO - precision@20: 0.004173
2025-11-22 22:07:27 - GraphTrainer - INFO - recall@20: 0.078972
2025-11-22 22:07:27 - GraphTrainer - INFO - hit_rate@20: 0.082952
2025-11-22 22:07:27 - GraphTrainer - INFO - ndcg@20: 0.034737
2025-11-22 22:07:27 - GraphTrainer - INFO - map@20: 0.022194
2025-11-22 22:07:27 - GraphTrainer - INFO - mrr@20: 0.023094
2025-11-22 22:07:27 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:07:27 - GraphTrainer - INFO - ============================================================
2025-11-22 22:07:27 - GraphTrainer - INFO - 开始第 167/1000 轮训练
2025-11-22 22:07:27 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3272, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3105, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3462, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3318, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3233, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3188, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3228, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3509, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3060, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3128, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3174, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3233, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3152, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3202, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3494, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3138, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3225, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3169, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3327, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3306, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3303, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3123, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3211, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3203, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3109, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3434, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
The 166 training average loss: 0.330941791164464
2025-11-22 22:07:38 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:07:38 - GraphTrainer - INFO -   precision@5: 0.006727
2025-11-22 22:07:38 - GraphTrainer - INFO -   recall@5: 0.032180
2025-11-22 22:07:38 - GraphTrainer - INFO -   hit_rate@5: 0.033582
2025-11-22 22:07:38 - GraphTrainer - INFO -   ndcg@5: 0.021491
2025-11-22 22:07:38 - GraphTrainer - INFO -   map@5: 0.017758
2025-11-22 22:07:38 - GraphTrainer - INFO -   mrr@5: 0.018407
2025-11-22 22:07:38 - GraphTrainer - INFO -   precision@10: 0.005276
2025-11-22 22:07:38 - GraphTrainer - INFO -   recall@10: 0.050089
2025-11-22 22:07:38 - GraphTrainer - INFO -   hit_rate@10: 0.052610
2025-11-22 22:07:38 - GraphTrainer - INFO -   ndcg@10: 0.027303
2025-11-22 22:07:38 - GraphTrainer - INFO -   map@10: 0.020098
2025-11-22 22:07:38 - GraphTrainer - INFO -   mrr@10: 0.020896
2025-11-22 22:07:38 - GraphTrainer - INFO -   precision@20: 0.004145
2025-11-22 22:07:38 - GraphTrainer - INFO -   recall@20: 0.078487
2025-11-22 22:07:38 - GraphTrainer - INFO -   hit_rate@20: 0.082386
2025-11-22 22:07:38 - GraphTrainer - INFO -   ndcg@20: 0.034493
2025-11-22 22:07:38 - GraphTrainer - INFO -   map@20: 0.022012
2025-11-22 22:07:38 - GraphTrainer - INFO -   mrr@20: 0.022901
2025-11-22 22:07:38 - GraphTrainer - INFO - 第 167 轮训练完成
2025-11-22 22:07:38 - GraphTrainer - INFO - train_loss: 0.332993
2025-11-22 22:07:38 - GraphTrainer - INFO - precision@5: 0.006727
2025-11-22 22:07:38 - GraphTrainer - INFO - recall@5: 0.032180
2025-11-22 22:07:38 - GraphTrainer - INFO - hit_rate@5: 0.033582
2025-11-22 22:07:38 - GraphTrainer - INFO - ndcg@5: 0.021491
2025-11-22 22:07:38 - GraphTrainer - INFO - map@5: 0.017758
2025-11-22 22:07:38 - GraphTrainer - INFO - mrr@5: 0.018407
2025-11-22 22:07:38 - GraphTrainer - INFO - precision@10: 0.005276
2025-11-22 22:07:38 - GraphTrainer - INFO - recall@10: 0.050089
2025-11-22 22:07:38 - GraphTrainer - INFO - hit_rate@10: 0.052610
2025-11-22 22:07:38 - GraphTrainer - INFO - ndcg@10: 0.027303
2025-11-22 22:07:38 - GraphTrainer - INFO - map@10: 0.020098
2025-11-22 22:07:38 - GraphTrainer - INFO - mrr@10: 0.020896
2025-11-22 22:07:38 - GraphTrainer - INFO - precision@20: 0.004145
2025-11-22 22:07:38 - GraphTrainer - INFO - recall@20: 0.078487
2025-11-22 22:07:38 - GraphTrainer - INFO - hit_rate@20: 0.082386
2025-11-22 22:07:38 - GraphTrainer - INFO - ndcg@20: 0.034493
2025-11-22 22:07:38 - GraphTrainer - INFO - map@20: 0.022012
2025-11-22 22:07:38 - GraphTrainer - INFO - mrr@20: 0.022901
2025-11-22 22:07:38 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:07:38 - GraphTrainer - INFO - ============================================================
2025-11-22 22:07:38 - GraphTrainer - INFO - 开始第 168/1000 轮训练
2025-11-22 22:07:38 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3228, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3318, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3164, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3163, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3517, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3259, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3113, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3657, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3272, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3278, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3268, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3269, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3258, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3649, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3177, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3196, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3466, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3244, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3067, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3230, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3193, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3115, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3214, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3293, device='cuda:0', grad_fn=<AddBackward0>)
The 167 training average loss: 0.3329934210612856
2025-11-22 22:07:49 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:07:49 - GraphTrainer - INFO -   precision@5: 0.006747
2025-11-22 22:07:49 - GraphTrainer - INFO -   recall@5: 0.032185
2025-11-22 22:07:49 - GraphTrainer - INFO -   hit_rate@5: 0.033633
2025-11-22 22:07:49 - GraphTrainer - INFO -   ndcg@5: 0.021218
2025-11-22 22:07:49 - GraphTrainer - INFO -   map@5: 0.017377
2025-11-22 22:07:49 - GraphTrainer - INFO -   mrr@5: 0.018059
2025-11-22 22:07:49 - GraphTrainer - INFO -   precision@10: 0.005276
2025-11-22 22:07:49 - GraphTrainer - INFO -   recall@10: 0.050171
2025-11-22 22:07:49 - GraphTrainer - INFO -   hit_rate@10: 0.052610
2025-11-22 22:07:49 - GraphTrainer - INFO -   ndcg@10: 0.027053
2025-11-22 22:07:49 - GraphTrainer - INFO -   map@10: 0.019736
2025-11-22 22:07:49 - GraphTrainer - INFO -   mrr@10: 0.020547
2025-11-22 22:07:49 - GraphTrainer - INFO -   precision@20: 0.004191
2025-11-22 22:07:49 - GraphTrainer - INFO -   recall@20: 0.079295
2025-11-22 22:07:49 - GraphTrainer - INFO -   hit_rate@20: 0.083363
2025-11-22 22:07:49 - GraphTrainer - INFO -   ndcg@20: 0.034455
2025-11-22 22:07:49 - GraphTrainer - INFO -   map@20: 0.021713
2025-11-22 22:07:49 - GraphTrainer - INFO -   mrr@20: 0.022634
2025-11-22 22:07:49 - GraphTrainer - INFO - 第 168 轮训练完成
2025-11-22 22:07:49 - GraphTrainer - INFO - train_loss: 0.331931
2025-11-22 22:07:49 - GraphTrainer - INFO - precision@5: 0.006747
2025-11-22 22:07:49 - GraphTrainer - INFO - recall@5: 0.032185
2025-11-22 22:07:49 - GraphTrainer - INFO - hit_rate@5: 0.033633
2025-11-22 22:07:49 - GraphTrainer - INFO - ndcg@5: 0.021218
2025-11-22 22:07:49 - GraphTrainer - INFO - map@5: 0.017377
2025-11-22 22:07:49 - GraphTrainer - INFO - mrr@5: 0.018059
2025-11-22 22:07:49 - GraphTrainer - INFO - precision@10: 0.005276
2025-11-22 22:07:49 - GraphTrainer - INFO - recall@10: 0.050171
2025-11-22 22:07:49 - GraphTrainer - INFO - hit_rate@10: 0.052610
2025-11-22 22:07:49 - GraphTrainer - INFO - ndcg@10: 0.027053
2025-11-22 22:07:49 - GraphTrainer - INFO - map@10: 0.019736
2025-11-22 22:07:49 - GraphTrainer - INFO - mrr@10: 0.020547
2025-11-22 22:07:49 - GraphTrainer - INFO - precision@20: 0.004191
2025-11-22 22:07:49 - GraphTrainer - INFO - recall@20: 0.079295
2025-11-22 22:07:49 - GraphTrainer - INFO - hit_rate@20: 0.083363
2025-11-22 22:07:49 - GraphTrainer - INFO - ndcg@20: 0.034455
2025-11-22 22:07:49 - GraphTrainer - INFO - map@20: 0.021713
2025-11-22 22:07:49 - GraphTrainer - INFO - mrr@20: 0.022634
2025-11-22 22:07:49 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:07:49 - GraphTrainer - INFO - ============================================================
2025-11-22 22:07:49 - GraphTrainer - INFO - 开始第 169/1000 轮训练
2025-11-22 22:07:49 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3304, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3139, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3194, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3245, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3221, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3179, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3074, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3213, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3379, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3313, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3178, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3219, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3268, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3239, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3147, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3092, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3215, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3222, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3246, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3278, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3190, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3274, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3136, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3263, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
The 168 training average loss: 0.33193054178665427
2025-11-22 22:08:00 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:08:00 - GraphTrainer - INFO -   precision@5: 0.006778
2025-11-22 22:08:00 - GraphTrainer - INFO -   recall@5: 0.032313
2025-11-22 22:08:00 - GraphTrainer - INFO -   hit_rate@5: 0.033788
2025-11-22 22:08:00 - GraphTrainer - INFO -   ndcg@5: 0.021350
2025-11-22 22:08:00 - GraphTrainer - INFO -   map@5: 0.017522
2025-11-22 22:08:00 - GraphTrainer - INFO -   mrr@5: 0.018183
2025-11-22 22:08:00 - GraphTrainer - INFO -   precision@10: 0.005240
2025-11-22 22:08:00 - GraphTrainer - INFO -   recall@10: 0.049829
2025-11-22 22:08:00 - GraphTrainer - INFO -   hit_rate@10: 0.052301
2025-11-22 22:08:00 - GraphTrainer - INFO -   ndcg@10: 0.027023
2025-11-22 22:08:00 - GraphTrainer - INFO -   map@10: 0.019811
2025-11-22 22:08:00 - GraphTrainer - INFO -   mrr@10: 0.020598
2025-11-22 22:08:00 - GraphTrainer - INFO -   precision@20: 0.004225
2025-11-22 22:08:00 - GraphTrainer - INFO -   recall@20: 0.080073
2025-11-22 22:08:00 - GraphTrainer - INFO -   hit_rate@20: 0.084032
2025-11-22 22:08:00 - GraphTrainer - INFO -   ndcg@20: 0.034695
2025-11-22 22:08:00 - GraphTrainer - INFO -   map@20: 0.021861
2025-11-22 22:08:00 - GraphTrainer - INFO -   mrr@20: 0.022749
2025-11-22 22:08:00 - GraphTrainer - INFO - 第 169 轮训练完成
2025-11-22 22:08:00 - GraphTrainer - INFO - train_loss: 0.333350
2025-11-22 22:08:00 - GraphTrainer - INFO - precision@5: 0.006778
2025-11-22 22:08:00 - GraphTrainer - INFO - recall@5: 0.032313
2025-11-22 22:08:00 - GraphTrainer - INFO - hit_rate@5: 0.033788
2025-11-22 22:08:00 - GraphTrainer - INFO - ndcg@5: 0.021350
2025-11-22 22:08:00 - GraphTrainer - INFO - map@5: 0.017522
2025-11-22 22:08:00 - GraphTrainer - INFO - mrr@5: 0.018183
2025-11-22 22:08:00 - GraphTrainer - INFO - precision@10: 0.005240
2025-11-22 22:08:00 - GraphTrainer - INFO - recall@10: 0.049829
2025-11-22 22:08:00 - GraphTrainer - INFO - hit_rate@10: 0.052301
2025-11-22 22:08:00 - GraphTrainer - INFO - ndcg@10: 0.027023
2025-11-22 22:08:00 - GraphTrainer - INFO - map@10: 0.019811
2025-11-22 22:08:00 - GraphTrainer - INFO - mrr@10: 0.020598
2025-11-22 22:08:00 - GraphTrainer - INFO - precision@20: 0.004225
2025-11-22 22:08:00 - GraphTrainer - INFO - recall@20: 0.080073
2025-11-22 22:08:00 - GraphTrainer - INFO - hit_rate@20: 0.084032
2025-11-22 22:08:00 - GraphTrainer - INFO - ndcg@20: 0.034695
2025-11-22 22:08:00 - GraphTrainer - INFO - map@20: 0.021861
2025-11-22 22:08:00 - GraphTrainer - INFO - mrr@20: 0.022749
2025-11-22 22:08:00 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:08:00 - GraphTrainer - INFO - ============================================================
2025-11-22 22:08:00 - GraphTrainer - INFO - 开始第 170/1000 轮训练
2025-11-22 22:08:00 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3211, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3169, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3202, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3073, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3521, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3219, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3123, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3379, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3081, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3312, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3313, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3147, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3232, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3237, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3150, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3756, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3235, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3258, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3214, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3142, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3273, device='cuda:0', grad_fn=<AddBackward0>)
The 169 training average loss: 0.3333496245844611
2025-11-22 22:08:12 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:08:12 - GraphTrainer - INFO -   precision@5: 0.006675
2025-11-22 22:08:12 - GraphTrainer - INFO -   recall@5: 0.031829
2025-11-22 22:08:12 - GraphTrainer - INFO -   hit_rate@5: 0.033273
2025-11-22 22:08:12 - GraphTrainer - INFO -   ndcg@5: 0.021185
2025-11-22 22:08:12 - GraphTrainer - INFO -   map@5: 0.017454
2025-11-22 22:08:12 - GraphTrainer - INFO -   mrr@5: 0.018130
2025-11-22 22:08:12 - GraphTrainer - INFO -   precision@10: 0.005220
2025-11-22 22:08:12 - GraphTrainer - INFO -   recall@10: 0.049550
2025-11-22 22:08:12 - GraphTrainer - INFO -   hit_rate@10: 0.052044
2025-11-22 22:08:12 - GraphTrainer - INFO -   ndcg@10: 0.026943
2025-11-22 22:08:12 - GraphTrainer - INFO -   map@10: 0.019785
2025-11-22 22:08:12 - GraphTrainer - INFO -   mrr@10: 0.020590
2025-11-22 22:08:12 - GraphTrainer - INFO -   precision@20: 0.004212
2025-11-22 22:08:12 - GraphTrainer - INFO -   recall@20: 0.079877
2025-11-22 22:08:12 - GraphTrainer - INFO -   hit_rate@20: 0.083775
2025-11-22 22:08:12 - GraphTrainer - INFO -   ndcg@20: 0.034632
2025-11-22 22:08:12 - GraphTrainer - INFO -   map@20: 0.021844
2025-11-22 22:08:12 - GraphTrainer - INFO -   mrr@20: 0.022741
2025-11-22 22:08:12 - GraphTrainer - INFO - 第 170 轮训练完成
2025-11-22 22:08:12 - GraphTrainer - INFO - train_loss: 0.333248
2025-11-22 22:08:12 - GraphTrainer - INFO - precision@5: 0.006675
2025-11-22 22:08:12 - GraphTrainer - INFO - recall@5: 0.031829
2025-11-22 22:08:12 - GraphTrainer - INFO - hit_rate@5: 0.033273
2025-11-22 22:08:12 - GraphTrainer - INFO - ndcg@5: 0.021185
2025-11-22 22:08:12 - GraphTrainer - INFO - map@5: 0.017454
2025-11-22 22:08:12 - GraphTrainer - INFO - mrr@5: 0.018130
2025-11-22 22:08:12 - GraphTrainer - INFO - precision@10: 0.005220
2025-11-22 22:08:12 - GraphTrainer - INFO - recall@10: 0.049550
2025-11-22 22:08:12 - GraphTrainer - INFO - hit_rate@10: 0.052044
2025-11-22 22:08:12 - GraphTrainer - INFO - ndcg@10: 0.026943
2025-11-22 22:08:12 - GraphTrainer - INFO - map@10: 0.019785
2025-11-22 22:08:12 - GraphTrainer - INFO - mrr@10: 0.020590
2025-11-22 22:08:12 - GraphTrainer - INFO - precision@20: 0.004212
2025-11-22 22:08:12 - GraphTrainer - INFO - recall@20: 0.079877
2025-11-22 22:08:12 - GraphTrainer - INFO - hit_rate@20: 0.083775
2025-11-22 22:08:12 - GraphTrainer - INFO - ndcg@20: 0.034632
2025-11-22 22:08:12 - GraphTrainer - INFO - map@20: 0.021844
2025-11-22 22:08:12 - GraphTrainer - INFO - mrr@20: 0.022741
2025-11-22 22:08:12 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:08:12 - GraphTrainer - INFO - 检查点已保存: Epoch 170 -> ./checkpoints/checkpoint_epoch_170.pth
2025-11-22 22:08:12 - GraphTrainer - INFO - ============================================================
2025-11-22 22:08:12 - GraphTrainer - INFO - 开始第 171/1000 轮训练
2025-11-22 22:08:12 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3525, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3210, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3183, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3531, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3605, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3121, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3373, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3166, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3468, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3342, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3206, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3373, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3509, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3125, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3262, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3211, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3694, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3202, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3166, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2964, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3095, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3146, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3177, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3141, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3118, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3121, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3214, device='cuda:0', grad_fn=<AddBackward0>)
The 170 training average loss: 0.33324751977262823
2025-11-22 22:08:23 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:08:23 - GraphTrainer - INFO -   precision@5: 0.006675
2025-11-22 22:08:23 - GraphTrainer - INFO -   recall@5: 0.031752
2025-11-22 22:08:23 - GraphTrainer - INFO -   hit_rate@5: 0.033273
2025-11-22 22:08:23 - GraphTrainer - INFO -   ndcg@5: 0.021047
2025-11-22 22:08:23 - GraphTrainer - INFO -   map@5: 0.017289
2025-11-22 22:08:23 - GraphTrainer - INFO -   mrr@5: 0.017960
2025-11-22 22:08:23 - GraphTrainer - INFO -   precision@10: 0.005189
2025-11-22 22:08:23 - GraphTrainer - INFO -   recall@10: 0.049182
2025-11-22 22:08:23 - GraphTrainer - INFO -   hit_rate@10: 0.051736
2025-11-22 22:08:23 - GraphTrainer - INFO -   ndcg@10: 0.026717
2025-11-22 22:08:23 - GraphTrainer - INFO -   map@10: 0.019588
2025-11-22 22:08:23 - GraphTrainer - INFO -   mrr@10: 0.020391
2025-11-22 22:08:23 - GraphTrainer - INFO -   precision@20: 0.004145
2025-11-22 22:08:23 - GraphTrainer - INFO -   recall@20: 0.078527
2025-11-22 22:08:23 - GraphTrainer - INFO -   hit_rate@20: 0.082540
2025-11-22 22:08:23 - GraphTrainer - INFO -   ndcg@20: 0.034182
2025-11-22 22:08:23 - GraphTrainer - INFO -   map@20: 0.021596
2025-11-22 22:08:23 - GraphTrainer - INFO -   mrr@20: 0.022496
2025-11-22 22:08:23 - GraphTrainer - INFO - 第 171 轮训练完成
2025-11-22 22:08:23 - GraphTrainer - INFO - train_loss: 0.335767
2025-11-22 22:08:23 - GraphTrainer - INFO - precision@5: 0.006675
2025-11-22 22:08:23 - GraphTrainer - INFO - recall@5: 0.031752
2025-11-22 22:08:23 - GraphTrainer - INFO - hit_rate@5: 0.033273
2025-11-22 22:08:23 - GraphTrainer - INFO - ndcg@5: 0.021047
2025-11-22 22:08:23 - GraphTrainer - INFO - map@5: 0.017289
2025-11-22 22:08:23 - GraphTrainer - INFO - mrr@5: 0.017960
2025-11-22 22:08:23 - GraphTrainer - INFO - precision@10: 0.005189
2025-11-22 22:08:23 - GraphTrainer - INFO - recall@10: 0.049182
2025-11-22 22:08:23 - GraphTrainer - INFO - hit_rate@10: 0.051736
2025-11-22 22:08:23 - GraphTrainer - INFO - ndcg@10: 0.026717
2025-11-22 22:08:23 - GraphTrainer - INFO - map@10: 0.019588
2025-11-22 22:08:23 - GraphTrainer - INFO - mrr@10: 0.020391
2025-11-22 22:08:23 - GraphTrainer - INFO - precision@20: 0.004145
2025-11-22 22:08:23 - GraphTrainer - INFO - recall@20: 0.078527
2025-11-22 22:08:23 - GraphTrainer - INFO - hit_rate@20: 0.082540
2025-11-22 22:08:23 - GraphTrainer - INFO - ndcg@20: 0.034182
2025-11-22 22:08:23 - GraphTrainer - INFO - map@20: 0.021596
2025-11-22 22:08:23 - GraphTrainer - INFO - mrr@20: 0.022496
2025-11-22 22:08:23 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:08:23 - GraphTrainer - INFO - ============================================================
2025-11-22 22:08:23 - GraphTrainer - INFO - 开始第 172/1000 轮训练
2025-11-22 22:08:23 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3435, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3279, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3601, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3434, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3219, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3260, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3043, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3532, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3233, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3195, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3506, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3235, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3051, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3506, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3379, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3222, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3278, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3331, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3205, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3203, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3254, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
The 171 training average loss: 0.33576730458900844
2025-11-22 22:08:34 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:08:34 - GraphTrainer - INFO -   precision@5: 0.006727
2025-11-22 22:08:34 - GraphTrainer - INFO -   recall@5: 0.032027
2025-11-22 22:08:34 - GraphTrainer - INFO -   hit_rate@5: 0.033530
2025-11-22 22:08:34 - GraphTrainer - INFO -   ndcg@5: 0.021204
2025-11-22 22:08:34 - GraphTrainer - INFO -   map@5: 0.017411
2025-11-22 22:08:34 - GraphTrainer - INFO -   mrr@5: 0.018093
2025-11-22 22:08:34 - GraphTrainer - INFO -   precision@10: 0.005282
2025-11-22 22:08:34 - GraphTrainer - INFO -   recall@10: 0.050095
2025-11-22 22:08:34 - GraphTrainer - INFO -   hit_rate@10: 0.052661
2025-11-22 22:08:34 - GraphTrainer - INFO -   ndcg@10: 0.027061
2025-11-22 22:08:34 - GraphTrainer - INFO -   map@10: 0.019774
2025-11-22 22:08:34 - GraphTrainer - INFO -   mrr@10: 0.020591
2025-11-22 22:08:34 - GraphTrainer - INFO -   precision@20: 0.004142
2025-11-22 22:08:34 - GraphTrainer - INFO -   recall@20: 0.078452
2025-11-22 22:08:34 - GraphTrainer - INFO -   hit_rate@20: 0.082438
2025-11-22 22:08:34 - GraphTrainer - INFO -   ndcg@20: 0.034257
2025-11-22 22:08:34 - GraphTrainer - INFO -   map@20: 0.021699
2025-11-22 22:08:34 - GraphTrainer - INFO -   mrr@20: 0.022606
2025-11-22 22:08:34 - GraphTrainer - INFO - 第 172 轮训练完成
2025-11-22 22:08:34 - GraphTrainer - INFO - train_loss: 0.332473
2025-11-22 22:08:34 - GraphTrainer - INFO - precision@5: 0.006727
2025-11-22 22:08:34 - GraphTrainer - INFO - recall@5: 0.032027
2025-11-22 22:08:34 - GraphTrainer - INFO - hit_rate@5: 0.033530
2025-11-22 22:08:34 - GraphTrainer - INFO - ndcg@5: 0.021204
2025-11-22 22:08:34 - GraphTrainer - INFO - map@5: 0.017411
2025-11-22 22:08:34 - GraphTrainer - INFO - mrr@5: 0.018093
2025-11-22 22:08:34 - GraphTrainer - INFO - precision@10: 0.005282
2025-11-22 22:08:34 - GraphTrainer - INFO - recall@10: 0.050095
2025-11-22 22:08:34 - GraphTrainer - INFO - hit_rate@10: 0.052661
2025-11-22 22:08:34 - GraphTrainer - INFO - ndcg@10: 0.027061
2025-11-22 22:08:34 - GraphTrainer - INFO - map@10: 0.019774
2025-11-22 22:08:34 - GraphTrainer - INFO - mrr@10: 0.020591
2025-11-22 22:08:34 - GraphTrainer - INFO - precision@20: 0.004142
2025-11-22 22:08:34 - GraphTrainer - INFO - recall@20: 0.078452
2025-11-22 22:08:34 - GraphTrainer - INFO - hit_rate@20: 0.082438
2025-11-22 22:08:34 - GraphTrainer - INFO - ndcg@20: 0.034257
2025-11-22 22:08:34 - GraphTrainer - INFO - map@20: 0.021699
2025-11-22 22:08:34 - GraphTrainer - INFO - mrr@20: 0.022606
2025-11-22 22:08:34 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:08:34 - GraphTrainer - INFO - ============================================================
2025-11-22 22:08:34 - GraphTrainer - INFO - 开始第 173/1000 轮训练
2025-11-22 22:08:34 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3484, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3157, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3601, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3217, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3136, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3285, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3288, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3071, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3316, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3547, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3183, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3123, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3304, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3234, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3313, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3297, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3218, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3302, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3200, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3516, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3213, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3174, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3227, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3166, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3233, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3172, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3182, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3557, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
The 172 training average loss: 0.332472857730142
2025-11-22 22:08:45 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:08:45 - GraphTrainer - INFO -   precision@5: 0.006768
2025-11-22 22:08:45 - GraphTrainer - INFO -   recall@5: 0.032257
2025-11-22 22:08:45 - GraphTrainer - INFO -   hit_rate@5: 0.033788
2025-11-22 22:08:45 - GraphTrainer - INFO -   ndcg@5: 0.021239
2025-11-22 22:08:45 - GraphTrainer - INFO -   map@5: 0.017379
2025-11-22 22:08:45 - GraphTrainer - INFO -   mrr@5: 0.018089
2025-11-22 22:08:45 - GraphTrainer - INFO -   precision@10: 0.005292
2025-11-22 22:08:45 - GraphTrainer - INFO -   recall@10: 0.050335
2025-11-22 22:08:45 - GraphTrainer - INFO -   hit_rate@10: 0.052764
2025-11-22 22:08:45 - GraphTrainer - INFO -   ndcg@10: 0.027078
2025-11-22 22:08:45 - GraphTrainer - INFO -   map@10: 0.019731
2025-11-22 22:08:45 - GraphTrainer - INFO -   mrr@10: 0.020550
2025-11-22 22:08:45 - GraphTrainer - INFO -   precision@20: 0.004160
2025-11-22 22:08:45 - GraphTrainer - INFO -   recall@20: 0.079037
2025-11-22 22:08:45 - GraphTrainer - INFO -   hit_rate@20: 0.082900
2025-11-22 22:08:45 - GraphTrainer - INFO -   ndcg@20: 0.034351
2025-11-22 22:08:45 - GraphTrainer - INFO -   map@20: 0.021671
2025-11-22 22:08:45 - GraphTrainer - INFO -   mrr@20: 0.022588
2025-11-22 22:08:45 - GraphTrainer - INFO - 第 173 轮训练完成
2025-11-22 22:08:45 - GraphTrainer - INFO - train_loss: 0.332528
2025-11-22 22:08:45 - GraphTrainer - INFO - precision@5: 0.006768
2025-11-22 22:08:45 - GraphTrainer - INFO - recall@5: 0.032257
2025-11-22 22:08:45 - GraphTrainer - INFO - hit_rate@5: 0.033788
2025-11-22 22:08:45 - GraphTrainer - INFO - ndcg@5: 0.021239
2025-11-22 22:08:45 - GraphTrainer - INFO - map@5: 0.017379
2025-11-22 22:08:45 - GraphTrainer - INFO - mrr@5: 0.018089
2025-11-22 22:08:45 - GraphTrainer - INFO - precision@10: 0.005292
2025-11-22 22:08:45 - GraphTrainer - INFO - recall@10: 0.050335
2025-11-22 22:08:45 - GraphTrainer - INFO - hit_rate@10: 0.052764
2025-11-22 22:08:45 - GraphTrainer - INFO - ndcg@10: 0.027078
2025-11-22 22:08:45 - GraphTrainer - INFO - map@10: 0.019731
2025-11-22 22:08:45 - GraphTrainer - INFO - mrr@10: 0.020550
2025-11-22 22:08:45 - GraphTrainer - INFO - precision@20: 0.004160
2025-11-22 22:08:45 - GraphTrainer - INFO - recall@20: 0.079037
2025-11-22 22:08:45 - GraphTrainer - INFO - hit_rate@20: 0.082900
2025-11-22 22:08:45 - GraphTrainer - INFO - ndcg@20: 0.034351
2025-11-22 22:08:45 - GraphTrainer - INFO - map@20: 0.021671
2025-11-22 22:08:45 - GraphTrainer - INFO - mrr@20: 0.022588
2025-11-22 22:08:45 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:08:45 - GraphTrainer - INFO - ============================================================
2025-11-22 22:08:45 - GraphTrainer - INFO - 开始第 174/1000 轮训练
2025-11-22 22:08:45 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3260, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3198, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3112, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3154, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3197, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3164, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3211, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3713, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3313, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3249, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3293, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3194, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3569, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3180, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3282, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3318, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3232, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3252, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3180, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3176, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3281, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3160, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3611, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3268, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3141, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3129, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
The 173 training average loss: 0.3325275516715543
2025-11-22 22:08:56 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:08:56 - GraphTrainer - INFO -   precision@5: 0.006675
2025-11-22 22:08:56 - GraphTrainer - INFO -   recall@5: 0.031843
2025-11-22 22:08:56 - GraphTrainer - INFO -   hit_rate@5: 0.033273
2025-11-22 22:08:56 - GraphTrainer - INFO -   ndcg@5: 0.021047
2025-11-22 22:08:56 - GraphTrainer - INFO -   map@5: 0.017268
2025-11-22 22:08:56 - GraphTrainer - INFO -   mrr@5: 0.017921
2025-11-22 22:08:56 - GraphTrainer - INFO -   precision@10: 0.005302
2025-11-22 22:08:56 - GraphTrainer - INFO -   recall@10: 0.050437
2025-11-22 22:08:56 - GraphTrainer - INFO -   hit_rate@10: 0.052918
2025-11-22 22:08:56 - GraphTrainer - INFO -   ndcg@10: 0.027087
2025-11-22 22:08:56 - GraphTrainer - INFO -   map@10: 0.019714
2025-11-22 22:08:56 - GraphTrainer - INFO -   mrr@10: 0.020506
2025-11-22 22:08:56 - GraphTrainer - INFO -   precision@20: 0.004191
2025-11-22 22:08:56 - GraphTrainer - INFO -   recall@20: 0.079403
2025-11-22 22:08:56 - GraphTrainer - INFO -   hit_rate@20: 0.083415
2025-11-22 22:08:56 - GraphTrainer - INFO -   ndcg@20: 0.034432
2025-11-22 22:08:56 - GraphTrainer - INFO -   map@20: 0.021672
2025-11-22 22:08:56 - GraphTrainer - INFO -   mrr@20: 0.022564
2025-11-22 22:08:56 - GraphTrainer - INFO - 第 174 轮训练完成
2025-11-22 22:08:56 - GraphTrainer - INFO - train_loss: 0.333471
2025-11-22 22:08:56 - GraphTrainer - INFO - precision@5: 0.006675
2025-11-22 22:08:56 - GraphTrainer - INFO - recall@5: 0.031843
2025-11-22 22:08:56 - GraphTrainer - INFO - hit_rate@5: 0.033273
2025-11-22 22:08:56 - GraphTrainer - INFO - ndcg@5: 0.021047
2025-11-22 22:08:56 - GraphTrainer - INFO - map@5: 0.017268
2025-11-22 22:08:56 - GraphTrainer - INFO - mrr@5: 0.017921
2025-11-22 22:08:56 - GraphTrainer - INFO - precision@10: 0.005302
2025-11-22 22:08:56 - GraphTrainer - INFO - recall@10: 0.050437
2025-11-22 22:08:56 - GraphTrainer - INFO - hit_rate@10: 0.052918
2025-11-22 22:08:56 - GraphTrainer - INFO - ndcg@10: 0.027087
2025-11-22 22:08:56 - GraphTrainer - INFO - map@10: 0.019714
2025-11-22 22:08:56 - GraphTrainer - INFO - mrr@10: 0.020506
2025-11-22 22:08:56 - GraphTrainer - INFO - precision@20: 0.004191
2025-11-22 22:08:56 - GraphTrainer - INFO - recall@20: 0.079403
2025-11-22 22:08:56 - GraphTrainer - INFO - hit_rate@20: 0.083415
2025-11-22 22:08:56 - GraphTrainer - INFO - ndcg@20: 0.034432
2025-11-22 22:08:56 - GraphTrainer - INFO - map@20: 0.021672
2025-11-22 22:08:56 - GraphTrainer - INFO - mrr@20: 0.022564
2025-11-22 22:08:56 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:08:56 - GraphTrainer - INFO - ============================================================
2025-11-22 22:08:56 - GraphTrainer - INFO - 开始第 175/1000 轮训练
2025-11-22 22:08:56 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3033, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3433, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3313, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3679, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3214, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3117, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3544, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3005, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3204, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3133, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3037, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3210, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3288, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3506, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3260, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3646, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3176, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3574, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3205, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3173, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3273, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3249, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3605, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3293, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3342, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3205, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3288, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3379, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3246, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3434, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
The 174 training average loss: 0.3334712288502989
2025-11-22 22:09:07 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:09:07 - GraphTrainer - INFO -   precision@5: 0.006809
2025-11-22 22:09:07 - GraphTrainer - INFO -   recall@5: 0.032469
2025-11-22 22:09:07 - GraphTrainer - INFO -   hit_rate@5: 0.033942
2025-11-22 22:09:07 - GraphTrainer - INFO -   ndcg@5: 0.021489
2025-11-22 22:09:07 - GraphTrainer - INFO -   map@5: 0.017648
2025-11-22 22:09:07 - GraphTrainer - INFO -   mrr@5: 0.018313
2025-11-22 22:09:07 - GraphTrainer - INFO -   precision@10: 0.005266
2025-11-22 22:09:07 - GraphTrainer - INFO -   recall@10: 0.050180
2025-11-22 22:09:07 - GraphTrainer - INFO -   hit_rate@10: 0.052558
2025-11-22 22:09:07 - GraphTrainer - INFO -   ndcg@10: 0.027220
2025-11-22 22:09:07 - GraphTrainer - INFO -   map@10: 0.019962
2025-11-22 22:09:07 - GraphTrainer - INFO -   mrr@10: 0.020750
2025-11-22 22:09:07 - GraphTrainer - INFO -   precision@20: 0.004142
2025-11-22 22:09:07 - GraphTrainer - INFO -   recall@20: 0.078462
2025-11-22 22:09:07 - GraphTrainer - INFO -   hit_rate@20: 0.082489
2025-11-22 22:09:07 - GraphTrainer - INFO -   ndcg@20: 0.034417
2025-11-22 22:09:07 - GraphTrainer - INFO -   map@20: 0.021888
2025-11-22 22:09:07 - GraphTrainer - INFO -   mrr@20: 0.022787
2025-11-22 22:09:07 - GraphTrainer - INFO - 第 175 轮训练完成
2025-11-22 22:09:07 - GraphTrainer - INFO - train_loss: 0.332977
2025-11-22 22:09:07 - GraphTrainer - INFO - precision@5: 0.006809
2025-11-22 22:09:07 - GraphTrainer - INFO - recall@5: 0.032469
2025-11-22 22:09:07 - GraphTrainer - INFO - hit_rate@5: 0.033942
2025-11-22 22:09:07 - GraphTrainer - INFO - ndcg@5: 0.021489
2025-11-22 22:09:07 - GraphTrainer - INFO - map@5: 0.017648
2025-11-22 22:09:07 - GraphTrainer - INFO - mrr@5: 0.018313
2025-11-22 22:09:07 - GraphTrainer - INFO - precision@10: 0.005266
2025-11-22 22:09:07 - GraphTrainer - INFO - recall@10: 0.050180
2025-11-22 22:09:07 - GraphTrainer - INFO - hit_rate@10: 0.052558
2025-11-22 22:09:07 - GraphTrainer - INFO - ndcg@10: 0.027220
2025-11-22 22:09:07 - GraphTrainer - INFO - map@10: 0.019962
2025-11-22 22:09:07 - GraphTrainer - INFO - mrr@10: 0.020750
2025-11-22 22:09:07 - GraphTrainer - INFO - precision@20: 0.004142
2025-11-22 22:09:07 - GraphTrainer - INFO - recall@20: 0.078462
2025-11-22 22:09:07 - GraphTrainer - INFO - hit_rate@20: 0.082489
2025-11-22 22:09:07 - GraphTrainer - INFO - ndcg@20: 0.034417
2025-11-22 22:09:07 - GraphTrainer - INFO - map@20: 0.021888
2025-11-22 22:09:07 - GraphTrainer - INFO - mrr@20: 0.022787
2025-11-22 22:09:07 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:09:07 - GraphTrainer - INFO - ============================================================
2025-11-22 22:09:07 - GraphTrainer - INFO - 开始第 176/1000 轮训练
2025-11-22 22:09:07 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3435, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3316, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3502, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3188, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3258, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3490, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3083, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3178, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3259, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3113, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3209, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3233, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3309, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3211, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3281, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3083, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3198, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3181, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3333, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3089, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3566, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3194, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3181, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3256, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
The 175 training average loss: 0.3329766382431162
2025-11-22 22:09:18 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:09:18 - GraphTrainer - INFO -   precision@5: 0.006747
2025-11-22 22:09:18 - GraphTrainer - INFO -   recall@5: 0.032245
2025-11-22 22:09:18 - GraphTrainer - INFO -   hit_rate@5: 0.033685
2025-11-22 22:09:18 - GraphTrainer - INFO -   ndcg@5: 0.021377
2025-11-22 22:09:18 - GraphTrainer - INFO -   map@5: 0.017575
2025-11-22 22:09:18 - GraphTrainer - INFO -   mrr@5: 0.018244
2025-11-22 22:09:18 - GraphTrainer - INFO -   precision@10: 0.005266
2025-11-22 22:09:18 - GraphTrainer - INFO -   recall@10: 0.049953
2025-11-22 22:09:18 - GraphTrainer - INFO -   hit_rate@10: 0.052507
2025-11-22 22:09:18 - GraphTrainer - INFO -   ndcg@10: 0.027120
2025-11-22 22:09:18 - GraphTrainer - INFO -   map@10: 0.019885
2025-11-22 22:09:18 - GraphTrainer - INFO -   mrr@10: 0.020698
2025-11-22 22:09:18 - GraphTrainer - INFO -   precision@20: 0.004153
2025-11-22 22:09:18 - GraphTrainer - INFO -   recall@20: 0.078552
2025-11-22 22:09:18 - GraphTrainer - INFO -   hit_rate@20: 0.082643
2025-11-22 22:09:18 - GraphTrainer - INFO -   ndcg@20: 0.034387
2025-11-22 22:09:18 - GraphTrainer - INFO -   map@20: 0.021831
2025-11-22 22:09:18 - GraphTrainer - INFO -   mrr@20: 0.022743
2025-11-22 22:09:18 - GraphTrainer - INFO - 第 176 轮训练完成
2025-11-22 22:09:18 - GraphTrainer - INFO - train_loss: 0.333239
2025-11-22 22:09:18 - GraphTrainer - INFO - precision@5: 0.006747
2025-11-22 22:09:18 - GraphTrainer - INFO - recall@5: 0.032245
2025-11-22 22:09:18 - GraphTrainer - INFO - hit_rate@5: 0.033685
2025-11-22 22:09:18 - GraphTrainer - INFO - ndcg@5: 0.021377
2025-11-22 22:09:18 - GraphTrainer - INFO - map@5: 0.017575
2025-11-22 22:09:18 - GraphTrainer - INFO - mrr@5: 0.018244
2025-11-22 22:09:18 - GraphTrainer - INFO - precision@10: 0.005266
2025-11-22 22:09:18 - GraphTrainer - INFO - recall@10: 0.049953
2025-11-22 22:09:18 - GraphTrainer - INFO - hit_rate@10: 0.052507
2025-11-22 22:09:18 - GraphTrainer - INFO - ndcg@10: 0.027120
2025-11-22 22:09:18 - GraphTrainer - INFO - map@10: 0.019885
2025-11-22 22:09:18 - GraphTrainer - INFO - mrr@10: 0.020698
2025-11-22 22:09:18 - GraphTrainer - INFO - precision@20: 0.004153
2025-11-22 22:09:18 - GraphTrainer - INFO - recall@20: 0.078552
2025-11-22 22:09:18 - GraphTrainer - INFO - hit_rate@20: 0.082643
2025-11-22 22:09:18 - GraphTrainer - INFO - ndcg@20: 0.034387
2025-11-22 22:09:18 - GraphTrainer - INFO - map@20: 0.021831
2025-11-22 22:09:18 - GraphTrainer - INFO - mrr@20: 0.022743
2025-11-22 22:09:18 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:09:18 - GraphTrainer - INFO - ============================================================
2025-11-22 22:09:18 - GraphTrainer - INFO - 开始第 177/1000 轮训练
2025-11-22 22:09:18 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3170, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3151, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3225, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3155, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3184, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3197, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3151, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3276, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3518, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3296, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3509, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3532, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3205, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3192, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3160, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3312, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3133, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3239, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3194, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3215, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3163, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3290, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3099, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3619, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3575, device='cuda:0', grad_fn=<AddBackward0>)
The 176 training average loss: 0.33323887966830157
2025-11-22 22:09:29 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:09:29 - GraphTrainer - INFO -   precision@5: 0.006747
2025-11-22 22:09:29 - GraphTrainer - INFO -   recall@5: 0.032163
2025-11-22 22:09:29 - GraphTrainer - INFO -   hit_rate@5: 0.033685
2025-11-22 22:09:29 - GraphTrainer - INFO -   ndcg@5: 0.021128
2025-11-22 22:09:29 - GraphTrainer - INFO -   map@5: 0.017264
2025-11-22 22:09:29 - GraphTrainer - INFO -   mrr@5: 0.017947
2025-11-22 22:09:29 - GraphTrainer - INFO -   precision@10: 0.005210
2025-11-22 22:09:29 - GraphTrainer - INFO -   recall@10: 0.049416
2025-11-22 22:09:29 - GraphTrainer - INFO -   hit_rate@10: 0.051890
2025-11-22 22:09:29 - GraphTrainer - INFO -   ndcg@10: 0.026759
2025-11-22 22:09:29 - GraphTrainer - INFO -   map@10: 0.019559
2025-11-22 22:09:29 - GraphTrainer - INFO -   mrr@10: 0.020360
2025-11-22 22:09:29 - GraphTrainer - INFO -   precision@20: 0.004155
2025-11-22 22:09:29 - GraphTrainer - INFO -   recall@20: 0.078725
2025-11-22 22:09:29 - GraphTrainer - INFO -   hit_rate@20: 0.082643
2025-11-22 22:09:29 - GraphTrainer - INFO -   ndcg@20: 0.034236
2025-11-22 22:09:29 - GraphTrainer - INFO -   map@20: 0.021580
2025-11-22 22:09:29 - GraphTrainer - INFO -   mrr@20: 0.022479
2025-11-22 22:09:29 - GraphTrainer - INFO - 第 177 轮训练完成
2025-11-22 22:09:29 - GraphTrainer - INFO - train_loss: 0.334635
2025-11-22 22:09:29 - GraphTrainer - INFO - precision@5: 0.006747
2025-11-22 22:09:29 - GraphTrainer - INFO - recall@5: 0.032163
2025-11-22 22:09:29 - GraphTrainer - INFO - hit_rate@5: 0.033685
2025-11-22 22:09:29 - GraphTrainer - INFO - ndcg@5: 0.021128
2025-11-22 22:09:29 - GraphTrainer - INFO - map@5: 0.017264
2025-11-22 22:09:29 - GraphTrainer - INFO - mrr@5: 0.017947
2025-11-22 22:09:29 - GraphTrainer - INFO - precision@10: 0.005210
2025-11-22 22:09:29 - GraphTrainer - INFO - recall@10: 0.049416
2025-11-22 22:09:29 - GraphTrainer - INFO - hit_rate@10: 0.051890
2025-11-22 22:09:29 - GraphTrainer - INFO - ndcg@10: 0.026759
2025-11-22 22:09:29 - GraphTrainer - INFO - map@10: 0.019559
2025-11-22 22:09:29 - GraphTrainer - INFO - mrr@10: 0.020360
2025-11-22 22:09:29 - GraphTrainer - INFO - precision@20: 0.004155
2025-11-22 22:09:29 - GraphTrainer - INFO - recall@20: 0.078725
2025-11-22 22:09:29 - GraphTrainer - INFO - hit_rate@20: 0.082643
2025-11-22 22:09:29 - GraphTrainer - INFO - ndcg@20: 0.034236
2025-11-22 22:09:29 - GraphTrainer - INFO - map@20: 0.021580
2025-11-22 22:09:29 - GraphTrainer - INFO - mrr@20: 0.022479
2025-11-22 22:09:29 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:09:29 - GraphTrainer - INFO - ============================================================
2025-11-22 22:09:29 - GraphTrainer - INFO - 开始第 178/1000 轮训练
2025-11-22 22:09:29 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3333, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3421, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3502, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3276, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3421, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3162, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3565, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3179, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3559, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3278, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3281, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3180, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3169, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3114, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3597, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3278, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3215, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3137, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3509, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3249, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3249, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3245, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3284, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3065, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3231, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3533, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3299, device='cuda:0', grad_fn=<AddBackward0>)
The 177 training average loss: 0.33463515752348405
2025-11-22 22:09:40 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:09:40 - GraphTrainer - INFO -   precision@5: 0.006696
2025-11-22 22:09:40 - GraphTrainer - INFO -   recall@5: 0.031907
2025-11-22 22:09:40 - GraphTrainer - INFO -   hit_rate@5: 0.033376
2025-11-22 22:09:40 - GraphTrainer - INFO -   ndcg@5: 0.021060
2025-11-22 22:09:40 - GraphTrainer - INFO -   map@5: 0.017255
2025-11-22 22:09:40 - GraphTrainer - INFO -   mrr@5: 0.017927
2025-11-22 22:09:40 - GraphTrainer - INFO -   precision@10: 0.005287
2025-11-22 22:09:40 - GraphTrainer - INFO -   recall@10: 0.050106
2025-11-22 22:09:40 - GraphTrainer - INFO -   hit_rate@10: 0.052713
2025-11-22 22:09:40 - GraphTrainer - INFO -   ndcg@10: 0.026954
2025-11-22 22:09:40 - GraphTrainer - INFO -   map@10: 0.019624
2025-11-22 22:09:40 - GraphTrainer - INFO -   mrr@10: 0.020444
2025-11-22 22:09:40 - GraphTrainer - INFO -   precision@20: 0.004184
2025-11-22 22:09:40 - GraphTrainer - INFO -   recall@20: 0.079212
2025-11-22 22:09:40 - GraphTrainer - INFO -   hit_rate@20: 0.083260
2025-11-22 22:09:40 - GraphTrainer - INFO -   ndcg@20: 0.034314
2025-11-22 22:09:40 - GraphTrainer - INFO -   map@20: 0.021581
2025-11-22 22:09:40 - GraphTrainer - INFO -   mrr@20: 0.022489
2025-11-22 22:09:40 - GraphTrainer - INFO - 第 178 轮训练完成
2025-11-22 22:09:40 - GraphTrainer - INFO - train_loss: 0.333488
2025-11-22 22:09:40 - GraphTrainer - INFO - precision@5: 0.006696
2025-11-22 22:09:40 - GraphTrainer - INFO - recall@5: 0.031907
2025-11-22 22:09:40 - GraphTrainer - INFO - hit_rate@5: 0.033376
2025-11-22 22:09:40 - GraphTrainer - INFO - ndcg@5: 0.021060
2025-11-22 22:09:40 - GraphTrainer - INFO - map@5: 0.017255
2025-11-22 22:09:40 - GraphTrainer - INFO - mrr@5: 0.017927
2025-11-22 22:09:40 - GraphTrainer - INFO - precision@10: 0.005287
2025-11-22 22:09:40 - GraphTrainer - INFO - recall@10: 0.050106
2025-11-22 22:09:40 - GraphTrainer - INFO - hit_rate@10: 0.052713
2025-11-22 22:09:40 - GraphTrainer - INFO - ndcg@10: 0.026954
2025-11-22 22:09:40 - GraphTrainer - INFO - map@10: 0.019624
2025-11-22 22:09:40 - GraphTrainer - INFO - mrr@10: 0.020444
2025-11-22 22:09:40 - GraphTrainer - INFO - precision@20: 0.004184
2025-11-22 22:09:40 - GraphTrainer - INFO - recall@20: 0.079212
2025-11-22 22:09:40 - GraphTrainer - INFO - hit_rate@20: 0.083260
2025-11-22 22:09:40 - GraphTrainer - INFO - ndcg@20: 0.034314
2025-11-22 22:09:40 - GraphTrainer - INFO - map@20: 0.021581
2025-11-22 22:09:40 - GraphTrainer - INFO - mrr@20: 0.022489
2025-11-22 22:09:40 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:09:40 - GraphTrainer - INFO - ============================================================
2025-11-22 22:09:40 - GraphTrainer - INFO - 开始第 179/1000 轮训练
2025-11-22 22:09:40 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3639, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3192, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3216, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3148, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3187, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3512, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3230, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3467, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3182, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3274, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3231, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3167, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3124, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3192, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3296, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3204, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3494, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3056, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3464, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3190, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3550, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3233, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3299, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3197, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3331, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3214, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3462, device='cuda:0', grad_fn=<AddBackward0>)
The 178 training average loss: 0.3334884674384676
2025-11-22 22:09:51 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:09:51 - GraphTrainer - INFO -   precision@5: 0.006624
2025-11-22 22:09:51 - GraphTrainer - INFO -   recall@5: 0.031516
2025-11-22 22:09:51 - GraphTrainer - INFO -   hit_rate@5: 0.033016
2025-11-22 22:09:51 - GraphTrainer - INFO -   ndcg@5: 0.020745
2025-11-22 22:09:51 - GraphTrainer - INFO -   map@5: 0.016962
2025-11-22 22:09:51 - GraphTrainer - INFO -   mrr@5: 0.017651
2025-11-22 22:09:51 - GraphTrainer - INFO -   precision@10: 0.005271
2025-11-22 22:09:51 - GraphTrainer - INFO -   recall@10: 0.050102
2025-11-22 22:09:51 - GraphTrainer - INFO -   hit_rate@10: 0.052507
2025-11-22 22:09:51 - GraphTrainer - INFO -   ndcg@10: 0.026767
2025-11-22 22:09:51 - GraphTrainer - INFO -   map@10: 0.019400
2025-11-22 22:09:51 - GraphTrainer - INFO -   mrr@10: 0.020207
2025-11-22 22:09:51 - GraphTrainer - INFO -   precision@20: 0.004163
2025-11-22 22:09:51 - GraphTrainer - INFO -   recall@20: 0.078885
2025-11-22 22:09:51 - GraphTrainer - INFO -   hit_rate@20: 0.082900
2025-11-22 22:09:51 - GraphTrainer - INFO -   ndcg@20: 0.034060
2025-11-22 22:09:51 - GraphTrainer - INFO -   map@20: 0.021339
2025-11-22 22:09:51 - GraphTrainer - INFO -   mrr@20: 0.022253
2025-11-22 22:09:51 - GraphTrainer - INFO - 第 179 轮训练完成
2025-11-22 22:09:51 - GraphTrainer - INFO - train_loss: 0.333783
2025-11-22 22:09:51 - GraphTrainer - INFO - precision@5: 0.006624
2025-11-22 22:09:51 - GraphTrainer - INFO - recall@5: 0.031516
2025-11-22 22:09:51 - GraphTrainer - INFO - hit_rate@5: 0.033016
2025-11-22 22:09:51 - GraphTrainer - INFO - ndcg@5: 0.020745
2025-11-22 22:09:51 - GraphTrainer - INFO - map@5: 0.016962
2025-11-22 22:09:51 - GraphTrainer - INFO - mrr@5: 0.017651
2025-11-22 22:09:51 - GraphTrainer - INFO - precision@10: 0.005271
2025-11-22 22:09:51 - GraphTrainer - INFO - recall@10: 0.050102
2025-11-22 22:09:51 - GraphTrainer - INFO - hit_rate@10: 0.052507
2025-11-22 22:09:51 - GraphTrainer - INFO - ndcg@10: 0.026767
2025-11-22 22:09:51 - GraphTrainer - INFO - map@10: 0.019400
2025-11-22 22:09:51 - GraphTrainer - INFO - mrr@10: 0.020207
2025-11-22 22:09:51 - GraphTrainer - INFO - precision@20: 0.004163
2025-11-22 22:09:51 - GraphTrainer - INFO - recall@20: 0.078885
2025-11-22 22:09:51 - GraphTrainer - INFO - hit_rate@20: 0.082900
2025-11-22 22:09:51 - GraphTrainer - INFO - ndcg@20: 0.034060
2025-11-22 22:09:51 - GraphTrainer - INFO - map@20: 0.021339
2025-11-22 22:09:51 - GraphTrainer - INFO - mrr@20: 0.022253
2025-11-22 22:09:51 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:09:51 - GraphTrainer - INFO - ============================================================
2025-11-22 22:09:51 - GraphTrainer - INFO - 开始第 180/1000 轮训练
2025-11-22 22:09:51 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3226, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3181, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3227, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3231, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3180, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2998, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3263, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3559, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3580, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3262, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3212, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3263, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3025, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3195, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3150, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3699, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3200, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3220, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3254, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3233, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3212, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3187, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3060, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3279, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3201, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)
The 179 training average loss: 0.3337828033956988
2025-11-22 22:10:02 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:10:02 - GraphTrainer - INFO -   precision@5: 0.006675
2025-11-22 22:10:02 - GraphTrainer - INFO -   recall@5: 0.031708
2025-11-22 22:10:02 - GraphTrainer - INFO -   hit_rate@5: 0.033273
2025-11-22 22:10:02 - GraphTrainer - INFO -   ndcg@5: 0.021051
2025-11-22 22:10:02 - GraphTrainer - INFO -   map@5: 0.017294
2025-11-22 22:10:02 - GraphTrainer - INFO -   mrr@5: 0.017985
2025-11-22 22:10:02 - GraphTrainer - INFO -   precision@10: 0.005292
2025-11-22 22:10:02 - GraphTrainer - INFO -   recall@10: 0.050252
2025-11-22 22:10:02 - GraphTrainer - INFO -   hit_rate@10: 0.052713
2025-11-22 22:10:02 - GraphTrainer - INFO -   ndcg@10: 0.027042
2025-11-22 22:10:02 - GraphTrainer - INFO -   map@10: 0.019706
2025-11-22 22:10:02 - GraphTrainer - INFO -   mrr@10: 0.020516
2025-11-22 22:10:02 - GraphTrainer - INFO -   precision@20: 0.004130
2025-11-22 22:10:02 - GraphTrainer - INFO -   recall@20: 0.078162
2025-11-22 22:10:02 - GraphTrainer - INFO -   hit_rate@20: 0.082078
2025-11-22 22:10:02 - GraphTrainer - INFO -   ndcg@20: 0.034149
2025-11-22 22:10:02 - GraphTrainer - INFO -   map@20: 0.021617
2025-11-22 22:10:02 - GraphTrainer - INFO -   mrr@20: 0.022524
2025-11-22 22:10:02 - GraphTrainer - INFO - 第 180 轮训练完成
2025-11-22 22:10:02 - GraphTrainer - INFO - train_loss: 0.334812
2025-11-22 22:10:02 - GraphTrainer - INFO - precision@5: 0.006675
2025-11-22 22:10:02 - GraphTrainer - INFO - recall@5: 0.031708
2025-11-22 22:10:02 - GraphTrainer - INFO - hit_rate@5: 0.033273
2025-11-22 22:10:02 - GraphTrainer - INFO - ndcg@5: 0.021051
2025-11-22 22:10:02 - GraphTrainer - INFO - map@5: 0.017294
2025-11-22 22:10:02 - GraphTrainer - INFO - mrr@5: 0.017985
2025-11-22 22:10:02 - GraphTrainer - INFO - precision@10: 0.005292
2025-11-22 22:10:02 - GraphTrainer - INFO - recall@10: 0.050252
2025-11-22 22:10:02 - GraphTrainer - INFO - hit_rate@10: 0.052713
2025-11-22 22:10:02 - GraphTrainer - INFO - ndcg@10: 0.027042
2025-11-22 22:10:02 - GraphTrainer - INFO - map@10: 0.019706
2025-11-22 22:10:02 - GraphTrainer - INFO - mrr@10: 0.020516
2025-11-22 22:10:02 - GraphTrainer - INFO - precision@20: 0.004130
2025-11-22 22:10:02 - GraphTrainer - INFO - recall@20: 0.078162
2025-11-22 22:10:02 - GraphTrainer - INFO - hit_rate@20: 0.082078
2025-11-22 22:10:02 - GraphTrainer - INFO - ndcg@20: 0.034149
2025-11-22 22:10:02 - GraphTrainer - INFO - map@20: 0.021617
2025-11-22 22:10:02 - GraphTrainer - INFO - mrr@20: 0.022524
2025-11-22 22:10:02 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:10:02 - GraphTrainer - INFO - 检查点已保存: Epoch 180 -> ./checkpoints/checkpoint_epoch_180.pth
2025-11-22 22:10:02 - GraphTrainer - INFO - ============================================================
2025-11-22 22:10:02 - GraphTrainer - INFO - 开始第 181/1000 轮训练
2025-11-22 22:10:02 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3227, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3631, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3257, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3297, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3318, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3268, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3245, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3158, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3244, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3216, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3512, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3331, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3274, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3597, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3290, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3137, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3313, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3175, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3263, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3240, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3169, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
The 180 training average loss: 0.33481156414952773
2025-11-22 22:10:14 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:10:14 - GraphTrainer - INFO -   precision@5: 0.006634
2025-11-22 22:10:14 - GraphTrainer - INFO -   recall@5: 0.031515
2025-11-22 22:10:14 - GraphTrainer - INFO -   hit_rate@5: 0.033119
2025-11-22 22:10:14 - GraphTrainer - INFO -   ndcg@5: 0.020985
2025-11-22 22:10:14 - GraphTrainer - INFO -   map@5: 0.017260
2025-11-22 22:10:14 - GraphTrainer - INFO -   mrr@5: 0.017962
2025-11-22 22:10:14 - GraphTrainer - INFO -   precision@10: 0.005312
2025-11-22 22:10:14 - GraphTrainer - INFO -   recall@10: 0.050325
2025-11-22 22:10:14 - GraphTrainer - INFO -   hit_rate@10: 0.052918
2025-11-22 22:10:14 - GraphTrainer - INFO -   ndcg@10: 0.027079
2025-11-22 22:10:14 - GraphTrainer - INFO -   map@10: 0.019720
2025-11-22 22:10:14 - GraphTrainer - INFO -   mrr@10: 0.020546
2025-11-22 22:10:14 - GraphTrainer - INFO -   precision@20: 0.004181
2025-11-22 22:10:14 - GraphTrainer - INFO -   recall@20: 0.079061
2025-11-22 22:10:14 - GraphTrainer - INFO -   hit_rate@20: 0.083106
2025-11-22 22:10:14 - GraphTrainer - INFO -   ndcg@20: 0.034377
2025-11-22 22:10:14 - GraphTrainer - INFO -   map@20: 0.021674
2025-11-22 22:10:14 - GraphTrainer - INFO -   mrr@20: 0.022595
2025-11-22 22:10:14 - GraphTrainer - INFO - 第 181 轮训练完成
2025-11-22 22:10:14 - GraphTrainer - INFO - train_loss: 0.329374
2025-11-22 22:10:14 - GraphTrainer - INFO - precision@5: 0.006634
2025-11-22 22:10:14 - GraphTrainer - INFO - recall@5: 0.031515
2025-11-22 22:10:14 - GraphTrainer - INFO - hit_rate@5: 0.033119
2025-11-22 22:10:14 - GraphTrainer - INFO - ndcg@5: 0.020985
2025-11-22 22:10:14 - GraphTrainer - INFO - map@5: 0.017260
2025-11-22 22:10:14 - GraphTrainer - INFO - mrr@5: 0.017962
2025-11-22 22:10:14 - GraphTrainer - INFO - precision@10: 0.005312
2025-11-22 22:10:14 - GraphTrainer - INFO - recall@10: 0.050325
2025-11-22 22:10:14 - GraphTrainer - INFO - hit_rate@10: 0.052918
2025-11-22 22:10:14 - GraphTrainer - INFO - ndcg@10: 0.027079
2025-11-22 22:10:14 - GraphTrainer - INFO - map@10: 0.019720
2025-11-22 22:10:14 - GraphTrainer - INFO - mrr@10: 0.020546
2025-11-22 22:10:14 - GraphTrainer - INFO - precision@20: 0.004181
2025-11-22 22:10:14 - GraphTrainer - INFO - recall@20: 0.079061
2025-11-22 22:10:14 - GraphTrainer - INFO - hit_rate@20: 0.083106
2025-11-22 22:10:14 - GraphTrainer - INFO - ndcg@20: 0.034377
2025-11-22 22:10:14 - GraphTrainer - INFO - map@20: 0.021674
2025-11-22 22:10:14 - GraphTrainer - INFO - mrr@20: 0.022595
2025-11-22 22:10:14 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:10:14 - GraphTrainer - INFO - ============================================================
2025-11-22 22:10:14 - GraphTrainer - INFO - 开始第 182/1000 轮训练
2025-11-22 22:10:14 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3282, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3157, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3518, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3048, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3239, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3327, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3190, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3218, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3512, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3182, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3205, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3203, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3194, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3234, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3534, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3129, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3143, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3155, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3236, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3281, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3220, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3127, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3029, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3142, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3207, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3176, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3209, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3212, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3262, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3138, device='cuda:0', grad_fn=<AddBackward0>)
The 181 training average loss: 0.3293743431568146
2025-11-22 22:10:24 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:10:24 - GraphTrainer - INFO -   precision@5: 0.006686
2025-11-22 22:10:24 - GraphTrainer - INFO -   recall@5: 0.031726
2025-11-22 22:10:24 - GraphTrainer - INFO -   hit_rate@5: 0.033325
2025-11-22 22:10:24 - GraphTrainer - INFO -   ndcg@5: 0.021081
2025-11-22 22:10:24 - GraphTrainer - INFO -   map@5: 0.017324
2025-11-22 22:10:24 - GraphTrainer - INFO -   mrr@5: 0.017999
2025-11-22 22:10:24 - GraphTrainer - INFO -   precision@10: 0.005292
2025-11-22 22:10:24 - GraphTrainer - INFO -   recall@10: 0.050188
2025-11-22 22:10:24 - GraphTrainer - INFO -   hit_rate@10: 0.052713
2025-11-22 22:10:24 - GraphTrainer - INFO -   ndcg@10: 0.027066
2025-11-22 22:10:24 - GraphTrainer - INFO -   map@10: 0.019747
2025-11-22 22:10:24 - GraphTrainer - INFO -   mrr@10: 0.020538
2025-11-22 22:10:24 - GraphTrainer - INFO -   precision@20: 0.004194
2025-11-22 22:10:24 - GraphTrainer - INFO -   recall@20: 0.079353
2025-11-22 22:10:24 - GraphTrainer - INFO -   hit_rate@20: 0.083363
2025-11-22 22:10:24 - GraphTrainer - INFO -   ndcg@20: 0.034460
2025-11-22 22:10:24 - GraphTrainer - INFO -   map@20: 0.021718
2025-11-22 22:10:24 - GraphTrainer - INFO -   mrr@20: 0.022607
2025-11-22 22:10:24 - GraphTrainer - INFO - 第 182 轮训练完成
2025-11-22 22:10:24 - GraphTrainer - INFO - train_loss: 0.333387
2025-11-22 22:10:24 - GraphTrainer - INFO - precision@5: 0.006686
2025-11-22 22:10:24 - GraphTrainer - INFO - recall@5: 0.031726
2025-11-22 22:10:24 - GraphTrainer - INFO - hit_rate@5: 0.033325
2025-11-22 22:10:24 - GraphTrainer - INFO - ndcg@5: 0.021081
2025-11-22 22:10:24 - GraphTrainer - INFO - map@5: 0.017324
2025-11-22 22:10:24 - GraphTrainer - INFO - mrr@5: 0.017999
2025-11-22 22:10:24 - GraphTrainer - INFO - precision@10: 0.005292
2025-11-22 22:10:24 - GraphTrainer - INFO - recall@10: 0.050188
2025-11-22 22:10:24 - GraphTrainer - INFO - hit_rate@10: 0.052713
2025-11-22 22:10:24 - GraphTrainer - INFO - ndcg@10: 0.027066
2025-11-22 22:10:24 - GraphTrainer - INFO - map@10: 0.019747
2025-11-22 22:10:24 - GraphTrainer - INFO - mrr@10: 0.020538
2025-11-22 22:10:24 - GraphTrainer - INFO - precision@20: 0.004194
2025-11-22 22:10:24 - GraphTrainer - INFO - recall@20: 0.079353
2025-11-22 22:10:24 - GraphTrainer - INFO - hit_rate@20: 0.083363
2025-11-22 22:10:24 - GraphTrainer - INFO - ndcg@20: 0.034460
2025-11-22 22:10:24 - GraphTrainer - INFO - map@20: 0.021718
2025-11-22 22:10:24 - GraphTrainer - INFO - mrr@20: 0.022607
2025-11-22 22:10:24 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:10:24 - GraphTrainer - INFO - ============================================================
2025-11-22 22:10:24 - GraphTrainer - INFO - 开始第 183/1000 轮训练
2025-11-22 22:10:24 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3510, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3220, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3302, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3234, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3073, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3198, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3262, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3171, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3211, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3673, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3080, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3316, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3143, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3168, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3306, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3299, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3204, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3167, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3218, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3197, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3221, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3293, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3181, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>)
The 182 training average loss: 0.33338690883126754
2025-11-22 22:10:35 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:10:35 - GraphTrainer - INFO -   precision@5: 0.006778
2025-11-22 22:10:35 - GraphTrainer - INFO -   recall@5: 0.032232
2025-11-22 22:10:35 - GraphTrainer - INFO -   hit_rate@5: 0.033839
2025-11-22 22:10:35 - GraphTrainer - INFO -   ndcg@5: 0.021284
2025-11-22 22:10:35 - GraphTrainer - INFO -   map@5: 0.017444
2025-11-22 22:10:35 - GraphTrainer - INFO -   mrr@5: 0.018136
2025-11-22 22:10:35 - GraphTrainer - INFO -   precision@10: 0.005271
2025-11-22 22:10:35 - GraphTrainer - INFO -   recall@10: 0.050043
2025-11-22 22:10:35 - GraphTrainer - INFO -   hit_rate@10: 0.052558
2025-11-22 22:10:35 - GraphTrainer - INFO -   ndcg@10: 0.027050
2025-11-22 22:10:35 - GraphTrainer - INFO -   map@10: 0.019773
2025-11-22 22:10:35 - GraphTrainer - INFO -   mrr@10: 0.020580
2025-11-22 22:10:35 - GraphTrainer - INFO -   precision@20: 0.004140
2025-11-22 22:10:35 - GraphTrainer - INFO -   recall@20: 0.078421
2025-11-22 22:10:35 - GraphTrainer - INFO -   hit_rate@20: 0.082386
2025-11-22 22:10:35 - GraphTrainer - INFO -   ndcg@20: 0.034264
2025-11-22 22:10:35 - GraphTrainer - INFO -   map@20: 0.021707
2025-11-22 22:10:35 - GraphTrainer - INFO -   mrr@20: 0.022611
2025-11-22 22:10:35 - GraphTrainer - INFO - 第 183 轮训练完成
2025-11-22 22:10:35 - GraphTrainer - INFO - train_loss: 0.332183
2025-11-22 22:10:35 - GraphTrainer - INFO - precision@5: 0.006778
2025-11-22 22:10:35 - GraphTrainer - INFO - recall@5: 0.032232
2025-11-22 22:10:35 - GraphTrainer - INFO - hit_rate@5: 0.033839
2025-11-22 22:10:35 - GraphTrainer - INFO - ndcg@5: 0.021284
2025-11-22 22:10:35 - GraphTrainer - INFO - map@5: 0.017444
2025-11-22 22:10:35 - GraphTrainer - INFO - mrr@5: 0.018136
2025-11-22 22:10:35 - GraphTrainer - INFO - precision@10: 0.005271
2025-11-22 22:10:35 - GraphTrainer - INFO - recall@10: 0.050043
2025-11-22 22:10:35 - GraphTrainer - INFO - hit_rate@10: 0.052558
2025-11-22 22:10:35 - GraphTrainer - INFO - ndcg@10: 0.027050
2025-11-22 22:10:35 - GraphTrainer - INFO - map@10: 0.019773
2025-11-22 22:10:35 - GraphTrainer - INFO - mrr@10: 0.020580
2025-11-22 22:10:35 - GraphTrainer - INFO - precision@20: 0.004140
2025-11-22 22:10:35 - GraphTrainer - INFO - recall@20: 0.078421
2025-11-22 22:10:35 - GraphTrainer - INFO - hit_rate@20: 0.082386
2025-11-22 22:10:35 - GraphTrainer - INFO - ndcg@20: 0.034264
2025-11-22 22:10:35 - GraphTrainer - INFO - map@20: 0.021707
2025-11-22 22:10:35 - GraphTrainer - INFO - mrr@20: 0.022611
2025-11-22 22:10:35 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:10:35 - GraphTrainer - INFO - ============================================================
2025-11-22 22:10:35 - GraphTrainer - INFO - 开始第 184/1000 轮训练
2025-11-22 22:10:35 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3192, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3373, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3333, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3191, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3312, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3226, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3080, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3173, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3175, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3333, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3240, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3612, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3207, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3210, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3094, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3233, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3376, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3241, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3180, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3174, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3126, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3313, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
The 183 training average loss: 0.3321833348479764
2025-11-22 22:10:46 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:10:46 - GraphTrainer - INFO -   precision@5: 0.006788
2025-11-22 22:10:46 - GraphTrainer - INFO -   recall@5: 0.032283
2025-11-22 22:10:46 - GraphTrainer - INFO -   hit_rate@5: 0.033890
2025-11-22 22:10:46 - GraphTrainer - INFO -   ndcg@5: 0.021273
2025-11-22 22:10:46 - GraphTrainer - INFO -   map@5: 0.017421
2025-11-22 22:10:46 - GraphTrainer - INFO -   mrr@5: 0.018117
2025-11-22 22:10:46 - GraphTrainer - INFO -   precision@10: 0.005256
2025-11-22 22:10:46 - GraphTrainer - INFO -   recall@10: 0.049879
2025-11-22 22:10:46 - GraphTrainer - INFO -   hit_rate@10: 0.052353
2025-11-22 22:10:46 - GraphTrainer - INFO -   ndcg@10: 0.026974
2025-11-22 22:10:46 - GraphTrainer - INFO -   map@10: 0.019727
2025-11-22 22:10:46 - GraphTrainer - INFO -   mrr@10: 0.020530
2025-11-22 22:10:46 - GraphTrainer - INFO -   precision@20: 0.004117
2025-11-22 22:10:46 - GraphTrainer - INFO -   recall@20: 0.077926
2025-11-22 22:10:46 - GraphTrainer - INFO -   hit_rate@20: 0.081872
2025-11-22 22:10:46 - GraphTrainer - INFO -   ndcg@20: 0.034133
2025-11-22 22:10:46 - GraphTrainer - INFO -   map@20: 0.021660
2025-11-22 22:10:46 - GraphTrainer - INFO -   mrr@20: 0.022564
2025-11-22 22:10:46 - GraphTrainer - INFO - 第 184 轮训练完成
2025-11-22 22:10:46 - GraphTrainer - INFO - train_loss: 0.331083
2025-11-22 22:10:46 - GraphTrainer - INFO - precision@5: 0.006788
2025-11-22 22:10:46 - GraphTrainer - INFO - recall@5: 0.032283
2025-11-22 22:10:46 - GraphTrainer - INFO - hit_rate@5: 0.033890
2025-11-22 22:10:46 - GraphTrainer - INFO - ndcg@5: 0.021273
2025-11-22 22:10:46 - GraphTrainer - INFO - map@5: 0.017421
2025-11-22 22:10:46 - GraphTrainer - INFO - mrr@5: 0.018117
2025-11-22 22:10:46 - GraphTrainer - INFO - precision@10: 0.005256
2025-11-22 22:10:46 - GraphTrainer - INFO - recall@10: 0.049879
2025-11-22 22:10:46 - GraphTrainer - INFO - hit_rate@10: 0.052353
2025-11-22 22:10:46 - GraphTrainer - INFO - ndcg@10: 0.026974
2025-11-22 22:10:46 - GraphTrainer - INFO - map@10: 0.019727
2025-11-22 22:10:46 - GraphTrainer - INFO - mrr@10: 0.020530
2025-11-22 22:10:46 - GraphTrainer - INFO - precision@20: 0.004117
2025-11-22 22:10:46 - GraphTrainer - INFO - recall@20: 0.077926
2025-11-22 22:10:46 - GraphTrainer - INFO - hit_rate@20: 0.081872
2025-11-22 22:10:46 - GraphTrainer - INFO - ndcg@20: 0.034133
2025-11-22 22:10:46 - GraphTrainer - INFO - map@20: 0.021660
2025-11-22 22:10:46 - GraphTrainer - INFO - mrr@20: 0.022564
2025-11-22 22:10:46 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:10:46 - GraphTrainer - INFO - ============================================================
2025-11-22 22:10:46 - GraphTrainer - INFO - 开始第 185/1000 轮训练
2025-11-22 22:10:46 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3205, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3155, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3205, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3260, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3185, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3409, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3013, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3186, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3257, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3285, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3123, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3219, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3281, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3433, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3312, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3276, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3233, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3210, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3199, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3181, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3102, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)
The 184 training average loss: 0.331082565003428
2025-11-22 22:10:57 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:10:57 - GraphTrainer - INFO -   precision@5: 0.006768
2025-11-22 22:10:57 - GraphTrainer - INFO -   recall@5: 0.032155
2025-11-22 22:10:57 - GraphTrainer - INFO -   hit_rate@5: 0.033788
2025-11-22 22:10:57 - GraphTrainer - INFO -   ndcg@5: 0.021306
2025-11-22 22:10:57 - GraphTrainer - INFO -   map@5: 0.017497
2025-11-22 22:10:57 - GraphTrainer - INFO -   mrr@5: 0.018189
2025-11-22 22:10:57 - GraphTrainer - INFO -   precision@10: 0.005225
2025-11-22 22:10:57 - GraphTrainer - INFO -   recall@10: 0.049635
2025-11-22 22:10:57 - GraphTrainer - INFO -   hit_rate@10: 0.052044
2025-11-22 22:10:57 - GraphTrainer - INFO -   ndcg@10: 0.026982
2025-11-22 22:10:57 - GraphTrainer - INFO -   map@10: 0.019805
2025-11-22 22:10:57 - GraphTrainer - INFO -   mrr@10: 0.020593
2025-11-22 22:10:57 - GraphTrainer - INFO -   precision@20: 0.004130
2025-11-22 22:10:57 - GraphTrainer - INFO -   recall@20: 0.078164
2025-11-22 22:10:57 - GraphTrainer - INFO -   hit_rate@20: 0.082181
2025-11-22 22:10:57 - GraphTrainer - INFO -   ndcg@20: 0.034256
2025-11-22 22:10:57 - GraphTrainer - INFO -   map@20: 0.021762
2025-11-22 22:10:57 - GraphTrainer - INFO -   mrr@20: 0.022661
2025-11-22 22:10:57 - GraphTrainer - INFO - 第 185 轮训练完成
2025-11-22 22:10:57 - GraphTrainer - INFO - train_loss: 0.331453
2025-11-22 22:10:57 - GraphTrainer - INFO - precision@5: 0.006768
2025-11-22 22:10:57 - GraphTrainer - INFO - recall@5: 0.032155
2025-11-22 22:10:57 - GraphTrainer - INFO - hit_rate@5: 0.033788
2025-11-22 22:10:57 - GraphTrainer - INFO - ndcg@5: 0.021306
2025-11-22 22:10:57 - GraphTrainer - INFO - map@5: 0.017497
2025-11-22 22:10:57 - GraphTrainer - INFO - mrr@5: 0.018189
2025-11-22 22:10:57 - GraphTrainer - INFO - precision@10: 0.005225
2025-11-22 22:10:57 - GraphTrainer - INFO - recall@10: 0.049635
2025-11-22 22:10:57 - GraphTrainer - INFO - hit_rate@10: 0.052044
2025-11-22 22:10:57 - GraphTrainer - INFO - ndcg@10: 0.026982
2025-11-22 22:10:57 - GraphTrainer - INFO - map@10: 0.019805
2025-11-22 22:10:57 - GraphTrainer - INFO - mrr@10: 0.020593
2025-11-22 22:10:57 - GraphTrainer - INFO - precision@20: 0.004130
2025-11-22 22:10:57 - GraphTrainer - INFO - recall@20: 0.078164
2025-11-22 22:10:57 - GraphTrainer - INFO - hit_rate@20: 0.082181
2025-11-22 22:10:57 - GraphTrainer - INFO - ndcg@20: 0.034256
2025-11-22 22:10:57 - GraphTrainer - INFO - map@20: 0.021762
2025-11-22 22:10:57 - GraphTrainer - INFO - mrr@20: 0.022661
2025-11-22 22:10:57 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:10:57 - GraphTrainer - INFO - ============================================================
2025-11-22 22:10:57 - GraphTrainer - INFO - 开始第 186/1000 轮训练
2025-11-22 22:10:57 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3145, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3096, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3114, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3234, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3171, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3103, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3259, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3125, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3241, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3575, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3245, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3138, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3221, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3012, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3099, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3269, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3064, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3327, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3492, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3215, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3316, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3205, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3245, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3176, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3558, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3121, device='cuda:0', grad_fn=<AddBackward0>)
The 185 training average loss: 0.3314533120599286
2025-11-22 22:11:08 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:11:08 - GraphTrainer - INFO -   precision@5: 0.006758
2025-11-22 22:11:08 - GraphTrainer - INFO -   recall@5: 0.032137
2025-11-22 22:11:08 - GraphTrainer - INFO -   hit_rate@5: 0.033736
2025-11-22 22:11:08 - GraphTrainer - INFO -   ndcg@5: 0.021311
2025-11-22 22:11:08 - GraphTrainer - INFO -   map@5: 0.017513
2025-11-22 22:11:08 - GraphTrainer - INFO -   mrr@5: 0.018205
2025-11-22 22:11:08 - GraphTrainer - INFO -   precision@10: 0.005282
2025-11-22 22:11:08 - GraphTrainer - INFO -   recall@10: 0.050102
2025-11-22 22:11:08 - GraphTrainer - INFO -   hit_rate@10: 0.052610
2025-11-22 22:11:08 - GraphTrainer - INFO -   ndcg@10: 0.027120
2025-11-22 22:11:08 - GraphTrainer - INFO -   map@10: 0.019854
2025-11-22 22:11:08 - GraphTrainer - INFO -   mrr@10: 0.020660
2025-11-22 22:11:08 - GraphTrainer - INFO -   precision@20: 0.004163
2025-11-22 22:11:08 - GraphTrainer - INFO -   recall@20: 0.078798
2025-11-22 22:11:08 - GraphTrainer - INFO -   hit_rate@20: 0.082798
2025-11-22 22:11:08 - GraphTrainer - INFO -   ndcg@20: 0.034410
2025-11-22 22:11:08 - GraphTrainer - INFO -   map@20: 0.021805
2025-11-22 22:11:08 - GraphTrainer - INFO -   mrr@20: 0.022714
2025-11-22 22:11:08 - GraphTrainer - INFO - 第 186 轮训练完成
2025-11-22 22:11:08 - GraphTrainer - INFO - train_loss: 0.330951
2025-11-22 22:11:08 - GraphTrainer - INFO - precision@5: 0.006758
2025-11-22 22:11:08 - GraphTrainer - INFO - recall@5: 0.032137
2025-11-22 22:11:08 - GraphTrainer - INFO - hit_rate@5: 0.033736
2025-11-22 22:11:08 - GraphTrainer - INFO - ndcg@5: 0.021311
2025-11-22 22:11:08 - GraphTrainer - INFO - map@5: 0.017513
2025-11-22 22:11:08 - GraphTrainer - INFO - mrr@5: 0.018205
2025-11-22 22:11:08 - GraphTrainer - INFO - precision@10: 0.005282
2025-11-22 22:11:08 - GraphTrainer - INFO - recall@10: 0.050102
2025-11-22 22:11:08 - GraphTrainer - INFO - hit_rate@10: 0.052610
2025-11-22 22:11:08 - GraphTrainer - INFO - ndcg@10: 0.027120
2025-11-22 22:11:08 - GraphTrainer - INFO - map@10: 0.019854
2025-11-22 22:11:08 - GraphTrainer - INFO - mrr@10: 0.020660
2025-11-22 22:11:08 - GraphTrainer - INFO - precision@20: 0.004163
2025-11-22 22:11:08 - GraphTrainer - INFO - recall@20: 0.078798
2025-11-22 22:11:08 - GraphTrainer - INFO - hit_rate@20: 0.082798
2025-11-22 22:11:08 - GraphTrainer - INFO - ndcg@20: 0.034410
2025-11-22 22:11:08 - GraphTrainer - INFO - map@20: 0.021805
2025-11-22 22:11:08 - GraphTrainer - INFO - mrr@20: 0.022714
2025-11-22 22:11:08 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:11:08 - GraphTrainer - INFO - ============================================================
2025-11-22 22:11:08 - GraphTrainer - INFO - 开始第 187/1000 轮训练
2025-11-22 22:11:08 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3302, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3205, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3137, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3183, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3226, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3272, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3259, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3263, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3188, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3217, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3306, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3302, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3239, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3228, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3192, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3249, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3135, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3099, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3154, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3240, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3205, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3239, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3227, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
The 186 training average loss: 0.3309511737576846
2025-11-22 22:11:19 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:11:19 - GraphTrainer - INFO -   precision@5: 0.006768
2025-11-22 22:11:19 - GraphTrainer - INFO -   recall@5: 0.032116
2025-11-22 22:11:19 - GraphTrainer - INFO -   hit_rate@5: 0.033736
2025-11-22 22:11:19 - GraphTrainer - INFO -   ndcg@5: 0.021311
2025-11-22 22:11:19 - GraphTrainer - INFO -   map@5: 0.017512
2025-11-22 22:11:19 - GraphTrainer - INFO -   mrr@5: 0.018201
2025-11-22 22:11:19 - GraphTrainer - INFO -   precision@10: 0.005266
2025-11-22 22:11:19 - GraphTrainer - INFO -   recall@10: 0.050012
2025-11-22 22:11:19 - GraphTrainer - INFO -   hit_rate@10: 0.052456
2025-11-22 22:11:19 - GraphTrainer - INFO -   ndcg@10: 0.027091
2025-11-22 22:11:19 - GraphTrainer - INFO -   map@10: 0.019843
2025-11-22 22:11:19 - GraphTrainer - INFO -   mrr@10: 0.020638
2025-11-22 22:11:19 - GraphTrainer - INFO -   precision@20: 0.004155
2025-11-22 22:11:19 - GraphTrainer - INFO -   recall@20: 0.078598
2025-11-22 22:11:19 - GraphTrainer - INFO -   hit_rate@20: 0.082540
2025-11-22 22:11:19 - GraphTrainer - INFO -   ndcg@20: 0.034363
2025-11-22 22:11:19 - GraphTrainer - INFO -   map@20: 0.021792
2025-11-22 22:11:19 - GraphTrainer - INFO -   mrr@20: 0.022688
2025-11-22 22:11:19 - GraphTrainer - INFO - 第 187 轮训练完成
2025-11-22 22:11:19 - GraphTrainer - INFO - train_loss: 0.331971
2025-11-22 22:11:19 - GraphTrainer - INFO - precision@5: 0.006768
2025-11-22 22:11:19 - GraphTrainer - INFO - recall@5: 0.032116
2025-11-22 22:11:19 - GraphTrainer - INFO - hit_rate@5: 0.033736
2025-11-22 22:11:19 - GraphTrainer - INFO - ndcg@5: 0.021311
2025-11-22 22:11:19 - GraphTrainer - INFO - map@5: 0.017512
2025-11-22 22:11:19 - GraphTrainer - INFO - mrr@5: 0.018201
2025-11-22 22:11:19 - GraphTrainer - INFO - precision@10: 0.005266
2025-11-22 22:11:19 - GraphTrainer - INFO - recall@10: 0.050012
2025-11-22 22:11:19 - GraphTrainer - INFO - hit_rate@10: 0.052456
2025-11-22 22:11:19 - GraphTrainer - INFO - ndcg@10: 0.027091
2025-11-22 22:11:19 - GraphTrainer - INFO - map@10: 0.019843
2025-11-22 22:11:19 - GraphTrainer - INFO - mrr@10: 0.020638
2025-11-22 22:11:19 - GraphTrainer - INFO - precision@20: 0.004155
2025-11-22 22:11:19 - GraphTrainer - INFO - recall@20: 0.078598
2025-11-22 22:11:19 - GraphTrainer - INFO - hit_rate@20: 0.082540
2025-11-22 22:11:19 - GraphTrainer - INFO - ndcg@20: 0.034363
2025-11-22 22:11:19 - GraphTrainer - INFO - map@20: 0.021792
2025-11-22 22:11:19 - GraphTrainer - INFO - mrr@20: 0.022688
2025-11-22 22:11:19 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:11:19 - GraphTrainer - INFO - ============================================================
2025-11-22 22:11:19 - GraphTrainer - INFO - 开始第 188/1000 轮训练
2025-11-22 22:11:19 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3302, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3184, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3525, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3316, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3214, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3169, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3516, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2986, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3258, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3290, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3214, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3592, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3303, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3137, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3299, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3083, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3120, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3219, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3228, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3254, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3258, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
The 187 training average loss: 0.33197087100867567
2025-11-22 22:11:30 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:11:30 - GraphTrainer - INFO -   precision@5: 0.006830
2025-11-22 22:11:30 - GraphTrainer - INFO -   recall@5: 0.032510
2025-11-22 22:11:30 - GraphTrainer - INFO -   hit_rate@5: 0.034096
2025-11-22 22:11:30 - GraphTrainer - INFO -   ndcg@5: 0.021369
2025-11-22 22:11:30 - GraphTrainer - INFO -   map@5: 0.017479
2025-11-22 22:11:30 - GraphTrainer - INFO -   mrr@5: 0.018154
2025-11-22 22:11:30 - GraphTrainer - INFO -   precision@10: 0.005261
2025-11-22 22:11:30 - GraphTrainer - INFO -   recall@10: 0.049901
2025-11-22 22:11:30 - GraphTrainer - INFO -   hit_rate@10: 0.052404
2025-11-22 22:11:30 - GraphTrainer - INFO -   ndcg@10: 0.026990
2025-11-22 22:11:30 - GraphTrainer - INFO -   map@10: 0.019742
2025-11-22 22:11:30 - GraphTrainer - INFO -   mrr@10: 0.020531
2025-11-22 22:11:30 - GraphTrainer - INFO -   precision@20: 0.004173
2025-11-22 22:11:30 - GraphTrainer - INFO -   recall@20: 0.079091
2025-11-22 22:11:30 - GraphTrainer - INFO -   hit_rate@20: 0.082952
2025-11-22 22:11:30 - GraphTrainer - INFO -   ndcg@20: 0.034395
2025-11-22 22:11:30 - GraphTrainer - INFO -   map@20: 0.021723
2025-11-22 22:11:30 - GraphTrainer - INFO -   mrr@20: 0.022603
2025-11-22 22:11:30 - GraphTrainer - INFO - 第 188 轮训练完成
2025-11-22 22:11:30 - GraphTrainer - INFO - train_loss: 0.328743
2025-11-22 22:11:30 - GraphTrainer - INFO - precision@5: 0.006830
2025-11-22 22:11:30 - GraphTrainer - INFO - recall@5: 0.032510
2025-11-22 22:11:30 - GraphTrainer - INFO - hit_rate@5: 0.034096
2025-11-22 22:11:30 - GraphTrainer - INFO - ndcg@5: 0.021369
2025-11-22 22:11:30 - GraphTrainer - INFO - map@5: 0.017479
2025-11-22 22:11:30 - GraphTrainer - INFO - mrr@5: 0.018154
2025-11-22 22:11:30 - GraphTrainer - INFO - precision@10: 0.005261
2025-11-22 22:11:30 - GraphTrainer - INFO - recall@10: 0.049901
2025-11-22 22:11:30 - GraphTrainer - INFO - hit_rate@10: 0.052404
2025-11-22 22:11:30 - GraphTrainer - INFO - ndcg@10: 0.026990
2025-11-22 22:11:30 - GraphTrainer - INFO - map@10: 0.019742
2025-11-22 22:11:30 - GraphTrainer - INFO - mrr@10: 0.020531
2025-11-22 22:11:30 - GraphTrainer - INFO - precision@20: 0.004173
2025-11-22 22:11:30 - GraphTrainer - INFO - recall@20: 0.079091
2025-11-22 22:11:30 - GraphTrainer - INFO - hit_rate@20: 0.082952
2025-11-22 22:11:30 - GraphTrainer - INFO - ndcg@20: 0.034395
2025-11-22 22:11:30 - GraphTrainer - INFO - map@20: 0.021723
2025-11-22 22:11:30 - GraphTrainer - INFO - mrr@20: 0.022603
2025-11-22 22:11:30 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:11:30 - GraphTrainer - INFO - ============================================================
2025-11-22 22:11:30 - GraphTrainer - INFO - 开始第 189/1000 轮训练
2025-11-22 22:11:30 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3409, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3261, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3234, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3261, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3306, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3092, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3182, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2987, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3565, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2818, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3221, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3246, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3039, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3256, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3136, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3209, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3531, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3127, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3209, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2909, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3227, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3191, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3113, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3147, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3588, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3197, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3140, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
The 188 training average loss: 0.3287432949090826
2025-11-22 22:11:41 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:11:41 - GraphTrainer - INFO -   precision@5: 0.006716
2025-11-22 22:11:41 - GraphTrainer - INFO -   recall@5: 0.031970
2025-11-22 22:11:41 - GraphTrainer - INFO -   hit_rate@5: 0.033530
2025-11-22 22:11:41 - GraphTrainer - INFO -   ndcg@5: 0.021215
2025-11-22 22:11:41 - GraphTrainer - INFO -   map@5: 0.017442
2025-11-22 22:11:41 - GraphTrainer - INFO -   mrr@5: 0.018116
2025-11-22 22:11:41 - GraphTrainer - INFO -   precision@10: 0.005256
2025-11-22 22:11:41 - GraphTrainer - INFO -   recall@10: 0.049858
2025-11-22 22:11:41 - GraphTrainer - INFO -   hit_rate@10: 0.052353
2025-11-22 22:11:41 - GraphTrainer - INFO -   ndcg@10: 0.027018
2025-11-22 22:11:41 - GraphTrainer - INFO -   map@10: 0.019788
2025-11-22 22:11:41 - GraphTrainer - INFO -   mrr@10: 0.020584
2025-11-22 22:11:41 - GraphTrainer - INFO -   precision@20: 0.004176
2025-11-22 22:11:41 - GraphTrainer - INFO -   recall@20: 0.079116
2025-11-22 22:11:41 - GraphTrainer - INFO -   hit_rate@20: 0.083055
2025-11-22 22:11:41 - GraphTrainer - INFO -   ndcg@20: 0.034451
2025-11-22 22:11:41 - GraphTrainer - INFO -   map@20: 0.021781
2025-11-22 22:11:41 - GraphTrainer - INFO -   mrr@20: 0.022674
2025-11-22 22:11:41 - GraphTrainer - INFO - 第 189 轮训练完成
2025-11-22 22:11:41 - GraphTrainer - INFO - train_loss: 0.330195
2025-11-22 22:11:41 - GraphTrainer - INFO - precision@5: 0.006716
2025-11-22 22:11:41 - GraphTrainer - INFO - recall@5: 0.031970
2025-11-22 22:11:41 - GraphTrainer - INFO - hit_rate@5: 0.033530
2025-11-22 22:11:41 - GraphTrainer - INFO - ndcg@5: 0.021215
2025-11-22 22:11:41 - GraphTrainer - INFO - map@5: 0.017442
2025-11-22 22:11:41 - GraphTrainer - INFO - mrr@5: 0.018116
2025-11-22 22:11:41 - GraphTrainer - INFO - precision@10: 0.005256
2025-11-22 22:11:41 - GraphTrainer - INFO - recall@10: 0.049858
2025-11-22 22:11:41 - GraphTrainer - INFO - hit_rate@10: 0.052353
2025-11-22 22:11:41 - GraphTrainer - INFO - ndcg@10: 0.027018
2025-11-22 22:11:41 - GraphTrainer - INFO - map@10: 0.019788
2025-11-22 22:11:41 - GraphTrainer - INFO - mrr@10: 0.020584
2025-11-22 22:11:41 - GraphTrainer - INFO - precision@20: 0.004176
2025-11-22 22:11:41 - GraphTrainer - INFO - recall@20: 0.079116
2025-11-22 22:11:41 - GraphTrainer - INFO - hit_rate@20: 0.083055
2025-11-22 22:11:41 - GraphTrainer - INFO - ndcg@20: 0.034451
2025-11-22 22:11:41 - GraphTrainer - INFO - map@20: 0.021781
2025-11-22 22:11:41 - GraphTrainer - INFO - mrr@20: 0.022674
2025-11-22 22:11:41 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:11:41 - GraphTrainer - WARNING - 早停触发 - 第 189 轮，最佳指标: 0.080073
2025-11-22 22:11:41 - GraphTrainer - INFO - ============================================================
2025-11-22 22:11:41 - GraphTrainer - INFO - 训练完成!
2025-11-22 22:11:41 - GraphTrainer - INFO - 总训练时间: 0.58 hours
2025-11-22 22:11:41 - GraphTrainer - INFO - 最佳指标:
2025-11-22 22:11:41 - GraphTrainer - INFO -   best_precision@5: 0.006716
2025-11-22 22:11:41 - GraphTrainer - INFO -   best_recall@5: 0.031970
2025-11-22 22:11:41 - GraphTrainer - INFO -   best_hit_rate@5: 0.033530
2025-11-22 22:11:41 - GraphTrainer - INFO -   best_ndcg@5: 0.021215
2025-11-22 22:11:41 - GraphTrainer - INFO -   best_map@5: 0.017442
2025-11-22 22:11:41 - GraphTrainer - INFO -   best_mrr@5: 0.018116
2025-11-22 22:11:41 - GraphTrainer - INFO -   best_precision@10: 0.005256
2025-11-22 22:11:41 - GraphTrainer - INFO -   best_recall@10: 0.049858
2025-11-22 22:11:41 - GraphTrainer - INFO -   best_hit_rate@10: 0.052353
2025-11-22 22:11:41 - GraphTrainer - INFO -   best_ndcg@10: 0.027018
2025-11-22 22:11:41 - GraphTrainer - INFO -   best_map@10: 0.019788
2025-11-22 22:11:41 - GraphTrainer - INFO -   best_mrr@10: 0.020584
2025-11-22 22:11:41 - GraphTrainer - INFO -   best_precision@20: 0.004176
2025-11-22 22:11:41 - GraphTrainer - INFO -   best_recall@20: 0.079116
2025-11-22 22:11:41 - GraphTrainer - INFO -   best_hit_rate@20: 0.083055
2025-11-22 22:11:41 - GraphTrainer - INFO -   best_ndcg@20: 0.034451
2025-11-22 22:11:41 - GraphTrainer - INFO -   best_map@20: 0.021781
2025-11-22 22:11:41 - GraphTrainer - INFO -   best_mrr@20: 0.022674
2025-11-22 22:11:41 - GraphTrainer - INFO - ============================================================
2025-11-22 22:11:41 - GraphTrainer - INFO - Loaded best model from epoch 169
[I 2025-11-22 22:11:44,043] Trial 1 finished with value: 0.0800730362534523 and parameters: {'model.layer_num': 2, 'graph.v_k': 4, 'graph.t_k': 3, 'model.gcn_v_k': 1, 'model.gcn_t_k': 7, 'model.k': 7, 'model.alpha': 0.49010032836358575, 'model.hidden_unit': 512}. Best is trial 0 with value: 0.08310925960540771.
2025-11-22 22:12:02 - GraphTrainer - INFO - Starting training...
2025-11-22 22:12:02 - GraphTrainer - INFO - 模型: SGrec
2025-11-22 22:12:02 - GraphTrainer - INFO - 总参数量: 4,056,128
2025-11-22 22:12:02 - GraphTrainer - INFO - 可训练参数量: 4,056,128
2025-11-22 22:12:02 - GraphTrainer - INFO - ============================================================
2025-11-22 22:12:02 - GraphTrainer - INFO - 开始第 1/1000 轮训练
2025-11-22 22:12:02 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3143, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3506, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3181, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3285, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3143, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3290, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3172, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3199, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3191, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3072, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3226, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3190, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3138, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3141, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3512, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3137, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3213, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3074, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3303, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3131, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3115, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3203, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3299, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3197, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3133, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3223, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3502, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3492, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3225, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
The 189 training average loss: 0.3301954634230712

============================================================
FINAL RESULTS
============================================================
Training Results:
  Best epoch: 169
  Best validation metric: 0.0801
  Training time: 0.58 hours

Test Metrics:
  precision@5: 0.0071
  recall@5: 0.0324
  hit_rate@5: 0.0354
  ndcg@5: 0.0210
  map@5: 0.0167
  mrr@5: 0.0184
  precision@10: 0.0058
  recall@10: 0.0526
  hit_rate@10: 0.0575
  ndcg@10: 0.0277
  map@10: 0.0194
  mrr@10: 0.0213
  precision@20: 0.0045
  recall@20: 0.0816
  hit_rate@20: 0.0897
  ndcg@20: 0.0352
  map@20: 0.0214
  mrr@20: 0.0235
Saving results...
Results saved to ./results/results_20251122_2211.json

Training completed successfully!

############################################################
Optuna Trial 2
############################################################
Trial config (partial):
  lr=0.001, wd=0, layer_num=3, graph_v_k=8, graph_t_k=6, gcn_v_k=10, gcn_t_k=10, k=8, alpha=0.3431001252000459, beta=0.6568998747999542, hidden_unit=512
Using GPU: NVIDIA GeForce RTX 3080
============================================================
Graph-based Recommendation System
============================================================
Dataset: baby
Device: cuda
Model: SGrec
Embedding dim: 64
Epochs: 1000
============================================================
Loading data...
Initializing full dataset from ../autodl-tmp/data/ori_data/baby
Loading interaction data from ../autodl-tmp/data/ori_data/baby
Loading features from ../autodl-tmp/data/ori_data/baby
Building user-item interaction index...
Dataset Statistics:
  num_users: 19445
  num_items: 7050
  num_interactions: 160792
  sparsity: 0.9988270827520429
  user_features: []
  item_features_dimensions: {'image_feat': 4096, 'text_feat': 384}
  user_feature_dimensions: {}
  train_ratio: 0.737294143987263
  val_ratio: 0.12786083884770386
  test_ratio: 0.13484501716503308
Full dataset initialized: 160792 interactions, 19445 users, 7050 items
Splitting dataset into train/val/test...
Initializing subset dataset (mode: train) with 118551 interactions
Initializing subset dataset (mode: val) with 20559 interactions
Initializing subset dataset (mode: test) with 21682 interactions
Split results - Train: 118551 interactions, Val: 20559, Test: 21682
Data loaders created - Train batches: 58, Val batches: 11, Test batches: 11
Data loaded: 19445 users, 7050 items
User features: []
Item features: ['image_feat', 'text_feat']
Building graph and model...
Extracting training interactions for graph construction...
Extracted 118551 positive interactions for graph construction
Graph built from training data only: 26495 nodes, 263597 edges
⚠️  Important: Graph constructed using only training data to prevent data leakage
SGrec(
  (user_emb): Embedding(19445, 64)
  (item_emb): Embedding(7050, 64)
  (graph): Graph(
    (input_feat_dropout): Dropout(p=0.1, inplace=False)
    (v_ffn): Sequential(
      (0): Linear(in_features=4096, out_features=512, bias=True)
      (1): Linear(in_features=512, out_features=64, bias=True)
    )
    (t_ffn): Sequential(
      (0): Linear(in_features=384, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=64, bias=True)
    )
    (v_gcn): II_GCN(
      (x_dropout): Dropout(p=0.3, inplace=False)
      (edge_dropout): Dropout(p=0.2, inplace=False)
      (z_dropout): Dropout(p=0.3, inplace=False)
    )
    (t_gcn): II_GCN(
      (x_dropout): Dropout(p=0.3, inplace=False)
      (edge_dropout): Dropout(p=0.2, inplace=False)
      (z_dropout): Dropout(p=0.3, inplace=False)
    )
    (iu_gcn): IU_GCN(
      (x_dropout): Dropout(p=0.3, inplace=False)
      (edge_dropout): Dropout(p=0.2, inplace=False)
      (z_dropout): Dropout(p=0.3, inplace=False)
    )
    (activate): ReLU()
  )
)
Model parameters: 4,056,128
init trainer,verifier,tester
2025-11-22 22:12:13 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:12:13 - GraphTrainer - INFO -   precision@5: 0.002448
2025-11-22 22:12:13 - GraphTrainer - INFO -   recall@5: 0.011659
2025-11-22 22:12:13 - GraphTrainer - INFO -   hit_rate@5: 0.012240
2025-11-22 22:12:13 - GraphTrainer - INFO -   ndcg@5: 0.007551
2025-11-22 22:12:13 - GraphTrainer - INFO -   map@5: 0.006060
2025-11-22 22:12:13 - GraphTrainer - INFO -   mrr@5: 0.006357
2025-11-22 22:12:13 - GraphTrainer - INFO -   precision@10: 0.001810
2025-11-22 22:12:13 - GraphTrainer - INFO -   recall@10: 0.017444
2025-11-22 22:12:13 - GraphTrainer - INFO -   hit_rate@10: 0.018102
2025-11-22 22:12:13 - GraphTrainer - INFO -   ndcg@10: 0.009408
2025-11-22 22:12:13 - GraphTrainer - INFO -   map@10: 0.006817
2025-11-22 22:12:13 - GraphTrainer - INFO -   mrr@10: 0.007126
2025-11-22 22:12:13 - GraphTrainer - INFO -   precision@20: 0.001268
2025-11-22 22:12:13 - GraphTrainer - INFO -   recall@20: 0.024101
2025-11-22 22:12:13 - GraphTrainer - INFO -   hit_rate@20: 0.025251
2025-11-22 22:12:13 - GraphTrainer - INFO -   ndcg@20: 0.011122
2025-11-22 22:12:13 - GraphTrainer - INFO -   map@20: 0.007282
2025-11-22 22:12:13 - GraphTrainer - INFO -   mrr@20: 0.007624
2025-11-22 22:12:13 - GraphTrainer - INFO - 第 1 轮训练完成
2025-11-22 22:12:13 - GraphTrainer - INFO - train_loss: 0.674040
2025-11-22 22:12:13 - GraphTrainer - INFO - precision@5: 0.002448
2025-11-22 22:12:13 - GraphTrainer - INFO - recall@5: 0.011659
2025-11-22 22:12:13 - GraphTrainer - INFO - hit_rate@5: 0.012240
2025-11-22 22:12:13 - GraphTrainer - INFO - ndcg@5: 0.007551
2025-11-22 22:12:13 - GraphTrainer - INFO - map@5: 0.006060
2025-11-22 22:12:13 - GraphTrainer - INFO - mrr@5: 0.006357
2025-11-22 22:12:13 - GraphTrainer - INFO - precision@10: 0.001810
2025-11-22 22:12:13 - GraphTrainer - INFO - recall@10: 0.017444
2025-11-22 22:12:13 - GraphTrainer - INFO - hit_rate@10: 0.018102
2025-11-22 22:12:13 - GraphTrainer - INFO - ndcg@10: 0.009408
2025-11-22 22:12:13 - GraphTrainer - INFO - map@10: 0.006817
2025-11-22 22:12:13 - GraphTrainer - INFO - mrr@10: 0.007126
2025-11-22 22:12:13 - GraphTrainer - INFO - precision@20: 0.001268
2025-11-22 22:12:13 - GraphTrainer - INFO - recall@20: 0.024101
2025-11-22 22:12:13 - GraphTrainer - INFO - hit_rate@20: 0.025251
2025-11-22 22:12:13 - GraphTrainer - INFO - ndcg@20: 0.011122
2025-11-22 22:12:13 - GraphTrainer - INFO - map@20: 0.007282
2025-11-22 22:12:13 - GraphTrainer - INFO - mrr@20: 0.007624
2025-11-22 22:12:13 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:12:13 - GraphTrainer - INFO - ============================================================
2025-11-22 22:12:13 - GraphTrainer - INFO - 开始第 2/1000 轮训练
2025-11-22 22:12:13 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.6942, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.6961, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.6927, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.6852, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.6910, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.6980, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.6861, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.6888, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.6879, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.6882, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.6842, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.6909, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.6901, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.6915, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.6909, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.6931, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.6790, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.6854, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.6794, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.6890, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.6782, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.6895, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.6912, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.6719, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.6725, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.6817, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.6801, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.6635, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.6692, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.6701, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.6704, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.6785, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.6677, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.6675, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.6803, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.6637, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.6707, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.6680, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.6712, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.6628, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.6610, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.6610, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.6716, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.6568, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.6757, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.6597, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.6508, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.6597, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.6494, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.6549, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.6613, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.6600, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.6493, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.6348, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.6596, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.6694, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.6614, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.6476, device='cuda:0', grad_fn=<AddBackward0>)
The 1 training average loss: 0.6740403812507103
2025-11-22 22:12:24 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:12:24 - GraphTrainer - INFO -   precision@5: 0.002756
2025-11-22 22:12:24 - GraphTrainer - INFO -   recall@5: 0.013177
2025-11-22 22:12:24 - GraphTrainer - INFO -   hit_rate@5: 0.013782
2025-11-22 22:12:24 - GraphTrainer - INFO -   ndcg@5: 0.009434
2025-11-22 22:12:24 - GraphTrainer - INFO -   map@5: 0.008119
2025-11-22 22:12:24 - GraphTrainer - INFO -   mrr@5: 0.008422
2025-11-22 22:12:24 - GraphTrainer - INFO -   precision@10: 0.002407
2025-11-22 22:12:24 - GraphTrainer - INFO -   recall@10: 0.022982
2025-11-22 22:12:24 - GraphTrainer - INFO -   hit_rate@10: 0.024016
2025-11-22 22:12:24 - GraphTrainer - INFO -   ndcg@10: 0.012613
2025-11-22 22:12:24 - GraphTrainer - INFO -   map@10: 0.009407
2025-11-22 22:12:24 - GraphTrainer - INFO -   mrr@10: 0.009765
2025-11-22 22:12:24 - GraphTrainer - INFO -   precision@20: 0.002080
2025-11-22 22:12:24 - GraphTrainer - INFO -   recall@20: 0.039463
2025-11-22 22:12:24 - GraphTrainer - INFO -   hit_rate@20: 0.041450
2025-11-22 22:12:24 - GraphTrainer - INFO -   ndcg@20: 0.016839
2025-11-22 22:12:24 - GraphTrainer - INFO -   map@20: 0.010558
2025-11-22 22:12:24 - GraphTrainer - INFO -   mrr@20: 0.010980
2025-11-22 22:12:24 - GraphTrainer - INFO - 第 2 轮训练完成
2025-11-22 22:12:24 - GraphTrainer - INFO - train_loss: 0.625511
2025-11-22 22:12:24 - GraphTrainer - INFO - precision@5: 0.002756
2025-11-22 22:12:24 - GraphTrainer - INFO - recall@5: 0.013177
2025-11-22 22:12:24 - GraphTrainer - INFO - hit_rate@5: 0.013782
2025-11-22 22:12:24 - GraphTrainer - INFO - ndcg@5: 0.009434
2025-11-22 22:12:24 - GraphTrainer - INFO - map@5: 0.008119
2025-11-22 22:12:24 - GraphTrainer - INFO - mrr@5: 0.008422
2025-11-22 22:12:24 - GraphTrainer - INFO - precision@10: 0.002407
2025-11-22 22:12:24 - GraphTrainer - INFO - recall@10: 0.022982
2025-11-22 22:12:24 - GraphTrainer - INFO - hit_rate@10: 0.024016
2025-11-22 22:12:24 - GraphTrainer - INFO - ndcg@10: 0.012613
2025-11-22 22:12:24 - GraphTrainer - INFO - map@10: 0.009407
2025-11-22 22:12:24 - GraphTrainer - INFO - mrr@10: 0.009765
2025-11-22 22:12:24 - GraphTrainer - INFO - precision@20: 0.002080
2025-11-22 22:12:24 - GraphTrainer - INFO - recall@20: 0.039463
2025-11-22 22:12:24 - GraphTrainer - INFO - hit_rate@20: 0.041450
2025-11-22 22:12:24 - GraphTrainer - INFO - ndcg@20: 0.016839
2025-11-22 22:12:24 - GraphTrainer - INFO - map@20: 0.010558
2025-11-22 22:12:24 - GraphTrainer - INFO - mrr@20: 0.010980
2025-11-22 22:12:24 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:12:24 - GraphTrainer - INFO - ============================================================
2025-11-22 22:12:24 - GraphTrainer - INFO - 开始第 3/1000 轮训练
2025-11-22 22:12:24 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.6500, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.6520, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.6502, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.6432, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.6263, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.6458, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.6420, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.6340, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.6458, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.6379, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.6396, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.6300, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.6337, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.6396, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.6363, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.6273, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.6293, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.6304, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.6328, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.6198, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.6316, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.6362, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.6307, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.6421, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.6070, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.6081, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.6200, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.6372, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.6317, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.6308, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.6126, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.6237, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.6104, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.6190, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.6060, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.6216, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.6134, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.6136, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.6178, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.6259, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.6213, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.6270, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.6099, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.6259, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.6229, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.6190, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.6266, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.6154, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.6262, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.6212, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.6185, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.6162, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.6144, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.6052, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.6027, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.6011, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.6018, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.6192, device='cuda:0', grad_fn=<AddBackward0>)
The 2 training average loss: 0.6255109125170214
2025-11-22 22:12:35 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:12:35 - GraphTrainer - INFO -   precision@5: 0.003219
2025-11-22 22:12:35 - GraphTrainer - INFO -   recall@5: 0.015114
2025-11-22 22:12:35 - GraphTrainer - INFO -   hit_rate@5: 0.016045
2025-11-22 22:12:35 - GraphTrainer - INFO -   ndcg@5: 0.008593
2025-11-22 22:12:35 - GraphTrainer - INFO -   map@5: 0.006297
2025-11-22 22:12:35 - GraphTrainer - INFO -   mrr@5: 0.006740
2025-11-22 22:12:35 - GraphTrainer - INFO -   precision@10: 0.002854
2025-11-22 22:12:35 - GraphTrainer - INFO -   recall@10: 0.026914
2025-11-22 22:12:35 - GraphTrainer - INFO -   hit_rate@10: 0.028388
2025-11-22 22:12:35 - GraphTrainer - INFO -   ndcg@10: 0.012462
2025-11-22 22:12:35 - GraphTrainer - INFO -   map@10: 0.007891
2025-11-22 22:12:35 - GraphTrainer - INFO -   mrr@10: 0.008405
2025-11-22 22:12:35 - GraphTrainer - INFO -   precision@20: 0.002214
2025-11-22 22:12:35 - GraphTrainer - INFO -   recall@20: 0.041624
2025-11-22 22:12:35 - GraphTrainer - INFO -   hit_rate@20: 0.044022
2025-11-22 22:12:35 - GraphTrainer - INFO -   ndcg@20: 0.016218
2025-11-22 22:12:35 - GraphTrainer - INFO -   map@20: 0.008901
2025-11-22 22:12:35 - GraphTrainer - INFO -   mrr@20: 0.009476
2025-11-22 22:12:35 - GraphTrainer - INFO - 第 3 轮训练完成
2025-11-22 22:12:35 - GraphTrainer - INFO - train_loss: 0.592998
2025-11-22 22:12:35 - GraphTrainer - INFO - precision@5: 0.003219
2025-11-22 22:12:35 - GraphTrainer - INFO - recall@5: 0.015114
2025-11-22 22:12:35 - GraphTrainer - INFO - hit_rate@5: 0.016045
2025-11-22 22:12:35 - GraphTrainer - INFO - ndcg@5: 0.008593
2025-11-22 22:12:35 - GraphTrainer - INFO - map@5: 0.006297
2025-11-22 22:12:35 - GraphTrainer - INFO - mrr@5: 0.006740
2025-11-22 22:12:35 - GraphTrainer - INFO - precision@10: 0.002854
2025-11-22 22:12:35 - GraphTrainer - INFO - recall@10: 0.026914
2025-11-22 22:12:35 - GraphTrainer - INFO - hit_rate@10: 0.028388
2025-11-22 22:12:35 - GraphTrainer - INFO - ndcg@10: 0.012462
2025-11-22 22:12:35 - GraphTrainer - INFO - map@10: 0.007891
2025-11-22 22:12:35 - GraphTrainer - INFO - mrr@10: 0.008405
2025-11-22 22:12:35 - GraphTrainer - INFO - precision@20: 0.002214
2025-11-22 22:12:35 - GraphTrainer - INFO - recall@20: 0.041624
2025-11-22 22:12:35 - GraphTrainer - INFO - hit_rate@20: 0.044022
2025-11-22 22:12:35 - GraphTrainer - INFO - ndcg@20: 0.016218
2025-11-22 22:12:35 - GraphTrainer - INFO - map@20: 0.008901
2025-11-22 22:12:35 - GraphTrainer - INFO - mrr@20: 0.009476
2025-11-22 22:12:35 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:12:35 - GraphTrainer - INFO - ============================================================
2025-11-22 22:12:35 - GraphTrainer - INFO - 开始第 4/1000 轮训练
2025-11-22 22:12:35 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.6126, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.6107, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.6011, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.6045, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.5829, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.5937, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.6164, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.6097, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.6097, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.6122, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.5978, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.6133, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.5930, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.5969, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.6034, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.6127, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.6074, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.5976, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.5988, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.6051, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.5828, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.5895, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.5854, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.6003, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.5842, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.5668, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.5662, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.5968, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.5933, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.5883, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.5918, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.5767, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.5943, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.6018, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.6081, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.5681, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.5932, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.5884, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.5939, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.5930, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.5853, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.5816, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.5925, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.6065, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.5994, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.5989, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.5851, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.5732, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.5872, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.5724, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.5746, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.5770, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.5862, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.5835, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.5841, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.5770, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.5986, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.5882, device='cuda:0', grad_fn=<AddBackward0>)
The 3 training average loss: 0.5929984974450079
2025-11-22 22:12:46 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:12:46 - GraphTrainer - INFO -   precision@5: 0.003003
2025-11-22 22:12:46 - GraphTrainer - INFO -   recall@5: 0.014131
2025-11-22 22:12:46 - GraphTrainer - INFO -   hit_rate@5: 0.014965
2025-11-22 22:12:46 - GraphTrainer - INFO -   ndcg@5: 0.007990
2025-11-22 22:12:46 - GraphTrainer - INFO -   map@5: 0.005829
2025-11-22 22:12:46 - GraphTrainer - INFO -   mrr@5: 0.006303
2025-11-22 22:12:46 - GraphTrainer - INFO -   precision@10: 0.002489
2025-11-22 22:12:46 - GraphTrainer - INFO -   recall@10: 0.023362
2025-11-22 22:12:46 - GraphTrainer - INFO -   hit_rate@10: 0.024788
2025-11-22 22:12:46 - GraphTrainer - INFO -   ndcg@10: 0.010996
2025-11-22 22:12:46 - GraphTrainer - INFO -   map@10: 0.007050
2025-11-22 22:12:46 - GraphTrainer - INFO -   mrr@10: 0.007601
2025-11-22 22:12:46 - GraphTrainer - INFO -   precision@20: 0.002134
2025-11-22 22:12:46 - GraphTrainer - INFO -   recall@20: 0.040385
2025-11-22 22:12:46 - GraphTrainer - INFO -   hit_rate@20: 0.042530
2025-11-22 22:12:46 - GraphTrainer - INFO -   ndcg@20: 0.015304
2025-11-22 22:12:46 - GraphTrainer - INFO -   map@20: 0.008204
2025-11-22 22:12:46 - GraphTrainer - INFO -   mrr@20: 0.008801
2025-11-22 22:12:46 - GraphTrainer - INFO - 第 4 轮训练完成
2025-11-22 22:12:46 - GraphTrainer - INFO - train_loss: 0.572643
2025-11-22 22:12:46 - GraphTrainer - INFO - precision@5: 0.003003
2025-11-22 22:12:46 - GraphTrainer - INFO - recall@5: 0.014131
2025-11-22 22:12:46 - GraphTrainer - INFO - hit_rate@5: 0.014965
2025-11-22 22:12:46 - GraphTrainer - INFO - ndcg@5: 0.007990
2025-11-22 22:12:46 - GraphTrainer - INFO - map@5: 0.005829
2025-11-22 22:12:46 - GraphTrainer - INFO - mrr@5: 0.006303
2025-11-22 22:12:46 - GraphTrainer - INFO - precision@10: 0.002489
2025-11-22 22:12:46 - GraphTrainer - INFO - recall@10: 0.023362
2025-11-22 22:12:46 - GraphTrainer - INFO - hit_rate@10: 0.024788
2025-11-22 22:12:46 - GraphTrainer - INFO - ndcg@10: 0.010996
2025-11-22 22:12:46 - GraphTrainer - INFO - map@10: 0.007050
2025-11-22 22:12:46 - GraphTrainer - INFO - mrr@10: 0.007601
2025-11-22 22:12:46 - GraphTrainer - INFO - precision@20: 0.002134
2025-11-22 22:12:46 - GraphTrainer - INFO - recall@20: 0.040385
2025-11-22 22:12:46 - GraphTrainer - INFO - hit_rate@20: 0.042530
2025-11-22 22:12:46 - GraphTrainer - INFO - ndcg@20: 0.015304
2025-11-22 22:12:46 - GraphTrainer - INFO - map@20: 0.008204
2025-11-22 22:12:46 - GraphTrainer - INFO - mrr@20: 0.008801
2025-11-22 22:12:46 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:12:46 - GraphTrainer - INFO - ============================================================
2025-11-22 22:12:46 - GraphTrainer - INFO - 开始第 5/1000 轮训练
2025-11-22 22:12:46 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.5749, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.5727, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.5777, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.5627, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.5854, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.5634, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.5830, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.5649, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.5809, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.6002, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.5680, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.5849, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.5743, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.5750, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.5842, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.5790, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.5860, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.5792, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.5702, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.5864, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.5788, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.5620, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.5866, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.5782, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.5800, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.5466, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.5821, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.5834, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.5759, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.5674, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.5744, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.5670, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.5582, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.5704, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.5584, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.5775, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.5909, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.5809, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.5767, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.5823, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.5705, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.5685, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.5863, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.5607, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.5616, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.5699, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.5828, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.5624, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.5585, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.5689, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.5737, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.5602, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.5589, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.5497, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.5666, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.5707, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.5587, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.5539, device='cuda:0', grad_fn=<AddBackward0>)
The 4 training average loss: 0.5726431567093422
2025-11-22 22:12:57 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:12:57 - GraphTrainer - INFO -   precision@5: 0.003734
2025-11-22 22:12:57 - GraphTrainer - INFO -   recall@5: 0.017715
2025-11-22 22:12:57 - GraphTrainer - INFO -   hit_rate@5: 0.018617
2025-11-22 22:12:57 - GraphTrainer - INFO -   ndcg@5: 0.011031
2025-11-22 22:12:57 - GraphTrainer - INFO -   map@5: 0.008699
2025-11-22 22:12:57 - GraphTrainer - INFO -   mrr@5: 0.009105
2025-11-22 22:12:57 - GraphTrainer - INFO -   precision@10: 0.003142
2025-11-22 22:12:57 - GraphTrainer - INFO -   recall@10: 0.029658
2025-11-22 22:12:57 - GraphTrainer - INFO -   hit_rate@10: 0.031319
2025-11-22 22:12:57 - GraphTrainer - INFO -   ndcg@10: 0.014907
2025-11-22 22:12:57 - GraphTrainer - INFO -   map@10: 0.010262
2025-11-22 22:12:57 - GraphTrainer - INFO -   mrr@10: 0.010758
2025-11-22 22:12:57 - GraphTrainer - INFO -   precision@20: 0.002659
2025-11-22 22:12:57 - GraphTrainer - INFO -   recall@20: 0.050360
2025-11-22 22:12:57 - GraphTrainer - INFO -   hit_rate@20: 0.052918
2025-11-22 22:12:57 - GraphTrainer - INFO -   ndcg@20: 0.020162
2025-11-22 22:12:57 - GraphTrainer - INFO -   map@20: 0.011676
2025-11-22 22:12:57 - GraphTrainer - INFO -   mrr@20: 0.012223
2025-11-22 22:12:57 - GraphTrainer - INFO - 第 5 轮训练完成
2025-11-22 22:12:57 - GraphTrainer - INFO - train_loss: 0.555466
2025-11-22 22:12:57 - GraphTrainer - INFO - precision@5: 0.003734
2025-11-22 22:12:57 - GraphTrainer - INFO - recall@5: 0.017715
2025-11-22 22:12:57 - GraphTrainer - INFO - hit_rate@5: 0.018617
2025-11-22 22:12:57 - GraphTrainer - INFO - ndcg@5: 0.011031
2025-11-22 22:12:57 - GraphTrainer - INFO - map@5: 0.008699
2025-11-22 22:12:57 - GraphTrainer - INFO - mrr@5: 0.009105
2025-11-22 22:12:57 - GraphTrainer - INFO - precision@10: 0.003142
2025-11-22 22:12:57 - GraphTrainer - INFO - recall@10: 0.029658
2025-11-22 22:12:57 - GraphTrainer - INFO - hit_rate@10: 0.031319
2025-11-22 22:12:57 - GraphTrainer - INFO - ndcg@10: 0.014907
2025-11-22 22:12:57 - GraphTrainer - INFO - map@10: 0.010262
2025-11-22 22:12:57 - GraphTrainer - INFO - mrr@10: 0.010758
2025-11-22 22:12:57 - GraphTrainer - INFO - precision@20: 0.002659
2025-11-22 22:12:57 - GraphTrainer - INFO - recall@20: 0.050360
2025-11-22 22:12:57 - GraphTrainer - INFO - hit_rate@20: 0.052918
2025-11-22 22:12:57 - GraphTrainer - INFO - ndcg@20: 0.020162
2025-11-22 22:12:57 - GraphTrainer - INFO - map@20: 0.011676
2025-11-22 22:12:57 - GraphTrainer - INFO - mrr@20: 0.012223
2025-11-22 22:12:57 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:12:57 - GraphTrainer - INFO - ============================================================
2025-11-22 22:12:57 - GraphTrainer - INFO - 开始第 6/1000 轮训练
2025-11-22 22:12:57 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.5585, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.5538, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.5680, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.5644, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.5687, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.5623, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.5703, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.5555, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.5464, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.5616, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.5512, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.5500, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.5548, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.5502, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.5694, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.5527, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.5663, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.5613, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.5218, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.5565, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.5432, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.5582, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.5653, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.5466, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.5647, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.5664, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.5805, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.5661, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.5736, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.5451, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.5579, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.5335, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.5624, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.5568, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.5660, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.5675, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.5362, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.5513, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.5627, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.5441, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.5591, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.5447, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.5416, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.5489, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.5453, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.5745, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.5486, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.5541, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.5416, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.5627, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.5525, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.5482, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.5371, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.5450, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.5446, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.5652, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.5456, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.5656, device='cuda:0', grad_fn=<AddBackward0>)
The 5 training average loss: 0.5554657855938221
2025-11-22 22:13:09 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:13:09 - GraphTrainer - INFO -   precision@5: 0.003209
2025-11-22 22:13:09 - GraphTrainer - INFO -   recall@5: 0.015160
2025-11-22 22:13:09 - GraphTrainer - INFO -   hit_rate@5: 0.016045
2025-11-22 22:13:09 - GraphTrainer - INFO -   ndcg@5: 0.008725
2025-11-22 22:13:09 - GraphTrainer - INFO -   map@5: 0.006504
2025-11-22 22:13:09 - GraphTrainer - INFO -   mrr@5: 0.006857
2025-11-22 22:13:09 - GraphTrainer - INFO -   precision@10: 0.003003
2025-11-22 22:13:09 - GraphTrainer - INFO -   recall@10: 0.028599
2025-11-22 22:13:09 - GraphTrainer - INFO -   hit_rate@10: 0.029931
2025-11-22 22:13:09 - GraphTrainer - INFO -   ndcg@10: 0.013031
2025-11-22 22:13:09 - GraphTrainer - INFO -   map@10: 0.008228
2025-11-22 22:13:09 - GraphTrainer - INFO -   mrr@10: 0.008637
2025-11-22 22:13:09 - GraphTrainer - INFO -   precision@20: 0.002636
2025-11-22 22:13:09 - GraphTrainer - INFO -   recall@20: 0.050090
2025-11-22 22:13:09 - GraphTrainer - INFO -   hit_rate@20: 0.052456
2025-11-22 22:13:09 - GraphTrainer - INFO -   ndcg@20: 0.018446
2025-11-22 22:13:09 - GraphTrainer - INFO -   map@20: 0.009659
2025-11-22 22:13:09 - GraphTrainer - INFO -   mrr@20: 0.010136
2025-11-22 22:13:09 - GraphTrainer - INFO - 第 6 轮训练完成
2025-11-22 22:13:09 - GraphTrainer - INFO - train_loss: 0.539288
2025-11-22 22:13:09 - GraphTrainer - INFO - precision@5: 0.003209
2025-11-22 22:13:09 - GraphTrainer - INFO - recall@5: 0.015160
2025-11-22 22:13:09 - GraphTrainer - INFO - hit_rate@5: 0.016045
2025-11-22 22:13:09 - GraphTrainer - INFO - ndcg@5: 0.008725
2025-11-22 22:13:09 - GraphTrainer - INFO - map@5: 0.006504
2025-11-22 22:13:09 - GraphTrainer - INFO - mrr@5: 0.006857
2025-11-22 22:13:09 - GraphTrainer - INFO - precision@10: 0.003003
2025-11-22 22:13:09 - GraphTrainer - INFO - recall@10: 0.028599
2025-11-22 22:13:09 - GraphTrainer - INFO - hit_rate@10: 0.029931
2025-11-22 22:13:09 - GraphTrainer - INFO - ndcg@10: 0.013031
2025-11-22 22:13:09 - GraphTrainer - INFO - map@10: 0.008228
2025-11-22 22:13:09 - GraphTrainer - INFO - mrr@10: 0.008637
2025-11-22 22:13:09 - GraphTrainer - INFO - precision@20: 0.002636
2025-11-22 22:13:09 - GraphTrainer - INFO - recall@20: 0.050090
2025-11-22 22:13:09 - GraphTrainer - INFO - hit_rate@20: 0.052456
2025-11-22 22:13:09 - GraphTrainer - INFO - ndcg@20: 0.018446
2025-11-22 22:13:09 - GraphTrainer - INFO - map@20: 0.009659
2025-11-22 22:13:09 - GraphTrainer - INFO - mrr@20: 0.010136
2025-11-22 22:13:09 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:13:09 - GraphTrainer - INFO - ============================================================
2025-11-22 22:13:09 - GraphTrainer - INFO - 开始第 7/1000 轮训练
2025-11-22 22:13:09 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.5712, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.5577, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.5584, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.5415, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.5383, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.5540, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.5438, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.5554, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.5432, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.5348, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.5604, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.5243, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.5460, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.5520, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.5540, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.5292, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.5678, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.5238, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.5368, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.5380, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.5285, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.5410, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.5322, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.5353, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.5444, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.5198, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.5398, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.5134, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.5387, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.5519, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.5409, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.5518, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.5238, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.5306, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.5407, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.5490, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.5612, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.5521, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.5330, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.5343, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.5391, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.5418, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.5338, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.5259, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.5337, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.5239, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.5362, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.5481, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.5270, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.5271, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.5166, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.5357, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.5422, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.5143, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.5184, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.5330, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.5477, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.5412, device='cuda:0', grad_fn=<AddBackward0>)
The 6 training average loss: 0.5392880131458414
2025-11-22 22:13:20 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:13:20 - GraphTrainer - INFO -   precision@5: 0.003878
2025-11-22 22:13:20 - GraphTrainer - INFO -   recall@5: 0.018221
2025-11-22 22:13:20 - GraphTrainer - INFO -   hit_rate@5: 0.019337
2025-11-22 22:13:20 - GraphTrainer - INFO -   ndcg@5: 0.012920
2025-11-22 22:13:20 - GraphTrainer - INFO -   map@5: 0.010993
2025-11-22 22:13:20 - GraphTrainer - INFO -   mrr@5: 0.011532
2025-11-22 22:13:20 - GraphTrainer - INFO -   precision@10: 0.003132
2025-11-22 22:13:20 - GraphTrainer - INFO -   recall@10: 0.029651
2025-11-22 22:13:20 - GraphTrainer - INFO -   hit_rate@10: 0.031268
2025-11-22 22:13:20 - GraphTrainer - INFO -   ndcg@10: 0.016605
2025-11-22 22:13:20 - GraphTrainer - INFO -   map@10: 0.012481
2025-11-22 22:13:20 - GraphTrainer - INFO -   mrr@10: 0.013077
2025-11-22 22:13:20 - GraphTrainer - INFO -   precision@20: 0.002522
2025-11-22 22:13:20 - GraphTrainer - INFO -   recall@20: 0.047762
2025-11-22 22:13:20 - GraphTrainer - INFO -   hit_rate@20: 0.050296
2025-11-22 22:13:20 - GraphTrainer - INFO -   ndcg@20: 0.021198
2025-11-22 22:13:20 - GraphTrainer - INFO -   map@20: 0.013708
2025-11-22 22:13:20 - GraphTrainer - INFO -   mrr@20: 0.014364
2025-11-22 22:13:20 - GraphTrainer - INFO - 第 7 轮训练完成
2025-11-22 22:13:20 - GraphTrainer - INFO - train_loss: 0.526049
2025-11-22 22:13:20 - GraphTrainer - INFO - precision@5: 0.003878
2025-11-22 22:13:20 - GraphTrainer - INFO - recall@5: 0.018221
2025-11-22 22:13:20 - GraphTrainer - INFO - hit_rate@5: 0.019337
2025-11-22 22:13:20 - GraphTrainer - INFO - ndcg@5: 0.012920
2025-11-22 22:13:20 - GraphTrainer - INFO - map@5: 0.010993
2025-11-22 22:13:20 - GraphTrainer - INFO - mrr@5: 0.011532
2025-11-22 22:13:20 - GraphTrainer - INFO - precision@10: 0.003132
2025-11-22 22:13:20 - GraphTrainer - INFO - recall@10: 0.029651
2025-11-22 22:13:20 - GraphTrainer - INFO - hit_rate@10: 0.031268
2025-11-22 22:13:20 - GraphTrainer - INFO - ndcg@10: 0.016605
2025-11-22 22:13:20 - GraphTrainer - INFO - map@10: 0.012481
2025-11-22 22:13:20 - GraphTrainer - INFO - mrr@10: 0.013077
2025-11-22 22:13:20 - GraphTrainer - INFO - precision@20: 0.002522
2025-11-22 22:13:20 - GraphTrainer - INFO - recall@20: 0.047762
2025-11-22 22:13:20 - GraphTrainer - INFO - hit_rate@20: 0.050296
2025-11-22 22:13:20 - GraphTrainer - INFO - ndcg@20: 0.021198
2025-11-22 22:13:20 - GraphTrainer - INFO - map@20: 0.013708
2025-11-22 22:13:20 - GraphTrainer - INFO - mrr@20: 0.014364
2025-11-22 22:13:20 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:13:20 - GraphTrainer - INFO - ============================================================
2025-11-22 22:13:20 - GraphTrainer - INFO - 开始第 8/1000 轮训练
2025-11-22 22:13:20 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.5246, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.5307, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.5175, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.5180, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.5360, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.5142, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.5214, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.5354, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.5255, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.5403, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.5313, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.5256, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.5289, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.5325, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.5261, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.5189, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.5241, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.5219, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.5217, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.5270, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.5248, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.5323, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.5379, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.5295, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.5244, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.5305, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.5341, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.5260, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.5235, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.5269, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.5292, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.5315, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.5453, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.5277, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.5440, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.5301, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.5457, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.5340, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.5186, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.5242, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.5253, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.5152, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.5352, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.5088, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.5109, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.5202, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.5242, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.5300, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.5154, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.5247, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.5220, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.5182, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.5147, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.5323, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.5272, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.5240, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.5177, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.5030, device='cuda:0', grad_fn=<AddBackward0>)
The 7 training average loss: 0.5260487887366064
2025-11-22 22:13:31 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:13:31 - GraphTrainer - INFO -   precision@5: 0.004330
2025-11-22 22:13:31 - GraphTrainer - INFO -   recall@5: 0.020623
2025-11-22 22:13:31 - GraphTrainer - INFO -   hit_rate@5: 0.021599
2025-11-22 22:13:31 - GraphTrainer - INFO -   ndcg@5: 0.013402
2025-11-22 22:13:31 - GraphTrainer - INFO -   map@5: 0.010874
2025-11-22 22:13:31 - GraphTrainer - INFO -   mrr@5: 0.011389
2025-11-22 22:13:31 - GraphTrainer - INFO -   precision@10: 0.003492
2025-11-22 22:13:31 - GraphTrainer - INFO -   recall@10: 0.033031
2025-11-22 22:13:31 - GraphTrainer - INFO -   hit_rate@10: 0.034765
2025-11-22 22:13:31 - GraphTrainer - INFO -   ndcg@10: 0.017477
2025-11-22 22:13:31 - GraphTrainer - INFO -   map@10: 0.012546
2025-11-22 22:13:31 - GraphTrainer - INFO -   mrr@10: 0.013161
2025-11-22 22:13:31 - GraphTrainer - INFO -   precision@20: 0.002708
2025-11-22 22:13:31 - GraphTrainer - INFO -   recall@20: 0.051346
2025-11-22 22:13:31 - GraphTrainer - INFO -   hit_rate@20: 0.053741
2025-11-22 22:13:31 - GraphTrainer - INFO -   ndcg@20: 0.022110
2025-11-22 22:13:31 - GraphTrainer - INFO -   map@20: 0.013785
2025-11-22 22:13:31 - GraphTrainer - INFO -   mrr@20: 0.014440
2025-11-22 22:13:31 - GraphTrainer - INFO - 第 8 轮训练完成
2025-11-22 22:13:31 - GraphTrainer - INFO - train_loss: 0.512209
2025-11-22 22:13:31 - GraphTrainer - INFO - precision@5: 0.004330
2025-11-22 22:13:31 - GraphTrainer - INFO - recall@5: 0.020623
2025-11-22 22:13:31 - GraphTrainer - INFO - hit_rate@5: 0.021599
2025-11-22 22:13:31 - GraphTrainer - INFO - ndcg@5: 0.013402
2025-11-22 22:13:31 - GraphTrainer - INFO - map@5: 0.010874
2025-11-22 22:13:31 - GraphTrainer - INFO - mrr@5: 0.011389
2025-11-22 22:13:31 - GraphTrainer - INFO - precision@10: 0.003492
2025-11-22 22:13:31 - GraphTrainer - INFO - recall@10: 0.033031
2025-11-22 22:13:31 - GraphTrainer - INFO - hit_rate@10: 0.034765
2025-11-22 22:13:31 - GraphTrainer - INFO - ndcg@10: 0.017477
2025-11-22 22:13:31 - GraphTrainer - INFO - map@10: 0.012546
2025-11-22 22:13:31 - GraphTrainer - INFO - mrr@10: 0.013161
2025-11-22 22:13:31 - GraphTrainer - INFO - precision@20: 0.002708
2025-11-22 22:13:31 - GraphTrainer - INFO - recall@20: 0.051346
2025-11-22 22:13:31 - GraphTrainer - INFO - hit_rate@20: 0.053741
2025-11-22 22:13:31 - GraphTrainer - INFO - ndcg@20: 0.022110
2025-11-22 22:13:31 - GraphTrainer - INFO - map@20: 0.013785
2025-11-22 22:13:31 - GraphTrainer - INFO - mrr@20: 0.014440
2025-11-22 22:13:31 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:13:31 - GraphTrainer - INFO - ============================================================
2025-11-22 22:13:31 - GraphTrainer - INFO - 开始第 9/1000 轮训练
2025-11-22 22:13:31 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.5304, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.5281, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.5161, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.5250, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.5162, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.5150, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.5366, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.5312, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.5103, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.5301, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4964, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.5074, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.5041, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.5150, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.5032, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.5158, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.5171, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.5210, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.5177, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.5039, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.5355, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.5141, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.5204, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.5129, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.5041, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.5088, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4996, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.5155, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4976, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.5271, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.5257, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.5061, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.5078, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.5101, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.5015, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.5155, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4989, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.5005, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.5082, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.5166, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.5154, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.5239, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4864, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.5147, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.5110, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4953, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.5151, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.5169, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.5115, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.5031, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.5161, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.5007, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.5075, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4987, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.5011, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.5154, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4961, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.5123, device='cuda:0', grad_fn=<AddBackward0>)
The 8 training average loss: 0.5122089956341118
2025-11-22 22:13:42 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:13:42 - GraphTrainer - INFO -   precision@5: 0.004114
2025-11-22 22:13:42 - GraphTrainer - INFO -   recall@5: 0.019715
2025-11-22 22:13:42 - GraphTrainer - INFO -   hit_rate@5: 0.020519
2025-11-22 22:13:42 - GraphTrainer - INFO -   ndcg@5: 0.012619
2025-11-22 22:13:42 - GraphTrainer - INFO -   map@5: 0.010170
2025-11-22 22:13:42 - GraphTrainer - INFO -   mrr@5: 0.010591
2025-11-22 22:13:42 - GraphTrainer - INFO -   precision@10: 0.003471
2025-11-22 22:13:42 - GraphTrainer - INFO -   recall@10: 0.033055
2025-11-22 22:13:42 - GraphTrainer - INFO -   hit_rate@10: 0.034559
2025-11-22 22:13:42 - GraphTrainer - INFO -   ndcg@10: 0.016928
2025-11-22 22:13:42 - GraphTrainer - INFO -   map@10: 0.011902
2025-11-22 22:13:42 - GraphTrainer - INFO -   mrr@10: 0.012414
2025-11-22 22:13:42 - GraphTrainer - INFO -   precision@20: 0.002813
2025-11-22 22:13:42 - GraphTrainer - INFO -   recall@20: 0.053640
2025-11-22 22:13:42 - GraphTrainer - INFO -   hit_rate@20: 0.056107
2025-11-22 22:13:42 - GraphTrainer - INFO -   ndcg@20: 0.022116
2025-11-22 22:13:42 - GraphTrainer - INFO -   map@20: 0.013277
2025-11-22 22:13:42 - GraphTrainer - INFO -   mrr@20: 0.013854
2025-11-22 22:13:42 - GraphTrainer - INFO - 第 9 轮训练完成
2025-11-22 22:13:42 - GraphTrainer - INFO - train_loss: 0.504066
2025-11-22 22:13:42 - GraphTrainer - INFO - precision@5: 0.004114
2025-11-22 22:13:42 - GraphTrainer - INFO - recall@5: 0.019715
2025-11-22 22:13:42 - GraphTrainer - INFO - hit_rate@5: 0.020519
2025-11-22 22:13:42 - GraphTrainer - INFO - ndcg@5: 0.012619
2025-11-22 22:13:42 - GraphTrainer - INFO - map@5: 0.010170
2025-11-22 22:13:42 - GraphTrainer - INFO - mrr@5: 0.010591
2025-11-22 22:13:42 - GraphTrainer - INFO - precision@10: 0.003471
2025-11-22 22:13:42 - GraphTrainer - INFO - recall@10: 0.033055
2025-11-22 22:13:42 - GraphTrainer - INFO - hit_rate@10: 0.034559
2025-11-22 22:13:42 - GraphTrainer - INFO - ndcg@10: 0.016928
2025-11-22 22:13:42 - GraphTrainer - INFO - map@10: 0.011902
2025-11-22 22:13:42 - GraphTrainer - INFO - mrr@10: 0.012414
2025-11-22 22:13:42 - GraphTrainer - INFO - precision@20: 0.002813
2025-11-22 22:13:42 - GraphTrainer - INFO - recall@20: 0.053640
2025-11-22 22:13:42 - GraphTrainer - INFO - hit_rate@20: 0.056107
2025-11-22 22:13:42 - GraphTrainer - INFO - ndcg@20: 0.022116
2025-11-22 22:13:42 - GraphTrainer - INFO - map@20: 0.013277
2025-11-22 22:13:42 - GraphTrainer - INFO - mrr@20: 0.013854
2025-11-22 22:13:42 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:13:42 - GraphTrainer - INFO - ============================================================
2025-11-22 22:13:42 - GraphTrainer - INFO - 开始第 10/1000 轮训练
2025-11-22 22:13:42 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4940, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.5010, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.5138, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4999, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.5078, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4969, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.5255, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4912, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.5014, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.5088, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4921, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.5040, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.5142, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4954, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.5089, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.5239, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4939, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.5035, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.5136, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.5268, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4942, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4937, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4978, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.5097, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.5239, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.5074, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.5122, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.5064, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4980, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.5222, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4993, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.5123, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4898, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4803, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4935, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.5158, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.5106, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4990, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4885, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.5279, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4761, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.5037, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.5241, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.5085, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4973, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.5097, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4922, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.5004, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4984, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4942, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4950, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4834, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.5175, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.5013, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4898, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.5181, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.5036, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.5234, device='cuda:0', grad_fn=<AddBackward0>)
The 9 training average loss: 0.5040657561400841
2025-11-22 22:13:53 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:13:53 - GraphTrainer - INFO -   precision@5: 0.004196
2025-11-22 22:13:53 - GraphTrainer - INFO -   recall@5: 0.020139
2025-11-22 22:13:53 - GraphTrainer - INFO -   hit_rate@5: 0.020931
2025-11-22 22:13:53 - GraphTrainer - INFO -   ndcg@5: 0.012693
2025-11-22 22:13:53 - GraphTrainer - INFO -   map@5: 0.010132
2025-11-22 22:13:53 - GraphTrainer - INFO -   mrr@5: 0.010507
2025-11-22 22:13:53 - GraphTrainer - INFO -   precision@10: 0.003713
2025-11-22 22:13:53 - GraphTrainer - INFO -   recall@10: 0.035568
2025-11-22 22:13:53 - GraphTrainer - INFO -   hit_rate@10: 0.037028
2025-11-22 22:13:53 - GraphTrainer - INFO -   ndcg@10: 0.017705
2025-11-22 22:13:53 - GraphTrainer - INFO -   map@10: 0.012175
2025-11-22 22:13:53 - GraphTrainer - INFO -   mrr@10: 0.012630
2025-11-22 22:13:53 - GraphTrainer - INFO -   precision@20: 0.002924
2025-11-22 22:13:53 - GraphTrainer - INFO -   recall@20: 0.055860
2025-11-22 22:13:53 - GraphTrainer - INFO -   hit_rate@20: 0.058267
2025-11-22 22:13:53 - GraphTrainer - INFO -   ndcg@20: 0.022871
2025-11-22 22:13:53 - GraphTrainer - INFO -   map@20: 0.013570
2025-11-22 22:13:53 - GraphTrainer - INFO -   mrr@20: 0.014088
2025-11-22 22:13:53 - GraphTrainer - INFO - 第 10 轮训练完成
2025-11-22 22:13:53 - GraphTrainer - INFO - train_loss: 0.497155
2025-11-22 22:13:53 - GraphTrainer - INFO - precision@5: 0.004196
2025-11-22 22:13:53 - GraphTrainer - INFO - recall@5: 0.020139
2025-11-22 22:13:53 - GraphTrainer - INFO - hit_rate@5: 0.020931
2025-11-22 22:13:53 - GraphTrainer - INFO - ndcg@5: 0.012693
2025-11-22 22:13:53 - GraphTrainer - INFO - map@5: 0.010132
2025-11-22 22:13:53 - GraphTrainer - INFO - mrr@5: 0.010507
2025-11-22 22:13:53 - GraphTrainer - INFO - precision@10: 0.003713
2025-11-22 22:13:53 - GraphTrainer - INFO - recall@10: 0.035568
2025-11-22 22:13:53 - GraphTrainer - INFO - hit_rate@10: 0.037028
2025-11-22 22:13:53 - GraphTrainer - INFO - ndcg@10: 0.017705
2025-11-22 22:13:53 - GraphTrainer - INFO - map@10: 0.012175
2025-11-22 22:13:53 - GraphTrainer - INFO - mrr@10: 0.012630
2025-11-22 22:13:53 - GraphTrainer - INFO - precision@20: 0.002924
2025-11-22 22:13:53 - GraphTrainer - INFO - recall@20: 0.055860
2025-11-22 22:13:53 - GraphTrainer - INFO - hit_rate@20: 0.058267
2025-11-22 22:13:53 - GraphTrainer - INFO - ndcg@20: 0.022871
2025-11-22 22:13:53 - GraphTrainer - INFO - map@20: 0.013570
2025-11-22 22:13:53 - GraphTrainer - INFO - mrr@20: 0.014088
2025-11-22 22:13:53 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:13:53 - GraphTrainer - INFO - 检查点已保存: Epoch 10 -> ./checkpoints/checkpoint_epoch_10.pth
2025-11-22 22:13:53 - GraphTrainer - INFO - ============================================================
2025-11-22 22:13:53 - GraphTrainer - INFO - 开始第 11/1000 轮训练
2025-11-22 22:13:53 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.5005, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4993, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.5047, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.5077, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4954, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4987, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4957, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4897, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.5190, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.5018, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4979, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4965, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4738, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4830, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4966, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.5124, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4865, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4939, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4755, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.5071, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.5016, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4847, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4928, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4904, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.5066, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4815, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4824, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.5098, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4933, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4975, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.5047, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.5073, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.5248, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4832, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4957, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.5032, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.5180, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.5026, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4994, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4938, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4930, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.5118, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4921, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4834, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.5008, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4914, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4986, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4908, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4868, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4838, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4909, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4975, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.5162, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4960, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.5034, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4791, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4965, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.5143, device='cuda:0', grad_fn=<AddBackward0>)
The 10 training average loss: 0.4971552408974746
2025-11-22 22:14:04 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:14:04 - GraphTrainer - INFO -   precision@5: 0.004022
2025-11-22 22:14:04 - GraphTrainer - INFO -   recall@5: 0.019036
2025-11-22 22:14:04 - GraphTrainer - INFO -   hit_rate@5: 0.020005
2025-11-22 22:14:04 - GraphTrainer - INFO -   ndcg@5: 0.012625
2025-11-22 22:14:04 - GraphTrainer - INFO -   map@5: 0.010364
2025-11-22 22:14:04 - GraphTrainer - INFO -   mrr@5: 0.010819
2025-11-22 22:14:04 - GraphTrainer - INFO -   precision@10: 0.003487
2025-11-22 22:14:04 - GraphTrainer - INFO -   recall@10: 0.033242
2025-11-22 22:14:04 - GraphTrainer - INFO -   hit_rate@10: 0.034765
2025-11-22 22:14:04 - GraphTrainer - INFO -   ndcg@10: 0.017210
2025-11-22 22:14:04 - GraphTrainer - INFO -   map@10: 0.012225
2025-11-22 22:14:04 - GraphTrainer - INFO -   mrr@10: 0.012753
2025-11-22 22:14:04 - GraphTrainer - INFO -   precision@20: 0.002870
2025-11-22 22:14:04 - GraphTrainer - INFO -   recall@20: 0.054345
2025-11-22 22:14:04 - GraphTrainer - INFO -   hit_rate@20: 0.057136
2025-11-22 22:14:04 - GraphTrainer - INFO -   ndcg@20: 0.022579
2025-11-22 22:14:04 - GraphTrainer - INFO -   map@20: 0.013660
2025-11-22 22:14:04 - GraphTrainer - INFO -   mrr@20: 0.014269
2025-11-22 22:14:04 - GraphTrainer - INFO - 第 11 轮训练完成
2025-11-22 22:14:04 - GraphTrainer - INFO - train_loss: 0.489438
2025-11-22 22:14:04 - GraphTrainer - INFO - precision@5: 0.004022
2025-11-22 22:14:04 - GraphTrainer - INFO - recall@5: 0.019036
2025-11-22 22:14:04 - GraphTrainer - INFO - hit_rate@5: 0.020005
2025-11-22 22:14:04 - GraphTrainer - INFO - ndcg@5: 0.012625
2025-11-22 22:14:04 - GraphTrainer - INFO - map@5: 0.010364
2025-11-22 22:14:04 - GraphTrainer - INFO - mrr@5: 0.010819
2025-11-22 22:14:04 - GraphTrainer - INFO - precision@10: 0.003487
2025-11-22 22:14:04 - GraphTrainer - INFO - recall@10: 0.033242
2025-11-22 22:14:04 - GraphTrainer - INFO - hit_rate@10: 0.034765
2025-11-22 22:14:04 - GraphTrainer - INFO - ndcg@10: 0.017210
2025-11-22 22:14:04 - GraphTrainer - INFO - map@10: 0.012225
2025-11-22 22:14:04 - GraphTrainer - INFO - mrr@10: 0.012753
2025-11-22 22:14:04 - GraphTrainer - INFO - precision@20: 0.002870
2025-11-22 22:14:04 - GraphTrainer - INFO - recall@20: 0.054345
2025-11-22 22:14:04 - GraphTrainer - INFO - hit_rate@20: 0.057136
2025-11-22 22:14:04 - GraphTrainer - INFO - ndcg@20: 0.022579
2025-11-22 22:14:04 - GraphTrainer - INFO - map@20: 0.013660
2025-11-22 22:14:04 - GraphTrainer - INFO - mrr@20: 0.014269
2025-11-22 22:14:04 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:14:04 - GraphTrainer - INFO - ============================================================
2025-11-22 22:14:04 - GraphTrainer - INFO - 开始第 12/1000 轮训练
2025-11-22 22:14:04 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.5002, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4940, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4784, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4755, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4868, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.5026, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4765, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4688, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4921, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4735, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4728, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4799, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4811, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4916, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4758, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.5136, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4806, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4706, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4856, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.5111, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.5030, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4879, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.5003, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4951, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4912, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4941, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4929, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4921, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4916, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4994, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4871, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4767, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4847, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4911, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.5092, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4967, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4906, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.5105, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4953, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4792, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4816, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4804, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.5128, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4913, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4700, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4956, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4949, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.5006, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4821, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4964, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4763, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4793, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4900, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4657, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.5002, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4917, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4932, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.5051, device='cuda:0', grad_fn=<AddBackward0>)
The 11 training average loss: 0.4894379562345044
2025-11-22 22:14:16 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:14:16 - GraphTrainer - INFO -   precision@5: 0.004145
2025-11-22 22:14:16 - GraphTrainer - INFO -   recall@5: 0.019803
2025-11-22 22:14:16 - GraphTrainer - INFO -   hit_rate@5: 0.020674
2025-11-22 22:14:16 - GraphTrainer - INFO -   ndcg@5: 0.012639
2025-11-22 22:14:16 - GraphTrainer - INFO -   map@5: 0.010151
2025-11-22 22:14:16 - GraphTrainer - INFO -   mrr@5: 0.010675
2025-11-22 22:14:16 - GraphTrainer - INFO -   precision@10: 0.003579
2025-11-22 22:14:16 - GraphTrainer - INFO -   recall@10: 0.034119
2025-11-22 22:14:16 - GraphTrainer - INFO -   hit_rate@10: 0.035690
2025-11-22 22:14:16 - GraphTrainer - INFO -   ndcg@10: 0.017277
2025-11-22 22:14:16 - GraphTrainer - INFO -   map@10: 0.012031
2025-11-22 22:14:16 - GraphTrainer - INFO -   mrr@10: 0.012641
2025-11-22 22:14:16 - GraphTrainer - INFO -   precision@20: 0.002944
2025-11-22 22:14:16 - GraphTrainer - INFO -   recall@20: 0.055604
2025-11-22 22:14:16 - GraphTrainer - INFO -   hit_rate@20: 0.058627
2025-11-22 22:14:16 - GraphTrainer - INFO -   ndcg@20: 0.022752
2025-11-22 22:14:16 - GraphTrainer - INFO -   map@20: 0.013493
2025-11-22 22:14:16 - GraphTrainer - INFO -   mrr@20: 0.014201
2025-11-22 22:14:16 - GraphTrainer - INFO - 第 12 轮训练完成
2025-11-22 22:14:16 - GraphTrainer - INFO - train_loss: 0.483463
2025-11-22 22:14:16 - GraphTrainer - INFO - precision@5: 0.004145
2025-11-22 22:14:16 - GraphTrainer - INFO - recall@5: 0.019803
2025-11-22 22:14:16 - GraphTrainer - INFO - hit_rate@5: 0.020674
2025-11-22 22:14:16 - GraphTrainer - INFO - ndcg@5: 0.012639
2025-11-22 22:14:16 - GraphTrainer - INFO - map@5: 0.010151
2025-11-22 22:14:16 - GraphTrainer - INFO - mrr@5: 0.010675
2025-11-22 22:14:16 - GraphTrainer - INFO - precision@10: 0.003579
2025-11-22 22:14:16 - GraphTrainer - INFO - recall@10: 0.034119
2025-11-22 22:14:16 - GraphTrainer - INFO - hit_rate@10: 0.035690
2025-11-22 22:14:16 - GraphTrainer - INFO - ndcg@10: 0.017277
2025-11-22 22:14:16 - GraphTrainer - INFO - map@10: 0.012031
2025-11-22 22:14:16 - GraphTrainer - INFO - mrr@10: 0.012641
2025-11-22 22:14:16 - GraphTrainer - INFO - precision@20: 0.002944
2025-11-22 22:14:16 - GraphTrainer - INFO - recall@20: 0.055604
2025-11-22 22:14:16 - GraphTrainer - INFO - hit_rate@20: 0.058627
2025-11-22 22:14:16 - GraphTrainer - INFO - ndcg@20: 0.022752
2025-11-22 22:14:16 - GraphTrainer - INFO - map@20: 0.013493
2025-11-22 22:14:16 - GraphTrainer - INFO - mrr@20: 0.014201
2025-11-22 22:14:16 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:14:16 - GraphTrainer - INFO - ============================================================
2025-11-22 22:14:16 - GraphTrainer - INFO - 开始第 13/1000 轮训练
2025-11-22 22:14:16 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4876, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4656, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4879, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4696, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4750, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4856, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4856, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.5012, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.5164, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4784, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4767, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4772, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4795, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4826, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4995, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.5076, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4808, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4807, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4771, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4942, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4750, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4833, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.5058, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4878, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4705, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4909, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4709, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4846, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4637, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4811, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4988, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4735, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4957, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4941, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4723, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4694, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.5017, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4712, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4904, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4964, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4959, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4890, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.5075, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4702, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4950, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4811, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4574, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4872, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4962, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4524, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4854, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4600, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4972, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4777, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4612, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4753, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4955, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4707, device='cuda:0', grad_fn=<AddBackward0>)
The 12 training average loss: 0.48346269490389987
2025-11-22 22:14:26 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:14:26 - GraphTrainer - INFO -   precision@5: 0.004114
2025-11-22 22:14:26 - GraphTrainer - INFO -   recall@5: 0.019531
2025-11-22 22:14:26 - GraphTrainer - INFO -   hit_rate@5: 0.020519
2025-11-22 22:14:26 - GraphTrainer - INFO -   ndcg@5: 0.012850
2025-11-22 22:14:26 - GraphTrainer - INFO -   map@5: 0.010497
2025-11-22 22:14:26 - GraphTrainer - INFO -   mrr@5: 0.011022
2025-11-22 22:14:26 - GraphTrainer - INFO -   precision@10: 0.003353
2025-11-22 22:14:26 - GraphTrainer - INFO -   recall@10: 0.031906
2025-11-22 22:14:26 - GraphTrainer - INFO -   hit_rate@10: 0.033479
2025-11-22 22:14:26 - GraphTrainer - INFO -   ndcg@10: 0.016856
2025-11-22 22:14:26 - GraphTrainer - INFO -   map@10: 0.012122
2025-11-22 22:14:26 - GraphTrainer - INFO -   mrr@10: 0.012725
2025-11-22 22:14:26 - GraphTrainer - INFO -   precision@20: 0.002785
2025-11-22 22:14:26 - GraphTrainer - INFO -   recall@20: 0.052869
2025-11-22 22:14:26 - GraphTrainer - INFO -   hit_rate@20: 0.055438
2025-11-22 22:14:26 - GraphTrainer - INFO -   ndcg@20: 0.022150
2025-11-22 22:14:26 - GraphTrainer - INFO -   map@20: 0.013526
2025-11-22 22:14:26 - GraphTrainer - INFO -   mrr@20: 0.014189
2025-11-22 22:14:26 - GraphTrainer - INFO - 第 13 轮训练完成
2025-11-22 22:14:26 - GraphTrainer - INFO - train_loss: 0.475819
2025-11-22 22:14:26 - GraphTrainer - INFO - precision@5: 0.004114
2025-11-22 22:14:26 - GraphTrainer - INFO - recall@5: 0.019531
2025-11-22 22:14:26 - GraphTrainer - INFO - hit_rate@5: 0.020519
2025-11-22 22:14:26 - GraphTrainer - INFO - ndcg@5: 0.012850
2025-11-22 22:14:26 - GraphTrainer - INFO - map@5: 0.010497
2025-11-22 22:14:26 - GraphTrainer - INFO - mrr@5: 0.011022
2025-11-22 22:14:26 - GraphTrainer - INFO - precision@10: 0.003353
2025-11-22 22:14:26 - GraphTrainer - INFO - recall@10: 0.031906
2025-11-22 22:14:26 - GraphTrainer - INFO - hit_rate@10: 0.033479
2025-11-22 22:14:26 - GraphTrainer - INFO - ndcg@10: 0.016856
2025-11-22 22:14:26 - GraphTrainer - INFO - map@10: 0.012122
2025-11-22 22:14:26 - GraphTrainer - INFO - mrr@10: 0.012725
2025-11-22 22:14:26 - GraphTrainer - INFO - precision@20: 0.002785
2025-11-22 22:14:26 - GraphTrainer - INFO - recall@20: 0.052869
2025-11-22 22:14:26 - GraphTrainer - INFO - hit_rate@20: 0.055438
2025-11-22 22:14:26 - GraphTrainer - INFO - ndcg@20: 0.022150
2025-11-22 22:14:26 - GraphTrainer - INFO - map@20: 0.013526
2025-11-22 22:14:26 - GraphTrainer - INFO - mrr@20: 0.014189
2025-11-22 22:14:26 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:14:26 - GraphTrainer - INFO - ============================================================
2025-11-22 22:14:26 - GraphTrainer - INFO - 开始第 14/1000 轮训练
2025-11-22 22:14:26 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4910, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4649, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4719, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4716, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4863, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4516, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4739, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4971, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4773, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4652, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4868, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4813, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4910, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4788, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4645, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4709, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4780, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4838, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4592, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4673, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4855, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4712, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4603, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4899, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4835, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4816, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4614, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4548, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4873, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4683, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4761, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4765, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4738, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4591, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4954, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4713, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4737, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4886, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4901, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4780, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4873, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4688, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4803, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4666, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4803, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4627, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4592, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4798, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4798, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4896, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4614, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4835, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4579, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4861, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4674, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4858, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4707, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4915, device='cuda:0', grad_fn=<AddBackward0>)
The 13 training average loss: 0.47581932873561467
2025-11-22 22:14:37 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:14:37 - GraphTrainer - INFO -   precision@5: 0.004310
2025-11-22 22:14:37 - GraphTrainer - INFO -   recall@5: 0.020342
2025-11-22 22:14:37 - GraphTrainer - INFO -   hit_rate@5: 0.021497
2025-11-22 22:14:37 - GraphTrainer - INFO -   ndcg@5: 0.013491
2025-11-22 22:14:37 - GraphTrainer - INFO -   map@5: 0.011057
2025-11-22 22:14:37 - GraphTrainer - INFO -   mrr@5: 0.011659
2025-11-22 22:14:37 - GraphTrainer - INFO -   precision@10: 0.003677
2025-11-22 22:14:37 - GraphTrainer - INFO -   recall@10: 0.034862
2025-11-22 22:14:37 - GraphTrainer - INFO -   hit_rate@10: 0.036719
2025-11-22 22:14:37 - GraphTrainer - INFO -   ndcg@10: 0.018174
2025-11-22 22:14:37 - GraphTrainer - INFO -   map@10: 0.012942
2025-11-22 22:14:37 - GraphTrainer - INFO -   mrr@10: 0.013634
2025-11-22 22:14:37 - GraphTrainer - INFO -   precision@20: 0.003158
2025-11-22 22:14:37 - GraphTrainer - INFO -   recall@20: 0.059498
2025-11-22 22:14:37 - GraphTrainer - INFO -   hit_rate@20: 0.062741
2025-11-22 22:14:37 - GraphTrainer - INFO -   ndcg@20: 0.024454
2025-11-22 22:14:37 - GraphTrainer - INFO -   map@20: 0.014630
2025-11-22 22:14:37 - GraphTrainer - INFO -   mrr@20: 0.015404
2025-11-22 22:14:37 - GraphTrainer - INFO - 第 14 轮训练完成
2025-11-22 22:14:37 - GraphTrainer - INFO - train_loss: 0.472229
2025-11-22 22:14:37 - GraphTrainer - INFO - precision@5: 0.004310
2025-11-22 22:14:37 - GraphTrainer - INFO - recall@5: 0.020342
2025-11-22 22:14:37 - GraphTrainer - INFO - hit_rate@5: 0.021497
2025-11-22 22:14:37 - GraphTrainer - INFO - ndcg@5: 0.013491
2025-11-22 22:14:37 - GraphTrainer - INFO - map@5: 0.011057
2025-11-22 22:14:37 - GraphTrainer - INFO - mrr@5: 0.011659
2025-11-22 22:14:37 - GraphTrainer - INFO - precision@10: 0.003677
2025-11-22 22:14:37 - GraphTrainer - INFO - recall@10: 0.034862
2025-11-22 22:14:37 - GraphTrainer - INFO - hit_rate@10: 0.036719
2025-11-22 22:14:37 - GraphTrainer - INFO - ndcg@10: 0.018174
2025-11-22 22:14:37 - GraphTrainer - INFO - map@10: 0.012942
2025-11-22 22:14:37 - GraphTrainer - INFO - mrr@10: 0.013634
2025-11-22 22:14:37 - GraphTrainer - INFO - precision@20: 0.003158
2025-11-22 22:14:37 - GraphTrainer - INFO - recall@20: 0.059498
2025-11-22 22:14:37 - GraphTrainer - INFO - hit_rate@20: 0.062741
2025-11-22 22:14:37 - GraphTrainer - INFO - ndcg@20: 0.024454
2025-11-22 22:14:37 - GraphTrainer - INFO - map@20: 0.014630
2025-11-22 22:14:37 - GraphTrainer - INFO - mrr@20: 0.015404
2025-11-22 22:14:37 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:14:37 - GraphTrainer - INFO - ============================================================
2025-11-22 22:14:37 - GraphTrainer - INFO - 开始第 15/1000 轮训练
2025-11-22 22:14:37 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4799, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4852, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4743, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4749, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4753, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4899, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4842, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4824, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4706, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4575, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4588, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4525, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4737, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4664, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4984, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4772, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4912, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4765, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4779, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4762, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4766, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4666, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4812, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4755, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4681, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4829, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4911, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4899, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4455, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4719, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4834, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4700, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4624, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4758, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4696, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4792, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4582, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4696, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4634, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4483, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4859, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4680, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4737, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4563, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4729, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4813, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4574, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4439, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4758, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4692, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4804, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4529, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4582, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4797, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4651, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4719, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4678, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4766, device='cuda:0', grad_fn=<AddBackward0>)
The 14 training average loss: 0.47222911592187555
2025-11-22 22:14:48 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:14:48 - GraphTrainer - INFO -   precision@5: 0.004546
2025-11-22 22:14:48 - GraphTrainer - INFO -   recall@5: 0.021548
2025-11-22 22:14:48 - GraphTrainer - INFO -   hit_rate@5: 0.022679
2025-11-22 22:14:48 - GraphTrainer - INFO -   ndcg@5: 0.014005
2025-11-22 22:14:48 - GraphTrainer - INFO -   map@5: 0.011341
2025-11-22 22:14:48 - GraphTrainer - INFO -   mrr@5: 0.011965
2025-11-22 22:14:48 - GraphTrainer - INFO -   precision@10: 0.003631
2025-11-22 22:14:48 - GraphTrainer - INFO -   recall@10: 0.034468
2025-11-22 22:14:48 - GraphTrainer - INFO -   hit_rate@10: 0.036205
2025-11-22 22:14:48 - GraphTrainer - INFO -   ndcg@10: 0.018182
2025-11-22 22:14:48 - GraphTrainer - INFO -   map@10: 0.013033
2025-11-22 22:14:48 - GraphTrainer - INFO -   mrr@10: 0.013729
2025-11-22 22:14:48 - GraphTrainer - INFO -   precision@20: 0.002988
2025-11-22 22:14:48 - GraphTrainer - INFO -   recall@20: 0.056526
2025-11-22 22:14:48 - GraphTrainer - INFO -   hit_rate@20: 0.059501
2025-11-22 22:14:48 - GraphTrainer - INFO -   ndcg@20: 0.023755
2025-11-22 22:14:48 - GraphTrainer - INFO -   map@20: 0.014505
2025-11-22 22:14:48 - GraphTrainer - INFO -   mrr@20: 0.015283
2025-11-22 22:14:48 - GraphTrainer - INFO - 第 15 轮训练完成
2025-11-22 22:14:48 - GraphTrainer - INFO - train_loss: 0.468816
2025-11-22 22:14:48 - GraphTrainer - INFO - precision@5: 0.004546
2025-11-22 22:14:48 - GraphTrainer - INFO - recall@5: 0.021548
2025-11-22 22:14:48 - GraphTrainer - INFO - hit_rate@5: 0.022679
2025-11-22 22:14:48 - GraphTrainer - INFO - ndcg@5: 0.014005
2025-11-22 22:14:48 - GraphTrainer - INFO - map@5: 0.011341
2025-11-22 22:14:48 - GraphTrainer - INFO - mrr@5: 0.011965
2025-11-22 22:14:48 - GraphTrainer - INFO - precision@10: 0.003631
2025-11-22 22:14:48 - GraphTrainer - INFO - recall@10: 0.034468
2025-11-22 22:14:48 - GraphTrainer - INFO - hit_rate@10: 0.036205
2025-11-22 22:14:48 - GraphTrainer - INFO - ndcg@10: 0.018182
2025-11-22 22:14:48 - GraphTrainer - INFO - map@10: 0.013033
2025-11-22 22:14:48 - GraphTrainer - INFO - mrr@10: 0.013729
2025-11-22 22:14:48 - GraphTrainer - INFO - precision@20: 0.002988
2025-11-22 22:14:48 - GraphTrainer - INFO - recall@20: 0.056526
2025-11-22 22:14:48 - GraphTrainer - INFO - hit_rate@20: 0.059501
2025-11-22 22:14:48 - GraphTrainer - INFO - ndcg@20: 0.023755
2025-11-22 22:14:48 - GraphTrainer - INFO - map@20: 0.014505
2025-11-22 22:14:48 - GraphTrainer - INFO - mrr@20: 0.015283
2025-11-22 22:14:48 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:14:48 - GraphTrainer - INFO - ============================================================
2025-11-22 22:14:48 - GraphTrainer - INFO - 开始第 16/1000 轮训练
2025-11-22 22:14:48 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4611, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4826, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4524, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4562, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4491, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4641, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4565, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4726, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4700, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4589, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4683, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4691, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4566, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4874, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4797, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4700, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4918, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4607, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4806, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4498, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4563, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4852, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4735, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4773, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4555, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4649, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4739, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4889, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4795, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4512, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4725, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4760, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4765, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4865, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4765, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4782, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4512, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4842, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4564, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4739, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4623, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4760, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4524, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4661, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4657, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4742, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4689, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4692, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4784, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4639, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4561, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4683, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4642, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4621, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4871, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4606, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4846, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4559, device='cuda:0', grad_fn=<AddBackward0>)
The 15 training average loss: 0.46881604811240885
2025-11-22 22:15:00 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:15:00 - GraphTrainer - INFO -   precision@5: 0.004495
2025-11-22 22:15:00 - GraphTrainer - INFO -   recall@5: 0.021272
2025-11-22 22:15:00 - GraphTrainer - INFO -   hit_rate@5: 0.022422
2025-11-22 22:15:00 - GraphTrainer - INFO -   ndcg@5: 0.013780
2025-11-22 22:15:00 - GraphTrainer - INFO -   map@5: 0.011126
2025-11-22 22:15:00 - GraphTrainer - INFO -   mrr@5: 0.011725
2025-11-22 22:15:00 - GraphTrainer - INFO -   precision@10: 0.003759
2025-11-22 22:15:00 - GraphTrainer - INFO -   recall@10: 0.035613
2025-11-22 22:15:00 - GraphTrainer - INFO -   hit_rate@10: 0.037490
2025-11-22 22:15:00 - GraphTrainer - INFO -   ndcg@10: 0.018383
2025-11-22 22:15:00 - GraphTrainer - INFO -   map@10: 0.012962
2025-11-22 22:15:00 - GraphTrainer - INFO -   mrr@10: 0.013652
2025-11-22 22:15:00 - GraphTrainer - INFO -   precision@20: 0.003140
2025-11-22 22:15:00 - GraphTrainer - INFO -   recall@20: 0.059420
2025-11-22 22:15:00 - GraphTrainer - INFO -   hit_rate@20: 0.062433
2025-11-22 22:15:00 - GraphTrainer - INFO -   ndcg@20: 0.024434
2025-11-22 22:15:00 - GraphTrainer - INFO -   map@20: 0.014588
2025-11-22 22:15:00 - GraphTrainer - INFO -   mrr@20: 0.015351
2025-11-22 22:15:00 - GraphTrainer - INFO - 第 16 轮训练完成
2025-11-22 22:15:00 - GraphTrainer - INFO - train_loss: 0.465566
2025-11-22 22:15:00 - GraphTrainer - INFO - precision@5: 0.004495
2025-11-22 22:15:00 - GraphTrainer - INFO - recall@5: 0.021272
2025-11-22 22:15:00 - GraphTrainer - INFO - hit_rate@5: 0.022422
2025-11-22 22:15:00 - GraphTrainer - INFO - ndcg@5: 0.013780
2025-11-22 22:15:00 - GraphTrainer - INFO - map@5: 0.011126
2025-11-22 22:15:00 - GraphTrainer - INFO - mrr@5: 0.011725
2025-11-22 22:15:00 - GraphTrainer - INFO - precision@10: 0.003759
2025-11-22 22:15:00 - GraphTrainer - INFO - recall@10: 0.035613
2025-11-22 22:15:00 - GraphTrainer - INFO - hit_rate@10: 0.037490
2025-11-22 22:15:00 - GraphTrainer - INFO - ndcg@10: 0.018383
2025-11-22 22:15:00 - GraphTrainer - INFO - map@10: 0.012962
2025-11-22 22:15:00 - GraphTrainer - INFO - mrr@10: 0.013652
2025-11-22 22:15:00 - GraphTrainer - INFO - precision@20: 0.003140
2025-11-22 22:15:00 - GraphTrainer - INFO - recall@20: 0.059420
2025-11-22 22:15:00 - GraphTrainer - INFO - hit_rate@20: 0.062433
2025-11-22 22:15:00 - GraphTrainer - INFO - ndcg@20: 0.024434
2025-11-22 22:15:00 - GraphTrainer - INFO - map@20: 0.014588
2025-11-22 22:15:00 - GraphTrainer - INFO - mrr@20: 0.015351
2025-11-22 22:15:00 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:15:00 - GraphTrainer - INFO - ============================================================
2025-11-22 22:15:00 - GraphTrainer - INFO - 开始第 17/1000 轮训练
2025-11-22 22:15:00 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4551, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4670, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4610, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4629, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4916, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4780, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4760, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4768, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4594, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4737, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4636, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4683, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4482, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4466, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4641, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4707, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4717, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4584, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4645, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4777, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4662, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4751, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4614, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4646, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4543, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4629, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4662, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4516, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4680, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4675, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4603, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4667, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4541, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4614, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4533, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4563, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4761, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4819, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4677, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4642, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4580, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4918, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4732, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4691, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4555, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4678, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4820, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4513, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4653, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4543, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4466, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4514, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4807, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4691, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4988, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4644, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4685, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4400, device='cuda:0', grad_fn=<AddBackward0>)
The 16 training average loss: 0.4655659008642723
2025-11-22 22:15:11 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:15:11 - GraphTrainer - INFO -   precision@5: 0.004608
2025-11-22 22:15:11 - GraphTrainer - INFO -   recall@5: 0.021909
2025-11-22 22:15:11 - GraphTrainer - INFO -   hit_rate@5: 0.022988
2025-11-22 22:15:11 - GraphTrainer - INFO -   ndcg@5: 0.014155
2025-11-22 22:15:11 - GraphTrainer - INFO -   map@5: 0.011431
2025-11-22 22:15:11 - GraphTrainer - INFO -   mrr@5: 0.012008
2025-11-22 22:15:11 - GraphTrainer - INFO -   precision@10: 0.003929
2025-11-22 22:15:11 - GraphTrainer - INFO -   recall@10: 0.037072
2025-11-22 22:15:11 - GraphTrainer - INFO -   hit_rate@10: 0.039187
2025-11-22 22:15:11 - GraphTrainer - INFO -   ndcg@10: 0.019061
2025-11-22 22:15:11 - GraphTrainer - INFO -   map@10: 0.013395
2025-11-22 22:15:11 - GraphTrainer - INFO -   mrr@10: 0.014105
2025-11-22 22:15:11 - GraphTrainer - INFO -   precision@20: 0.003219
2025-11-22 22:15:11 - GraphTrainer - INFO -   recall@20: 0.060763
2025-11-22 22:15:11 - GraphTrainer - INFO -   hit_rate@20: 0.063872
2025-11-22 22:15:11 - GraphTrainer - INFO -   ndcg@20: 0.025069
2025-11-22 22:15:11 - GraphTrainer - INFO -   map@20: 0.015005
2025-11-22 22:15:11 - GraphTrainer - INFO -   mrr@20: 0.015774
2025-11-22 22:15:11 - GraphTrainer - INFO - 第 17 轮训练完成
2025-11-22 22:15:11 - GraphTrainer - INFO - train_loss: 0.460245
2025-11-22 22:15:11 - GraphTrainer - INFO - precision@5: 0.004608
2025-11-22 22:15:11 - GraphTrainer - INFO - recall@5: 0.021909
2025-11-22 22:15:11 - GraphTrainer - INFO - hit_rate@5: 0.022988
2025-11-22 22:15:11 - GraphTrainer - INFO - ndcg@5: 0.014155
2025-11-22 22:15:11 - GraphTrainer - INFO - map@5: 0.011431
2025-11-22 22:15:11 - GraphTrainer - INFO - mrr@5: 0.012008
2025-11-22 22:15:11 - GraphTrainer - INFO - precision@10: 0.003929
2025-11-22 22:15:11 - GraphTrainer - INFO - recall@10: 0.037072
2025-11-22 22:15:11 - GraphTrainer - INFO - hit_rate@10: 0.039187
2025-11-22 22:15:11 - GraphTrainer - INFO - ndcg@10: 0.019061
2025-11-22 22:15:11 - GraphTrainer - INFO - map@10: 0.013395
2025-11-22 22:15:11 - GraphTrainer - INFO - mrr@10: 0.014105
2025-11-22 22:15:11 - GraphTrainer - INFO - precision@20: 0.003219
2025-11-22 22:15:11 - GraphTrainer - INFO - recall@20: 0.060763
2025-11-22 22:15:11 - GraphTrainer - INFO - hit_rate@20: 0.063872
2025-11-22 22:15:11 - GraphTrainer - INFO - ndcg@20: 0.025069
2025-11-22 22:15:11 - GraphTrainer - INFO - map@20: 0.015005
2025-11-22 22:15:11 - GraphTrainer - INFO - mrr@20: 0.015774
2025-11-22 22:15:11 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:15:11 - GraphTrainer - INFO - ============================================================
2025-11-22 22:15:11 - GraphTrainer - INFO - 开始第 18/1000 轮训练
2025-11-22 22:15:11 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4862, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4690, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4499, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4602, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4473, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4447, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4595, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4747, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4637, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4705, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4553, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4457, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4427, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4647, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4720, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4647, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4717, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4432, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4831, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4692, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4702, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4495, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4606, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4804, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4741, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4561, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4557, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4874, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4608, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4667, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4487, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4585, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4589, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4493, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4722, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4360, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4631, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4669, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4549, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4555, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4617, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4611, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4634, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4555, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4482, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4420, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4556, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4784, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4502, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4364, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4609, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4627, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4497, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4368, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4440, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4699, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4702, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4841, device='cuda:0', grad_fn=<AddBackward0>)
The 17 training average loss: 0.4602451869126024
2025-11-22 22:15:22 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:15:22 - GraphTrainer - INFO -   precision@5: 0.004433
2025-11-22 22:15:22 - GraphTrainer - INFO -   recall@5: 0.021400
2025-11-22 22:15:22 - GraphTrainer - INFO -   hit_rate@5: 0.022165
2025-11-22 22:15:22 - GraphTrainer - INFO -   ndcg@5: 0.013743
2025-11-22 22:15:22 - GraphTrainer - INFO -   map@5: 0.011120
2025-11-22 22:15:22 - GraphTrainer - INFO -   mrr@5: 0.011463
2025-11-22 22:15:22 - GraphTrainer - INFO -   precision@10: 0.003698
2025-11-22 22:15:22 - GraphTrainer - INFO -   recall@10: 0.035407
2025-11-22 22:15:22 - GraphTrainer - INFO -   hit_rate@10: 0.036976
2025-11-22 22:15:22 - GraphTrainer - INFO -   ndcg@10: 0.018299
2025-11-22 22:15:22 - GraphTrainer - INFO -   map@10: 0.012964
2025-11-22 22:15:22 - GraphTrainer - INFO -   mrr@10: 0.013407
2025-11-22 22:15:22 - GraphTrainer - INFO -   precision@20: 0.003021
2025-11-22 22:15:22 - GraphTrainer - INFO -   recall@20: 0.057421
2025-11-22 22:15:22 - GraphTrainer - INFO -   hit_rate@20: 0.060170
2025-11-22 22:15:22 - GraphTrainer - INFO -   ndcg@20: 0.023866
2025-11-22 22:15:22 - GraphTrainer - INFO -   map@20: 0.014440
2025-11-22 22:15:22 - GraphTrainer - INFO -   mrr@20: 0.014957
2025-11-22 22:15:22 - GraphTrainer - INFO - 第 18 轮训练完成
2025-11-22 22:15:22 - GraphTrainer - INFO - train_loss: 0.460040
2025-11-22 22:15:22 - GraphTrainer - INFO - precision@5: 0.004433
2025-11-22 22:15:22 - GraphTrainer - INFO - recall@5: 0.021400
2025-11-22 22:15:22 - GraphTrainer - INFO - hit_rate@5: 0.022165
2025-11-22 22:15:22 - GraphTrainer - INFO - ndcg@5: 0.013743
2025-11-22 22:15:22 - GraphTrainer - INFO - map@5: 0.011120
2025-11-22 22:15:22 - GraphTrainer - INFO - mrr@5: 0.011463
2025-11-22 22:15:22 - GraphTrainer - INFO - precision@10: 0.003698
2025-11-22 22:15:22 - GraphTrainer - INFO - recall@10: 0.035407
2025-11-22 22:15:22 - GraphTrainer - INFO - hit_rate@10: 0.036976
2025-11-22 22:15:22 - GraphTrainer - INFO - ndcg@10: 0.018299
2025-11-22 22:15:22 - GraphTrainer - INFO - map@10: 0.012964
2025-11-22 22:15:22 - GraphTrainer - INFO - mrr@10: 0.013407
2025-11-22 22:15:22 - GraphTrainer - INFO - precision@20: 0.003021
2025-11-22 22:15:22 - GraphTrainer - INFO - recall@20: 0.057421
2025-11-22 22:15:22 - GraphTrainer - INFO - hit_rate@20: 0.060170
2025-11-22 22:15:22 - GraphTrainer - INFO - ndcg@20: 0.023866
2025-11-22 22:15:22 - GraphTrainer - INFO - map@20: 0.014440
2025-11-22 22:15:22 - GraphTrainer - INFO - mrr@20: 0.014957
2025-11-22 22:15:22 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:15:22 - GraphTrainer - INFO - ============================================================
2025-11-22 22:15:22 - GraphTrainer - INFO - 开始第 19/1000 轮训练
2025-11-22 22:15:22 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4796, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4612, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4447, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4485, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4436, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4586, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4776, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4269, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4327, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4590, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4613, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4533, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4747, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4666, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4640, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4545, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4721, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4431, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4579, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4498, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4682, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4698, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4451, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4591, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4642, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4426, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4485, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4937, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4414, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4635, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4579, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4669, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4461, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4628, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4328, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4581, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4749, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4667, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4711, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4533, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4853, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4542, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4775, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4560, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4438, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4525, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4420, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4841, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4487, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4695, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4767, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4807, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4696, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4540, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4795, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4677, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4467, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4776, device='cuda:0', grad_fn=<AddBackward0>)
The 18 training average loss: 0.4600402445628725
2025-11-22 22:15:33 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:15:33 - GraphTrainer - INFO -   precision@5: 0.004505
2025-11-22 22:15:33 - GraphTrainer - INFO -   recall@5: 0.021579
2025-11-22 22:15:33 - GraphTrainer - INFO -   hit_rate@5: 0.022422
2025-11-22 22:15:33 - GraphTrainer - INFO -   ndcg@5: 0.014335
2025-11-22 22:15:33 - GraphTrainer - INFO -   map@5: 0.011797
2025-11-22 22:15:33 - GraphTrainer - INFO -   mrr@5: 0.012283
2025-11-22 22:15:33 - GraphTrainer - INFO -   precision@10: 0.003944
2025-11-22 22:15:33 - GraphTrainer - INFO -   recall@10: 0.037709
2025-11-22 22:15:33 - GraphTrainer - INFO -   hit_rate@10: 0.039290
2025-11-22 22:15:33 - GraphTrainer - INFO -   ndcg@10: 0.019536
2025-11-22 22:15:33 - GraphTrainer - INFO -   map@10: 0.013893
2025-11-22 22:15:33 - GraphTrainer - INFO -   mrr@10: 0.014469
2025-11-22 22:15:33 - GraphTrainer - INFO -   precision@20: 0.003201
2025-11-22 22:15:33 - GraphTrainer - INFO -   recall@20: 0.060499
2025-11-22 22:15:33 - GraphTrainer - INFO -   hit_rate@20: 0.063461
2025-11-22 22:15:33 - GraphTrainer - INFO -   ndcg@20: 0.025345
2025-11-22 22:15:33 - GraphTrainer - INFO -   map@20: 0.015449
2025-11-22 22:15:33 - GraphTrainer - INFO -   mrr@20: 0.016109
2025-11-22 22:15:33 - GraphTrainer - INFO - 第 19 轮训练完成
2025-11-22 22:15:33 - GraphTrainer - INFO - train_loss: 0.454292
2025-11-22 22:15:33 - GraphTrainer - INFO - precision@5: 0.004505
2025-11-22 22:15:33 - GraphTrainer - INFO - recall@5: 0.021579
2025-11-22 22:15:33 - GraphTrainer - INFO - hit_rate@5: 0.022422
2025-11-22 22:15:33 - GraphTrainer - INFO - ndcg@5: 0.014335
2025-11-22 22:15:33 - GraphTrainer - INFO - map@5: 0.011797
2025-11-22 22:15:33 - GraphTrainer - INFO - mrr@5: 0.012283
2025-11-22 22:15:33 - GraphTrainer - INFO - precision@10: 0.003944
2025-11-22 22:15:33 - GraphTrainer - INFO - recall@10: 0.037709
2025-11-22 22:15:33 - GraphTrainer - INFO - hit_rate@10: 0.039290
2025-11-22 22:15:33 - GraphTrainer - INFO - ndcg@10: 0.019536
2025-11-22 22:15:33 - GraphTrainer - INFO - map@10: 0.013893
2025-11-22 22:15:33 - GraphTrainer - INFO - mrr@10: 0.014469
2025-11-22 22:15:33 - GraphTrainer - INFO - precision@20: 0.003201
2025-11-22 22:15:33 - GraphTrainer - INFO - recall@20: 0.060499
2025-11-22 22:15:33 - GraphTrainer - INFO - hit_rate@20: 0.063461
2025-11-22 22:15:33 - GraphTrainer - INFO - ndcg@20: 0.025345
2025-11-22 22:15:33 - GraphTrainer - INFO - map@20: 0.015449
2025-11-22 22:15:33 - GraphTrainer - INFO - mrr@20: 0.016109
2025-11-22 22:15:33 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:15:33 - GraphTrainer - INFO - ============================================================
2025-11-22 22:15:33 - GraphTrainer - INFO - 开始第 20/1000 轮训练
2025-11-22 22:15:33 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4786, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4671, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4634, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4388, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4629, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4934, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4468, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4450, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4430, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4561, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4745, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4300, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4368, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4487, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4173, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4536, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4350, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4584, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4460, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4623, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4601, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4558, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4519, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4486, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4528, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4619, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4525, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4661, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4520, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4576, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4682, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4616, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4683, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4256, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4338, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4578, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4779, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4466, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4523, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4486, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4160, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4635, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4466, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4524, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4661, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4373, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4785, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4553, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4642, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4473, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4735, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4506, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4490, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4505, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4626, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4561, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4690, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4526, device='cuda:0', grad_fn=<AddBackward0>)
The 19 training average loss: 0.45429226858862515
2025-11-22 22:15:44 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:15:44 - GraphTrainer - INFO -   precision@5: 0.004474
2025-11-22 22:15:44 - GraphTrainer - INFO -   recall@5: 0.021307
2025-11-22 22:15:44 - GraphTrainer - INFO -   hit_rate@5: 0.022371
2025-11-22 22:15:44 - GraphTrainer - INFO -   ndcg@5: 0.013424
2025-11-22 22:15:44 - GraphTrainer - INFO -   map@5: 0.010715
2025-11-22 22:15:44 - GraphTrainer - INFO -   mrr@5: 0.011108
2025-11-22 22:15:44 - GraphTrainer - INFO -   precision@10: 0.003965
2025-11-22 22:15:44 - GraphTrainer - INFO -   recall@10: 0.037708
2025-11-22 22:15:44 - GraphTrainer - INFO -   hit_rate@10: 0.039496
2025-11-22 22:15:44 - GraphTrainer - INFO -   ndcg@10: 0.018759
2025-11-22 22:15:44 - GraphTrainer - INFO -   map@10: 0.012887
2025-11-22 22:15:44 - GraphTrainer - INFO -   mrr@10: 0.013362
2025-11-22 22:15:44 - GraphTrainer - INFO -   precision@20: 0.003199
2025-11-22 22:15:44 - GraphTrainer - INFO -   recall@20: 0.060463
2025-11-22 22:15:44 - GraphTrainer - INFO -   hit_rate@20: 0.063564
2025-11-22 22:15:44 - GraphTrainer - INFO -   ndcg@20: 0.024556
2025-11-22 22:15:44 - GraphTrainer - INFO -   map@20: 0.014441
2025-11-22 22:15:44 - GraphTrainer - INFO -   mrr@20: 0.015000
2025-11-22 22:15:44 - GraphTrainer - INFO - 第 20 轮训练完成
2025-11-22 22:15:44 - GraphTrainer - INFO - train_loss: 0.450455
2025-11-22 22:15:44 - GraphTrainer - INFO - precision@5: 0.004474
2025-11-22 22:15:44 - GraphTrainer - INFO - recall@5: 0.021307
2025-11-22 22:15:44 - GraphTrainer - INFO - hit_rate@5: 0.022371
2025-11-22 22:15:44 - GraphTrainer - INFO - ndcg@5: 0.013424
2025-11-22 22:15:44 - GraphTrainer - INFO - map@5: 0.010715
2025-11-22 22:15:44 - GraphTrainer - INFO - mrr@5: 0.011108
2025-11-22 22:15:44 - GraphTrainer - INFO - precision@10: 0.003965
2025-11-22 22:15:44 - GraphTrainer - INFO - recall@10: 0.037708
2025-11-22 22:15:44 - GraphTrainer - INFO - hit_rate@10: 0.039496
2025-11-22 22:15:44 - GraphTrainer - INFO - ndcg@10: 0.018759
2025-11-22 22:15:44 - GraphTrainer - INFO - map@10: 0.012887
2025-11-22 22:15:44 - GraphTrainer - INFO - mrr@10: 0.013362
2025-11-22 22:15:44 - GraphTrainer - INFO - precision@20: 0.003199
2025-11-22 22:15:44 - GraphTrainer - INFO - recall@20: 0.060463
2025-11-22 22:15:44 - GraphTrainer - INFO - hit_rate@20: 0.063564
2025-11-22 22:15:44 - GraphTrainer - INFO - ndcg@20: 0.024556
2025-11-22 22:15:44 - GraphTrainer - INFO - map@20: 0.014441
2025-11-22 22:15:44 - GraphTrainer - INFO - mrr@20: 0.015000
2025-11-22 22:15:44 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:15:44 - GraphTrainer - INFO - 检查点已保存: Epoch 20 -> ./checkpoints/checkpoint_epoch_20.pth
2025-11-22 22:15:44 - GraphTrainer - INFO - ============================================================
2025-11-22 22:15:44 - GraphTrainer - INFO - 开始第 21/1000 轮训练
2025-11-22 22:15:44 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4493, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4461, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4713, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4727, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4502, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4352, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4612, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4454, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4471, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4433, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4442, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4573, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4427, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4524, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4518, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4553, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4453, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4609, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4436, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4476, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4440, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4522, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4417, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4603, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4627, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4387, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4669, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4731, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4396, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4461, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4516, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4724, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4176, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4297, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4547, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4823, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4393, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4445, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4510, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4528, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4387, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4362, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4314, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4734, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4595, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4475, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4660, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4454, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4543, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4577, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4525, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4288, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4474, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4611, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4576, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4503, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4282, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4463, device='cuda:0', grad_fn=<AddBackward0>)
The 20 training average loss: 0.4504549919531263
2025-11-22 22:15:55 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:15:55 - GraphTrainer - INFO -   precision@5: 0.004186
2025-11-22 22:15:55 - GraphTrainer - INFO -   recall@5: 0.020055
2025-11-22 22:15:55 - GraphTrainer - INFO -   hit_rate@5: 0.020879
2025-11-22 22:15:55 - GraphTrainer - INFO -   ndcg@5: 0.013335
2025-11-22 22:15:55 - GraphTrainer - INFO -   map@5: 0.010991
2025-11-22 22:15:55 - GraphTrainer - INFO -   mrr@5: 0.011452
2025-11-22 22:15:55 - GraphTrainer - INFO -   precision@10: 0.003662
2025-11-22 22:15:55 - GraphTrainer - INFO -   recall@10: 0.035032
2025-11-22 22:15:55 - GraphTrainer - INFO -   hit_rate@10: 0.036513
2025-11-22 22:15:55 - GraphTrainer - INFO -   ndcg@10: 0.018151
2025-11-22 22:15:55 - GraphTrainer - INFO -   map@10: 0.012927
2025-11-22 22:15:55 - GraphTrainer - INFO -   mrr@10: 0.013466
2025-11-22 22:15:55 - GraphTrainer - INFO -   precision@20: 0.003155
2025-11-22 22:15:55 - GraphTrainer - INFO -   recall@20: 0.060037
2025-11-22 22:15:55 - GraphTrainer - INFO -   hit_rate@20: 0.062741
2025-11-22 22:15:55 - GraphTrainer - INFO -   ndcg@20: 0.024505
2025-11-22 22:15:55 - GraphTrainer - INFO -   map@20: 0.014632
2025-11-22 22:15:55 - GraphTrainer - INFO -   mrr@20: 0.015252
2025-11-22 22:15:55 - GraphTrainer - INFO - 第 21 轮训练完成
2025-11-22 22:15:55 - GraphTrainer - INFO - train_loss: 0.450228
2025-11-22 22:15:55 - GraphTrainer - INFO - precision@5: 0.004186
2025-11-22 22:15:55 - GraphTrainer - INFO - recall@5: 0.020055
2025-11-22 22:15:55 - GraphTrainer - INFO - hit_rate@5: 0.020879
2025-11-22 22:15:55 - GraphTrainer - INFO - ndcg@5: 0.013335
2025-11-22 22:15:55 - GraphTrainer - INFO - map@5: 0.010991
2025-11-22 22:15:55 - GraphTrainer - INFO - mrr@5: 0.011452
2025-11-22 22:15:55 - GraphTrainer - INFO - precision@10: 0.003662
2025-11-22 22:15:55 - GraphTrainer - INFO - recall@10: 0.035032
2025-11-22 22:15:55 - GraphTrainer - INFO - hit_rate@10: 0.036513
2025-11-22 22:15:55 - GraphTrainer - INFO - ndcg@10: 0.018151
2025-11-22 22:15:55 - GraphTrainer - INFO - map@10: 0.012927
2025-11-22 22:15:55 - GraphTrainer - INFO - mrr@10: 0.013466
2025-11-22 22:15:55 - GraphTrainer - INFO - precision@20: 0.003155
2025-11-22 22:15:55 - GraphTrainer - INFO - recall@20: 0.060037
2025-11-22 22:15:55 - GraphTrainer - INFO - hit_rate@20: 0.062741
2025-11-22 22:15:55 - GraphTrainer - INFO - ndcg@20: 0.024505
2025-11-22 22:15:55 - GraphTrainer - INFO - map@20: 0.014632
2025-11-22 22:15:55 - GraphTrainer - INFO - mrr@20: 0.015252
2025-11-22 22:15:55 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:15:55 - GraphTrainer - INFO - ============================================================
2025-11-22 22:15:55 - GraphTrainer - INFO - 开始第 22/1000 轮训练
2025-11-22 22:15:55 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4316, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4464, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4461, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4366, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4502, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4428, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4414, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4400, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4389, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4723, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4357, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4532, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4592, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4625, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4478, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4599, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4429, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4578, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4506, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4685, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4382, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4245, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4417, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4334, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4581, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4406, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4507, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4693, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4697, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4348, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4653, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4571, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4323, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4439, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4696, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4534, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4610, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4455, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4562, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4731, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4420, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4289, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4469, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4670, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4584, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4440, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4759, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4339, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4546, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4439, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4368, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4683, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4770, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4349, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4274, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4722, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4607, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4378, device='cuda:0', grad_fn=<AddBackward0>)
The 21 training average loss: 0.4502282790068922
2025-11-22 22:16:06 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:16:06 - GraphTrainer - INFO -   precision@5: 0.004279
2025-11-22 22:16:06 - GraphTrainer - INFO -   recall@5: 0.020380
2025-11-22 22:16:06 - GraphTrainer - INFO -   hit_rate@5: 0.021342
2025-11-22 22:16:06 - GraphTrainer - INFO -   ndcg@5: 0.012902
2025-11-22 22:16:06 - GraphTrainer - INFO -   map@5: 0.010279
2025-11-22 22:16:06 - GraphTrainer - INFO -   mrr@5: 0.010809
2025-11-22 22:16:06 - GraphTrainer - INFO -   precision@10: 0.003641
2025-11-22 22:16:06 - GraphTrainer - INFO -   recall@10: 0.034714
2025-11-22 22:16:06 - GraphTrainer - INFO -   hit_rate@10: 0.036308
2025-11-22 22:16:06 - GraphTrainer - INFO -   ndcg@10: 0.017592
2025-11-22 22:16:06 - GraphTrainer - INFO -   map@10: 0.012210
2025-11-22 22:16:06 - GraphTrainer - INFO -   mrr@10: 0.012821
2025-11-22 22:16:06 - GraphTrainer - INFO -   precision@20: 0.003204
2025-11-22 22:16:06 - GraphTrainer - INFO -   recall@20: 0.060855
2025-11-22 22:16:06 - GraphTrainer - INFO -   hit_rate@20: 0.063615
2025-11-22 22:16:06 - GraphTrainer - INFO -   ndcg@20: 0.024234
2025-11-22 22:16:06 - GraphTrainer - INFO -   map@20: 0.013995
2025-11-22 22:16:06 - GraphTrainer - INFO -   mrr@20: 0.014677
2025-11-22 22:16:06 - GraphTrainer - INFO - 第 22 轮训练完成
2025-11-22 22:16:06 - GraphTrainer - INFO - train_loss: 0.446084
2025-11-22 22:16:06 - GraphTrainer - INFO - precision@5: 0.004279
2025-11-22 22:16:06 - GraphTrainer - INFO - recall@5: 0.020380
2025-11-22 22:16:06 - GraphTrainer - INFO - hit_rate@5: 0.021342
2025-11-22 22:16:06 - GraphTrainer - INFO - ndcg@5: 0.012902
2025-11-22 22:16:06 - GraphTrainer - INFO - map@5: 0.010279
2025-11-22 22:16:06 - GraphTrainer - INFO - mrr@5: 0.010809
2025-11-22 22:16:06 - GraphTrainer - INFO - precision@10: 0.003641
2025-11-22 22:16:06 - GraphTrainer - INFO - recall@10: 0.034714
2025-11-22 22:16:06 - GraphTrainer - INFO - hit_rate@10: 0.036308
2025-11-22 22:16:06 - GraphTrainer - INFO - ndcg@10: 0.017592
2025-11-22 22:16:06 - GraphTrainer - INFO - map@10: 0.012210
2025-11-22 22:16:06 - GraphTrainer - INFO - mrr@10: 0.012821
2025-11-22 22:16:06 - GraphTrainer - INFO - precision@20: 0.003204
2025-11-22 22:16:06 - GraphTrainer - INFO - recall@20: 0.060855
2025-11-22 22:16:06 - GraphTrainer - INFO - hit_rate@20: 0.063615
2025-11-22 22:16:06 - GraphTrainer - INFO - ndcg@20: 0.024234
2025-11-22 22:16:06 - GraphTrainer - INFO - map@20: 0.013995
2025-11-22 22:16:06 - GraphTrainer - INFO - mrr@20: 0.014677
2025-11-22 22:16:06 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:16:06 - GraphTrainer - INFO - ============================================================
2025-11-22 22:16:06 - GraphTrainer - INFO - 开始第 23/1000 轮训练
2025-11-22 22:16:06 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4355, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4745, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4805, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4530, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4524, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4367, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4295, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4369, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4446, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4303, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4406, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4512, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4312, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4460, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4527, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4472, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4087, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4647, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4416, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4497, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4680, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4402, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4537, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4329, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4532, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4628, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4567, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4291, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4334, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4337, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4603, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4656, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4593, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4725, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4346, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4415, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4301, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4446, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4368, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4245, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4519, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4448, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4598, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4495, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4399, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4335, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4744, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4431, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4343, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4515, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4307, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4549, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4379, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4348, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4636, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4341, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4389, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4545, device='cuda:0', grad_fn=<AddBackward0>)
The 22 training average loss: 0.4460841890039115
2025-11-22 22:16:18 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:16:18 - GraphTrainer - INFO -   precision@5: 0.004567
2025-11-22 22:16:18 - GraphTrainer - INFO -   recall@5: 0.021933
2025-11-22 22:16:18 - GraphTrainer - INFO -   hit_rate@5: 0.022834
2025-11-22 22:16:18 - GraphTrainer - INFO -   ndcg@5: 0.014740
2025-11-22 22:16:18 - GraphTrainer - INFO -   map@5: 0.012242
2025-11-22 22:16:18 - GraphTrainer - INFO -   mrr@5: 0.012641
2025-11-22 22:16:18 - GraphTrainer - INFO -   precision@10: 0.003780
2025-11-22 22:16:18 - GraphTrainer - INFO -   recall@10: 0.036116
2025-11-22 22:16:18 - GraphTrainer - INFO -   hit_rate@10: 0.037645
2025-11-22 22:16:18 - GraphTrainer - INFO -   ndcg@10: 0.019304
2025-11-22 22:16:18 - GraphTrainer - INFO -   map@10: 0.014068
2025-11-22 22:16:18 - GraphTrainer - INFO -   mrr@10: 0.014551
2025-11-22 22:16:18 - GraphTrainer - INFO -   precision@20: 0.003150
2025-11-22 22:16:18 - GraphTrainer - INFO -   recall@20: 0.060082
2025-11-22 22:16:18 - GraphTrainer - INFO -   hit_rate@20: 0.062638
2025-11-22 22:16:18 - GraphTrainer - INFO -   ndcg@20: 0.025368
2025-11-22 22:16:18 - GraphTrainer - INFO -   map@20: 0.015689
2025-11-22 22:16:18 - GraphTrainer - INFO -   mrr@20: 0.016239
2025-11-22 22:16:18 - GraphTrainer - INFO - 第 23 轮训练完成
2025-11-22 22:16:18 - GraphTrainer - INFO - train_loss: 0.441959
2025-11-22 22:16:18 - GraphTrainer - INFO - precision@5: 0.004567
2025-11-22 22:16:18 - GraphTrainer - INFO - recall@5: 0.021933
2025-11-22 22:16:18 - GraphTrainer - INFO - hit_rate@5: 0.022834
2025-11-22 22:16:18 - GraphTrainer - INFO - ndcg@5: 0.014740
2025-11-22 22:16:18 - GraphTrainer - INFO - map@5: 0.012242
2025-11-22 22:16:18 - GraphTrainer - INFO - mrr@5: 0.012641
2025-11-22 22:16:18 - GraphTrainer - INFO - precision@10: 0.003780
2025-11-22 22:16:18 - GraphTrainer - INFO - recall@10: 0.036116
2025-11-22 22:16:18 - GraphTrainer - INFO - hit_rate@10: 0.037645
2025-11-22 22:16:18 - GraphTrainer - INFO - ndcg@10: 0.019304
2025-11-22 22:16:18 - GraphTrainer - INFO - map@10: 0.014068
2025-11-22 22:16:18 - GraphTrainer - INFO - mrr@10: 0.014551
2025-11-22 22:16:18 - GraphTrainer - INFO - precision@20: 0.003150
2025-11-22 22:16:18 - GraphTrainer - INFO - recall@20: 0.060082
2025-11-22 22:16:18 - GraphTrainer - INFO - hit_rate@20: 0.062638
2025-11-22 22:16:18 - GraphTrainer - INFO - ndcg@20: 0.025368
2025-11-22 22:16:18 - GraphTrainer - INFO - map@20: 0.015689
2025-11-22 22:16:18 - GraphTrainer - INFO - mrr@20: 0.016239
2025-11-22 22:16:18 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:16:18 - GraphTrainer - INFO - ============================================================
2025-11-22 22:16:18 - GraphTrainer - INFO - 开始第 24/1000 轮训练
2025-11-22 22:16:18 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4410, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4539, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4458, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4254, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4351, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4416, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4356, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4465, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4416, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4576, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4497, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4307, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4423, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4200, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4577, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4296, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4466, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4413, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4349, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4495, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4327, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4288, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4373, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4410, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4358, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4273, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4201, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4335, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4127, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4482, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4374, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4463, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4444, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4427, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4468, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4454, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4440, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4415, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4717, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4508, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4505, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4385, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4400, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4303, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4664, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4365, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4327, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4466, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4663, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4393, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4489, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4485, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4325, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4323, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4833, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4331, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4615, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4318, device='cuda:0', grad_fn=<AddBackward0>)
The 23 training average loss: 0.4419586345039565
2025-11-22 22:16:29 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:16:29 - GraphTrainer - INFO -   precision@5: 0.004834
2025-11-22 22:16:29 - GraphTrainer - INFO -   recall@5: 0.023209
2025-11-22 22:16:29 - GraphTrainer - INFO -   hit_rate@5: 0.024119
2025-11-22 22:16:29 - GraphTrainer - INFO -   ndcg@5: 0.015326
2025-11-22 22:16:29 - GraphTrainer - INFO -   map@5: 0.012579
2025-11-22 22:16:29 - GraphTrainer - INFO -   mrr@5: 0.013077
2025-11-22 22:16:29 - GraphTrainer - INFO -   precision@10: 0.004083
2025-11-22 22:16:29 - GraphTrainer - INFO -   recall@10: 0.038822
2025-11-22 22:16:29 - GraphTrainer - INFO -   hit_rate@10: 0.040679
2025-11-22 22:16:29 - GraphTrainer - INFO -   ndcg@10: 0.020394
2025-11-22 22:16:29 - GraphTrainer - INFO -   map@10: 0.014623
2025-11-22 22:16:29 - GraphTrainer - INFO -   mrr@10: 0.015239
2025-11-22 22:16:29 - GraphTrainer - INFO -   precision@20: 0.003386
2025-11-22 22:16:29 - GraphTrainer - INFO -   recall@20: 0.064480
2025-11-22 22:16:29 - GraphTrainer - INFO -   hit_rate@20: 0.067421
2025-11-22 22:16:29 - GraphTrainer - INFO -   ndcg@20: 0.026895
2025-11-22 22:16:29 - GraphTrainer - INFO -   map@20: 0.016367
2025-11-22 22:16:29 - GraphTrainer - INFO -   mrr@20: 0.017052
2025-11-22 22:16:29 - GraphTrainer - INFO - 第 24 轮训练完成
2025-11-22 22:16:29 - GraphTrainer - INFO - train_loss: 0.440939
2025-11-22 22:16:29 - GraphTrainer - INFO - precision@5: 0.004834
2025-11-22 22:16:29 - GraphTrainer - INFO - recall@5: 0.023209
2025-11-22 22:16:29 - GraphTrainer - INFO - hit_rate@5: 0.024119
2025-11-22 22:16:29 - GraphTrainer - INFO - ndcg@5: 0.015326
2025-11-22 22:16:29 - GraphTrainer - INFO - map@5: 0.012579
2025-11-22 22:16:29 - GraphTrainer - INFO - mrr@5: 0.013077
2025-11-22 22:16:29 - GraphTrainer - INFO - precision@10: 0.004083
2025-11-22 22:16:29 - GraphTrainer - INFO - recall@10: 0.038822
2025-11-22 22:16:29 - GraphTrainer - INFO - hit_rate@10: 0.040679
2025-11-22 22:16:29 - GraphTrainer - INFO - ndcg@10: 0.020394
2025-11-22 22:16:29 - GraphTrainer - INFO - map@10: 0.014623
2025-11-22 22:16:29 - GraphTrainer - INFO - mrr@10: 0.015239
2025-11-22 22:16:29 - GraphTrainer - INFO - precision@20: 0.003386
2025-11-22 22:16:29 - GraphTrainer - INFO - recall@20: 0.064480
2025-11-22 22:16:29 - GraphTrainer - INFO - hit_rate@20: 0.067421
2025-11-22 22:16:29 - GraphTrainer - INFO - ndcg@20: 0.026895
2025-11-22 22:16:29 - GraphTrainer - INFO - map@20: 0.016367
2025-11-22 22:16:29 - GraphTrainer - INFO - mrr@20: 0.017052
2025-11-22 22:16:29 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:16:29 - GraphTrainer - INFO - ============================================================
2025-11-22 22:16:29 - GraphTrainer - INFO - 开始第 25/1000 轮训练
2025-11-22 22:16:29 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4394, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4672, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4437, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4489, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4322, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4342, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4324, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4528, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4232, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4234, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4339, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4375, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4305, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4408, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4455, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4563, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4451, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4452, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4351, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4359, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4376, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4407, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4570, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4464, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4197, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4582, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4536, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4575, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4232, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4175, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4059, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4573, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4417, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4193, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4347, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4446, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4370, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4218, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4023, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4338, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4501, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4675, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4784, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4435, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4412, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4394, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4581, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4487, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4306, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4336, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4494, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4617, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4385, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4160, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4588, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4800, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4426, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4234, device='cuda:0', grad_fn=<AddBackward0>)
The 24 training average loss: 0.4409389429051301
2025-11-22 22:16:40 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:16:40 - GraphTrainer - INFO -   precision@5: 0.004916
2025-11-22 22:16:40 - GraphTrainer - INFO -   recall@5: 0.023517
2025-11-22 22:16:40 - GraphTrainer - INFO -   hit_rate@5: 0.024531
2025-11-22 22:16:40 - GraphTrainer - INFO -   ndcg@5: 0.015639
2025-11-22 22:16:40 - GraphTrainer - INFO -   map@5: 0.012875
2025-11-22 22:16:40 - GraphTrainer - INFO -   mrr@5: 0.013428
2025-11-22 22:16:40 - GraphTrainer - INFO -   precision@10: 0.004027
2025-11-22 22:16:40 - GraphTrainer - INFO -   recall@10: 0.038464
2025-11-22 22:16:40 - GraphTrainer - INFO -   hit_rate@10: 0.040165
2025-11-22 22:16:40 - GraphTrainer - INFO -   ndcg@10: 0.020458
2025-11-22 22:16:40 - GraphTrainer - INFO -   map@10: 0.014816
2025-11-22 22:16:40 - GraphTrainer - INFO -   mrr@10: 0.015459
2025-11-22 22:16:40 - GraphTrainer - INFO -   precision@20: 0.003386
2025-11-22 22:16:40 - GraphTrainer - INFO -   recall@20: 0.064708
2025-11-22 22:16:40 - GraphTrainer - INFO -   hit_rate@20: 0.067472
2025-11-22 22:16:40 - GraphTrainer - INFO -   ndcg@20: 0.027082
2025-11-22 22:16:40 - GraphTrainer - INFO -   map@20: 0.016580
2025-11-22 22:16:40 - GraphTrainer - INFO -   mrr@20: 0.017289
2025-11-22 22:16:40 - GraphTrainer - INFO - 第 25 轮训练完成
2025-11-22 22:16:40 - GraphTrainer - INFO - train_loss: 0.437650
2025-11-22 22:16:40 - GraphTrainer - INFO - precision@5: 0.004916
2025-11-22 22:16:40 - GraphTrainer - INFO - recall@5: 0.023517
2025-11-22 22:16:40 - GraphTrainer - INFO - hit_rate@5: 0.024531
2025-11-22 22:16:40 - GraphTrainer - INFO - ndcg@5: 0.015639
2025-11-22 22:16:40 - GraphTrainer - INFO - map@5: 0.012875
2025-11-22 22:16:40 - GraphTrainer - INFO - mrr@5: 0.013428
2025-11-22 22:16:40 - GraphTrainer - INFO - precision@10: 0.004027
2025-11-22 22:16:40 - GraphTrainer - INFO - recall@10: 0.038464
2025-11-22 22:16:40 - GraphTrainer - INFO - hit_rate@10: 0.040165
2025-11-22 22:16:40 - GraphTrainer - INFO - ndcg@10: 0.020458
2025-11-22 22:16:40 - GraphTrainer - INFO - map@10: 0.014816
2025-11-22 22:16:40 - GraphTrainer - INFO - mrr@10: 0.015459
2025-11-22 22:16:40 - GraphTrainer - INFO - precision@20: 0.003386
2025-11-22 22:16:40 - GraphTrainer - INFO - recall@20: 0.064708
2025-11-22 22:16:40 - GraphTrainer - INFO - hit_rate@20: 0.067472
2025-11-22 22:16:40 - GraphTrainer - INFO - ndcg@20: 0.027082
2025-11-22 22:16:40 - GraphTrainer - INFO - map@20: 0.016580
2025-11-22 22:16:40 - GraphTrainer - INFO - mrr@20: 0.017289
2025-11-22 22:16:40 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:16:40 - GraphTrainer - INFO - ============================================================
2025-11-22 22:16:40 - GraphTrainer - INFO - 开始第 26/1000 轮训练
2025-11-22 22:16:40 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4398, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4437, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4443, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4174, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4261, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4551, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4236, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4347, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4517, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4323, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4452, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4309, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4199, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4516, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4502, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4341, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4349, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4242, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4476, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4637, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4284, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4321, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4389, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4690, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4271, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4428, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4522, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4540, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4344, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4299, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4461, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4428, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4423, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4441, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4498, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4310, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4317, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4321, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4182, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4461, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4580, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4497, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4440, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4292, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4423, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4483, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4467, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4290, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4511, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4118, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4170, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4252, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4285, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4249, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4182, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4222, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4382, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4354, device='cuda:0', grad_fn=<AddBackward0>)
The 25 training average loss: 0.4376502864319703
2025-11-22 22:16:51 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:16:51 - GraphTrainer - INFO -   precision@5: 0.004649
2025-11-22 22:16:51 - GraphTrainer - INFO -   recall@5: 0.022146
2025-11-22 22:16:51 - GraphTrainer - INFO -   hit_rate@5: 0.023194
2025-11-22 22:16:51 - GraphTrainer - INFO -   ndcg@5: 0.014496
2025-11-22 22:16:51 - GraphTrainer - INFO -   map@5: 0.011807
2025-11-22 22:16:51 - GraphTrainer - INFO -   mrr@5: 0.012344
2025-11-22 22:16:51 - GraphTrainer - INFO -   precision@10: 0.003929
2025-11-22 22:16:51 - GraphTrainer - INFO -   recall@10: 0.037456
2025-11-22 22:16:51 - GraphTrainer - INFO -   hit_rate@10: 0.039187
2025-11-22 22:16:51 - GraphTrainer - INFO -   ndcg@10: 0.019434
2025-11-22 22:16:51 - GraphTrainer - INFO -   map@10: 0.013800
2025-11-22 22:16:51 - GraphTrainer - INFO -   mrr@10: 0.014423
2025-11-22 22:16:51 - GraphTrainer - INFO -   precision@20: 0.003312
2025-11-22 22:16:51 - GraphTrainer - INFO -   recall@20: 0.062923
2025-11-22 22:16:51 - GraphTrainer - INFO -   hit_rate@20: 0.065930
2025-11-22 22:16:51 - GraphTrainer - INFO -   ndcg@20: 0.025916
2025-11-22 22:16:51 - GraphTrainer - INFO -   map@20: 0.015543
2025-11-22 22:16:51 - GraphTrainer - INFO -   mrr@20: 0.016253
2025-11-22 22:16:51 - GraphTrainer - INFO - 第 26 轮训练完成
2025-11-22 22:16:51 - GraphTrainer - INFO - train_loss: 0.435927
2025-11-22 22:16:51 - GraphTrainer - INFO - precision@5: 0.004649
2025-11-22 22:16:51 - GraphTrainer - INFO - recall@5: 0.022146
2025-11-22 22:16:51 - GraphTrainer - INFO - hit_rate@5: 0.023194
2025-11-22 22:16:51 - GraphTrainer - INFO - ndcg@5: 0.014496
2025-11-22 22:16:51 - GraphTrainer - INFO - map@5: 0.011807
2025-11-22 22:16:51 - GraphTrainer - INFO - mrr@5: 0.012344
2025-11-22 22:16:51 - GraphTrainer - INFO - precision@10: 0.003929
2025-11-22 22:16:51 - GraphTrainer - INFO - recall@10: 0.037456
2025-11-22 22:16:51 - GraphTrainer - INFO - hit_rate@10: 0.039187
2025-11-22 22:16:51 - GraphTrainer - INFO - ndcg@10: 0.019434
2025-11-22 22:16:51 - GraphTrainer - INFO - map@10: 0.013800
2025-11-22 22:16:51 - GraphTrainer - INFO - mrr@10: 0.014423
2025-11-22 22:16:51 - GraphTrainer - INFO - precision@20: 0.003312
2025-11-22 22:16:51 - GraphTrainer - INFO - recall@20: 0.062923
2025-11-22 22:16:51 - GraphTrainer - INFO - hit_rate@20: 0.065930
2025-11-22 22:16:51 - GraphTrainer - INFO - ndcg@20: 0.025916
2025-11-22 22:16:51 - GraphTrainer - INFO - map@20: 0.015543
2025-11-22 22:16:51 - GraphTrainer - INFO - mrr@20: 0.016253
2025-11-22 22:16:51 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:16:51 - GraphTrainer - INFO - ============================================================
2025-11-22 22:16:51 - GraphTrainer - INFO - 开始第 27/1000 轮训练
2025-11-22 22:16:51 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4279, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4268, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4578, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4373, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4526, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4166, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4335, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4295, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4119, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4316, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4350, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4162, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4398, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4250, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4400, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4251, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4229, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4253, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4492, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4284, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4277, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4403, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4403, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4129, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4456, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4454, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4543, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4319, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4470, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4503, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4436, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4562, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4439, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4426, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4344, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4320, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4140, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4514, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4420, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4197, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4543, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4380, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4199, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4435, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4408, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4416, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4188, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4315, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4412, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4296, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4259, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4217, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4427, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4521, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4557, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4341, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4349, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4496, device='cuda:0', grad_fn=<AddBackward0>)
The 26 training average loss: 0.435927497415707
2025-11-22 22:17:02 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:17:02 - GraphTrainer - INFO -   precision@5: 0.004423
2025-11-22 22:17:02 - GraphTrainer - INFO -   recall@5: 0.021190
2025-11-22 22:17:02 - GraphTrainer - INFO -   hit_rate@5: 0.022062
2025-11-22 22:17:02 - GraphTrainer - INFO -   ndcg@5: 0.013803
2025-11-22 22:17:02 - GraphTrainer - INFO -   map@5: 0.011230
2025-11-22 22:17:02 - GraphTrainer - INFO -   mrr@5: 0.011655
2025-11-22 22:17:02 - GraphTrainer - INFO -   precision@10: 0.003996
2025-11-22 22:17:02 - GraphTrainer - INFO -   recall@10: 0.038000
2025-11-22 22:17:02 - GraphTrainer - INFO -   hit_rate@10: 0.039856
2025-11-22 22:17:02 - GraphTrainer - INFO -   ndcg@10: 0.019265
2025-11-22 22:17:02 - GraphTrainer - INFO -   map@10: 0.013442
2025-11-22 22:17:02 - GraphTrainer - INFO -   mrr@10: 0.013983
2025-11-22 22:17:02 - GraphTrainer - INFO -   precision@20: 0.003371
2025-11-22 22:17:02 - GraphTrainer - INFO -   recall@20: 0.063844
2025-11-22 22:17:02 - GraphTrainer - INFO -   hit_rate@20: 0.067112
2025-11-22 22:17:02 - GraphTrainer - INFO -   ndcg@20: 0.025830
2025-11-22 22:17:02 - GraphTrainer - INFO -   map@20: 0.015198
2025-11-22 22:17:02 - GraphTrainer - INFO -   mrr@20: 0.015828
2025-11-22 22:17:02 - GraphTrainer - INFO - 第 27 轮训练完成
2025-11-22 22:17:02 - GraphTrainer - INFO - train_loss: 0.433393
2025-11-22 22:17:02 - GraphTrainer - INFO - precision@5: 0.004423
2025-11-22 22:17:02 - GraphTrainer - INFO - recall@5: 0.021190
2025-11-22 22:17:02 - GraphTrainer - INFO - hit_rate@5: 0.022062
2025-11-22 22:17:02 - GraphTrainer - INFO - ndcg@5: 0.013803
2025-11-22 22:17:02 - GraphTrainer - INFO - map@5: 0.011230
2025-11-22 22:17:02 - GraphTrainer - INFO - mrr@5: 0.011655
2025-11-22 22:17:02 - GraphTrainer - INFO - precision@10: 0.003996
2025-11-22 22:17:02 - GraphTrainer - INFO - recall@10: 0.038000
2025-11-22 22:17:02 - GraphTrainer - INFO - hit_rate@10: 0.039856
2025-11-22 22:17:02 - GraphTrainer - INFO - ndcg@10: 0.019265
2025-11-22 22:17:02 - GraphTrainer - INFO - map@10: 0.013442
2025-11-22 22:17:02 - GraphTrainer - INFO - mrr@10: 0.013983
2025-11-22 22:17:02 - GraphTrainer - INFO - precision@20: 0.003371
2025-11-22 22:17:02 - GraphTrainer - INFO - recall@20: 0.063844
2025-11-22 22:17:02 - GraphTrainer - INFO - hit_rate@20: 0.067112
2025-11-22 22:17:02 - GraphTrainer - INFO - ndcg@20: 0.025830
2025-11-22 22:17:02 - GraphTrainer - INFO - map@20: 0.015198
2025-11-22 22:17:02 - GraphTrainer - INFO - mrr@20: 0.015828
2025-11-22 22:17:02 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:17:02 - GraphTrainer - INFO - ============================================================
2025-11-22 22:17:02 - GraphTrainer - INFO - 开始第 28/1000 轮训练
2025-11-22 22:17:02 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4278, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4213, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4357, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4517, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4418, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4328, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4310, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4139, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4436, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4556, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4291, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4384, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4218, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4409, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4240, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4553, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4334, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4284, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4165, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4241, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4479, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4276, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4347, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4357, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4383, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4391, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4179, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4253, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4050, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4149, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4333, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4495, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4220, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4404, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4267, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4502, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4379, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4412, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4193, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4334, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4260, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4425, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4316, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4519, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4473, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4446, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4293, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4422, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4300, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4191, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4226, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4292, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4494, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4319, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4204, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4426, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4512, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4173, device='cuda:0', grad_fn=<AddBackward0>)
The 27 training average loss: 0.43339344191140144
2025-11-22 22:17:14 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:17:14 - GraphTrainer - INFO -   precision@5: 0.004814
2025-11-22 22:17:14 - GraphTrainer - INFO -   recall@5: 0.022955
2025-11-22 22:17:14 - GraphTrainer - INFO -   hit_rate@5: 0.024016
2025-11-22 22:17:14 - GraphTrainer - INFO -   ndcg@5: 0.015705
2025-11-22 22:17:14 - GraphTrainer - INFO -   map@5: 0.013120
2025-11-22 22:17:14 - GraphTrainer - INFO -   mrr@5: 0.013740
2025-11-22 22:17:14 - GraphTrainer - INFO -   precision@10: 0.004016
2025-11-22 22:17:14 - GraphTrainer - INFO -   recall@10: 0.038151
2025-11-22 22:17:14 - GraphTrainer - INFO -   hit_rate@10: 0.040010
2025-11-22 22:17:14 - GraphTrainer - INFO -   ndcg@10: 0.020608
2025-11-22 22:17:14 - GraphTrainer - INFO -   map@10: 0.015088
2025-11-22 22:17:14 - GraphTrainer - INFO -   mrr@10: 0.015807
2025-11-22 22:17:14 - GraphTrainer - INFO -   precision@20: 0.003327
2025-11-22 22:17:14 - GraphTrainer - INFO -   recall@20: 0.063140
2025-11-22 22:17:14 - GraphTrainer - INFO -   hit_rate@20: 0.066135
2025-11-22 22:17:14 - GraphTrainer - INFO -   ndcg@20: 0.026927
2025-11-22 22:17:14 - GraphTrainer - INFO -   map@20: 0.016770
2025-11-22 22:17:14 - GraphTrainer - INFO -   mrr@20: 0.017565
2025-11-22 22:17:14 - GraphTrainer - INFO - 第 28 轮训练完成
2025-11-22 22:17:14 - GraphTrainer - INFO - train_loss: 0.431798
2025-11-22 22:17:14 - GraphTrainer - INFO - precision@5: 0.004814
2025-11-22 22:17:14 - GraphTrainer - INFO - recall@5: 0.022955
2025-11-22 22:17:14 - GraphTrainer - INFO - hit_rate@5: 0.024016
2025-11-22 22:17:14 - GraphTrainer - INFO - ndcg@5: 0.015705
2025-11-22 22:17:14 - GraphTrainer - INFO - map@5: 0.013120
2025-11-22 22:17:14 - GraphTrainer - INFO - mrr@5: 0.013740
2025-11-22 22:17:14 - GraphTrainer - INFO - precision@10: 0.004016
2025-11-22 22:17:14 - GraphTrainer - INFO - recall@10: 0.038151
2025-11-22 22:17:14 - GraphTrainer - INFO - hit_rate@10: 0.040010
2025-11-22 22:17:14 - GraphTrainer - INFO - ndcg@10: 0.020608
2025-11-22 22:17:14 - GraphTrainer - INFO - map@10: 0.015088
2025-11-22 22:17:14 - GraphTrainer - INFO - mrr@10: 0.015807
2025-11-22 22:17:14 - GraphTrainer - INFO - precision@20: 0.003327
2025-11-22 22:17:14 - GraphTrainer - INFO - recall@20: 0.063140
2025-11-22 22:17:14 - GraphTrainer - INFO - hit_rate@20: 0.066135
2025-11-22 22:17:14 - GraphTrainer - INFO - ndcg@20: 0.026927
2025-11-22 22:17:14 - GraphTrainer - INFO - map@20: 0.016770
2025-11-22 22:17:14 - GraphTrainer - INFO - mrr@20: 0.017565
2025-11-22 22:17:14 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:17:14 - GraphTrainer - INFO - ============================================================
2025-11-22 22:17:14 - GraphTrainer - INFO - 开始第 29/1000 轮训练
2025-11-22 22:17:14 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4229, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4203, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4229, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4288, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4574, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4226, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4411, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4463, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4000, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4532, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4201, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4110, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4243, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4357, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4310, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4470, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4197, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4453, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4146, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4415, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4336, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4202, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4233, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4185, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4230, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4239, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4398, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4282, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4313, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4282, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4507, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4247, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4283, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4240, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4115, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4224, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4503, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4241, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4332, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4350, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4324, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4628, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4243, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4333, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4434, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4318, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4323, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4614, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4139, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4509, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4346, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4542, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4345, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4281, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4258, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4204, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4313, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4487, device='cuda:0', grad_fn=<AddBackward0>)
The 28 training average loss: 0.4317983332379111
2025-11-22 22:17:25 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:17:25 - GraphTrainer - INFO -   precision@5: 0.005174
2025-11-22 22:17:25 - GraphTrainer - INFO -   recall@5: 0.024640
2025-11-22 22:17:25 - GraphTrainer - INFO -   hit_rate@5: 0.025816
2025-11-22 22:17:25 - GraphTrainer - INFO -   ndcg@5: 0.015853
2025-11-22 22:17:25 - GraphTrainer - INFO -   map@5: 0.012778
2025-11-22 22:17:25 - GraphTrainer - INFO -   mrr@5: 0.013403
2025-11-22 22:17:25 - GraphTrainer - INFO -   precision@10: 0.004088
2025-11-22 22:17:25 - GraphTrainer - INFO -   recall@10: 0.038985
2025-11-22 22:17:25 - GraphTrainer - INFO -   hit_rate@10: 0.040782
2025-11-22 22:17:25 - GraphTrainer - INFO -   ndcg@10: 0.020506
2025-11-22 22:17:25 - GraphTrainer - INFO -   map@10: 0.014671
2025-11-22 22:17:25 - GraphTrainer - INFO -   mrr@10: 0.015377
2025-11-22 22:17:25 - GraphTrainer - INFO -   precision@20: 0.003412
2025-11-22 22:17:25 - GraphTrainer - INFO -   recall@20: 0.064461
2025-11-22 22:17:25 - GraphTrainer - INFO -   hit_rate@20: 0.067678
2025-11-22 22:17:25 - GraphTrainer - INFO -   ndcg@20: 0.026976
2025-11-22 22:17:25 - GraphTrainer - INFO -   map@20: 0.016392
2025-11-22 22:17:25 - GraphTrainer - INFO -   mrr@20: 0.017189
2025-11-22 22:17:25 - GraphTrainer - INFO - 第 29 轮训练完成
2025-11-22 22:17:25 - GraphTrainer - INFO - train_loss: 0.431005
2025-11-22 22:17:25 - GraphTrainer - INFO - precision@5: 0.005174
2025-11-22 22:17:25 - GraphTrainer - INFO - recall@5: 0.024640
2025-11-22 22:17:25 - GraphTrainer - INFO - hit_rate@5: 0.025816
2025-11-22 22:17:25 - GraphTrainer - INFO - ndcg@5: 0.015853
2025-11-22 22:17:25 - GraphTrainer - INFO - map@5: 0.012778
2025-11-22 22:17:25 - GraphTrainer - INFO - mrr@5: 0.013403
2025-11-22 22:17:25 - GraphTrainer - INFO - precision@10: 0.004088
2025-11-22 22:17:25 - GraphTrainer - INFO - recall@10: 0.038985
2025-11-22 22:17:25 - GraphTrainer - INFO - hit_rate@10: 0.040782
2025-11-22 22:17:25 - GraphTrainer - INFO - ndcg@10: 0.020506
2025-11-22 22:17:25 - GraphTrainer - INFO - map@10: 0.014671
2025-11-22 22:17:25 - GraphTrainer - INFO - mrr@10: 0.015377
2025-11-22 22:17:25 - GraphTrainer - INFO - precision@20: 0.003412
2025-11-22 22:17:25 - GraphTrainer - INFO - recall@20: 0.064461
2025-11-22 22:17:25 - GraphTrainer - INFO - hit_rate@20: 0.067678
2025-11-22 22:17:25 - GraphTrainer - INFO - ndcg@20: 0.026976
2025-11-22 22:17:25 - GraphTrainer - INFO - map@20: 0.016392
2025-11-22 22:17:25 - GraphTrainer - INFO - mrr@20: 0.017189
2025-11-22 22:17:25 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:17:25 - GraphTrainer - INFO - ============================================================
2025-11-22 22:17:25 - GraphTrainer - INFO - 开始第 30/1000 轮训练
2025-11-22 22:17:25 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4617, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4251, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4110, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4194, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4309, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4221, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4319, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4172, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4129, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4393, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4381, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4321, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4463, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4619, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4416, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4199, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4202, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4293, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4169, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4371, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4303, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4312, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4277, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4217, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4484, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4398, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4266, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4423, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4469, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4283, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4282, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4079, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4479, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4589, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3992, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4385, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4286, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4396, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4481, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4395, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4497, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4386, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4166, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4357, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4125, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4332, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4401, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4199, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4279, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4385, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4254, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4239, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4405, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4034, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4217, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4324, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4192, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4246, device='cuda:0', grad_fn=<AddBackward0>)
The 29 training average loss: 0.43100465012007744
2025-11-22 22:17:36 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:17:36 - GraphTrainer - INFO -   precision@5: 0.004803
2025-11-22 22:17:36 - GraphTrainer - INFO -   recall@5: 0.023039
2025-11-22 22:17:36 - GraphTrainer - INFO -   hit_rate@5: 0.023965
2025-11-22 22:17:36 - GraphTrainer - INFO -   ndcg@5: 0.015622
2025-11-22 22:17:36 - GraphTrainer - INFO -   map@5: 0.013040
2025-11-22 22:17:36 - GraphTrainer - INFO -   mrr@5: 0.013494
2025-11-22 22:17:36 - GraphTrainer - INFO -   precision@10: 0.004011
2025-11-22 22:17:36 - GraphTrainer - INFO -   recall@10: 0.038340
2025-11-22 22:17:36 - GraphTrainer - INFO -   hit_rate@10: 0.040062
2025-11-22 22:17:36 - GraphTrainer - INFO -   ndcg@10: 0.020593
2025-11-22 22:17:36 - GraphTrainer - INFO -   map@10: 0.015057
2025-11-22 22:17:36 - GraphTrainer - INFO -   mrr@10: 0.015614
2025-11-22 22:17:36 - GraphTrainer - INFO -   precision@20: 0.003325
2025-11-22 22:17:36 - GraphTrainer - INFO -   recall@20: 0.063178
2025-11-22 22:17:36 - GraphTrainer - INFO -   hit_rate@20: 0.066392
2025-11-22 22:17:36 - GraphTrainer - INFO -   ndcg@20: 0.026897
2025-11-22 22:17:36 - GraphTrainer - INFO -   map@20: 0.016739
2025-11-22 22:17:36 - GraphTrainer - INFO -   mrr@20: 0.017393
2025-11-22 22:17:36 - GraphTrainer - INFO - 第 30 轮训练完成
2025-11-22 22:17:36 - GraphTrainer - INFO - train_loss: 0.429112
2025-11-22 22:17:36 - GraphTrainer - INFO - precision@5: 0.004803
2025-11-22 22:17:36 - GraphTrainer - INFO - recall@5: 0.023039
2025-11-22 22:17:36 - GraphTrainer - INFO - hit_rate@5: 0.023965
2025-11-22 22:17:36 - GraphTrainer - INFO - ndcg@5: 0.015622
2025-11-22 22:17:36 - GraphTrainer - INFO - map@5: 0.013040
2025-11-22 22:17:36 - GraphTrainer - INFO - mrr@5: 0.013494
2025-11-22 22:17:36 - GraphTrainer - INFO - precision@10: 0.004011
2025-11-22 22:17:36 - GraphTrainer - INFO - recall@10: 0.038340
2025-11-22 22:17:36 - GraphTrainer - INFO - hit_rate@10: 0.040062
2025-11-22 22:17:36 - GraphTrainer - INFO - ndcg@10: 0.020593
2025-11-22 22:17:36 - GraphTrainer - INFO - map@10: 0.015057
2025-11-22 22:17:36 - GraphTrainer - INFO - mrr@10: 0.015614
2025-11-22 22:17:36 - GraphTrainer - INFO - precision@20: 0.003325
2025-11-22 22:17:36 - GraphTrainer - INFO - recall@20: 0.063178
2025-11-22 22:17:36 - GraphTrainer - INFO - hit_rate@20: 0.066392
2025-11-22 22:17:36 - GraphTrainer - INFO - ndcg@20: 0.026897
2025-11-22 22:17:36 - GraphTrainer - INFO - map@20: 0.016739
2025-11-22 22:17:36 - GraphTrainer - INFO - mrr@20: 0.017393
2025-11-22 22:17:36 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:17:36 - GraphTrainer - INFO - 检查点已保存: Epoch 30 -> ./checkpoints/checkpoint_epoch_30.pth
2025-11-22 22:17:36 - GraphTrainer - INFO - ============================================================
2025-11-22 22:17:36 - GraphTrainer - INFO - 开始第 31/1000 轮训练
2025-11-22 22:17:36 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4155, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4168, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4066, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4188, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4243, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4259, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4266, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4247, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4389, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4266, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4409, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4378, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4005, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4201, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4238, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4293, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4318, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4399, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4137, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4485, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4377, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4458, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4168, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4422, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4302, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4330, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4411, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4153, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4433, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4212, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4365, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4322, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4350, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4210, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4365, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4330, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4343, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4202, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4124, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4130, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4246, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4087, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4674, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4184, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4676, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4589, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4249, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4167, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4231, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4420, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4373, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4299, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4328, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4216, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4153, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4302, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4399, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4178, device='cuda:0', grad_fn=<AddBackward0>)
The 30 training average loss: 0.4291120839530024
2025-11-22 22:17:47 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:17:47 - GraphTrainer - INFO -   precision@5: 0.005451
2025-11-22 22:17:47 - GraphTrainer - INFO -   recall@5: 0.026109
2025-11-22 22:17:47 - GraphTrainer - INFO -   hit_rate@5: 0.027154
2025-11-22 22:17:47 - GraphTrainer - INFO -   ndcg@5: 0.016790
2025-11-22 22:17:47 - GraphTrainer - INFO -   map@5: 0.013549
2025-11-22 22:17:47 - GraphTrainer - INFO -   mrr@5: 0.014088
2025-11-22 22:17:47 - GraphTrainer - INFO -   precision@10: 0.004181
2025-11-22 22:17:47 - GraphTrainer - INFO -   recall@10: 0.040239
2025-11-22 22:17:47 - GraphTrainer - INFO -   hit_rate@10: 0.041707
2025-11-22 22:17:47 - GraphTrainer - INFO -   ndcg@10: 0.021377
2025-11-22 22:17:47 - GraphTrainer - INFO -   map@10: 0.015432
2025-11-22 22:17:47 - GraphTrainer - INFO -   mrr@10: 0.016025
2025-11-22 22:17:47 - GraphTrainer - INFO -   precision@20: 0.003464
2025-11-22 22:17:47 - GraphTrainer - INFO -   recall@20: 0.066037
2025-11-22 22:17:47 - GraphTrainer - INFO -   hit_rate@20: 0.068912
2025-11-22 22:17:47 - GraphTrainer - INFO -   ndcg@20: 0.027906
2025-11-22 22:17:47 - GraphTrainer - INFO -   map@20: 0.017163
2025-11-22 22:17:47 - GraphTrainer - INFO -   mrr@20: 0.017847
2025-11-22 22:17:47 - GraphTrainer - INFO - 第 31 轮训练完成
2025-11-22 22:17:47 - GraphTrainer - INFO - train_loss: 0.425671
2025-11-22 22:17:47 - GraphTrainer - INFO - precision@5: 0.005451
2025-11-22 22:17:47 - GraphTrainer - INFO - recall@5: 0.026109
2025-11-22 22:17:47 - GraphTrainer - INFO - hit_rate@5: 0.027154
2025-11-22 22:17:47 - GraphTrainer - INFO - ndcg@5: 0.016790
2025-11-22 22:17:47 - GraphTrainer - INFO - map@5: 0.013549
2025-11-22 22:17:47 - GraphTrainer - INFO - mrr@5: 0.014088
2025-11-22 22:17:47 - GraphTrainer - INFO - precision@10: 0.004181
2025-11-22 22:17:47 - GraphTrainer - INFO - recall@10: 0.040239
2025-11-22 22:17:47 - GraphTrainer - INFO - hit_rate@10: 0.041707
2025-11-22 22:17:47 - GraphTrainer - INFO - ndcg@10: 0.021377
2025-11-22 22:17:47 - GraphTrainer - INFO - map@10: 0.015432
2025-11-22 22:17:47 - GraphTrainer - INFO - mrr@10: 0.016025
2025-11-22 22:17:47 - GraphTrainer - INFO - precision@20: 0.003464
2025-11-22 22:17:47 - GraphTrainer - INFO - recall@20: 0.066037
2025-11-22 22:17:47 - GraphTrainer - INFO - hit_rate@20: 0.068912
2025-11-22 22:17:47 - GraphTrainer - INFO - ndcg@20: 0.027906
2025-11-22 22:17:47 - GraphTrainer - INFO - map@20: 0.017163
2025-11-22 22:17:47 - GraphTrainer - INFO - mrr@20: 0.017847
2025-11-22 22:17:47 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:17:47 - GraphTrainer - INFO - ============================================================
2025-11-22 22:17:47 - GraphTrainer - INFO - 开始第 32/1000 轮训练
2025-11-22 22:17:47 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4078, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4222, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4427, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4447, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4108, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4035, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4220, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4419, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4296, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4329, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4362, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4144, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4266, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4201, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4214, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4410, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4071, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4029, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4220, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4153, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4372, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4422, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4074, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4388, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4256, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4237, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4178, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4172, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3861, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4453, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4048, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4170, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4236, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4226, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4254, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4250, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4380, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4335, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4362, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4222, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4427, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4062, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4148, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4297, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4344, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4283, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4152, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4287, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4147, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4291, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4261, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4511, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4461, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4375, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4496, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4388, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4193, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4219, device='cuda:0', grad_fn=<AddBackward0>)
The 31 training average loss: 0.425671089825959
2025-11-22 22:17:58 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:17:58 - GraphTrainer - INFO -   precision@5: 0.005698
2025-11-22 22:17:58 - GraphTrainer - INFO -   recall@5: 0.026943
2025-11-22 22:17:58 - GraphTrainer - INFO -   hit_rate@5: 0.028388
2025-11-22 22:17:58 - GraphTrainer - INFO -   ndcg@5: 0.017087
2025-11-22 22:17:58 - GraphTrainer - INFO -   map@5: 0.013629
2025-11-22 22:17:58 - GraphTrainer - INFO -   mrr@5: 0.014271
2025-11-22 22:17:58 - GraphTrainer - INFO -   precision@10: 0.004392
2025-11-22 22:17:58 - GraphTrainer - INFO -   recall@10: 0.041230
2025-11-22 22:17:58 - GraphTrainer - INFO -   hit_rate@10: 0.043713
2025-11-22 22:17:58 - GraphTrainer - INFO -   ndcg@10: 0.021736
2025-11-22 22:17:58 - GraphTrainer - INFO -   map@10: 0.015506
2025-11-22 22:17:58 - GraphTrainer - INFO -   mrr@10: 0.016272
2025-11-22 22:17:58 - GraphTrainer - INFO -   precision@20: 0.003446
2025-11-22 22:17:58 - GraphTrainer - INFO -   recall@20: 0.064946
2025-11-22 22:17:58 - GraphTrainer - INFO -   hit_rate@20: 0.068449
2025-11-22 22:17:58 - GraphTrainer - INFO -   ndcg@20: 0.027755
2025-11-22 22:17:58 - GraphTrainer - INFO -   map@20: 0.017122
2025-11-22 22:17:58 - GraphTrainer - INFO -   mrr@20: 0.017955
2025-11-22 22:17:58 - GraphTrainer - INFO - 第 32 轮训练完成
2025-11-22 22:17:58 - GraphTrainer - INFO - train_loss: 0.424278
2025-11-22 22:17:58 - GraphTrainer - INFO - precision@5: 0.005698
2025-11-22 22:17:58 - GraphTrainer - INFO - recall@5: 0.026943
2025-11-22 22:17:58 - GraphTrainer - INFO - hit_rate@5: 0.028388
2025-11-22 22:17:58 - GraphTrainer - INFO - ndcg@5: 0.017087
2025-11-22 22:17:58 - GraphTrainer - INFO - map@5: 0.013629
2025-11-22 22:17:58 - GraphTrainer - INFO - mrr@5: 0.014271
2025-11-22 22:17:58 - GraphTrainer - INFO - precision@10: 0.004392
2025-11-22 22:17:58 - GraphTrainer - INFO - recall@10: 0.041230
2025-11-22 22:17:58 - GraphTrainer - INFO - hit_rate@10: 0.043713
2025-11-22 22:17:58 - GraphTrainer - INFO - ndcg@10: 0.021736
2025-11-22 22:17:58 - GraphTrainer - INFO - map@10: 0.015506
2025-11-22 22:17:58 - GraphTrainer - INFO - mrr@10: 0.016272
2025-11-22 22:17:58 - GraphTrainer - INFO - precision@20: 0.003446
2025-11-22 22:17:58 - GraphTrainer - INFO - recall@20: 0.064946
2025-11-22 22:17:58 - GraphTrainer - INFO - hit_rate@20: 0.068449
2025-11-22 22:17:58 - GraphTrainer - INFO - ndcg@20: 0.027755
2025-11-22 22:17:58 - GraphTrainer - INFO - map@20: 0.017122
2025-11-22 22:17:58 - GraphTrainer - INFO - mrr@20: 0.017955
2025-11-22 22:17:58 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:17:58 - GraphTrainer - INFO - ============================================================
2025-11-22 22:17:58 - GraphTrainer - INFO - 开始第 33/1000 轮训练
2025-11-22 22:17:58 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3999, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4194, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4517, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4300, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4321, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4040, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4202, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4380, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4260, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4372, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4095, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4128, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4103, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4219, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4256, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4224, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4107, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4018, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4208, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4001, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4063, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4253, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4207, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4192, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3995, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4350, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4427, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4377, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4381, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4301, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4353, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4384, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4199, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4416, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4282, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4127, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4088, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4479, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4708, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4154, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4331, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4247, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4329, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4066, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4469, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4413, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4373, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4034, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4076, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4146, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4047, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4498, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4137, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4201, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4353, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4271, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4195, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4219, device='cuda:0', grad_fn=<AddBackward0>)
The 32 training average loss: 0.4242780840602414
2025-11-22 22:18:10 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:18:10 - GraphTrainer - INFO -   precision@5: 0.004834
2025-11-22 22:18:10 - GraphTrainer - INFO -   recall@5: 0.023274
2025-11-22 22:18:10 - GraphTrainer - INFO -   hit_rate@5: 0.024171
2025-11-22 22:18:10 - GraphTrainer - INFO -   ndcg@5: 0.015345
2025-11-22 22:18:10 - GraphTrainer - INFO -   map@5: 0.012604
2025-11-22 22:18:10 - GraphTrainer - INFO -   mrr@5: 0.013050
2025-11-22 22:18:10 - GraphTrainer - INFO -   precision@10: 0.004166
2025-11-22 22:18:10 - GraphTrainer - INFO -   recall@10: 0.039852
2025-11-22 22:18:10 - GraphTrainer - INFO -   hit_rate@10: 0.041605
2025-11-22 22:18:10 - GraphTrainer - INFO -   ndcg@10: 0.020730
2025-11-22 22:18:10 - GraphTrainer - INFO -   map@10: 0.014787
2025-11-22 22:18:10 - GraphTrainer - INFO -   mrr@10: 0.015347
2025-11-22 22:18:10 - GraphTrainer - INFO -   precision@20: 0.003368
2025-11-22 22:18:10 - GraphTrainer - INFO -   recall@20: 0.064135
2025-11-22 22:18:10 - GraphTrainer - INFO -   hit_rate@20: 0.067112
2025-11-22 22:18:10 - GraphTrainer - INFO -   ndcg@20: 0.026879
2025-11-22 22:18:10 - GraphTrainer - INFO -   map@20: 0.016426
2025-11-22 22:18:10 - GraphTrainer - INFO -   mrr@20: 0.017062
2025-11-22 22:18:10 - GraphTrainer - INFO - 第 33 轮训练完成
2025-11-22 22:18:10 - GraphTrainer - INFO - train_loss: 0.423245
2025-11-22 22:18:10 - GraphTrainer - INFO - precision@5: 0.004834
2025-11-22 22:18:10 - GraphTrainer - INFO - recall@5: 0.023274
2025-11-22 22:18:10 - GraphTrainer - INFO - hit_rate@5: 0.024171
2025-11-22 22:18:10 - GraphTrainer - INFO - ndcg@5: 0.015345
2025-11-22 22:18:10 - GraphTrainer - INFO - map@5: 0.012604
2025-11-22 22:18:10 - GraphTrainer - INFO - mrr@5: 0.013050
2025-11-22 22:18:10 - GraphTrainer - INFO - precision@10: 0.004166
2025-11-22 22:18:10 - GraphTrainer - INFO - recall@10: 0.039852
2025-11-22 22:18:10 - GraphTrainer - INFO - hit_rate@10: 0.041605
2025-11-22 22:18:10 - GraphTrainer - INFO - ndcg@10: 0.020730
2025-11-22 22:18:10 - GraphTrainer - INFO - map@10: 0.014787
2025-11-22 22:18:10 - GraphTrainer - INFO - mrr@10: 0.015347
2025-11-22 22:18:10 - GraphTrainer - INFO - precision@20: 0.003368
2025-11-22 22:18:10 - GraphTrainer - INFO - recall@20: 0.064135
2025-11-22 22:18:10 - GraphTrainer - INFO - hit_rate@20: 0.067112
2025-11-22 22:18:10 - GraphTrainer - INFO - ndcg@20: 0.026879
2025-11-22 22:18:10 - GraphTrainer - INFO - map@20: 0.016426
2025-11-22 22:18:10 - GraphTrainer - INFO - mrr@20: 0.017062
2025-11-22 22:18:10 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:18:10 - GraphTrainer - INFO - ============================================================
2025-11-22 22:18:10 - GraphTrainer - INFO - 开始第 34/1000 轮训练
2025-11-22 22:18:10 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4222, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4116, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4119, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4311, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4112, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4036, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4393, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4157, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4533, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4309, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4275, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4257, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4191, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4130, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4301, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4184, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4166, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4335, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4098, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4291, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4203, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4404, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4259, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4219, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4302, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4373, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4134, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4154, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4313, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4037, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4207, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4170, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4273, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4403, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4224, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4321, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4335, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4151, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4202, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4108, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4574, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4029, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4186, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4012, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4247, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4439, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4380, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4014, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4190, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4341, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4433, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4237, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4048, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4380, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4280, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4183, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4108, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4069, device='cuda:0', grad_fn=<AddBackward0>)
The 33 training average loss: 0.4232447728000838
2025-11-22 22:18:21 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:18:21 - GraphTrainer - INFO -   precision@5: 0.005060
2025-11-22 22:18:21 - GraphTrainer - INFO -   recall@5: 0.024390
2025-11-22 22:18:21 - GraphTrainer - INFO -   hit_rate@5: 0.025302
2025-11-22 22:18:21 - GraphTrainer - INFO -   ndcg@5: 0.015232
2025-11-22 22:18:21 - GraphTrainer - INFO -   map@5: 0.012097
2025-11-22 22:18:21 - GraphTrainer - INFO -   mrr@5: 0.012555
2025-11-22 22:18:21 - GraphTrainer - INFO -   precision@10: 0.004304
2025-11-22 22:18:21 - GraphTrainer - INFO -   recall@10: 0.041089
2025-11-22 22:18:21 - GraphTrainer - INFO -   hit_rate@10: 0.042942
2025-11-22 22:18:21 - GraphTrainer - INFO -   ndcg@10: 0.020670
2025-11-22 22:18:21 - GraphTrainer - INFO -   map@10: 0.014299
2025-11-22 22:18:21 - GraphTrainer - INFO -   mrr@10: 0.014890
2025-11-22 22:18:21 - GraphTrainer - INFO -   precision@20: 0.003458
2025-11-22 22:18:21 - GraphTrainer - INFO -   recall@20: 0.065604
2025-11-22 22:18:21 - GraphTrainer - INFO -   hit_rate@20: 0.068964
2025-11-22 22:18:21 - GraphTrainer - INFO -   ndcg@20: 0.026921
2025-11-22 22:18:21 - GraphTrainer - INFO -   map@20: 0.015979
2025-11-22 22:18:21 - GraphTrainer - INFO -   mrr@20: 0.016669
2025-11-22 22:18:21 - GraphTrainer - INFO - 第 34 轮训练完成
2025-11-22 22:18:21 - GraphTrainer - INFO - train_loss: 0.419150
2025-11-22 22:18:21 - GraphTrainer - INFO - precision@5: 0.005060
2025-11-22 22:18:21 - GraphTrainer - INFO - recall@5: 0.024390
2025-11-22 22:18:21 - GraphTrainer - INFO - hit_rate@5: 0.025302
2025-11-22 22:18:21 - GraphTrainer - INFO - ndcg@5: 0.015232
2025-11-22 22:18:21 - GraphTrainer - INFO - map@5: 0.012097
2025-11-22 22:18:21 - GraphTrainer - INFO - mrr@5: 0.012555
2025-11-22 22:18:21 - GraphTrainer - INFO - precision@10: 0.004304
2025-11-22 22:18:21 - GraphTrainer - INFO - recall@10: 0.041089
2025-11-22 22:18:21 - GraphTrainer - INFO - hit_rate@10: 0.042942
2025-11-22 22:18:21 - GraphTrainer - INFO - ndcg@10: 0.020670
2025-11-22 22:18:21 - GraphTrainer - INFO - map@10: 0.014299
2025-11-22 22:18:21 - GraphTrainer - INFO - mrr@10: 0.014890
2025-11-22 22:18:21 - GraphTrainer - INFO - precision@20: 0.003458
2025-11-22 22:18:21 - GraphTrainer - INFO - recall@20: 0.065604
2025-11-22 22:18:21 - GraphTrainer - INFO - hit_rate@20: 0.068964
2025-11-22 22:18:21 - GraphTrainer - INFO - ndcg@20: 0.026921
2025-11-22 22:18:21 - GraphTrainer - INFO - map@20: 0.015979
2025-11-22 22:18:21 - GraphTrainer - INFO - mrr@20: 0.016669
2025-11-22 22:18:21 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:18:21 - GraphTrainer - INFO - ============================================================
2025-11-22 22:18:21 - GraphTrainer - INFO - 开始第 35/1000 轮训练
2025-11-22 22:18:21 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4268, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4117, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4480, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4199, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4075, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4185, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4466, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4267, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4343, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4184, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4219, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4187, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4154, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3955, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4034, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4180, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4041, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3865, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4051, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4254, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4345, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4058, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4172, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4340, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4261, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4267, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4203, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4103, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4223, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4234, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4071, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4213, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4203, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4034, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4182, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4211, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4131, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4310, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4032, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4289, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4055, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4301, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4078, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4333, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4092, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4240, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4340, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4120, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4283, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4162, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4181, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4218, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4274, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4154, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4271, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4180, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4254, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4166, device='cuda:0', grad_fn=<AddBackward0>)
The 34 training average loss: 0.41915030982987633
2025-11-22 22:18:32 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:18:32 - GraphTrainer - INFO -   precision@5: 0.005801
2025-11-22 22:18:32 - GraphTrainer - INFO -   recall@5: 0.027695
2025-11-22 22:18:32 - GraphTrainer - INFO -   hit_rate@5: 0.028953
2025-11-22 22:18:32 - GraphTrainer - INFO -   ndcg@5: 0.018098
2025-11-22 22:18:32 - GraphTrainer - INFO -   map@5: 0.014744
2025-11-22 22:18:32 - GraphTrainer - INFO -   mrr@5: 0.015317
2025-11-22 22:18:32 - GraphTrainer - INFO -   precision@10: 0.004577
2025-11-22 22:18:32 - GraphTrainer - INFO -   recall@10: 0.043399
2025-11-22 22:18:32 - GraphTrainer - INFO -   hit_rate@10: 0.045616
2025-11-22 22:18:32 - GraphTrainer - INFO -   ndcg@10: 0.023212
2025-11-22 22:18:32 - GraphTrainer - INFO -   map@10: 0.016817
2025-11-22 22:18:32 - GraphTrainer - INFO -   mrr@10: 0.017511
2025-11-22 22:18:32 - GraphTrainer - INFO -   precision@20: 0.003615
2025-11-22 22:18:32 - GraphTrainer - INFO -   recall@20: 0.068474
2025-11-22 22:18:32 - GraphTrainer - INFO -   hit_rate@20: 0.071895
2025-11-22 22:18:32 - GraphTrainer - INFO -   ndcg@20: 0.029589
2025-11-22 22:18:32 - GraphTrainer - INFO -   map@20: 0.018532
2025-11-22 22:18:32 - GraphTrainer - INFO -   mrr@20: 0.019301
2025-11-22 22:18:32 - GraphTrainer - INFO - 第 35 轮训练完成
2025-11-22 22:18:32 - GraphTrainer - INFO - train_loss: 0.417152
2025-11-22 22:18:32 - GraphTrainer - INFO - precision@5: 0.005801
2025-11-22 22:18:32 - GraphTrainer - INFO - recall@5: 0.027695
2025-11-22 22:18:32 - GraphTrainer - INFO - hit_rate@5: 0.028953
2025-11-22 22:18:32 - GraphTrainer - INFO - ndcg@5: 0.018098
2025-11-22 22:18:32 - GraphTrainer - INFO - map@5: 0.014744
2025-11-22 22:18:32 - GraphTrainer - INFO - mrr@5: 0.015317
2025-11-22 22:18:32 - GraphTrainer - INFO - precision@10: 0.004577
2025-11-22 22:18:32 - GraphTrainer - INFO - recall@10: 0.043399
2025-11-22 22:18:32 - GraphTrainer - INFO - hit_rate@10: 0.045616
2025-11-22 22:18:32 - GraphTrainer - INFO - ndcg@10: 0.023212
2025-11-22 22:18:32 - GraphTrainer - INFO - map@10: 0.016817
2025-11-22 22:18:32 - GraphTrainer - INFO - mrr@10: 0.017511
2025-11-22 22:18:32 - GraphTrainer - INFO - precision@20: 0.003615
2025-11-22 22:18:32 - GraphTrainer - INFO - recall@20: 0.068474
2025-11-22 22:18:32 - GraphTrainer - INFO - hit_rate@20: 0.071895
2025-11-22 22:18:32 - GraphTrainer - INFO - ndcg@20: 0.029589
2025-11-22 22:18:32 - GraphTrainer - INFO - map@20: 0.018532
2025-11-22 22:18:32 - GraphTrainer - INFO - mrr@20: 0.019301
2025-11-22 22:18:32 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:18:32 - GraphTrainer - INFO - ============================================================
2025-11-22 22:18:32 - GraphTrainer - INFO - 开始第 36/1000 轮训练
2025-11-22 22:18:32 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3980, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4270, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4237, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4095, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4236, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4148, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4104, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3878, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4050, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4064, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4389, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4252, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4343, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4101, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4151, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3985, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4127, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4306, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4485, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4297, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4065, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4236, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3994, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4144, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4397, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4258, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4076, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4215, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4082, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4339, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3945, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4185, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3871, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4017, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4564, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4189, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4120, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4344, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4217, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4124, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4111, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4178, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4042, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4380, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4507, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4204, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4125, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4044, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4194, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4188, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3998, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4217, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4231, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4005, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4217, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4130, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4270, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4027, device='cuda:0', grad_fn=<AddBackward0>)
The 35 training average loss: 0.41715226091187574
2025-11-22 22:18:43 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:18:43 - GraphTrainer - INFO -   precision@5: 0.005204
2025-11-22 22:18:43 - GraphTrainer - INFO -   recall@5: 0.025076
2025-11-22 22:18:43 - GraphTrainer - INFO -   hit_rate@5: 0.026022
2025-11-22 22:18:43 - GraphTrainer - INFO -   ndcg@5: 0.016918
2025-11-22 22:18:43 - GraphTrainer - INFO -   map@5: 0.014090
2025-11-22 22:18:43 - GraphTrainer - INFO -   mrr@5: 0.014506
2025-11-22 22:18:43 - GraphTrainer - INFO -   precision@10: 0.004258
2025-11-22 22:18:43 - GraphTrainer - INFO -   recall@10: 0.040579
2025-11-22 22:18:43 - GraphTrainer - INFO -   hit_rate@10: 0.042427
2025-11-22 22:18:43 - GraphTrainer - INFO -   ndcg@10: 0.021977
2025-11-22 22:18:43 - GraphTrainer - INFO -   map@10: 0.016147
2025-11-22 22:18:43 - GraphTrainer - INFO -   mrr@10: 0.016677
2025-11-22 22:18:43 - GraphTrainer - INFO -   precision@20: 0.003456
2025-11-22 22:18:43 - GraphTrainer - INFO -   recall@20: 0.065883
2025-11-22 22:18:43 - GraphTrainer - INFO -   hit_rate@20: 0.068809
2025-11-22 22:18:43 - GraphTrainer - INFO -   ndcg@20: 0.028408
2025-11-22 22:18:43 - GraphTrainer - INFO -   map@20: 0.017882
2025-11-22 22:18:43 - GraphTrainer - INFO -   mrr@20: 0.018485
2025-11-22 22:18:43 - GraphTrainer - INFO - 第 36 轮训练完成
2025-11-22 22:18:43 - GraphTrainer - INFO - train_loss: 0.415932
2025-11-22 22:18:43 - GraphTrainer - INFO - precision@5: 0.005204
2025-11-22 22:18:43 - GraphTrainer - INFO - recall@5: 0.025076
2025-11-22 22:18:43 - GraphTrainer - INFO - hit_rate@5: 0.026022
2025-11-22 22:18:43 - GraphTrainer - INFO - ndcg@5: 0.016918
2025-11-22 22:18:43 - GraphTrainer - INFO - map@5: 0.014090
2025-11-22 22:18:43 - GraphTrainer - INFO - mrr@5: 0.014506
2025-11-22 22:18:43 - GraphTrainer - INFO - precision@10: 0.004258
2025-11-22 22:18:43 - GraphTrainer - INFO - recall@10: 0.040579
2025-11-22 22:18:43 - GraphTrainer - INFO - hit_rate@10: 0.042427
2025-11-22 22:18:43 - GraphTrainer - INFO - ndcg@10: 0.021977
2025-11-22 22:18:43 - GraphTrainer - INFO - map@10: 0.016147
2025-11-22 22:18:43 - GraphTrainer - INFO - mrr@10: 0.016677
2025-11-22 22:18:43 - GraphTrainer - INFO - precision@20: 0.003456
2025-11-22 22:18:43 - GraphTrainer - INFO - recall@20: 0.065883
2025-11-22 22:18:43 - GraphTrainer - INFO - hit_rate@20: 0.068809
2025-11-22 22:18:43 - GraphTrainer - INFO - ndcg@20: 0.028408
2025-11-22 22:18:43 - GraphTrainer - INFO - map@20: 0.017882
2025-11-22 22:18:43 - GraphTrainer - INFO - mrr@20: 0.018485
2025-11-22 22:18:43 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:18:43 - GraphTrainer - INFO - ============================================================
2025-11-22 22:18:43 - GraphTrainer - INFO - 开始第 37/1000 轮训练
2025-11-22 22:18:43 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4058, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4134, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4226, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4153, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4084, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4133, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4184, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4084, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4072, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4136, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4190, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4161, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4054, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4312, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4371, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4229, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4141, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4079, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3959, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4306, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4092, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4138, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4110, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4136, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4128, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4069, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4244, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4210, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4091, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4342, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4512, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4087, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4254, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4054, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4278, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4275, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4176, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4087, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4282, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4171, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3835, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4220, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4128, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4168, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4138, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4210, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4002, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4256, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4185, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4165, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4077, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4179, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4214, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4171, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3960, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4116, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4168, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4246, device='cuda:0', grad_fn=<AddBackward0>)
The 36 training average loss: 0.4159316076286908
2025-11-22 22:18:54 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:18:54 - GraphTrainer - INFO -   precision@5: 0.005194
2025-11-22 22:18:54 - GraphTrainer - INFO -   recall@5: 0.024669
2025-11-22 22:18:54 - GraphTrainer - INFO -   hit_rate@5: 0.025919
2025-11-22 22:18:54 - GraphTrainer - INFO -   ndcg@5: 0.016264
2025-11-22 22:18:54 - GraphTrainer - INFO -   map@5: 0.013311
2025-11-22 22:18:54 - GraphTrainer - INFO -   mrr@5: 0.013944
2025-11-22 22:18:54 - GraphTrainer - INFO -   precision@10: 0.004181
2025-11-22 22:18:54 - GraphTrainer - INFO -   recall@10: 0.039703
2025-11-22 22:18:54 - GraphTrainer - INFO -   hit_rate@10: 0.041707
2025-11-22 22:18:54 - GraphTrainer - INFO -   ndcg@10: 0.021136
2025-11-22 22:18:54 - GraphTrainer - INFO -   map@10: 0.015283
2025-11-22 22:18:54 - GraphTrainer - INFO -   mrr@10: 0.016014
2025-11-22 22:18:54 - GraphTrainer - INFO -   precision@20: 0.003471
2025-11-22 22:18:54 - GraphTrainer - INFO -   recall@20: 0.065899
2025-11-22 22:18:54 - GraphTrainer - INFO -   hit_rate@20: 0.069169
2025-11-22 22:18:54 - GraphTrainer - INFO -   ndcg@20: 0.027752
2025-11-22 22:18:54 - GraphTrainer - INFO -   map@20: 0.017042
2025-11-22 22:18:54 - GraphTrainer - INFO -   mrr@20: 0.017852
2025-11-22 22:18:54 - GraphTrainer - INFO - 第 37 轮训练完成
2025-11-22 22:18:54 - GraphTrainer - INFO - train_loss: 0.415854
2025-11-22 22:18:54 - GraphTrainer - INFO - precision@5: 0.005194
2025-11-22 22:18:54 - GraphTrainer - INFO - recall@5: 0.024669
2025-11-22 22:18:54 - GraphTrainer - INFO - hit_rate@5: 0.025919
2025-11-22 22:18:54 - GraphTrainer - INFO - ndcg@5: 0.016264
2025-11-22 22:18:54 - GraphTrainer - INFO - map@5: 0.013311
2025-11-22 22:18:54 - GraphTrainer - INFO - mrr@5: 0.013944
2025-11-22 22:18:54 - GraphTrainer - INFO - precision@10: 0.004181
2025-11-22 22:18:54 - GraphTrainer - INFO - recall@10: 0.039703
2025-11-22 22:18:54 - GraphTrainer - INFO - hit_rate@10: 0.041707
2025-11-22 22:18:54 - GraphTrainer - INFO - ndcg@10: 0.021136
2025-11-22 22:18:54 - GraphTrainer - INFO - map@10: 0.015283
2025-11-22 22:18:54 - GraphTrainer - INFO - mrr@10: 0.016014
2025-11-22 22:18:54 - GraphTrainer - INFO - precision@20: 0.003471
2025-11-22 22:18:54 - GraphTrainer - INFO - recall@20: 0.065899
2025-11-22 22:18:54 - GraphTrainer - INFO - hit_rate@20: 0.069169
2025-11-22 22:18:54 - GraphTrainer - INFO - ndcg@20: 0.027752
2025-11-22 22:18:54 - GraphTrainer - INFO - map@20: 0.017042
2025-11-22 22:18:54 - GraphTrainer - INFO - mrr@20: 0.017852
2025-11-22 22:18:54 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:18:54 - GraphTrainer - INFO - ============================================================
2025-11-22 22:18:54 - GraphTrainer - INFO - 开始第 38/1000 轮训练
2025-11-22 22:18:54 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4042, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4166, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4419, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3802, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4256, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4236, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4015, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4097, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4165, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3883, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4210, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4137, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4107, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4182, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4142, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4228, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3967, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4166, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4132, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4391, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4251, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4158, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4077, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4077, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4115, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4053, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4283, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4136, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4305, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3937, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4159, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4275, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3923, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4105, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3964, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4105, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4299, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4148, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4427, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4026, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4314, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4044, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4167, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4283, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4307, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4157, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4245, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3972, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4056, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4180, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4335, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4093, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4235, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4307, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4179, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4391, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4107, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4256, device='cuda:0', grad_fn=<AddBackward0>)
The 37 training average loss: 0.4158540316696825
2025-11-22 22:19:05 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:19:05 - GraphTrainer - INFO -   precision@5: 0.004814
2025-11-22 22:19:05 - GraphTrainer - INFO -   recall@5: 0.022984
2025-11-22 22:19:05 - GraphTrainer - INFO -   hit_rate@5: 0.024016
2025-11-22 22:19:05 - GraphTrainer - INFO -   ndcg@5: 0.014922
2025-11-22 22:19:05 - GraphTrainer - INFO -   map@5: 0.012098
2025-11-22 22:19:05 - GraphTrainer - INFO -   mrr@5: 0.012565
2025-11-22 22:19:05 - GraphTrainer - INFO -   precision@10: 0.004047
2025-11-22 22:19:05 - GraphTrainer - INFO -   recall@10: 0.038339
2025-11-22 22:19:05 - GraphTrainer - INFO -   hit_rate@10: 0.040422
2025-11-22 22:19:05 - GraphTrainer - INFO -   ndcg@10: 0.019847
2025-11-22 22:19:05 - GraphTrainer - INFO -   map@10: 0.014051
2025-11-22 22:19:05 - GraphTrainer - INFO -   mrr@10: 0.014647
2025-11-22 22:19:05 - GraphTrainer - INFO -   precision@20: 0.003412
2025-11-22 22:19:05 - GraphTrainer - INFO -   recall@20: 0.064314
2025-11-22 22:19:05 - GraphTrainer - INFO -   hit_rate@20: 0.067935
2025-11-22 22:19:05 - GraphTrainer - INFO -   ndcg@20: 0.026456
2025-11-22 22:19:05 - GraphTrainer - INFO -   map@20: 0.015816
2025-11-22 22:19:05 - GraphTrainer - INFO -   mrr@20: 0.016510
2025-11-22 22:19:05 - GraphTrainer - INFO - 第 38 轮训练完成
2025-11-22 22:19:05 - GraphTrainer - INFO - train_loss: 0.414770
2025-11-22 22:19:05 - GraphTrainer - INFO - precision@5: 0.004814
2025-11-22 22:19:05 - GraphTrainer - INFO - recall@5: 0.022984
2025-11-22 22:19:05 - GraphTrainer - INFO - hit_rate@5: 0.024016
2025-11-22 22:19:05 - GraphTrainer - INFO - ndcg@5: 0.014922
2025-11-22 22:19:05 - GraphTrainer - INFO - map@5: 0.012098
2025-11-22 22:19:05 - GraphTrainer - INFO - mrr@5: 0.012565
2025-11-22 22:19:05 - GraphTrainer - INFO - precision@10: 0.004047
2025-11-22 22:19:05 - GraphTrainer - INFO - recall@10: 0.038339
2025-11-22 22:19:05 - GraphTrainer - INFO - hit_rate@10: 0.040422
2025-11-22 22:19:05 - GraphTrainer - INFO - ndcg@10: 0.019847
2025-11-22 22:19:05 - GraphTrainer - INFO - map@10: 0.014051
2025-11-22 22:19:05 - GraphTrainer - INFO - mrr@10: 0.014647
2025-11-22 22:19:05 - GraphTrainer - INFO - precision@20: 0.003412
2025-11-22 22:19:05 - GraphTrainer - INFO - recall@20: 0.064314
2025-11-22 22:19:05 - GraphTrainer - INFO - hit_rate@20: 0.067935
2025-11-22 22:19:05 - GraphTrainer - INFO - ndcg@20: 0.026456
2025-11-22 22:19:05 - GraphTrainer - INFO - map@20: 0.015816
2025-11-22 22:19:05 - GraphTrainer - INFO - mrr@20: 0.016510
2025-11-22 22:19:05 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:19:05 - GraphTrainer - INFO - ============================================================
2025-11-22 22:19:05 - GraphTrainer - INFO - 开始第 39/1000 轮训练
2025-11-22 22:19:05 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4155, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4273, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4236, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4232, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4311, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4141, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3987, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4115, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4106, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4401, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4062, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4193, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3979, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3962, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3867, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4203, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4113, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4169, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4098, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3948, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4004, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4407, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3966, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4100, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4042, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4091, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4241, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4190, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4168, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4246, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4258, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3904, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4389, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3985, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4174, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4183, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4102, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4282, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3880, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4049, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4193, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4022, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4284, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4107, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4260, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4157, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4018, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4269, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4097, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4322, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4197, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4256, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4271, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4191, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3964, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4185, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4306, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4259, device='cuda:0', grad_fn=<AddBackward0>)
The 38 training average loss: 0.4147695693476447
2025-11-22 22:19:16 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:19:16 - GraphTrainer - INFO -   precision@5: 0.005318
2025-11-22 22:19:16 - GraphTrainer - INFO -   recall@5: 0.025570
2025-11-22 22:19:16 - GraphTrainer - INFO -   hit_rate@5: 0.026536
2025-11-22 22:19:16 - GraphTrainer - INFO -   ndcg@5: 0.016761
2025-11-22 22:19:16 - GraphTrainer - INFO -   map@5: 0.013698
2025-11-22 22:19:16 - GraphTrainer - INFO -   mrr@5: 0.014161
2025-11-22 22:19:16 - GraphTrainer - INFO -   precision@10: 0.004382
2025-11-22 22:19:16 - GraphTrainer - INFO -   recall@10: 0.041559
2025-11-22 22:19:16 - GraphTrainer - INFO -   hit_rate@10: 0.043713
2025-11-22 22:19:16 - GraphTrainer - INFO -   ndcg@10: 0.021930
2025-11-22 22:19:16 - GraphTrainer - INFO -   map@10: 0.015762
2025-11-22 22:19:16 - GraphTrainer - INFO -   mrr@10: 0.016375
2025-11-22 22:19:16 - GraphTrainer - INFO -   precision@20: 0.003464
2025-11-22 22:19:16 - GraphTrainer - INFO -   recall@20: 0.065417
2025-11-22 22:19:16 - GraphTrainer - INFO -   hit_rate@20: 0.068809
2025-11-22 22:19:16 - GraphTrainer - INFO -   ndcg@20: 0.028000
2025-11-22 22:19:16 - GraphTrainer - INFO -   map@20: 0.017389
2025-11-22 22:19:16 - GraphTrainer - INFO -   mrr@20: 0.018085
2025-11-22 22:19:16 - GraphTrainer - INFO - 第 39 轮训练完成
2025-11-22 22:19:16 - GraphTrainer - INFO - train_loss: 0.411995
2025-11-22 22:19:16 - GraphTrainer - INFO - precision@5: 0.005318
2025-11-22 22:19:16 - GraphTrainer - INFO - recall@5: 0.025570
2025-11-22 22:19:16 - GraphTrainer - INFO - hit_rate@5: 0.026536
2025-11-22 22:19:16 - GraphTrainer - INFO - ndcg@5: 0.016761
2025-11-22 22:19:16 - GraphTrainer - INFO - map@5: 0.013698
2025-11-22 22:19:16 - GraphTrainer - INFO - mrr@5: 0.014161
2025-11-22 22:19:16 - GraphTrainer - INFO - precision@10: 0.004382
2025-11-22 22:19:16 - GraphTrainer - INFO - recall@10: 0.041559
2025-11-22 22:19:16 - GraphTrainer - INFO - hit_rate@10: 0.043713
2025-11-22 22:19:16 - GraphTrainer - INFO - ndcg@10: 0.021930
2025-11-22 22:19:16 - GraphTrainer - INFO - map@10: 0.015762
2025-11-22 22:19:16 - GraphTrainer - INFO - mrr@10: 0.016375
2025-11-22 22:19:16 - GraphTrainer - INFO - precision@20: 0.003464
2025-11-22 22:19:16 - GraphTrainer - INFO - recall@20: 0.065417
2025-11-22 22:19:16 - GraphTrainer - INFO - hit_rate@20: 0.068809
2025-11-22 22:19:16 - GraphTrainer - INFO - ndcg@20: 0.028000
2025-11-22 22:19:16 - GraphTrainer - INFO - map@20: 0.017389
2025-11-22 22:19:16 - GraphTrainer - INFO - mrr@20: 0.018085
2025-11-22 22:19:16 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:19:16 - GraphTrainer - INFO - ============================================================
2025-11-22 22:19:16 - GraphTrainer - INFO - 开始第 40/1000 轮训练
2025-11-22 22:19:16 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4268, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4173, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3959, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4130, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4162, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4404, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4254, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4089, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3975, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4001, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4049, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4054, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4073, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4118, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4219, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3969, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4090, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4261, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4220, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4158, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3947, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4062, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4310, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4088, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4198, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3926, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4153, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4115, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4148, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4255, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4080, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4085, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4134, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4049, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4038, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4340, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4348, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4225, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3989, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4054, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4264, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3871, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4053, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4160, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4079, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4206, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4098, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4343, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4101, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4073, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4136, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4124, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4094, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4043, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4137, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3899, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4102, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4004, device='cuda:0', grad_fn=<AddBackward0>)
The 39 training average loss: 0.4119945127388527
2025-11-22 22:19:28 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:19:28 - GraphTrainer - INFO -   precision@5: 0.005276
2025-11-22 22:19:28 - GraphTrainer - INFO -   recall@5: 0.025645
2025-11-22 22:19:28 - GraphTrainer - INFO -   hit_rate@5: 0.026382
2025-11-22 22:19:28 - GraphTrainer - INFO -   ndcg@5: 0.016577
2025-11-22 22:19:28 - GraphTrainer - INFO -   map@5: 0.013496
2025-11-22 22:19:28 - GraphTrainer - INFO -   mrr@5: 0.013869
2025-11-22 22:19:28 - GraphTrainer - INFO -   precision@10: 0.004274
2025-11-22 22:19:28 - GraphTrainer - INFO -   recall@10: 0.040895
2025-11-22 22:19:28 - GraphTrainer - INFO -   hit_rate@10: 0.042633
2025-11-22 22:19:28 - GraphTrainer - INFO -   ndcg@10: 0.021546
2025-11-22 22:19:28 - GraphTrainer - INFO -   map@10: 0.015503
2025-11-22 22:19:28 - GraphTrainer - INFO -   mrr@10: 0.016003
2025-11-22 22:19:28 - GraphTrainer - INFO -   precision@20: 0.003620
2025-11-22 22:19:28 - GraphTrainer - INFO -   recall@20: 0.068696
2025-11-22 22:19:28 - GraphTrainer - INFO -   hit_rate@20: 0.072049
2025-11-22 22:19:28 - GraphTrainer - INFO -   ndcg@20: 0.028614
2025-11-22 22:19:28 - GraphTrainer - INFO -   map@20: 0.017390
2025-11-22 22:19:28 - GraphTrainer - INFO -   mrr@20: 0.017999
2025-11-22 22:19:28 - GraphTrainer - INFO - 第 40 轮训练完成
2025-11-22 22:19:28 - GraphTrainer - INFO - train_loss: 0.410963
2025-11-22 22:19:28 - GraphTrainer - INFO - precision@5: 0.005276
2025-11-22 22:19:28 - GraphTrainer - INFO - recall@5: 0.025645
2025-11-22 22:19:28 - GraphTrainer - INFO - hit_rate@5: 0.026382
2025-11-22 22:19:28 - GraphTrainer - INFO - ndcg@5: 0.016577
2025-11-22 22:19:28 - GraphTrainer - INFO - map@5: 0.013496
2025-11-22 22:19:28 - GraphTrainer - INFO - mrr@5: 0.013869
2025-11-22 22:19:28 - GraphTrainer - INFO - precision@10: 0.004274
2025-11-22 22:19:28 - GraphTrainer - INFO - recall@10: 0.040895
2025-11-22 22:19:28 - GraphTrainer - INFO - hit_rate@10: 0.042633
2025-11-22 22:19:28 - GraphTrainer - INFO - ndcg@10: 0.021546
2025-11-22 22:19:28 - GraphTrainer - INFO - map@10: 0.015503
2025-11-22 22:19:28 - GraphTrainer - INFO - mrr@10: 0.016003
2025-11-22 22:19:28 - GraphTrainer - INFO - precision@20: 0.003620
2025-11-22 22:19:28 - GraphTrainer - INFO - recall@20: 0.068696
2025-11-22 22:19:28 - GraphTrainer - INFO - hit_rate@20: 0.072049
2025-11-22 22:19:28 - GraphTrainer - INFO - ndcg@20: 0.028614
2025-11-22 22:19:28 - GraphTrainer - INFO - map@20: 0.017390
2025-11-22 22:19:28 - GraphTrainer - INFO - mrr@20: 0.017999
2025-11-22 22:19:28 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:19:28 - GraphTrainer - INFO - 检查点已保存: Epoch 40 -> ./checkpoints/checkpoint_epoch_40.pth
2025-11-22 22:19:28 - GraphTrainer - INFO - ============================================================
2025-11-22 22:19:28 - GraphTrainer - INFO - 开始第 41/1000 轮训练
2025-11-22 22:19:28 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4083, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4220, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4100, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4135, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4118, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4060, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4028, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4162, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4104, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3983, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4146, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3721, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3980, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4054, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4220, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4191, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3977, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4009, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4147, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4124, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4135, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3928, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4123, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4201, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4084, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4161, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4021, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4266, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4079, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4222, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4324, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4086, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4285, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4167, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4233, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4062, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4118, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4133, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4470, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4316, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4077, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3991, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4009, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4229, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4183, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3923, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4065, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4043, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4055, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4281, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4008, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4148, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3982, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4013, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4117, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4190, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4053, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4015, device='cuda:0', grad_fn=<AddBackward0>)
The 40 training average loss: 0.41096289353124027
2025-11-22 22:19:39 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:19:39 - GraphTrainer - INFO -   precision@5: 0.005318
2025-11-22 22:19:39 - GraphTrainer - INFO -   recall@5: 0.025800
2025-11-22 22:19:39 - GraphTrainer - INFO -   hit_rate@5: 0.026588
2025-11-22 22:19:39 - GraphTrainer - INFO -   ndcg@5: 0.016870
2025-11-22 22:19:39 - GraphTrainer - INFO -   map@5: 0.013823
2025-11-22 22:19:39 - GraphTrainer - INFO -   mrr@5: 0.014167
2025-11-22 22:19:39 - GraphTrainer - INFO -   precision@10: 0.004274
2025-11-22 22:19:39 - GraphTrainer - INFO -   recall@10: 0.040843
2025-11-22 22:19:39 - GraphTrainer - INFO -   hit_rate@10: 0.042684
2025-11-22 22:19:39 - GraphTrainer - INFO -   ndcg@10: 0.021768
2025-11-22 22:19:39 - GraphTrainer - INFO -   map@10: 0.015794
2025-11-22 22:19:39 - GraphTrainer - INFO -   mrr@10: 0.016279
2025-11-22 22:19:39 - GraphTrainer - INFO -   precision@20: 0.003620
2025-11-22 22:19:39 - GraphTrainer - INFO -   recall@20: 0.068797
2025-11-22 22:19:39 - GraphTrainer - INFO -   hit_rate@20: 0.071947
2025-11-22 22:19:39 - GraphTrainer - INFO -   ndcg@20: 0.028873
2025-11-22 22:19:39 - GraphTrainer - INFO -   map@20: 0.017703
2025-11-22 22:19:39 - GraphTrainer - INFO -   mrr@20: 0.018268
2025-11-22 22:19:39 - GraphTrainer - INFO - 第 41 轮训练完成
2025-11-22 22:19:39 - GraphTrainer - INFO - train_loss: 0.410284
2025-11-22 22:19:39 - GraphTrainer - INFO - precision@5: 0.005318
2025-11-22 22:19:39 - GraphTrainer - INFO - recall@5: 0.025800
2025-11-22 22:19:39 - GraphTrainer - INFO - hit_rate@5: 0.026588
2025-11-22 22:19:39 - GraphTrainer - INFO - ndcg@5: 0.016870
2025-11-22 22:19:39 - GraphTrainer - INFO - map@5: 0.013823
2025-11-22 22:19:39 - GraphTrainer - INFO - mrr@5: 0.014167
2025-11-22 22:19:39 - GraphTrainer - INFO - precision@10: 0.004274
2025-11-22 22:19:39 - GraphTrainer - INFO - recall@10: 0.040843
2025-11-22 22:19:39 - GraphTrainer - INFO - hit_rate@10: 0.042684
2025-11-22 22:19:39 - GraphTrainer - INFO - ndcg@10: 0.021768
2025-11-22 22:19:39 - GraphTrainer - INFO - map@10: 0.015794
2025-11-22 22:19:39 - GraphTrainer - INFO - mrr@10: 0.016279
2025-11-22 22:19:39 - GraphTrainer - INFO - precision@20: 0.003620
2025-11-22 22:19:39 - GraphTrainer - INFO - recall@20: 0.068797
2025-11-22 22:19:39 - GraphTrainer - INFO - hit_rate@20: 0.071947
2025-11-22 22:19:39 - GraphTrainer - INFO - ndcg@20: 0.028873
2025-11-22 22:19:39 - GraphTrainer - INFO - map@20: 0.017703
2025-11-22 22:19:39 - GraphTrainer - INFO - mrr@20: 0.018268
2025-11-22 22:19:39 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:19:39 - GraphTrainer - INFO - ============================================================
2025-11-22 22:19:39 - GraphTrainer - INFO - 开始第 42/1000 轮训练
2025-11-22 22:19:39 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3937, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3967, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4115, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3987, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3963, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4072, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4161, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4136, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4329, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4324, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4147, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4105, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3974, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4119, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4281, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3890, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4127, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4001, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4050, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4201, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4107, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4098, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3860, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4028, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4055, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4160, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4047, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4068, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4074, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4181, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4430, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4241, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4074, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4088, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4145, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4315, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4101, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4181, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4316, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4088, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3930, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4045, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3816, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4136, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4147, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4313, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4114, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4212, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4091, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4026, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4358, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3916, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4235, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4180, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4136, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4027, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4062, device='cuda:0', grad_fn=<AddBackward0>)
The 41 training average loss: 0.4102840156390749
2025-11-22 22:19:50 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:19:50 - GraphTrainer - INFO -   precision@5: 0.005266
2025-11-22 22:19:50 - GraphTrainer - INFO -   recall@5: 0.025015
2025-11-22 22:19:50 - GraphTrainer - INFO -   hit_rate@5: 0.026279
2025-11-22 22:19:50 - GraphTrainer - INFO -   ndcg@5: 0.016549
2025-11-22 22:19:50 - GraphTrainer - INFO -   map@5: 0.013558
2025-11-22 22:19:50 - GraphTrainer - INFO -   mrr@5: 0.014204
2025-11-22 22:19:50 - GraphTrainer - INFO -   precision@10: 0.004284
2025-11-22 22:19:50 - GraphTrainer - INFO -   recall@10: 0.040818
2025-11-22 22:19:50 - GraphTrainer - INFO -   hit_rate@10: 0.042787
2025-11-22 22:19:50 - GraphTrainer - INFO -   ndcg@10: 0.021657
2025-11-22 22:19:50 - GraphTrainer - INFO -   map@10: 0.015626
2025-11-22 22:19:50 - GraphTrainer - INFO -   mrr@10: 0.016365
2025-11-22 22:19:50 - GraphTrainer - INFO -   precision@20: 0.003610
2025-11-22 22:19:50 - GraphTrainer - INFO -   recall@20: 0.068778
2025-11-22 22:19:50 - GraphTrainer - INFO -   hit_rate@20: 0.071895
2025-11-22 22:19:50 - GraphTrainer - INFO -   ndcg@20: 0.028721
2025-11-22 22:19:50 - GraphTrainer - INFO -   map@20: 0.017509
2025-11-22 22:19:50 - GraphTrainer - INFO -   mrr@20: 0.018324
2025-11-22 22:19:50 - GraphTrainer - INFO - 第 42 轮训练完成
2025-11-22 22:19:50 - GraphTrainer - INFO - train_loss: 0.411978
2025-11-22 22:19:50 - GraphTrainer - INFO - precision@5: 0.005266
2025-11-22 22:19:50 - GraphTrainer - INFO - recall@5: 0.025015
2025-11-22 22:19:50 - GraphTrainer - INFO - hit_rate@5: 0.026279
2025-11-22 22:19:50 - GraphTrainer - INFO - ndcg@5: 0.016549
2025-11-22 22:19:50 - GraphTrainer - INFO - map@5: 0.013558
2025-11-22 22:19:50 - GraphTrainer - INFO - mrr@5: 0.014204
2025-11-22 22:19:50 - GraphTrainer - INFO - precision@10: 0.004284
2025-11-22 22:19:50 - GraphTrainer - INFO - recall@10: 0.040818
2025-11-22 22:19:50 - GraphTrainer - INFO - hit_rate@10: 0.042787
2025-11-22 22:19:50 - GraphTrainer - INFO - ndcg@10: 0.021657
2025-11-22 22:19:50 - GraphTrainer - INFO - map@10: 0.015626
2025-11-22 22:19:50 - GraphTrainer - INFO - mrr@10: 0.016365
2025-11-22 22:19:50 - GraphTrainer - INFO - precision@20: 0.003610
2025-11-22 22:19:50 - GraphTrainer - INFO - recall@20: 0.068778
2025-11-22 22:19:50 - GraphTrainer - INFO - hit_rate@20: 0.071895
2025-11-22 22:19:50 - GraphTrainer - INFO - ndcg@20: 0.028721
2025-11-22 22:19:50 - GraphTrainer - INFO - map@20: 0.017509
2025-11-22 22:19:50 - GraphTrainer - INFO - mrr@20: 0.018324
2025-11-22 22:19:50 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:19:50 - GraphTrainer - INFO - ============================================================
2025-11-22 22:19:50 - GraphTrainer - INFO - 开始第 43/1000 轮训练
2025-11-22 22:19:50 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4013, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4252, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4025, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4020, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4202, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4006, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4190, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4244, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4023, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4169, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4260, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4323, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4063, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4151, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3951, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3996, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4139, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3895, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4245, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3972, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4085, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4063, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4046, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4212, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4190, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3891, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4150, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4257, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4091, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4246, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4013, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3921, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3975, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4015, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4087, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4272, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4086, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4041, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4100, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4274, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4309, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3924, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4321, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4129, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4229, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4103, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4235, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4095, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3937, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4009, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4280, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4057, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4342, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4241, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4068, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4155, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4280, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4080, device='cuda:0', grad_fn=<AddBackward0>)
The 42 training average loss: 0.4119777869561623
2025-11-22 22:20:01 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:20:01 - GraphTrainer - INFO -   precision@5: 0.005081
2025-11-22 22:20:01 - GraphTrainer - INFO -   recall@5: 0.024248
2025-11-22 22:20:01 - GraphTrainer - INFO -   hit_rate@5: 0.025354
2025-11-22 22:20:01 - GraphTrainer - INFO -   ndcg@5: 0.015610
2025-11-22 22:20:01 - GraphTrainer - INFO -   map@5: 0.012604
2025-11-22 22:20:01 - GraphTrainer - INFO -   mrr@5: 0.013194
2025-11-22 22:20:01 - GraphTrainer - INFO -   precision@10: 0.004207
2025-11-22 22:20:01 - GraphTrainer - INFO -   recall@10: 0.039888
2025-11-22 22:20:01 - GraphTrainer - INFO -   hit_rate@10: 0.042016
2025-11-22 22:20:01 - GraphTrainer - INFO -   ndcg@10: 0.020647
2025-11-22 22:20:01 - GraphTrainer - INFO -   map@10: 0.014618
2025-11-22 22:20:01 - GraphTrainer - INFO -   mrr@10: 0.015345
2025-11-22 22:20:01 - GraphTrainer - INFO -   precision@20: 0.003538
2025-11-22 22:20:01 - GraphTrainer - INFO -   recall@20: 0.067138
2025-11-22 22:20:01 - GraphTrainer - INFO -   hit_rate@20: 0.070455
2025-11-22 22:20:01 - GraphTrainer - INFO -   ndcg@20: 0.027542
2025-11-22 22:20:01 - GraphTrainer - INFO -   map@20: 0.016458
2025-11-22 22:20:01 - GraphTrainer - INFO -   mrr@20: 0.017259
2025-11-22 22:20:01 - GraphTrainer - INFO - 第 43 轮训练完成
2025-11-22 22:20:01 - GraphTrainer - INFO - train_loss: 0.408433
2025-11-22 22:20:01 - GraphTrainer - INFO - precision@5: 0.005081
2025-11-22 22:20:01 - GraphTrainer - INFO - recall@5: 0.024248
2025-11-22 22:20:01 - GraphTrainer - INFO - hit_rate@5: 0.025354
2025-11-22 22:20:01 - GraphTrainer - INFO - ndcg@5: 0.015610
2025-11-22 22:20:01 - GraphTrainer - INFO - map@5: 0.012604
2025-11-22 22:20:01 - GraphTrainer - INFO - mrr@5: 0.013194
2025-11-22 22:20:01 - GraphTrainer - INFO - precision@10: 0.004207
2025-11-22 22:20:01 - GraphTrainer - INFO - recall@10: 0.039888
2025-11-22 22:20:01 - GraphTrainer - INFO - hit_rate@10: 0.042016
2025-11-22 22:20:01 - GraphTrainer - INFO - ndcg@10: 0.020647
2025-11-22 22:20:01 - GraphTrainer - INFO - map@10: 0.014618
2025-11-22 22:20:01 - GraphTrainer - INFO - mrr@10: 0.015345
2025-11-22 22:20:01 - GraphTrainer - INFO - precision@20: 0.003538
2025-11-22 22:20:01 - GraphTrainer - INFO - recall@20: 0.067138
2025-11-22 22:20:01 - GraphTrainer - INFO - hit_rate@20: 0.070455
2025-11-22 22:20:01 - GraphTrainer - INFO - ndcg@20: 0.027542
2025-11-22 22:20:01 - GraphTrainer - INFO - map@20: 0.016458
2025-11-22 22:20:01 - GraphTrainer - INFO - mrr@20: 0.017259
2025-11-22 22:20:01 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:20:01 - GraphTrainer - INFO - ============================================================
2025-11-22 22:20:01 - GraphTrainer - INFO - 开始第 44/1000 轮训练
2025-11-22 22:20:01 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3791, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4039, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4037, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3879, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4129, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4154, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3885, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4070, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4078, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4032, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4122, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4282, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4163, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4103, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4339, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4041, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4326, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4186, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4087, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4101, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4114, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4106, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3993, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4148, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4172, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4203, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3968, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4022, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4177, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3995, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3938, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3940, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3953, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3916, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4235, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4299, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4402, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3940, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4116, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3615, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4101, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3990, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4095, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4120, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4096, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4191, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4152, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4166, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4192, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4222, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3789, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4064, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3908, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4309, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4170, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3898, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4046, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4283, device='cuda:0', grad_fn=<AddBackward0>)
The 43 training average loss: 0.40843320715016335
2025-11-22 22:20:12 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:20:12 - GraphTrainer - INFO -   precision@5: 0.004958
2025-11-22 22:20:12 - GraphTrainer - INFO -   recall@5: 0.023470
2025-11-22 22:20:12 - GraphTrainer - INFO -   hit_rate@5: 0.024736
2025-11-22 22:20:12 - GraphTrainer - INFO -   ndcg@5: 0.015272
2025-11-22 22:20:12 - GraphTrainer - INFO -   map@5: 0.012387
2025-11-22 22:20:12 - GraphTrainer - INFO -   mrr@5: 0.012924
2025-11-22 22:20:12 - GraphTrainer - INFO -   precision@10: 0.004299
2025-11-22 22:20:12 - GraphTrainer - INFO -   recall@10: 0.040946
2025-11-22 22:20:12 - GraphTrainer - INFO -   hit_rate@10: 0.042942
2025-11-22 22:20:12 - GraphTrainer - INFO -   ndcg@10: 0.020915
2025-11-22 22:20:12 - GraphTrainer - INFO -   map@10: 0.014668
2025-11-22 22:20:12 - GraphTrainer - INFO -   mrr@10: 0.015298
2025-11-22 22:20:12 - GraphTrainer - INFO -   precision@20: 0.003518
2025-11-22 22:20:12 - GraphTrainer - INFO -   recall@20: 0.066865
2025-11-22 22:20:12 - GraphTrainer - INFO -   hit_rate@20: 0.070147
2025-11-22 22:20:12 - GraphTrainer - INFO -   ndcg@20: 0.027443
2025-11-22 22:20:12 - GraphTrainer - INFO -   map@20: 0.016391
2025-11-22 22:20:12 - GraphTrainer - INFO -   mrr@20: 0.017108
2025-11-22 22:20:12 - GraphTrainer - INFO - 第 44 轮训练完成
2025-11-22 22:20:12 - GraphTrainer - INFO - train_loss: 0.403304
2025-11-22 22:20:12 - GraphTrainer - INFO - precision@5: 0.004958
2025-11-22 22:20:12 - GraphTrainer - INFO - recall@5: 0.023470
2025-11-22 22:20:12 - GraphTrainer - INFO - hit_rate@5: 0.024736
2025-11-22 22:20:12 - GraphTrainer - INFO - ndcg@5: 0.015272
2025-11-22 22:20:12 - GraphTrainer - INFO - map@5: 0.012387
2025-11-22 22:20:12 - GraphTrainer - INFO - mrr@5: 0.012924
2025-11-22 22:20:12 - GraphTrainer - INFO - precision@10: 0.004299
2025-11-22 22:20:12 - GraphTrainer - INFO - recall@10: 0.040946
2025-11-22 22:20:12 - GraphTrainer - INFO - hit_rate@10: 0.042942
2025-11-22 22:20:12 - GraphTrainer - INFO - ndcg@10: 0.020915
2025-11-22 22:20:12 - GraphTrainer - INFO - map@10: 0.014668
2025-11-22 22:20:12 - GraphTrainer - INFO - mrr@10: 0.015298
2025-11-22 22:20:12 - GraphTrainer - INFO - precision@20: 0.003518
2025-11-22 22:20:12 - GraphTrainer - INFO - recall@20: 0.066865
2025-11-22 22:20:12 - GraphTrainer - INFO - hit_rate@20: 0.070147
2025-11-22 22:20:12 - GraphTrainer - INFO - ndcg@20: 0.027443
2025-11-22 22:20:12 - GraphTrainer - INFO - map@20: 0.016391
2025-11-22 22:20:12 - GraphTrainer - INFO - mrr@20: 0.017108
2025-11-22 22:20:12 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:20:12 - GraphTrainer - INFO - ============================================================
2025-11-22 22:20:12 - GraphTrainer - INFO - 开始第 45/1000 轮训练
2025-11-22 22:20:12 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4183, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4284, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4065, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3982, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4110, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3877, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3922, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4286, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3943, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3866, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3960, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3995, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3910, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3959, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3903, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4045, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4290, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3994, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4141, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3993, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4058, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4037, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4125, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4040, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3951, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3949, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3960, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3987, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3957, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4034, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3993, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4019, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4143, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3862, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4118, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4057, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4054, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4072, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3970, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4032, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4178, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4115, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3940, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4148, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4082, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4229, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4147, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3710, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4058, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4094, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3924, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4094, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3967, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4041, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3959, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4123, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3977, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4004, device='cuda:0', grad_fn=<AddBackward0>)
The 44 training average loss: 0.40330364889112014
2025-11-22 22:20:23 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:20:23 - GraphTrainer - INFO -   precision@5: 0.005441
2025-11-22 22:20:23 - GraphTrainer - INFO -   recall@5: 0.025990
2025-11-22 22:20:23 - GraphTrainer - INFO -   hit_rate@5: 0.027154
2025-11-22 22:20:23 - GraphTrainer - INFO -   ndcg@5: 0.016703
2025-11-22 22:20:23 - GraphTrainer - INFO -   map@5: 0.013444
2025-11-22 22:20:23 - GraphTrainer - INFO -   mrr@5: 0.014066
2025-11-22 22:20:23 - GraphTrainer - INFO -   precision@10: 0.004474
2025-11-22 22:20:23 - GraphTrainer - INFO -   recall@10: 0.042483
2025-11-22 22:20:23 - GraphTrainer - INFO -   hit_rate@10: 0.044639
2025-11-22 22:20:23 - GraphTrainer - INFO -   ndcg@10: 0.022044
2025-11-22 22:20:23 - GraphTrainer - INFO -   map@10: 0.015591
2025-11-22 22:20:23 - GraphTrainer - INFO -   mrr@10: 0.016343
2025-11-22 22:20:23 - GraphTrainer - INFO -   precision@20: 0.003497
2025-11-22 22:20:23 - GraphTrainer - INFO -   recall@20: 0.066405
2025-11-22 22:20:23 - GraphTrainer - INFO -   hit_rate@20: 0.069581
2025-11-22 22:20:23 - GraphTrainer - INFO -   ndcg@20: 0.028112
2025-11-22 22:20:23 - GraphTrainer - INFO -   map@20: 0.017222
2025-11-22 22:20:23 - GraphTrainer - INFO -   mrr@20: 0.018033
2025-11-22 22:20:23 - GraphTrainer - INFO - 第 45 轮训练完成
2025-11-22 22:20:23 - GraphTrainer - INFO - train_loss: 0.408623
2025-11-22 22:20:23 - GraphTrainer - INFO - precision@5: 0.005441
2025-11-22 22:20:23 - GraphTrainer - INFO - recall@5: 0.025990
2025-11-22 22:20:23 - GraphTrainer - INFO - hit_rate@5: 0.027154
2025-11-22 22:20:23 - GraphTrainer - INFO - ndcg@5: 0.016703
2025-11-22 22:20:23 - GraphTrainer - INFO - map@5: 0.013444
2025-11-22 22:20:23 - GraphTrainer - INFO - mrr@5: 0.014066
2025-11-22 22:20:23 - GraphTrainer - INFO - precision@10: 0.004474
2025-11-22 22:20:23 - GraphTrainer - INFO - recall@10: 0.042483
2025-11-22 22:20:23 - GraphTrainer - INFO - hit_rate@10: 0.044639
2025-11-22 22:20:23 - GraphTrainer - INFO - ndcg@10: 0.022044
2025-11-22 22:20:23 - GraphTrainer - INFO - map@10: 0.015591
2025-11-22 22:20:23 - GraphTrainer - INFO - mrr@10: 0.016343
2025-11-22 22:20:23 - GraphTrainer - INFO - precision@20: 0.003497
2025-11-22 22:20:23 - GraphTrainer - INFO - recall@20: 0.066405
2025-11-22 22:20:23 - GraphTrainer - INFO - hit_rate@20: 0.069581
2025-11-22 22:20:23 - GraphTrainer - INFO - ndcg@20: 0.028112
2025-11-22 22:20:23 - GraphTrainer - INFO - map@20: 0.017222
2025-11-22 22:20:23 - GraphTrainer - INFO - mrr@20: 0.018033
2025-11-22 22:20:23 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:20:23 - GraphTrainer - INFO - ============================================================
2025-11-22 22:20:23 - GraphTrainer - INFO - 开始第 46/1000 轮训练
2025-11-22 22:20:23 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3870, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4230, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3970, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4313, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4121, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3980, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3984, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3979, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3924, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4142, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4069, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4276, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3901, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3874, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3804, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3998, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4397, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3966, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4045, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4019, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4306, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4286, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4187, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4063, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4313, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4029, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4099, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3750, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3994, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4037, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4092, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4159, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3958, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4166, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4245, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3990, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3902, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4021, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4196, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3899, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4117, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3950, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4002, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4025, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4126, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4237, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4094, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4158, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4102, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4048, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4144, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4368, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4050, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4273, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4237, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4202, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4099, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4217, device='cuda:0', grad_fn=<AddBackward0>)
The 45 training average loss: 0.40862346312095377
2025-11-22 22:20:34 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:20:34 - GraphTrainer - INFO -   precision@5: 0.005606
2025-11-22 22:20:34 - GraphTrainer - INFO -   recall@5: 0.026903
2025-11-22 22:20:34 - GraphTrainer - INFO -   hit_rate@5: 0.027976
2025-11-22 22:20:34 - GraphTrainer - INFO -   ndcg@5: 0.017714
2025-11-22 22:20:34 - GraphTrainer - INFO -   map@5: 0.014523
2025-11-22 22:20:34 - GraphTrainer - INFO -   mrr@5: 0.015025
2025-11-22 22:20:34 - GraphTrainer - INFO -   precision@10: 0.004618
2025-11-22 22:20:34 - GraphTrainer - INFO -   recall@10: 0.043836
2025-11-22 22:20:34 - GraphTrainer - INFO -   hit_rate@10: 0.046079
2025-11-22 22:20:34 - GraphTrainer - INFO -   ndcg@10: 0.023190
2025-11-22 22:20:34 - GraphTrainer - INFO -   map@10: 0.016711
2025-11-22 22:20:34 - GraphTrainer - INFO -   mrr@10: 0.017366
2025-11-22 22:20:34 - GraphTrainer - INFO -   precision@20: 0.003618
2025-11-22 22:20:34 - GraphTrainer - INFO -   recall@20: 0.068565
2025-11-22 22:20:34 - GraphTrainer - INFO -   hit_rate@20: 0.071947
2025-11-22 22:20:34 - GraphTrainer - INFO -   ndcg@20: 0.029465
2025-11-22 22:20:34 - GraphTrainer - INFO -   map@20: 0.018389
2025-11-22 22:20:34 - GraphTrainer - INFO -   mrr@20: 0.019118
2025-11-22 22:20:34 - GraphTrainer - INFO - 第 46 轮训练完成
2025-11-22 22:20:34 - GraphTrainer - INFO - train_loss: 0.406608
2025-11-22 22:20:34 - GraphTrainer - INFO - precision@5: 0.005606
2025-11-22 22:20:34 - GraphTrainer - INFO - recall@5: 0.026903
2025-11-22 22:20:34 - GraphTrainer - INFO - hit_rate@5: 0.027976
2025-11-22 22:20:34 - GraphTrainer - INFO - ndcg@5: 0.017714
2025-11-22 22:20:34 - GraphTrainer - INFO - map@5: 0.014523
2025-11-22 22:20:34 - GraphTrainer - INFO - mrr@5: 0.015025
2025-11-22 22:20:34 - GraphTrainer - INFO - precision@10: 0.004618
2025-11-22 22:20:34 - GraphTrainer - INFO - recall@10: 0.043836
2025-11-22 22:20:34 - GraphTrainer - INFO - hit_rate@10: 0.046079
2025-11-22 22:20:34 - GraphTrainer - INFO - ndcg@10: 0.023190
2025-11-22 22:20:34 - GraphTrainer - INFO - map@10: 0.016711
2025-11-22 22:20:34 - GraphTrainer - INFO - mrr@10: 0.017366
2025-11-22 22:20:34 - GraphTrainer - INFO - precision@20: 0.003618
2025-11-22 22:20:34 - GraphTrainer - INFO - recall@20: 0.068565
2025-11-22 22:20:34 - GraphTrainer - INFO - hit_rate@20: 0.071947
2025-11-22 22:20:34 - GraphTrainer - INFO - ndcg@20: 0.029465
2025-11-22 22:20:34 - GraphTrainer - INFO - map@20: 0.018389
2025-11-22 22:20:34 - GraphTrainer - INFO - mrr@20: 0.019118
2025-11-22 22:20:34 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:20:34 - GraphTrainer - INFO - ============================================================
2025-11-22 22:20:34 - GraphTrainer - INFO - 开始第 47/1000 轮训练
2025-11-22 22:20:34 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4174, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4327, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3751, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4141, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4086, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4223, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4147, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3996, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3951, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4347, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4256, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3990, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4315, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4175, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3994, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4038, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3859, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4072, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4127, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4079, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4020, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3874, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4039, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3968, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3929, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4035, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3964, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4188, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4079, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4150, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4073, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4092, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3953, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4068, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4322, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4068, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4057, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4179, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4159, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4174, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4025, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3998, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4161, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4012, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4139, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3896, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4069, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3876, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4281, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3837, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4020, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4011, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3921, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4120, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4116, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4006, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3846, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4061, device='cuda:0', grad_fn=<AddBackward0>)
The 46 training average loss: 0.4066077398842779
2025-11-22 22:20:45 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:20:45 - GraphTrainer - INFO -   precision@5: 0.005235
2025-11-22 22:20:45 - GraphTrainer - INFO -   recall@5: 0.024867
2025-11-22 22:20:45 - GraphTrainer - INFO -   hit_rate@5: 0.026125
2025-11-22 22:20:45 - GraphTrainer - INFO -   ndcg@5: 0.016627
2025-11-22 22:20:45 - GraphTrainer - INFO -   map@5: 0.013718
2025-11-22 22:20:45 - GraphTrainer - INFO -   mrr@5: 0.014331
2025-11-22 22:20:45 - GraphTrainer - INFO -   precision@10: 0.004572
2025-11-22 22:20:45 - GraphTrainer - INFO -   recall@10: 0.043266
2025-11-22 22:20:45 - GraphTrainer - INFO -   hit_rate@10: 0.045564
2025-11-22 22:20:45 - GraphTrainer - INFO -   ndcg@10: 0.022640
2025-11-22 22:20:45 - GraphTrainer - INFO -   map@10: 0.016172
2025-11-22 22:20:45 - GraphTrainer - INFO -   mrr@10: 0.016921
2025-11-22 22:20:45 - GraphTrainer - INFO -   precision@20: 0.003638
2025-11-22 22:20:45 - GraphTrainer - INFO -   recall@20: 0.068484
2025-11-22 22:20:45 - GraphTrainer - INFO -   hit_rate@20: 0.072204
2025-11-22 22:20:45 - GraphTrainer - INFO -   ndcg@20: 0.029069
2025-11-22 22:20:45 - GraphTrainer - INFO -   map@20: 0.017896
2025-11-22 22:20:45 - GraphTrainer - INFO -   mrr@20: 0.018736
2025-11-22 22:20:45 - GraphTrainer - INFO - 第 47 轮训练完成
2025-11-22 22:20:45 - GraphTrainer - INFO - train_loss: 0.402952
2025-11-22 22:20:45 - GraphTrainer - INFO - precision@5: 0.005235
2025-11-22 22:20:45 - GraphTrainer - INFO - recall@5: 0.024867
2025-11-22 22:20:45 - GraphTrainer - INFO - hit_rate@5: 0.026125
2025-11-22 22:20:45 - GraphTrainer - INFO - ndcg@5: 0.016627
2025-11-22 22:20:45 - GraphTrainer - INFO - map@5: 0.013718
2025-11-22 22:20:45 - GraphTrainer - INFO - mrr@5: 0.014331
2025-11-22 22:20:45 - GraphTrainer - INFO - precision@10: 0.004572
2025-11-22 22:20:45 - GraphTrainer - INFO - recall@10: 0.043266
2025-11-22 22:20:45 - GraphTrainer - INFO - hit_rate@10: 0.045564
2025-11-22 22:20:45 - GraphTrainer - INFO - ndcg@10: 0.022640
2025-11-22 22:20:45 - GraphTrainer - INFO - map@10: 0.016172
2025-11-22 22:20:45 - GraphTrainer - INFO - mrr@10: 0.016921
2025-11-22 22:20:45 - GraphTrainer - INFO - precision@20: 0.003638
2025-11-22 22:20:45 - GraphTrainer - INFO - recall@20: 0.068484
2025-11-22 22:20:45 - GraphTrainer - INFO - hit_rate@20: 0.072204
2025-11-22 22:20:45 - GraphTrainer - INFO - ndcg@20: 0.029069
2025-11-22 22:20:45 - GraphTrainer - INFO - map@20: 0.017896
2025-11-22 22:20:45 - GraphTrainer - INFO - mrr@20: 0.018736
2025-11-22 22:20:45 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:20:45 - GraphTrainer - INFO - ============================================================
2025-11-22 22:20:45 - GraphTrainer - INFO - 开始第 48/1000 轮训练
2025-11-22 22:20:45 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3888, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3889, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3972, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4168, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3909, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4058, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4109, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3855, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3941, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4047, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4179, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4233, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3748, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4104, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3774, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4009, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4073, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4234, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4002, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3964, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3923, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4293, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4088, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4017, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4047, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4035, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4116, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3967, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4024, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3806, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4045, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3981, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3781, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4240, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4012, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4033, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4058, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3984, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4137, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4033, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4080, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4053, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4042, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3888, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4202, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3935, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4128, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4248, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4066, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3909, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4152, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3889, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4056, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3962, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4114, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4142, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4194, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3878, device='cuda:0', grad_fn=<AddBackward0>)
The 47 training average loss: 0.40295203800859125
2025-11-22 22:20:56 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:20:56 - GraphTrainer - INFO -   precision@5: 0.005410
2025-11-22 22:20:56 - GraphTrainer - INFO -   recall@5: 0.025737
2025-11-22 22:20:56 - GraphTrainer - INFO -   hit_rate@5: 0.026999
2025-11-22 22:20:56 - GraphTrainer - INFO -   ndcg@5: 0.017053
2025-11-22 22:20:56 - GraphTrainer - INFO -   map@5: 0.013994
2025-11-22 22:20:56 - GraphTrainer - INFO -   mrr@5: 0.014612
2025-11-22 22:20:56 - GraphTrainer - INFO -   precision@10: 0.004556
2025-11-22 22:20:56 - GraphTrainer - INFO -   recall@10: 0.043426
2025-11-22 22:20:56 - GraphTrainer - INFO -   hit_rate@10: 0.045513
2025-11-22 22:20:56 - GraphTrainer - INFO -   ndcg@10: 0.022792
2025-11-22 22:20:56 - GraphTrainer - INFO -   map@10: 0.016323
2025-11-22 22:20:56 - GraphTrainer - INFO -   mrr@10: 0.017058
2025-11-22 22:20:56 - GraphTrainer - INFO -   precision@20: 0.003680
2025-11-22 22:20:56 - GraphTrainer - INFO -   recall@20: 0.069532
2025-11-22 22:20:56 - GraphTrainer - INFO -   hit_rate@20: 0.073078
2025-11-22 22:20:56 - GraphTrainer - INFO -   ndcg@20: 0.029445
2025-11-22 22:20:56 - GraphTrainer - INFO -   map@20: 0.018106
2025-11-22 22:20:56 - GraphTrainer - INFO -   mrr@20: 0.018934
2025-11-22 22:20:56 - GraphTrainer - INFO - 第 48 轮训练完成
2025-11-22 22:20:56 - GraphTrainer - INFO - train_loss: 0.401452
2025-11-22 22:20:56 - GraphTrainer - INFO - precision@5: 0.005410
2025-11-22 22:20:56 - GraphTrainer - INFO - recall@5: 0.025737
2025-11-22 22:20:56 - GraphTrainer - INFO - hit_rate@5: 0.026999
2025-11-22 22:20:56 - GraphTrainer - INFO - ndcg@5: 0.017053
2025-11-22 22:20:56 - GraphTrainer - INFO - map@5: 0.013994
2025-11-22 22:20:56 - GraphTrainer - INFO - mrr@5: 0.014612
2025-11-22 22:20:56 - GraphTrainer - INFO - precision@10: 0.004556
2025-11-22 22:20:56 - GraphTrainer - INFO - recall@10: 0.043426
2025-11-22 22:20:56 - GraphTrainer - INFO - hit_rate@10: 0.045513
2025-11-22 22:20:56 - GraphTrainer - INFO - ndcg@10: 0.022792
2025-11-22 22:20:56 - GraphTrainer - INFO - map@10: 0.016323
2025-11-22 22:20:56 - GraphTrainer - INFO - mrr@10: 0.017058
2025-11-22 22:20:56 - GraphTrainer - INFO - precision@20: 0.003680
2025-11-22 22:20:56 - GraphTrainer - INFO - recall@20: 0.069532
2025-11-22 22:20:56 - GraphTrainer - INFO - hit_rate@20: 0.073078
2025-11-22 22:20:56 - GraphTrainer - INFO - ndcg@20: 0.029445
2025-11-22 22:20:56 - GraphTrainer - INFO - map@20: 0.018106
2025-11-22 22:20:56 - GraphTrainer - INFO - mrr@20: 0.018934
2025-11-22 22:20:56 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:20:56 - GraphTrainer - INFO - ============================================================
2025-11-22 22:20:56 - GraphTrainer - INFO - 开始第 49/1000 轮训练
2025-11-22 22:20:56 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4185, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3933, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4136, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4077, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4013, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3872, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4304, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3903, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4181, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4031, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3922, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4031, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4123, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4112, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4195, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3983, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4102, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4068, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4169, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4118, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4029, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3869, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3815, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4118, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4008, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3955, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4081, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3854, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4001, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3885, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3961, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4004, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3891, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3933, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4166, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4056, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4094, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3838, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3983, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4168, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4081, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4104, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3959, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3990, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4042, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4148, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3869, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4133, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4006, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3918, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3805, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4027, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3862, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3879, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3924, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3882, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3830, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4216, device='cuda:0', grad_fn=<AddBackward0>)
The 48 training average loss: 0.4014515260170246
2025-11-22 22:21:08 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:21:08 - GraphTrainer - INFO -   precision@5: 0.005482
2025-11-22 22:21:08 - GraphTrainer - INFO -   recall@5: 0.026144
2025-11-22 22:21:08 - GraphTrainer - INFO -   hit_rate@5: 0.027359
2025-11-22 22:21:08 - GraphTrainer - INFO -   ndcg@5: 0.017487
2025-11-22 22:21:08 - GraphTrainer - INFO -   map@5: 0.014429
2025-11-22 22:21:08 - GraphTrainer - INFO -   mrr@5: 0.015096
2025-11-22 22:21:08 - GraphTrainer - INFO -   precision@10: 0.004592
2025-11-22 22:21:08 - GraphTrainer - INFO -   recall@10: 0.043649
2025-11-22 22:21:08 - GraphTrainer - INFO -   hit_rate@10: 0.045873
2025-11-22 22:21:08 - GraphTrainer - INFO -   ndcg@10: 0.023159
2025-11-22 22:21:08 - GraphTrainer - INFO -   map@10: 0.016717
2025-11-22 22:21:08 - GraphTrainer - INFO -   mrr@10: 0.017513
2025-11-22 22:21:08 - GraphTrainer - INFO -   precision@20: 0.003659
2025-11-22 22:21:08 - GraphTrainer - INFO -   recall@20: 0.069106
2025-11-22 22:21:08 - GraphTrainer - INFO -   hit_rate@20: 0.072718
2025-11-22 22:21:08 - GraphTrainer - INFO -   ndcg@20: 0.029658
2025-11-22 22:21:08 - GraphTrainer - INFO -   map@20: 0.018468
2025-11-22 22:21:08 - GraphTrainer - INFO -   mrr@20: 0.019349
2025-11-22 22:21:08 - GraphTrainer - INFO - 第 49 轮训练完成
2025-11-22 22:21:08 - GraphTrainer - INFO - train_loss: 0.403035
2025-11-22 22:21:08 - GraphTrainer - INFO - precision@5: 0.005482
2025-11-22 22:21:08 - GraphTrainer - INFO - recall@5: 0.026144
2025-11-22 22:21:08 - GraphTrainer - INFO - hit_rate@5: 0.027359
2025-11-22 22:21:08 - GraphTrainer - INFO - ndcg@5: 0.017487
2025-11-22 22:21:08 - GraphTrainer - INFO - map@5: 0.014429
2025-11-22 22:21:08 - GraphTrainer - INFO - mrr@5: 0.015096
2025-11-22 22:21:08 - GraphTrainer - INFO - precision@10: 0.004592
2025-11-22 22:21:08 - GraphTrainer - INFO - recall@10: 0.043649
2025-11-22 22:21:08 - GraphTrainer - INFO - hit_rate@10: 0.045873
2025-11-22 22:21:08 - GraphTrainer - INFO - ndcg@10: 0.023159
2025-11-22 22:21:08 - GraphTrainer - INFO - map@10: 0.016717
2025-11-22 22:21:08 - GraphTrainer - INFO - mrr@10: 0.017513
2025-11-22 22:21:08 - GraphTrainer - INFO - precision@20: 0.003659
2025-11-22 22:21:08 - GraphTrainer - INFO - recall@20: 0.069106
2025-11-22 22:21:08 - GraphTrainer - INFO - hit_rate@20: 0.072718
2025-11-22 22:21:08 - GraphTrainer - INFO - ndcg@20: 0.029658
2025-11-22 22:21:08 - GraphTrainer - INFO - map@20: 0.018468
2025-11-22 22:21:08 - GraphTrainer - INFO - mrr@20: 0.019349
2025-11-22 22:21:08 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:21:08 - GraphTrainer - INFO - ============================================================
2025-11-22 22:21:08 - GraphTrainer - INFO - 开始第 50/1000 轮训练
2025-11-22 22:21:08 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3951, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4119, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4118, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4173, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4123, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4014, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3932, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3804, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4085, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3893, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3857, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4085, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3857, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4099, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4089, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4051, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3963, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4180, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4044, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4089, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4155, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4181, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4002, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4032, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3982, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3968, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4048, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4037, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4055, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3949, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4214, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4089, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4091, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4147, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3941, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3787, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3905, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3957, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3925, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4143, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4052, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3933, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4002, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4072, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4196, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4082, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3907, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4278, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4029, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4118, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3968, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4092, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3803, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4219, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4031, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3834, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4173, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3841, device='cuda:0', grad_fn=<AddBackward0>)
The 49 training average loss: 0.4030354541951212
2025-11-22 22:21:19 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:21:19 - GraphTrainer - INFO -   precision@5: 0.005369
2025-11-22 22:21:19 - GraphTrainer - INFO -   recall@5: 0.025568
2025-11-22 22:21:19 - GraphTrainer - INFO -   hit_rate@5: 0.026691
2025-11-22 22:21:19 - GraphTrainer - INFO -   ndcg@5: 0.016394
2025-11-22 22:21:19 - GraphTrainer - INFO -   map@5: 0.013181
2025-11-22 22:21:19 - GraphTrainer - INFO -   mrr@5: 0.013750
2025-11-22 22:21:19 - GraphTrainer - INFO -   precision@10: 0.004418
2025-11-22 22:21:19 - GraphTrainer - INFO -   recall@10: 0.041899
2025-11-22 22:21:19 - GraphTrainer - INFO -   hit_rate@10: 0.044022
2025-11-22 22:21:19 - GraphTrainer - INFO -   ndcg@10: 0.021692
2025-11-22 22:21:19 - GraphTrainer - INFO -   map@10: 0.015318
2025-11-22 22:21:19 - GraphTrainer - INFO -   mrr@10: 0.016023
2025-11-22 22:21:19 - GraphTrainer - INFO -   precision@20: 0.003623
2025-11-22 22:21:19 - GraphTrainer - INFO -   recall@20: 0.068778
2025-11-22 22:21:19 - GraphTrainer - INFO -   hit_rate@20: 0.072101
2025-11-22 22:21:19 - GraphTrainer - INFO -   ndcg@20: 0.028501
2025-11-22 22:21:19 - GraphTrainer - INFO -   map@20: 0.017142
2025-11-22 22:21:19 - GraphTrainer - INFO -   mrr@20: 0.017922
2025-11-22 22:21:19 - GraphTrainer - INFO - 第 50 轮训练完成
2025-11-22 22:21:19 - GraphTrainer - INFO - train_loss: 0.401350
2025-11-22 22:21:19 - GraphTrainer - INFO - precision@5: 0.005369
2025-11-22 22:21:19 - GraphTrainer - INFO - recall@5: 0.025568
2025-11-22 22:21:19 - GraphTrainer - INFO - hit_rate@5: 0.026691
2025-11-22 22:21:19 - GraphTrainer - INFO - ndcg@5: 0.016394
2025-11-22 22:21:19 - GraphTrainer - INFO - map@5: 0.013181
2025-11-22 22:21:19 - GraphTrainer - INFO - mrr@5: 0.013750
2025-11-22 22:21:19 - GraphTrainer - INFO - precision@10: 0.004418
2025-11-22 22:21:19 - GraphTrainer - INFO - recall@10: 0.041899
2025-11-22 22:21:19 - GraphTrainer - INFO - hit_rate@10: 0.044022
2025-11-22 22:21:19 - GraphTrainer - INFO - ndcg@10: 0.021692
2025-11-22 22:21:19 - GraphTrainer - INFO - map@10: 0.015318
2025-11-22 22:21:19 - GraphTrainer - INFO - mrr@10: 0.016023
2025-11-22 22:21:19 - GraphTrainer - INFO - precision@20: 0.003623
2025-11-22 22:21:19 - GraphTrainer - INFO - recall@20: 0.068778
2025-11-22 22:21:19 - GraphTrainer - INFO - hit_rate@20: 0.072101
2025-11-22 22:21:19 - GraphTrainer - INFO - ndcg@20: 0.028501
2025-11-22 22:21:19 - GraphTrainer - INFO - map@20: 0.017142
2025-11-22 22:21:19 - GraphTrainer - INFO - mrr@20: 0.017922
2025-11-22 22:21:19 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:21:19 - GraphTrainer - INFO - 检查点已保存: Epoch 50 -> ./checkpoints/checkpoint_epoch_50.pth
2025-11-22 22:21:19 - GraphTrainer - INFO - ============================================================
2025-11-22 22:21:19 - GraphTrainer - INFO - 开始第 51/1000 轮训练
2025-11-22 22:21:19 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3947, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4078, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4031, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3871, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4082, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4007, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3692, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4152, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4246, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3938, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4211, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3938, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3974, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3976, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3942, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4023, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3949, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4097, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3952, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3974, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3840, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3945, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3971, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4220, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4041, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4039, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4173, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4199, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3971, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4115, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4081, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3969, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3997, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3883, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3975, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3877, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4046, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4198, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3795, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3800, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4021, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4083, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4139, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4010, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4013, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3791, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4046, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4223, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3944, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3976, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4043, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3969, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3925, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3937, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4059, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4091, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4290, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4006, device='cuda:0', grad_fn=<AddBackward0>)
The 50 training average loss: 0.40135048997813255
2025-11-22 22:21:30 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:21:30 - GraphTrainer - INFO -   precision@5: 0.005667
2025-11-22 22:21:30 - GraphTrainer - INFO -   recall@5: 0.026976
2025-11-22 22:21:30 - GraphTrainer - INFO -   hit_rate@5: 0.028285
2025-11-22 22:21:30 - GraphTrainer - INFO -   ndcg@5: 0.018169
2025-11-22 22:21:30 - GraphTrainer - INFO -   map@5: 0.015038
2025-11-22 22:21:30 - GraphTrainer - INFO -   mrr@5: 0.015743
2025-11-22 22:21:30 - GraphTrainer - INFO -   precision@10: 0.004536
2025-11-22 22:21:30 - GraphTrainer - INFO -   recall@10: 0.043206
2025-11-22 22:21:30 - GraphTrainer - INFO -   hit_rate@10: 0.045153
2025-11-22 22:21:30 - GraphTrainer - INFO -   ndcg@10: 0.023402
2025-11-22 22:21:30 - GraphTrainer - INFO -   map@10: 0.017154
2025-11-22 22:21:30 - GraphTrainer - INFO -   mrr@10: 0.017934
2025-11-22 22:21:30 - GraphTrainer - INFO -   precision@20: 0.003649
2025-11-22 22:21:30 - GraphTrainer - INFO -   recall@20: 0.069159
2025-11-22 22:21:30 - GraphTrainer - INFO -   hit_rate@20: 0.072718
2025-11-22 22:21:30 - GraphTrainer - INFO -   ndcg@20: 0.029984
2025-11-22 22:21:30 - GraphTrainer - INFO -   map@20: 0.018904
2025-11-22 22:21:30 - GraphTrainer - INFO -   mrr@20: 0.019790
2025-11-22 22:21:30 - GraphTrainer - INFO - 第 51 轮训练完成
2025-11-22 22:21:30 - GraphTrainer - INFO - train_loss: 0.397163
2025-11-22 22:21:30 - GraphTrainer - INFO - precision@5: 0.005667
2025-11-22 22:21:30 - GraphTrainer - INFO - recall@5: 0.026976
2025-11-22 22:21:30 - GraphTrainer - INFO - hit_rate@5: 0.028285
2025-11-22 22:21:30 - GraphTrainer - INFO - ndcg@5: 0.018169
2025-11-22 22:21:30 - GraphTrainer - INFO - map@5: 0.015038
2025-11-22 22:21:30 - GraphTrainer - INFO - mrr@5: 0.015743
2025-11-22 22:21:30 - GraphTrainer - INFO - precision@10: 0.004536
2025-11-22 22:21:30 - GraphTrainer - INFO - recall@10: 0.043206
2025-11-22 22:21:30 - GraphTrainer - INFO - hit_rate@10: 0.045153
2025-11-22 22:21:30 - GraphTrainer - INFO - ndcg@10: 0.023402
2025-11-22 22:21:30 - GraphTrainer - INFO - map@10: 0.017154
2025-11-22 22:21:30 - GraphTrainer - INFO - mrr@10: 0.017934
2025-11-22 22:21:30 - GraphTrainer - INFO - precision@20: 0.003649
2025-11-22 22:21:30 - GraphTrainer - INFO - recall@20: 0.069159
2025-11-22 22:21:30 - GraphTrainer - INFO - hit_rate@20: 0.072718
2025-11-22 22:21:30 - GraphTrainer - INFO - ndcg@20: 0.029984
2025-11-22 22:21:30 - GraphTrainer - INFO - map@20: 0.018904
2025-11-22 22:21:30 - GraphTrainer - INFO - mrr@20: 0.019790
2025-11-22 22:21:30 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:21:30 - GraphTrainer - INFO - ============================================================
2025-11-22 22:21:30 - GraphTrainer - INFO - 开始第 52/1000 轮训练
2025-11-22 22:21:30 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3995, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3947, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3956, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4132, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4265, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4037, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4019, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3733, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3754, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4051, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3977, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3862, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3944, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3768, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4016, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3981, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3973, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3964, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4055, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3915, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4283, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4097, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4012, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4006, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3974, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4002, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4312, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3862, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4081, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4343, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3967, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3997, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4142, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3971, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3948, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4217, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3759, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3832, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3802, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3967, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4150, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4006, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3887, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3714, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3574, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3749, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3819, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3876, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4014, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4117, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4048, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3848, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3991, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4024, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4042, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3962, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3814, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3801, device='cuda:0', grad_fn=<AddBackward0>)
The 51 training average loss: 0.39716337621212006
2025-11-22 22:21:41 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:21:41 - GraphTrainer - INFO -   precision@5: 0.005595
2025-11-22 22:21:41 - GraphTrainer - INFO -   recall@5: 0.026436
2025-11-22 22:21:41 - GraphTrainer - INFO -   hit_rate@5: 0.027925
2025-11-22 22:21:41 - GraphTrainer - INFO -   ndcg@5: 0.017409
2025-11-22 22:21:41 - GraphTrainer - INFO -   map@5: 0.014192
2025-11-22 22:21:41 - GraphTrainer - INFO -   mrr@5: 0.014915
2025-11-22 22:21:41 - GraphTrainer - INFO -   precision@10: 0.004618
2025-11-22 22:21:41 - GraphTrainer - INFO -   recall@10: 0.043541
2025-11-22 22:21:41 - GraphTrainer - INFO -   hit_rate@10: 0.045976
2025-11-22 22:21:41 - GraphTrainer - INFO -   ndcg@10: 0.022933
2025-11-22 22:21:41 - GraphTrainer - INFO -   map@10: 0.016409
2025-11-22 22:21:41 - GraphTrainer - INFO -   mrr@10: 0.017252
2025-11-22 22:21:41 - GraphTrainer - INFO -   precision@20: 0.003662
2025-11-22 22:21:41 - GraphTrainer - INFO -   recall@20: 0.069290
2025-11-22 22:21:41 - GraphTrainer - INFO -   hit_rate@20: 0.072821
2025-11-22 22:21:41 - GraphTrainer - INFO -   ndcg@20: 0.029447
2025-11-22 22:21:41 - GraphTrainer - INFO -   map@20: 0.018151
2025-11-22 22:21:41 - GraphTrainer - INFO -   mrr@20: 0.019065
2025-11-22 22:21:41 - GraphTrainer - INFO - 第 52 轮训练完成
2025-11-22 22:21:41 - GraphTrainer - INFO - train_loss: 0.396027
2025-11-22 22:21:41 - GraphTrainer - INFO - precision@5: 0.005595
2025-11-22 22:21:41 - GraphTrainer - INFO - recall@5: 0.026436
2025-11-22 22:21:41 - GraphTrainer - INFO - hit_rate@5: 0.027925
2025-11-22 22:21:41 - GraphTrainer - INFO - ndcg@5: 0.017409
2025-11-22 22:21:41 - GraphTrainer - INFO - map@5: 0.014192
2025-11-22 22:21:41 - GraphTrainer - INFO - mrr@5: 0.014915
2025-11-22 22:21:41 - GraphTrainer - INFO - precision@10: 0.004618
2025-11-22 22:21:41 - GraphTrainer - INFO - recall@10: 0.043541
2025-11-22 22:21:41 - GraphTrainer - INFO - hit_rate@10: 0.045976
2025-11-22 22:21:41 - GraphTrainer - INFO - ndcg@10: 0.022933
2025-11-22 22:21:41 - GraphTrainer - INFO - map@10: 0.016409
2025-11-22 22:21:41 - GraphTrainer - INFO - mrr@10: 0.017252
2025-11-22 22:21:41 - GraphTrainer - INFO - precision@20: 0.003662
2025-11-22 22:21:41 - GraphTrainer - INFO - recall@20: 0.069290
2025-11-22 22:21:41 - GraphTrainer - INFO - hit_rate@20: 0.072821
2025-11-22 22:21:41 - GraphTrainer - INFO - ndcg@20: 0.029447
2025-11-22 22:21:41 - GraphTrainer - INFO - map@20: 0.018151
2025-11-22 22:21:41 - GraphTrainer - INFO - mrr@20: 0.019065
2025-11-22 22:21:41 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:21:41 - GraphTrainer - INFO - ============================================================
2025-11-22 22:21:41 - GraphTrainer - INFO - 开始第 53/1000 轮训练
2025-11-22 22:21:41 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4088, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3904, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3891, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4102, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4046, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3925, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3984, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4079, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3808, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3843, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3908, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3691, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4100, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4103, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4177, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4003, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3722, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3930, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3968, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3845, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3950, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4052, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3835, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4026, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3959, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4014, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3819, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3966, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3958, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4033, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3913, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3841, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3984, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3881, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3821, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4163, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3947, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4007, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3923, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3989, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3862, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3950, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4092, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3937, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3855, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3742, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4031, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3959, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4078, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4077, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3615, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4030, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4083, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4079, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4073, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3966, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4243, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3828, device='cuda:0', grad_fn=<AddBackward0>)
The 52 training average loss: 0.39602697152515937
2025-11-22 22:21:52 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:21:52 - GraphTrainer - INFO -   precision@5: 0.005369
2025-11-22 22:21:52 - GraphTrainer - INFO -   recall@5: 0.025519
2025-11-22 22:21:52 - GraphTrainer - INFO -   hit_rate@5: 0.026794
2025-11-22 22:21:52 - GraphTrainer - INFO -   ndcg@5: 0.016609
2025-11-22 22:21:52 - GraphTrainer - INFO -   map@5: 0.013488
2025-11-22 22:21:52 - GraphTrainer - INFO -   mrr@5: 0.014109
2025-11-22 22:21:52 - GraphTrainer - INFO -   precision@10: 0.004289
2025-11-22 22:21:52 - GraphTrainer - INFO -   recall@10: 0.040673
2025-11-22 22:21:52 - GraphTrainer - INFO -   hit_rate@10: 0.042787
2025-11-22 22:21:52 - GraphTrainer - INFO -   ndcg@10: 0.021549
2025-11-22 22:21:52 - GraphTrainer - INFO -   map@10: 0.015500
2025-11-22 22:21:52 - GraphTrainer - INFO -   mrr@10: 0.016233
2025-11-22 22:21:52 - GraphTrainer - INFO -   precision@20: 0.003551
2025-11-22 22:21:52 - GraphTrainer - INFO -   recall@20: 0.067449
2025-11-22 22:21:52 - GraphTrainer - INFO -   hit_rate@20: 0.070609
2025-11-22 22:21:52 - GraphTrainer - INFO -   ndcg@20: 0.028340
2025-11-22 22:21:52 - GraphTrainer - INFO -   map@20: 0.017325
2025-11-22 22:21:52 - GraphTrainer - INFO -   mrr@20: 0.018124
2025-11-22 22:21:52 - GraphTrainer - INFO - 第 53 轮训练完成
2025-11-22 22:21:52 - GraphTrainer - INFO - train_loss: 0.398989
2025-11-22 22:21:52 - GraphTrainer - INFO - precision@5: 0.005369
2025-11-22 22:21:52 - GraphTrainer - INFO - recall@5: 0.025519
2025-11-22 22:21:52 - GraphTrainer - INFO - hit_rate@5: 0.026794
2025-11-22 22:21:52 - GraphTrainer - INFO - ndcg@5: 0.016609
2025-11-22 22:21:52 - GraphTrainer - INFO - map@5: 0.013488
2025-11-22 22:21:52 - GraphTrainer - INFO - mrr@5: 0.014109
2025-11-22 22:21:52 - GraphTrainer - INFO - precision@10: 0.004289
2025-11-22 22:21:52 - GraphTrainer - INFO - recall@10: 0.040673
2025-11-22 22:21:52 - GraphTrainer - INFO - hit_rate@10: 0.042787
2025-11-22 22:21:52 - GraphTrainer - INFO - ndcg@10: 0.021549
2025-11-22 22:21:52 - GraphTrainer - INFO - map@10: 0.015500
2025-11-22 22:21:52 - GraphTrainer - INFO - mrr@10: 0.016233
2025-11-22 22:21:52 - GraphTrainer - INFO - precision@20: 0.003551
2025-11-22 22:21:52 - GraphTrainer - INFO - recall@20: 0.067449
2025-11-22 22:21:52 - GraphTrainer - INFO - hit_rate@20: 0.070609
2025-11-22 22:21:52 - GraphTrainer - INFO - ndcg@20: 0.028340
2025-11-22 22:21:52 - GraphTrainer - INFO - map@20: 0.017325
2025-11-22 22:21:52 - GraphTrainer - INFO - mrr@20: 0.018124
2025-11-22 22:21:52 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:21:52 - GraphTrainer - INFO - ============================================================
2025-11-22 22:21:52 - GraphTrainer - INFO - 开始第 54/1000 轮训练
2025-11-22 22:21:52 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3862, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3787, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3904, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3986, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4037, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4018, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3796, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4052, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4029, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3919, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3953, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3953, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3997, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4082, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3762, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4015, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4034, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3891, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3948, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3949, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3866, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4110, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4192, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4122, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4034, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4000, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3883, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3975, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3742, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3942, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3766, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4042, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3822, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4372, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4119, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4203, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3965, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4013, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4049, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4299, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4152, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3874, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3883, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4011, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4179, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4007, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3882, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4143, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4064, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4083, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4166, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3974, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3926, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3923, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3880, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3979, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3850, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3952, device='cuda:0', grad_fn=<AddBackward0>)
The 53 training average loss: 0.3989889205529772
2025-11-22 22:22:04 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:22:04 - GraphTrainer - INFO -   precision@5: 0.005606
2025-11-22 22:22:04 - GraphTrainer - INFO -   recall@5: 0.026753
2025-11-22 22:22:04 - GraphTrainer - INFO -   hit_rate@5: 0.027976
2025-11-22 22:22:04 - GraphTrainer - INFO -   ndcg@5: 0.018014
2025-11-22 22:22:04 - GraphTrainer - INFO -   map@5: 0.014938
2025-11-22 22:22:04 - GraphTrainer - INFO -   mrr@5: 0.015561
2025-11-22 22:22:04 - GraphTrainer - INFO -   precision@10: 0.004526
2025-11-22 22:22:04 - GraphTrainer - INFO -   recall@10: 0.043093
2025-11-22 22:22:04 - GraphTrainer - INFO -   hit_rate@10: 0.045153
2025-11-22 22:22:04 - GraphTrainer - INFO -   ndcg@10: 0.023295
2025-11-22 22:22:04 - GraphTrainer - INFO -   map@10: 0.017067
2025-11-22 22:22:04 - GraphTrainer - INFO -   mrr@10: 0.017797
2025-11-22 22:22:04 - GraphTrainer - INFO -   precision@20: 0.003644
2025-11-22 22:22:04 - GraphTrainer - INFO -   recall@20: 0.068995
2025-11-22 22:22:04 - GraphTrainer - INFO -   hit_rate@20: 0.072409
2025-11-22 22:22:04 - GraphTrainer - INFO -   ndcg@20: 0.029891
2025-11-22 22:22:04 - GraphTrainer - INFO -   map@20: 0.018840
2025-11-22 22:22:04 - GraphTrainer - INFO -   mrr@20: 0.019652
2025-11-22 22:22:04 - GraphTrainer - INFO - 第 54 轮训练完成
2025-11-22 22:22:04 - GraphTrainer - INFO - train_loss: 0.400136
2025-11-22 22:22:04 - GraphTrainer - INFO - precision@5: 0.005606
2025-11-22 22:22:04 - GraphTrainer - INFO - recall@5: 0.026753
2025-11-22 22:22:04 - GraphTrainer - INFO - hit_rate@5: 0.027976
2025-11-22 22:22:04 - GraphTrainer - INFO - ndcg@5: 0.018014
2025-11-22 22:22:04 - GraphTrainer - INFO - map@5: 0.014938
2025-11-22 22:22:04 - GraphTrainer - INFO - mrr@5: 0.015561
2025-11-22 22:22:04 - GraphTrainer - INFO - precision@10: 0.004526
2025-11-22 22:22:04 - GraphTrainer - INFO - recall@10: 0.043093
2025-11-22 22:22:04 - GraphTrainer - INFO - hit_rate@10: 0.045153
2025-11-22 22:22:04 - GraphTrainer - INFO - ndcg@10: 0.023295
2025-11-22 22:22:04 - GraphTrainer - INFO - map@10: 0.017067
2025-11-22 22:22:04 - GraphTrainer - INFO - mrr@10: 0.017797
2025-11-22 22:22:04 - GraphTrainer - INFO - precision@20: 0.003644
2025-11-22 22:22:04 - GraphTrainer - INFO - recall@20: 0.068995
2025-11-22 22:22:04 - GraphTrainer - INFO - hit_rate@20: 0.072409
2025-11-22 22:22:04 - GraphTrainer - INFO - ndcg@20: 0.029891
2025-11-22 22:22:04 - GraphTrainer - INFO - map@20: 0.018840
2025-11-22 22:22:04 - GraphTrainer - INFO - mrr@20: 0.019652
2025-11-22 22:22:04 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:22:04 - GraphTrainer - INFO - ============================================================
2025-11-22 22:22:04 - GraphTrainer - INFO - 开始第 55/1000 轮训练
2025-11-22 22:22:04 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3915, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3875, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3893, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4170, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3800, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4265, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4017, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4006, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4029, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4142, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3799, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3857, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4069, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3845, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4001, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4152, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3996, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3887, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3921, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4225, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3933, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3801, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3823, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3861, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3955, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3990, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3943, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3959, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3971, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4217, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3988, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3843, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3953, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3865, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3910, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3950, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4119, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4157, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3974, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3818, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4164, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4098, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4157, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3841, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4484, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4071, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4120, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3920, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3826, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3920, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4036, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4155, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4150, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3995, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3952, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3860, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4297, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4135, device='cuda:0', grad_fn=<AddBackward0>)
The 54 training average loss: 0.4001362354590975
2025-11-22 22:22:15 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:22:15 - GraphTrainer - INFO -   precision@5: 0.005472
2025-11-22 22:22:15 - GraphTrainer - INFO -   recall@5: 0.025986
2025-11-22 22:22:15 - GraphTrainer - INFO -   hit_rate@5: 0.027256
2025-11-22 22:22:15 - GraphTrainer - INFO -   ndcg@5: 0.016956
2025-11-22 22:22:15 - GraphTrainer - INFO -   map@5: 0.013779
2025-11-22 22:22:15 - GraphTrainer - INFO -   mrr@5: 0.014408
2025-11-22 22:22:15 - GraphTrainer - INFO -   precision@10: 0.004304
2025-11-22 22:22:15 - GraphTrainer - INFO -   recall@10: 0.040693
2025-11-22 22:22:15 - GraphTrainer - INFO -   hit_rate@10: 0.042890
2025-11-22 22:22:15 - GraphTrainer - INFO -   ndcg@10: 0.021740
2025-11-22 22:22:15 - GraphTrainer - INFO -   map@10: 0.015712
2025-11-22 22:22:15 - GraphTrainer - INFO -   mrr@10: 0.016465
2025-11-22 22:22:15 - GraphTrainer - INFO -   precision@20: 0.003536
2025-11-22 22:22:15 - GraphTrainer - INFO -   recall@20: 0.067109
2025-11-22 22:22:15 - GraphTrainer - INFO -   hit_rate@20: 0.070301
2025-11-22 22:22:15 - GraphTrainer - INFO -   ndcg@20: 0.028406
2025-11-22 22:22:15 - GraphTrainer - INFO -   map@20: 0.017489
2025-11-22 22:22:15 - GraphTrainer - INFO -   mrr@20: 0.018301
2025-11-22 22:22:15 - GraphTrainer - INFO - 第 55 轮训练完成
2025-11-22 22:22:15 - GraphTrainer - INFO - train_loss: 0.391756
2025-11-22 22:22:15 - GraphTrainer - INFO - precision@5: 0.005472
2025-11-22 22:22:15 - GraphTrainer - INFO - recall@5: 0.025986
2025-11-22 22:22:15 - GraphTrainer - INFO - hit_rate@5: 0.027256
2025-11-22 22:22:15 - GraphTrainer - INFO - ndcg@5: 0.016956
2025-11-22 22:22:15 - GraphTrainer - INFO - map@5: 0.013779
2025-11-22 22:22:15 - GraphTrainer - INFO - mrr@5: 0.014408
2025-11-22 22:22:15 - GraphTrainer - INFO - precision@10: 0.004304
2025-11-22 22:22:15 - GraphTrainer - INFO - recall@10: 0.040693
2025-11-22 22:22:15 - GraphTrainer - INFO - hit_rate@10: 0.042890
2025-11-22 22:22:15 - GraphTrainer - INFO - ndcg@10: 0.021740
2025-11-22 22:22:15 - GraphTrainer - INFO - map@10: 0.015712
2025-11-22 22:22:15 - GraphTrainer - INFO - mrr@10: 0.016465
2025-11-22 22:22:15 - GraphTrainer - INFO - precision@20: 0.003536
2025-11-22 22:22:15 - GraphTrainer - INFO - recall@20: 0.067109
2025-11-22 22:22:15 - GraphTrainer - INFO - hit_rate@20: 0.070301
2025-11-22 22:22:15 - GraphTrainer - INFO - ndcg@20: 0.028406
2025-11-22 22:22:15 - GraphTrainer - INFO - map@20: 0.017489
2025-11-22 22:22:15 - GraphTrainer - INFO - mrr@20: 0.018301
2025-11-22 22:22:15 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:22:15 - GraphTrainer - INFO - ============================================================
2025-11-22 22:22:15 - GraphTrainer - INFO - 开始第 56/1000 轮训练
2025-11-22 22:22:15 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3907, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4111, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3945, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3941, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3773, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3968, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3908, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4108, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4026, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4065, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3987, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4028, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4016, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3984, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3837, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3801, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4013, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3881, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3804, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3807, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3800, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3796, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4087, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3963, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3877, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3795, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3688, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3932, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4086, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3890, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3870, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3995, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3878, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3723, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4055, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3796, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3765, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3958, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3826, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3784, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3831, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4107, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3966, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3835, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3738, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3831, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4147, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3988, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3768, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4084, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3908, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3862, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3921, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3948, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3968, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4043, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3883, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3910, device='cuda:0', grad_fn=<AddBackward0>)
The 55 training average loss: 0.39175577821402713
2025-11-22 22:22:26 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:22:26 - GraphTrainer - INFO -   precision@5: 0.006120
2025-11-22 22:22:26 - GraphTrainer - INFO -   recall@5: 0.029223
2025-11-22 22:22:26 - GraphTrainer - INFO -   hit_rate@5: 0.030548
2025-11-22 22:22:26 - GraphTrainer - INFO -   ndcg@5: 0.019363
2025-11-22 22:22:26 - GraphTrainer - INFO -   map@5: 0.015888
2025-11-22 22:22:26 - GraphTrainer - INFO -   mrr@5: 0.016552
2025-11-22 22:22:26 - GraphTrainer - INFO -   precision@10: 0.004623
2025-11-22 22:22:26 - GraphTrainer - INFO -   recall@10: 0.044095
2025-11-22 22:22:26 - GraphTrainer - INFO -   hit_rate@10: 0.046130
2025-11-22 22:22:26 - GraphTrainer - INFO -   ndcg@10: 0.024158
2025-11-22 22:22:26 - GraphTrainer - INFO -   map@10: 0.017818
2025-11-22 22:22:26 - GraphTrainer - INFO -   mrr@10: 0.018568
2025-11-22 22:22:26 - GraphTrainer - INFO -   precision@20: 0.003700
2025-11-22 22:22:26 - GraphTrainer - INFO -   recall@20: 0.070523
2025-11-22 22:22:26 - GraphTrainer - INFO -   hit_rate@20: 0.073746
2025-11-22 22:22:26 - GraphTrainer - INFO -   ndcg@20: 0.030820
2025-11-22 22:22:26 - GraphTrainer - INFO -   map@20: 0.019586
2025-11-22 22:22:26 - GraphTrainer - INFO -   mrr@20: 0.020412
2025-11-22 22:22:26 - GraphTrainer - INFO - 第 56 轮训练完成
2025-11-22 22:22:26 - GraphTrainer - INFO - train_loss: 0.391682
2025-11-22 22:22:26 - GraphTrainer - INFO - precision@5: 0.006120
2025-11-22 22:22:26 - GraphTrainer - INFO - recall@5: 0.029223
2025-11-22 22:22:26 - GraphTrainer - INFO - hit_rate@5: 0.030548
2025-11-22 22:22:26 - GraphTrainer - INFO - ndcg@5: 0.019363
2025-11-22 22:22:26 - GraphTrainer - INFO - map@5: 0.015888
2025-11-22 22:22:26 - GraphTrainer - INFO - mrr@5: 0.016552
2025-11-22 22:22:26 - GraphTrainer - INFO - precision@10: 0.004623
2025-11-22 22:22:26 - GraphTrainer - INFO - recall@10: 0.044095
2025-11-22 22:22:26 - GraphTrainer - INFO - hit_rate@10: 0.046130
2025-11-22 22:22:26 - GraphTrainer - INFO - ndcg@10: 0.024158
2025-11-22 22:22:26 - GraphTrainer - INFO - map@10: 0.017818
2025-11-22 22:22:26 - GraphTrainer - INFO - mrr@10: 0.018568
2025-11-22 22:22:26 - GraphTrainer - INFO - precision@20: 0.003700
2025-11-22 22:22:26 - GraphTrainer - INFO - recall@20: 0.070523
2025-11-22 22:22:26 - GraphTrainer - INFO - hit_rate@20: 0.073746
2025-11-22 22:22:26 - GraphTrainer - INFO - ndcg@20: 0.030820
2025-11-22 22:22:26 - GraphTrainer - INFO - map@20: 0.019586
2025-11-22 22:22:26 - GraphTrainer - INFO - mrr@20: 0.020412
2025-11-22 22:22:26 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:22:26 - GraphTrainer - INFO - ============================================================
2025-11-22 22:22:26 - GraphTrainer - INFO - 开始第 57/1000 轮训练
2025-11-22 22:22:26 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3863, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3681, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3884, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4028, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3854, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3918, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4137, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3717, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3625, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4063, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4005, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3789, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3779, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3944, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3943, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3871, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3914, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3930, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3788, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3834, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3927, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4023, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4299, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3809, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3850, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4018, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3823, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4024, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3820, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3838, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4042, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3859, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3881, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3874, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3934, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3832, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3847, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3811, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3761, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4144, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4008, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4128, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3964, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4014, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3907, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4078, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3806, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3993, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3888, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4202, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3775, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3922, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3859, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3933, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4165, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3728, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3819, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4005, device='cuda:0', grad_fn=<AddBackward0>)
The 56 training average loss: 0.39168156888978234
2025-11-22 22:22:37 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:22:37 - GraphTrainer - INFO -   precision@5: 0.005739
2025-11-22 22:22:37 - GraphTrainer - INFO -   recall@5: 0.027198
2025-11-22 22:22:37 - GraphTrainer - INFO -   hit_rate@5: 0.028593
2025-11-22 22:22:37 - GraphTrainer - INFO -   ndcg@5: 0.017595
2025-11-22 22:22:37 - GraphTrainer - INFO -   map@5: 0.014225
2025-11-22 22:22:37 - GraphTrainer - INFO -   mrr@5: 0.014907
2025-11-22 22:22:37 - GraphTrainer - INFO -   precision@10: 0.004536
2025-11-22 22:22:37 - GraphTrainer - INFO -   recall@10: 0.042675
2025-11-22 22:22:37 - GraphTrainer - INFO -   hit_rate@10: 0.045153
2025-11-22 22:22:37 - GraphTrainer - INFO -   ndcg@10: 0.022624
2025-11-22 22:22:37 - GraphTrainer - INFO -   map@10: 0.016247
2025-11-22 22:22:37 - GraphTrainer - INFO -   mrr@10: 0.017062
2025-11-22 22:22:37 - GraphTrainer - INFO -   precision@20: 0.003651
2025-11-22 22:22:37 - GraphTrainer - INFO -   recall@20: 0.068839
2025-11-22 22:22:37 - GraphTrainer - INFO -   hit_rate@20: 0.072615
2025-11-22 22:22:37 - GraphTrainer - INFO -   ndcg@20: 0.029226
2025-11-22 22:22:37 - GraphTrainer - INFO -   map@20: 0.017995
2025-11-22 22:22:37 - GraphTrainer - INFO -   mrr@20: 0.018894
2025-11-22 22:22:37 - GraphTrainer - INFO - 第 57 轮训练完成
2025-11-22 22:22:37 - GraphTrainer - INFO - train_loss: 0.394253
2025-11-22 22:22:37 - GraphTrainer - INFO - precision@5: 0.005739
2025-11-22 22:22:37 - GraphTrainer - INFO - recall@5: 0.027198
2025-11-22 22:22:37 - GraphTrainer - INFO - hit_rate@5: 0.028593
2025-11-22 22:22:37 - GraphTrainer - INFO - ndcg@5: 0.017595
2025-11-22 22:22:37 - GraphTrainer - INFO - map@5: 0.014225
2025-11-22 22:22:37 - GraphTrainer - INFO - mrr@5: 0.014907
2025-11-22 22:22:37 - GraphTrainer - INFO - precision@10: 0.004536
2025-11-22 22:22:37 - GraphTrainer - INFO - recall@10: 0.042675
2025-11-22 22:22:37 - GraphTrainer - INFO - hit_rate@10: 0.045153
2025-11-22 22:22:37 - GraphTrainer - INFO - ndcg@10: 0.022624
2025-11-22 22:22:37 - GraphTrainer - INFO - map@10: 0.016247
2025-11-22 22:22:37 - GraphTrainer - INFO - mrr@10: 0.017062
2025-11-22 22:22:37 - GraphTrainer - INFO - precision@20: 0.003651
2025-11-22 22:22:37 - GraphTrainer - INFO - recall@20: 0.068839
2025-11-22 22:22:37 - GraphTrainer - INFO - hit_rate@20: 0.072615
2025-11-22 22:22:37 - GraphTrainer - INFO - ndcg@20: 0.029226
2025-11-22 22:22:37 - GraphTrainer - INFO - map@20: 0.017995
2025-11-22 22:22:37 - GraphTrainer - INFO - mrr@20: 0.018894
2025-11-22 22:22:37 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:22:37 - GraphTrainer - INFO - ============================================================
2025-11-22 22:22:37 - GraphTrainer - INFO - 开始第 58/1000 轮训练
2025-11-22 22:22:37 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4179, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4015, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3771, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4124, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4002, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4156, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3989, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3846, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3869, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3736, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4026, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3792, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4031, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3858, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3798, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3789, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3988, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4013, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3999, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3687, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3921, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3988, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4112, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4123, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3929, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3920, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3740, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3948, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4155, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3781, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3746, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4015, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3880, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3746, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3752, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3800, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3964, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4260, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4002, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4284, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4029, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3980, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3909, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4146, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4194, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3918, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3913, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3975, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3974, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3928, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3917, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4132, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3988, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3842, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4083, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3812, device='cuda:0', grad_fn=<AddBackward0>)
The 57 training average loss: 0.3942530581663395
2025-11-22 22:22:48 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:22:48 - GraphTrainer - INFO -   precision@5: 0.005729
2025-11-22 22:22:48 - GraphTrainer - INFO -   recall@5: 0.027122
2025-11-22 22:22:48 - GraphTrainer - INFO -   hit_rate@5: 0.028593
2025-11-22 22:22:48 - GraphTrainer - INFO -   ndcg@5: 0.017764
2025-11-22 22:22:48 - GraphTrainer - INFO -   map@5: 0.014446
2025-11-22 22:22:48 - GraphTrainer - INFO -   mrr@5: 0.015150
2025-11-22 22:22:48 - GraphTrainer - INFO -   precision@10: 0.004536
2025-11-22 22:22:48 - GraphTrainer - INFO -   recall@10: 0.042725
2025-11-22 22:22:48 - GraphTrainer - INFO -   hit_rate@10: 0.045307
2025-11-22 22:22:48 - GraphTrainer - INFO -   ndcg@10: 0.022850
2025-11-22 22:22:48 - GraphTrainer - INFO -   map@10: 0.016507
2025-11-22 22:22:48 - GraphTrainer - INFO -   mrr@10: 0.017349
2025-11-22 22:22:48 - GraphTrainer - INFO -   precision@20: 0.003600
2025-11-22 22:22:48 - GraphTrainer - INFO -   recall@20: 0.067818
2025-11-22 22:22:48 - GraphTrainer - INFO -   hit_rate@20: 0.071689
2025-11-22 22:22:48 - GraphTrainer - INFO -   ndcg@20: 0.029221
2025-11-22 22:22:48 - GraphTrainer - INFO -   map@20: 0.018208
2025-11-22 22:22:48 - GraphTrainer - INFO -   mrr@20: 0.019136
2025-11-22 22:22:48 - GraphTrainer - INFO - 第 58 轮训练完成
2025-11-22 22:22:48 - GraphTrainer - INFO - train_loss: 0.391475
2025-11-22 22:22:48 - GraphTrainer - INFO - precision@5: 0.005729
2025-11-22 22:22:48 - GraphTrainer - INFO - recall@5: 0.027122
2025-11-22 22:22:48 - GraphTrainer - INFO - hit_rate@5: 0.028593
2025-11-22 22:22:48 - GraphTrainer - INFO - ndcg@5: 0.017764
2025-11-22 22:22:48 - GraphTrainer - INFO - map@5: 0.014446
2025-11-22 22:22:48 - GraphTrainer - INFO - mrr@5: 0.015150
2025-11-22 22:22:48 - GraphTrainer - INFO - precision@10: 0.004536
2025-11-22 22:22:48 - GraphTrainer - INFO - recall@10: 0.042725
2025-11-22 22:22:48 - GraphTrainer - INFO - hit_rate@10: 0.045307
2025-11-22 22:22:48 - GraphTrainer - INFO - ndcg@10: 0.022850
2025-11-22 22:22:48 - GraphTrainer - INFO - map@10: 0.016507
2025-11-22 22:22:48 - GraphTrainer - INFO - mrr@10: 0.017349
2025-11-22 22:22:48 - GraphTrainer - INFO - precision@20: 0.003600
2025-11-22 22:22:48 - GraphTrainer - INFO - recall@20: 0.067818
2025-11-22 22:22:48 - GraphTrainer - INFO - hit_rate@20: 0.071689
2025-11-22 22:22:48 - GraphTrainer - INFO - ndcg@20: 0.029221
2025-11-22 22:22:48 - GraphTrainer - INFO - map@20: 0.018208
2025-11-22 22:22:48 - GraphTrainer - INFO - mrr@20: 0.019136
2025-11-22 22:22:48 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:22:48 - GraphTrainer - INFO - ============================================================
2025-11-22 22:22:48 - GraphTrainer - INFO - 开始第 59/1000 轮训练
2025-11-22 22:22:48 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3778, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4062, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3741, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4047, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3887, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3871, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4111, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3966, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3816, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4017, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4206, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4145, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4016, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4074, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4132, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3828, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3967, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3792, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3994, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3936, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3910, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3983, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3786, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3924, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3905, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3987, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3901, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3955, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3722, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3768, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4255, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3685, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3784, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3733, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3900, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3975, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4037, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4186, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3815, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3632, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3968, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3927, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3929, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3829, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3743, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4019, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3903, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3792, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3842, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3837, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4043, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3639, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3874, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3978, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3967, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3910, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3870, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3756, device='cuda:0', grad_fn=<AddBackward0>)
The 58 training average loss: 0.3914753830638425
2025-11-22 22:22:59 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:22:59 - GraphTrainer - INFO -   precision@5: 0.005595
2025-11-22 22:22:59 - GraphTrainer - INFO -   recall@5: 0.026803
2025-11-22 22:22:59 - GraphTrainer - INFO -   hit_rate@5: 0.027925
2025-11-22 22:22:59 - GraphTrainer - INFO -   ndcg@5: 0.017314
2025-11-22 22:22:59 - GraphTrainer - INFO -   map@5: 0.014012
2025-11-22 22:22:59 - GraphTrainer - INFO -   mrr@5: 0.014639
2025-11-22 22:22:59 - GraphTrainer - INFO -   precision@10: 0.004603
2025-11-22 22:22:59 - GraphTrainer - INFO -   recall@10: 0.043745
2025-11-22 22:22:59 - GraphTrainer - INFO -   hit_rate@10: 0.045924
2025-11-22 22:22:59 - GraphTrainer - INFO -   ndcg@10: 0.022786
2025-11-22 22:22:59 - GraphTrainer - INFO -   map@10: 0.016204
2025-11-22 22:22:59 - GraphTrainer - INFO -   mrr@10: 0.016968
2025-11-22 22:22:59 - GraphTrainer - INFO -   precision@20: 0.003682
2025-11-22 22:22:59 - GraphTrainer - INFO -   recall@20: 0.069759
2025-11-22 22:22:59 - GraphTrainer - INFO -   hit_rate@20: 0.073284
2025-11-22 22:22:59 - GraphTrainer - INFO -   ndcg@20: 0.029384
2025-11-22 22:22:59 - GraphTrainer - INFO -   map@20: 0.017963
2025-11-22 22:22:59 - GraphTrainer - INFO -   mrr@20: 0.018812
2025-11-22 22:22:59 - GraphTrainer - INFO - 第 59 轮训练完成
2025-11-22 22:22:59 - GraphTrainer - INFO - train_loss: 0.391263
2025-11-22 22:22:59 - GraphTrainer - INFO - precision@5: 0.005595
2025-11-22 22:22:59 - GraphTrainer - INFO - recall@5: 0.026803
2025-11-22 22:22:59 - GraphTrainer - INFO - hit_rate@5: 0.027925
2025-11-22 22:22:59 - GraphTrainer - INFO - ndcg@5: 0.017314
2025-11-22 22:22:59 - GraphTrainer - INFO - map@5: 0.014012
2025-11-22 22:22:59 - GraphTrainer - INFO - mrr@5: 0.014639
2025-11-22 22:22:59 - GraphTrainer - INFO - precision@10: 0.004603
2025-11-22 22:22:59 - GraphTrainer - INFO - recall@10: 0.043745
2025-11-22 22:22:59 - GraphTrainer - INFO - hit_rate@10: 0.045924
2025-11-22 22:22:59 - GraphTrainer - INFO - ndcg@10: 0.022786
2025-11-22 22:22:59 - GraphTrainer - INFO - map@10: 0.016204
2025-11-22 22:22:59 - GraphTrainer - INFO - mrr@10: 0.016968
2025-11-22 22:22:59 - GraphTrainer - INFO - precision@20: 0.003682
2025-11-22 22:22:59 - GraphTrainer - INFO - recall@20: 0.069759
2025-11-22 22:22:59 - GraphTrainer - INFO - hit_rate@20: 0.073284
2025-11-22 22:22:59 - GraphTrainer - INFO - ndcg@20: 0.029384
2025-11-22 22:22:59 - GraphTrainer - INFO - map@20: 0.017963
2025-11-22 22:22:59 - GraphTrainer - INFO - mrr@20: 0.018812
2025-11-22 22:22:59 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:22:59 - GraphTrainer - INFO - ============================================================
2025-11-22 22:22:59 - GraphTrainer - INFO - 开始第 60/1000 轮训练
2025-11-22 22:22:59 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3978, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3961, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4042, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3626, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4049, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3860, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3885, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3837, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4118, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3828, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3935, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4040, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3838, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3952, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4058, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3925, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4017, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3787, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3894, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3863, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3998, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3689, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3855, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3786, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3807, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3917, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3944, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3877, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3690, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3701, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3771, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3900, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3746, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3834, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4111, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3929, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4017, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3839, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4026, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4007, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3911, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4152, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3938, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3692, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3805, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4030, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4012, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4041, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4142, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4065, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3866, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3718, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3966, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4195, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3920, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3853, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3965, device='cuda:0', grad_fn=<AddBackward0>)
The 59 training average loss: 0.3912632953504036
2025-11-22 22:23:10 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:23:10 - GraphTrainer - INFO -   precision@5: 0.005750
2025-11-22 22:23:10 - GraphTrainer - INFO -   recall@5: 0.027489
2025-11-22 22:23:10 - GraphTrainer - INFO -   hit_rate@5: 0.028696
2025-11-22 22:23:10 - GraphTrainer - INFO -   ndcg@5: 0.017787
2025-11-22 22:23:10 - GraphTrainer - INFO -   map@5: 0.014410
2025-11-22 22:23:10 - GraphTrainer - INFO -   mrr@5: 0.015012
2025-11-22 22:23:10 - GraphTrainer - INFO -   precision@10: 0.004634
2025-11-22 22:23:10 - GraphTrainer - INFO -   recall@10: 0.043905
2025-11-22 22:23:10 - GraphTrainer - INFO -   hit_rate@10: 0.046182
2025-11-22 22:23:10 - GraphTrainer - INFO -   ndcg@10: 0.023118
2025-11-22 22:23:10 - GraphTrainer - INFO -   map@10: 0.016559
2025-11-22 22:23:10 - GraphTrainer - INFO -   mrr@10: 0.017295
2025-11-22 22:23:10 - GraphTrainer - INFO -   precision@20: 0.003682
2025-11-22 22:23:10 - GraphTrainer - INFO -   recall@20: 0.069650
2025-11-22 22:23:10 - GraphTrainer - INFO -   hit_rate@20: 0.073232
2025-11-22 22:23:10 - GraphTrainer - INFO -   ndcg@20: 0.029611
2025-11-22 22:23:10 - GraphTrainer - INFO -   map@20: 0.018273
2025-11-22 22:23:10 - GraphTrainer - INFO -   mrr@20: 0.019094
2025-11-22 22:23:10 - GraphTrainer - INFO - 第 60 轮训练完成
2025-11-22 22:23:10 - GraphTrainer - INFO - train_loss: 0.388525
2025-11-22 22:23:10 - GraphTrainer - INFO - precision@5: 0.005750
2025-11-22 22:23:10 - GraphTrainer - INFO - recall@5: 0.027489
2025-11-22 22:23:10 - GraphTrainer - INFO - hit_rate@5: 0.028696
2025-11-22 22:23:10 - GraphTrainer - INFO - ndcg@5: 0.017787
2025-11-22 22:23:10 - GraphTrainer - INFO - map@5: 0.014410
2025-11-22 22:23:10 - GraphTrainer - INFO - mrr@5: 0.015012
2025-11-22 22:23:10 - GraphTrainer - INFO - precision@10: 0.004634
2025-11-22 22:23:10 - GraphTrainer - INFO - recall@10: 0.043905
2025-11-22 22:23:10 - GraphTrainer - INFO - hit_rate@10: 0.046182
2025-11-22 22:23:10 - GraphTrainer - INFO - ndcg@10: 0.023118
2025-11-22 22:23:10 - GraphTrainer - INFO - map@10: 0.016559
2025-11-22 22:23:10 - GraphTrainer - INFO - mrr@10: 0.017295
2025-11-22 22:23:10 - GraphTrainer - INFO - precision@20: 0.003682
2025-11-22 22:23:10 - GraphTrainer - INFO - recall@20: 0.069650
2025-11-22 22:23:10 - GraphTrainer - INFO - hit_rate@20: 0.073232
2025-11-22 22:23:10 - GraphTrainer - INFO - ndcg@20: 0.029611
2025-11-22 22:23:10 - GraphTrainer - INFO - map@20: 0.018273
2025-11-22 22:23:10 - GraphTrainer - INFO - mrr@20: 0.019094
2025-11-22 22:23:10 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:23:10 - GraphTrainer - INFO - 检查点已保存: Epoch 60 -> ./checkpoints/checkpoint_epoch_60.pth
2025-11-22 22:23:10 - GraphTrainer - INFO - ============================================================
2025-11-22 22:23:10 - GraphTrainer - INFO - 开始第 61/1000 轮训练
2025-11-22 22:23:10 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3598, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3791, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3998, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3904, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3941, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3737, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3784, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3749, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4167, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3778, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3651, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4079, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4038, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3630, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3786, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4098, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3782, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3925, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3805, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3796, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3928, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3926, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3838, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3808, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4145, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3941, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4119, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3821, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3990, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3939, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3967, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4041, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3929, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3999, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3673, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3846, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3748, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3831, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4078, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4074, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3850, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3769, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3840, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3754, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4016, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4075, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3874, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3956, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4019, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3752, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3888, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3898, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3825, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3867, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3880, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4182, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3753, device='cuda:0', grad_fn=<AddBackward0>)
The 60 training average loss: 0.3885253529096472
2025-11-22 22:23:21 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:23:21 - GraphTrainer - INFO -   precision@5: 0.005410
2025-11-22 22:23:21 - GraphTrainer - INFO -   recall@5: 0.025620
2025-11-22 22:23:21 - GraphTrainer - INFO -   hit_rate@5: 0.026948
2025-11-22 22:23:21 - GraphTrainer - INFO -   ndcg@5: 0.017210
2025-11-22 22:23:21 - GraphTrainer - INFO -   map@5: 0.014233
2025-11-22 22:23:21 - GraphTrainer - INFO -   mrr@5: 0.014871
2025-11-22 22:23:21 - GraphTrainer - INFO -   precision@10: 0.004623
2025-11-22 22:23:21 - GraphTrainer - INFO -   recall@10: 0.043717
2025-11-22 22:23:21 - GraphTrainer - INFO -   hit_rate@10: 0.046027
2025-11-22 22:23:21 - GraphTrainer - INFO -   ndcg@10: 0.023059
2025-11-22 22:23:21 - GraphTrainer - INFO -   map@10: 0.016590
2025-11-22 22:23:21 - GraphTrainer - INFO -   mrr@10: 0.017344
2025-11-22 22:23:21 - GraphTrainer - INFO -   precision@20: 0.003692
2025-11-22 22:23:21 - GraphTrainer - INFO -   recall@20: 0.069754
2025-11-22 22:23:21 - GraphTrainer - INFO -   hit_rate@20: 0.073438
2025-11-22 22:23:21 - GraphTrainer - INFO -   ndcg@20: 0.029648
2025-11-22 22:23:21 - GraphTrainer - INFO -   map@20: 0.018339
2025-11-22 22:23:21 - GraphTrainer - INFO -   mrr@20: 0.019184
2025-11-22 22:23:21 - GraphTrainer - INFO - 第 61 轮训练完成
2025-11-22 22:23:21 - GraphTrainer - INFO - train_loss: 0.390957
2025-11-22 22:23:21 - GraphTrainer - INFO - precision@5: 0.005410
2025-11-22 22:23:21 - GraphTrainer - INFO - recall@5: 0.025620
2025-11-22 22:23:21 - GraphTrainer - INFO - hit_rate@5: 0.026948
2025-11-22 22:23:21 - GraphTrainer - INFO - ndcg@5: 0.017210
2025-11-22 22:23:21 - GraphTrainer - INFO - map@5: 0.014233
2025-11-22 22:23:21 - GraphTrainer - INFO - mrr@5: 0.014871
2025-11-22 22:23:21 - GraphTrainer - INFO - precision@10: 0.004623
2025-11-22 22:23:21 - GraphTrainer - INFO - recall@10: 0.043717
2025-11-22 22:23:21 - GraphTrainer - INFO - hit_rate@10: 0.046027
2025-11-22 22:23:21 - GraphTrainer - INFO - ndcg@10: 0.023059
2025-11-22 22:23:21 - GraphTrainer - INFO - map@10: 0.016590
2025-11-22 22:23:21 - GraphTrainer - INFO - mrr@10: 0.017344
2025-11-22 22:23:21 - GraphTrainer - INFO - precision@20: 0.003692
2025-11-22 22:23:21 - GraphTrainer - INFO - recall@20: 0.069754
2025-11-22 22:23:21 - GraphTrainer - INFO - hit_rate@20: 0.073438
2025-11-22 22:23:21 - GraphTrainer - INFO - ndcg@20: 0.029648
2025-11-22 22:23:21 - GraphTrainer - INFO - map@20: 0.018339
2025-11-22 22:23:21 - GraphTrainer - INFO - mrr@20: 0.019184
2025-11-22 22:23:21 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:23:21 - GraphTrainer - INFO - ============================================================
2025-11-22 22:23:21 - GraphTrainer - INFO - 开始第 62/1000 轮训练
2025-11-22 22:23:21 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3971, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3762, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4042, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3820, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3916, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3795, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3899, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3945, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4107, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4064, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4196, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3860, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4002, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3888, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3798, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3839, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3870, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3889, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3991, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4064, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3929, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3655, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4171, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3700, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3852, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3954, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3907, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3981, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3953, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3968, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4069, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3766, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3853, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3963, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4042, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3878, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4150, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4018, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3822, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3847, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3987, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3847, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3843, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3820, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3770, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4122, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3861, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3637, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3713, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4066, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3995, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3881, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4016, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3886, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3979, device='cuda:0', grad_fn=<AddBackward0>)
The 61 training average loss: 0.39095654107373334
2025-11-22 22:23:33 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:23:33 - GraphTrainer - INFO -   precision@5: 0.005307
2025-11-22 22:23:33 - GraphTrainer - INFO -   recall@5: 0.025142
2025-11-22 22:23:33 - GraphTrainer - INFO -   hit_rate@5: 0.026485
2025-11-22 22:23:33 - GraphTrainer - INFO -   ndcg@5: 0.016780
2025-11-22 22:23:33 - GraphTrainer - INFO -   map@5: 0.013834
2025-11-22 22:23:33 - GraphTrainer - INFO -   mrr@5: 0.014440
2025-11-22 22:23:33 - GraphTrainer - INFO -   precision@10: 0.004366
2025-11-22 22:23:33 - GraphTrainer - INFO -   recall@10: 0.041199
2025-11-22 22:23:33 - GraphTrainer - INFO -   hit_rate@10: 0.043507
2025-11-22 22:23:33 - GraphTrainer - INFO -   ndcg@10: 0.022008
2025-11-22 22:23:33 - GraphTrainer - INFO -   map@10: 0.015950
2025-11-22 22:23:33 - GraphTrainer - INFO -   mrr@10: 0.016680
2025-11-22 22:23:33 - GraphTrainer - INFO -   precision@20: 0.003572
2025-11-22 22:23:33 - GraphTrainer - INFO -   recall@20: 0.067673
2025-11-22 22:23:33 - GraphTrainer - INFO -   hit_rate@20: 0.071021
2025-11-22 22:23:33 - GraphTrainer - INFO -   ndcg@20: 0.028710
2025-11-22 22:23:33 - GraphTrainer - INFO -   map@20: 0.017745
2025-11-22 22:23:33 - GraphTrainer - INFO -   mrr@20: 0.018538
2025-11-22 22:23:33 - GraphTrainer - INFO - 第 62 轮训练完成
2025-11-22 22:23:33 - GraphTrainer - INFO - train_loss: 0.390071
2025-11-22 22:23:33 - GraphTrainer - INFO - precision@5: 0.005307
2025-11-22 22:23:33 - GraphTrainer - INFO - recall@5: 0.025142
2025-11-22 22:23:33 - GraphTrainer - INFO - hit_rate@5: 0.026485
2025-11-22 22:23:33 - GraphTrainer - INFO - ndcg@5: 0.016780
2025-11-22 22:23:33 - GraphTrainer - INFO - map@5: 0.013834
2025-11-22 22:23:33 - GraphTrainer - INFO - mrr@5: 0.014440
2025-11-22 22:23:33 - GraphTrainer - INFO - precision@10: 0.004366
2025-11-22 22:23:33 - GraphTrainer - INFO - recall@10: 0.041199
2025-11-22 22:23:33 - GraphTrainer - INFO - hit_rate@10: 0.043507
2025-11-22 22:23:33 - GraphTrainer - INFO - ndcg@10: 0.022008
2025-11-22 22:23:33 - GraphTrainer - INFO - map@10: 0.015950
2025-11-22 22:23:33 - GraphTrainer - INFO - mrr@10: 0.016680
2025-11-22 22:23:33 - GraphTrainer - INFO - precision@20: 0.003572
2025-11-22 22:23:33 - GraphTrainer - INFO - recall@20: 0.067673
2025-11-22 22:23:33 - GraphTrainer - INFO - hit_rate@20: 0.071021
2025-11-22 22:23:33 - GraphTrainer - INFO - ndcg@20: 0.028710
2025-11-22 22:23:33 - GraphTrainer - INFO - map@20: 0.017745
2025-11-22 22:23:33 - GraphTrainer - INFO - mrr@20: 0.018538
2025-11-22 22:23:33 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:23:33 - GraphTrainer - INFO - ============================================================
2025-11-22 22:23:33 - GraphTrainer - INFO - 开始第 63/1000 轮训练
2025-11-22 22:23:33 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3896, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3893, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4229, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3882, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4002, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3897, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3645, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3929, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4181, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3855, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3830, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3919, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4032, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3796, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3913, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3870, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3792, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3665, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4059, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3943, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3930, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3927, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3905, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3978, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3687, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3949, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3852, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3592, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3992, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4072, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3957, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4076, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3921, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3912, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3739, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3823, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4004, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3718, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4104, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4031, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4010, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3727, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3912, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4024, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3802, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3668, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3947, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3885, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3889, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3750, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3820, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3801, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3902, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3922, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4139, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3936, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4124, device='cuda:0', grad_fn=<AddBackward0>)
The 62 training average loss: 0.390071132059755
2025-11-22 22:23:44 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:23:44 - GraphTrainer - INFO -   precision@5: 0.005770
2025-11-22 22:23:44 - GraphTrainer - INFO -   recall@5: 0.027476
2025-11-22 22:23:44 - GraphTrainer - INFO -   hit_rate@5: 0.028748
2025-11-22 22:23:44 - GraphTrainer - INFO -   ndcg@5: 0.018072
2025-11-22 22:23:44 - GraphTrainer - INFO -   map@5: 0.014777
2025-11-22 22:23:44 - GraphTrainer - INFO -   mrr@5: 0.015369
2025-11-22 22:23:44 - GraphTrainer - INFO -   precision@10: 0.004536
2025-11-22 22:23:44 - GraphTrainer - INFO -   recall@10: 0.043070
2025-11-22 22:23:44 - GraphTrainer - INFO -   hit_rate@10: 0.045153
2025-11-22 22:23:44 - GraphTrainer - INFO -   ndcg@10: 0.023085
2025-11-22 22:23:44 - GraphTrainer - INFO -   map@10: 0.016779
2025-11-22 22:23:44 - GraphTrainer - INFO -   mrr@10: 0.017477
2025-11-22 22:23:44 - GraphTrainer - INFO -   precision@20: 0.003649
2025-11-22 22:23:44 - GraphTrainer - INFO -   recall@20: 0.069063
2025-11-22 22:23:44 - GraphTrainer - INFO -   hit_rate@20: 0.072666
2025-11-22 22:23:44 - GraphTrainer - INFO -   ndcg@20: 0.029715
2025-11-22 22:23:44 - GraphTrainer - INFO -   map@20: 0.018565
2025-11-22 22:23:44 - GraphTrainer - INFO -   mrr@20: 0.019367
2025-11-22 22:23:44 - GraphTrainer - INFO - 第 63 轮训练完成
2025-11-22 22:23:44 - GraphTrainer - INFO - train_loss: 0.389238
2025-11-22 22:23:44 - GraphTrainer - INFO - precision@5: 0.005770
2025-11-22 22:23:44 - GraphTrainer - INFO - recall@5: 0.027476
2025-11-22 22:23:44 - GraphTrainer - INFO - hit_rate@5: 0.028748
2025-11-22 22:23:44 - GraphTrainer - INFO - ndcg@5: 0.018072
2025-11-22 22:23:44 - GraphTrainer - INFO - map@5: 0.014777
2025-11-22 22:23:44 - GraphTrainer - INFO - mrr@5: 0.015369
2025-11-22 22:23:44 - GraphTrainer - INFO - precision@10: 0.004536
2025-11-22 22:23:44 - GraphTrainer - INFO - recall@10: 0.043070
2025-11-22 22:23:44 - GraphTrainer - INFO - hit_rate@10: 0.045153
2025-11-22 22:23:44 - GraphTrainer - INFO - ndcg@10: 0.023085
2025-11-22 22:23:44 - GraphTrainer - INFO - map@10: 0.016779
2025-11-22 22:23:44 - GraphTrainer - INFO - mrr@10: 0.017477
2025-11-22 22:23:44 - GraphTrainer - INFO - precision@20: 0.003649
2025-11-22 22:23:44 - GraphTrainer - INFO - recall@20: 0.069063
2025-11-22 22:23:44 - GraphTrainer - INFO - hit_rate@20: 0.072666
2025-11-22 22:23:44 - GraphTrainer - INFO - ndcg@20: 0.029715
2025-11-22 22:23:44 - GraphTrainer - INFO - map@20: 0.018565
2025-11-22 22:23:44 - GraphTrainer - INFO - mrr@20: 0.019367
2025-11-22 22:23:44 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:23:44 - GraphTrainer - INFO - ============================================================
2025-11-22 22:23:44 - GraphTrainer - INFO - 开始第 64/1000 轮训练
2025-11-22 22:23:44 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3770, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3939, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3912, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3953, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4000, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3798, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3789, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3911, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3814, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4188, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3917, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3793, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3814, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3738, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3745, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3869, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3988, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3907, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3955, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3878, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3973, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3825, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3830, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3719, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3756, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4091, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3797, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3938, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3800, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4055, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3861, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3964, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3839, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4064, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3828, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3993, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4072, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4034, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3925, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3889, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3806, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3922, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4067, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3839, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3753, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3749, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3915, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4091, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4092, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3756, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3774, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3762, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4059, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4106, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4028, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4028, device='cuda:0', grad_fn=<AddBackward0>)
The 63 training average loss: 0.38923842177308837
2025-11-22 22:23:55 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:23:55 - GraphTrainer - INFO -   precision@5: 0.005791
2025-11-22 22:23:55 - GraphTrainer - INFO -   recall@5: 0.027689
2025-11-22 22:23:55 - GraphTrainer - INFO -   hit_rate@5: 0.028902
2025-11-22 22:23:55 - GraphTrainer - INFO -   ndcg@5: 0.018212
2025-11-22 22:23:55 - GraphTrainer - INFO -   map@5: 0.014887
2025-11-22 22:23:55 - GraphTrainer - INFO -   mrr@5: 0.015499
2025-11-22 22:23:55 - GraphTrainer - INFO -   precision@10: 0.004711
2025-11-22 22:23:55 - GraphTrainer - INFO -   recall@10: 0.044785
2025-11-22 22:23:55 - GraphTrainer - INFO -   hit_rate@10: 0.046953
2025-11-22 22:23:55 - GraphTrainer - INFO -   ndcg@10: 0.023766
2025-11-22 22:23:55 - GraphTrainer - INFO -   map@10: 0.017136
2025-11-22 22:23:55 - GraphTrainer - INFO -   mrr@10: 0.017874
2025-11-22 22:23:55 - GraphTrainer - INFO -   precision@20: 0.003759
2025-11-22 22:23:55 - GraphTrainer - INFO -   recall@20: 0.070975
2025-11-22 22:23:55 - GraphTrainer - INFO -   hit_rate@20: 0.074672
2025-11-22 22:23:55 - GraphTrainer - INFO -   ndcg@20: 0.030426
2025-11-22 22:23:55 - GraphTrainer - INFO -   map@20: 0.018914
2025-11-22 22:23:55 - GraphTrainer - INFO -   mrr@20: 0.019749
2025-11-22 22:23:55 - GraphTrainer - INFO - 第 64 轮训练完成
2025-11-22 22:23:55 - GraphTrainer - INFO - train_loss: 0.387609
2025-11-22 22:23:55 - GraphTrainer - INFO - precision@5: 0.005791
2025-11-22 22:23:55 - GraphTrainer - INFO - recall@5: 0.027689
2025-11-22 22:23:55 - GraphTrainer - INFO - hit_rate@5: 0.028902
2025-11-22 22:23:55 - GraphTrainer - INFO - ndcg@5: 0.018212
2025-11-22 22:23:55 - GraphTrainer - INFO - map@5: 0.014887
2025-11-22 22:23:55 - GraphTrainer - INFO - mrr@5: 0.015499
2025-11-22 22:23:55 - GraphTrainer - INFO - precision@10: 0.004711
2025-11-22 22:23:55 - GraphTrainer - INFO - recall@10: 0.044785
2025-11-22 22:23:55 - GraphTrainer - INFO - hit_rate@10: 0.046953
2025-11-22 22:23:55 - GraphTrainer - INFO - ndcg@10: 0.023766
2025-11-22 22:23:55 - GraphTrainer - INFO - map@10: 0.017136
2025-11-22 22:23:55 - GraphTrainer - INFO - mrr@10: 0.017874
2025-11-22 22:23:55 - GraphTrainer - INFO - precision@20: 0.003759
2025-11-22 22:23:55 - GraphTrainer - INFO - recall@20: 0.070975
2025-11-22 22:23:55 - GraphTrainer - INFO - hit_rate@20: 0.074672
2025-11-22 22:23:55 - GraphTrainer - INFO - ndcg@20: 0.030426
2025-11-22 22:23:55 - GraphTrainer - INFO - map@20: 0.018914
2025-11-22 22:23:55 - GraphTrainer - INFO - mrr@20: 0.019749
2025-11-22 22:23:55 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:23:55 - GraphTrainer - INFO - ============================================================
2025-11-22 22:23:55 - GraphTrainer - INFO - 开始第 65/1000 轮训练
2025-11-22 22:23:55 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3755, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3873, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3908, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3823, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3991, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3751, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3809, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3713, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4049, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3992, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3754, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3865, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3981, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3750, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3802, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3886, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3907, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3837, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3694, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3925, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3882, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3766, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3782, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3723, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3959, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3710, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4047, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3892, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3870, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3926, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3785, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3960, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3965, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3897, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3764, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4002, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3789, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4041, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4087, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3597, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3910, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4075, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3727, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3850, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3836, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3946, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3764, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3896, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3838, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3945, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3982, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4018, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3864, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3858, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4070, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3778, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4147, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3801, device='cuda:0', grad_fn=<AddBackward0>)
The 64 training average loss: 0.38760854355220137
2025-11-22 22:24:06 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:24:06 - GraphTrainer - INFO -   precision@5: 0.005554
2025-11-22 22:24:06 - GraphTrainer - INFO -   recall@5: 0.026542
2025-11-22 22:24:06 - GraphTrainer - INFO -   hit_rate@5: 0.027719
2025-11-22 22:24:06 - GraphTrainer - INFO -   ndcg@5: 0.017923
2025-11-22 22:24:06 - GraphTrainer - INFO -   map@5: 0.014894
2025-11-22 22:24:06 - GraphTrainer - INFO -   mrr@5: 0.015479
2025-11-22 22:24:06 - GraphTrainer - INFO -   precision@10: 0.004500
2025-11-22 22:24:06 - GraphTrainer - INFO -   recall@10: 0.042621
2025-11-22 22:24:06 - GraphTrainer - INFO -   hit_rate@10: 0.044793
2025-11-22 22:24:06 - GraphTrainer - INFO -   ndcg@10: 0.023108
2025-11-22 22:24:06 - GraphTrainer - INFO -   map@10: 0.016962
2025-11-22 22:24:06 - GraphTrainer - INFO -   mrr@10: 0.017678
2025-11-22 22:24:06 - GraphTrainer - INFO -   precision@20: 0.003749
2025-11-22 22:24:06 - GraphTrainer - INFO -   recall@20: 0.070842
2025-11-22 22:24:06 - GraphTrainer - INFO -   hit_rate@20: 0.074621
2025-11-22 22:24:06 - GraphTrainer - INFO -   ndcg@20: 0.030276
2025-11-22 22:24:06 - GraphTrainer - INFO -   map@20: 0.018875
2025-11-22 22:24:06 - GraphTrainer - INFO -   mrr@20: 0.019700
2025-11-22 22:24:06 - GraphTrainer - INFO - 第 65 轮训练完成
2025-11-22 22:24:06 - GraphTrainer - INFO - train_loss: 0.387589
2025-11-22 22:24:06 - GraphTrainer - INFO - precision@5: 0.005554
2025-11-22 22:24:06 - GraphTrainer - INFO - recall@5: 0.026542
2025-11-22 22:24:06 - GraphTrainer - INFO - hit_rate@5: 0.027719
2025-11-22 22:24:06 - GraphTrainer - INFO - ndcg@5: 0.017923
2025-11-22 22:24:06 - GraphTrainer - INFO - map@5: 0.014894
2025-11-22 22:24:06 - GraphTrainer - INFO - mrr@5: 0.015479
2025-11-22 22:24:06 - GraphTrainer - INFO - precision@10: 0.004500
2025-11-22 22:24:06 - GraphTrainer - INFO - recall@10: 0.042621
2025-11-22 22:24:06 - GraphTrainer - INFO - hit_rate@10: 0.044793
2025-11-22 22:24:06 - GraphTrainer - INFO - ndcg@10: 0.023108
2025-11-22 22:24:06 - GraphTrainer - INFO - map@10: 0.016962
2025-11-22 22:24:06 - GraphTrainer - INFO - mrr@10: 0.017678
2025-11-22 22:24:06 - GraphTrainer - INFO - precision@20: 0.003749
2025-11-22 22:24:06 - GraphTrainer - INFO - recall@20: 0.070842
2025-11-22 22:24:06 - GraphTrainer - INFO - hit_rate@20: 0.074621
2025-11-22 22:24:06 - GraphTrainer - INFO - ndcg@20: 0.030276
2025-11-22 22:24:06 - GraphTrainer - INFO - map@20: 0.018875
2025-11-22 22:24:06 - GraphTrainer - INFO - mrr@20: 0.019700
2025-11-22 22:24:06 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:24:06 - GraphTrainer - INFO - ============================================================
2025-11-22 22:24:06 - GraphTrainer - INFO - 开始第 66/1000 轮训练
2025-11-22 22:24:06 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3778, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3983, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3832, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3729, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3744, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4019, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3680, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3915, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3690, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3812, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4072, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3994, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3717, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3986, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3684, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3722, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3819, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3855, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3830, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3836, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3800, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4003, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3755, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3996, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4050, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3830, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4207, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3876, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3945, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3744, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3662, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3739, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3793, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3993, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4095, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3897, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4018, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4129, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3877, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3741, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3801, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3826, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4050, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3900, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3826, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3888, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3938, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3833, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3986, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3842, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3980, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3918, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4066, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3663, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3896, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3989, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3936, device='cuda:0', grad_fn=<AddBackward0>)
The 65 training average loss: 0.3875885898696965
2025-11-22 22:24:17 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:24:17 - GraphTrainer - INFO -   precision@5: 0.005636
2025-11-22 22:24:17 - GraphTrainer - INFO -   recall@5: 0.026782
2025-11-22 22:24:17 - GraphTrainer - INFO -   hit_rate@5: 0.028131
2025-11-22 22:24:17 - GraphTrainer - INFO -   ndcg@5: 0.017249
2025-11-22 22:24:17 - GraphTrainer - INFO -   map@5: 0.013899
2025-11-22 22:24:17 - GraphTrainer - INFO -   mrr@5: 0.014557
2025-11-22 22:24:17 - GraphTrainer - INFO -   precision@10: 0.004731
2025-11-22 22:24:17 - GraphTrainer - INFO -   recall@10: 0.044599
2025-11-22 22:24:17 - GraphTrainer - INFO -   hit_rate@10: 0.047107
2025-11-22 22:24:17 - GraphTrainer - INFO -   ndcg@10: 0.023052
2025-11-22 22:24:17 - GraphTrainer - INFO -   map@10: 0.016246
2025-11-22 22:24:17 - GraphTrainer - INFO -   mrr@10: 0.017053
2025-11-22 22:24:17 - GraphTrainer - INFO -   precision@20: 0.003770
2025-11-22 22:24:17 - GraphTrainer - INFO -   recall@20: 0.070964
2025-11-22 22:24:17 - GraphTrainer - INFO -   hit_rate@20: 0.074929
2025-11-22 22:24:17 - GraphTrainer - INFO -   ndcg@20: 0.029770
2025-11-22 22:24:17 - GraphTrainer - INFO -   map@20: 0.018052
2025-11-22 22:24:17 - GraphTrainer - INFO -   mrr@20: 0.018953
2025-11-22 22:24:17 - GraphTrainer - INFO - 第 66 轮训练完成
2025-11-22 22:24:17 - GraphTrainer - INFO - train_loss: 0.388639
2025-11-22 22:24:17 - GraphTrainer - INFO - precision@5: 0.005636
2025-11-22 22:24:17 - GraphTrainer - INFO - recall@5: 0.026782
2025-11-22 22:24:17 - GraphTrainer - INFO - hit_rate@5: 0.028131
2025-11-22 22:24:17 - GraphTrainer - INFO - ndcg@5: 0.017249
2025-11-22 22:24:17 - GraphTrainer - INFO - map@5: 0.013899
2025-11-22 22:24:17 - GraphTrainer - INFO - mrr@5: 0.014557
2025-11-22 22:24:17 - GraphTrainer - INFO - precision@10: 0.004731
2025-11-22 22:24:17 - GraphTrainer - INFO - recall@10: 0.044599
2025-11-22 22:24:17 - GraphTrainer - INFO - hit_rate@10: 0.047107
2025-11-22 22:24:17 - GraphTrainer - INFO - ndcg@10: 0.023052
2025-11-22 22:24:17 - GraphTrainer - INFO - map@10: 0.016246
2025-11-22 22:24:17 - GraphTrainer - INFO - mrr@10: 0.017053
2025-11-22 22:24:17 - GraphTrainer - INFO - precision@20: 0.003770
2025-11-22 22:24:17 - GraphTrainer - INFO - recall@20: 0.070964
2025-11-22 22:24:17 - GraphTrainer - INFO - hit_rate@20: 0.074929
2025-11-22 22:24:17 - GraphTrainer - INFO - ndcg@20: 0.029770
2025-11-22 22:24:17 - GraphTrainer - INFO - map@20: 0.018052
2025-11-22 22:24:17 - GraphTrainer - INFO - mrr@20: 0.018953
2025-11-22 22:24:17 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:24:17 - GraphTrainer - INFO - ============================================================
2025-11-22 22:24:17 - GraphTrainer - INFO - 开始第 67/1000 轮训练
2025-11-22 22:24:17 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4047, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3951, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3845, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3707, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3864, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3868, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3909, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3849, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4061, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3862, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3771, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3946, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3768, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3848, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3855, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3928, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3957, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3622, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3798, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3781, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3857, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3824, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3806, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3814, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4004, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3657, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3986, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3963, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3836, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3994, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3699, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3837, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3841, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3827, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4162, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4051, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3973, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4029, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3799, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4069, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3703, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3785, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3858, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4086, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4177, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4088, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3844, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3854, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4220, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3727, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3927, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3806, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3933, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3993, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3832, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3696, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3809, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3805, device='cuda:0', grad_fn=<AddBackward0>)
The 66 training average loss: 0.38863904054822596
2025-11-22 22:24:29 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:24:29 - GraphTrainer - INFO -   precision@5: 0.005811
2025-11-22 22:24:29 - GraphTrainer - INFO -   recall@5: 0.027536
2025-11-22 22:24:29 - GraphTrainer - INFO -   hit_rate@5: 0.028953
2025-11-22 22:24:29 - GraphTrainer - INFO -   ndcg@5: 0.017893
2025-11-22 22:24:29 - GraphTrainer - INFO -   map@5: 0.014489
2025-11-22 22:24:29 - GraphTrainer - INFO -   mrr@5: 0.015187
2025-11-22 22:24:29 - GraphTrainer - INFO -   precision@10: 0.004587
2025-11-22 22:24:29 - GraphTrainer - INFO -   recall@10: 0.043423
2025-11-22 22:24:29 - GraphTrainer - INFO -   hit_rate@10: 0.045719
2025-11-22 22:24:29 - GraphTrainer - INFO -   ndcg@10: 0.023016
2025-11-22 22:24:29 - GraphTrainer - INFO -   map@10: 0.016544
2025-11-22 22:24:29 - GraphTrainer - INFO -   mrr@10: 0.017349
2025-11-22 22:24:29 - GraphTrainer - INFO -   precision@20: 0.003785
2025-11-22 22:24:29 - GraphTrainer - INFO -   recall@20: 0.071536
2025-11-22 22:24:29 - GraphTrainer - INFO -   hit_rate@20: 0.075392
2025-11-22 22:24:29 - GraphTrainer - INFO -   ndcg@20: 0.030114
2025-11-22 22:24:29 - GraphTrainer - INFO -   map@20: 0.018421
2025-11-22 22:24:29 - GraphTrainer - INFO -   mrr@20: 0.019325
2025-11-22 22:24:29 - GraphTrainer - INFO - 第 67 轮训练完成
2025-11-22 22:24:29 - GraphTrainer - INFO - train_loss: 0.387169
2025-11-22 22:24:29 - GraphTrainer - INFO - precision@5: 0.005811
2025-11-22 22:24:29 - GraphTrainer - INFO - recall@5: 0.027536
2025-11-22 22:24:29 - GraphTrainer - INFO - hit_rate@5: 0.028953
2025-11-22 22:24:29 - GraphTrainer - INFO - ndcg@5: 0.017893
2025-11-22 22:24:29 - GraphTrainer - INFO - map@5: 0.014489
2025-11-22 22:24:29 - GraphTrainer - INFO - mrr@5: 0.015187
2025-11-22 22:24:29 - GraphTrainer - INFO - precision@10: 0.004587
2025-11-22 22:24:29 - GraphTrainer - INFO - recall@10: 0.043423
2025-11-22 22:24:29 - GraphTrainer - INFO - hit_rate@10: 0.045719
2025-11-22 22:24:29 - GraphTrainer - INFO - ndcg@10: 0.023016
2025-11-22 22:24:29 - GraphTrainer - INFO - map@10: 0.016544
2025-11-22 22:24:29 - GraphTrainer - INFO - mrr@10: 0.017349
2025-11-22 22:24:29 - GraphTrainer - INFO - precision@20: 0.003785
2025-11-22 22:24:29 - GraphTrainer - INFO - recall@20: 0.071536
2025-11-22 22:24:29 - GraphTrainer - INFO - hit_rate@20: 0.075392
2025-11-22 22:24:29 - GraphTrainer - INFO - ndcg@20: 0.030114
2025-11-22 22:24:29 - GraphTrainer - INFO - map@20: 0.018421
2025-11-22 22:24:29 - GraphTrainer - INFO - mrr@20: 0.019325
2025-11-22 22:24:29 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:24:29 - GraphTrainer - INFO - ============================================================
2025-11-22 22:24:29 - GraphTrainer - INFO - 开始第 68/1000 轮训练
2025-11-22 22:24:29 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4060, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3868, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4013, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4009, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3973, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3703, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3874, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3775, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3737, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3970, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3936, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3885, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4044, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3772, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3819, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4122, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3980, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3807, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3819, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3925, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3895, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3922, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3885, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3940, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3938, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3776, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3662, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3784, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3719, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3907, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3805, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3917, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4004, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3805, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3742, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3730, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4129, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3903, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4099, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3855, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3788, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3894, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3773, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3816, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3688, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3874, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3925, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3775, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3856, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4039, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3899, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3949, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3677, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3941, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3912, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3960, device='cuda:0', grad_fn=<AddBackward0>)
The 67 training average loss: 0.38716905384228145
2025-11-22 22:24:40 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:24:40 - GraphTrainer - INFO -   precision@5: 0.005657
2025-11-22 22:24:40 - GraphTrainer - INFO -   recall@5: 0.026882
2025-11-22 22:24:40 - GraphTrainer - INFO -   hit_rate@5: 0.028233
2025-11-22 22:24:40 - GraphTrainer - INFO -   ndcg@5: 0.017611
2025-11-22 22:24:40 - GraphTrainer - INFO -   map@5: 0.014335
2025-11-22 22:24:40 - GraphTrainer - INFO -   mrr@5: 0.014992
2025-11-22 22:24:40 - GraphTrainer - INFO -   precision@10: 0.004459
2025-11-22 22:24:40 - GraphTrainer - INFO -   recall@10: 0.042314
2025-11-22 22:24:40 - GraphTrainer - INFO -   hit_rate@10: 0.044484
2025-11-22 22:24:40 - GraphTrainer - INFO -   ndcg@10: 0.022625
2025-11-22 22:24:40 - GraphTrainer - INFO -   map@10: 0.016366
2025-11-22 22:24:40 - GraphTrainer - INFO -   mrr@10: 0.017133
2025-11-22 22:24:40 - GraphTrainer - INFO -   precision@20: 0.003692
2025-11-22 22:24:40 - GraphTrainer - INFO -   recall@20: 0.070186
2025-11-22 22:24:40 - GraphTrainer - INFO -   hit_rate@20: 0.073592
2025-11-22 22:24:40 - GraphTrainer - INFO -   ndcg@20: 0.029676
2025-11-22 22:24:40 - GraphTrainer - INFO -   map@20: 0.018252
2025-11-22 22:24:40 - GraphTrainer - INFO -   mrr@20: 0.019096
2025-11-22 22:24:40 - GraphTrainer - INFO - 第 68 轮训练完成
2025-11-22 22:24:40 - GraphTrainer - INFO - train_loss: 0.384092
2025-11-22 22:24:40 - GraphTrainer - INFO - precision@5: 0.005657
2025-11-22 22:24:40 - GraphTrainer - INFO - recall@5: 0.026882
2025-11-22 22:24:40 - GraphTrainer - INFO - hit_rate@5: 0.028233
2025-11-22 22:24:40 - GraphTrainer - INFO - ndcg@5: 0.017611
2025-11-22 22:24:40 - GraphTrainer - INFO - map@5: 0.014335
2025-11-22 22:24:40 - GraphTrainer - INFO - mrr@5: 0.014992
2025-11-22 22:24:40 - GraphTrainer - INFO - precision@10: 0.004459
2025-11-22 22:24:40 - GraphTrainer - INFO - recall@10: 0.042314
2025-11-22 22:24:40 - GraphTrainer - INFO - hit_rate@10: 0.044484
2025-11-22 22:24:40 - GraphTrainer - INFO - ndcg@10: 0.022625
2025-11-22 22:24:40 - GraphTrainer - INFO - map@10: 0.016366
2025-11-22 22:24:40 - GraphTrainer - INFO - mrr@10: 0.017133
2025-11-22 22:24:40 - GraphTrainer - INFO - precision@20: 0.003692
2025-11-22 22:24:40 - GraphTrainer - INFO - recall@20: 0.070186
2025-11-22 22:24:40 - GraphTrainer - INFO - hit_rate@20: 0.073592
2025-11-22 22:24:40 - GraphTrainer - INFO - ndcg@20: 0.029676
2025-11-22 22:24:40 - GraphTrainer - INFO - map@20: 0.018252
2025-11-22 22:24:40 - GraphTrainer - INFO - mrr@20: 0.019096
2025-11-22 22:24:40 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:24:40 - GraphTrainer - INFO - ============================================================
2025-11-22 22:24:40 - GraphTrainer - INFO - 开始第 69/1000 轮训练
2025-11-22 22:24:40 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3948, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4104, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3776, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3784, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3871, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4032, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3792, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3898, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3739, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3653, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3933, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3973, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4006, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3558, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3844, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3816, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3636, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3918, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3835, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3753, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3782, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3696, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3968, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3788, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3865, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3992, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3782, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3916, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4026, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3928, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3760, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3607, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4046, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3897, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3941, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3925, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3792, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3622, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3787, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3833, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3874, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3801, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3901, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4125, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3892, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3755, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3763, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3979, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3766, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3960, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3953, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3708, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3649, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3982, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3849, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3885, device='cuda:0', grad_fn=<AddBackward0>)
The 68 training average loss: 0.38409187362111846
2025-11-22 22:24:51 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:24:51 - GraphTrainer - INFO -   precision@5: 0.005585
2025-11-22 22:24:51 - GraphTrainer - INFO -   recall@5: 0.026760
2025-11-22 22:24:51 - GraphTrainer - INFO -   hit_rate@5: 0.027925
2025-11-22 22:24:51 - GraphTrainer - INFO -   ndcg@5: 0.017725
2025-11-22 22:24:51 - GraphTrainer - INFO -   map@5: 0.014580
2025-11-22 22:24:51 - GraphTrainer - INFO -   mrr@5: 0.015128
2025-11-22 22:24:51 - GraphTrainer - INFO -   precision@10: 0.004536
2025-11-22 22:24:51 - GraphTrainer - INFO -   recall@10: 0.043107
2025-11-22 22:24:51 - GraphTrainer - INFO -   hit_rate@10: 0.045204
2025-11-22 22:24:51 - GraphTrainer - INFO -   ndcg@10: 0.023029
2025-11-22 22:24:51 - GraphTrainer - INFO -   map@10: 0.016716
2025-11-22 22:24:51 - GraphTrainer - INFO -   mrr@10: 0.017377
2025-11-22 22:24:51 - GraphTrainer - INFO -   precision@20: 0.003726
2025-11-22 22:24:51 - GraphTrainer - INFO -   recall@20: 0.070696
2025-11-22 22:24:51 - GraphTrainer - INFO -   hit_rate@20: 0.074055
2025-11-22 22:24:51 - GraphTrainer - INFO -   ndcg@20: 0.030042
2025-11-22 22:24:51 - GraphTrainer - INFO -   map@20: 0.018603
2025-11-22 22:24:51 - GraphTrainer - INFO -   mrr@20: 0.019343
2025-11-22 22:24:51 - GraphTrainer - INFO - 第 69 轮训练完成
2025-11-22 22:24:51 - GraphTrainer - INFO - train_loss: 0.383402
2025-11-22 22:24:51 - GraphTrainer - INFO - precision@5: 0.005585
2025-11-22 22:24:51 - GraphTrainer - INFO - recall@5: 0.026760
2025-11-22 22:24:51 - GraphTrainer - INFO - hit_rate@5: 0.027925
2025-11-22 22:24:51 - GraphTrainer - INFO - ndcg@5: 0.017725
2025-11-22 22:24:51 - GraphTrainer - INFO - map@5: 0.014580
2025-11-22 22:24:51 - GraphTrainer - INFO - mrr@5: 0.015128
2025-11-22 22:24:51 - GraphTrainer - INFO - precision@10: 0.004536
2025-11-22 22:24:51 - GraphTrainer - INFO - recall@10: 0.043107
2025-11-22 22:24:51 - GraphTrainer - INFO - hit_rate@10: 0.045204
2025-11-22 22:24:51 - GraphTrainer - INFO - ndcg@10: 0.023029
2025-11-22 22:24:51 - GraphTrainer - INFO - map@10: 0.016716
2025-11-22 22:24:51 - GraphTrainer - INFO - mrr@10: 0.017377
2025-11-22 22:24:51 - GraphTrainer - INFO - precision@20: 0.003726
2025-11-22 22:24:51 - GraphTrainer - INFO - recall@20: 0.070696
2025-11-22 22:24:51 - GraphTrainer - INFO - hit_rate@20: 0.074055
2025-11-22 22:24:51 - GraphTrainer - INFO - ndcg@20: 0.030042
2025-11-22 22:24:51 - GraphTrainer - INFO - map@20: 0.018603
2025-11-22 22:24:51 - GraphTrainer - INFO - mrr@20: 0.019343
2025-11-22 22:24:51 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:24:51 - GraphTrainer - INFO - ============================================================
2025-11-22 22:24:51 - GraphTrainer - INFO - 开始第 70/1000 轮训练
2025-11-22 22:24:51 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3722, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3913, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3961, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3694, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3907, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3822, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3888, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3870, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3940, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4082, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3911, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3908, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3969, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3811, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3723, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4083, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3845, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3807, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3694, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4212, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3758, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4033, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3855, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3903, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4118, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3539, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3649, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3831, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3687, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3762, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3873, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3916, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3751, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3737, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3786, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3764, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3718, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3821, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3798, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3954, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3796, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3944, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3918, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3895, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3705, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3729, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3917, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3914, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3815, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3779, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3625, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3780, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3904, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3823, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3830, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3654, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3790, device='cuda:0', grad_fn=<AddBackward0>)
The 69 training average loss: 0.3834015475264911
2025-11-22 22:25:02 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:25:02 - GraphTrainer - INFO -   precision@5: 0.005575
2025-11-22 22:25:02 - GraphTrainer - INFO -   recall@5: 0.026811
2025-11-22 22:25:02 - GraphTrainer - INFO -   hit_rate@5: 0.027873
2025-11-22 22:25:02 - GraphTrainer - INFO -   ndcg@5: 0.017278
2025-11-22 22:25:02 - GraphTrainer - INFO -   map@5: 0.013986
2025-11-22 22:25:02 - GraphTrainer - INFO -   mrr@5: 0.014467
2025-11-22 22:25:02 - GraphTrainer - INFO -   precision@10: 0.004670
2025-11-22 22:25:02 - GraphTrainer - INFO -   recall@10: 0.044482
2025-11-22 22:25:02 - GraphTrainer - INFO -   hit_rate@10: 0.046644
2025-11-22 22:25:02 - GraphTrainer - INFO -   ndcg@10: 0.023066
2025-11-22 22:25:02 - GraphTrainer - INFO -   map@10: 0.016350
2025-11-22 22:25:02 - GraphTrainer - INFO -   mrr@10: 0.016970
2025-11-22 22:25:02 - GraphTrainer - INFO -   precision@20: 0.003690
2025-11-22 22:25:02 - GraphTrainer - INFO -   recall@20: 0.070229
2025-11-22 22:25:02 - GraphTrainer - INFO -   hit_rate@20: 0.073438
2025-11-22 22:25:02 - GraphTrainer - INFO -   ndcg@20: 0.029601
2025-11-22 22:25:02 - GraphTrainer - INFO -   map@20: 0.018107
2025-11-22 22:25:02 - GraphTrainer - INFO -   mrr@20: 0.018796
2025-11-22 22:25:02 - GraphTrainer - INFO - 第 70 轮训练完成
2025-11-22 22:25:02 - GraphTrainer - INFO - train_loss: 0.384896
2025-11-22 22:25:02 - GraphTrainer - INFO - precision@5: 0.005575
2025-11-22 22:25:02 - GraphTrainer - INFO - recall@5: 0.026811
2025-11-22 22:25:02 - GraphTrainer - INFO - hit_rate@5: 0.027873
2025-11-22 22:25:02 - GraphTrainer - INFO - ndcg@5: 0.017278
2025-11-22 22:25:02 - GraphTrainer - INFO - map@5: 0.013986
2025-11-22 22:25:02 - GraphTrainer - INFO - mrr@5: 0.014467
2025-11-22 22:25:02 - GraphTrainer - INFO - precision@10: 0.004670
2025-11-22 22:25:02 - GraphTrainer - INFO - recall@10: 0.044482
2025-11-22 22:25:02 - GraphTrainer - INFO - hit_rate@10: 0.046644
2025-11-22 22:25:02 - GraphTrainer - INFO - ndcg@10: 0.023066
2025-11-22 22:25:02 - GraphTrainer - INFO - map@10: 0.016350
2025-11-22 22:25:02 - GraphTrainer - INFO - mrr@10: 0.016970
2025-11-22 22:25:02 - GraphTrainer - INFO - precision@20: 0.003690
2025-11-22 22:25:02 - GraphTrainer - INFO - recall@20: 0.070229
2025-11-22 22:25:02 - GraphTrainer - INFO - hit_rate@20: 0.073438
2025-11-22 22:25:02 - GraphTrainer - INFO - ndcg@20: 0.029601
2025-11-22 22:25:02 - GraphTrainer - INFO - map@20: 0.018107
2025-11-22 22:25:02 - GraphTrainer - INFO - mrr@20: 0.018796
2025-11-22 22:25:02 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:25:02 - GraphTrainer - INFO - 检查点已保存: Epoch 70 -> ./checkpoints/checkpoint_epoch_70.pth
2025-11-22 22:25:02 - GraphTrainer - INFO - ============================================================
2025-11-22 22:25:02 - GraphTrainer - INFO - 开始第 71/1000 轮训练
2025-11-22 22:25:02 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3617, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3827, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3818, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3662, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3938, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3956, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3865, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3786, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4142, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3990, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3857, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3942, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4038, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3964, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4033, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3764, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3643, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3718, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4069, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3962, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3770, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3637, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4024, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3661, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3906, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3842, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3795, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4056, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3962, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3796, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3905, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4021, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3903, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3674, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3857, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3625, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3668, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4022, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3815, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3716, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3698, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4144, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3805, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3996, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3676, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3665, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3705, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3775, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4093, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3822, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3754, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3933, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3782, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4017, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3631, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3924, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3846, device='cuda:0', grad_fn=<AddBackward0>)
The 70 training average loss: 0.38489564174208146
2025-11-22 22:25:13 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:25:13 - GraphTrainer - INFO -   precision@5: 0.005719
2025-11-22 22:25:13 - GraphTrainer - INFO -   recall@5: 0.027474
2025-11-22 22:25:13 - GraphTrainer - INFO -   hit_rate@5: 0.028542
2025-11-22 22:25:13 - GraphTrainer - INFO -   ndcg@5: 0.018326
2025-11-22 22:25:13 - GraphTrainer - INFO -   map@5: 0.015144
2025-11-22 22:25:13 - GraphTrainer - INFO -   mrr@5: 0.015654
2025-11-22 22:25:13 - GraphTrainer - INFO -   precision@10: 0.004726
2025-11-22 22:25:13 - GraphTrainer - INFO -   recall@10: 0.045077
2025-11-22 22:25:13 - GraphTrainer - INFO -   hit_rate@10: 0.047210
2025-11-22 22:25:13 - GraphTrainer - INFO -   ndcg@10: 0.024000
2025-11-22 22:25:13 - GraphTrainer - INFO -   map@10: 0.017410
2025-11-22 22:25:13 - GraphTrainer - INFO -   mrr@10: 0.018053
2025-11-22 22:25:13 - GraphTrainer - INFO -   precision@20: 0.003777
2025-11-22 22:25:13 - GraphTrainer - INFO -   recall@20: 0.071489
2025-11-22 22:25:13 - GraphTrainer - INFO -   hit_rate@20: 0.075135
2025-11-22 22:25:13 - GraphTrainer - INFO -   ndcg@20: 0.030723
2025-11-22 22:25:13 - GraphTrainer - INFO -   map@20: 0.019211
2025-11-22 22:25:13 - GraphTrainer - INFO -   mrr@20: 0.019946
2025-11-22 22:25:13 - GraphTrainer - INFO - 第 71 轮训练完成
2025-11-22 22:25:13 - GraphTrainer - INFO - train_loss: 0.382028
2025-11-22 22:25:13 - GraphTrainer - INFO - precision@5: 0.005719
2025-11-22 22:25:13 - GraphTrainer - INFO - recall@5: 0.027474
2025-11-22 22:25:13 - GraphTrainer - INFO - hit_rate@5: 0.028542
2025-11-22 22:25:13 - GraphTrainer - INFO - ndcg@5: 0.018326
2025-11-22 22:25:13 - GraphTrainer - INFO - map@5: 0.015144
2025-11-22 22:25:13 - GraphTrainer - INFO - mrr@5: 0.015654
2025-11-22 22:25:13 - GraphTrainer - INFO - precision@10: 0.004726
2025-11-22 22:25:13 - GraphTrainer - INFO - recall@10: 0.045077
2025-11-22 22:25:13 - GraphTrainer - INFO - hit_rate@10: 0.047210
2025-11-22 22:25:13 - GraphTrainer - INFO - ndcg@10: 0.024000
2025-11-22 22:25:13 - GraphTrainer - INFO - map@10: 0.017410
2025-11-22 22:25:13 - GraphTrainer - INFO - mrr@10: 0.018053
2025-11-22 22:25:13 - GraphTrainer - INFO - precision@20: 0.003777
2025-11-22 22:25:13 - GraphTrainer - INFO - recall@20: 0.071489
2025-11-22 22:25:13 - GraphTrainer - INFO - hit_rate@20: 0.075135
2025-11-22 22:25:13 - GraphTrainer - INFO - ndcg@20: 0.030723
2025-11-22 22:25:13 - GraphTrainer - INFO - map@20: 0.019211
2025-11-22 22:25:13 - GraphTrainer - INFO - mrr@20: 0.019946
2025-11-22 22:25:13 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:25:13 - GraphTrainer - INFO - ============================================================
2025-11-22 22:25:13 - GraphTrainer - INFO - 开始第 72/1000 轮训练
2025-11-22 22:25:13 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3708, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3802, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3545, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3901, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3718, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3765, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3984, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3960, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3754, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3764, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3959, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3797, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3811, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3762, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3691, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3784, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3814, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3733, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3867, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3852, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3911, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3635, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4003, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3842, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3996, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3816, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4010, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3752, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3956, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3852, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3837, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3906, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3790, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3823, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3690, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3869, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3919, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3858, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3763, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4043, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3706, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3666, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3805, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3856, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3897, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3892, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3837, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4054, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3863, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3727, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3819, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3874, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3669, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3722, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3924, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3864, device='cuda:0', grad_fn=<AddBackward0>)
The 71 training average loss: 0.3820280931119261
2025-11-22 22:25:25 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:25:25 - GraphTrainer - INFO -   precision@5: 0.005935
2025-11-22 22:25:25 - GraphTrainer - INFO -   recall@5: 0.028169
2025-11-22 22:25:25 - GraphTrainer - INFO -   hit_rate@5: 0.029571
2025-11-22 22:25:25 - GraphTrainer - INFO -   ndcg@5: 0.018611
2025-11-22 22:25:25 - GraphTrainer - INFO -   map@5: 0.015231
2025-11-22 22:25:25 - GraphTrainer - INFO -   mrr@5: 0.015863
2025-11-22 22:25:25 - GraphTrainer - INFO -   precision@10: 0.004911
2025-11-22 22:25:25 - GraphTrainer - INFO -   recall@10: 0.046579
2025-11-22 22:25:25 - GraphTrainer - INFO -   hit_rate@10: 0.048959
2025-11-22 22:25:25 - GraphTrainer - INFO -   ndcg@10: 0.024583
2025-11-22 22:25:25 - GraphTrainer - INFO -   map@10: 0.017648
2025-11-22 22:25:25 - GraphTrainer - INFO -   mrr@10: 0.018402
2025-11-22 22:25:25 - GraphTrainer - INFO -   precision@20: 0.003829
2025-11-22 22:25:25 - GraphTrainer - INFO -   recall@20: 0.072500
2025-11-22 22:25:25 - GraphTrainer - INFO -   hit_rate@20: 0.076164
2025-11-22 22:25:25 - GraphTrainer - INFO -   ndcg@20: 0.031164
2025-11-22 22:25:25 - GraphTrainer - INFO -   map@20: 0.019409
2025-11-22 22:25:25 - GraphTrainer - INFO -   mrr@20: 0.020243
2025-11-22 22:25:25 - GraphTrainer - INFO - 第 72 轮训练完成
2025-11-22 22:25:25 - GraphTrainer - INFO - train_loss: 0.380394
2025-11-22 22:25:25 - GraphTrainer - INFO - precision@5: 0.005935
2025-11-22 22:25:25 - GraphTrainer - INFO - recall@5: 0.028169
2025-11-22 22:25:25 - GraphTrainer - INFO - hit_rate@5: 0.029571
2025-11-22 22:25:25 - GraphTrainer - INFO - ndcg@5: 0.018611
2025-11-22 22:25:25 - GraphTrainer - INFO - map@5: 0.015231
2025-11-22 22:25:25 - GraphTrainer - INFO - mrr@5: 0.015863
2025-11-22 22:25:25 - GraphTrainer - INFO - precision@10: 0.004911
2025-11-22 22:25:25 - GraphTrainer - INFO - recall@10: 0.046579
2025-11-22 22:25:25 - GraphTrainer - INFO - hit_rate@10: 0.048959
2025-11-22 22:25:25 - GraphTrainer - INFO - ndcg@10: 0.024583
2025-11-22 22:25:25 - GraphTrainer - INFO - map@10: 0.017648
2025-11-22 22:25:25 - GraphTrainer - INFO - mrr@10: 0.018402
2025-11-22 22:25:25 - GraphTrainer - INFO - precision@20: 0.003829
2025-11-22 22:25:25 - GraphTrainer - INFO - recall@20: 0.072500
2025-11-22 22:25:25 - GraphTrainer - INFO - hit_rate@20: 0.076164
2025-11-22 22:25:25 - GraphTrainer - INFO - ndcg@20: 0.031164
2025-11-22 22:25:25 - GraphTrainer - INFO - map@20: 0.019409
2025-11-22 22:25:25 - GraphTrainer - INFO - mrr@20: 0.020243
2025-11-22 22:25:25 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:25:25 - GraphTrainer - INFO - ============================================================
2025-11-22 22:25:25 - GraphTrainer - INFO - 开始第 73/1000 轮训练
2025-11-22 22:25:25 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3835, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3663, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3880, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3986, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4080, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3645, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3668, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3918, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3874, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3784, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3704, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4020, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3696, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3890, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3842, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4041, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3766, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3871, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3636, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3888, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3624, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4021, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3832, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3914, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3885, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3666, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4067, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3749, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3750, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3794, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3652, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3816, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3479, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3736, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3674, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3848, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3661, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3776, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3706, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3663, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3821, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3975, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4134, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3638, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4022, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3785, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3716, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3861, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3801, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3576, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3835, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3742, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3913, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3982, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3890, device='cuda:0', grad_fn=<AddBackward0>)
The 72 training average loss: 0.380394348810459
2025-11-22 22:25:36 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:25:36 - GraphTrainer - INFO -   precision@5: 0.005534
2025-11-22 22:25:36 - GraphTrainer - INFO -   recall@5: 0.026345
2025-11-22 22:25:36 - GraphTrainer - INFO -   hit_rate@5: 0.027616
2025-11-22 22:25:36 - GraphTrainer - INFO -   ndcg@5: 0.016723
2025-11-22 22:25:36 - GraphTrainer - INFO -   map@5: 0.013373
2025-11-22 22:25:36 - GraphTrainer - INFO -   mrr@5: 0.013973
2025-11-22 22:25:36 - GraphTrainer - INFO -   precision@10: 0.004562
2025-11-22 22:25:36 - GraphTrainer - INFO -   recall@10: 0.043481
2025-11-22 22:25:36 - GraphTrainer - INFO -   hit_rate@10: 0.045564
2025-11-22 22:25:36 - GraphTrainer - INFO -   ndcg@10: 0.022274
2025-11-22 22:25:36 - GraphTrainer - INFO -   map@10: 0.015622
2025-11-22 22:25:36 - GraphTrainer - INFO -   mrr@10: 0.016334
2025-11-22 22:25:36 - GraphTrainer - INFO -   precision@20: 0.003638
2025-11-22 22:25:36 - GraphTrainer - INFO -   recall@20: 0.068781
2025-11-22 22:25:36 - GraphTrainer - INFO -   hit_rate@20: 0.072255
2025-11-22 22:25:36 - GraphTrainer - INFO -   ndcg@20: 0.028751
2025-11-22 22:25:36 - GraphTrainer - INFO -   map@20: 0.017373
2025-11-22 22:25:36 - GraphTrainer - INFO -   mrr@20: 0.018175
2025-11-22 22:25:36 - GraphTrainer - INFO - 第 73 轮训练完成
2025-11-22 22:25:36 - GraphTrainer - INFO - train_loss: 0.380433
2025-11-22 22:25:36 - GraphTrainer - INFO - precision@5: 0.005534
2025-11-22 22:25:36 - GraphTrainer - INFO - recall@5: 0.026345
2025-11-22 22:25:36 - GraphTrainer - INFO - hit_rate@5: 0.027616
2025-11-22 22:25:36 - GraphTrainer - INFO - ndcg@5: 0.016723
2025-11-22 22:25:36 - GraphTrainer - INFO - map@5: 0.013373
2025-11-22 22:25:36 - GraphTrainer - INFO - mrr@5: 0.013973
2025-11-22 22:25:36 - GraphTrainer - INFO - precision@10: 0.004562
2025-11-22 22:25:36 - GraphTrainer - INFO - recall@10: 0.043481
2025-11-22 22:25:36 - GraphTrainer - INFO - hit_rate@10: 0.045564
2025-11-22 22:25:36 - GraphTrainer - INFO - ndcg@10: 0.022274
2025-11-22 22:25:36 - GraphTrainer - INFO - map@10: 0.015622
2025-11-22 22:25:36 - GraphTrainer - INFO - mrr@10: 0.016334
2025-11-22 22:25:36 - GraphTrainer - INFO - precision@20: 0.003638
2025-11-22 22:25:36 - GraphTrainer - INFO - recall@20: 0.068781
2025-11-22 22:25:36 - GraphTrainer - INFO - hit_rate@20: 0.072255
2025-11-22 22:25:36 - GraphTrainer - INFO - ndcg@20: 0.028751
2025-11-22 22:25:36 - GraphTrainer - INFO - map@20: 0.017373
2025-11-22 22:25:36 - GraphTrainer - INFO - mrr@20: 0.018175
2025-11-22 22:25:36 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:25:36 - GraphTrainer - INFO - ============================================================
2025-11-22 22:25:36 - GraphTrainer - INFO - 开始第 74/1000 轮训练
2025-11-22 22:25:36 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3946, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3753, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3695, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3954, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3745, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3881, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3802, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3736, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3907, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3671, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3906, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3737, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3971, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4010, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3763, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4050, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4017, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3797, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3699, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3753, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3634, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3790, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3690, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3903, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3592, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3599, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3861, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3878, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3805, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3726, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3849, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3864, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3860, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3801, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3653, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4130, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3728, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3774, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3707, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3695, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3925, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3687, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3849, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4038, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4035, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4063, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3755, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3784, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3904, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3703, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3731, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3844, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3821, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3846, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3909, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
The 73 training average loss: 0.38043314167137804
2025-11-22 22:25:47 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:25:47 - GraphTrainer - INFO -   precision@5: 0.005390
2025-11-22 22:25:47 - GraphTrainer - INFO -   recall@5: 0.025826
2025-11-22 22:25:47 - GraphTrainer - INFO -   hit_rate@5: 0.026896
2025-11-22 22:25:47 - GraphTrainer - INFO -   ndcg@5: 0.017116
2025-11-22 22:25:47 - GraphTrainer - INFO -   map@5: 0.014071
2025-11-22 22:25:47 - GraphTrainer - INFO -   mrr@5: 0.014584
2025-11-22 22:25:47 - GraphTrainer - INFO -   precision@10: 0.004608
2025-11-22 22:25:47 - GraphTrainer - INFO -   recall@10: 0.043920
2025-11-22 22:25:47 - GraphTrainer - INFO -   hit_rate@10: 0.045976
2025-11-22 22:25:47 - GraphTrainer - INFO -   ndcg@10: 0.023013
2025-11-22 22:25:47 - GraphTrainer - INFO -   map@10: 0.016473
2025-11-22 22:25:47 - GraphTrainer - INFO -   mrr@10: 0.017111
2025-11-22 22:25:47 - GraphTrainer - INFO -   precision@20: 0.003685
2025-11-22 22:25:47 - GraphTrainer - INFO -   recall@20: 0.070087
2025-11-22 22:25:47 - GraphTrainer - INFO -   hit_rate@20: 0.073438
2025-11-22 22:25:47 - GraphTrainer - INFO -   ndcg@20: 0.029655
2025-11-22 22:25:47 - GraphTrainer - INFO -   map@20: 0.018252
2025-11-22 22:25:47 - GraphTrainer - INFO -   mrr@20: 0.018976
2025-11-22 22:25:47 - GraphTrainer - INFO - 第 74 轮训练完成
2025-11-22 22:25:47 - GraphTrainer - INFO - train_loss: 0.380444
2025-11-22 22:25:47 - GraphTrainer - INFO - precision@5: 0.005390
2025-11-22 22:25:47 - GraphTrainer - INFO - recall@5: 0.025826
2025-11-22 22:25:47 - GraphTrainer - INFO - hit_rate@5: 0.026896
2025-11-22 22:25:47 - GraphTrainer - INFO - ndcg@5: 0.017116
2025-11-22 22:25:47 - GraphTrainer - INFO - map@5: 0.014071
2025-11-22 22:25:47 - GraphTrainer - INFO - mrr@5: 0.014584
2025-11-22 22:25:47 - GraphTrainer - INFO - precision@10: 0.004608
2025-11-22 22:25:47 - GraphTrainer - INFO - recall@10: 0.043920
2025-11-22 22:25:47 - GraphTrainer - INFO - hit_rate@10: 0.045976
2025-11-22 22:25:47 - GraphTrainer - INFO - ndcg@10: 0.023013
2025-11-22 22:25:47 - GraphTrainer - INFO - map@10: 0.016473
2025-11-22 22:25:47 - GraphTrainer - INFO - mrr@10: 0.017111
2025-11-22 22:25:47 - GraphTrainer - INFO - precision@20: 0.003685
2025-11-22 22:25:47 - GraphTrainer - INFO - recall@20: 0.070087
2025-11-22 22:25:47 - GraphTrainer - INFO - hit_rate@20: 0.073438
2025-11-22 22:25:47 - GraphTrainer - INFO - ndcg@20: 0.029655
2025-11-22 22:25:47 - GraphTrainer - INFO - map@20: 0.018252
2025-11-22 22:25:47 - GraphTrainer - INFO - mrr@20: 0.018976
2025-11-22 22:25:47 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:25:47 - GraphTrainer - INFO - ============================================================
2025-11-22 22:25:47 - GraphTrainer - INFO - 开始第 75/1000 轮训练
2025-11-22 22:25:47 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3835, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3787, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3785, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3901, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3867, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3759, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3716, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3972, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3698, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3565, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3742, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3869, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3824, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3701, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3742, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3880, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3726, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4009, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4077, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3838, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3890, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3652, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3945, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3749, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3743, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3730, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3754, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3716, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3919, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3986, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3903, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3787, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4039, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4027, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3873, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3834, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3510, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3904, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3849, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3796, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3665, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3727, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3762, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3599, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3858, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3834, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3815, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3671, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3683, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4015, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3968, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3783, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4043, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3750, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3654, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3668, device='cuda:0', grad_fn=<AddBackward0>)
The 74 training average loss: 0.3804435293222296
2025-11-22 22:25:58 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:25:58 - GraphTrainer - INFO -   precision@5: 0.005883
2025-11-22 22:25:58 - GraphTrainer - INFO -   recall@5: 0.028196
2025-11-22 22:25:58 - GraphTrainer - INFO -   hit_rate@5: 0.029365
2025-11-22 22:25:58 - GraphTrainer - INFO -   ndcg@5: 0.018377
2025-11-22 22:25:58 - GraphTrainer - INFO -   map@5: 0.014964
2025-11-22 22:25:58 - GraphTrainer - INFO -   mrr@5: 0.015522
2025-11-22 22:25:58 - GraphTrainer - INFO -   precision@10: 0.004870
2025-11-22 22:25:58 - GraphTrainer - INFO -   recall@10: 0.046169
2025-11-22 22:25:58 - GraphTrainer - INFO -   hit_rate@10: 0.048599
2025-11-22 22:25:58 - GraphTrainer - INFO -   ndcg@10: 0.024202
2025-11-22 22:25:58 - GraphTrainer - INFO -   map@10: 0.017297
2025-11-22 22:25:58 - GraphTrainer - INFO -   mrr@10: 0.018017
2025-11-22 22:25:58 - GraphTrainer - INFO -   precision@20: 0.003782
2025-11-22 22:25:58 - GraphTrainer - INFO -   recall@20: 0.071479
2025-11-22 22:25:58 - GraphTrainer - INFO -   hit_rate@20: 0.075135
2025-11-22 22:25:58 - GraphTrainer - INFO -   ndcg@20: 0.030629
2025-11-22 22:25:58 - GraphTrainer - INFO -   map@20: 0.019019
2025-11-22 22:25:58 - GraphTrainer - INFO -   mrr@20: 0.019812
2025-11-22 22:25:58 - GraphTrainer - INFO - 第 75 轮训练完成
2025-11-22 22:25:58 - GraphTrainer - INFO - train_loss: 0.379335
2025-11-22 22:25:58 - GraphTrainer - INFO - precision@5: 0.005883
2025-11-22 22:25:58 - GraphTrainer - INFO - recall@5: 0.028196
2025-11-22 22:25:58 - GraphTrainer - INFO - hit_rate@5: 0.029365
2025-11-22 22:25:58 - GraphTrainer - INFO - ndcg@5: 0.018377
2025-11-22 22:25:58 - GraphTrainer - INFO - map@5: 0.014964
2025-11-22 22:25:58 - GraphTrainer - INFO - mrr@5: 0.015522
2025-11-22 22:25:58 - GraphTrainer - INFO - precision@10: 0.004870
2025-11-22 22:25:58 - GraphTrainer - INFO - recall@10: 0.046169
2025-11-22 22:25:58 - GraphTrainer - INFO - hit_rate@10: 0.048599
2025-11-22 22:25:58 - GraphTrainer - INFO - ndcg@10: 0.024202
2025-11-22 22:25:58 - GraphTrainer - INFO - map@10: 0.017297
2025-11-22 22:25:58 - GraphTrainer - INFO - mrr@10: 0.018017
2025-11-22 22:25:58 - GraphTrainer - INFO - precision@20: 0.003782
2025-11-22 22:25:58 - GraphTrainer - INFO - recall@20: 0.071479
2025-11-22 22:25:58 - GraphTrainer - INFO - hit_rate@20: 0.075135
2025-11-22 22:25:58 - GraphTrainer - INFO - ndcg@20: 0.030629
2025-11-22 22:25:58 - GraphTrainer - INFO - map@20: 0.019019
2025-11-22 22:25:58 - GraphTrainer - INFO - mrr@20: 0.019812
2025-11-22 22:25:58 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:25:58 - GraphTrainer - INFO - ============================================================
2025-11-22 22:25:58 - GraphTrainer - INFO - 开始第 76/1000 轮训练
2025-11-22 22:25:58 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3892, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3837, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3885, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3830, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3818, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3827, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3864, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3615, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3747, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3764, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3778, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3659, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3533, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3772, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3825, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3882, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3838, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3915, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3626, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3871, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3702, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4042, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3779, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3701, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3790, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4019, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3633, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3981, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3681, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3796, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4023, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3667, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3769, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3944, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3602, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3859, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3768, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3796, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3622, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3671, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3763, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3772, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4064, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3626, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3998, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3877, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3822, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3745, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3557, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3954, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3873, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3907, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3991, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3824, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3899, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3531, device='cuda:0', grad_fn=<AddBackward0>)
The 75 training average loss: 0.37933491684239484
2025-11-22 22:26:09 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:26:09 - GraphTrainer - INFO -   precision@5: 0.005791
2025-11-22 22:26:09 - GraphTrainer - INFO -   recall@5: 0.027361
2025-11-22 22:26:09 - GraphTrainer - INFO -   hit_rate@5: 0.028851
2025-11-22 22:26:09 - GraphTrainer - INFO -   ndcg@5: 0.018188
2025-11-22 22:26:09 - GraphTrainer - INFO -   map@5: 0.014930
2025-11-22 22:26:09 - GraphTrainer - INFO -   mrr@5: 0.015630
2025-11-22 22:26:09 - GraphTrainer - INFO -   precision@10: 0.004819
2025-11-22 22:26:09 - GraphTrainer - INFO -   recall@10: 0.045614
2025-11-22 22:26:09 - GraphTrainer - INFO -   hit_rate@10: 0.048084
2025-11-22 22:26:09 - GraphTrainer - INFO -   ndcg@10: 0.024146
2025-11-22 22:26:09 - GraphTrainer - INFO -   map@10: 0.017363
2025-11-22 22:26:09 - GraphTrainer - INFO -   mrr@10: 0.018191
2025-11-22 22:26:09 - GraphTrainer - INFO -   precision@20: 0.003839
2025-11-22 22:26:09 - GraphTrainer - INFO -   recall@20: 0.072652
2025-11-22 22:26:09 - GraphTrainer - INFO -   hit_rate@20: 0.076421
2025-11-22 22:26:09 - GraphTrainer - INFO -   ndcg@20: 0.030994
2025-11-22 22:26:09 - GraphTrainer - INFO -   map@20: 0.019189
2025-11-22 22:26:09 - GraphTrainer - INFO -   mrr@20: 0.020100
2025-11-22 22:26:09 - GraphTrainer - INFO - 第 76 轮训练完成
2025-11-22 22:26:09 - GraphTrainer - INFO - train_loss: 0.380691
2025-11-22 22:26:09 - GraphTrainer - INFO - precision@5: 0.005791
2025-11-22 22:26:09 - GraphTrainer - INFO - recall@5: 0.027361
2025-11-22 22:26:09 - GraphTrainer - INFO - hit_rate@5: 0.028851
2025-11-22 22:26:09 - GraphTrainer - INFO - ndcg@5: 0.018188
2025-11-22 22:26:09 - GraphTrainer - INFO - map@5: 0.014930
2025-11-22 22:26:09 - GraphTrainer - INFO - mrr@5: 0.015630
2025-11-22 22:26:09 - GraphTrainer - INFO - precision@10: 0.004819
2025-11-22 22:26:09 - GraphTrainer - INFO - recall@10: 0.045614
2025-11-22 22:26:09 - GraphTrainer - INFO - hit_rate@10: 0.048084
2025-11-22 22:26:09 - GraphTrainer - INFO - ndcg@10: 0.024146
2025-11-22 22:26:09 - GraphTrainer - INFO - map@10: 0.017363
2025-11-22 22:26:09 - GraphTrainer - INFO - mrr@10: 0.018191
2025-11-22 22:26:09 - GraphTrainer - INFO - precision@20: 0.003839
2025-11-22 22:26:09 - GraphTrainer - INFO - recall@20: 0.072652
2025-11-22 22:26:09 - GraphTrainer - INFO - hit_rate@20: 0.076421
2025-11-22 22:26:09 - GraphTrainer - INFO - ndcg@20: 0.030994
2025-11-22 22:26:09 - GraphTrainer - INFO - map@20: 0.019189
2025-11-22 22:26:09 - GraphTrainer - INFO - mrr@20: 0.020100
2025-11-22 22:26:09 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:26:09 - GraphTrainer - INFO - ============================================================
2025-11-22 22:26:09 - GraphTrainer - INFO - 开始第 77/1000 轮训练
2025-11-22 22:26:09 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3809, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3715, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3846, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3568, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3960, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4035, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3925, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3956, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3739, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3650, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3868, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4114, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3869, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3790, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3930, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3885, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3871, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3667, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3710, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3838, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4059, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3832, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3730, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3814, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3974, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3809, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3647, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3907, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3580, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3919, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3866, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3996, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3706, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3873, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3744, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3765, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3608, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3733, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3920, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3765, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3817, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3953, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3681, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3615, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3670, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3829, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3671, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3901, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3930, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4024, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3880, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3883, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3744, device='cuda:0', grad_fn=<AddBackward0>)
The 76 training average loss: 0.38069130685822716
2025-11-22 22:26:20 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:26:20 - GraphTrainer - INFO -   precision@5: 0.005729
2025-11-22 22:26:20 - GraphTrainer - INFO -   recall@5: 0.027283
2025-11-22 22:26:20 - GraphTrainer - INFO -   hit_rate@5: 0.028593
2025-11-22 22:26:20 - GraphTrainer - INFO -   ndcg@5: 0.017395
2025-11-22 22:26:20 - GraphTrainer - INFO -   map@5: 0.013946
2025-11-22 22:26:20 - GraphTrainer - INFO -   mrr@5: 0.014501
2025-11-22 22:26:20 - GraphTrainer - INFO -   precision@10: 0.004670
2025-11-22 22:26:20 - GraphTrainer - INFO -   recall@10: 0.044329
2025-11-22 22:26:20 - GraphTrainer - INFO -   hit_rate@10: 0.046439
2025-11-22 22:26:20 - GraphTrainer - INFO -   ndcg@10: 0.022907
2025-11-22 22:26:20 - GraphTrainer - INFO -   map@10: 0.016169
2025-11-22 22:26:20 - GraphTrainer - INFO -   mrr@10: 0.016825
2025-11-22 22:26:20 - GraphTrainer - INFO -   precision@20: 0.003721
2025-11-22 22:26:20 - GraphTrainer - INFO -   recall@20: 0.070157
2025-11-22 22:26:20 - GraphTrainer - INFO -   hit_rate@20: 0.073901
2025-11-22 22:26:20 - GraphTrainer - INFO -   ndcg@20: 0.029503
2025-11-22 22:26:20 - GraphTrainer - INFO -   map@20: 0.017941
2025-11-22 22:26:20 - GraphTrainer - INFO -   mrr@20: 0.018705
2025-11-22 22:26:20 - GraphTrainer - INFO - 第 77 轮训练完成
2025-11-22 22:26:20 - GraphTrainer - INFO - train_loss: 0.379954
2025-11-22 22:26:20 - GraphTrainer - INFO - precision@5: 0.005729
2025-11-22 22:26:20 - GraphTrainer - INFO - recall@5: 0.027283
2025-11-22 22:26:20 - GraphTrainer - INFO - hit_rate@5: 0.028593
2025-11-22 22:26:20 - GraphTrainer - INFO - ndcg@5: 0.017395
2025-11-22 22:26:20 - GraphTrainer - INFO - map@5: 0.013946
2025-11-22 22:26:20 - GraphTrainer - INFO - mrr@5: 0.014501
2025-11-22 22:26:20 - GraphTrainer - INFO - precision@10: 0.004670
2025-11-22 22:26:20 - GraphTrainer - INFO - recall@10: 0.044329
2025-11-22 22:26:20 - GraphTrainer - INFO - hit_rate@10: 0.046439
2025-11-22 22:26:20 - GraphTrainer - INFO - ndcg@10: 0.022907
2025-11-22 22:26:20 - GraphTrainer - INFO - map@10: 0.016169
2025-11-22 22:26:20 - GraphTrainer - INFO - mrr@10: 0.016825
2025-11-22 22:26:20 - GraphTrainer - INFO - precision@20: 0.003721
2025-11-22 22:26:20 - GraphTrainer - INFO - recall@20: 0.070157
2025-11-22 22:26:20 - GraphTrainer - INFO - hit_rate@20: 0.073901
2025-11-22 22:26:20 - GraphTrainer - INFO - ndcg@20: 0.029503
2025-11-22 22:26:20 - GraphTrainer - INFO - map@20: 0.017941
2025-11-22 22:26:20 - GraphTrainer - INFO - mrr@20: 0.018705
2025-11-22 22:26:20 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:26:20 - GraphTrainer - INFO - ============================================================
2025-11-22 22:26:20 - GraphTrainer - INFO - 开始第 78/1000 轮训练
2025-11-22 22:26:20 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3738, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3642, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4043, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3848, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3938, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3640, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3648, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3709, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3956, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3998, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3765, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3825, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3711, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3727, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3733, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3851, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3919, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3772, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3925, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3799, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3614, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3641, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3653, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3880, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3848, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3787, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3627, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3826, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3775, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3669, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3847, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3701, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3767, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3968, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3833, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3718, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4031, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3965, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3784, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3806, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3821, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3720, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3985, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3693, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3982, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3779, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3832, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3798, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3824, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3863, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3763, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4004, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4190, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3835, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3611, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
The 77 training average loss: 0.37995409965515137
2025-11-22 22:26:31 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:26:31 - GraphTrainer - INFO -   precision@5: 0.005647
2025-11-22 22:26:31 - GraphTrainer - INFO -   recall@5: 0.026959
2025-11-22 22:26:31 - GraphTrainer - INFO -   hit_rate@5: 0.028233
2025-11-22 22:26:31 - GraphTrainer - INFO -   ndcg@5: 0.016843
2025-11-22 22:26:31 - GraphTrainer - INFO -   map@5: 0.013312
2025-11-22 22:26:31 - GraphTrainer - INFO -   mrr@5: 0.013912
2025-11-22 22:26:31 - GraphTrainer - INFO -   precision@10: 0.004603
2025-11-22 22:26:31 - GraphTrainer - INFO -   recall@10: 0.043590
2025-11-22 22:26:31 - GraphTrainer - INFO -   hit_rate@10: 0.045976
2025-11-22 22:26:31 - GraphTrainer - INFO -   ndcg@10: 0.022240
2025-11-22 22:26:31 - GraphTrainer - INFO -   map@10: 0.015478
2025-11-22 22:26:31 - GraphTrainer - INFO -   mrr@10: 0.016224
2025-11-22 22:26:31 - GraphTrainer - INFO -   precision@20: 0.003744
2025-11-22 22:26:31 - GraphTrainer - INFO -   recall@20: 0.070581
2025-11-22 22:26:31 - GraphTrainer - INFO -   hit_rate@20: 0.074518
2025-11-22 22:26:31 - GraphTrainer - INFO -   ndcg@20: 0.029093
2025-11-22 22:26:31 - GraphTrainer - INFO -   map@20: 0.017304
2025-11-22 22:26:31 - GraphTrainer - INFO -   mrr@20: 0.018144
2025-11-22 22:26:31 - GraphTrainer - INFO - 第 78 轮训练完成
2025-11-22 22:26:31 - GraphTrainer - INFO - train_loss: 0.377356
2025-11-22 22:26:31 - GraphTrainer - INFO - precision@5: 0.005647
2025-11-22 22:26:31 - GraphTrainer - INFO - recall@5: 0.026959
2025-11-22 22:26:31 - GraphTrainer - INFO - hit_rate@5: 0.028233
2025-11-22 22:26:31 - GraphTrainer - INFO - ndcg@5: 0.016843
2025-11-22 22:26:31 - GraphTrainer - INFO - map@5: 0.013312
2025-11-22 22:26:31 - GraphTrainer - INFO - mrr@5: 0.013912
2025-11-22 22:26:31 - GraphTrainer - INFO - precision@10: 0.004603
2025-11-22 22:26:31 - GraphTrainer - INFO - recall@10: 0.043590
2025-11-22 22:26:31 - GraphTrainer - INFO - hit_rate@10: 0.045976
2025-11-22 22:26:31 - GraphTrainer - INFO - ndcg@10: 0.022240
2025-11-22 22:26:31 - GraphTrainer - INFO - map@10: 0.015478
2025-11-22 22:26:31 - GraphTrainer - INFO - mrr@10: 0.016224
2025-11-22 22:26:31 - GraphTrainer - INFO - precision@20: 0.003744
2025-11-22 22:26:31 - GraphTrainer - INFO - recall@20: 0.070581
2025-11-22 22:26:31 - GraphTrainer - INFO - hit_rate@20: 0.074518
2025-11-22 22:26:31 - GraphTrainer - INFO - ndcg@20: 0.029093
2025-11-22 22:26:31 - GraphTrainer - INFO - map@20: 0.017304
2025-11-22 22:26:31 - GraphTrainer - INFO - mrr@20: 0.018144
2025-11-22 22:26:31 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:26:31 - GraphTrainer - INFO - ============================================================
2025-11-22 22:26:31 - GraphTrainer - INFO - 开始第 79/1000 轮训练
2025-11-22 22:26:31 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3771, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3840, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3627, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3744, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3749, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3994, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3484, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3962, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3716, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3961, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3737, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3710, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3752, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3843, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3801, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3884, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3921, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3767, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3771, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3631, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3693, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3741, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3760, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3825, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3863, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3661, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3856, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3549, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4016, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3713, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3624, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3865, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3933, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3907, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3810, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3920, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3638, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3753, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3685, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3822, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3777, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3889, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3705, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3630, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3681, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3842, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3825, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3913, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3826, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3719, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3835, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3766, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3717, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3766, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3858, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3726, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3660, device='cuda:0', grad_fn=<AddBackward0>)
The 78 training average loss: 0.37735608631166917
2025-11-22 22:26:43 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:26:43 - GraphTrainer - INFO -   precision@5: 0.005822
2025-11-22 22:26:43 - GraphTrainer - INFO -   recall@5: 0.027692
2025-11-22 22:26:43 - GraphTrainer - INFO -   hit_rate@5: 0.029108
2025-11-22 22:26:43 - GraphTrainer - INFO -   ndcg@5: 0.018117
2025-11-22 22:26:43 - GraphTrainer - INFO -   map@5: 0.014756
2025-11-22 22:26:43 - GraphTrainer - INFO -   mrr@5: 0.015374
2025-11-22 22:26:43 - GraphTrainer - INFO -   precision@10: 0.004829
2025-11-22 22:26:43 - GraphTrainer - INFO -   recall@10: 0.045678
2025-11-22 22:26:43 - GraphTrainer - INFO -   hit_rate@10: 0.048187
2025-11-22 22:26:43 - GraphTrainer - INFO -   ndcg@10: 0.023956
2025-11-22 22:26:43 - GraphTrainer - INFO -   map@10: 0.017112
2025-11-22 22:26:43 - GraphTrainer - INFO -   mrr@10: 0.017872
2025-11-22 22:26:43 - GraphTrainer - INFO -   precision@20: 0.003839
2025-11-22 22:26:43 - GraphTrainer - INFO -   recall@20: 0.072323
2025-11-22 22:26:43 - GraphTrainer - INFO -   hit_rate@20: 0.076266
2025-11-22 22:26:43 - GraphTrainer - INFO -   ndcg@20: 0.030746
2025-11-22 22:26:43 - GraphTrainer - INFO -   map@20: 0.018936
2025-11-22 22:26:43 - GraphTrainer - INFO -   mrr@20: 0.019788
2025-11-22 22:26:43 - GraphTrainer - INFO - 第 79 轮训练完成
2025-11-22 22:26:43 - GraphTrainer - INFO - train_loss: 0.376787
2025-11-22 22:26:43 - GraphTrainer - INFO - precision@5: 0.005822
2025-11-22 22:26:43 - GraphTrainer - INFO - recall@5: 0.027692
2025-11-22 22:26:43 - GraphTrainer - INFO - hit_rate@5: 0.029108
2025-11-22 22:26:43 - GraphTrainer - INFO - ndcg@5: 0.018117
2025-11-22 22:26:43 - GraphTrainer - INFO - map@5: 0.014756
2025-11-22 22:26:43 - GraphTrainer - INFO - mrr@5: 0.015374
2025-11-22 22:26:43 - GraphTrainer - INFO - precision@10: 0.004829
2025-11-22 22:26:43 - GraphTrainer - INFO - recall@10: 0.045678
2025-11-22 22:26:43 - GraphTrainer - INFO - hit_rate@10: 0.048187
2025-11-22 22:26:43 - GraphTrainer - INFO - ndcg@10: 0.023956
2025-11-22 22:26:43 - GraphTrainer - INFO - map@10: 0.017112
2025-11-22 22:26:43 - GraphTrainer - INFO - mrr@10: 0.017872
2025-11-22 22:26:43 - GraphTrainer - INFO - precision@20: 0.003839
2025-11-22 22:26:43 - GraphTrainer - INFO - recall@20: 0.072323
2025-11-22 22:26:43 - GraphTrainer - INFO - hit_rate@20: 0.076266
2025-11-22 22:26:43 - GraphTrainer - INFO - ndcg@20: 0.030746
2025-11-22 22:26:43 - GraphTrainer - INFO - map@20: 0.018936
2025-11-22 22:26:43 - GraphTrainer - INFO - mrr@20: 0.019788
2025-11-22 22:26:43 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:26:43 - GraphTrainer - INFO - ============================================================
2025-11-22 22:26:43 - GraphTrainer - INFO - 开始第 80/1000 轮训练
2025-11-22 22:26:43 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3769, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4043, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3708, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3576, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3689, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3837, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3711, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3960, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3943, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3880, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3685, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4018, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3637, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3918, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3510, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3676, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3795, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3779, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4040, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3652, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3920, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3799, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3684, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3650, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3772, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3658, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3654, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3976, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3664, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3970, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3820, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3905, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3763, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4038, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3757, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4045, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3536, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3881, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3969, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3789, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3791, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4020, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3943, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3797, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3837, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3831, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3833, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3892, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3732, device='cuda:0', grad_fn=<AddBackward0>)
The 79 training average loss: 0.376787401478866
2025-11-22 22:26:54 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:26:54 - GraphTrainer - INFO -   precision@5: 0.006068
2025-11-22 22:26:54 - GraphTrainer - INFO -   recall@5: 0.029029
2025-11-22 22:26:54 - GraphTrainer - INFO -   hit_rate@5: 0.030342
2025-11-22 22:26:54 - GraphTrainer - INFO -   ndcg@5: 0.018572
2025-11-22 22:26:54 - GraphTrainer - INFO -   map@5: 0.014966
2025-11-22 22:26:54 - GraphTrainer - INFO -   mrr@5: 0.015484
2025-11-22 22:26:54 - GraphTrainer - INFO -   precision@10: 0.004819
2025-11-22 22:26:54 - GraphTrainer - INFO -   recall@10: 0.045747
2025-11-22 22:26:54 - GraphTrainer - INFO -   hit_rate@10: 0.048136
2025-11-22 22:26:54 - GraphTrainer - INFO -   ndcg@10: 0.024008
2025-11-22 22:26:54 - GraphTrainer - INFO -   map@10: 0.017158
2025-11-22 22:26:54 - GraphTrainer - INFO -   mrr@10: 0.017820
2025-11-22 22:26:54 - GraphTrainer - INFO -   precision@20: 0.003749
2025-11-22 22:26:54 - GraphTrainer - INFO -   recall@20: 0.071360
2025-11-22 22:26:54 - GraphTrainer - INFO -   hit_rate@20: 0.074724
2025-11-22 22:26:54 - GraphTrainer - INFO -   ndcg@20: 0.030526
2025-11-22 22:26:54 - GraphTrainer - INFO -   map@20: 0.018926
2025-11-22 22:26:54 - GraphTrainer - INFO -   mrr@20: 0.019652
2025-11-22 22:26:54 - GraphTrainer - INFO - 第 80 轮训练完成
2025-11-22 22:26:54 - GraphTrainer - INFO - train_loss: 0.378177
2025-11-22 22:26:54 - GraphTrainer - INFO - precision@5: 0.006068
2025-11-22 22:26:54 - GraphTrainer - INFO - recall@5: 0.029029
2025-11-22 22:26:54 - GraphTrainer - INFO - hit_rate@5: 0.030342
2025-11-22 22:26:54 - GraphTrainer - INFO - ndcg@5: 0.018572
2025-11-22 22:26:54 - GraphTrainer - INFO - map@5: 0.014966
2025-11-22 22:26:54 - GraphTrainer - INFO - mrr@5: 0.015484
2025-11-22 22:26:54 - GraphTrainer - INFO - precision@10: 0.004819
2025-11-22 22:26:54 - GraphTrainer - INFO - recall@10: 0.045747
2025-11-22 22:26:54 - GraphTrainer - INFO - hit_rate@10: 0.048136
2025-11-22 22:26:54 - GraphTrainer - INFO - ndcg@10: 0.024008
2025-11-22 22:26:54 - GraphTrainer - INFO - map@10: 0.017158
2025-11-22 22:26:54 - GraphTrainer - INFO - mrr@10: 0.017820
2025-11-22 22:26:54 - GraphTrainer - INFO - precision@20: 0.003749
2025-11-22 22:26:54 - GraphTrainer - INFO - recall@20: 0.071360
2025-11-22 22:26:54 - GraphTrainer - INFO - hit_rate@20: 0.074724
2025-11-22 22:26:54 - GraphTrainer - INFO - ndcg@20: 0.030526
2025-11-22 22:26:54 - GraphTrainer - INFO - map@20: 0.018926
2025-11-22 22:26:54 - GraphTrainer - INFO - mrr@20: 0.019652
2025-11-22 22:26:54 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:26:54 - GraphTrainer - INFO - 检查点已保存: Epoch 80 -> ./checkpoints/checkpoint_epoch_80.pth
2025-11-22 22:26:54 - GraphTrainer - INFO - ============================================================
2025-11-22 22:26:54 - GraphTrainer - INFO - 开始第 81/1000 轮训练
2025-11-22 22:26:54 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3898, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3996, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4020, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3562, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3809, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3561, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3852, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3819, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3732, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3735, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3795, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3746, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3735, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4062, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3842, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3797, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3764, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3734, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3758, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3992, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3863, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3690, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3921, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4013, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3691, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3905, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3693, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4015, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3748, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3740, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3787, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3676, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3902, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3750, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3810, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3696, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3895, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3795, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3863, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3869, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3775, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3883, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3607, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3687, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3729, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3886, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3831, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3741, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3725, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3754, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3819, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3713, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3907, device='cuda:0', grad_fn=<AddBackward0>)
The 80 training average loss: 0.3781773216765502
2025-11-22 22:27:05 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:27:05 - GraphTrainer - INFO -   precision@5: 0.005513
2025-11-22 22:27:05 - GraphTrainer - INFO -   recall@5: 0.026256
2025-11-22 22:27:05 - GraphTrainer - INFO -   hit_rate@5: 0.027462
2025-11-22 22:27:05 - GraphTrainer - INFO -   ndcg@5: 0.016917
2025-11-22 22:27:05 - GraphTrainer - INFO -   map@5: 0.013644
2025-11-22 22:27:05 - GraphTrainer - INFO -   mrr@5: 0.014222
2025-11-22 22:27:05 - GraphTrainer - INFO -   precision@10: 0.004649
2025-11-22 22:27:05 - GraphTrainer - INFO -   recall@10: 0.044083
2025-11-22 22:27:05 - GraphTrainer - INFO -   hit_rate@10: 0.046387
2025-11-22 22:27:05 - GraphTrainer - INFO -   ndcg@10: 0.022678
2025-11-22 22:27:05 - GraphTrainer - INFO -   map@10: 0.015954
2025-11-22 22:27:05 - GraphTrainer - INFO -   mrr@10: 0.016679
2025-11-22 22:27:05 - GraphTrainer - INFO -   precision@20: 0.003736
2025-11-22 22:27:05 - GraphTrainer - INFO -   recall@20: 0.070796
2025-11-22 22:27:05 - GraphTrainer - INFO -   hit_rate@20: 0.074415
2025-11-22 22:27:05 - GraphTrainer - INFO -   ndcg@20: 0.029448
2025-11-22 22:27:05 - GraphTrainer - INFO -   map@20: 0.017762
2025-11-22 22:27:05 - GraphTrainer - INFO -   mrr@20: 0.018574
2025-11-22 22:27:05 - GraphTrainer - INFO - 第 81 轮训练完成
2025-11-22 22:27:05 - GraphTrainer - INFO - train_loss: 0.374286
2025-11-22 22:27:05 - GraphTrainer - INFO - precision@5: 0.005513
2025-11-22 22:27:05 - GraphTrainer - INFO - recall@5: 0.026256
2025-11-22 22:27:05 - GraphTrainer - INFO - hit_rate@5: 0.027462
2025-11-22 22:27:05 - GraphTrainer - INFO - ndcg@5: 0.016917
2025-11-22 22:27:05 - GraphTrainer - INFO - map@5: 0.013644
2025-11-22 22:27:05 - GraphTrainer - INFO - mrr@5: 0.014222
2025-11-22 22:27:05 - GraphTrainer - INFO - precision@10: 0.004649
2025-11-22 22:27:05 - GraphTrainer - INFO - recall@10: 0.044083
2025-11-22 22:27:05 - GraphTrainer - INFO - hit_rate@10: 0.046387
2025-11-22 22:27:05 - GraphTrainer - INFO - ndcg@10: 0.022678
2025-11-22 22:27:05 - GraphTrainer - INFO - map@10: 0.015954
2025-11-22 22:27:05 - GraphTrainer - INFO - mrr@10: 0.016679
2025-11-22 22:27:05 - GraphTrainer - INFO - precision@20: 0.003736
2025-11-22 22:27:05 - GraphTrainer - INFO - recall@20: 0.070796
2025-11-22 22:27:05 - GraphTrainer - INFO - hit_rate@20: 0.074415
2025-11-22 22:27:05 - GraphTrainer - INFO - ndcg@20: 0.029448
2025-11-22 22:27:05 - GraphTrainer - INFO - map@20: 0.017762
2025-11-22 22:27:05 - GraphTrainer - INFO - mrr@20: 0.018574
2025-11-22 22:27:05 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:27:05 - GraphTrainer - INFO - ============================================================
2025-11-22 22:27:05 - GraphTrainer - INFO - 开始第 82/1000 轮训练
2025-11-22 22:27:05 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3785, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3664, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3708, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3744, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3781, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3803, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3881, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3789, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3631, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3619, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3643, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3721, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3932, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3748, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3838, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3640, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3909, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3807, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3714, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3665, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3684, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3834, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3603, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3691, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3878, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3758, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3967, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3603, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3733, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3849, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3810, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3719, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3550, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3947, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3653, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3966, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4075, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3662, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3859, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3703, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3808, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3677, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3677, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3642, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3648, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3969, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3756, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3690, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3584, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3733, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3806, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3753, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3701, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3737, device='cuda:0', grad_fn=<AddBackward0>)
The 81 training average loss: 0.37428558746288565
2025-11-22 22:27:16 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:27:16 - GraphTrainer - INFO -   precision@5: 0.005575
2025-11-22 22:27:16 - GraphTrainer - INFO -   recall@5: 0.026639
2025-11-22 22:27:16 - GraphTrainer - INFO -   hit_rate@5: 0.027822
2025-11-22 22:27:16 - GraphTrainer - INFO -   ndcg@5: 0.017149
2025-11-22 22:27:16 - GraphTrainer - INFO -   map@5: 0.013853
2025-11-22 22:27:16 - GraphTrainer - INFO -   mrr@5: 0.014404
2025-11-22 22:27:16 - GraphTrainer - INFO -   precision@10: 0.004644
2025-11-22 22:27:16 - GraphTrainer - INFO -   recall@10: 0.044067
2025-11-22 22:27:16 - GraphTrainer - INFO -   hit_rate@10: 0.046336
2025-11-22 22:27:16 - GraphTrainer - INFO -   ndcg@10: 0.022846
2025-11-22 22:27:16 - GraphTrainer - INFO -   map@10: 0.016170
2025-11-22 22:27:16 - GraphTrainer - INFO -   mrr@10: 0.016871
2025-11-22 22:27:16 - GraphTrainer - INFO -   precision@20: 0.003782
2025-11-22 22:27:16 - GraphTrainer - INFO -   recall@20: 0.071375
2025-11-22 22:27:16 - GraphTrainer - INFO -   hit_rate@20: 0.075084
2025-11-22 22:27:16 - GraphTrainer - INFO -   ndcg@20: 0.029801
2025-11-22 22:27:16 - GraphTrainer - INFO -   map@20: 0.018037
2025-11-22 22:27:16 - GraphTrainer - INFO -   mrr@20: 0.018829
2025-11-22 22:27:16 - GraphTrainer - INFO - 第 82 轮训练完成
2025-11-22 22:27:16 - GraphTrainer - INFO - train_loss: 0.374608
2025-11-22 22:27:16 - GraphTrainer - INFO - precision@5: 0.005575
2025-11-22 22:27:16 - GraphTrainer - INFO - recall@5: 0.026639
2025-11-22 22:27:16 - GraphTrainer - INFO - hit_rate@5: 0.027822
2025-11-22 22:27:16 - GraphTrainer - INFO - ndcg@5: 0.017149
2025-11-22 22:27:16 - GraphTrainer - INFO - map@5: 0.013853
2025-11-22 22:27:16 - GraphTrainer - INFO - mrr@5: 0.014404
2025-11-22 22:27:16 - GraphTrainer - INFO - precision@10: 0.004644
2025-11-22 22:27:16 - GraphTrainer - INFO - recall@10: 0.044067
2025-11-22 22:27:16 - GraphTrainer - INFO - hit_rate@10: 0.046336
2025-11-22 22:27:16 - GraphTrainer - INFO - ndcg@10: 0.022846
2025-11-22 22:27:16 - GraphTrainer - INFO - map@10: 0.016170
2025-11-22 22:27:16 - GraphTrainer - INFO - mrr@10: 0.016871
2025-11-22 22:27:16 - GraphTrainer - INFO - precision@20: 0.003782
2025-11-22 22:27:16 - GraphTrainer - INFO - recall@20: 0.071375
2025-11-22 22:27:16 - GraphTrainer - INFO - hit_rate@20: 0.075084
2025-11-22 22:27:16 - GraphTrainer - INFO - ndcg@20: 0.029801
2025-11-22 22:27:16 - GraphTrainer - INFO - map@20: 0.018037
2025-11-22 22:27:16 - GraphTrainer - INFO - mrr@20: 0.018829
2025-11-22 22:27:16 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:27:16 - GraphTrainer - INFO - ============================================================
2025-11-22 22:27:16 - GraphTrainer - INFO - 开始第 83/1000 轮训练
2025-11-22 22:27:16 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3736, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3706, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3746, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3819, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3693, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3772, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4000, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3831, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3969, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3762, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3830, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3621, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3681, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3942, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3839, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3829, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3745, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3938, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3823, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3738, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3817, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3653, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3645, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3789, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4037, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3911, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3484, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3687, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3775, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3704, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4029, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3890, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3651, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3657, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3684, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3739, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3677, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3759, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3746, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3695, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3705, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3742, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3777, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3624, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3983, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3844, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3918, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3634, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3984, device='cuda:0', grad_fn=<AddBackward0>)
The 82 training average loss: 0.3746078250737026
2025-11-22 22:27:27 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:27:27 - GraphTrainer - INFO -   precision@5: 0.005379
2025-11-22 22:27:27 - GraphTrainer - INFO -   recall@5: 0.025556
2025-11-22 22:27:27 - GraphTrainer - INFO -   hit_rate@5: 0.026845
2025-11-22 22:27:27 - GraphTrainer - INFO -   ndcg@5: 0.016045
2025-11-22 22:27:27 - GraphTrainer - INFO -   map@5: 0.012728
2025-11-22 22:27:27 - GraphTrainer - INFO -   mrr@5: 0.013347
2025-11-22 22:27:27 - GraphTrainer - INFO -   precision@10: 0.004577
2025-11-22 22:27:27 - GraphTrainer - INFO -   recall@10: 0.043350
2025-11-22 22:27:27 - GraphTrainer - INFO -   hit_rate@10: 0.045719
2025-11-22 22:27:27 - GraphTrainer - INFO -   ndcg@10: 0.021808
2025-11-22 22:27:27 - GraphTrainer - INFO -   map@10: 0.015043
2025-11-22 22:27:27 - GraphTrainer - INFO -   mrr@10: 0.015808
2025-11-22 22:27:27 - GraphTrainer - INFO -   precision@20: 0.003816
2025-11-22 22:27:27 - GraphTrainer - INFO -   recall@20: 0.072457
2025-11-22 22:27:27 - GraphTrainer - INFO -   hit_rate@20: 0.075855
2025-11-22 22:27:27 - GraphTrainer - INFO -   ndcg@20: 0.029178
2025-11-22 22:27:27 - GraphTrainer - INFO -   map@20: 0.017024
2025-11-22 22:27:27 - GraphTrainer - INFO -   mrr@20: 0.017848
2025-11-22 22:27:27 - GraphTrainer - INFO - 第 83 轮训练完成
2025-11-22 22:27:27 - GraphTrainer - INFO - train_loss: 0.373848
2025-11-22 22:27:27 - GraphTrainer - INFO - precision@5: 0.005379
2025-11-22 22:27:27 - GraphTrainer - INFO - recall@5: 0.025556
2025-11-22 22:27:27 - GraphTrainer - INFO - hit_rate@5: 0.026845
2025-11-22 22:27:27 - GraphTrainer - INFO - ndcg@5: 0.016045
2025-11-22 22:27:27 - GraphTrainer - INFO - map@5: 0.012728
2025-11-22 22:27:27 - GraphTrainer - INFO - mrr@5: 0.013347
2025-11-22 22:27:27 - GraphTrainer - INFO - precision@10: 0.004577
2025-11-22 22:27:27 - GraphTrainer - INFO - recall@10: 0.043350
2025-11-22 22:27:27 - GraphTrainer - INFO - hit_rate@10: 0.045719
2025-11-22 22:27:27 - GraphTrainer - INFO - ndcg@10: 0.021808
2025-11-22 22:27:27 - GraphTrainer - INFO - map@10: 0.015043
2025-11-22 22:27:27 - GraphTrainer - INFO - mrr@10: 0.015808
2025-11-22 22:27:27 - GraphTrainer - INFO - precision@20: 0.003816
2025-11-22 22:27:27 - GraphTrainer - INFO - recall@20: 0.072457
2025-11-22 22:27:27 - GraphTrainer - INFO - hit_rate@20: 0.075855
2025-11-22 22:27:27 - GraphTrainer - INFO - ndcg@20: 0.029178
2025-11-22 22:27:27 - GraphTrainer - INFO - map@20: 0.017024
2025-11-22 22:27:27 - GraphTrainer - INFO - mrr@20: 0.017848
2025-11-22 22:27:27 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:27:27 - GraphTrainer - INFO - ============================================================
2025-11-22 22:27:27 - GraphTrainer - INFO - 开始第 84/1000 轮训练
2025-11-22 22:27:27 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3760, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3773, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3902, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3516, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3731, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3805, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3708, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3833, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3699, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3614, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3931, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3771, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3817, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3639, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3966, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3837, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3853, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3911, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3772, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3529, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3650, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3661, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3976, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3846, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4003, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3586, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3751, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3736, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4009, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3711, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3891, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3951, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3529, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3632, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3806, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3615, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3657, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3659, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3719, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3689, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3679, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3762, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3669, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3709, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3622, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3727, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3784, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3851, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3767, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3761, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3687, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3807, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3771, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3623, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3701, device='cuda:0', grad_fn=<AddBackward0>)
The 83 training average loss: 0.37384846087159784
2025-11-22 22:27:38 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:27:38 - GraphTrainer - INFO -   precision@5: 0.005914
2025-11-22 22:27:38 - GraphTrainer - INFO -   recall@5: 0.028190
2025-11-22 22:27:38 - GraphTrainer - INFO -   hit_rate@5: 0.029519
2025-11-22 22:27:38 - GraphTrainer - INFO -   ndcg@5: 0.017505
2025-11-22 22:27:38 - GraphTrainer - INFO -   map@5: 0.013801
2025-11-22 22:27:38 - GraphTrainer - INFO -   mrr@5: 0.014370
2025-11-22 22:27:38 - GraphTrainer - INFO -   precision@10: 0.004690
2025-11-22 22:27:38 - GraphTrainer - INFO -   recall@10: 0.044331
2025-11-22 22:27:38 - GraphTrainer - INFO -   hit_rate@10: 0.046747
2025-11-22 22:27:38 - GraphTrainer - INFO -   ndcg@10: 0.022737
2025-11-22 22:27:38 - GraphTrainer - INFO -   map@10: 0.015899
2025-11-22 22:27:38 - GraphTrainer - INFO -   mrr@10: 0.016608
2025-11-22 22:27:38 - GraphTrainer - INFO -   precision@20: 0.003770
2025-11-22 22:27:38 - GraphTrainer - INFO -   recall@20: 0.071377
2025-11-22 22:27:38 - GraphTrainer - INFO -   hit_rate@20: 0.074929
2025-11-22 22:27:38 - GraphTrainer - INFO -   ndcg@20: 0.029620
2025-11-22 22:27:38 - GraphTrainer - INFO -   map@20: 0.017758
2025-11-22 22:27:38 - GraphTrainer - INFO -   mrr@20: 0.018540
2025-11-22 22:27:38 - GraphTrainer - INFO - 第 84 轮训练完成
2025-11-22 22:27:38 - GraphTrainer - INFO - train_loss: 0.373826
2025-11-22 22:27:38 - GraphTrainer - INFO - precision@5: 0.005914
2025-11-22 22:27:38 - GraphTrainer - INFO - recall@5: 0.028190
2025-11-22 22:27:38 - GraphTrainer - INFO - hit_rate@5: 0.029519
2025-11-22 22:27:38 - GraphTrainer - INFO - ndcg@5: 0.017505
2025-11-22 22:27:38 - GraphTrainer - INFO - map@5: 0.013801
2025-11-22 22:27:38 - GraphTrainer - INFO - mrr@5: 0.014370
2025-11-22 22:27:38 - GraphTrainer - INFO - precision@10: 0.004690
2025-11-22 22:27:38 - GraphTrainer - INFO - recall@10: 0.044331
2025-11-22 22:27:38 - GraphTrainer - INFO - hit_rate@10: 0.046747
2025-11-22 22:27:38 - GraphTrainer - INFO - ndcg@10: 0.022737
2025-11-22 22:27:38 - GraphTrainer - INFO - map@10: 0.015899
2025-11-22 22:27:38 - GraphTrainer - INFO - mrr@10: 0.016608
2025-11-22 22:27:38 - GraphTrainer - INFO - precision@20: 0.003770
2025-11-22 22:27:38 - GraphTrainer - INFO - recall@20: 0.071377
2025-11-22 22:27:38 - GraphTrainer - INFO - hit_rate@20: 0.074929
2025-11-22 22:27:38 - GraphTrainer - INFO - ndcg@20: 0.029620
2025-11-22 22:27:38 - GraphTrainer - INFO - map@20: 0.017758
2025-11-22 22:27:38 - GraphTrainer - INFO - mrr@20: 0.018540
2025-11-22 22:27:38 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:27:38 - GraphTrainer - INFO - ============================================================
2025-11-22 22:27:38 - GraphTrainer - INFO - 开始第 85/1000 轮训练
2025-11-22 22:27:38 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3786, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3536, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3685, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3747, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3707, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3655, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3725, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3612, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3949, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3687, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3854, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3696, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3714, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3900, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3704, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3767, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3840, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3911, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3681, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3801, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3815, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3961, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3809, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3757, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3702, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3836, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3755, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3687, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3562, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3831, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3834, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3827, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3869, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3851, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3725, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3890, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3912, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3749, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3667, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3509, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3722, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3565, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3687, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3637, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3810, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3672, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3676, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3700, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3735, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3946, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3750, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3625, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3582, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3694, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3858, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
The 84 training average loss: 0.37382554031651594
2025-11-22 22:27:49 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:27:49 - GraphTrainer - INFO -   precision@5: 0.005904
2025-11-22 22:27:49 - GraphTrainer - INFO -   recall@5: 0.028131
2025-11-22 22:27:49 - GraphTrainer - INFO -   hit_rate@5: 0.029365
2025-11-22 22:27:49 - GraphTrainer - INFO -   ndcg@5: 0.018575
2025-11-22 22:27:49 - GraphTrainer - INFO -   map@5: 0.015241
2025-11-22 22:27:49 - GraphTrainer - INFO -   mrr@5: 0.015785
2025-11-22 22:27:49 - GraphTrainer - INFO -   precision@10: 0.004695
2025-11-22 22:27:49 - GraphTrainer - INFO -   recall@10: 0.044758
2025-11-22 22:27:49 - GraphTrainer - INFO -   hit_rate@10: 0.046799
2025-11-22 22:27:49 - GraphTrainer - INFO -   ndcg@10: 0.023934
2025-11-22 22:27:49 - GraphTrainer - INFO -   map@10: 0.017399
2025-11-22 22:27:49 - GraphTrainer - INFO -   mrr@10: 0.018050
2025-11-22 22:27:49 - GraphTrainer - INFO -   precision@20: 0.003757
2025-11-22 22:27:49 - GraphTrainer - INFO -   recall@20: 0.071287
2025-11-22 22:27:49 - GraphTrainer - INFO -   hit_rate@20: 0.074672
2025-11-22 22:27:49 - GraphTrainer - INFO -   ndcg@20: 0.030682
2025-11-22 22:27:49 - GraphTrainer - INFO -   map@20: 0.019211
2025-11-22 22:27:49 - GraphTrainer - INFO -   mrr@20: 0.019947
2025-11-22 22:27:49 - GraphTrainer - INFO - 第 85 轮训练完成
2025-11-22 22:27:49 - GraphTrainer - INFO - train_loss: 0.375303
2025-11-22 22:27:49 - GraphTrainer - INFO - precision@5: 0.005904
2025-11-22 22:27:49 - GraphTrainer - INFO - recall@5: 0.028131
2025-11-22 22:27:49 - GraphTrainer - INFO - hit_rate@5: 0.029365
2025-11-22 22:27:49 - GraphTrainer - INFO - ndcg@5: 0.018575
2025-11-22 22:27:49 - GraphTrainer - INFO - map@5: 0.015241
2025-11-22 22:27:49 - GraphTrainer - INFO - mrr@5: 0.015785
2025-11-22 22:27:49 - GraphTrainer - INFO - precision@10: 0.004695
2025-11-22 22:27:49 - GraphTrainer - INFO - recall@10: 0.044758
2025-11-22 22:27:49 - GraphTrainer - INFO - hit_rate@10: 0.046799
2025-11-22 22:27:49 - GraphTrainer - INFO - ndcg@10: 0.023934
2025-11-22 22:27:49 - GraphTrainer - INFO - map@10: 0.017399
2025-11-22 22:27:49 - GraphTrainer - INFO - mrr@10: 0.018050
2025-11-22 22:27:49 - GraphTrainer - INFO - precision@20: 0.003757
2025-11-22 22:27:49 - GraphTrainer - INFO - recall@20: 0.071287
2025-11-22 22:27:49 - GraphTrainer - INFO - hit_rate@20: 0.074672
2025-11-22 22:27:49 - GraphTrainer - INFO - ndcg@20: 0.030682
2025-11-22 22:27:49 - GraphTrainer - INFO - map@20: 0.019211
2025-11-22 22:27:49 - GraphTrainer - INFO - mrr@20: 0.019947
2025-11-22 22:27:49 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:27:49 - GraphTrainer - INFO - ============================================================
2025-11-22 22:27:49 - GraphTrainer - INFO - 开始第 86/1000 轮训练
2025-11-22 22:27:49 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3559, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3819, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3676, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3737, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3785, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3788, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3854, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3614, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3916, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3558, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3901, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3688, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3889, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3721, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3694, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3685, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3648, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3690, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3584, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3712, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3684, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3766, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3779, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3612, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3674, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3729, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3631, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3746, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3926, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3704, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3673, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3694, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3641, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3965, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3814, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3788, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3659, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4007, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4073, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3694, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4075, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3906, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3840, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3862, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3870, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3772, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3997, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4046, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3655, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3752, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3729, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3952, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3761, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3762, device='cuda:0', grad_fn=<AddBackward0>)
The 85 training average loss: 0.37530275768247146
2025-11-22 22:28:00 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:28:00 - GraphTrainer - INFO -   precision@5: 0.005451
2025-11-22 22:28:00 - GraphTrainer - INFO -   recall@5: 0.026243
2025-11-22 22:28:00 - GraphTrainer - INFO -   hit_rate@5: 0.027256
2025-11-22 22:28:00 - GraphTrainer - INFO -   ndcg@5: 0.017224
2025-11-22 22:28:00 - GraphTrainer - INFO -   map@5: 0.014110
2025-11-22 22:28:00 - GraphTrainer - INFO -   mrr@5: 0.014556
2025-11-22 22:28:00 - GraphTrainer - INFO -   precision@10: 0.004587
2025-11-22 22:28:00 - GraphTrainer - INFO -   recall@10: 0.043804
2025-11-22 22:28:00 - GraphTrainer - INFO -   hit_rate@10: 0.045822
2025-11-22 22:28:00 - GraphTrainer - INFO -   ndcg@10: 0.022947
2025-11-22 22:28:00 - GraphTrainer - INFO -   map@10: 0.016435
2025-11-22 22:28:00 - GraphTrainer - INFO -   mrr@10: 0.017009
2025-11-22 22:28:00 - GraphTrainer - INFO -   precision@20: 0.003798
2025-11-22 22:28:00 - GraphTrainer - INFO -   recall@20: 0.072317
2025-11-22 22:28:00 - GraphTrainer - INFO -   hit_rate@20: 0.075495
2025-11-22 22:28:00 - GraphTrainer - INFO -   ndcg@20: 0.030151
2025-11-22 22:28:00 - GraphTrainer - INFO -   map@20: 0.018354
2025-11-22 22:28:00 - GraphTrainer - INFO -   mrr@20: 0.018997
2025-11-22 22:28:00 - GraphTrainer - INFO - 第 86 轮训练完成
2025-11-22 22:28:00 - GraphTrainer - INFO - train_loss: 0.374788
2025-11-22 22:28:00 - GraphTrainer - INFO - precision@5: 0.005451
2025-11-22 22:28:00 - GraphTrainer - INFO - recall@5: 0.026243
2025-11-22 22:28:00 - GraphTrainer - INFO - hit_rate@5: 0.027256
2025-11-22 22:28:00 - GraphTrainer - INFO - ndcg@5: 0.017224
2025-11-22 22:28:00 - GraphTrainer - INFO - map@5: 0.014110
2025-11-22 22:28:00 - GraphTrainer - INFO - mrr@5: 0.014556
2025-11-22 22:28:00 - GraphTrainer - INFO - precision@10: 0.004587
2025-11-22 22:28:00 - GraphTrainer - INFO - recall@10: 0.043804
2025-11-22 22:28:00 - GraphTrainer - INFO - hit_rate@10: 0.045822
2025-11-22 22:28:00 - GraphTrainer - INFO - ndcg@10: 0.022947
2025-11-22 22:28:00 - GraphTrainer - INFO - map@10: 0.016435
2025-11-22 22:28:00 - GraphTrainer - INFO - mrr@10: 0.017009
2025-11-22 22:28:00 - GraphTrainer - INFO - precision@20: 0.003798
2025-11-22 22:28:00 - GraphTrainer - INFO - recall@20: 0.072317
2025-11-22 22:28:00 - GraphTrainer - INFO - hit_rate@20: 0.075495
2025-11-22 22:28:00 - GraphTrainer - INFO - ndcg@20: 0.030151
2025-11-22 22:28:00 - GraphTrainer - INFO - map@20: 0.018354
2025-11-22 22:28:00 - GraphTrainer - INFO - mrr@20: 0.018997
2025-11-22 22:28:00 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:28:00 - GraphTrainer - INFO - ============================================================
2025-11-22 22:28:00 - GraphTrainer - INFO - 开始第 87/1000 轮训练
2025-11-22 22:28:00 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3858, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3595, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3649, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3759, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3832, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3559, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3875, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3671, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3602, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3610, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3885, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3591, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3979, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3611, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3818, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3769, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3801, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3718, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4024, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3870, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3516, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3778, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3791, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3776, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3649, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3670, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3919, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3728, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3689, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3756, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3746, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3934, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3700, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4098, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3803, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3714, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3750, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3539, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3856, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3654, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3771, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3886, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3947, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3773, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3591, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3860, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3745, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3732, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3813, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3614, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3817, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3872, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3760, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3695, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3788, device='cuda:0', grad_fn=<AddBackward0>)
The 86 training average loss: 0.37478823394610966
2025-11-22 22:28:10 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:28:10 - GraphTrainer - INFO -   precision@5: 0.005955
2025-11-22 22:28:10 - GraphTrainer - INFO -   recall@5: 0.028240
2025-11-22 22:28:10 - GraphTrainer - INFO -   hit_rate@5: 0.029725
2025-11-22 22:28:10 - GraphTrainer - INFO -   ndcg@5: 0.018253
2025-11-22 22:28:10 - GraphTrainer - INFO -   map@5: 0.014751
2025-11-22 22:28:10 - GraphTrainer - INFO -   mrr@5: 0.015378
2025-11-22 22:28:10 - GraphTrainer - INFO -   precision@10: 0.004793
2025-11-22 22:28:10 - GraphTrainer - INFO -   recall@10: 0.045640
2025-11-22 22:28:10 - GraphTrainer - INFO -   hit_rate@10: 0.047879
2025-11-22 22:28:10 - GraphTrainer - INFO -   ndcg@10: 0.023874
2025-11-22 22:28:10 - GraphTrainer - INFO -   map@10: 0.017024
2025-11-22 22:28:10 - GraphTrainer - INFO -   mrr@10: 0.017752
2025-11-22 22:28:10 - GraphTrainer - INFO -   precision@20: 0.003847
2025-11-22 22:28:10 - GraphTrainer - INFO -   recall@20: 0.072683
2025-11-22 22:28:10 - GraphTrainer - INFO -   hit_rate@20: 0.076626
2025-11-22 22:28:10 - GraphTrainer - INFO -   ndcg@20: 0.030759
2025-11-22 22:28:10 - GraphTrainer - INFO -   map@20: 0.018863
2025-11-22 22:28:10 - GraphTrainer - INFO -   mrr@20: 0.019704
2025-11-22 22:28:10 - GraphTrainer - INFO - 第 87 轮训练完成
2025-11-22 22:28:10 - GraphTrainer - INFO - train_loss: 0.372545
2025-11-22 22:28:10 - GraphTrainer - INFO - precision@5: 0.005955
2025-11-22 22:28:10 - GraphTrainer - INFO - recall@5: 0.028240
2025-11-22 22:28:10 - GraphTrainer - INFO - hit_rate@5: 0.029725
2025-11-22 22:28:10 - GraphTrainer - INFO - ndcg@5: 0.018253
2025-11-22 22:28:10 - GraphTrainer - INFO - map@5: 0.014751
2025-11-22 22:28:10 - GraphTrainer - INFO - mrr@5: 0.015378
2025-11-22 22:28:10 - GraphTrainer - INFO - precision@10: 0.004793
2025-11-22 22:28:10 - GraphTrainer - INFO - recall@10: 0.045640
2025-11-22 22:28:10 - GraphTrainer - INFO - hit_rate@10: 0.047879
2025-11-22 22:28:10 - GraphTrainer - INFO - ndcg@10: 0.023874
2025-11-22 22:28:10 - GraphTrainer - INFO - map@10: 0.017024
2025-11-22 22:28:10 - GraphTrainer - INFO - mrr@10: 0.017752
2025-11-22 22:28:10 - GraphTrainer - INFO - precision@20: 0.003847
2025-11-22 22:28:10 - GraphTrainer - INFO - recall@20: 0.072683
2025-11-22 22:28:10 - GraphTrainer - INFO - hit_rate@20: 0.076626
2025-11-22 22:28:10 - GraphTrainer - INFO - ndcg@20: 0.030759
2025-11-22 22:28:10 - GraphTrainer - INFO - map@20: 0.018863
2025-11-22 22:28:10 - GraphTrainer - INFO - mrr@20: 0.019704
2025-11-22 22:28:10 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:28:10 - GraphTrainer - INFO - ============================================================
2025-11-22 22:28:10 - GraphTrainer - INFO - 开始第 88/1000 轮训练
2025-11-22 22:28:10 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3704, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3778, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3805, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3793, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3605, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3955, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3658, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3963, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3851, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3621, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3623, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3772, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3779, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3644, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3705, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3730, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3772, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3625, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3913, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3536, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3634, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3828, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3760, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3691, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3745, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3823, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3711, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4059, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3577, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3739, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3631, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3680, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3837, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3625, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3556, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3845, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3920, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3715, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3664, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3805, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3871, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3945, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3634, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3790, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3753, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3748, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3696, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3576, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3579, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3780, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3457, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3783, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3774, device='cuda:0', grad_fn=<AddBackward0>)
The 87 training average loss: 0.37254503574864617
2025-11-22 22:28:21 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:28:21 - GraphTrainer - INFO -   precision@5: 0.005863
2025-11-22 22:28:21 - GraphTrainer - INFO -   recall@5: 0.027852
2025-11-22 22:28:21 - GraphTrainer - INFO -   hit_rate@5: 0.029262
2025-11-22 22:28:21 - GraphTrainer - INFO -   ndcg@5: 0.017830
2025-11-22 22:28:21 - GraphTrainer - INFO -   map@5: 0.014314
2025-11-22 22:28:21 - GraphTrainer - INFO -   mrr@5: 0.014988
2025-11-22 22:28:21 - GraphTrainer - INFO -   precision@10: 0.004932
2025-11-22 22:28:21 - GraphTrainer - INFO -   recall@10: 0.046780
2025-11-22 22:28:21 - GraphTrainer - INFO -   hit_rate@10: 0.049164
2025-11-22 22:28:21 - GraphTrainer - INFO -   ndcg@10: 0.023972
2025-11-22 22:28:21 - GraphTrainer - INFO -   map@10: 0.016799
2025-11-22 22:28:21 - GraphTrainer - INFO -   mrr@10: 0.017601
2025-11-22 22:28:21 - GraphTrainer - INFO -   precision@20: 0.003842
2025-11-22 22:28:21 - GraphTrainer - INFO -   recall@20: 0.073014
2025-11-22 22:28:21 - GraphTrainer - INFO -   hit_rate@20: 0.076421
2025-11-22 22:28:21 - GraphTrainer - INFO -   ndcg@20: 0.030625
2025-11-22 22:28:21 - GraphTrainer - INFO -   map@20: 0.018588
2025-11-22 22:28:21 - GraphTrainer - INFO -   mrr@20: 0.019456
2025-11-22 22:28:21 - GraphTrainer - INFO - 第 88 轮训练完成
2025-11-22 22:28:21 - GraphTrainer - INFO - train_loss: 0.368635
2025-11-22 22:28:21 - GraphTrainer - INFO - precision@5: 0.005863
2025-11-22 22:28:21 - GraphTrainer - INFO - recall@5: 0.027852
2025-11-22 22:28:21 - GraphTrainer - INFO - hit_rate@5: 0.029262
2025-11-22 22:28:21 - GraphTrainer - INFO - ndcg@5: 0.017830
2025-11-22 22:28:21 - GraphTrainer - INFO - map@5: 0.014314
2025-11-22 22:28:21 - GraphTrainer - INFO - mrr@5: 0.014988
2025-11-22 22:28:21 - GraphTrainer - INFO - precision@10: 0.004932
2025-11-22 22:28:21 - GraphTrainer - INFO - recall@10: 0.046780
2025-11-22 22:28:21 - GraphTrainer - INFO - hit_rate@10: 0.049164
2025-11-22 22:28:21 - GraphTrainer - INFO - ndcg@10: 0.023972
2025-11-22 22:28:21 - GraphTrainer - INFO - map@10: 0.016799
2025-11-22 22:28:21 - GraphTrainer - INFO - mrr@10: 0.017601
2025-11-22 22:28:21 - GraphTrainer - INFO - precision@20: 0.003842
2025-11-22 22:28:21 - GraphTrainer - INFO - recall@20: 0.073014
2025-11-22 22:28:21 - GraphTrainer - INFO - hit_rate@20: 0.076421
2025-11-22 22:28:21 - GraphTrainer - INFO - ndcg@20: 0.030625
2025-11-22 22:28:21 - GraphTrainer - INFO - map@20: 0.018588
2025-11-22 22:28:21 - GraphTrainer - INFO - mrr@20: 0.019456
2025-11-22 22:28:21 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:28:21 - GraphTrainer - INFO - ============================================================
2025-11-22 22:28:21 - GraphTrainer - INFO - 开始第 89/1000 轮训练
2025-11-22 22:28:21 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3742, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3810, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3822, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3781, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3614, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3699, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3773, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3657, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3731, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3732, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3795, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3613, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3577, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3674, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3610, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3878, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3551, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3845, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3614, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3539, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3788, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3852, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3608, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3688, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3576, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3679, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3944, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3843, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3604, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3818, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3713, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3839, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3806, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3768, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3468, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4037, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3751, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3759, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3780, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3944, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3665, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3658, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3882, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4037, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3799, device='cuda:0', grad_fn=<AddBackward0>)
The 88 training average loss: 0.368634798403444
2025-11-22 22:28:32 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:28:32 - GraphTrainer - INFO -   precision@5: 0.005739
2025-11-22 22:28:32 - GraphTrainer - INFO -   recall@5: 0.027413
2025-11-22 22:28:32 - GraphTrainer - INFO -   hit_rate@5: 0.028645
2025-11-22 22:28:32 - GraphTrainer - INFO -   ndcg@5: 0.017835
2025-11-22 22:28:32 - GraphTrainer - INFO -   map@5: 0.014495
2025-11-22 22:28:32 - GraphTrainer - INFO -   mrr@5: 0.015056
2025-11-22 22:28:32 - GraphTrainer - INFO -   precision@10: 0.004649
2025-11-22 22:28:32 - GraphTrainer - INFO -   recall@10: 0.044348
2025-11-22 22:28:32 - GraphTrainer - INFO -   hit_rate@10: 0.046336
2025-11-22 22:28:32 - GraphTrainer - INFO -   ndcg@10: 0.023266
2025-11-22 22:28:32 - GraphTrainer - INFO -   map@10: 0.016666
2025-11-22 22:28:32 - GraphTrainer - INFO -   mrr@10: 0.017316
2025-11-22 22:28:32 - GraphTrainer - INFO -   precision@20: 0.003775
2025-11-22 22:28:32 - GraphTrainer - INFO -   recall@20: 0.071539
2025-11-22 22:28:32 - GraphTrainer - INFO -   hit_rate@20: 0.074878
2025-11-22 22:28:32 - GraphTrainer - INFO -   ndcg@20: 0.030183
2025-11-22 22:28:32 - GraphTrainer - INFO -   map@20: 0.018522
2025-11-22 22:28:32 - GraphTrainer - INFO -   mrr@20: 0.019259
2025-11-22 22:28:32 - GraphTrainer - INFO - 第 89 轮训练完成
2025-11-22 22:28:32 - GraphTrainer - INFO - train_loss: 0.372965
2025-11-22 22:28:32 - GraphTrainer - INFO - precision@5: 0.005739
2025-11-22 22:28:32 - GraphTrainer - INFO - recall@5: 0.027413
2025-11-22 22:28:32 - GraphTrainer - INFO - hit_rate@5: 0.028645
2025-11-22 22:28:32 - GraphTrainer - INFO - ndcg@5: 0.017835
2025-11-22 22:28:32 - GraphTrainer - INFO - map@5: 0.014495
2025-11-22 22:28:32 - GraphTrainer - INFO - mrr@5: 0.015056
2025-11-22 22:28:32 - GraphTrainer - INFO - precision@10: 0.004649
2025-11-22 22:28:32 - GraphTrainer - INFO - recall@10: 0.044348
2025-11-22 22:28:32 - GraphTrainer - INFO - hit_rate@10: 0.046336
2025-11-22 22:28:32 - GraphTrainer - INFO - ndcg@10: 0.023266
2025-11-22 22:28:32 - GraphTrainer - INFO - map@10: 0.016666
2025-11-22 22:28:32 - GraphTrainer - INFO - mrr@10: 0.017316
2025-11-22 22:28:32 - GraphTrainer - INFO - precision@20: 0.003775
2025-11-22 22:28:32 - GraphTrainer - INFO - recall@20: 0.071539
2025-11-22 22:28:32 - GraphTrainer - INFO - hit_rate@20: 0.074878
2025-11-22 22:28:32 - GraphTrainer - INFO - ndcg@20: 0.030183
2025-11-22 22:28:32 - GraphTrainer - INFO - map@20: 0.018522
2025-11-22 22:28:32 - GraphTrainer - INFO - mrr@20: 0.019259
2025-11-22 22:28:32 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:28:32 - GraphTrainer - INFO - ============================================================
2025-11-22 22:28:32 - GraphTrainer - INFO - 开始第 90/1000 轮训练
2025-11-22 22:28:32 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3652, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3933, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3605, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3742, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3619, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3737, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3887, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3681, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3651, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3559, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3761, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3769, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3811, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3792, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3707, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3668, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3946, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3967, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3689, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3736, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3728, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3616, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3630, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3741, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3824, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3630, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3877, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3455, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3718, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3786, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3533, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3899, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3771, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3885, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3858, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3725, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3856, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3730, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3752, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3744, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3920, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3718, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3824, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3786, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3855, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3586, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3716, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4029, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3937, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3614, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>)
The 89 training average loss: 0.37296482869263353
2025-11-22 22:28:43 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:28:43 - GraphTrainer - INFO -   precision@5: 0.005708
2025-11-22 22:28:43 - GraphTrainer - INFO -   recall@5: 0.027490
2025-11-22 22:28:43 - GraphTrainer - INFO -   hit_rate@5: 0.028542
2025-11-22 22:28:43 - GraphTrainer - INFO -   ndcg@5: 0.017995
2025-11-22 22:28:43 - GraphTrainer - INFO -   map@5: 0.014706
2025-11-22 22:28:43 - GraphTrainer - INFO -   mrr@5: 0.015221
2025-11-22 22:28:43 - GraphTrainer - INFO -   precision@10: 0.004767
2025-11-22 22:28:43 - GraphTrainer - INFO -   recall@10: 0.045336
2025-11-22 22:28:43 - GraphTrainer - INFO -   hit_rate@10: 0.047519
2025-11-22 22:28:43 - GraphTrainer - INFO -   ndcg@10: 0.023804
2025-11-22 22:28:43 - GraphTrainer - INFO -   map@10: 0.017050
2025-11-22 22:28:43 - GraphTrainer - INFO -   mrr@10: 0.017708
2025-11-22 22:28:43 - GraphTrainer - INFO -   precision@20: 0.003834
2025-11-22 22:28:43 - GraphTrainer - INFO -   recall@20: 0.072625
2025-11-22 22:28:43 - GraphTrainer - INFO -   hit_rate@20: 0.076318
2025-11-22 22:28:43 - GraphTrainer - INFO -   ndcg@20: 0.030759
2025-11-22 22:28:43 - GraphTrainer - INFO -   map@20: 0.018922
2025-11-22 22:28:43 - GraphTrainer - INFO -   mrr@20: 0.019681
2025-11-22 22:28:43 - GraphTrainer - INFO - 第 90 轮训练完成
2025-11-22 22:28:43 - GraphTrainer - INFO - train_loss: 0.371685
2025-11-22 22:28:43 - GraphTrainer - INFO - precision@5: 0.005708
2025-11-22 22:28:43 - GraphTrainer - INFO - recall@5: 0.027490
2025-11-22 22:28:43 - GraphTrainer - INFO - hit_rate@5: 0.028542
2025-11-22 22:28:43 - GraphTrainer - INFO - ndcg@5: 0.017995
2025-11-22 22:28:43 - GraphTrainer - INFO - map@5: 0.014706
2025-11-22 22:28:43 - GraphTrainer - INFO - mrr@5: 0.015221
2025-11-22 22:28:43 - GraphTrainer - INFO - precision@10: 0.004767
2025-11-22 22:28:43 - GraphTrainer - INFO - recall@10: 0.045336
2025-11-22 22:28:43 - GraphTrainer - INFO - hit_rate@10: 0.047519
2025-11-22 22:28:43 - GraphTrainer - INFO - ndcg@10: 0.023804
2025-11-22 22:28:43 - GraphTrainer - INFO - map@10: 0.017050
2025-11-22 22:28:43 - GraphTrainer - INFO - mrr@10: 0.017708
2025-11-22 22:28:43 - GraphTrainer - INFO - precision@20: 0.003834
2025-11-22 22:28:43 - GraphTrainer - INFO - recall@20: 0.072625
2025-11-22 22:28:43 - GraphTrainer - INFO - hit_rate@20: 0.076318
2025-11-22 22:28:43 - GraphTrainer - INFO - ndcg@20: 0.030759
2025-11-22 22:28:43 - GraphTrainer - INFO - map@20: 0.018922
2025-11-22 22:28:43 - GraphTrainer - INFO - mrr@20: 0.019681
2025-11-22 22:28:43 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:28:43 - GraphTrainer - INFO - 检查点已保存: Epoch 90 -> ./checkpoints/checkpoint_epoch_90.pth
2025-11-22 22:28:43 - GraphTrainer - INFO - ============================================================
2025-11-22 22:28:43 - GraphTrainer - INFO - 开始第 91/1000 轮训练
2025-11-22 22:28:43 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3826, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3674, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3711, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3756, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3557, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3728, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3656, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3837, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3796, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3746, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3735, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3462, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3772, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4040, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3736, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3732, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3798, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3612, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3863, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3851, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3712, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3846, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3728, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3709, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4033, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3720, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3464, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3714, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3627, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3747, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3707, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3671, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3865, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3739, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3747, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3911, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3786, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3918, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3455, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3717, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3808, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3676, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3677, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3722, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3601, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3604, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3706, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3631, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4156, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3607, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3663, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3579, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3630, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3484, device='cuda:0', grad_fn=<AddBackward0>)
The 90 training average loss: 0.37168493301704014
2025-11-22 22:28:54 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:28:54 - GraphTrainer - INFO -   precision@5: 0.005698
2025-11-22 22:28:54 - GraphTrainer - INFO -   recall@5: 0.027207
2025-11-22 22:28:54 - GraphTrainer - INFO -   hit_rate@5: 0.028388
2025-11-22 22:28:54 - GraphTrainer - INFO -   ndcg@5: 0.017827
2025-11-22 22:28:54 - GraphTrainer - INFO -   map@5: 0.014529
2025-11-22 22:28:54 - GraphTrainer - INFO -   mrr@5: 0.015147
2025-11-22 22:28:54 - GraphTrainer - INFO -   precision@10: 0.004747
2025-11-22 22:28:54 - GraphTrainer - INFO -   recall@10: 0.044925
2025-11-22 22:28:54 - GraphTrainer - INFO -   hit_rate@10: 0.047313
2025-11-22 22:28:54 - GraphTrainer - INFO -   ndcg@10: 0.023581
2025-11-22 22:28:54 - GraphTrainer - INFO -   map@10: 0.016844
2025-11-22 22:28:54 - GraphTrainer - INFO -   mrr@10: 0.017620
2025-11-22 22:28:54 - GraphTrainer - INFO -   precision@20: 0.003821
2025-11-22 22:28:54 - GraphTrainer - INFO -   recall@20: 0.072332
2025-11-22 22:28:54 - GraphTrainer - INFO -   hit_rate@20: 0.076009
2025-11-22 22:28:54 - GraphTrainer - INFO -   ndcg@20: 0.030520
2025-11-22 22:28:54 - GraphTrainer - INFO -   map@20: 0.018694
2025-11-22 22:28:54 - GraphTrainer - INFO -   mrr@20: 0.019553
2025-11-22 22:28:54 - GraphTrainer - INFO - 第 91 轮训练完成
2025-11-22 22:28:54 - GraphTrainer - INFO - train_loss: 0.370054
2025-11-22 22:28:54 - GraphTrainer - INFO - precision@5: 0.005698
2025-11-22 22:28:54 - GraphTrainer - INFO - recall@5: 0.027207
2025-11-22 22:28:54 - GraphTrainer - INFO - hit_rate@5: 0.028388
2025-11-22 22:28:54 - GraphTrainer - INFO - ndcg@5: 0.017827
2025-11-22 22:28:54 - GraphTrainer - INFO - map@5: 0.014529
2025-11-22 22:28:54 - GraphTrainer - INFO - mrr@5: 0.015147
2025-11-22 22:28:54 - GraphTrainer - INFO - precision@10: 0.004747
2025-11-22 22:28:54 - GraphTrainer - INFO - recall@10: 0.044925
2025-11-22 22:28:54 - GraphTrainer - INFO - hit_rate@10: 0.047313
2025-11-22 22:28:54 - GraphTrainer - INFO - ndcg@10: 0.023581
2025-11-22 22:28:54 - GraphTrainer - INFO - map@10: 0.016844
2025-11-22 22:28:54 - GraphTrainer - INFO - mrr@10: 0.017620
2025-11-22 22:28:54 - GraphTrainer - INFO - precision@20: 0.003821
2025-11-22 22:28:54 - GraphTrainer - INFO - recall@20: 0.072332
2025-11-22 22:28:54 - GraphTrainer - INFO - hit_rate@20: 0.076009
2025-11-22 22:28:54 - GraphTrainer - INFO - ndcg@20: 0.030520
2025-11-22 22:28:54 - GraphTrainer - INFO - map@20: 0.018694
2025-11-22 22:28:54 - GraphTrainer - INFO - mrr@20: 0.019553
2025-11-22 22:28:54 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:28:54 - GraphTrainer - INFO - ============================================================
2025-11-22 22:28:54 - GraphTrainer - INFO - 开始第 92/1000 轮训练
2025-11-22 22:28:54 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3744, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3628, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3665, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3704, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3621, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3796, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4040, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3863, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3905, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3582, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3639, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3754, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3814, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3854, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3751, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3868, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3977, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3677, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3627, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3604, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3510, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3698, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3796, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3630, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3915, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3666, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3653, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3662, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3693, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3695, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3748, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3728, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3615, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3753, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3433, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3689, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3539, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3613, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3685, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3586, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3731, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3798, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3791, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3665, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3799, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3741, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3842, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3655, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3776, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3962, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3872, device='cuda:0', grad_fn=<AddBackward0>)
The 91 training average loss: 0.37005393875056297
2025-11-22 22:29:05 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:29:05 - GraphTrainer - INFO -   precision@5: 0.006068
2025-11-22 22:29:05 - GraphTrainer - INFO -   recall@5: 0.028733
2025-11-22 22:29:05 - GraphTrainer - INFO -   hit_rate@5: 0.030239
2025-11-22 22:29:05 - GraphTrainer - INFO -   ndcg@5: 0.018885
2025-11-22 22:29:05 - GraphTrainer - INFO -   map@5: 0.015413
2025-11-22 22:29:05 - GraphTrainer - INFO -   mrr@5: 0.016078
2025-11-22 22:29:05 - GraphTrainer - INFO -   precision@10: 0.004726
2025-11-22 22:29:05 - GraphTrainer - INFO -   recall@10: 0.044716
2025-11-22 22:29:05 - GraphTrainer - INFO -   hit_rate@10: 0.047107
2025-11-22 22:29:05 - GraphTrainer - INFO -   ndcg@10: 0.024053
2025-11-22 22:29:05 - GraphTrainer - INFO -   map@10: 0.017491
2025-11-22 22:29:05 - GraphTrainer - INFO -   mrr@10: 0.018275
2025-11-22 22:29:05 - GraphTrainer - INFO -   precision@20: 0.003860
2025-11-22 22:29:05 - GraphTrainer - INFO -   recall@20: 0.073148
2025-11-22 22:29:05 - GraphTrainer - INFO -   hit_rate@20: 0.076935
2025-11-22 22:29:05 - GraphTrainer - INFO -   ndcg@20: 0.031293
2025-11-22 22:29:05 - GraphTrainer - INFO -   map@20: 0.019446
2025-11-22 22:29:05 - GraphTrainer - INFO -   mrr@20: 0.020322
2025-11-22 22:29:05 - GraphTrainer - INFO - 第 92 轮训练完成
2025-11-22 22:29:05 - GraphTrainer - INFO - train_loss: 0.370697
2025-11-22 22:29:05 - GraphTrainer - INFO - precision@5: 0.006068
2025-11-22 22:29:05 - GraphTrainer - INFO - recall@5: 0.028733
2025-11-22 22:29:05 - GraphTrainer - INFO - hit_rate@5: 0.030239
2025-11-22 22:29:05 - GraphTrainer - INFO - ndcg@5: 0.018885
2025-11-22 22:29:05 - GraphTrainer - INFO - map@5: 0.015413
2025-11-22 22:29:05 - GraphTrainer - INFO - mrr@5: 0.016078
2025-11-22 22:29:05 - GraphTrainer - INFO - precision@10: 0.004726
2025-11-22 22:29:05 - GraphTrainer - INFO - recall@10: 0.044716
2025-11-22 22:29:05 - GraphTrainer - INFO - hit_rate@10: 0.047107
2025-11-22 22:29:05 - GraphTrainer - INFO - ndcg@10: 0.024053
2025-11-22 22:29:05 - GraphTrainer - INFO - map@10: 0.017491
2025-11-22 22:29:05 - GraphTrainer - INFO - mrr@10: 0.018275
2025-11-22 22:29:05 - GraphTrainer - INFO - precision@20: 0.003860
2025-11-22 22:29:05 - GraphTrainer - INFO - recall@20: 0.073148
2025-11-22 22:29:05 - GraphTrainer - INFO - hit_rate@20: 0.076935
2025-11-22 22:29:05 - GraphTrainer - INFO - ndcg@20: 0.031293
2025-11-22 22:29:05 - GraphTrainer - INFO - map@20: 0.019446
2025-11-22 22:29:05 - GraphTrainer - INFO - mrr@20: 0.020322
2025-11-22 22:29:05 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:29:05 - GraphTrainer - INFO - ============================================================
2025-11-22 22:29:05 - GraphTrainer - INFO - 开始第 93/1000 轮训练
2025-11-22 22:29:05 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3543, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3701, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3908, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3783, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3779, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3580, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3669, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3640, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3688, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3758, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3710, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3551, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3592, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3557, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3762, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3757, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3569, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3810, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3711, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3701, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3681, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3652, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3661, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3894, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3595, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3714, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3605, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3802, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3685, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3884, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3849, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3908, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3943, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3628, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3620, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3697, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3910, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3781, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3893, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3660, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3683, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3569, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3789, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4018, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3732, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3759, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3742, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3771, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3548, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3586, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3688, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3790, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3743, device='cuda:0', grad_fn=<AddBackward0>)
The 92 training average loss: 0.3706971576501583
2025-11-22 22:29:16 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:29:16 - GraphTrainer - INFO -   precision@5: 0.006161
2025-11-22 22:29:16 - GraphTrainer - INFO -   recall@5: 0.029299
2025-11-22 22:29:16 - GraphTrainer - INFO -   hit_rate@5: 0.030753
2025-11-22 22:29:16 - GraphTrainer - INFO -   ndcg@5: 0.020247
2025-11-22 22:29:16 - GraphTrainer - INFO -   map@5: 0.017007
2025-11-22 22:29:16 - GraphTrainer - INFO -   mrr@5: 0.017723
2025-11-22 22:29:16 - GraphTrainer - INFO -   precision@10: 0.004968
2025-11-22 22:29:16 - GraphTrainer - INFO -   recall@10: 0.047207
2025-11-22 22:29:16 - GraphTrainer - INFO -   hit_rate@10: 0.049576
2025-11-22 22:29:16 - GraphTrainer - INFO -   ndcg@10: 0.026017
2025-11-22 22:29:16 - GraphTrainer - INFO -   map@10: 0.019321
2025-11-22 22:29:16 - GraphTrainer - INFO -   mrr@10: 0.020157
2025-11-22 22:29:16 - GraphTrainer - INFO -   precision@20: 0.003921
2025-11-22 22:29:16 - GraphTrainer - INFO -   recall@20: 0.074149
2025-11-22 22:29:16 - GraphTrainer - INFO -   hit_rate@20: 0.077861
2025-11-22 22:29:16 - GraphTrainer - INFO -   ndcg@20: 0.032898
2025-11-22 22:29:16 - GraphTrainer - INFO -   map@20: 0.021181
2025-11-22 22:29:16 - GraphTrainer - INFO -   mrr@20: 0.022100
2025-11-22 22:29:16 - GraphTrainer - INFO - 第 93 轮训练完成
2025-11-22 22:29:16 - GraphTrainer - INFO - train_loss: 0.368990
2025-11-22 22:29:16 - GraphTrainer - INFO - precision@5: 0.006161
2025-11-22 22:29:16 - GraphTrainer - INFO - recall@5: 0.029299
2025-11-22 22:29:16 - GraphTrainer - INFO - hit_rate@5: 0.030753
2025-11-22 22:29:16 - GraphTrainer - INFO - ndcg@5: 0.020247
2025-11-22 22:29:16 - GraphTrainer - INFO - map@5: 0.017007
2025-11-22 22:29:16 - GraphTrainer - INFO - mrr@5: 0.017723
2025-11-22 22:29:16 - GraphTrainer - INFO - precision@10: 0.004968
2025-11-22 22:29:16 - GraphTrainer - INFO - recall@10: 0.047207
2025-11-22 22:29:16 - GraphTrainer - INFO - hit_rate@10: 0.049576
2025-11-22 22:29:16 - GraphTrainer - INFO - ndcg@10: 0.026017
2025-11-22 22:29:16 - GraphTrainer - INFO - map@10: 0.019321
2025-11-22 22:29:16 - GraphTrainer - INFO - mrr@10: 0.020157
2025-11-22 22:29:16 - GraphTrainer - INFO - precision@20: 0.003921
2025-11-22 22:29:16 - GraphTrainer - INFO - recall@20: 0.074149
2025-11-22 22:29:16 - GraphTrainer - INFO - hit_rate@20: 0.077861
2025-11-22 22:29:16 - GraphTrainer - INFO - ndcg@20: 0.032898
2025-11-22 22:29:16 - GraphTrainer - INFO - map@20: 0.021181
2025-11-22 22:29:16 - GraphTrainer - INFO - mrr@20: 0.022100
2025-11-22 22:29:16 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:29:16 - GraphTrainer - INFO - ============================================================
2025-11-22 22:29:16 - GraphTrainer - INFO - 开始第 94/1000 轮训练
2025-11-22 22:29:16 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3590, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3885, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3579, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3548, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3660, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3750, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3853, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3803, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3816, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3588, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3778, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3671, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3789, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3757, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3712, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3688, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3900, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3669, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3831, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3683, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3730, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3716, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3830, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3544, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3841, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3703, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3822, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3532, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3857, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3617, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3492, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3763, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3815, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3708, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3869, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3529, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3777, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3759, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3614, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3780, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3792, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3575, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3715, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3767, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3614, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3698, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3717, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3730, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3698, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3719, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3770, device='cuda:0', grad_fn=<AddBackward0>)
The 93 training average loss: 0.3689900826791237
2025-11-22 22:29:27 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:29:27 - GraphTrainer - INFO -   precision@5: 0.005822
2025-11-22 22:29:27 - GraphTrainer - INFO -   recall@5: 0.027682
2025-11-22 22:29:27 - GraphTrainer - INFO -   hit_rate@5: 0.029056
2025-11-22 22:29:27 - GraphTrainer - INFO -   ndcg@5: 0.018465
2025-11-22 22:29:27 - GraphTrainer - INFO -   map@5: 0.015183
2025-11-22 22:29:27 - GraphTrainer - INFO -   mrr@5: 0.015881
2025-11-22 22:29:27 - GraphTrainer - INFO -   precision@10: 0.004798
2025-11-22 22:29:27 - GraphTrainer - INFO -   recall@10: 0.045695
2025-11-22 22:29:27 - GraphTrainer - INFO -   hit_rate@10: 0.047879
2025-11-22 22:29:27 - GraphTrainer - INFO -   ndcg@10: 0.024257
2025-11-22 22:29:27 - GraphTrainer - INFO -   map@10: 0.017507
2025-11-22 22:29:27 - GraphTrainer - INFO -   mrr@10: 0.018308
2025-11-22 22:29:27 - GraphTrainer - INFO -   precision@20: 0.003898
2025-11-22 22:29:27 - GraphTrainer - INFO -   recall@20: 0.074035
2025-11-22 22:29:27 - GraphTrainer - INFO -   hit_rate@20: 0.077501
2025-11-22 22:29:27 - GraphTrainer - INFO -   ndcg@20: 0.031446
2025-11-22 22:29:27 - GraphTrainer - INFO -   map@20: 0.019431
2025-11-22 22:29:27 - GraphTrainer - INFO -   mrr@20: 0.020313
2025-11-22 22:29:27 - GraphTrainer - INFO - 第 94 轮训练完成
2025-11-22 22:29:27 - GraphTrainer - INFO - train_loss: 0.367886
2025-11-22 22:29:27 - GraphTrainer - INFO - precision@5: 0.005822
2025-11-22 22:29:27 - GraphTrainer - INFO - recall@5: 0.027682
2025-11-22 22:29:27 - GraphTrainer - INFO - hit_rate@5: 0.029056
2025-11-22 22:29:27 - GraphTrainer - INFO - ndcg@5: 0.018465
2025-11-22 22:29:27 - GraphTrainer - INFO - map@5: 0.015183
2025-11-22 22:29:27 - GraphTrainer - INFO - mrr@5: 0.015881
2025-11-22 22:29:27 - GraphTrainer - INFO - precision@10: 0.004798
2025-11-22 22:29:27 - GraphTrainer - INFO - recall@10: 0.045695
2025-11-22 22:29:27 - GraphTrainer - INFO - hit_rate@10: 0.047879
2025-11-22 22:29:27 - GraphTrainer - INFO - ndcg@10: 0.024257
2025-11-22 22:29:27 - GraphTrainer - INFO - map@10: 0.017507
2025-11-22 22:29:27 - GraphTrainer - INFO - mrr@10: 0.018308
2025-11-22 22:29:27 - GraphTrainer - INFO - precision@20: 0.003898
2025-11-22 22:29:27 - GraphTrainer - INFO - recall@20: 0.074035
2025-11-22 22:29:27 - GraphTrainer - INFO - hit_rate@20: 0.077501
2025-11-22 22:29:27 - GraphTrainer - INFO - ndcg@20: 0.031446
2025-11-22 22:29:27 - GraphTrainer - INFO - map@20: 0.019431
2025-11-22 22:29:27 - GraphTrainer - INFO - mrr@20: 0.020313
2025-11-22 22:29:27 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:29:27 - GraphTrainer - INFO - ============================================================
2025-11-22 22:29:27 - GraphTrainer - INFO - 开始第 95/1000 轮训练
2025-11-22 22:29:27 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3757, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3646, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3757, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3841, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3651, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3558, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3853, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3693, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3653, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3764, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3627, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3688, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3735, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3537, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3798, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3652, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3659, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3570, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3784, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3785, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3999, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3920, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3718, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3484, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3723, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3679, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3962, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3844, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3695, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3764, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3740, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3869, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3516, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3661, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3839, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3725, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3613, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3613, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3602, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3646, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3676, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3851, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3716, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>)
The 94 training average loss: 0.3678864148156396
2025-11-22 22:29:38 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:29:38 - GraphTrainer - INFO -   precision@5: 0.006120
2025-11-22 22:29:38 - GraphTrainer - INFO -   recall@5: 0.029210
2025-11-22 22:29:38 - GraphTrainer - INFO -   hit_rate@5: 0.030548
2025-11-22 22:29:38 - GraphTrainer - INFO -   ndcg@5: 0.018859
2025-11-22 22:29:38 - GraphTrainer - INFO -   map@5: 0.015260
2025-11-22 22:29:38 - GraphTrainer - INFO -   mrr@5: 0.015806
2025-11-22 22:29:38 - GraphTrainer - INFO -   precision@10: 0.004937
2025-11-22 22:29:38 - GraphTrainer - INFO -   recall@10: 0.046928
2025-11-22 22:29:38 - GraphTrainer - INFO -   hit_rate@10: 0.049267
2025-11-22 22:29:38 - GraphTrainer - INFO -   ndcg@10: 0.024605
2025-11-22 22:29:38 - GraphTrainer - INFO -   map@10: 0.017579
2025-11-22 22:29:38 - GraphTrainer - INFO -   mrr@10: 0.018260
2025-11-22 22:29:38 - GraphTrainer - INFO -   precision@20: 0.003896
2025-11-22 22:29:38 - GraphTrainer - INFO -   recall@20: 0.073986
2025-11-22 22:29:38 - GraphTrainer - INFO -   hit_rate@20: 0.077603
2025-11-22 22:29:38 - GraphTrainer - INFO -   ndcg@20: 0.031453
2025-11-22 22:29:38 - GraphTrainer - INFO -   map@20: 0.019405
2025-11-22 22:29:38 - GraphTrainer - INFO -   mrr@20: 0.020168
2025-11-22 22:29:38 - GraphTrainer - INFO - 第 95 轮训练完成
2025-11-22 22:29:38 - GraphTrainer - INFO - train_loss: 0.366942
2025-11-22 22:29:38 - GraphTrainer - INFO - precision@5: 0.006120
2025-11-22 22:29:38 - GraphTrainer - INFO - recall@5: 0.029210
2025-11-22 22:29:38 - GraphTrainer - INFO - hit_rate@5: 0.030548
2025-11-22 22:29:38 - GraphTrainer - INFO - ndcg@5: 0.018859
2025-11-22 22:29:38 - GraphTrainer - INFO - map@5: 0.015260
2025-11-22 22:29:38 - GraphTrainer - INFO - mrr@5: 0.015806
2025-11-22 22:29:38 - GraphTrainer - INFO - precision@10: 0.004937
2025-11-22 22:29:38 - GraphTrainer - INFO - recall@10: 0.046928
2025-11-22 22:29:38 - GraphTrainer - INFO - hit_rate@10: 0.049267
2025-11-22 22:29:38 - GraphTrainer - INFO - ndcg@10: 0.024605
2025-11-22 22:29:38 - GraphTrainer - INFO - map@10: 0.017579
2025-11-22 22:29:38 - GraphTrainer - INFO - mrr@10: 0.018260
2025-11-22 22:29:38 - GraphTrainer - INFO - precision@20: 0.003896
2025-11-22 22:29:38 - GraphTrainer - INFO - recall@20: 0.073986
2025-11-22 22:29:38 - GraphTrainer - INFO - hit_rate@20: 0.077603
2025-11-22 22:29:38 - GraphTrainer - INFO - ndcg@20: 0.031453
2025-11-22 22:29:38 - GraphTrainer - INFO - map@20: 0.019405
2025-11-22 22:29:38 - GraphTrainer - INFO - mrr@20: 0.020168
2025-11-22 22:29:38 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:29:38 - GraphTrainer - INFO - ============================================================
2025-11-22 22:29:38 - GraphTrainer - INFO - 开始第 96/1000 轮训练
2025-11-22 22:29:38 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3652, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3728, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3830, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3574, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3855, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3735, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3789, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3628, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3789, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3704, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3518, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3657, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3647, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3718, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3611, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3710, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3595, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3616, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3664, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3559, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3839, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3728, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3730, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3653, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3946, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3607, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3615, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3883, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3660, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3624, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3770, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3834, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3588, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3690, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3840, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3695, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3573, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4015, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3642, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3506, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3681, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3767, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3861, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3537, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3651, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3651, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3742, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3634, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3611, device='cuda:0', grad_fn=<AddBackward0>)
The 95 training average loss: 0.36694176238158654
2025-11-22 22:29:49 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:29:49 - GraphTrainer - INFO -   precision@5: 0.005945
2025-11-22 22:29:49 - GraphTrainer - INFO -   recall@5: 0.028266
2025-11-22 22:29:49 - GraphTrainer - INFO -   hit_rate@5: 0.029673
2025-11-22 22:29:49 - GraphTrainer - INFO -   ndcg@5: 0.018238
2025-11-22 22:29:49 - GraphTrainer - INFO -   map@5: 0.014718
2025-11-22 22:29:49 - GraphTrainer - INFO -   mrr@5: 0.015361
2025-11-22 22:29:49 - GraphTrainer - INFO -   precision@10: 0.004937
2025-11-22 22:29:49 - GraphTrainer - INFO -   recall@10: 0.047045
2025-11-22 22:29:49 - GraphTrainer - INFO -   hit_rate@10: 0.049216
2025-11-22 22:29:49 - GraphTrainer - INFO -   ndcg@10: 0.024291
2025-11-22 22:29:49 - GraphTrainer - INFO -   map@10: 0.017158
2025-11-22 22:29:49 - GraphTrainer - INFO -   mrr@10: 0.017899
2025-11-22 22:29:49 - GraphTrainer - INFO -   precision@20: 0.003937
2025-11-22 22:29:49 - GraphTrainer - INFO -   recall@20: 0.074566
2025-11-22 22:29:49 - GraphTrainer - INFO -   hit_rate@20: 0.078478
2025-11-22 22:29:49 - GraphTrainer - INFO -   ndcg@20: 0.031296
2025-11-22 22:29:49 - GraphTrainer - INFO -   map@20: 0.019030
2025-11-22 22:29:49 - GraphTrainer - INFO -   mrr@20: 0.019884
2025-11-22 22:29:49 - GraphTrainer - INFO - 第 96 轮训练完成
2025-11-22 22:29:49 - GraphTrainer - INFO - train_loss: 0.369942
2025-11-22 22:29:49 - GraphTrainer - INFO - precision@5: 0.005945
2025-11-22 22:29:49 - GraphTrainer - INFO - recall@5: 0.028266
2025-11-22 22:29:49 - GraphTrainer - INFO - hit_rate@5: 0.029673
2025-11-22 22:29:49 - GraphTrainer - INFO - ndcg@5: 0.018238
2025-11-22 22:29:49 - GraphTrainer - INFO - map@5: 0.014718
2025-11-22 22:29:49 - GraphTrainer - INFO - mrr@5: 0.015361
2025-11-22 22:29:49 - GraphTrainer - INFO - precision@10: 0.004937
2025-11-22 22:29:49 - GraphTrainer - INFO - recall@10: 0.047045
2025-11-22 22:29:49 - GraphTrainer - INFO - hit_rate@10: 0.049216
2025-11-22 22:29:49 - GraphTrainer - INFO - ndcg@10: 0.024291
2025-11-22 22:29:49 - GraphTrainer - INFO - map@10: 0.017158
2025-11-22 22:29:49 - GraphTrainer - INFO - mrr@10: 0.017899
2025-11-22 22:29:49 - GraphTrainer - INFO - precision@20: 0.003937
2025-11-22 22:29:49 - GraphTrainer - INFO - recall@20: 0.074566
2025-11-22 22:29:49 - GraphTrainer - INFO - hit_rate@20: 0.078478
2025-11-22 22:29:49 - GraphTrainer - INFO - ndcg@20: 0.031296
2025-11-22 22:29:49 - GraphTrainer - INFO - map@20: 0.019030
2025-11-22 22:29:49 - GraphTrainer - INFO - mrr@20: 0.019884
2025-11-22 22:29:49 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:29:49 - GraphTrainer - INFO - ============================================================
2025-11-22 22:29:49 - GraphTrainer - INFO - 开始第 97/1000 轮训练
2025-11-22 22:29:49 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3592, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3879, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3688, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3688, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3751, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3643, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3669, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3763, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3806, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3774, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3622, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3633, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3683, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3729, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3563, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3608, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3777, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4010, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3691, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3554, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3763, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3604, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3649, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3657, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3598, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3764, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3689, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3707, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3821, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3804, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3754, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3694, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3659, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3773, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3955, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3809, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3736, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3747, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3888, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3676, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3612, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3681, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3817, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3910, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3818, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3700, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3558, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3701, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3786, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3550, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3591, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3827, device='cuda:0', grad_fn=<AddBackward0>)
The 96 training average loss: 0.36994154545767555
2025-11-22 22:30:00 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:30:00 - GraphTrainer - INFO -   precision@5: 0.005708
2025-11-22 22:30:00 - GraphTrainer - INFO -   recall@5: 0.027283
2025-11-22 22:30:00 - GraphTrainer - INFO -   hit_rate@5: 0.028439
2025-11-22 22:30:00 - GraphTrainer - INFO -   ndcg@5: 0.017979
2025-11-22 22:30:00 - GraphTrainer - INFO -   map@5: 0.014731
2025-11-22 22:30:00 - GraphTrainer - INFO -   mrr@5: 0.015267
2025-11-22 22:30:00 - GraphTrainer - INFO -   precision@10: 0.004844
2025-11-22 22:30:00 - GraphTrainer - INFO -   recall@10: 0.046139
2025-11-22 22:30:00 - GraphTrainer - INFO -   hit_rate@10: 0.048290
2025-11-22 22:30:00 - GraphTrainer - INFO -   ndcg@10: 0.024100
2025-11-22 22:30:00 - GraphTrainer - INFO -   map@10: 0.017211
2025-11-22 22:30:00 - GraphTrainer - INFO -   mrr@10: 0.017886
2025-11-22 22:30:00 - GraphTrainer - INFO -   precision@20: 0.003811
2025-11-22 22:30:00 - GraphTrainer - INFO -   recall@20: 0.072269
2025-11-22 22:30:00 - GraphTrainer - INFO -   hit_rate@20: 0.075752
2025-11-22 22:30:00 - GraphTrainer - INFO -   ndcg@20: 0.030744
2025-11-22 22:30:00 - GraphTrainer - INFO -   map@20: 0.018991
2025-11-22 22:30:00 - GraphTrainer - INFO -   mrr@20: 0.019755
2025-11-22 22:30:00 - GraphTrainer - INFO - 第 97 轮训练完成
2025-11-22 22:30:00 - GraphTrainer - INFO - train_loss: 0.367023
2025-11-22 22:30:00 - GraphTrainer - INFO - precision@5: 0.005708
2025-11-22 22:30:00 - GraphTrainer - INFO - recall@5: 0.027283
2025-11-22 22:30:00 - GraphTrainer - INFO - hit_rate@5: 0.028439
2025-11-22 22:30:00 - GraphTrainer - INFO - ndcg@5: 0.017979
2025-11-22 22:30:00 - GraphTrainer - INFO - map@5: 0.014731
2025-11-22 22:30:00 - GraphTrainer - INFO - mrr@5: 0.015267
2025-11-22 22:30:00 - GraphTrainer - INFO - precision@10: 0.004844
2025-11-22 22:30:00 - GraphTrainer - INFO - recall@10: 0.046139
2025-11-22 22:30:00 - GraphTrainer - INFO - hit_rate@10: 0.048290
2025-11-22 22:30:00 - GraphTrainer - INFO - ndcg@10: 0.024100
2025-11-22 22:30:00 - GraphTrainer - INFO - map@10: 0.017211
2025-11-22 22:30:00 - GraphTrainer - INFO - mrr@10: 0.017886
2025-11-22 22:30:00 - GraphTrainer - INFO - precision@20: 0.003811
2025-11-22 22:30:00 - GraphTrainer - INFO - recall@20: 0.072269
2025-11-22 22:30:00 - GraphTrainer - INFO - hit_rate@20: 0.075752
2025-11-22 22:30:00 - GraphTrainer - INFO - ndcg@20: 0.030744
2025-11-22 22:30:00 - GraphTrainer - INFO - map@20: 0.018991
2025-11-22 22:30:00 - GraphTrainer - INFO - mrr@20: 0.019755
2025-11-22 22:30:00 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:30:00 - GraphTrainer - INFO - ============================================================
2025-11-22 22:30:00 - GraphTrainer - INFO - 开始第 98/1000 轮训练
2025-11-22 22:30:00 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3898, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3745, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3773, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3816, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3617, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3537, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3566, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3887, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3882, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3584, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3525, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3521, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3810, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3679, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3771, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3830, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3591, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3691, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3969, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3744, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3603, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3743, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3720, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3534, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3797, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3669, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3570, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3757, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3674, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4005, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3783, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3687, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3848, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3648, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3902, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3807, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3785, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3706, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3650, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3807, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3702, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3629, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3866, device='cuda:0', grad_fn=<AddBackward0>)
The 97 training average loss: 0.367022892010623
2025-11-22 22:30:11 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:30:11 - GraphTrainer - INFO -   precision@5: 0.005616
2025-11-22 22:30:11 - GraphTrainer - INFO -   recall@5: 0.026577
2025-11-22 22:30:11 - GraphTrainer - INFO -   hit_rate@5: 0.028028
2025-11-22 22:30:11 - GraphTrainer - INFO -   ndcg@5: 0.017447
2025-11-22 22:30:11 - GraphTrainer - INFO -   map@5: 0.014227
2025-11-22 22:30:11 - GraphTrainer - INFO -   mrr@5: 0.014862
2025-11-22 22:30:11 - GraphTrainer - INFO -   precision@10: 0.004639
2025-11-22 22:30:11 - GraphTrainer - INFO -   recall@10: 0.044054
2025-11-22 22:30:11 - GraphTrainer - INFO -   hit_rate@10: 0.046336
2025-11-22 22:30:11 - GraphTrainer - INFO -   ndcg@10: 0.023084
2025-11-22 22:30:11 - GraphTrainer - INFO -   map@10: 0.016492
2025-11-22 22:30:11 - GraphTrainer - INFO -   mrr@10: 0.017236
2025-11-22 22:30:11 - GraphTrainer - INFO -   precision@20: 0.003816
2025-11-22 22:30:11 - GraphTrainer - INFO -   recall@20: 0.072462
2025-11-22 22:30:11 - GraphTrainer - INFO -   hit_rate@20: 0.075855
2025-11-22 22:30:11 - GraphTrainer - INFO -   ndcg@20: 0.030261
2025-11-22 22:30:11 - GraphTrainer - INFO -   map@20: 0.018404
2025-11-22 22:30:11 - GraphTrainer - INFO -   mrr@20: 0.019220
2025-11-22 22:30:11 - GraphTrainer - INFO - 第 98 轮训练完成
2025-11-22 22:30:11 - GraphTrainer - INFO - train_loss: 0.364866
2025-11-22 22:30:11 - GraphTrainer - INFO - precision@5: 0.005616
2025-11-22 22:30:11 - GraphTrainer - INFO - recall@5: 0.026577
2025-11-22 22:30:11 - GraphTrainer - INFO - hit_rate@5: 0.028028
2025-11-22 22:30:11 - GraphTrainer - INFO - ndcg@5: 0.017447
2025-11-22 22:30:11 - GraphTrainer - INFO - map@5: 0.014227
2025-11-22 22:30:11 - GraphTrainer - INFO - mrr@5: 0.014862
2025-11-22 22:30:11 - GraphTrainer - INFO - precision@10: 0.004639
2025-11-22 22:30:11 - GraphTrainer - INFO - recall@10: 0.044054
2025-11-22 22:30:11 - GraphTrainer - INFO - hit_rate@10: 0.046336
2025-11-22 22:30:11 - GraphTrainer - INFO - ndcg@10: 0.023084
2025-11-22 22:30:11 - GraphTrainer - INFO - map@10: 0.016492
2025-11-22 22:30:11 - GraphTrainer - INFO - mrr@10: 0.017236
2025-11-22 22:30:11 - GraphTrainer - INFO - precision@20: 0.003816
2025-11-22 22:30:11 - GraphTrainer - INFO - recall@20: 0.072462
2025-11-22 22:30:11 - GraphTrainer - INFO - hit_rate@20: 0.075855
2025-11-22 22:30:11 - GraphTrainer - INFO - ndcg@20: 0.030261
2025-11-22 22:30:11 - GraphTrainer - INFO - map@20: 0.018404
2025-11-22 22:30:11 - GraphTrainer - INFO - mrr@20: 0.019220
2025-11-22 22:30:11 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:30:11 - GraphTrainer - INFO - ============================================================
2025-11-22 22:30:11 - GraphTrainer - INFO - 开始第 99/1000 轮训练
2025-11-22 22:30:11 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3592, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3532, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3776, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3803, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3655, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3595, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3888, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3696, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3701, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3560, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3873, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3681, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3770, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3604, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3825, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3774, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3903, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3555, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3586, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3676, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3654, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3635, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3507, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3704, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3608, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3825, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3662, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3680, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3681, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3568, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3466, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3613, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3627, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3643, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3595, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3685, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3543, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3577, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3797, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3837, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3665, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3743, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3730, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3760, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3778, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3661, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3571, device='cuda:0', grad_fn=<AddBackward0>)
The 98 training average loss: 0.3648661416152428
2025-11-22 22:30:22 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:30:22 - GraphTrainer - INFO -   precision@5: 0.005822
2025-11-22 22:30:22 - GraphTrainer - INFO -   recall@5: 0.027648
2025-11-22 22:30:22 - GraphTrainer - INFO -   hit_rate@5: 0.029056
2025-11-22 22:30:22 - GraphTrainer - INFO -   ndcg@5: 0.017712
2025-11-22 22:30:22 - GraphTrainer - INFO -   map@5: 0.014226
2025-11-22 22:30:22 - GraphTrainer - INFO -   mrr@5: 0.014922
2025-11-22 22:30:22 - GraphTrainer - INFO -   precision@10: 0.004767
2025-11-22 22:30:22 - GraphTrainer - INFO -   recall@10: 0.045206
2025-11-22 22:30:22 - GraphTrainer - INFO -   hit_rate@10: 0.047621
2025-11-22 22:30:22 - GraphTrainer - INFO -   ndcg@10: 0.023410
2025-11-22 22:30:22 - GraphTrainer - INFO -   map@10: 0.016532
2025-11-22 22:30:22 - GraphTrainer - INFO -   mrr@10: 0.017362
2025-11-22 22:30:22 - GraphTrainer - INFO -   precision@20: 0.003808
2025-11-22 22:30:22 - GraphTrainer - INFO -   recall@20: 0.072508
2025-11-22 22:30:22 - GraphTrainer - INFO -   hit_rate@20: 0.076009
2025-11-22 22:30:22 - GraphTrainer - INFO -   ndcg@20: 0.030310
2025-11-22 22:30:22 - GraphTrainer - INFO -   map@20: 0.018377
2025-11-22 22:30:22 - GraphTrainer - INFO -   mrr@20: 0.019278
2025-11-22 22:30:22 - GraphTrainer - INFO - 第 99 轮训练完成
2025-11-22 22:30:22 - GraphTrainer - INFO - train_loss: 0.362430
2025-11-22 22:30:22 - GraphTrainer - INFO - precision@5: 0.005822
2025-11-22 22:30:22 - GraphTrainer - INFO - recall@5: 0.027648
2025-11-22 22:30:22 - GraphTrainer - INFO - hit_rate@5: 0.029056
2025-11-22 22:30:22 - GraphTrainer - INFO - ndcg@5: 0.017712
2025-11-22 22:30:22 - GraphTrainer - INFO - map@5: 0.014226
2025-11-22 22:30:22 - GraphTrainer - INFO - mrr@5: 0.014922
2025-11-22 22:30:22 - GraphTrainer - INFO - precision@10: 0.004767
2025-11-22 22:30:22 - GraphTrainer - INFO - recall@10: 0.045206
2025-11-22 22:30:22 - GraphTrainer - INFO - hit_rate@10: 0.047621
2025-11-22 22:30:22 - GraphTrainer - INFO - ndcg@10: 0.023410
2025-11-22 22:30:22 - GraphTrainer - INFO - map@10: 0.016532
2025-11-22 22:30:22 - GraphTrainer - INFO - mrr@10: 0.017362
2025-11-22 22:30:22 - GraphTrainer - INFO - precision@20: 0.003808
2025-11-22 22:30:22 - GraphTrainer - INFO - recall@20: 0.072508
2025-11-22 22:30:22 - GraphTrainer - INFO - hit_rate@20: 0.076009
2025-11-22 22:30:22 - GraphTrainer - INFO - ndcg@20: 0.030310
2025-11-22 22:30:22 - GraphTrainer - INFO - map@20: 0.018377
2025-11-22 22:30:22 - GraphTrainer - INFO - mrr@20: 0.019278
2025-11-22 22:30:22 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:30:22 - GraphTrainer - INFO - ============================================================
2025-11-22 22:30:22 - GraphTrainer - INFO - 开始第 100/1000 轮训练
2025-11-22 22:30:22 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4121, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3638, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3644, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3473, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3690, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3635, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3584, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3684, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3652, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3637, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3561, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3666, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3604, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3727, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3490, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3632, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3640, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3620, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3557, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3717, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3649, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3756, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3819, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3628, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3689, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3650, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3591, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3462, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3748, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3732, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3558, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3652, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3657, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3611, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3825, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3620, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3518, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3569, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3720, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3525, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3492, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3663, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3734, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3679, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3856, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3509, device='cuda:0', grad_fn=<AddBackward0>)
The 99 training average loss: 0.3624299029851782
2025-11-22 22:30:33 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:30:33 - GraphTrainer - INFO -   precision@5: 0.005976
2025-11-22 22:30:33 - GraphTrainer - INFO -   recall@5: 0.028293
2025-11-22 22:30:33 - GraphTrainer - INFO -   hit_rate@5: 0.029828
2025-11-22 22:30:33 - GraphTrainer - INFO -   ndcg@5: 0.018711
2025-11-22 22:30:33 - GraphTrainer - INFO -   map@5: 0.015333
2025-11-22 22:30:33 - GraphTrainer - INFO -   mrr@5: 0.016012
2025-11-22 22:30:33 - GraphTrainer - INFO -   precision@10: 0.004932
2025-11-22 22:30:33 - GraphTrainer - INFO -   recall@10: 0.046634
2025-11-22 22:30:33 - GraphTrainer - INFO -   hit_rate@10: 0.049216
2025-11-22 22:30:33 - GraphTrainer - INFO -   ndcg@10: 0.024616
2025-11-22 22:30:33 - GraphTrainer - INFO -   map@10: 0.017692
2025-11-22 22:30:33 - GraphTrainer - INFO -   mrr@10: 0.018508
2025-11-22 22:30:33 - GraphTrainer - INFO -   precision@20: 0.003862
2025-11-22 22:30:33 - GraphTrainer - INFO -   recall@20: 0.072831
2025-11-22 22:30:33 - GraphTrainer - INFO -   hit_rate@20: 0.076678
2025-11-22 22:30:33 - GraphTrainer - INFO -   ndcg@20: 0.031250
2025-11-22 22:30:33 - GraphTrainer - INFO -   map@20: 0.019457
2025-11-22 22:30:33 - GraphTrainer - INFO -   mrr@20: 0.020348
2025-11-22 22:30:33 - GraphTrainer - INFO - 第 100 轮训练完成
2025-11-22 22:30:33 - GraphTrainer - INFO - train_loss: 0.362291
2025-11-22 22:30:33 - GraphTrainer - INFO - precision@5: 0.005976
2025-11-22 22:30:33 - GraphTrainer - INFO - recall@5: 0.028293
2025-11-22 22:30:33 - GraphTrainer - INFO - hit_rate@5: 0.029828
2025-11-22 22:30:33 - GraphTrainer - INFO - ndcg@5: 0.018711
2025-11-22 22:30:33 - GraphTrainer - INFO - map@5: 0.015333
2025-11-22 22:30:33 - GraphTrainer - INFO - mrr@5: 0.016012
2025-11-22 22:30:33 - GraphTrainer - INFO - precision@10: 0.004932
2025-11-22 22:30:33 - GraphTrainer - INFO - recall@10: 0.046634
2025-11-22 22:30:33 - GraphTrainer - INFO - hit_rate@10: 0.049216
2025-11-22 22:30:33 - GraphTrainer - INFO - ndcg@10: 0.024616
2025-11-22 22:30:33 - GraphTrainer - INFO - map@10: 0.017692
2025-11-22 22:30:33 - GraphTrainer - INFO - mrr@10: 0.018508
2025-11-22 22:30:33 - GraphTrainer - INFO - precision@20: 0.003862
2025-11-22 22:30:33 - GraphTrainer - INFO - recall@20: 0.072831
2025-11-22 22:30:33 - GraphTrainer - INFO - hit_rate@20: 0.076678
2025-11-22 22:30:33 - GraphTrainer - INFO - ndcg@20: 0.031250
2025-11-22 22:30:33 - GraphTrainer - INFO - map@20: 0.019457
2025-11-22 22:30:33 - GraphTrainer - INFO - mrr@20: 0.020348
2025-11-22 22:30:33 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:30:33 - GraphTrainer - INFO - 检查点已保存: Epoch 100 -> ./checkpoints/checkpoint_epoch_100.pth
2025-11-22 22:30:33 - GraphTrainer - INFO - ============================================================
2025-11-22 22:30:33 - GraphTrainer - INFO - 开始第 101/1000 轮训练
2025-11-22 22:30:33 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3490, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3681, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3792, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3616, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3628, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3624, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3625, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3673, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3516, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3731, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3935, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3590, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3714, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3864, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3712, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3611, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3797, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3637, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3656, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3794, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3626, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3655, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3602, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3771, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3658, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3554, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3750, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3740, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3802, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3843, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3462, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3777, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3742, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3597, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3836, device='cuda:0', grad_fn=<AddBackward0>)
The 100 training average loss: 0.36229052882770013
2025-11-22 22:30:44 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:30:44 - GraphTrainer - INFO -   precision@5: 0.006140
2025-11-22 22:30:44 - GraphTrainer - INFO -   recall@5: 0.029145
2025-11-22 22:30:44 - GraphTrainer - INFO -   hit_rate@5: 0.030651
2025-11-22 22:30:44 - GraphTrainer - INFO -   ndcg@5: 0.018634
2025-11-22 22:30:44 - GraphTrainer - INFO -   map@5: 0.014959
2025-11-22 22:30:44 - GraphTrainer - INFO -   mrr@5: 0.015632
2025-11-22 22:30:44 - GraphTrainer - INFO -   precision@10: 0.004891
2025-11-22 22:30:44 - GraphTrainer - INFO -   recall@10: 0.046306
2025-11-22 22:30:44 - GraphTrainer - INFO -   hit_rate@10: 0.048701
2025-11-22 22:30:44 - GraphTrainer - INFO -   ndcg@10: 0.024194
2025-11-22 22:30:44 - GraphTrainer - INFO -   map@10: 0.017204
2025-11-22 22:30:44 - GraphTrainer - INFO -   mrr@10: 0.017988
2025-11-22 22:30:44 - GraphTrainer - INFO -   precision@20: 0.003885
2025-11-22 22:30:44 - GraphTrainer - INFO -   recall@20: 0.073575
2025-11-22 22:30:44 - GraphTrainer - INFO -   hit_rate@20: 0.077295
2025-11-22 22:30:44 - GraphTrainer - INFO -   ndcg@20: 0.031083
2025-11-22 22:30:44 - GraphTrainer - INFO -   map@20: 0.019036
2025-11-22 22:30:44 - GraphTrainer - INFO -   mrr@20: 0.019905
2025-11-22 22:30:44 - GraphTrainer - INFO - 第 101 轮训练完成
2025-11-22 22:30:44 - GraphTrainer - INFO - train_loss: 0.366612
2025-11-22 22:30:44 - GraphTrainer - INFO - precision@5: 0.006140
2025-11-22 22:30:44 - GraphTrainer - INFO - recall@5: 0.029145
2025-11-22 22:30:44 - GraphTrainer - INFO - hit_rate@5: 0.030651
2025-11-22 22:30:44 - GraphTrainer - INFO - ndcg@5: 0.018634
2025-11-22 22:30:44 - GraphTrainer - INFO - map@5: 0.014959
2025-11-22 22:30:44 - GraphTrainer - INFO - mrr@5: 0.015632
2025-11-22 22:30:44 - GraphTrainer - INFO - precision@10: 0.004891
2025-11-22 22:30:44 - GraphTrainer - INFO - recall@10: 0.046306
2025-11-22 22:30:44 - GraphTrainer - INFO - hit_rate@10: 0.048701
2025-11-22 22:30:44 - GraphTrainer - INFO - ndcg@10: 0.024194
2025-11-22 22:30:44 - GraphTrainer - INFO - map@10: 0.017204
2025-11-22 22:30:44 - GraphTrainer - INFO - mrr@10: 0.017988
2025-11-22 22:30:44 - GraphTrainer - INFO - precision@20: 0.003885
2025-11-22 22:30:44 - GraphTrainer - INFO - recall@20: 0.073575
2025-11-22 22:30:44 - GraphTrainer - INFO - hit_rate@20: 0.077295
2025-11-22 22:30:44 - GraphTrainer - INFO - ndcg@20: 0.031083
2025-11-22 22:30:44 - GraphTrainer - INFO - map@20: 0.019036
2025-11-22 22:30:44 - GraphTrainer - INFO - mrr@20: 0.019905
2025-11-22 22:30:44 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:30:44 - GraphTrainer - INFO - ============================================================
2025-11-22 22:30:44 - GraphTrainer - INFO - 开始第 102/1000 轮训练
2025-11-22 22:30:44 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3659, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3950, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3801, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3707, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3557, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3736, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4047, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3839, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3728, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3956, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3817, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3697, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3813, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3554, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3644, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3637, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3886, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3695, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3473, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3660, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3663, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3549, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3573, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3756, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3833, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3899, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3764, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3664, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3599, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3878, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3738, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3650, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3576, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3619, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3664, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3812, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3537, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3722, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3633, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3599, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3831, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3617, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3878, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3673, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3791, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>)
The 101 training average loss: 0.36661203616651994
2025-11-22 22:30:55 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:30:55 - GraphTrainer - INFO -   precision@5: 0.005996
2025-11-22 22:30:55 - GraphTrainer - INFO -   recall@5: 0.028480
2025-11-22 22:30:55 - GraphTrainer - INFO -   hit_rate@5: 0.029982
2025-11-22 22:30:55 - GraphTrainer - INFO -   ndcg@5: 0.018615
2025-11-22 22:30:55 - GraphTrainer - INFO -   map@5: 0.015137
2025-11-22 22:30:55 - GraphTrainer - INFO -   mrr@5: 0.015888
2025-11-22 22:30:55 - GraphTrainer - INFO -   precision@10: 0.004757
2025-11-22 22:30:55 - GraphTrainer - INFO -   recall@10: 0.045339
2025-11-22 22:30:55 - GraphTrainer - INFO -   hit_rate@10: 0.047519
2025-11-22 22:30:55 - GraphTrainer - INFO -   ndcg@10: 0.024049
2025-11-22 22:30:55 - GraphTrainer - INFO -   map@10: 0.017325
2025-11-22 22:30:55 - GraphTrainer - INFO -   mrr@10: 0.018167
2025-11-22 22:30:55 - GraphTrainer - INFO -   precision@20: 0.003818
2025-11-22 22:30:55 - GraphTrainer - INFO -   recall@20: 0.072448
2025-11-22 22:30:55 - GraphTrainer - INFO -   hit_rate@20: 0.075906
2025-11-22 22:30:55 - GraphTrainer - INFO -   ndcg@20: 0.030950
2025-11-22 22:30:55 - GraphTrainer - INFO -   map@20: 0.019185
2025-11-22 22:30:55 - GraphTrainer - INFO -   mrr@20: 0.020101
2025-11-22 22:30:55 - GraphTrainer - INFO - 第 102 轮训练完成
2025-11-22 22:30:55 - GraphTrainer - INFO - train_loss: 0.360487
2025-11-22 22:30:55 - GraphTrainer - INFO - precision@5: 0.005996
2025-11-22 22:30:55 - GraphTrainer - INFO - recall@5: 0.028480
2025-11-22 22:30:55 - GraphTrainer - INFO - hit_rate@5: 0.029982
2025-11-22 22:30:55 - GraphTrainer - INFO - ndcg@5: 0.018615
2025-11-22 22:30:55 - GraphTrainer - INFO - map@5: 0.015137
2025-11-22 22:30:55 - GraphTrainer - INFO - mrr@5: 0.015888
2025-11-22 22:30:55 - GraphTrainer - INFO - precision@10: 0.004757
2025-11-22 22:30:55 - GraphTrainer - INFO - recall@10: 0.045339
2025-11-22 22:30:55 - GraphTrainer - INFO - hit_rate@10: 0.047519
2025-11-22 22:30:55 - GraphTrainer - INFO - ndcg@10: 0.024049
2025-11-22 22:30:55 - GraphTrainer - INFO - map@10: 0.017325
2025-11-22 22:30:55 - GraphTrainer - INFO - mrr@10: 0.018167
2025-11-22 22:30:55 - GraphTrainer - INFO - precision@20: 0.003818
2025-11-22 22:30:55 - GraphTrainer - INFO - recall@20: 0.072448
2025-11-22 22:30:55 - GraphTrainer - INFO - hit_rate@20: 0.075906
2025-11-22 22:30:55 - GraphTrainer - INFO - ndcg@20: 0.030950
2025-11-22 22:30:55 - GraphTrainer - INFO - map@20: 0.019185
2025-11-22 22:30:55 - GraphTrainer - INFO - mrr@20: 0.020101
2025-11-22 22:30:55 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:30:55 - GraphTrainer - INFO - ============================================================
2025-11-22 22:30:55 - GraphTrainer - INFO - 开始第 103/1000 轮训练
2025-11-22 22:30:55 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3704, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3577, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3670, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3555, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3707, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3563, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3659, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3506, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3691, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3730, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3788, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3741, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3537, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3598, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4009, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3837, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3748, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3705, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3754, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3706, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3649, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3638, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3728, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3628, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3568, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3700, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3848, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3911, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3773, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3755, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3641, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3588, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3584, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3966, device='cuda:0', grad_fn=<AddBackward0>)
The 102 training average loss: 0.3604870176520841
2025-11-22 22:31:06 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:31:06 - GraphTrainer - INFO -   precision@5: 0.006089
2025-11-22 22:31:06 - GraphTrainer - INFO -   recall@5: 0.028839
2025-11-22 22:31:06 - GraphTrainer - INFO -   hit_rate@5: 0.030342
2025-11-22 22:31:06 - GraphTrainer - INFO -   ndcg@5: 0.018722
2025-11-22 22:31:06 - GraphTrainer - INFO -   map@5: 0.015158
2025-11-22 22:31:06 - GraphTrainer - INFO -   mrr@5: 0.015834
2025-11-22 22:31:06 - GraphTrainer - INFO -   precision@10: 0.004978
2025-11-22 22:31:06 - GraphTrainer - INFO -   recall@10: 0.047216
2025-11-22 22:31:06 - GraphTrainer - INFO -   hit_rate@10: 0.049627
2025-11-22 22:31:06 - GraphTrainer - INFO -   ndcg@10: 0.024665
2025-11-22 22:31:06 - GraphTrainer - INFO -   map@10: 0.017558
2025-11-22 22:31:06 - GraphTrainer - INFO -   mrr@10: 0.018349
2025-11-22 22:31:06 - GraphTrainer - INFO -   precision@20: 0.003921
2025-11-22 22:31:06 - GraphTrainer - INFO -   recall@20: 0.074201
2025-11-22 22:31:06 - GraphTrainer - INFO -   hit_rate@20: 0.078169
2025-11-22 22:31:06 - GraphTrainer - INFO -   ndcg@20: 0.031507
2025-11-22 22:31:06 - GraphTrainer - INFO -   map@20: 0.019378
2025-11-22 22:31:06 - GraphTrainer - INFO -   mrr@20: 0.020272
2025-11-22 22:31:06 - GraphTrainer - INFO - 第 103 轮训练完成
2025-11-22 22:31:06 - GraphTrainer - INFO - train_loss: 0.363111
2025-11-22 22:31:06 - GraphTrainer - INFO - precision@5: 0.006089
2025-11-22 22:31:06 - GraphTrainer - INFO - recall@5: 0.028839
2025-11-22 22:31:06 - GraphTrainer - INFO - hit_rate@5: 0.030342
2025-11-22 22:31:06 - GraphTrainer - INFO - ndcg@5: 0.018722
2025-11-22 22:31:06 - GraphTrainer - INFO - map@5: 0.015158
2025-11-22 22:31:06 - GraphTrainer - INFO - mrr@5: 0.015834
2025-11-22 22:31:06 - GraphTrainer - INFO - precision@10: 0.004978
2025-11-22 22:31:06 - GraphTrainer - INFO - recall@10: 0.047216
2025-11-22 22:31:06 - GraphTrainer - INFO - hit_rate@10: 0.049627
2025-11-22 22:31:06 - GraphTrainer - INFO - ndcg@10: 0.024665
2025-11-22 22:31:06 - GraphTrainer - INFO - map@10: 0.017558
2025-11-22 22:31:06 - GraphTrainer - INFO - mrr@10: 0.018349
2025-11-22 22:31:06 - GraphTrainer - INFO - precision@20: 0.003921
2025-11-22 22:31:06 - GraphTrainer - INFO - recall@20: 0.074201
2025-11-22 22:31:06 - GraphTrainer - INFO - hit_rate@20: 0.078169
2025-11-22 22:31:06 - GraphTrainer - INFO - ndcg@20: 0.031507
2025-11-22 22:31:06 - GraphTrainer - INFO - map@20: 0.019378
2025-11-22 22:31:06 - GraphTrainer - INFO - mrr@20: 0.020272
2025-11-22 22:31:06 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:31:06 - GraphTrainer - INFO - ============================================================
2025-11-22 22:31:06 - GraphTrainer - INFO - 开始第 104/1000 轮训练
2025-11-22 22:31:06 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3769, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3639, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3682, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3783, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3735, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3648, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3577, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3672, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3653, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3650, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3601, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3865, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3702, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3595, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3554, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3891, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3537, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3566, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3619, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3747, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3708, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3704, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3512, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3435, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3910, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3788, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3627, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3554, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3848, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3557, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3789, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3720, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3550, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3912, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3786, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3730, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3660, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3699, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3572, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3655, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3588, device='cuda:0', grad_fn=<AddBackward0>)
The 103 training average loss: 0.3631110134823569
2025-11-22 22:31:17 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:31:17 - GraphTrainer - INFO -   precision@5: 0.005914
2025-11-22 22:31:17 - GraphTrainer - INFO -   recall@5: 0.028362
2025-11-22 22:31:17 - GraphTrainer - INFO -   hit_rate@5: 0.029519
2025-11-22 22:31:17 - GraphTrainer - INFO -   ndcg@5: 0.018612
2025-11-22 22:31:17 - GraphTrainer - INFO -   map@5: 0.015237
2025-11-22 22:31:17 - GraphTrainer - INFO -   mrr@5: 0.015804
2025-11-22 22:31:17 - GraphTrainer - INFO -   precision@10: 0.004778
2025-11-22 22:31:17 - GraphTrainer - INFO -   recall@10: 0.045228
2025-11-22 22:31:17 - GraphTrainer - INFO -   hit_rate@10: 0.047621
2025-11-22 22:31:17 - GraphTrainer - INFO -   ndcg@10: 0.024118
2025-11-22 22:31:17 - GraphTrainer - INFO -   map@10: 0.017462
2025-11-22 22:31:17 - GraphTrainer - INFO -   mrr@10: 0.018187
2025-11-22 22:31:17 - GraphTrainer - INFO -   precision@20: 0.003803
2025-11-22 22:31:17 - GraphTrainer - INFO -   recall@20: 0.071945
2025-11-22 22:31:17 - GraphTrainer - INFO -   hit_rate@20: 0.075649
2025-11-22 22:31:17 - GraphTrainer - INFO -   ndcg@20: 0.030911
2025-11-22 22:31:17 - GraphTrainer - INFO -   map@20: 0.019286
2025-11-22 22:31:17 - GraphTrainer - INFO -   mrr@20: 0.020098
2025-11-22 22:31:17 - GraphTrainer - INFO - 第 104 轮训练完成
2025-11-22 22:31:17 - GraphTrainer - INFO - train_loss: 0.362352
2025-11-22 22:31:17 - GraphTrainer - INFO - precision@5: 0.005914
2025-11-22 22:31:17 - GraphTrainer - INFO - recall@5: 0.028362
2025-11-22 22:31:17 - GraphTrainer - INFO - hit_rate@5: 0.029519
2025-11-22 22:31:17 - GraphTrainer - INFO - ndcg@5: 0.018612
2025-11-22 22:31:17 - GraphTrainer - INFO - map@5: 0.015237
2025-11-22 22:31:17 - GraphTrainer - INFO - mrr@5: 0.015804
2025-11-22 22:31:17 - GraphTrainer - INFO - precision@10: 0.004778
2025-11-22 22:31:17 - GraphTrainer - INFO - recall@10: 0.045228
2025-11-22 22:31:17 - GraphTrainer - INFO - hit_rate@10: 0.047621
2025-11-22 22:31:17 - GraphTrainer - INFO - ndcg@10: 0.024118
2025-11-22 22:31:17 - GraphTrainer - INFO - map@10: 0.017462
2025-11-22 22:31:17 - GraphTrainer - INFO - mrr@10: 0.018187
2025-11-22 22:31:17 - GraphTrainer - INFO - precision@20: 0.003803
2025-11-22 22:31:17 - GraphTrainer - INFO - recall@20: 0.071945
2025-11-22 22:31:17 - GraphTrainer - INFO - hit_rate@20: 0.075649
2025-11-22 22:31:17 - GraphTrainer - INFO - ndcg@20: 0.030911
2025-11-22 22:31:17 - GraphTrainer - INFO - map@20: 0.019286
2025-11-22 22:31:17 - GraphTrainer - INFO - mrr@20: 0.020098
2025-11-22 22:31:17 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:31:17 - GraphTrainer - INFO - ============================================================
2025-11-22 22:31:17 - GraphTrainer - INFO - 开始第 105/1000 轮训练
2025-11-22 22:31:17 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3620, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3601, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3765, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3792, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3602, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3611, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3534, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3703, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3661, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3561, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3637, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3630, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3673, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3579, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3730, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3748, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3573, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3565, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3635, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3805, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3757, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3543, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4024, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3691, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3823, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3717, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3613, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3711, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3662, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3807, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3563, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3602, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3657, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4001, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3769, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3296, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3479, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3665, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3758, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3784, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3858, device='cuda:0', grad_fn=<AddBackward0>)
The 104 training average loss: 0.36235236813282146
2025-11-22 22:31:27 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:31:27 - GraphTrainer - INFO -   precision@5: 0.006110
2025-11-22 22:31:27 - GraphTrainer - INFO -   recall@5: 0.028985
2025-11-22 22:31:27 - GraphTrainer - INFO -   hit_rate@5: 0.030496
2025-11-22 22:31:27 - GraphTrainer - INFO -   ndcg@5: 0.019210
2025-11-22 22:31:27 - GraphTrainer - INFO -   map@5: 0.015753
2025-11-22 22:31:27 - GraphTrainer - INFO -   mrr@5: 0.016484
2025-11-22 22:31:27 - GraphTrainer - INFO -   precision@10: 0.004860
2025-11-22 22:31:27 - GraphTrainer - INFO -   recall@10: 0.045738
2025-11-22 22:31:27 - GraphTrainer - INFO -   hit_rate@10: 0.048444
2025-11-22 22:31:27 - GraphTrainer - INFO -   ndcg@10: 0.024662
2025-11-22 22:31:27 - GraphTrainer - INFO -   map@10: 0.017949
2025-11-22 22:31:27 - GraphTrainer - INFO -   mrr@10: 0.018831
2025-11-22 22:31:27 - GraphTrainer - INFO -   precision@20: 0.003890
2025-11-22 22:31:27 - GraphTrainer - INFO -   recall@20: 0.073714
2025-11-22 22:31:27 - GraphTrainer - INFO -   hit_rate@20: 0.077449
2025-11-22 22:31:27 - GraphTrainer - INFO -   ndcg@20: 0.031711
2025-11-22 22:31:27 - GraphTrainer - INFO -   map@20: 0.019826
2025-11-22 22:31:27 - GraphTrainer - INFO -   mrr@20: 0.020769
2025-11-22 22:31:27 - GraphTrainer - INFO - 第 105 轮训练完成
2025-11-22 22:31:27 - GraphTrainer - INFO - train_loss: 0.363442
2025-11-22 22:31:27 - GraphTrainer - INFO - precision@5: 0.006110
2025-11-22 22:31:27 - GraphTrainer - INFO - recall@5: 0.028985
2025-11-22 22:31:27 - GraphTrainer - INFO - hit_rate@5: 0.030496
2025-11-22 22:31:27 - GraphTrainer - INFO - ndcg@5: 0.019210
2025-11-22 22:31:27 - GraphTrainer - INFO - map@5: 0.015753
2025-11-22 22:31:27 - GraphTrainer - INFO - mrr@5: 0.016484
2025-11-22 22:31:27 - GraphTrainer - INFO - precision@10: 0.004860
2025-11-22 22:31:27 - GraphTrainer - INFO - recall@10: 0.045738
2025-11-22 22:31:27 - GraphTrainer - INFO - hit_rate@10: 0.048444
2025-11-22 22:31:27 - GraphTrainer - INFO - ndcg@10: 0.024662
2025-11-22 22:31:27 - GraphTrainer - INFO - map@10: 0.017949
2025-11-22 22:31:27 - GraphTrainer - INFO - mrr@10: 0.018831
2025-11-22 22:31:27 - GraphTrainer - INFO - precision@20: 0.003890
2025-11-22 22:31:27 - GraphTrainer - INFO - recall@20: 0.073714
2025-11-22 22:31:27 - GraphTrainer - INFO - hit_rate@20: 0.077449
2025-11-22 22:31:27 - GraphTrainer - INFO - ndcg@20: 0.031711
2025-11-22 22:31:27 - GraphTrainer - INFO - map@20: 0.019826
2025-11-22 22:31:27 - GraphTrainer - INFO - mrr@20: 0.020769
2025-11-22 22:31:27 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:31:27 - GraphTrainer - INFO - ============================================================
2025-11-22 22:31:27 - GraphTrainer - INFO - 开始第 106/1000 轮训练
2025-11-22 22:31:27 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3855, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3827, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3638, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3604, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3661, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3650, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3509, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3718, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3559, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3619, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3674, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3847, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3951, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3647, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3768, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3662, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3789, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3531, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3640, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3846, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3592, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3640, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3666, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3748, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3633, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3742, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3633, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3742, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3797, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3584, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3732, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3557, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3851, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3616, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3863, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3591, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3547, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3833, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3750, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3703, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3877, device='cuda:0', grad_fn=<AddBackward0>)
The 105 training average loss: 0.3634416841227433
2025-11-22 22:31:38 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:31:38 - GraphTrainer - INFO -   precision@5: 0.005636
2025-11-22 22:31:38 - GraphTrainer - INFO -   recall@5: 0.026828
2025-11-22 22:31:38 - GraphTrainer - INFO -   hit_rate@5: 0.028131
2025-11-22 22:31:38 - GraphTrainer - INFO -   ndcg@5: 0.017862
2025-11-22 22:31:38 - GraphTrainer - INFO -   map@5: 0.014701
2025-11-22 22:31:38 - GraphTrainer - INFO -   mrr@5: 0.015363
2025-11-22 22:31:38 - GraphTrainer - INFO -   precision@10: 0.004649
2025-11-22 22:31:38 - GraphTrainer - INFO -   recall@10: 0.043854
2025-11-22 22:31:38 - GraphTrainer - INFO -   hit_rate@10: 0.046336
2025-11-22 22:31:38 - GraphTrainer - INFO -   ndcg@10: 0.023429
2025-11-22 22:31:38 - GraphTrainer - INFO -   map@10: 0.016960
2025-11-22 22:31:38 - GraphTrainer - INFO -   mrr@10: 0.017772
2025-11-22 22:31:38 - GraphTrainer - INFO -   precision@20: 0.003883
2025-11-22 22:31:38 - GraphTrainer - INFO -   recall@20: 0.073517
2025-11-22 22:31:38 - GraphTrainer - INFO -   hit_rate@20: 0.077244
2025-11-22 22:31:38 - GraphTrainer - INFO -   ndcg@20: 0.030947
2025-11-22 22:31:38 - GraphTrainer - INFO -   map@20: 0.018976
2025-11-22 22:31:38 - GraphTrainer - INFO -   mrr@20: 0.019872
2025-11-22 22:31:38 - GraphTrainer - INFO - 第 106 轮训练完成
2025-11-22 22:31:38 - GraphTrainer - INFO - train_loss: 0.360900
2025-11-22 22:31:38 - GraphTrainer - INFO - precision@5: 0.005636
2025-11-22 22:31:38 - GraphTrainer - INFO - recall@5: 0.026828
2025-11-22 22:31:38 - GraphTrainer - INFO - hit_rate@5: 0.028131
2025-11-22 22:31:38 - GraphTrainer - INFO - ndcg@5: 0.017862
2025-11-22 22:31:38 - GraphTrainer - INFO - map@5: 0.014701
2025-11-22 22:31:38 - GraphTrainer - INFO - mrr@5: 0.015363
2025-11-22 22:31:38 - GraphTrainer - INFO - precision@10: 0.004649
2025-11-22 22:31:38 - GraphTrainer - INFO - recall@10: 0.043854
2025-11-22 22:31:38 - GraphTrainer - INFO - hit_rate@10: 0.046336
2025-11-22 22:31:38 - GraphTrainer - INFO - ndcg@10: 0.023429
2025-11-22 22:31:38 - GraphTrainer - INFO - map@10: 0.016960
2025-11-22 22:31:38 - GraphTrainer - INFO - mrr@10: 0.017772
2025-11-22 22:31:38 - GraphTrainer - INFO - precision@20: 0.003883
2025-11-22 22:31:38 - GraphTrainer - INFO - recall@20: 0.073517
2025-11-22 22:31:38 - GraphTrainer - INFO - hit_rate@20: 0.077244
2025-11-22 22:31:38 - GraphTrainer - INFO - ndcg@20: 0.030947
2025-11-22 22:31:38 - GraphTrainer - INFO - map@20: 0.018976
2025-11-22 22:31:38 - GraphTrainer - INFO - mrr@20: 0.019872
2025-11-22 22:31:38 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:31:38 - GraphTrainer - INFO - ============================================================
2025-11-22 22:31:38 - GraphTrainer - INFO - 开始第 107/1000 轮训练
2025-11-22 22:31:38 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3731, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3646, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3680, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3853, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3533, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3691, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3582, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3698, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3661, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3601, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3765, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3820, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3778, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3605, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4016, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3692, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3630, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3602, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3698, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3688, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3819, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3708, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3591, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3615, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3490, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3753, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3658, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3534, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3714, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3615, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3842, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3601, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3608, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3644, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3763, device='cuda:0', grad_fn=<AddBackward0>)
The 106 training average loss: 0.3608995912403896
2025-11-22 22:31:49 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:31:49 - GraphTrainer - INFO -   precision@5: 0.005698
2025-11-22 22:31:49 - GraphTrainer - INFO -   recall@5: 0.027115
2025-11-22 22:31:49 - GraphTrainer - INFO -   hit_rate@5: 0.028439
2025-11-22 22:31:49 - GraphTrainer - INFO -   ndcg@5: 0.017893
2025-11-22 22:31:49 - GraphTrainer - INFO -   map@5: 0.014656
2025-11-22 22:31:49 - GraphTrainer - INFO -   mrr@5: 0.015238
2025-11-22 22:31:49 - GraphTrainer - INFO -   precision@10: 0.004834
2025-11-22 22:31:49 - GraphTrainer - INFO -   recall@10: 0.045645
2025-11-22 22:31:49 - GraphTrainer - INFO -   hit_rate@10: 0.048187
2025-11-22 22:31:49 - GraphTrainer - INFO -   ndcg@10: 0.023911
2025-11-22 22:31:49 - GraphTrainer - INFO -   map@10: 0.017079
2025-11-22 22:31:49 - GraphTrainer - INFO -   mrr@10: 0.017817
2025-11-22 22:31:49 - GraphTrainer - INFO -   precision@20: 0.003921
2025-11-22 22:31:49 - GraphTrainer - INFO -   recall@20: 0.074247
2025-11-22 22:31:49 - GraphTrainer - INFO -   hit_rate@20: 0.078066
2025-11-22 22:31:49 - GraphTrainer - INFO -   ndcg@20: 0.031165
2025-11-22 22:31:49 - GraphTrainer - INFO -   map@20: 0.019024
2025-11-22 22:31:49 - GraphTrainer - INFO -   mrr@20: 0.019839
2025-11-22 22:31:49 - GraphTrainer - INFO - 第 107 轮训练完成
2025-11-22 22:31:49 - GraphTrainer - INFO - train_loss: 0.362464
2025-11-22 22:31:49 - GraphTrainer - INFO - precision@5: 0.005698
2025-11-22 22:31:49 - GraphTrainer - INFO - recall@5: 0.027115
2025-11-22 22:31:49 - GraphTrainer - INFO - hit_rate@5: 0.028439
2025-11-22 22:31:49 - GraphTrainer - INFO - ndcg@5: 0.017893
2025-11-22 22:31:49 - GraphTrainer - INFO - map@5: 0.014656
2025-11-22 22:31:49 - GraphTrainer - INFO - mrr@5: 0.015238
2025-11-22 22:31:49 - GraphTrainer - INFO - precision@10: 0.004834
2025-11-22 22:31:49 - GraphTrainer - INFO - recall@10: 0.045645
2025-11-22 22:31:49 - GraphTrainer - INFO - hit_rate@10: 0.048187
2025-11-22 22:31:49 - GraphTrainer - INFO - ndcg@10: 0.023911
2025-11-22 22:31:49 - GraphTrainer - INFO - map@10: 0.017079
2025-11-22 22:31:49 - GraphTrainer - INFO - mrr@10: 0.017817
2025-11-22 22:31:49 - GraphTrainer - INFO - precision@20: 0.003921
2025-11-22 22:31:49 - GraphTrainer - INFO - recall@20: 0.074247
2025-11-22 22:31:49 - GraphTrainer - INFO - hit_rate@20: 0.078066
2025-11-22 22:31:49 - GraphTrainer - INFO - ndcg@20: 0.031165
2025-11-22 22:31:49 - GraphTrainer - INFO - map@20: 0.019024
2025-11-22 22:31:49 - GraphTrainer - INFO - mrr@20: 0.019839
2025-11-22 22:31:49 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:31:49 - GraphTrainer - INFO - ============================================================
2025-11-22 22:31:49 - GraphTrainer - INFO - 开始第 108/1000 轮训练
2025-11-22 22:31:49 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3841, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3536, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3598, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3664, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3712, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3643, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3989, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3512, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3857, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3709, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3605, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3886, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3706, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3596, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3579, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3694, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3784, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3626, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3763, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3846, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3695, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3569, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3373, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3639, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3880, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3588, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3679, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3566, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3782, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3681, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3596, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3710, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3640, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3667, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3554, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3792, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3715, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3845, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3791, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3570, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
The 107 training average loss: 0.3624638134035571
2025-11-22 22:32:00 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:32:00 - GraphTrainer - INFO -   precision@5: 0.006346
2025-11-22 22:32:00 - GraphTrainer - INFO -   recall@5: 0.030379
2025-11-22 22:32:00 - GraphTrainer - INFO -   hit_rate@5: 0.031679
2025-11-22 22:32:00 - GraphTrainer - INFO -   ndcg@5: 0.019616
2025-11-22 22:32:00 - GraphTrainer - INFO -   map@5: 0.015880
2025-11-22 22:32:00 - GraphTrainer - INFO -   mrr@5: 0.016451
2025-11-22 22:32:00 - GraphTrainer - INFO -   precision@10: 0.004978
2025-11-22 22:32:00 - GraphTrainer - INFO -   recall@10: 0.047221
2025-11-22 22:32:00 - GraphTrainer - INFO -   hit_rate@10: 0.049524
2025-11-22 22:32:00 - GraphTrainer - INFO -   ndcg@10: 0.025076
2025-11-22 22:32:00 - GraphTrainer - INFO -   map@10: 0.018079
2025-11-22 22:32:00 - GraphTrainer - INFO -   mrr@10: 0.018777
2025-11-22 22:32:00 - GraphTrainer - INFO -   precision@20: 0.003988
2025-11-22 22:32:00 - GraphTrainer - INFO -   recall@20: 0.075538
2025-11-22 22:32:00 - GraphTrainer - INFO -   hit_rate@20: 0.079301
2025-11-22 22:32:00 - GraphTrainer - INFO -   ndcg@20: 0.032277
2025-11-22 22:32:00 - GraphTrainer - INFO -   map@20: 0.020010
2025-11-22 22:32:00 - GraphTrainer - INFO -   mrr@20: 0.020806
2025-11-22 22:32:00 - GraphTrainer - INFO - 第 108 轮训练完成
2025-11-22 22:32:00 - GraphTrainer - INFO - train_loss: 0.355547
2025-11-22 22:32:00 - GraphTrainer - INFO - precision@5: 0.006346
2025-11-22 22:32:00 - GraphTrainer - INFO - recall@5: 0.030379
2025-11-22 22:32:00 - GraphTrainer - INFO - hit_rate@5: 0.031679
2025-11-22 22:32:00 - GraphTrainer - INFO - ndcg@5: 0.019616
2025-11-22 22:32:00 - GraphTrainer - INFO - map@5: 0.015880
2025-11-22 22:32:00 - GraphTrainer - INFO - mrr@5: 0.016451
2025-11-22 22:32:00 - GraphTrainer - INFO - precision@10: 0.004978
2025-11-22 22:32:00 - GraphTrainer - INFO - recall@10: 0.047221
2025-11-22 22:32:00 - GraphTrainer - INFO - hit_rate@10: 0.049524
2025-11-22 22:32:00 - GraphTrainer - INFO - ndcg@10: 0.025076
2025-11-22 22:32:00 - GraphTrainer - INFO - map@10: 0.018079
2025-11-22 22:32:00 - GraphTrainer - INFO - mrr@10: 0.018777
2025-11-22 22:32:00 - GraphTrainer - INFO - precision@20: 0.003988
2025-11-22 22:32:00 - GraphTrainer - INFO - recall@20: 0.075538
2025-11-22 22:32:00 - GraphTrainer - INFO - hit_rate@20: 0.079301
2025-11-22 22:32:00 - GraphTrainer - INFO - ndcg@20: 0.032277
2025-11-22 22:32:00 - GraphTrainer - INFO - map@20: 0.020010
2025-11-22 22:32:00 - GraphTrainer - INFO - mrr@20: 0.020806
2025-11-22 22:32:00 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:32:00 - GraphTrainer - INFO - ============================================================
2025-11-22 22:32:00 - GraphTrainer - INFO - 开始第 109/1000 轮训练
2025-11-22 22:32:00 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3574, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3536, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3533, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3697, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3499, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3605, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3756, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3749, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3560, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3767, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3590, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3284, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3702, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3571, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3480, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3651, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3331, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3729, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3549, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3643, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3733, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3922, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3160, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3814, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3605, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3631, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3759, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3617, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3462, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3607, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3550, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3758, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3549, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3536, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3532, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3656, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3516, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3544, device='cuda:0', grad_fn=<AddBackward0>)
The 108 training average loss: 0.35554699651126204
2025-11-22 22:32:11 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:32:11 - GraphTrainer - INFO -   precision@5: 0.006356
2025-11-22 22:32:11 - GraphTrainer - INFO -   recall@5: 0.030259
2025-11-22 22:32:11 - GraphTrainer - INFO -   hit_rate@5: 0.031731
2025-11-22 22:32:11 - GraphTrainer - INFO -   ndcg@5: 0.020181
2025-11-22 22:32:11 - GraphTrainer - INFO -   map@5: 0.016639
2025-11-22 22:32:11 - GraphTrainer - INFO -   mrr@5: 0.017299
2025-11-22 22:32:11 - GraphTrainer - INFO -   precision@10: 0.005071
2025-11-22 22:32:11 - GraphTrainer - INFO -   recall@10: 0.048287
2025-11-22 22:32:11 - GraphTrainer - INFO -   hit_rate@10: 0.050604
2025-11-22 22:32:11 - GraphTrainer - INFO -   ndcg@10: 0.026060
2025-11-22 22:32:11 - GraphTrainer - INFO -   map@10: 0.019040
2025-11-22 22:32:11 - GraphTrainer - INFO -   mrr@10: 0.019811
2025-11-22 22:32:11 - GraphTrainer - INFO -   precision@20: 0.004050
2025-11-22 22:32:11 - GraphTrainer - INFO -   recall@20: 0.076772
2025-11-22 22:32:11 - GraphTrainer - INFO -   hit_rate@20: 0.080535
2025-11-22 22:32:11 - GraphTrainer - INFO -   ndcg@20: 0.033282
2025-11-22 22:32:11 - GraphTrainer - INFO -   map@20: 0.020965
2025-11-22 22:32:11 - GraphTrainer - INFO -   mrr@20: 0.021830
2025-11-22 22:32:11 - GraphTrainer - INFO - 第 109 轮训练完成
2025-11-22 22:32:11 - GraphTrainer - INFO - train_loss: 0.356178
2025-11-22 22:32:11 - GraphTrainer - INFO - precision@5: 0.006356
2025-11-22 22:32:11 - GraphTrainer - INFO - recall@5: 0.030259
2025-11-22 22:32:11 - GraphTrainer - INFO - hit_rate@5: 0.031731
2025-11-22 22:32:11 - GraphTrainer - INFO - ndcg@5: 0.020181
2025-11-22 22:32:11 - GraphTrainer - INFO - map@5: 0.016639
2025-11-22 22:32:11 - GraphTrainer - INFO - mrr@5: 0.017299
2025-11-22 22:32:11 - GraphTrainer - INFO - precision@10: 0.005071
2025-11-22 22:32:11 - GraphTrainer - INFO - recall@10: 0.048287
2025-11-22 22:32:11 - GraphTrainer - INFO - hit_rate@10: 0.050604
2025-11-22 22:32:11 - GraphTrainer - INFO - ndcg@10: 0.026060
2025-11-22 22:32:11 - GraphTrainer - INFO - map@10: 0.019040
2025-11-22 22:32:11 - GraphTrainer - INFO - mrr@10: 0.019811
2025-11-22 22:32:11 - GraphTrainer - INFO - precision@20: 0.004050
2025-11-22 22:32:11 - GraphTrainer - INFO - recall@20: 0.076772
2025-11-22 22:32:11 - GraphTrainer - INFO - hit_rate@20: 0.080535
2025-11-22 22:32:11 - GraphTrainer - INFO - ndcg@20: 0.033282
2025-11-22 22:32:11 - GraphTrainer - INFO - map@20: 0.020965
2025-11-22 22:32:11 - GraphTrainer - INFO - mrr@20: 0.021830
2025-11-22 22:32:11 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:32:11 - GraphTrainer - INFO - ============================================================
2025-11-22 22:32:11 - GraphTrainer - INFO - 开始第 110/1000 轮训练
2025-11-22 22:32:11 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3612, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3677, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3312, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3693, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3649, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3518, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3653, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3715, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3805, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3891, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3672, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3588, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3590, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3554, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3690, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3656, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3608, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3579, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3689, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3631, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3801, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3558, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3626, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3679, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3629, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3610, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3710, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3673, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)
The 109 training average loss: 0.3561779214390393
2025-11-22 22:32:22 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:32:22 - GraphTrainer - INFO -   precision@5: 0.006305
2025-11-22 22:32:22 - GraphTrainer - INFO -   recall@5: 0.029965
2025-11-22 22:32:22 - GraphTrainer - INFO -   hit_rate@5: 0.031473
2025-11-22 22:32:22 - GraphTrainer - INFO -   ndcg@5: 0.019817
2025-11-22 22:32:22 - GraphTrainer - INFO -   map@5: 0.016249
2025-11-22 22:32:22 - GraphTrainer - INFO -   mrr@5: 0.016859
2025-11-22 22:32:22 - GraphTrainer - INFO -   precision@10: 0.005091
2025-11-22 22:32:22 - GraphTrainer - INFO -   recall@10: 0.048272
2025-11-22 22:32:22 - GraphTrainer - INFO -   hit_rate@10: 0.050759
2025-11-22 22:32:22 - GraphTrainer - INFO -   ndcg@10: 0.025763
2025-11-22 22:32:22 - GraphTrainer - INFO -   map@10: 0.018655
2025-11-22 22:32:22 - GraphTrainer - INFO -   mrr@10: 0.019395
2025-11-22 22:32:22 - GraphTrainer - INFO -   precision@20: 0.004055
2025-11-22 22:32:22 - GraphTrainer - INFO -   recall@20: 0.077034
2025-11-22 22:32:22 - GraphTrainer - INFO -   hit_rate@20: 0.080689
2025-11-22 22:32:22 - GraphTrainer - INFO -   ndcg@20: 0.033066
2025-11-22 22:32:22 - GraphTrainer - INFO -   map@20: 0.020623
2025-11-22 22:32:22 - GraphTrainer - INFO -   mrr@20: 0.021437
2025-11-22 22:32:22 - GraphTrainer - INFO - 第 110 轮训练完成
2025-11-22 22:32:22 - GraphTrainer - INFO - train_loss: 0.351152
2025-11-22 22:32:22 - GraphTrainer - INFO - precision@5: 0.006305
2025-11-22 22:32:22 - GraphTrainer - INFO - recall@5: 0.029965
2025-11-22 22:32:22 - GraphTrainer - INFO - hit_rate@5: 0.031473
2025-11-22 22:32:22 - GraphTrainer - INFO - ndcg@5: 0.019817
2025-11-22 22:32:22 - GraphTrainer - INFO - map@5: 0.016249
2025-11-22 22:32:22 - GraphTrainer - INFO - mrr@5: 0.016859
2025-11-22 22:32:22 - GraphTrainer - INFO - precision@10: 0.005091
2025-11-22 22:32:22 - GraphTrainer - INFO - recall@10: 0.048272
2025-11-22 22:32:22 - GraphTrainer - INFO - hit_rate@10: 0.050759
2025-11-22 22:32:22 - GraphTrainer - INFO - ndcg@10: 0.025763
2025-11-22 22:32:22 - GraphTrainer - INFO - map@10: 0.018655
2025-11-22 22:32:22 - GraphTrainer - INFO - mrr@10: 0.019395
2025-11-22 22:32:22 - GraphTrainer - INFO - precision@20: 0.004055
2025-11-22 22:32:22 - GraphTrainer - INFO - recall@20: 0.077034
2025-11-22 22:32:22 - GraphTrainer - INFO - hit_rate@20: 0.080689
2025-11-22 22:32:22 - GraphTrainer - INFO - ndcg@20: 0.033066
2025-11-22 22:32:22 - GraphTrainer - INFO - map@20: 0.020623
2025-11-22 22:32:22 - GraphTrainer - INFO - mrr@20: 0.021437
2025-11-22 22:32:22 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:32:23 - GraphTrainer - INFO - 检查点已保存: Epoch 110 -> ./checkpoints/checkpoint_epoch_110.pth
2025-11-22 22:32:23 - GraphTrainer - INFO - ============================================================
2025-11-22 22:32:23 - GraphTrainer - INFO - 开始第 111/1000 轮训练
2025-11-22 22:32:23 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3626, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3257, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3376, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3525, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3596, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3549, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3703, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3561, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3473, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3544, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3713, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3559, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3507, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3720, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3846, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3480, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3521, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3613, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3544, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3665, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3810, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3605, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3571, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3176, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3619, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3563, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3838, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>)
The 110 training average loss: 0.35115158403741903
2025-11-22 22:32:34 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:32:34 - GraphTrainer - INFO -   precision@5: 0.006480
2025-11-22 22:32:34 - GraphTrainer - INFO -   recall@5: 0.030743
2025-11-22 22:32:34 - GraphTrainer - INFO -   hit_rate@5: 0.032348
2025-11-22 22:32:34 - GraphTrainer - INFO -   ndcg@5: 0.020017
2025-11-22 22:32:34 - GraphTrainer - INFO -   map@5: 0.016252
2025-11-22 22:32:34 - GraphTrainer - INFO -   mrr@5: 0.016912
2025-11-22 22:32:34 - GraphTrainer - INFO -   precision@10: 0.005143
2025-11-22 22:32:34 - GraphTrainer - INFO -   recall@10: 0.048917
2025-11-22 22:32:34 - GraphTrainer - INFO -   hit_rate@10: 0.051376
2025-11-22 22:32:34 - GraphTrainer - INFO -   ndcg@10: 0.025934
2025-11-22 22:32:34 - GraphTrainer - INFO -   map@10: 0.018667
2025-11-22 22:32:34 - GraphTrainer - INFO -   mrr@10: 0.019441
2025-11-22 22:32:34 - GraphTrainer - INFO -   precision@20: 0.004086
2025-11-22 22:32:34 - GraphTrainer - INFO -   recall@20: 0.077304
2025-11-22 22:32:34 - GraphTrainer - INFO -   hit_rate@20: 0.081358
2025-11-22 22:32:34 - GraphTrainer - INFO -   ndcg@20: 0.033144
2025-11-22 22:32:34 - GraphTrainer - INFO -   map@20: 0.020591
2025-11-22 22:32:34 - GraphTrainer - INFO -   mrr@20: 0.021467
2025-11-22 22:32:34 - GraphTrainer - INFO - 第 111 轮训练完成
2025-11-22 22:32:34 - GraphTrainer - INFO - train_loss: 0.349227
2025-11-22 22:32:34 - GraphTrainer - INFO - precision@5: 0.006480
2025-11-22 22:32:34 - GraphTrainer - INFO - recall@5: 0.030743
2025-11-22 22:32:34 - GraphTrainer - INFO - hit_rate@5: 0.032348
2025-11-22 22:32:34 - GraphTrainer - INFO - ndcg@5: 0.020017
2025-11-22 22:32:34 - GraphTrainer - INFO - map@5: 0.016252
2025-11-22 22:32:34 - GraphTrainer - INFO - mrr@5: 0.016912
2025-11-22 22:32:34 - GraphTrainer - INFO - precision@10: 0.005143
2025-11-22 22:32:34 - GraphTrainer - INFO - recall@10: 0.048917
2025-11-22 22:32:34 - GraphTrainer - INFO - hit_rate@10: 0.051376
2025-11-22 22:32:34 - GraphTrainer - INFO - ndcg@10: 0.025934
2025-11-22 22:32:34 - GraphTrainer - INFO - map@10: 0.018667
2025-11-22 22:32:34 - GraphTrainer - INFO - mrr@10: 0.019441
2025-11-22 22:32:34 - GraphTrainer - INFO - precision@20: 0.004086
2025-11-22 22:32:34 - GraphTrainer - INFO - recall@20: 0.077304
2025-11-22 22:32:34 - GraphTrainer - INFO - hit_rate@20: 0.081358
2025-11-22 22:32:34 - GraphTrainer - INFO - ndcg@20: 0.033144
2025-11-22 22:32:34 - GraphTrainer - INFO - map@20: 0.020591
2025-11-22 22:32:34 - GraphTrainer - INFO - mrr@20: 0.021467
2025-11-22 22:32:34 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:32:34 - GraphTrainer - INFO - ============================================================
2025-11-22 22:32:34 - GraphTrainer - INFO - 开始第 112/1000 轮训练
2025-11-22 22:32:34 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3534, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3652, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3499, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3709, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3739, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3373, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3620, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3248, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3167, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3525, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3670, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3549, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3614, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3673, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3502, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3791, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3665, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3421, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3690, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3433, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3480, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3130, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3856, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)
The 111 training average loss: 0.3492271201363925
2025-11-22 22:32:45 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:32:45 - GraphTrainer - INFO -   precision@5: 0.006480
2025-11-22 22:32:45 - GraphTrainer - INFO -   recall@5: 0.030887
2025-11-22 22:32:45 - GraphTrainer - INFO -   hit_rate@5: 0.032348
2025-11-22 22:32:45 - GraphTrainer - INFO -   ndcg@5: 0.019597
2025-11-22 22:32:45 - GraphTrainer - INFO -   map@5: 0.015679
2025-11-22 22:32:45 - GraphTrainer - INFO -   mrr@5: 0.016274
2025-11-22 22:32:45 - GraphTrainer - INFO -   precision@10: 0.005158
2025-11-22 22:32:45 - GraphTrainer - INFO -   recall@10: 0.049246
2025-11-22 22:32:45 - GraphTrainer - INFO -   hit_rate@10: 0.051479
2025-11-22 22:32:45 - GraphTrainer - INFO -   ndcg@10: 0.025551
2025-11-22 22:32:45 - GraphTrainer - INFO -   map@10: 0.018098
2025-11-22 22:32:45 - GraphTrainer - INFO -   mrr@10: 0.018794
2025-11-22 22:32:45 - GraphTrainer - INFO -   precision@20: 0.003978
2025-11-22 22:32:45 - GraphTrainer - INFO -   recall@20: 0.075403
2025-11-22 22:32:45 - GraphTrainer - INFO -   hit_rate@20: 0.079198
2025-11-22 22:32:45 - GraphTrainer - INFO -   ndcg@20: 0.032210
2025-11-22 22:32:45 - GraphTrainer - INFO -   map@20: 0.019880
2025-11-22 22:32:45 - GraphTrainer - INFO -   mrr@20: 0.020676
2025-11-22 22:32:45 - GraphTrainer - INFO - 第 112 轮训练完成
2025-11-22 22:32:45 - GraphTrainer - INFO - train_loss: 0.351065
2025-11-22 22:32:45 - GraphTrainer - INFO - precision@5: 0.006480
2025-11-22 22:32:45 - GraphTrainer - INFO - recall@5: 0.030887
2025-11-22 22:32:45 - GraphTrainer - INFO - hit_rate@5: 0.032348
2025-11-22 22:32:45 - GraphTrainer - INFO - ndcg@5: 0.019597
2025-11-22 22:32:45 - GraphTrainer - INFO - map@5: 0.015679
2025-11-22 22:32:45 - GraphTrainer - INFO - mrr@5: 0.016274
2025-11-22 22:32:45 - GraphTrainer - INFO - precision@10: 0.005158
2025-11-22 22:32:45 - GraphTrainer - INFO - recall@10: 0.049246
2025-11-22 22:32:45 - GraphTrainer - INFO - hit_rate@10: 0.051479
2025-11-22 22:32:45 - GraphTrainer - INFO - ndcg@10: 0.025551
2025-11-22 22:32:45 - GraphTrainer - INFO - map@10: 0.018098
2025-11-22 22:32:45 - GraphTrainer - INFO - mrr@10: 0.018794
2025-11-22 22:32:45 - GraphTrainer - INFO - precision@20: 0.003978
2025-11-22 22:32:45 - GraphTrainer - INFO - recall@20: 0.075403
2025-11-22 22:32:45 - GraphTrainer - INFO - hit_rate@20: 0.079198
2025-11-22 22:32:45 - GraphTrainer - INFO - ndcg@20: 0.032210
2025-11-22 22:32:45 - GraphTrainer - INFO - map@20: 0.019880
2025-11-22 22:32:45 - GraphTrainer - INFO - mrr@20: 0.020676
2025-11-22 22:32:45 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:32:45 - GraphTrainer - INFO - ============================================================
2025-11-22 22:32:45 - GraphTrainer - INFO - 开始第 113/1000 轮训练
2025-11-22 22:32:45 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3586, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3632, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3327, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3551, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3506, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3951, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3379, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3557, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3297, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3574, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3644, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3191, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3681, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3502, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3494, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3566, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3810, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3729, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3669, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3689, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3531, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3626, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3624, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3333, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3643, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3749, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3573, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3561, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3625, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
The 112 training average loss: 0.3510645170663965
2025-11-22 22:32:55 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:32:55 - GraphTrainer - INFO -   precision@5: 0.006110
2025-11-22 22:32:55 - GraphTrainer - INFO -   recall@5: 0.029157
2025-11-22 22:32:55 - GraphTrainer - INFO -   hit_rate@5: 0.030496
2025-11-22 22:32:55 - GraphTrainer - INFO -   ndcg@5: 0.018969
2025-11-22 22:32:55 - GraphTrainer - INFO -   map@5: 0.015424
2025-11-22 22:32:55 - GraphTrainer - INFO -   mrr@5: 0.016040
2025-11-22 22:32:55 - GraphTrainer - INFO -   precision@10: 0.005127
2025-11-22 22:32:55 - GraphTrainer - INFO -   recall@10: 0.048655
2025-11-22 22:32:55 - GraphTrainer - INFO -   hit_rate@10: 0.051067
2025-11-22 22:32:55 - GraphTrainer - INFO -   ndcg@10: 0.025285
2025-11-22 22:32:55 - GraphTrainer - INFO -   map@10: 0.017965
2025-11-22 22:32:55 - GraphTrainer - INFO -   mrr@10: 0.018720
2025-11-22 22:32:55 - GraphTrainer - INFO -   precision@20: 0.003934
2025-11-22 22:32:55 - GraphTrainer - INFO -   recall@20: 0.074598
2025-11-22 22:32:55 - GraphTrainer - INFO -   hit_rate@20: 0.078169
2025-11-22 22:32:55 - GraphTrainer - INFO -   ndcg@20: 0.031850
2025-11-22 22:32:55 - GraphTrainer - INFO -   map@20: 0.019716
2025-11-22 22:32:55 - GraphTrainer - INFO -   mrr@20: 0.020547
2025-11-22 22:32:55 - GraphTrainer - INFO - 第 113 轮训练完成
2025-11-22 22:32:55 - GraphTrainer - INFO - train_loss: 0.351553
2025-11-22 22:32:55 - GraphTrainer - INFO - precision@5: 0.006110
2025-11-22 22:32:55 - GraphTrainer - INFO - recall@5: 0.029157
2025-11-22 22:32:55 - GraphTrainer - INFO - hit_rate@5: 0.030496
2025-11-22 22:32:55 - GraphTrainer - INFO - ndcg@5: 0.018969
2025-11-22 22:32:55 - GraphTrainer - INFO - map@5: 0.015424
2025-11-22 22:32:55 - GraphTrainer - INFO - mrr@5: 0.016040
2025-11-22 22:32:55 - GraphTrainer - INFO - precision@10: 0.005127
2025-11-22 22:32:55 - GraphTrainer - INFO - recall@10: 0.048655
2025-11-22 22:32:55 - GraphTrainer - INFO - hit_rate@10: 0.051067
2025-11-22 22:32:55 - GraphTrainer - INFO - ndcg@10: 0.025285
2025-11-22 22:32:55 - GraphTrainer - INFO - map@10: 0.017965
2025-11-22 22:32:55 - GraphTrainer - INFO - mrr@10: 0.018720
2025-11-22 22:32:55 - GraphTrainer - INFO - precision@20: 0.003934
2025-11-22 22:32:55 - GraphTrainer - INFO - recall@20: 0.074598
2025-11-22 22:32:55 - GraphTrainer - INFO - hit_rate@20: 0.078169
2025-11-22 22:32:55 - GraphTrainer - INFO - ndcg@20: 0.031850
2025-11-22 22:32:55 - GraphTrainer - INFO - map@20: 0.019716
2025-11-22 22:32:55 - GraphTrainer - INFO - mrr@20: 0.020547
2025-11-22 22:32:55 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:32:55 - GraphTrainer - INFO - ============================================================
2025-11-22 22:32:55 - GraphTrainer - INFO - 开始第 114/1000 轮训练
2025-11-22 22:32:55 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3557, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3649, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3586, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3525, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3679, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3818, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3518, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3379, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3783, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3512, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3692, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3574, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3636, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3667, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3709, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3248, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3590, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3464, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3672, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3565, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3550, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3550, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3620, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3575, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3155, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3604, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3249, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3757, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3467, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3876, device='cuda:0', grad_fn=<AddBackward0>)
The 113 training average loss: 0.3515531066162833
2025-11-22 22:33:07 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:33:07 - GraphTrainer - INFO -   precision@5: 0.006151
2025-11-22 22:33:07 - GraphTrainer - INFO -   recall@5: 0.029260
2025-11-22 22:33:07 - GraphTrainer - INFO -   hit_rate@5: 0.030753
2025-11-22 22:33:07 - GraphTrainer - INFO -   ndcg@5: 0.019377
2025-11-22 22:33:07 - GraphTrainer - INFO -   map@5: 0.015904
2025-11-22 22:33:07 - GraphTrainer - INFO -   mrr@5: 0.016546
2025-11-22 22:33:07 - GraphTrainer - INFO -   precision@10: 0.004958
2025-11-22 22:33:07 - GraphTrainer - INFO -   recall@10: 0.047122
2025-11-22 22:33:07 - GraphTrainer - INFO -   hit_rate@10: 0.049524
2025-11-22 22:33:07 - GraphTrainer - INFO -   ndcg@10: 0.025167
2025-11-22 22:33:07 - GraphTrainer - INFO -   map@10: 0.018243
2025-11-22 22:33:07 - GraphTrainer - INFO -   mrr@10: 0.019000
2025-11-22 22:33:07 - GraphTrainer - INFO -   precision@20: 0.003991
2025-11-22 22:33:07 - GraphTrainer - INFO -   recall@20: 0.075839
2025-11-22 22:33:07 - GraphTrainer - INFO -   hit_rate@20: 0.079455
2025-11-22 22:33:07 - GraphTrainer - INFO -   ndcg@20: 0.032458
2025-11-22 22:33:07 - GraphTrainer - INFO -   map@20: 0.020202
2025-11-22 22:33:07 - GraphTrainer - INFO -   mrr@20: 0.021040
2025-11-22 22:33:07 - GraphTrainer - INFO - 第 114 轮训练完成
2025-11-22 22:33:07 - GraphTrainer - INFO - train_loss: 0.349491
2025-11-22 22:33:07 - GraphTrainer - INFO - precision@5: 0.006151
2025-11-22 22:33:07 - GraphTrainer - INFO - recall@5: 0.029260
2025-11-22 22:33:07 - GraphTrainer - INFO - hit_rate@5: 0.030753
2025-11-22 22:33:07 - GraphTrainer - INFO - ndcg@5: 0.019377
2025-11-22 22:33:07 - GraphTrainer - INFO - map@5: 0.015904
2025-11-22 22:33:07 - GraphTrainer - INFO - mrr@5: 0.016546
2025-11-22 22:33:07 - GraphTrainer - INFO - precision@10: 0.004958
2025-11-22 22:33:07 - GraphTrainer - INFO - recall@10: 0.047122
2025-11-22 22:33:07 - GraphTrainer - INFO - hit_rate@10: 0.049524
2025-11-22 22:33:07 - GraphTrainer - INFO - ndcg@10: 0.025167
2025-11-22 22:33:07 - GraphTrainer - INFO - map@10: 0.018243
2025-11-22 22:33:07 - GraphTrainer - INFO - mrr@10: 0.019000
2025-11-22 22:33:07 - GraphTrainer - INFO - precision@20: 0.003991
2025-11-22 22:33:07 - GraphTrainer - INFO - recall@20: 0.075839
2025-11-22 22:33:07 - GraphTrainer - INFO - hit_rate@20: 0.079455
2025-11-22 22:33:07 - GraphTrainer - INFO - ndcg@20: 0.032458
2025-11-22 22:33:07 - GraphTrainer - INFO - map@20: 0.020202
2025-11-22 22:33:07 - GraphTrainer - INFO - mrr@20: 0.021040
2025-11-22 22:33:07 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:33:07 - GraphTrainer - INFO - ============================================================
2025-11-22 22:33:07 - GraphTrainer - INFO - 开始第 115/1000 轮训练
2025-11-22 22:33:07 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3480, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3268, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3698, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3537, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3274, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3296, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3738, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3800, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3616, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3285, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3685, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3666, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3529, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3582, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3434, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3507, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3695, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3611, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3434, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3665, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3455, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3595, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3548, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3604, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3559, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3466, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
The 114 training average loss: 0.3494907884762205
2025-11-22 22:33:18 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:33:18 - GraphTrainer - INFO -   precision@5: 0.006212
2025-11-22 22:33:18 - GraphTrainer - INFO -   recall@5: 0.029527
2025-11-22 22:33:18 - GraphTrainer - INFO -   hit_rate@5: 0.031011
2025-11-22 22:33:18 - GraphTrainer - INFO -   ndcg@5: 0.019285
2025-11-22 22:33:18 - GraphTrainer - INFO -   map@5: 0.015686
2025-11-22 22:33:18 - GraphTrainer - INFO -   mrr@5: 0.016343
2025-11-22 22:33:18 - GraphTrainer - INFO -   precision@10: 0.005035
2025-11-22 22:33:18 - GraphTrainer - INFO -   recall@10: 0.047762
2025-11-22 22:33:18 - GraphTrainer - INFO -   hit_rate@10: 0.050193
2025-11-22 22:33:18 - GraphTrainer - INFO -   ndcg@10: 0.025158
2025-11-22 22:33:18 - GraphTrainer - INFO -   map@10: 0.018034
2025-11-22 22:33:18 - GraphTrainer - INFO -   mrr@10: 0.018815
2025-11-22 22:33:18 - GraphTrainer - INFO -   precision@20: 0.004099
2025-11-22 22:33:18 - GraphTrainer - INFO -   recall@20: 0.077585
2025-11-22 22:33:18 - GraphTrainer - INFO -   hit_rate@20: 0.081461
2025-11-22 22:33:18 - GraphTrainer - INFO -   ndcg@20: 0.032742
2025-11-22 22:33:18 - GraphTrainer - INFO -   map@20: 0.020073
2025-11-22 22:33:18 - GraphTrainer - INFO -   mrr@20: 0.020941
2025-11-22 22:33:18 - GraphTrainer - INFO - 第 115 轮训练完成
2025-11-22 22:33:18 - GraphTrainer - INFO - train_loss: 0.348800
2025-11-22 22:33:18 - GraphTrainer - INFO - precision@5: 0.006212
2025-11-22 22:33:18 - GraphTrainer - INFO - recall@5: 0.029527
2025-11-22 22:33:18 - GraphTrainer - INFO - hit_rate@5: 0.031011
2025-11-22 22:33:18 - GraphTrainer - INFO - ndcg@5: 0.019285
2025-11-22 22:33:18 - GraphTrainer - INFO - map@5: 0.015686
2025-11-22 22:33:18 - GraphTrainer - INFO - mrr@5: 0.016343
2025-11-22 22:33:18 - GraphTrainer - INFO - precision@10: 0.005035
2025-11-22 22:33:18 - GraphTrainer - INFO - recall@10: 0.047762
2025-11-22 22:33:18 - GraphTrainer - INFO - hit_rate@10: 0.050193
2025-11-22 22:33:18 - GraphTrainer - INFO - ndcg@10: 0.025158
2025-11-22 22:33:18 - GraphTrainer - INFO - map@10: 0.018034
2025-11-22 22:33:18 - GraphTrainer - INFO - mrr@10: 0.018815
2025-11-22 22:33:18 - GraphTrainer - INFO - precision@20: 0.004099
2025-11-22 22:33:18 - GraphTrainer - INFO - recall@20: 0.077585
2025-11-22 22:33:18 - GraphTrainer - INFO - hit_rate@20: 0.081461
2025-11-22 22:33:18 - GraphTrainer - INFO - ndcg@20: 0.032742
2025-11-22 22:33:18 - GraphTrainer - INFO - map@20: 0.020073
2025-11-22 22:33:18 - GraphTrainer - INFO - mrr@20: 0.020941
2025-11-22 22:33:18 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:33:18 - GraphTrainer - INFO - ============================================================
2025-11-22 22:33:18 - GraphTrainer - INFO - 开始第 116/1000 轮训练
2025-11-22 22:33:18 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3273, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3626, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3509, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3479, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3464, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3532, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3533, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3559, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3468, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3279, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3658, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3614, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3731, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3521, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3679, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3518, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3580, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3548, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3479, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3679, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3736, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3649, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3318, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3652, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3550, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3201, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3645, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
The 115 training average loss: 0.3487998802086403
2025-11-22 22:33:29 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:33:29 - GraphTrainer - INFO -   precision@5: 0.006243
2025-11-22 22:33:29 - GraphTrainer - INFO -   recall@5: 0.029807
2025-11-22 22:33:29 - GraphTrainer - INFO -   hit_rate@5: 0.031165
2025-11-22 22:33:29 - GraphTrainer - INFO -   ndcg@5: 0.019684
2025-11-22 22:33:29 - GraphTrainer - INFO -   map@5: 0.016136
2025-11-22 22:33:29 - GraphTrainer - INFO -   mrr@5: 0.016752
2025-11-22 22:33:29 - GraphTrainer - INFO -   precision@10: 0.005163
2025-11-22 22:33:29 - GraphTrainer - INFO -   recall@10: 0.048996
2025-11-22 22:33:29 - GraphTrainer - INFO -   hit_rate@10: 0.051530
2025-11-22 22:33:29 - GraphTrainer - INFO -   ndcg@10: 0.025946
2025-11-22 22:33:29 - GraphTrainer - INFO -   map@10: 0.018677
2025-11-22 22:33:29 - GraphTrainer - INFO -   mrr@10: 0.019449
2025-11-22 22:33:29 - GraphTrainer - INFO -   precision@20: 0.004065
2025-11-22 22:33:29 - GraphTrainer - INFO -   recall@20: 0.076947
2025-11-22 22:33:29 - GraphTrainer - INFO -   hit_rate@20: 0.080895
2025-11-22 22:33:29 - GraphTrainer - INFO -   ndcg@20: 0.033045
2025-11-22 22:33:29 - GraphTrainer - INFO -   map@20: 0.020580
2025-11-22 22:33:29 - GraphTrainer - INFO -   mrr@20: 0.021436
2025-11-22 22:33:29 - GraphTrainer - INFO - 第 116 轮训练完成
2025-11-22 22:33:29 - GraphTrainer - INFO - train_loss: 0.350875
2025-11-22 22:33:29 - GraphTrainer - INFO - precision@5: 0.006243
2025-11-22 22:33:29 - GraphTrainer - INFO - recall@5: 0.029807
2025-11-22 22:33:29 - GraphTrainer - INFO - hit_rate@5: 0.031165
2025-11-22 22:33:29 - GraphTrainer - INFO - ndcg@5: 0.019684
2025-11-22 22:33:29 - GraphTrainer - INFO - map@5: 0.016136
2025-11-22 22:33:29 - GraphTrainer - INFO - mrr@5: 0.016752
2025-11-22 22:33:29 - GraphTrainer - INFO - precision@10: 0.005163
2025-11-22 22:33:29 - GraphTrainer - INFO - recall@10: 0.048996
2025-11-22 22:33:29 - GraphTrainer - INFO - hit_rate@10: 0.051530
2025-11-22 22:33:29 - GraphTrainer - INFO - ndcg@10: 0.025946
2025-11-22 22:33:29 - GraphTrainer - INFO - map@10: 0.018677
2025-11-22 22:33:29 - GraphTrainer - INFO - mrr@10: 0.019449
2025-11-22 22:33:29 - GraphTrainer - INFO - precision@20: 0.004065
2025-11-22 22:33:29 - GraphTrainer - INFO - recall@20: 0.076947
2025-11-22 22:33:29 - GraphTrainer - INFO - hit_rate@20: 0.080895
2025-11-22 22:33:29 - GraphTrainer - INFO - ndcg@20: 0.033045
2025-11-22 22:33:29 - GraphTrainer - INFO - map@20: 0.020580
2025-11-22 22:33:29 - GraphTrainer - INFO - mrr@20: 0.021436
2025-11-22 22:33:29 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:33:29 - GraphTrainer - INFO - ============================================================
2025-11-22 22:33:29 - GraphTrainer - INFO - 开始第 117/1000 轮训练
2025-11-22 22:33:29 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3462, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3742, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3506, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3595, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3462, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3601, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3683, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3484, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3588, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3604, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3694, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3114, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3570, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3592, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3721, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3555, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3677, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3624, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3873, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3549, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3473, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3750, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3610, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3591, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3650, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3696, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3309, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3304, device='cuda:0', grad_fn=<AddBackward0>)
The 116 training average loss: 0.35087528362356385
2025-11-22 22:33:40 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:33:40 - GraphTrainer - INFO -   precision@5: 0.006243
2025-11-22 22:33:40 - GraphTrainer - INFO -   recall@5: 0.029643
2025-11-22 22:33:40 - GraphTrainer - INFO -   hit_rate@5: 0.031165
2025-11-22 22:33:40 - GraphTrainer - INFO -   ndcg@5: 0.018941
2025-11-22 22:33:40 - GraphTrainer - INFO -   map@5: 0.015213
2025-11-22 22:33:40 - GraphTrainer - INFO -   mrr@5: 0.015863
2025-11-22 22:33:40 - GraphTrainer - INFO -   precision@10: 0.004947
2025-11-22 22:33:40 - GraphTrainer - INFO -   recall@10: 0.046919
2025-11-22 22:33:40 - GraphTrainer - INFO -   hit_rate@10: 0.049421
2025-11-22 22:33:40 - GraphTrainer - INFO -   ndcg@10: 0.024561
2025-11-22 22:33:40 - GraphTrainer - INFO -   map@10: 0.017492
2025-11-22 22:33:40 - GraphTrainer - INFO -   mrr@10: 0.018272
2025-11-22 22:33:40 - GraphTrainer - INFO -   precision@20: 0.004029
2025-11-22 22:33:40 - GraphTrainer - INFO -   recall@20: 0.076195
2025-11-22 22:33:40 - GraphTrainer - INFO -   hit_rate@20: 0.080072
2025-11-22 22:33:40 - GraphTrainer - INFO -   ndcg@20: 0.031990
2025-11-22 22:33:40 - GraphTrainer - INFO -   map@20: 0.019480
2025-11-22 22:33:40 - GraphTrainer - INFO -   mrr@20: 0.020345
2025-11-22 22:33:40 - GraphTrainer - INFO - 第 117 轮训练完成
2025-11-22 22:33:40 - GraphTrainer - INFO - train_loss: 0.350266
2025-11-22 22:33:40 - GraphTrainer - INFO - precision@5: 0.006243
2025-11-22 22:33:40 - GraphTrainer - INFO - recall@5: 0.029643
2025-11-22 22:33:40 - GraphTrainer - INFO - hit_rate@5: 0.031165
2025-11-22 22:33:40 - GraphTrainer - INFO - ndcg@5: 0.018941
2025-11-22 22:33:40 - GraphTrainer - INFO - map@5: 0.015213
2025-11-22 22:33:40 - GraphTrainer - INFO - mrr@5: 0.015863
2025-11-22 22:33:40 - GraphTrainer - INFO - precision@10: 0.004947
2025-11-22 22:33:40 - GraphTrainer - INFO - recall@10: 0.046919
2025-11-22 22:33:40 - GraphTrainer - INFO - hit_rate@10: 0.049421
2025-11-22 22:33:40 - GraphTrainer - INFO - ndcg@10: 0.024561
2025-11-22 22:33:40 - GraphTrainer - INFO - map@10: 0.017492
2025-11-22 22:33:40 - GraphTrainer - INFO - mrr@10: 0.018272
2025-11-22 22:33:40 - GraphTrainer - INFO - precision@20: 0.004029
2025-11-22 22:33:40 - GraphTrainer - INFO - recall@20: 0.076195
2025-11-22 22:33:40 - GraphTrainer - INFO - hit_rate@20: 0.080072
2025-11-22 22:33:40 - GraphTrainer - INFO - ndcg@20: 0.031990
2025-11-22 22:33:40 - GraphTrainer - INFO - map@20: 0.019480
2025-11-22 22:33:40 - GraphTrainer - INFO - mrr@20: 0.020345
2025-11-22 22:33:40 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:33:40 - GraphTrainer - INFO - ============================================================
2025-11-22 22:33:40 - GraphTrainer - INFO - 开始第 118/1000 轮训练
2025-11-22 22:33:40 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3303, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3490, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3550, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3626, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3591, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3855, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3573, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3555, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3545, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3595, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3490, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3635, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3610, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3622, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3558, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3306, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3712, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3664, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3739, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3457, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3590, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3831, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3649, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
The 117 training average loss: 0.3502655065265195
2025-11-22 22:33:51 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:33:51 - GraphTrainer - INFO -   precision@5: 0.006284
2025-11-22 22:33:51 - GraphTrainer - INFO -   recall@5: 0.029979
2025-11-22 22:33:51 - GraphTrainer - INFO -   hit_rate@5: 0.031371
2025-11-22 22:33:51 - GraphTrainer - INFO -   ndcg@5: 0.019807
2025-11-22 22:33:51 - GraphTrainer - INFO -   map@5: 0.016247
2025-11-22 22:33:51 - GraphTrainer - INFO -   mrr@5: 0.016868
2025-11-22 22:33:51 - GraphTrainer - INFO -   precision@10: 0.004973
2025-11-22 22:33:51 - GraphTrainer - INFO -   recall@10: 0.047234
2025-11-22 22:33:51 - GraphTrainer - INFO -   hit_rate@10: 0.049576
2025-11-22 22:33:51 - GraphTrainer - INFO -   ndcg@10: 0.025415
2025-11-22 22:33:51 - GraphTrainer - INFO -   map@10: 0.018515
2025-11-22 22:33:51 - GraphTrainer - INFO -   mrr@10: 0.019261
2025-11-22 22:33:51 - GraphTrainer - INFO -   precision@20: 0.003875
2025-11-22 22:33:51 - GraphTrainer - INFO -   recall@20: 0.073418
2025-11-22 22:33:51 - GraphTrainer - INFO -   hit_rate@20: 0.077089
2025-11-22 22:33:51 - GraphTrainer - INFO -   ndcg@20: 0.032094
2025-11-22 22:33:51 - GraphTrainer - INFO -   map@20: 0.020320
2025-11-22 22:33:51 - GraphTrainer - INFO -   mrr@20: 0.021152
2025-11-22 22:33:51 - GraphTrainer - INFO - 第 118 轮训练完成
2025-11-22 22:33:51 - GraphTrainer - INFO - train_loss: 0.350465
2025-11-22 22:33:51 - GraphTrainer - INFO - precision@5: 0.006284
2025-11-22 22:33:51 - GraphTrainer - INFO - recall@5: 0.029979
2025-11-22 22:33:51 - GraphTrainer - INFO - hit_rate@5: 0.031371
2025-11-22 22:33:51 - GraphTrainer - INFO - ndcg@5: 0.019807
2025-11-22 22:33:51 - GraphTrainer - INFO - map@5: 0.016247
2025-11-22 22:33:51 - GraphTrainer - INFO - mrr@5: 0.016868
2025-11-22 22:33:51 - GraphTrainer - INFO - precision@10: 0.004973
2025-11-22 22:33:51 - GraphTrainer - INFO - recall@10: 0.047234
2025-11-22 22:33:51 - GraphTrainer - INFO - hit_rate@10: 0.049576
2025-11-22 22:33:51 - GraphTrainer - INFO - ndcg@10: 0.025415
2025-11-22 22:33:51 - GraphTrainer - INFO - map@10: 0.018515
2025-11-22 22:33:51 - GraphTrainer - INFO - mrr@10: 0.019261
2025-11-22 22:33:51 - GraphTrainer - INFO - precision@20: 0.003875
2025-11-22 22:33:51 - GraphTrainer - INFO - recall@20: 0.073418
2025-11-22 22:33:51 - GraphTrainer - INFO - hit_rate@20: 0.077089
2025-11-22 22:33:51 - GraphTrainer - INFO - ndcg@20: 0.032094
2025-11-22 22:33:51 - GraphTrainer - INFO - map@20: 0.020320
2025-11-22 22:33:51 - GraphTrainer - INFO - mrr@20: 0.021152
2025-11-22 22:33:51 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:33:51 - GraphTrainer - INFO - ============================================================
2025-11-22 22:33:51 - GraphTrainer - INFO - 开始第 119/1000 轮训练
2025-11-22 22:33:51 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3548, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3547, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3622, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3658, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3634, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3462, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3532, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3181, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3582, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3902, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3462, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3563, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3531, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3634, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3559, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3735, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3464, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3572, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3433, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3597, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3628, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3806, device='cuda:0', grad_fn=<AddBackward0>)
The 118 training average loss: 0.350464652324545
2025-11-22 22:34:02 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:34:02 - GraphTrainer - INFO -   precision@5: 0.006326
2025-11-22 22:34:02 - GraphTrainer - INFO -   recall@5: 0.030304
2025-11-22 22:34:02 - GraphTrainer - INFO -   hit_rate@5: 0.031628
2025-11-22 22:34:02 - GraphTrainer - INFO -   ndcg@5: 0.019193
2025-11-22 22:34:02 - GraphTrainer - INFO -   map@5: 0.015361
2025-11-22 22:34:02 - GraphTrainer - INFO -   mrr@5: 0.015942
2025-11-22 22:34:02 - GraphTrainer - INFO -   precision@10: 0.005081
2025-11-22 22:34:02 - GraphTrainer - INFO -   recall@10: 0.048383
2025-11-22 22:34:02 - GraphTrainer - INFO -   hit_rate@10: 0.050707
2025-11-22 22:34:02 - GraphTrainer - INFO -   ndcg@10: 0.025077
2025-11-22 22:34:02 - GraphTrainer - INFO -   map@10: 0.017746
2025-11-22 22:34:02 - GraphTrainer - INFO -   mrr@10: 0.018455
2025-11-22 22:34:02 - GraphTrainer - INFO -   precision@20: 0.004050
2025-11-22 22:34:02 - GraphTrainer - INFO -   recall@20: 0.077054
2025-11-22 22:34:02 - GraphTrainer - INFO -   hit_rate@20: 0.080689
2025-11-22 22:34:02 - GraphTrainer - INFO -   ndcg@20: 0.032337
2025-11-22 22:34:02 - GraphTrainer - INFO -   map@20: 0.019685
2025-11-22 22:34:02 - GraphTrainer - INFO -   mrr@20: 0.020480
2025-11-22 22:34:02 - GraphTrainer - INFO - 第 119 轮训练完成
2025-11-22 22:34:02 - GraphTrainer - INFO - train_loss: 0.349293
2025-11-22 22:34:02 - GraphTrainer - INFO - precision@5: 0.006326
2025-11-22 22:34:02 - GraphTrainer - INFO - recall@5: 0.030304
2025-11-22 22:34:02 - GraphTrainer - INFO - hit_rate@5: 0.031628
2025-11-22 22:34:02 - GraphTrainer - INFO - ndcg@5: 0.019193
2025-11-22 22:34:02 - GraphTrainer - INFO - map@5: 0.015361
2025-11-22 22:34:02 - GraphTrainer - INFO - mrr@5: 0.015942
2025-11-22 22:34:02 - GraphTrainer - INFO - precision@10: 0.005081
2025-11-22 22:34:02 - GraphTrainer - INFO - recall@10: 0.048383
2025-11-22 22:34:02 - GraphTrainer - INFO - hit_rate@10: 0.050707
2025-11-22 22:34:02 - GraphTrainer - INFO - ndcg@10: 0.025077
2025-11-22 22:34:02 - GraphTrainer - INFO - map@10: 0.017746
2025-11-22 22:34:02 - GraphTrainer - INFO - mrr@10: 0.018455
2025-11-22 22:34:02 - GraphTrainer - INFO - precision@20: 0.004050
2025-11-22 22:34:02 - GraphTrainer - INFO - recall@20: 0.077054
2025-11-22 22:34:02 - GraphTrainer - INFO - hit_rate@20: 0.080689
2025-11-22 22:34:02 - GraphTrainer - INFO - ndcg@20: 0.032337
2025-11-22 22:34:02 - GraphTrainer - INFO - map@20: 0.019685
2025-11-22 22:34:02 - GraphTrainer - INFO - mrr@20: 0.020480
2025-11-22 22:34:02 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:34:02 - GraphTrainer - INFO - ============================================================
2025-11-22 22:34:02 - GraphTrainer - INFO - 开始第 120/1000 轮训练
2025-11-22 22:34:02 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3272, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3466, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3521, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3309, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3608, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3731, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3313, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3549, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3158, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3703, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3573, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3653, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3762, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3434, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3701, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3592, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3545, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3605, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3565, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3667, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3693, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3588, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3902, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3592, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3132, device='cuda:0', grad_fn=<AddBackward0>)
The 119 training average loss: 0.3492927623206171
2025-11-22 22:34:13 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:34:13 - GraphTrainer - INFO -   precision@5: 0.006007
2025-11-22 22:34:13 - GraphTrainer - INFO -   recall@5: 0.028650
2025-11-22 22:34:13 - GraphTrainer - INFO -   hit_rate@5: 0.029982
2025-11-22 22:34:13 - GraphTrainer - INFO -   ndcg@5: 0.017990
2025-11-22 22:34:13 - GraphTrainer - INFO -   map@5: 0.014305
2025-11-22 22:34:13 - GraphTrainer - INFO -   mrr@5: 0.014880
2025-11-22 22:34:13 - GraphTrainer - INFO -   precision@10: 0.005102
2025-11-22 22:34:13 - GraphTrainer - INFO -   recall@10: 0.048569
2025-11-22 22:34:13 - GraphTrainer - INFO -   hit_rate@10: 0.050913
2025-11-22 22:34:13 - GraphTrainer - INFO -   ndcg@10: 0.024449
2025-11-22 22:34:13 - GraphTrainer - INFO -   map@10: 0.016916
2025-11-22 22:34:13 - GraphTrainer - INFO -   mrr@10: 0.017618
2025-11-22 22:34:13 - GraphTrainer - INFO -   precision@20: 0.004073
2025-11-22 22:34:13 - GraphTrainer - INFO -   recall@20: 0.077140
2025-11-22 22:34:13 - GraphTrainer - INFO -   hit_rate@20: 0.081049
2025-11-22 22:34:13 - GraphTrainer - INFO -   ndcg@20: 0.031713
2025-11-22 22:34:13 - GraphTrainer - INFO -   map@20: 0.018860
2025-11-22 22:34:13 - GraphTrainer - INFO -   mrr@20: 0.019665
2025-11-22 22:34:13 - GraphTrainer - INFO - 第 120 轮训练完成
2025-11-22 22:34:13 - GraphTrainer - INFO - train_loss: 0.347909
2025-11-22 22:34:13 - GraphTrainer - INFO - precision@5: 0.006007
2025-11-22 22:34:13 - GraphTrainer - INFO - recall@5: 0.028650
2025-11-22 22:34:13 - GraphTrainer - INFO - hit_rate@5: 0.029982
2025-11-22 22:34:13 - GraphTrainer - INFO - ndcg@5: 0.017990
2025-11-22 22:34:13 - GraphTrainer - INFO - map@5: 0.014305
2025-11-22 22:34:13 - GraphTrainer - INFO - mrr@5: 0.014880
2025-11-22 22:34:13 - GraphTrainer - INFO - precision@10: 0.005102
2025-11-22 22:34:13 - GraphTrainer - INFO - recall@10: 0.048569
2025-11-22 22:34:13 - GraphTrainer - INFO - hit_rate@10: 0.050913
2025-11-22 22:34:13 - GraphTrainer - INFO - ndcg@10: 0.024449
2025-11-22 22:34:13 - GraphTrainer - INFO - map@10: 0.016916
2025-11-22 22:34:13 - GraphTrainer - INFO - mrr@10: 0.017618
2025-11-22 22:34:13 - GraphTrainer - INFO - precision@20: 0.004073
2025-11-22 22:34:13 - GraphTrainer - INFO - recall@20: 0.077140
2025-11-22 22:34:13 - GraphTrainer - INFO - hit_rate@20: 0.081049
2025-11-22 22:34:13 - GraphTrainer - INFO - ndcg@20: 0.031713
2025-11-22 22:34:13 - GraphTrainer - INFO - map@20: 0.018860
2025-11-22 22:34:13 - GraphTrainer - INFO - mrr@20: 0.019665
2025-11-22 22:34:13 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:34:13 - GraphTrainer - INFO - 检查点已保存: Epoch 120 -> ./checkpoints/checkpoint_epoch_120.pth
2025-11-22 22:34:13 - GraphTrainer - INFO - ============================================================
2025-11-22 22:34:13 - GraphTrainer - INFO - 开始第 121/1000 轮训练
2025-11-22 22:34:13 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3572, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3633, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3666, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3507, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3640, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3775, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3531, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3582, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3539, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3138, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3188, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3685, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3623, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3409, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3611, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3615, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3278, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3227, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3558, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3272, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3201, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3741, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3684, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3721, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3660, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3279, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3533, device='cuda:0', grad_fn=<AddBackward0>)
The 120 training average loss: 0.3479087995044116
2025-11-22 22:34:24 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:34:24 - GraphTrainer - INFO -   precision@5: 0.006470
2025-11-22 22:34:24 - GraphTrainer - INFO -   recall@5: 0.030769
2025-11-22 22:34:24 - GraphTrainer - INFO -   hit_rate@5: 0.032296
2025-11-22 22:34:24 - GraphTrainer - INFO -   ndcg@5: 0.020638
2025-11-22 22:34:24 - GraphTrainer - INFO -   map@5: 0.017056
2025-11-22 22:34:24 - GraphTrainer - INFO -   mrr@5: 0.017825
2025-11-22 22:34:24 - GraphTrainer - INFO -   precision@10: 0.005158
2025-11-22 22:34:24 - GraphTrainer - INFO -   recall@10: 0.048958
2025-11-22 22:34:24 - GraphTrainer - INFO -   hit_rate@10: 0.051479
2025-11-22 22:34:24 - GraphTrainer - INFO -   ndcg@10: 0.026558
2025-11-22 22:34:24 - GraphTrainer - INFO -   map@10: 0.019460
2025-11-22 22:34:24 - GraphTrainer - INFO -   mrr@10: 0.020360
2025-11-22 22:34:24 - GraphTrainer - INFO -   precision@20: 0.004124
2025-11-22 22:34:24 - GraphTrainer - INFO -   recall@20: 0.078232
2025-11-22 22:34:24 - GraphTrainer - INFO -   hit_rate@20: 0.082232
2025-11-22 22:34:24 - GraphTrainer - INFO -   ndcg@20: 0.033974
2025-11-22 22:34:24 - GraphTrainer - INFO -   map@20: 0.021438
2025-11-22 22:34:24 - GraphTrainer - INFO -   mrr@20: 0.022433
2025-11-22 22:34:24 - GraphTrainer - INFO - 第 121 轮训练完成
2025-11-22 22:34:24 - GraphTrainer - INFO - train_loss: 0.346639
2025-11-22 22:34:24 - GraphTrainer - INFO - precision@5: 0.006470
2025-11-22 22:34:24 - GraphTrainer - INFO - recall@5: 0.030769
2025-11-22 22:34:24 - GraphTrainer - INFO - hit_rate@5: 0.032296
2025-11-22 22:34:24 - GraphTrainer - INFO - ndcg@5: 0.020638
2025-11-22 22:34:24 - GraphTrainer - INFO - map@5: 0.017056
2025-11-22 22:34:24 - GraphTrainer - INFO - mrr@5: 0.017825
2025-11-22 22:34:24 - GraphTrainer - INFO - precision@10: 0.005158
2025-11-22 22:34:24 - GraphTrainer - INFO - recall@10: 0.048958
2025-11-22 22:34:24 - GraphTrainer - INFO - hit_rate@10: 0.051479
2025-11-22 22:34:24 - GraphTrainer - INFO - ndcg@10: 0.026558
2025-11-22 22:34:24 - GraphTrainer - INFO - map@10: 0.019460
2025-11-22 22:34:24 - GraphTrainer - INFO - mrr@10: 0.020360
2025-11-22 22:34:24 - GraphTrainer - INFO - precision@20: 0.004124
2025-11-22 22:34:24 - GraphTrainer - INFO - recall@20: 0.078232
2025-11-22 22:34:24 - GraphTrainer - INFO - hit_rate@20: 0.082232
2025-11-22 22:34:24 - GraphTrainer - INFO - ndcg@20: 0.033974
2025-11-22 22:34:24 - GraphTrainer - INFO - map@20: 0.021438
2025-11-22 22:34:24 - GraphTrainer - INFO - mrr@20: 0.022433
2025-11-22 22:34:24 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:34:24 - GraphTrainer - INFO - ============================================================
2025-11-22 22:34:24 - GraphTrainer - INFO - 开始第 122/1000 轮训练
2025-11-22 22:34:24 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3595, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3603, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3695, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3590, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3245, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3172, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3373, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3533, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3577, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3484, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3544, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3597, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3764, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3543, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3614, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3647, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3592, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3234, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3455, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3569, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3636, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3518, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3537, device='cuda:0', grad_fn=<AddBackward0>)
The 121 training average loss: 0.34663898163828355
2025-11-22 22:34:35 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:34:35 - GraphTrainer - INFO -   precision@5: 0.006603
2025-11-22 22:34:35 - GraphTrainer - INFO -   recall@5: 0.031433
2025-11-22 22:34:35 - GraphTrainer - INFO -   hit_rate@5: 0.032965
2025-11-22 22:34:35 - GraphTrainer - INFO -   ndcg@5: 0.020203
2025-11-22 22:34:35 - GraphTrainer - INFO -   map@5: 0.016276
2025-11-22 22:34:35 - GraphTrainer - INFO -   mrr@5: 0.016986
2025-11-22 22:34:35 - GraphTrainer - INFO -   precision@10: 0.005251
2025-11-22 22:34:35 - GraphTrainer - INFO -   recall@10: 0.049722
2025-11-22 22:34:35 - GraphTrainer - INFO -   hit_rate@10: 0.052353
2025-11-22 22:34:35 - GraphTrainer - INFO -   ndcg@10: 0.026149
2025-11-22 22:34:35 - GraphTrainer - INFO -   map@10: 0.018681
2025-11-22 22:34:35 - GraphTrainer - INFO -   mrr@10: 0.019529
2025-11-22 22:34:35 - GraphTrainer - INFO -   precision@20: 0.004091
2025-11-22 22:34:35 - GraphTrainer - INFO -   recall@20: 0.077519
2025-11-22 22:34:35 - GraphTrainer - INFO -   hit_rate@20: 0.081512
2025-11-22 22:34:35 - GraphTrainer - INFO -   ndcg@20: 0.033165
2025-11-22 22:34:35 - GraphTrainer - INFO -   map@20: 0.020540
2025-11-22 22:34:35 - GraphTrainer - INFO -   mrr@20: 0.021477
2025-11-22 22:34:35 - GraphTrainer - INFO - 第 122 轮训练完成
2025-11-22 22:34:35 - GraphTrainer - INFO - train_loss: 0.347653
2025-11-22 22:34:35 - GraphTrainer - INFO - precision@5: 0.006603
2025-11-22 22:34:35 - GraphTrainer - INFO - recall@5: 0.031433
2025-11-22 22:34:35 - GraphTrainer - INFO - hit_rate@5: 0.032965
2025-11-22 22:34:35 - GraphTrainer - INFO - ndcg@5: 0.020203
2025-11-22 22:34:35 - GraphTrainer - INFO - map@5: 0.016276
2025-11-22 22:34:35 - GraphTrainer - INFO - mrr@5: 0.016986
2025-11-22 22:34:35 - GraphTrainer - INFO - precision@10: 0.005251
2025-11-22 22:34:35 - GraphTrainer - INFO - recall@10: 0.049722
2025-11-22 22:34:35 - GraphTrainer - INFO - hit_rate@10: 0.052353
2025-11-22 22:34:35 - GraphTrainer - INFO - ndcg@10: 0.026149
2025-11-22 22:34:35 - GraphTrainer - INFO - map@10: 0.018681
2025-11-22 22:34:35 - GraphTrainer - INFO - mrr@10: 0.019529
2025-11-22 22:34:35 - GraphTrainer - INFO - precision@20: 0.004091
2025-11-22 22:34:35 - GraphTrainer - INFO - recall@20: 0.077519
2025-11-22 22:34:35 - GraphTrainer - INFO - hit_rate@20: 0.081512
2025-11-22 22:34:35 - GraphTrainer - INFO - ndcg@20: 0.033165
2025-11-22 22:34:35 - GraphTrainer - INFO - map@20: 0.020540
2025-11-22 22:34:35 - GraphTrainer - INFO - mrr@20: 0.021477
2025-11-22 22:34:35 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:34:35 - GraphTrainer - INFO - ============================================================
2025-11-22 22:34:35 - GraphTrainer - INFO - 开始第 123/1000 轮训练
2025-11-22 22:34:35 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3492, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3576, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3569, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3490, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3521, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3978, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3274, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3874, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3696, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3484, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3568, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3342, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3601, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3246, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3605, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3672, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3548, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3667, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3490, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3701, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3572, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3685, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3586, device='cuda:0', grad_fn=<AddBackward0>)
The 122 training average loss: 0.3476532630879304
2025-11-22 22:34:46 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:34:46 - GraphTrainer - INFO -   precision@5: 0.006398
2025-11-22 22:34:46 - GraphTrainer - INFO -   recall@5: 0.030620
2025-11-22 22:34:46 - GraphTrainer - INFO -   hit_rate@5: 0.031936
2025-11-22 22:34:46 - GraphTrainer - INFO -   ndcg@5: 0.019859
2025-11-22 22:34:46 - GraphTrainer - INFO -   map@5: 0.016118
2025-11-22 22:34:46 - GraphTrainer - INFO -   mrr@5: 0.016713
2025-11-22 22:34:46 - GraphTrainer - INFO -   precision@10: 0.005138
2025-11-22 22:34:46 - GraphTrainer - INFO -   recall@10: 0.048499
2025-11-22 22:34:46 - GraphTrainer - INFO -   hit_rate@10: 0.051067
2025-11-22 22:34:46 - GraphTrainer - INFO -   ndcg@10: 0.025701
2025-11-22 22:34:46 - GraphTrainer - INFO -   map@10: 0.018481
2025-11-22 22:34:46 - GraphTrainer - INFO -   mrr@10: 0.019226
2025-11-22 22:34:46 - GraphTrainer - INFO -   precision@20: 0.004047
2025-11-22 22:34:46 - GraphTrainer - INFO -   recall@20: 0.076651
2025-11-22 22:34:46 - GraphTrainer - INFO -   hit_rate@20: 0.080432
2025-11-22 22:34:46 - GraphTrainer - INFO -   ndcg@20: 0.032845
2025-11-22 22:34:46 - GraphTrainer - INFO -   map@20: 0.020401
2025-11-22 22:34:46 - GraphTrainer - INFO -   mrr@20: 0.021231
2025-11-22 22:34:46 - GraphTrainer - INFO - 第 123 轮训练完成
2025-11-22 22:34:46 - GraphTrainer - INFO - train_loss: 0.346723
2025-11-22 22:34:46 - GraphTrainer - INFO - precision@5: 0.006398
2025-11-22 22:34:46 - GraphTrainer - INFO - recall@5: 0.030620
2025-11-22 22:34:46 - GraphTrainer - INFO - hit_rate@5: 0.031936
2025-11-22 22:34:46 - GraphTrainer - INFO - ndcg@5: 0.019859
2025-11-22 22:34:46 - GraphTrainer - INFO - map@5: 0.016118
2025-11-22 22:34:46 - GraphTrainer - INFO - mrr@5: 0.016713
2025-11-22 22:34:46 - GraphTrainer - INFO - precision@10: 0.005138
2025-11-22 22:34:46 - GraphTrainer - INFO - recall@10: 0.048499
2025-11-22 22:34:46 - GraphTrainer - INFO - hit_rate@10: 0.051067
2025-11-22 22:34:46 - GraphTrainer - INFO - ndcg@10: 0.025701
2025-11-22 22:34:46 - GraphTrainer - INFO - map@10: 0.018481
2025-11-22 22:34:46 - GraphTrainer - INFO - mrr@10: 0.019226
2025-11-22 22:34:46 - GraphTrainer - INFO - precision@20: 0.004047
2025-11-22 22:34:46 - GraphTrainer - INFO - recall@20: 0.076651
2025-11-22 22:34:46 - GraphTrainer - INFO - hit_rate@20: 0.080432
2025-11-22 22:34:46 - GraphTrainer - INFO - ndcg@20: 0.032845
2025-11-22 22:34:46 - GraphTrainer - INFO - map@20: 0.020401
2025-11-22 22:34:46 - GraphTrainer - INFO - mrr@20: 0.021231
2025-11-22 22:34:46 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:34:46 - GraphTrainer - INFO - ============================================================
2025-11-22 22:34:46 - GraphTrainer - INFO - 开始第 124/1000 轮训练
2025-11-22 22:34:46 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3707, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3590, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3327, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3707, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3462, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3637, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3533, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3635, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3642, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3521, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3484, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3480, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3629, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3575, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3521, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3604, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3268, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3559, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3643, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3293, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3516, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3636, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3518, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3490, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3579, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3506, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3568, device='cuda:0', grad_fn=<AddBackward0>)
The 123 training average loss: 0.3467226120932349
2025-11-22 22:34:57 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:34:57 - GraphTrainer - INFO -   precision@5: 0.006336
2025-11-22 22:34:57 - GraphTrainer - INFO -   recall@5: 0.030157
2025-11-22 22:34:57 - GraphTrainer - INFO -   hit_rate@5: 0.031679
2025-11-22 22:34:57 - GraphTrainer - INFO -   ndcg@5: 0.019608
2025-11-22 22:34:57 - GraphTrainer - INFO -   map@5: 0.015935
2025-11-22 22:34:57 - GraphTrainer - INFO -   mrr@5: 0.016540
2025-11-22 22:34:57 - GraphTrainer - INFO -   precision@10: 0.005122
2025-11-22 22:34:57 - GraphTrainer - INFO -   recall@10: 0.048779
2025-11-22 22:34:57 - GraphTrainer - INFO -   hit_rate@10: 0.051119
2025-11-22 22:34:57 - GraphTrainer - INFO -   ndcg@10: 0.025674
2025-11-22 22:34:57 - GraphTrainer - INFO -   map@10: 0.018412
2025-11-22 22:34:57 - GraphTrainer - INFO -   mrr@10: 0.019119
2025-11-22 22:34:57 - GraphTrainer - INFO -   precision@20: 0.003978
2025-11-22 22:34:57 - GraphTrainer - INFO -   recall@20: 0.075386
2025-11-22 22:34:57 - GraphTrainer - INFO -   hit_rate@20: 0.079198
2025-11-22 22:34:57 - GraphTrainer - INFO -   ndcg@20: 0.032430
2025-11-22 22:34:57 - GraphTrainer - INFO -   map@20: 0.020217
2025-11-22 22:34:57 - GraphTrainer - INFO -   mrr@20: 0.021016
2025-11-22 22:34:57 - GraphTrainer - INFO - 第 124 轮训练完成
2025-11-22 22:34:57 - GraphTrainer - INFO - train_loss: 0.344647
2025-11-22 22:34:57 - GraphTrainer - INFO - precision@5: 0.006336
2025-11-22 22:34:57 - GraphTrainer - INFO - recall@5: 0.030157
2025-11-22 22:34:57 - GraphTrainer - INFO - hit_rate@5: 0.031679
2025-11-22 22:34:57 - GraphTrainer - INFO - ndcg@5: 0.019608
2025-11-22 22:34:57 - GraphTrainer - INFO - map@5: 0.015935
2025-11-22 22:34:57 - GraphTrainer - INFO - mrr@5: 0.016540
2025-11-22 22:34:57 - GraphTrainer - INFO - precision@10: 0.005122
2025-11-22 22:34:57 - GraphTrainer - INFO - recall@10: 0.048779
2025-11-22 22:34:57 - GraphTrainer - INFO - hit_rate@10: 0.051119
2025-11-22 22:34:57 - GraphTrainer - INFO - ndcg@10: 0.025674
2025-11-22 22:34:57 - GraphTrainer - INFO - map@10: 0.018412
2025-11-22 22:34:57 - GraphTrainer - INFO - mrr@10: 0.019119
2025-11-22 22:34:57 - GraphTrainer - INFO - precision@20: 0.003978
2025-11-22 22:34:57 - GraphTrainer - INFO - recall@20: 0.075386
2025-11-22 22:34:57 - GraphTrainer - INFO - hit_rate@20: 0.079198
2025-11-22 22:34:57 - GraphTrainer - INFO - ndcg@20: 0.032430
2025-11-22 22:34:57 - GraphTrainer - INFO - map@20: 0.020217
2025-11-22 22:34:57 - GraphTrainer - INFO - mrr@20: 0.021016
2025-11-22 22:34:57 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:34:57 - GraphTrainer - INFO - ============================================================
2025-11-22 22:34:57 - GraphTrainer - INFO - 开始第 125/1000 轮训练
2025-11-22 22:34:57 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3789, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3512, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3282, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3627, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3214, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3791, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3373, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3512, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3613, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3194, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3667, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3333, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3211, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3312, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3543, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3666, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3333, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3579, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3518, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3510, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3516, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3192, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3627, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3616, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3666, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
The 124 training average loss: 0.34464748100987797
2025-11-22 22:35:08 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:35:08 - GraphTrainer - INFO -   precision@5: 0.006387
2025-11-22 22:35:08 - GraphTrainer - INFO -   recall@5: 0.030701
2025-11-22 22:35:08 - GraphTrainer - INFO -   hit_rate@5: 0.031885
2025-11-22 22:35:08 - GraphTrainer - INFO -   ndcg@5: 0.019936
2025-11-22 22:35:08 - GraphTrainer - INFO -   map@5: 0.016208
2025-11-22 22:35:08 - GraphTrainer - INFO -   mrr@5: 0.016763
2025-11-22 22:35:08 - GraphTrainer - INFO -   precision@10: 0.005096
2025-11-22 22:35:08 - GraphTrainer - INFO -   recall@10: 0.048187
2025-11-22 22:35:08 - GraphTrainer - INFO -   hit_rate@10: 0.050707
2025-11-22 22:35:08 - GraphTrainer - INFO -   ndcg@10: 0.025664
2025-11-22 22:35:08 - GraphTrainer - INFO -   map@10: 0.018527
2025-11-22 22:35:08 - GraphTrainer - INFO -   mrr@10: 0.019249
2025-11-22 22:35:08 - GraphTrainer - INFO -   precision@20: 0.004073
2025-11-22 22:35:08 - GraphTrainer - INFO -   recall@20: 0.077167
2025-11-22 22:35:08 - GraphTrainer - INFO -   hit_rate@20: 0.080998
2025-11-22 22:35:08 - GraphTrainer - INFO -   ndcg@20: 0.032987
2025-11-22 22:35:08 - GraphTrainer - INFO -   map@20: 0.020475
2025-11-22 22:35:08 - GraphTrainer - INFO -   mrr@20: 0.021284
2025-11-22 22:35:08 - GraphTrainer - INFO - 第 125 轮训练完成
2025-11-22 22:35:08 - GraphTrainer - INFO - train_loss: 0.344701
2025-11-22 22:35:08 - GraphTrainer - INFO - precision@5: 0.006387
2025-11-22 22:35:08 - GraphTrainer - INFO - recall@5: 0.030701
2025-11-22 22:35:08 - GraphTrainer - INFO - hit_rate@5: 0.031885
2025-11-22 22:35:08 - GraphTrainer - INFO - ndcg@5: 0.019936
2025-11-22 22:35:08 - GraphTrainer - INFO - map@5: 0.016208
2025-11-22 22:35:08 - GraphTrainer - INFO - mrr@5: 0.016763
2025-11-22 22:35:08 - GraphTrainer - INFO - precision@10: 0.005096
2025-11-22 22:35:08 - GraphTrainer - INFO - recall@10: 0.048187
2025-11-22 22:35:08 - GraphTrainer - INFO - hit_rate@10: 0.050707
2025-11-22 22:35:08 - GraphTrainer - INFO - ndcg@10: 0.025664
2025-11-22 22:35:08 - GraphTrainer - INFO - map@10: 0.018527
2025-11-22 22:35:08 - GraphTrainer - INFO - mrr@10: 0.019249
2025-11-22 22:35:08 - GraphTrainer - INFO - precision@20: 0.004073
2025-11-22 22:35:08 - GraphTrainer - INFO - recall@20: 0.077167
2025-11-22 22:35:08 - GraphTrainer - INFO - hit_rate@20: 0.080998
2025-11-22 22:35:08 - GraphTrainer - INFO - ndcg@20: 0.032987
2025-11-22 22:35:08 - GraphTrainer - INFO - map@20: 0.020475
2025-11-22 22:35:08 - GraphTrainer - INFO - mrr@20: 0.021284
2025-11-22 22:35:08 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:35:08 - GraphTrainer - INFO - ============================================================
2025-11-22 22:35:08 - GraphTrainer - INFO - 开始第 126/1000 轮训练
2025-11-22 22:35:08 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3562, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3179, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3627, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3654, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3532, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3560, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3510, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3240, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3679, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3228, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3648, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3743, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3137, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3244, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3409, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3434, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3473, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3611, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3316, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3557, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3689, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3573, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3506, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3579, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3829, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3506, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3494, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3568, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2987, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3222, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3177, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>)
The 125 training average loss: 0.3447007264556556
2025-11-22 22:35:19 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:35:19 - GraphTrainer - INFO -   precision@5: 0.006511
2025-11-22 22:35:19 - GraphTrainer - INFO -   recall@5: 0.031091
2025-11-22 22:35:19 - GraphTrainer - INFO -   hit_rate@5: 0.032553
2025-11-22 22:35:19 - GraphTrainer - INFO -   ndcg@5: 0.019893
2025-11-22 22:35:19 - GraphTrainer - INFO -   map@5: 0.015991
2025-11-22 22:35:19 - GraphTrainer - INFO -   mrr@5: 0.016632
2025-11-22 22:35:19 - GraphTrainer - INFO -   precision@10: 0.005071
2025-11-22 22:35:19 - GraphTrainer - INFO -   recall@10: 0.048119
2025-11-22 22:35:19 - GraphTrainer - INFO -   hit_rate@10: 0.050656
2025-11-22 22:35:19 - GraphTrainer - INFO -   ndcg@10: 0.025411
2025-11-22 22:35:19 - GraphTrainer - INFO -   map@10: 0.018209
2025-11-22 22:35:19 - GraphTrainer - INFO -   mrr@10: 0.018989
2025-11-22 22:35:19 - GraphTrainer - INFO -   precision@20: 0.004037
2025-11-22 22:35:19 - GraphTrainer - INFO -   recall@20: 0.076381
2025-11-22 22:35:19 - GraphTrainer - INFO -   hit_rate@20: 0.080278
2025-11-22 22:35:19 - GraphTrainer - INFO -   ndcg@20: 0.032580
2025-11-22 22:35:19 - GraphTrainer - INFO -   map@20: 0.020123
2025-11-22 22:35:19 - GraphTrainer - INFO -   mrr@20: 0.020992
2025-11-22 22:35:19 - GraphTrainer - INFO - 第 126 轮训练完成
2025-11-22 22:35:19 - GraphTrainer - INFO - train_loss: 0.348900
2025-11-22 22:35:19 - GraphTrainer - INFO - precision@5: 0.006511
2025-11-22 22:35:19 - GraphTrainer - INFO - recall@5: 0.031091
2025-11-22 22:35:19 - GraphTrainer - INFO - hit_rate@5: 0.032553
2025-11-22 22:35:19 - GraphTrainer - INFO - ndcg@5: 0.019893
2025-11-22 22:35:19 - GraphTrainer - INFO - map@5: 0.015991
2025-11-22 22:35:19 - GraphTrainer - INFO - mrr@5: 0.016632
2025-11-22 22:35:19 - GraphTrainer - INFO - precision@10: 0.005071
2025-11-22 22:35:19 - GraphTrainer - INFO - recall@10: 0.048119
2025-11-22 22:35:19 - GraphTrainer - INFO - hit_rate@10: 0.050656
2025-11-22 22:35:19 - GraphTrainer - INFO - ndcg@10: 0.025411
2025-11-22 22:35:19 - GraphTrainer - INFO - map@10: 0.018209
2025-11-22 22:35:19 - GraphTrainer - INFO - mrr@10: 0.018989
2025-11-22 22:35:19 - GraphTrainer - INFO - precision@20: 0.004037
2025-11-22 22:35:19 - GraphTrainer - INFO - recall@20: 0.076381
2025-11-22 22:35:19 - GraphTrainer - INFO - hit_rate@20: 0.080278
2025-11-22 22:35:19 - GraphTrainer - INFO - ndcg@20: 0.032580
2025-11-22 22:35:19 - GraphTrainer - INFO - map@20: 0.020123
2025-11-22 22:35:19 - GraphTrainer - INFO - mrr@20: 0.020992
2025-11-22 22:35:19 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:35:19 - GraphTrainer - INFO - ============================================================
2025-11-22 22:35:19 - GraphTrainer - INFO - 开始第 127/1000 轮训练
2025-11-22 22:35:19 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3312, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3518, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3544, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3595, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3313, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3755, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3586, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3886, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3531, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3574, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3533, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3525, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3435, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3588, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3626, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3628, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3512, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3531, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3630, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3602, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3473, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3659, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3610, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)
The 126 training average loss: 0.3488998048264405
2025-11-22 22:35:30 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:35:30 - GraphTrainer - INFO -   precision@5: 0.006531
2025-11-22 22:35:30 - GraphTrainer - INFO -   recall@5: 0.031322
2025-11-22 22:35:30 - GraphTrainer - INFO -   hit_rate@5: 0.032605
2025-11-22 22:35:30 - GraphTrainer - INFO -   ndcg@5: 0.020075
2025-11-22 22:35:30 - GraphTrainer - INFO -   map@5: 0.016189
2025-11-22 22:35:30 - GraphTrainer - INFO -   mrr@5: 0.016782
2025-11-22 22:35:30 - GraphTrainer - INFO -   precision@10: 0.005004
2025-11-22 22:35:30 - GraphTrainer - INFO -   recall@10: 0.047456
2025-11-22 22:35:30 - GraphTrainer - INFO -   hit_rate@10: 0.049987
2025-11-22 22:35:30 - GraphTrainer - INFO -   ndcg@10: 0.025335
2025-11-22 22:35:30 - GraphTrainer - INFO -   map@10: 0.018308
2025-11-22 22:35:30 - GraphTrainer - INFO -   mrr@10: 0.019059
2025-11-22 22:35:30 - GraphTrainer - INFO -   precision@20: 0.004055
2025-11-22 22:35:30 - GraphTrainer - INFO -   recall@20: 0.076932
2025-11-22 22:35:30 - GraphTrainer - INFO -   hit_rate@20: 0.080741
2025-11-22 22:35:30 - GraphTrainer - INFO -   ndcg@20: 0.032808
2025-11-22 22:35:30 - GraphTrainer - INFO -   map@20: 0.020311
2025-11-22 22:35:30 - GraphTrainer - INFO -   mrr@20: 0.021144
2025-11-22 22:35:30 - GraphTrainer - INFO - 第 127 轮训练完成
2025-11-22 22:35:30 - GraphTrainer - INFO - train_loss: 0.343702
2025-11-22 22:35:30 - GraphTrainer - INFO - precision@5: 0.006531
2025-11-22 22:35:30 - GraphTrainer - INFO - recall@5: 0.031322
2025-11-22 22:35:30 - GraphTrainer - INFO - hit_rate@5: 0.032605
2025-11-22 22:35:30 - GraphTrainer - INFO - ndcg@5: 0.020075
2025-11-22 22:35:30 - GraphTrainer - INFO - map@5: 0.016189
2025-11-22 22:35:30 - GraphTrainer - INFO - mrr@5: 0.016782
2025-11-22 22:35:30 - GraphTrainer - INFO - precision@10: 0.005004
2025-11-22 22:35:30 - GraphTrainer - INFO - recall@10: 0.047456
2025-11-22 22:35:30 - GraphTrainer - INFO - hit_rate@10: 0.049987
2025-11-22 22:35:30 - GraphTrainer - INFO - ndcg@10: 0.025335
2025-11-22 22:35:30 - GraphTrainer - INFO - map@10: 0.018308
2025-11-22 22:35:30 - GraphTrainer - INFO - mrr@10: 0.019059
2025-11-22 22:35:30 - GraphTrainer - INFO - precision@20: 0.004055
2025-11-22 22:35:30 - GraphTrainer - INFO - recall@20: 0.076932
2025-11-22 22:35:30 - GraphTrainer - INFO - hit_rate@20: 0.080741
2025-11-22 22:35:30 - GraphTrainer - INFO - ndcg@20: 0.032808
2025-11-22 22:35:30 - GraphTrainer - INFO - map@20: 0.020311
2025-11-22 22:35:30 - GraphTrainer - INFO - mrr@20: 0.021144
2025-11-22 22:35:30 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:35:30 - GraphTrainer - INFO - ============================================================
2025-11-22 22:35:30 - GraphTrainer - INFO - 开始第 128/1000 轮训练
2025-11-22 22:35:30 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3293, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3466, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3664, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3570, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3484, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3549, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3512, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3240, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3841, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3588, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3248, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3502, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3601, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3637, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3120, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3534, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3628, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3566, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3327, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3278, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3464, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3672, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3466, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
The 127 training average loss: 0.34370186873551073
2025-11-22 22:35:41 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:35:41 - GraphTrainer - INFO -   precision@5: 0.006459
2025-11-22 22:35:41 - GraphTrainer - INFO -   recall@5: 0.030684
2025-11-22 22:35:41 - GraphTrainer - INFO -   hit_rate@5: 0.032245
2025-11-22 22:35:41 - GraphTrainer - INFO -   ndcg@5: 0.019761
2025-11-22 22:35:41 - GraphTrainer - INFO -   map@5: 0.015949
2025-11-22 22:35:41 - GraphTrainer - INFO -   mrr@5: 0.016603
2025-11-22 22:35:41 - GraphTrainer - INFO -   precision@10: 0.005143
2025-11-22 22:35:41 - GraphTrainer - INFO -   recall@10: 0.048826
2025-11-22 22:35:41 - GraphTrainer - INFO -   hit_rate@10: 0.051273
2025-11-22 22:35:41 - GraphTrainer - INFO -   ndcg@10: 0.025597
2025-11-22 22:35:41 - GraphTrainer - INFO -   map@10: 0.018283
2025-11-22 22:35:41 - GraphTrainer - INFO -   mrr@10: 0.019052
2025-11-22 22:35:41 - GraphTrainer - INFO -   precision@20: 0.004101
2025-11-22 22:35:41 - GraphTrainer - INFO -   recall@20: 0.077563
2025-11-22 22:35:41 - GraphTrainer - INFO -   hit_rate@20: 0.081563
2025-11-22 22:35:41 - GraphTrainer - INFO -   ndcg@20: 0.032918
2025-11-22 22:35:41 - GraphTrainer - INFO -   map@20: 0.020253
2025-11-22 22:35:41 - GraphTrainer - INFO -   mrr@20: 0.021117
2025-11-22 22:35:41 - GraphTrainer - INFO - 第 128 轮训练完成
2025-11-22 22:35:41 - GraphTrainer - INFO - train_loss: 0.346134
2025-11-22 22:35:41 - GraphTrainer - INFO - precision@5: 0.006459
2025-11-22 22:35:41 - GraphTrainer - INFO - recall@5: 0.030684
2025-11-22 22:35:41 - GraphTrainer - INFO - hit_rate@5: 0.032245
2025-11-22 22:35:41 - GraphTrainer - INFO - ndcg@5: 0.019761
2025-11-22 22:35:41 - GraphTrainer - INFO - map@5: 0.015949
2025-11-22 22:35:41 - GraphTrainer - INFO - mrr@5: 0.016603
2025-11-22 22:35:41 - GraphTrainer - INFO - precision@10: 0.005143
2025-11-22 22:35:41 - GraphTrainer - INFO - recall@10: 0.048826
2025-11-22 22:35:41 - GraphTrainer - INFO - hit_rate@10: 0.051273
2025-11-22 22:35:41 - GraphTrainer - INFO - ndcg@10: 0.025597
2025-11-22 22:35:41 - GraphTrainer - INFO - map@10: 0.018283
2025-11-22 22:35:41 - GraphTrainer - INFO - mrr@10: 0.019052
2025-11-22 22:35:41 - GraphTrainer - INFO - precision@20: 0.004101
2025-11-22 22:35:41 - GraphTrainer - INFO - recall@20: 0.077563
2025-11-22 22:35:41 - GraphTrainer - INFO - hit_rate@20: 0.081563
2025-11-22 22:35:41 - GraphTrainer - INFO - ndcg@20: 0.032918
2025-11-22 22:35:41 - GraphTrainer - INFO - map@20: 0.020253
2025-11-22 22:35:41 - GraphTrainer - INFO - mrr@20: 0.021117
2025-11-22 22:35:41 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:35:41 - GraphTrainer - INFO - ============================================================
2025-11-22 22:35:41 - GraphTrainer - INFO - 开始第 129/1000 轮训练
2025-11-22 22:35:41 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3512, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3435, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3269, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3204, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3492, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3628, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3575, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3217, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3228, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3596, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3610, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3509, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3579, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3619, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3490, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3703, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3590, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3735, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3296, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3327, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3249, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3710, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3480, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3534, device='cuda:0', grad_fn=<AddBackward0>)
The 128 training average loss: 0.3461337248826849
2025-11-22 22:35:52 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:35:52 - GraphTrainer - INFO -   precision@5: 0.006428
2025-11-22 22:35:52 - GraphTrainer - INFO -   recall@5: 0.030509
2025-11-22 22:35:52 - GraphTrainer - INFO -   hit_rate@5: 0.032091
2025-11-22 22:35:52 - GraphTrainer - INFO -   ndcg@5: 0.019757
2025-11-22 22:35:52 - GraphTrainer - INFO -   map@5: 0.015985
2025-11-22 22:35:52 - GraphTrainer - INFO -   mrr@5: 0.016679
2025-11-22 22:35:52 - GraphTrainer - INFO -   precision@10: 0.005163
2025-11-22 22:35:52 - GraphTrainer - INFO -   recall@10: 0.049130
2025-11-22 22:35:52 - GraphTrainer - INFO -   hit_rate@10: 0.051427
2025-11-22 22:35:52 - GraphTrainer - INFO -   ndcg@10: 0.025771
2025-11-22 22:35:52 - GraphTrainer - INFO -   map@10: 0.018417
2025-11-22 22:35:52 - GraphTrainer - INFO -   mrr@10: 0.019201
2025-11-22 22:35:52 - GraphTrainer - INFO -   precision@20: 0.004070
2025-11-22 22:35:52 - GraphTrainer - INFO -   recall@20: 0.077180
2025-11-22 22:35:52 - GraphTrainer - INFO -   hit_rate@20: 0.080946
2025-11-22 22:35:52 - GraphTrainer - INFO -   ndcg@20: 0.032910
2025-11-22 22:35:52 - GraphTrainer - INFO -   map@20: 0.020336
2025-11-22 22:35:52 - GraphTrainer - INFO -   mrr@20: 0.021218
2025-11-22 22:35:52 - GraphTrainer - INFO - 第 129 轮训练完成
2025-11-22 22:35:52 - GraphTrainer - INFO - train_loss: 0.344593
2025-11-22 22:35:52 - GraphTrainer - INFO - precision@5: 0.006428
2025-11-22 22:35:52 - GraphTrainer - INFO - recall@5: 0.030509
2025-11-22 22:35:52 - GraphTrainer - INFO - hit_rate@5: 0.032091
2025-11-22 22:35:52 - GraphTrainer - INFO - ndcg@5: 0.019757
2025-11-22 22:35:52 - GraphTrainer - INFO - map@5: 0.015985
2025-11-22 22:35:52 - GraphTrainer - INFO - mrr@5: 0.016679
2025-11-22 22:35:52 - GraphTrainer - INFO - precision@10: 0.005163
2025-11-22 22:35:52 - GraphTrainer - INFO - recall@10: 0.049130
2025-11-22 22:35:52 - GraphTrainer - INFO - hit_rate@10: 0.051427
2025-11-22 22:35:52 - GraphTrainer - INFO - ndcg@10: 0.025771
2025-11-22 22:35:52 - GraphTrainer - INFO - map@10: 0.018417
2025-11-22 22:35:52 - GraphTrainer - INFO - mrr@10: 0.019201
2025-11-22 22:35:52 - GraphTrainer - INFO - precision@20: 0.004070
2025-11-22 22:35:52 - GraphTrainer - INFO - recall@20: 0.077180
2025-11-22 22:35:52 - GraphTrainer - INFO - hit_rate@20: 0.080946
2025-11-22 22:35:52 - GraphTrainer - INFO - ndcg@20: 0.032910
2025-11-22 22:35:52 - GraphTrainer - INFO - map@20: 0.020336
2025-11-22 22:35:52 - GraphTrainer - INFO - mrr@20: 0.021218
2025-11-22 22:35:52 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:35:52 - GraphTrainer - INFO - ============================================================
2025-11-22 22:35:52 - GraphTrainer - INFO - 开始第 130/1000 轮训练
2025-11-22 22:35:52 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3592, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3225, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3598, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3731, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3659, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3582, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3769, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3228, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3550, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3269, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3601, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3306, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3784, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3655, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3532, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3279, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3507, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3269, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3688, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3379, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3691, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3659, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3272, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3617, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3075, device='cuda:0', grad_fn=<AddBackward0>)
The 129 training average loss: 0.3445934535100542
2025-11-22 22:36:03 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:36:03 - GraphTrainer - INFO -   precision@5: 0.006243
2025-11-22 22:36:03 - GraphTrainer - INFO -   recall@5: 0.029889
2025-11-22 22:36:03 - GraphTrainer - INFO -   hit_rate@5: 0.031113
2025-11-22 22:36:03 - GraphTrainer - INFO -   ndcg@5: 0.019636
2025-11-22 22:36:03 - GraphTrainer - INFO -   map@5: 0.016073
2025-11-22 22:36:03 - GraphTrainer - INFO -   mrr@5: 0.016679
2025-11-22 22:36:03 - GraphTrainer - INFO -   precision@10: 0.004968
2025-11-22 22:36:03 - GraphTrainer - INFO -   recall@10: 0.047312
2025-11-22 22:36:03 - GraphTrainer - INFO -   hit_rate@10: 0.049473
2025-11-22 22:36:03 - GraphTrainer - INFO -   ndcg@10: 0.025316
2025-11-22 22:36:03 - GraphTrainer - INFO -   map@10: 0.018383
2025-11-22 22:36:03 - GraphTrainer - INFO -   mrr@10: 0.019117
2025-11-22 22:36:03 - GraphTrainer - INFO -   precision@20: 0.004068
2025-11-22 22:36:03 - GraphTrainer - INFO -   recall@20: 0.077185
2025-11-22 22:36:03 - GraphTrainer - INFO -   hit_rate@20: 0.081049
2025-11-22 22:36:03 - GraphTrainer - INFO -   ndcg@20: 0.032914
2025-11-22 22:36:03 - GraphTrainer - INFO -   map@20: 0.020418
2025-11-22 22:36:03 - GraphTrainer - INFO -   mrr@20: 0.021269
2025-11-22 22:36:03 - GraphTrainer - INFO - 第 130 轮训练完成
2025-11-22 22:36:03 - GraphTrainer - INFO - train_loss: 0.347000
2025-11-22 22:36:03 - GraphTrainer - INFO - precision@5: 0.006243
2025-11-22 22:36:03 - GraphTrainer - INFO - recall@5: 0.029889
2025-11-22 22:36:03 - GraphTrainer - INFO - hit_rate@5: 0.031113
2025-11-22 22:36:03 - GraphTrainer - INFO - ndcg@5: 0.019636
2025-11-22 22:36:03 - GraphTrainer - INFO - map@5: 0.016073
2025-11-22 22:36:03 - GraphTrainer - INFO - mrr@5: 0.016679
2025-11-22 22:36:03 - GraphTrainer - INFO - precision@10: 0.004968
2025-11-22 22:36:03 - GraphTrainer - INFO - recall@10: 0.047312
2025-11-22 22:36:03 - GraphTrainer - INFO - hit_rate@10: 0.049473
2025-11-22 22:36:03 - GraphTrainer - INFO - ndcg@10: 0.025316
2025-11-22 22:36:03 - GraphTrainer - INFO - map@10: 0.018383
2025-11-22 22:36:03 - GraphTrainer - INFO - mrr@10: 0.019117
2025-11-22 22:36:03 - GraphTrainer - INFO - precision@20: 0.004068
2025-11-22 22:36:03 - GraphTrainer - INFO - recall@20: 0.077185
2025-11-22 22:36:03 - GraphTrainer - INFO - hit_rate@20: 0.081049
2025-11-22 22:36:03 - GraphTrainer - INFO - ndcg@20: 0.032914
2025-11-22 22:36:03 - GraphTrainer - INFO - map@20: 0.020418
2025-11-22 22:36:03 - GraphTrainer - INFO - mrr@20: 0.021269
2025-11-22 22:36:03 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:36:03 - GraphTrainer - INFO - 检查点已保存: Epoch 130 -> ./checkpoints/checkpoint_epoch_130.pth
2025-11-22 22:36:03 - GraphTrainer - INFO - ============================================================
2025-11-22 22:36:03 - GraphTrainer - INFO - 开始第 131/1000 轮训练
2025-11-22 22:36:03 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3434, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3282, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3716, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3673, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3586, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3231, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3684, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3299, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3534, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3555, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3560, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3649, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3261, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3409, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3433, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3518, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3672, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3261, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3531, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3309, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3776, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3569, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3705, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)
The 130 training average loss: 0.34699977214994104
2025-11-22 22:36:14 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:36:14 - GraphTrainer - INFO -   precision@5: 0.006542
2025-11-22 22:36:14 - GraphTrainer - INFO -   recall@5: 0.031139
2025-11-22 22:36:14 - GraphTrainer - INFO -   hit_rate@5: 0.032656
2025-11-22 22:36:14 - GraphTrainer - INFO -   ndcg@5: 0.020669
2025-11-22 22:36:14 - GraphTrainer - INFO -   map@5: 0.017001
2025-11-22 22:36:14 - GraphTrainer - INFO -   mrr@5: 0.017669
2025-11-22 22:36:14 - GraphTrainer - INFO -   precision@10: 0.005071
2025-11-22 22:36:14 - GraphTrainer - INFO -   recall@10: 0.048188
2025-11-22 22:36:14 - GraphTrainer - INFO -   hit_rate@10: 0.050553
2025-11-22 22:36:14 - GraphTrainer - INFO -   ndcg@10: 0.026203
2025-11-22 22:36:14 - GraphTrainer - INFO -   map@10: 0.019244
2025-11-22 22:36:14 - GraphTrainer - INFO -   mrr@10: 0.020019
2025-11-22 22:36:14 - GraphTrainer - INFO -   precision@20: 0.004140
2025-11-22 22:36:14 - GraphTrainer - INFO -   recall@20: 0.078513
2025-11-22 22:36:14 - GraphTrainer - INFO -   hit_rate@20: 0.082335
2025-11-22 22:36:14 - GraphTrainer - INFO -   ndcg@20: 0.033925
2025-11-22 22:36:14 - GraphTrainer - INFO -   map@20: 0.021325
2025-11-22 22:36:14 - GraphTrainer - INFO -   mrr@20: 0.022194
2025-11-22 22:36:14 - GraphTrainer - INFO - 第 131 轮训练完成
2025-11-22 22:36:14 - GraphTrainer - INFO - train_loss: 0.351659
2025-11-22 22:36:14 - GraphTrainer - INFO - precision@5: 0.006542
2025-11-22 22:36:14 - GraphTrainer - INFO - recall@5: 0.031139
2025-11-22 22:36:14 - GraphTrainer - INFO - hit_rate@5: 0.032656
2025-11-22 22:36:14 - GraphTrainer - INFO - ndcg@5: 0.020669
2025-11-22 22:36:14 - GraphTrainer - INFO - map@5: 0.017001
2025-11-22 22:36:14 - GraphTrainer - INFO - mrr@5: 0.017669
2025-11-22 22:36:14 - GraphTrainer - INFO - precision@10: 0.005071
2025-11-22 22:36:14 - GraphTrainer - INFO - recall@10: 0.048188
2025-11-22 22:36:14 - GraphTrainer - INFO - hit_rate@10: 0.050553
2025-11-22 22:36:14 - GraphTrainer - INFO - ndcg@10: 0.026203
2025-11-22 22:36:14 - GraphTrainer - INFO - map@10: 0.019244
2025-11-22 22:36:14 - GraphTrainer - INFO - mrr@10: 0.020019
2025-11-22 22:36:14 - GraphTrainer - INFO - precision@20: 0.004140
2025-11-22 22:36:14 - GraphTrainer - INFO - recall@20: 0.078513
2025-11-22 22:36:14 - GraphTrainer - INFO - hit_rate@20: 0.082335
2025-11-22 22:36:14 - GraphTrainer - INFO - ndcg@20: 0.033925
2025-11-22 22:36:14 - GraphTrainer - INFO - map@20: 0.021325
2025-11-22 22:36:14 - GraphTrainer - INFO - mrr@20: 0.022194
2025-11-22 22:36:14 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:36:14 - GraphTrainer - INFO - ============================================================
2025-11-22 22:36:14 - GraphTrainer - INFO - 开始第 132/1000 轮训练
2025-11-22 22:36:14 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3705, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3490, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3570, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3576, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3569, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3269, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3434, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3829, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3661, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3602, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3651, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3435, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3285, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3672, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3732, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3566, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3556, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3545, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3643, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3466, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3824, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3856, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3555, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3568, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3679, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3721, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3318, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3657, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3327, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3480, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3746, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3798, device='cuda:0', grad_fn=<AddBackward0>)
The 131 training average loss: 0.3516587018966675
2025-11-22 22:36:25 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:36:25 - GraphTrainer - INFO -   precision@5: 0.006398
2025-11-22 22:36:25 - GraphTrainer - INFO -   recall@5: 0.030517
2025-11-22 22:36:25 - GraphTrainer - INFO -   hit_rate@5: 0.031936
2025-11-22 22:36:25 - GraphTrainer - INFO -   ndcg@5: 0.019915
2025-11-22 22:36:25 - GraphTrainer - INFO -   map@5: 0.016215
2025-11-22 22:36:25 - GraphTrainer - INFO -   mrr@5: 0.016845
2025-11-22 22:36:25 - GraphTrainer - INFO -   precision@10: 0.005143
2025-11-22 22:36:25 - GraphTrainer - INFO -   recall@10: 0.049070
2025-11-22 22:36:25 - GraphTrainer - INFO -   hit_rate@10: 0.051273
2025-11-22 22:36:25 - GraphTrainer - INFO -   ndcg@10: 0.025859
2025-11-22 22:36:25 - GraphTrainer - INFO -   map@10: 0.018586
2025-11-22 22:36:25 - GraphTrainer - INFO -   mrr@10: 0.019315
2025-11-22 22:36:25 - GraphTrainer - INFO -   precision@20: 0.004096
2025-11-22 22:36:25 - GraphTrainer - INFO -   recall@20: 0.077915
2025-11-22 22:36:25 - GraphTrainer - INFO -   hit_rate@20: 0.081409
2025-11-22 22:36:25 - GraphTrainer - INFO -   ndcg@20: 0.033181
2025-11-22 22:36:25 - GraphTrainer - INFO -   map@20: 0.020550
2025-11-22 22:36:25 - GraphTrainer - INFO -   mrr@20: 0.021361
2025-11-22 22:36:25 - GraphTrainer - INFO - 第 132 轮训练完成
2025-11-22 22:36:25 - GraphTrainer - INFO - train_loss: 0.343973
2025-11-22 22:36:25 - GraphTrainer - INFO - precision@5: 0.006398
2025-11-22 22:36:25 - GraphTrainer - INFO - recall@5: 0.030517
2025-11-22 22:36:25 - GraphTrainer - INFO - hit_rate@5: 0.031936
2025-11-22 22:36:25 - GraphTrainer - INFO - ndcg@5: 0.019915
2025-11-22 22:36:25 - GraphTrainer - INFO - map@5: 0.016215
2025-11-22 22:36:25 - GraphTrainer - INFO - mrr@5: 0.016845
2025-11-22 22:36:25 - GraphTrainer - INFO - precision@10: 0.005143
2025-11-22 22:36:25 - GraphTrainer - INFO - recall@10: 0.049070
2025-11-22 22:36:25 - GraphTrainer - INFO - hit_rate@10: 0.051273
2025-11-22 22:36:25 - GraphTrainer - INFO - ndcg@10: 0.025859
2025-11-22 22:36:25 - GraphTrainer - INFO - map@10: 0.018586
2025-11-22 22:36:25 - GraphTrainer - INFO - mrr@10: 0.019315
2025-11-22 22:36:25 - GraphTrainer - INFO - precision@20: 0.004096
2025-11-22 22:36:25 - GraphTrainer - INFO - recall@20: 0.077915
2025-11-22 22:36:25 - GraphTrainer - INFO - hit_rate@20: 0.081409
2025-11-22 22:36:25 - GraphTrainer - INFO - ndcg@20: 0.033181
2025-11-22 22:36:25 - GraphTrainer - INFO - map@20: 0.020550
2025-11-22 22:36:25 - GraphTrainer - INFO - mrr@20: 0.021361
2025-11-22 22:36:25 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:36:25 - GraphTrainer - INFO - ============================================================
2025-11-22 22:36:25 - GraphTrainer - INFO - 开始第 133/1000 轮训练
2025-11-22 22:36:25 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3621, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3272, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3304, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3285, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3795, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3313, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3786, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3603, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3582, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3629, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3479, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3561, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3304, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3653, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3610, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3492, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3455, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3296, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3628, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3635, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3293, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3318, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3297, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
The 132 training average loss: 0.3439733504221357
2025-11-22 22:36:36 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:36:36 - GraphTrainer - INFO -   precision@5: 0.006264
2025-11-22 22:36:36 - GraphTrainer - INFO -   recall@5: 0.030164
2025-11-22 22:36:36 - GraphTrainer - INFO -   hit_rate@5: 0.031319
2025-11-22 22:36:36 - GraphTrainer - INFO -   ndcg@5: 0.019558
2025-11-22 22:36:36 - GraphTrainer - INFO -   map@5: 0.015898
2025-11-22 22:36:36 - GraphTrainer - INFO -   mrr@5: 0.016446
2025-11-22 22:36:36 - GraphTrainer - INFO -   precision@10: 0.005132
2025-11-22 22:36:36 - GraphTrainer - INFO -   recall@10: 0.048766
2025-11-22 22:36:36 - GraphTrainer - INFO -   hit_rate@10: 0.051119
2025-11-22 22:36:36 - GraphTrainer - INFO -   ndcg@10: 0.025599
2025-11-22 22:36:36 - GraphTrainer - INFO -   map@10: 0.018324
2025-11-22 22:36:36 - GraphTrainer - INFO -   mrr@10: 0.019021
2025-11-22 22:36:36 - GraphTrainer - INFO -   precision@20: 0.004065
2025-11-22 22:36:36 - GraphTrainer - INFO -   recall@20: 0.077345
2025-11-22 22:36:36 - GraphTrainer - INFO -   hit_rate@20: 0.080946
2025-11-22 22:36:36 - GraphTrainer - INFO -   ndcg@20: 0.032834
2025-11-22 22:36:36 - GraphTrainer - INFO -   map@20: 0.020260
2025-11-22 22:36:36 - GraphTrainer - INFO -   mrr@20: 0.021037
2025-11-22 22:36:36 - GraphTrainer - INFO - 第 133 轮训练完成
2025-11-22 22:36:36 - GraphTrainer - INFO - train_loss: 0.343330
2025-11-22 22:36:36 - GraphTrainer - INFO - precision@5: 0.006264
2025-11-22 22:36:36 - GraphTrainer - INFO - recall@5: 0.030164
2025-11-22 22:36:36 - GraphTrainer - INFO - hit_rate@5: 0.031319
2025-11-22 22:36:36 - GraphTrainer - INFO - ndcg@5: 0.019558
2025-11-22 22:36:36 - GraphTrainer - INFO - map@5: 0.015898
2025-11-22 22:36:36 - GraphTrainer - INFO - mrr@5: 0.016446
2025-11-22 22:36:36 - GraphTrainer - INFO - precision@10: 0.005132
2025-11-22 22:36:36 - GraphTrainer - INFO - recall@10: 0.048766
2025-11-22 22:36:36 - GraphTrainer - INFO - hit_rate@10: 0.051119
2025-11-22 22:36:36 - GraphTrainer - INFO - ndcg@10: 0.025599
2025-11-22 22:36:36 - GraphTrainer - INFO - map@10: 0.018324
2025-11-22 22:36:36 - GraphTrainer - INFO - mrr@10: 0.019021
2025-11-22 22:36:36 - GraphTrainer - INFO - precision@20: 0.004065
2025-11-22 22:36:36 - GraphTrainer - INFO - recall@20: 0.077345
2025-11-22 22:36:36 - GraphTrainer - INFO - hit_rate@20: 0.080946
2025-11-22 22:36:36 - GraphTrainer - INFO - ndcg@20: 0.032834
2025-11-22 22:36:36 - GraphTrainer - INFO - map@20: 0.020260
2025-11-22 22:36:36 - GraphTrainer - INFO - mrr@20: 0.021037
2025-11-22 22:36:36 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:36:36 - GraphTrainer - INFO - ============================================================
2025-11-22 22:36:36 - GraphTrainer - INFO - 开始第 134/1000 轮训练
2025-11-22 22:36:36 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3557, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3434, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3473, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3548, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3596, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3435, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3331, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3208, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3620, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3110, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3279, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3576, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3688, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3281, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3584, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3547, device='cuda:0', grad_fn=<AddBackward0>)
The 133 training average loss: 0.34332974409234934
2025-11-22 22:36:48 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:36:48 - GraphTrainer - INFO -   precision@5: 0.006572
2025-11-22 22:36:48 - GraphTrainer - INFO -   recall@5: 0.031410
2025-11-22 22:36:48 - GraphTrainer - INFO -   hit_rate@5: 0.032810
2025-11-22 22:36:48 - GraphTrainer - INFO -   ndcg@5: 0.020235
2025-11-22 22:36:48 - GraphTrainer - INFO -   map@5: 0.016351
2025-11-22 22:36:48 - GraphTrainer - INFO -   mrr@5: 0.017007
2025-11-22 22:36:48 - GraphTrainer - INFO -   precision@10: 0.005158
2025-11-22 22:36:48 - GraphTrainer - INFO -   recall@10: 0.049077
2025-11-22 22:36:48 - GraphTrainer - INFO -   hit_rate@10: 0.051530
2025-11-22 22:36:48 - GraphTrainer - INFO -   ndcg@10: 0.025949
2025-11-22 22:36:48 - GraphTrainer - INFO -   map@10: 0.018646
2025-11-22 22:36:48 - GraphTrainer - INFO -   mrr@10: 0.019439
2025-11-22 22:36:48 - GraphTrainer - INFO -   precision@20: 0.004083
2025-11-22 22:36:48 - GraphTrainer - INFO -   recall@20: 0.077485
2025-11-22 22:36:48 - GraphTrainer - INFO -   hit_rate@20: 0.081255
2025-11-22 22:36:48 - GraphTrainer - INFO -   ndcg@20: 0.033127
2025-11-22 22:36:48 - GraphTrainer - INFO -   map@20: 0.020554
2025-11-22 22:36:48 - GraphTrainer - INFO -   mrr@20: 0.021428
2025-11-22 22:36:48 - GraphTrainer - INFO - 第 134 轮训练完成
2025-11-22 22:36:48 - GraphTrainer - INFO - train_loss: 0.343635
2025-11-22 22:36:48 - GraphTrainer - INFO - precision@5: 0.006572
2025-11-22 22:36:48 - GraphTrainer - INFO - recall@5: 0.031410
2025-11-22 22:36:48 - GraphTrainer - INFO - hit_rate@5: 0.032810
2025-11-22 22:36:48 - GraphTrainer - INFO - ndcg@5: 0.020235
2025-11-22 22:36:48 - GraphTrainer - INFO - map@5: 0.016351
2025-11-22 22:36:48 - GraphTrainer - INFO - mrr@5: 0.017007
2025-11-22 22:36:48 - GraphTrainer - INFO - precision@10: 0.005158
2025-11-22 22:36:48 - GraphTrainer - INFO - recall@10: 0.049077
2025-11-22 22:36:48 - GraphTrainer - INFO - hit_rate@10: 0.051530
2025-11-22 22:36:48 - GraphTrainer - INFO - ndcg@10: 0.025949
2025-11-22 22:36:48 - GraphTrainer - INFO - map@10: 0.018646
2025-11-22 22:36:48 - GraphTrainer - INFO - mrr@10: 0.019439
2025-11-22 22:36:48 - GraphTrainer - INFO - precision@20: 0.004083
2025-11-22 22:36:48 - GraphTrainer - INFO - recall@20: 0.077485
2025-11-22 22:36:48 - GraphTrainer - INFO - hit_rate@20: 0.081255
2025-11-22 22:36:48 - GraphTrainer - INFO - ndcg@20: 0.033127
2025-11-22 22:36:48 - GraphTrainer - INFO - map@20: 0.020554
2025-11-22 22:36:48 - GraphTrainer - INFO - mrr@20: 0.021428
2025-11-22 22:36:48 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:36:48 - GraphTrainer - INFO - ============================================================
2025-11-22 22:36:48 - GraphTrainer - INFO - 开始第 135/1000 轮训练
2025-11-22 22:36:48 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3303, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3204, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3273, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3237, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3662, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3521, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3577, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3245, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3409, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3711, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3433, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3545, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3576, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3642, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3379, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3674, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3293, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3592, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3127, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3642, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
The 134 training average loss: 0.3436345483722358
2025-11-22 22:36:59 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:36:59 - GraphTrainer - INFO -   precision@5: 0.006542
2025-11-22 22:36:59 - GraphTrainer - INFO -   recall@5: 0.031293
2025-11-22 22:36:59 - GraphTrainer - INFO -   hit_rate@5: 0.032708
2025-11-22 22:36:59 - GraphTrainer - INFO -   ndcg@5: 0.019925
2025-11-22 22:36:59 - GraphTrainer - INFO -   map@5: 0.016006
2025-11-22 22:36:59 - GraphTrainer - INFO -   mrr@5: 0.016616
2025-11-22 22:36:59 - GraphTrainer - INFO -   precision@10: 0.005055
2025-11-22 22:36:59 - GraphTrainer - INFO -   recall@10: 0.048137
2025-11-22 22:36:59 - GraphTrainer - INFO -   hit_rate@10: 0.050501
2025-11-22 22:36:59 - GraphTrainer - INFO -   ndcg@10: 0.025379
2025-11-22 22:36:59 - GraphTrainer - INFO -   map@10: 0.018200
2025-11-22 22:36:59 - GraphTrainer - INFO -   mrr@10: 0.018932
2025-11-22 22:36:59 - GraphTrainer - INFO -   precision@20: 0.003996
2025-11-22 22:36:59 - GraphTrainer - INFO -   recall@20: 0.075654
2025-11-22 22:36:59 - GraphTrainer - INFO -   hit_rate@20: 0.079609
2025-11-22 22:36:59 - GraphTrainer - INFO -   ndcg@20: 0.032379
2025-11-22 22:36:59 - GraphTrainer - INFO -   map@20: 0.020074
2025-11-22 22:36:59 - GraphTrainer - INFO -   mrr@20: 0.020906
2025-11-22 22:36:59 - GraphTrainer - INFO - 第 135 轮训练完成
2025-11-22 22:36:59 - GraphTrainer - INFO - train_loss: 0.346231
2025-11-22 22:36:59 - GraphTrainer - INFO - precision@5: 0.006542
2025-11-22 22:36:59 - GraphTrainer - INFO - recall@5: 0.031293
2025-11-22 22:36:59 - GraphTrainer - INFO - hit_rate@5: 0.032708
2025-11-22 22:36:59 - GraphTrainer - INFO - ndcg@5: 0.019925
2025-11-22 22:36:59 - GraphTrainer - INFO - map@5: 0.016006
2025-11-22 22:36:59 - GraphTrainer - INFO - mrr@5: 0.016616
2025-11-22 22:36:59 - GraphTrainer - INFO - precision@10: 0.005055
2025-11-22 22:36:59 - GraphTrainer - INFO - recall@10: 0.048137
2025-11-22 22:36:59 - GraphTrainer - INFO - hit_rate@10: 0.050501
2025-11-22 22:36:59 - GraphTrainer - INFO - ndcg@10: 0.025379
2025-11-22 22:36:59 - GraphTrainer - INFO - map@10: 0.018200
2025-11-22 22:36:59 - GraphTrainer - INFO - mrr@10: 0.018932
2025-11-22 22:36:59 - GraphTrainer - INFO - precision@20: 0.003996
2025-11-22 22:36:59 - GraphTrainer - INFO - recall@20: 0.075654
2025-11-22 22:36:59 - GraphTrainer - INFO - hit_rate@20: 0.079609
2025-11-22 22:36:59 - GraphTrainer - INFO - ndcg@20: 0.032379
2025-11-22 22:36:59 - GraphTrainer - INFO - map@20: 0.020074
2025-11-22 22:36:59 - GraphTrainer - INFO - mrr@20: 0.020906
2025-11-22 22:36:59 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:36:59 - GraphTrainer - INFO - ============================================================
2025-11-22 22:36:59 - GraphTrainer - INFO - 开始第 136/1000 轮训练
2025-11-22 22:36:59 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3077, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3507, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3220, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3640, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3677, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3479, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3592, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3327, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3206, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3466, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3532, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3536, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3565, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3665, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3494, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3804, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3624, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3753, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3616, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3533, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3694, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3166, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3152, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3455, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3563, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3228, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3685, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
The 135 training average loss: 0.34623094108597985
2025-11-22 22:37:10 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:37:10 - GraphTrainer - INFO -   precision@5: 0.006716
2025-11-22 22:37:10 - GraphTrainer - INFO -   recall@5: 0.031837
2025-11-22 22:37:10 - GraphTrainer - INFO -   hit_rate@5: 0.033530
2025-11-22 22:37:10 - GraphTrainer - INFO -   ndcg@5: 0.021364
2025-11-22 22:37:10 - GraphTrainer - INFO -   map@5: 0.017678
2025-11-22 22:37:10 - GraphTrainer - INFO -   mrr@5: 0.018422
2025-11-22 22:37:10 - GraphTrainer - INFO -   precision@10: 0.005215
2025-11-22 22:37:10 - GraphTrainer - INFO -   recall@10: 0.049416
2025-11-22 22:37:10 - GraphTrainer - INFO -   hit_rate@10: 0.051993
2025-11-22 22:37:10 - GraphTrainer - INFO -   ndcg@10: 0.027011
2025-11-22 22:37:10 - GraphTrainer - INFO -   map@10: 0.019931
2025-11-22 22:37:10 - GraphTrainer - INFO -   mrr@10: 0.020782
2025-11-22 22:37:10 - GraphTrainer - INFO -   precision@20: 0.004137
2025-11-22 22:37:10 - GraphTrainer - INFO -   recall@20: 0.078438
2025-11-22 22:37:10 - GraphTrainer - INFO -   hit_rate@20: 0.082438
2025-11-22 22:37:10 - GraphTrainer - INFO -   ndcg@20: 0.034353
2025-11-22 22:37:10 - GraphTrainer - INFO -   map@20: 0.021887
2025-11-22 22:37:10 - GraphTrainer - INFO -   mrr@20: 0.022832
2025-11-22 22:37:10 - GraphTrainer - INFO - 第 136 轮训练完成
2025-11-22 22:37:10 - GraphTrainer - INFO - train_loss: 0.342593
2025-11-22 22:37:10 - GraphTrainer - INFO - precision@5: 0.006716
2025-11-22 22:37:10 - GraphTrainer - INFO - recall@5: 0.031837
2025-11-22 22:37:10 - GraphTrainer - INFO - hit_rate@5: 0.033530
2025-11-22 22:37:10 - GraphTrainer - INFO - ndcg@5: 0.021364
2025-11-22 22:37:10 - GraphTrainer - INFO - map@5: 0.017678
2025-11-22 22:37:10 - GraphTrainer - INFO - mrr@5: 0.018422
2025-11-22 22:37:10 - GraphTrainer - INFO - precision@10: 0.005215
2025-11-22 22:37:10 - GraphTrainer - INFO - recall@10: 0.049416
2025-11-22 22:37:10 - GraphTrainer - INFO - hit_rate@10: 0.051993
2025-11-22 22:37:10 - GraphTrainer - INFO - ndcg@10: 0.027011
2025-11-22 22:37:10 - GraphTrainer - INFO - map@10: 0.019931
2025-11-22 22:37:10 - GraphTrainer - INFO - mrr@10: 0.020782
2025-11-22 22:37:10 - GraphTrainer - INFO - precision@20: 0.004137
2025-11-22 22:37:10 - GraphTrainer - INFO - recall@20: 0.078438
2025-11-22 22:37:10 - GraphTrainer - INFO - hit_rate@20: 0.082438
2025-11-22 22:37:10 - GraphTrainer - INFO - ndcg@20: 0.034353
2025-11-22 22:37:10 - GraphTrainer - INFO - map@20: 0.021887
2025-11-22 22:37:10 - GraphTrainer - INFO - mrr@20: 0.022832
2025-11-22 22:37:10 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:37:10 - GraphTrainer - INFO - ============================================================
2025-11-22 22:37:10 - GraphTrainer - INFO - 开始第 137/1000 轮训练
2025-11-22 22:37:10 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3140, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3379, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3715, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3373, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3645, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3468, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3182, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3579, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3709, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3257, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3657, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3316, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3612, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3566, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3494, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3231, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3688, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3282, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3614, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3577, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3225, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3569, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3575, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3510, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
The 136 training average loss: 0.34259342838977946
2025-11-22 22:37:21 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:37:21 - GraphTrainer - INFO -   precision@5: 0.006346
2025-11-22 22:37:21 - GraphTrainer - INFO -   recall@5: 0.030115
2025-11-22 22:37:21 - GraphTrainer - INFO -   hit_rate@5: 0.031679
2025-11-22 22:37:21 - GraphTrainer - INFO -   ndcg@5: 0.019776
2025-11-22 22:37:21 - GraphTrainer - INFO -   map@5: 0.016134
2025-11-22 22:37:21 - GraphTrainer - INFO -   mrr@5: 0.016835
2025-11-22 22:37:21 - GraphTrainer - INFO -   precision@10: 0.005132
2025-11-22 22:37:21 - GraphTrainer - INFO -   recall@10: 0.048610
2025-11-22 22:37:21 - GraphTrainer - INFO -   hit_rate@10: 0.051170
2025-11-22 22:37:21 - GraphTrainer - INFO -   ndcg@10: 0.025767
2025-11-22 22:37:21 - GraphTrainer - INFO -   map@10: 0.018548
2025-11-22 22:37:21 - GraphTrainer - INFO -   mrr@10: 0.019389
2025-11-22 22:37:21 - GraphTrainer - INFO -   precision@20: 0.004022
2025-11-22 22:37:21 - GraphTrainer - INFO -   recall@20: 0.076064
2025-11-22 22:37:21 - GraphTrainer - INFO -   hit_rate@20: 0.079969
2025-11-22 22:37:21 - GraphTrainer - INFO -   ndcg@20: 0.032724
2025-11-22 22:37:21 - GraphTrainer - INFO -   map@20: 0.020404
2025-11-22 22:37:21 - GraphTrainer - INFO -   mrr@20: 0.021328
2025-11-22 22:37:21 - GraphTrainer - INFO - 第 137 轮训练完成
2025-11-22 22:37:21 - GraphTrainer - INFO - train_loss: 0.343615
2025-11-22 22:37:21 - GraphTrainer - INFO - precision@5: 0.006346
2025-11-22 22:37:21 - GraphTrainer - INFO - recall@5: 0.030115
2025-11-22 22:37:21 - GraphTrainer - INFO - hit_rate@5: 0.031679
2025-11-22 22:37:21 - GraphTrainer - INFO - ndcg@5: 0.019776
2025-11-22 22:37:21 - GraphTrainer - INFO - map@5: 0.016134
2025-11-22 22:37:21 - GraphTrainer - INFO - mrr@5: 0.016835
2025-11-22 22:37:21 - GraphTrainer - INFO - precision@10: 0.005132
2025-11-22 22:37:21 - GraphTrainer - INFO - recall@10: 0.048610
2025-11-22 22:37:21 - GraphTrainer - INFO - hit_rate@10: 0.051170
2025-11-22 22:37:21 - GraphTrainer - INFO - ndcg@10: 0.025767
2025-11-22 22:37:21 - GraphTrainer - INFO - map@10: 0.018548
2025-11-22 22:37:21 - GraphTrainer - INFO - mrr@10: 0.019389
2025-11-22 22:37:21 - GraphTrainer - INFO - precision@20: 0.004022
2025-11-22 22:37:21 - GraphTrainer - INFO - recall@20: 0.076064
2025-11-22 22:37:21 - GraphTrainer - INFO - hit_rate@20: 0.079969
2025-11-22 22:37:21 - GraphTrainer - INFO - ndcg@20: 0.032724
2025-11-22 22:37:21 - GraphTrainer - INFO - map@20: 0.020404
2025-11-22 22:37:21 - GraphTrainer - INFO - mrr@20: 0.021328
2025-11-22 22:37:21 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:37:21 - GraphTrainer - INFO - ============================================================
2025-11-22 22:37:21 - GraphTrainer - INFO - 开始第 138/1000 轮训练
2025-11-22 22:37:21 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3561, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3635, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3433, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3565, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3656, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3169, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3736, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3661, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3516, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3327, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3484, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3657, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3105, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3572, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3499, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3409, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3179, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3568, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3632, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3592, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3373, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3531, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3521, device='cuda:0', grad_fn=<AddBackward0>)
The 137 training average loss: 0.34361512907620134
2025-11-22 22:37:32 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:37:32 - GraphTrainer - INFO -   precision@5: 0.006634
2025-11-22 22:37:32 - GraphTrainer - INFO -   recall@5: 0.031533
2025-11-22 22:37:32 - GraphTrainer - INFO -   hit_rate@5: 0.033119
2025-11-22 22:37:32 - GraphTrainer - INFO -   ndcg@5: 0.020688
2025-11-22 22:37:32 - GraphTrainer - INFO -   map@5: 0.016883
2025-11-22 22:37:32 - GraphTrainer - INFO -   mrr@5: 0.017561
2025-11-22 22:37:32 - GraphTrainer - INFO -   precision@10: 0.005143
2025-11-22 22:37:32 - GraphTrainer - INFO -   recall@10: 0.048821
2025-11-22 22:37:32 - GraphTrainer - INFO -   hit_rate@10: 0.051273
2025-11-22 22:37:32 - GraphTrainer - INFO -   ndcg@10: 0.026300
2025-11-22 22:37:32 - GraphTrainer - INFO -   map@10: 0.019157
2025-11-22 22:37:32 - GraphTrainer - INFO -   mrr@10: 0.019947
2025-11-22 22:37:32 - GraphTrainer - INFO -   precision@20: 0.004094
2025-11-22 22:37:32 - GraphTrainer - INFO -   recall@20: 0.077819
2025-11-22 22:37:32 - GraphTrainer - INFO -   hit_rate@20: 0.081409
2025-11-22 22:37:32 - GraphTrainer - INFO -   ndcg@20: 0.033622
2025-11-22 22:37:32 - GraphTrainer - INFO -   map@20: 0.021109
2025-11-22 22:37:32 - GraphTrainer - INFO -   mrr@20: 0.021975
2025-11-22 22:37:32 - GraphTrainer - INFO - 第 138 轮训练完成
2025-11-22 22:37:32 - GraphTrainer - INFO - train_loss: 0.343955
2025-11-22 22:37:32 - GraphTrainer - INFO - precision@5: 0.006634
2025-11-22 22:37:32 - GraphTrainer - INFO - recall@5: 0.031533
2025-11-22 22:37:32 - GraphTrainer - INFO - hit_rate@5: 0.033119
2025-11-22 22:37:32 - GraphTrainer - INFO - ndcg@5: 0.020688
2025-11-22 22:37:32 - GraphTrainer - INFO - map@5: 0.016883
2025-11-22 22:37:32 - GraphTrainer - INFO - mrr@5: 0.017561
2025-11-22 22:37:32 - GraphTrainer - INFO - precision@10: 0.005143
2025-11-22 22:37:32 - GraphTrainer - INFO - recall@10: 0.048821
2025-11-22 22:37:32 - GraphTrainer - INFO - hit_rate@10: 0.051273
2025-11-22 22:37:32 - GraphTrainer - INFO - ndcg@10: 0.026300
2025-11-22 22:37:32 - GraphTrainer - INFO - map@10: 0.019157
2025-11-22 22:37:32 - GraphTrainer - INFO - mrr@10: 0.019947
2025-11-22 22:37:32 - GraphTrainer - INFO - precision@20: 0.004094
2025-11-22 22:37:32 - GraphTrainer - INFO - recall@20: 0.077819
2025-11-22 22:37:32 - GraphTrainer - INFO - hit_rate@20: 0.081409
2025-11-22 22:37:32 - GraphTrainer - INFO - ndcg@20: 0.033622
2025-11-22 22:37:32 - GraphTrainer - INFO - map@20: 0.021109
2025-11-22 22:37:32 - GraphTrainer - INFO - mrr@20: 0.021975
2025-11-22 22:37:32 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:37:32 - GraphTrainer - INFO - ============================================================
2025-11-22 22:37:32 - GraphTrainer - INFO - 开始第 139/1000 轮训练
2025-11-22 22:37:32 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3628, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3245, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3544, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3662, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3109, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3512, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3825, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3227, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3622, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3293, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3596, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3272, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3561, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3234, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3574, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3479, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
The 138 training average loss: 0.34395535598541127
2025-11-22 22:37:43 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:37:43 - GraphTrainer - INFO -   precision@5: 0.006593
2025-11-22 22:37:43 - GraphTrainer - INFO -   recall@5: 0.031349
2025-11-22 22:37:43 - GraphTrainer - INFO -   hit_rate@5: 0.032913
2025-11-22 22:37:43 - GraphTrainer - INFO -   ndcg@5: 0.020142
2025-11-22 22:37:43 - GraphTrainer - INFO -   map@5: 0.016217
2025-11-22 22:37:43 - GraphTrainer - INFO -   mrr@5: 0.016959
2025-11-22 22:37:43 - GraphTrainer - INFO -   precision@10: 0.005153
2025-11-22 22:37:43 - GraphTrainer - INFO -   recall@10: 0.048794
2025-11-22 22:37:43 - GraphTrainer - INFO -   hit_rate@10: 0.051324
2025-11-22 22:37:43 - GraphTrainer - INFO -   ndcg@10: 0.025810
2025-11-22 22:37:43 - GraphTrainer - INFO -   map@10: 0.018510
2025-11-22 22:37:43 - GraphTrainer - INFO -   mrr@10: 0.019377
2025-11-22 22:37:43 - GraphTrainer - INFO -   precision@20: 0.004027
2025-11-22 22:37:43 - GraphTrainer - INFO -   recall@20: 0.076222
2025-11-22 22:37:43 - GraphTrainer - INFO -   hit_rate@20: 0.080072
2025-11-22 22:37:43 - GraphTrainer - INFO -   ndcg@20: 0.032783
2025-11-22 22:37:43 - GraphTrainer - INFO -   map@20: 0.020384
2025-11-22 22:37:43 - GraphTrainer - INFO -   mrr@20: 0.021336
2025-11-22 22:37:43 - GraphTrainer - INFO - 第 139 轮训练完成
2025-11-22 22:37:43 - GraphTrainer - INFO - train_loss: 0.343003
2025-11-22 22:37:43 - GraphTrainer - INFO - precision@5: 0.006593
2025-11-22 22:37:43 - GraphTrainer - INFO - recall@5: 0.031349
2025-11-22 22:37:43 - GraphTrainer - INFO - hit_rate@5: 0.032913
2025-11-22 22:37:43 - GraphTrainer - INFO - ndcg@5: 0.020142
2025-11-22 22:37:43 - GraphTrainer - INFO - map@5: 0.016217
2025-11-22 22:37:43 - GraphTrainer - INFO - mrr@5: 0.016959
2025-11-22 22:37:43 - GraphTrainer - INFO - precision@10: 0.005153
2025-11-22 22:37:43 - GraphTrainer - INFO - recall@10: 0.048794
2025-11-22 22:37:43 - GraphTrainer - INFO - hit_rate@10: 0.051324
2025-11-22 22:37:43 - GraphTrainer - INFO - ndcg@10: 0.025810
2025-11-22 22:37:43 - GraphTrainer - INFO - map@10: 0.018510
2025-11-22 22:37:43 - GraphTrainer - INFO - mrr@10: 0.019377
2025-11-22 22:37:43 - GraphTrainer - INFO - precision@20: 0.004027
2025-11-22 22:37:43 - GraphTrainer - INFO - recall@20: 0.076222
2025-11-22 22:37:43 - GraphTrainer - INFO - hit_rate@20: 0.080072
2025-11-22 22:37:43 - GraphTrainer - INFO - ndcg@20: 0.032783
2025-11-22 22:37:43 - GraphTrainer - INFO - map@20: 0.020384
2025-11-22 22:37:43 - GraphTrainer - INFO - mrr@20: 0.021336
2025-11-22 22:37:43 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:37:43 - GraphTrainer - INFO - ============================================================
2025-11-22 22:37:43 - GraphTrainer - INFO - 开始第 140/1000 轮训练
2025-11-22 22:37:43 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3539, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3261, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3534, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3598, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3218, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3236, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3725, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3636, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3660, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3703, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3126, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3648, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3125, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3545, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3212, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3579, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3691, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3613, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3376, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3185, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3640, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3810, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3554, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3220, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3516, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3631, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
The 139 training average loss: 0.34300296162736826
2025-11-22 22:37:55 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:37:55 - GraphTrainer - INFO -   precision@5: 0.006315
2025-11-22 22:37:55 - GraphTrainer - INFO -   recall@5: 0.029982
2025-11-22 22:37:55 - GraphTrainer - INFO -   hit_rate@5: 0.031473
2025-11-22 22:37:55 - GraphTrainer - INFO -   ndcg@5: 0.020795
2025-11-22 22:37:55 - GraphTrainer - INFO -   map@5: 0.017512
2025-11-22 22:37:55 - GraphTrainer - INFO -   mrr@5: 0.018233
2025-11-22 22:37:55 - GraphTrainer - INFO -   precision@10: 0.005199
2025-11-22 22:37:55 - GraphTrainer - INFO -   recall@10: 0.049415
2025-11-22 22:37:55 - GraphTrainer - INFO -   hit_rate@10: 0.051787
2025-11-22 22:37:55 - GraphTrainer - INFO -   ndcg@10: 0.027089
2025-11-22 22:37:55 - GraphTrainer - INFO -   map@10: 0.020057
2025-11-22 22:37:55 - GraphTrainer - INFO -   mrr@10: 0.020900
2025-11-22 22:37:55 - GraphTrainer - INFO -   precision@20: 0.004078
2025-11-22 22:37:55 - GraphTrainer - INFO -   recall@20: 0.077367
2025-11-22 22:37:55 - GraphTrainer - INFO -   hit_rate@20: 0.081152
2025-11-22 22:37:55 - GraphTrainer - INFO -   ndcg@20: 0.034170
2025-11-22 22:37:55 - GraphTrainer - INFO -   map@20: 0.021947
2025-11-22 22:37:55 - GraphTrainer - INFO -   mrr@20: 0.022879
2025-11-22 22:37:55 - GraphTrainer - INFO - 第 140 轮训练完成
2025-11-22 22:37:55 - GraphTrainer - INFO - train_loss: 0.341412
2025-11-22 22:37:55 - GraphTrainer - INFO - precision@5: 0.006315
2025-11-22 22:37:55 - GraphTrainer - INFO - recall@5: 0.029982
2025-11-22 22:37:55 - GraphTrainer - INFO - hit_rate@5: 0.031473
2025-11-22 22:37:55 - GraphTrainer - INFO - ndcg@5: 0.020795
2025-11-22 22:37:55 - GraphTrainer - INFO - map@5: 0.017512
2025-11-22 22:37:55 - GraphTrainer - INFO - mrr@5: 0.018233
2025-11-22 22:37:55 - GraphTrainer - INFO - precision@10: 0.005199
2025-11-22 22:37:55 - GraphTrainer - INFO - recall@10: 0.049415
2025-11-22 22:37:55 - GraphTrainer - INFO - hit_rate@10: 0.051787
2025-11-22 22:37:55 - GraphTrainer - INFO - ndcg@10: 0.027089
2025-11-22 22:37:55 - GraphTrainer - INFO - map@10: 0.020057
2025-11-22 22:37:55 - GraphTrainer - INFO - mrr@10: 0.020900
2025-11-22 22:37:55 - GraphTrainer - INFO - precision@20: 0.004078
2025-11-22 22:37:55 - GraphTrainer - INFO - recall@20: 0.077367
2025-11-22 22:37:55 - GraphTrainer - INFO - hit_rate@20: 0.081152
2025-11-22 22:37:55 - GraphTrainer - INFO - ndcg@20: 0.034170
2025-11-22 22:37:55 - GraphTrainer - INFO - map@20: 0.021947
2025-11-22 22:37:55 - GraphTrainer - INFO - mrr@20: 0.022879
2025-11-22 22:37:55 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:37:55 - GraphTrainer - INFO - 检查点已保存: Epoch 140 -> ./checkpoints/checkpoint_epoch_140.pth
2025-11-22 22:37:55 - GraphTrainer - INFO - ============================================================
2025-11-22 22:37:55 - GraphTrainer - INFO - 开始第 141/1000 轮训练
2025-11-22 22:37:55 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3544, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3290, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3590, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3261, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3214, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3245, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3285, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3302, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3236, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3130, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3543, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3671, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3434, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3455, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3647, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3409, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3201, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3246, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3509, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3554, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3534, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3596, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3536, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
The 140 training average loss: 0.3414122400612667
2025-11-22 22:38:06 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:38:06 - GraphTrainer - INFO -   precision@5: 0.006439
2025-11-22 22:38:06 - GraphTrainer - INFO -   recall@5: 0.030556
2025-11-22 22:38:06 - GraphTrainer - INFO -   hit_rate@5: 0.032142
2025-11-22 22:38:06 - GraphTrainer - INFO -   ndcg@5: 0.020520
2025-11-22 22:38:06 - GraphTrainer - INFO -   map@5: 0.016966
2025-11-22 22:38:06 - GraphTrainer - INFO -   mrr@5: 0.017669
2025-11-22 22:38:06 - GraphTrainer - INFO -   precision@10: 0.005153
2025-11-22 22:38:06 - GraphTrainer - INFO -   recall@10: 0.048919
2025-11-22 22:38:06 - GraphTrainer - INFO -   hit_rate@10: 0.051376
2025-11-22 22:38:06 - GraphTrainer - INFO -   ndcg@10: 0.026404
2025-11-22 22:38:06 - GraphTrainer - INFO -   map@10: 0.019309
2025-11-22 22:38:06 - GraphTrainer - INFO -   mrr@10: 0.020119
2025-11-22 22:38:06 - GraphTrainer - INFO -   precision@20: 0.004073
2025-11-22 22:38:06 - GraphTrainer - INFO -   recall@20: 0.077409
2025-11-22 22:38:06 - GraphTrainer - INFO -   hit_rate@20: 0.081049
2025-11-22 22:38:06 - GraphTrainer - INFO -   ndcg@20: 0.033637
2025-11-22 22:38:06 - GraphTrainer - INFO -   map@20: 0.021256
2025-11-22 22:38:06 - GraphTrainer - INFO -   mrr@20: 0.022143
2025-11-22 22:38:06 - GraphTrainer - INFO - 第 141 轮训练完成
2025-11-22 22:38:06 - GraphTrainer - INFO - train_loss: 0.341638
2025-11-22 22:38:06 - GraphTrainer - INFO - precision@5: 0.006439
2025-11-22 22:38:06 - GraphTrainer - INFO - recall@5: 0.030556
2025-11-22 22:38:06 - GraphTrainer - INFO - hit_rate@5: 0.032142
2025-11-22 22:38:06 - GraphTrainer - INFO - ndcg@5: 0.020520
2025-11-22 22:38:06 - GraphTrainer - INFO - map@5: 0.016966
2025-11-22 22:38:06 - GraphTrainer - INFO - mrr@5: 0.017669
2025-11-22 22:38:06 - GraphTrainer - INFO - precision@10: 0.005153
2025-11-22 22:38:06 - GraphTrainer - INFO - recall@10: 0.048919
2025-11-22 22:38:06 - GraphTrainer - INFO - hit_rate@10: 0.051376
2025-11-22 22:38:06 - GraphTrainer - INFO - ndcg@10: 0.026404
2025-11-22 22:38:06 - GraphTrainer - INFO - map@10: 0.019309
2025-11-22 22:38:06 - GraphTrainer - INFO - mrr@10: 0.020119
2025-11-22 22:38:06 - GraphTrainer - INFO - precision@20: 0.004073
2025-11-22 22:38:06 - GraphTrainer - INFO - recall@20: 0.077409
2025-11-22 22:38:06 - GraphTrainer - INFO - hit_rate@20: 0.081049
2025-11-22 22:38:06 - GraphTrainer - INFO - ndcg@20: 0.033637
2025-11-22 22:38:06 - GraphTrainer - INFO - map@20: 0.021256
2025-11-22 22:38:06 - GraphTrainer - INFO - mrr@20: 0.022143
2025-11-22 22:38:06 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:38:06 - GraphTrainer - INFO - ============================================================
2025-11-22 22:38:06 - GraphTrainer - INFO - 开始第 142/1000 轮训练
2025-11-22 22:38:06 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3177, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3182, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3457, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3284, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3599, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3316, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3573, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3468, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3532, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3318, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3241, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3331, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3464, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3756, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3574, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3536, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3566, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3239, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3179, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3760, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3656, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3521, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3615, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3595, device='cuda:0', grad_fn=<AddBackward0>)
The 141 training average loss: 0.3416375024565335
2025-11-22 22:38:17 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:38:17 - GraphTrainer - INFO -   precision@5: 0.006552
2025-11-22 22:38:17 - GraphTrainer - INFO -   recall@5: 0.031367
2025-11-22 22:38:17 - GraphTrainer - INFO -   hit_rate@5: 0.032708
2025-11-22 22:38:17 - GraphTrainer - INFO -   ndcg@5: 0.020565
2025-11-22 22:38:17 - GraphTrainer - INFO -   map@5: 0.016806
2025-11-22 22:38:17 - GraphTrainer - INFO -   mrr@5: 0.017387
2025-11-22 22:38:17 - GraphTrainer - INFO -   precision@10: 0.005117
2025-11-22 22:38:17 - GraphTrainer - INFO -   recall@10: 0.048496
2025-11-22 22:38:17 - GraphTrainer - INFO -   hit_rate@10: 0.051067
2025-11-22 22:38:17 - GraphTrainer - INFO -   ndcg@10: 0.026123
2025-11-22 22:38:17 - GraphTrainer - INFO -   map@10: 0.019031
2025-11-22 22:38:17 - GraphTrainer - INFO -   mrr@10: 0.019779
2025-11-22 22:38:17 - GraphTrainer - INFO -   precision@20: 0.004037
2025-11-22 22:38:17 - GraphTrainer - INFO -   recall@20: 0.076555
2025-11-22 22:38:17 - GraphTrainer - INFO -   hit_rate@20: 0.080381
2025-11-22 22:38:17 - GraphTrainer - INFO -   ndcg@20: 0.033244
2025-11-22 22:38:17 - GraphTrainer - INFO -   map@20: 0.020944
2025-11-22 22:38:17 - GraphTrainer - INFO -   mrr@20: 0.021770
2025-11-22 22:38:17 - GraphTrainer - INFO - 第 142 轮训练完成
2025-11-22 22:38:17 - GraphTrainer - INFO - train_loss: 0.340651
2025-11-22 22:38:17 - GraphTrainer - INFO - precision@5: 0.006552
2025-11-22 22:38:17 - GraphTrainer - INFO - recall@5: 0.031367
2025-11-22 22:38:17 - GraphTrainer - INFO - hit_rate@5: 0.032708
2025-11-22 22:38:17 - GraphTrainer - INFO - ndcg@5: 0.020565
2025-11-22 22:38:17 - GraphTrainer - INFO - map@5: 0.016806
2025-11-22 22:38:17 - GraphTrainer - INFO - mrr@5: 0.017387
2025-11-22 22:38:17 - GraphTrainer - INFO - precision@10: 0.005117
2025-11-22 22:38:17 - GraphTrainer - INFO - recall@10: 0.048496
2025-11-22 22:38:17 - GraphTrainer - INFO - hit_rate@10: 0.051067
2025-11-22 22:38:17 - GraphTrainer - INFO - ndcg@10: 0.026123
2025-11-22 22:38:17 - GraphTrainer - INFO - map@10: 0.019031
2025-11-22 22:38:17 - GraphTrainer - INFO - mrr@10: 0.019779
2025-11-22 22:38:17 - GraphTrainer - INFO - precision@20: 0.004037
2025-11-22 22:38:17 - GraphTrainer - INFO - recall@20: 0.076555
2025-11-22 22:38:17 - GraphTrainer - INFO - hit_rate@20: 0.080381
2025-11-22 22:38:17 - GraphTrainer - INFO - ndcg@20: 0.033244
2025-11-22 22:38:17 - GraphTrainer - INFO - map@20: 0.020944
2025-11-22 22:38:17 - GraphTrainer - INFO - mrr@20: 0.021770
2025-11-22 22:38:17 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:38:17 - GraphTrainer - INFO - ============================================================
2025-11-22 22:38:17 - GraphTrainer - INFO - 开始第 143/1000 轮训练
2025-11-22 22:38:17 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3331, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3612, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3237, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3169, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3138, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3133, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3561, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3213, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3570, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3517, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3502, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3658, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3746, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3871, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3561, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3118, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3216, device='cuda:0', grad_fn=<AddBackward0>)
The 142 training average loss: 0.3406509459018707
2025-11-22 22:38:29 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:38:29 - GraphTrainer - INFO -   precision@5: 0.006521
2025-11-22 22:38:29 - GraphTrainer - INFO -   recall@5: 0.031312
2025-11-22 22:38:29 - GraphTrainer - INFO -   hit_rate@5: 0.032553
2025-11-22 22:38:29 - GraphTrainer - INFO -   ndcg@5: 0.020715
2025-11-22 22:38:29 - GraphTrainer - INFO -   map@5: 0.017016
2025-11-22 22:38:29 - GraphTrainer - INFO -   mrr@5: 0.017656
2025-11-22 22:38:29 - GraphTrainer - INFO -   precision@10: 0.005235
2025-11-22 22:38:29 - GraphTrainer - INFO -   recall@10: 0.049551
2025-11-22 22:38:29 - GraphTrainer - INFO -   hit_rate@10: 0.052096
2025-11-22 22:38:29 - GraphTrainer - INFO -   ndcg@10: 0.026632
2025-11-22 22:38:29 - GraphTrainer - INFO -   map@10: 0.019383
2025-11-22 22:38:29 - GraphTrainer - INFO -   mrr@10: 0.020187
2025-11-22 22:38:29 - GraphTrainer - INFO -   precision@20: 0.004091
2025-11-22 22:38:29 - GraphTrainer - INFO -   recall@20: 0.077534
2025-11-22 22:38:29 - GraphTrainer - INFO -   hit_rate@20: 0.081409
2025-11-22 22:38:29 - GraphTrainer - INFO -   ndcg@20: 0.033714
2025-11-22 22:38:29 - GraphTrainer - INFO -   map@20: 0.021272
2025-11-22 22:38:29 - GraphTrainer - INFO -   mrr@20: 0.022162
2025-11-22 22:38:29 - GraphTrainer - INFO - 第 143 轮训练完成
2025-11-22 22:38:29 - GraphTrainer - INFO - train_loss: 0.339595
2025-11-22 22:38:29 - GraphTrainer - INFO - precision@5: 0.006521
2025-11-22 22:38:29 - GraphTrainer - INFO - recall@5: 0.031312
2025-11-22 22:38:29 - GraphTrainer - INFO - hit_rate@5: 0.032553
2025-11-22 22:38:29 - GraphTrainer - INFO - ndcg@5: 0.020715
2025-11-22 22:38:29 - GraphTrainer - INFO - map@5: 0.017016
2025-11-22 22:38:29 - GraphTrainer - INFO - mrr@5: 0.017656
2025-11-22 22:38:29 - GraphTrainer - INFO - precision@10: 0.005235
2025-11-22 22:38:29 - GraphTrainer - INFO - recall@10: 0.049551
2025-11-22 22:38:29 - GraphTrainer - INFO - hit_rate@10: 0.052096
2025-11-22 22:38:29 - GraphTrainer - INFO - ndcg@10: 0.026632
2025-11-22 22:38:29 - GraphTrainer - INFO - map@10: 0.019383
2025-11-22 22:38:29 - GraphTrainer - INFO - mrr@10: 0.020187
2025-11-22 22:38:29 - GraphTrainer - INFO - precision@20: 0.004091
2025-11-22 22:38:29 - GraphTrainer - INFO - recall@20: 0.077534
2025-11-22 22:38:29 - GraphTrainer - INFO - hit_rate@20: 0.081409
2025-11-22 22:38:29 - GraphTrainer - INFO - ndcg@20: 0.033714
2025-11-22 22:38:29 - GraphTrainer - INFO - map@20: 0.021272
2025-11-22 22:38:29 - GraphTrainer - INFO - mrr@20: 0.022162
2025-11-22 22:38:29 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:38:29 - GraphTrainer - INFO - ============================================================
2025-11-22 22:38:29 - GraphTrainer - INFO - 开始第 144/1000 轮训练
2025-11-22 22:38:29 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3555, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3605, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3516, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3608, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3201, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3231, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3293, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3534, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3586, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3596, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3327, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3228, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3327, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3157, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3281, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3457, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3462, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3044, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3434, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3183, device='cuda:0', grad_fn=<AddBackward0>)
The 143 training average loss: 0.3395953466152323
2025-11-22 22:38:40 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:38:40 - GraphTrainer - INFO -   precision@5: 0.006531
2025-11-22 22:38:40 - GraphTrainer - INFO -   recall@5: 0.031075
2025-11-22 22:38:40 - GraphTrainer - INFO -   hit_rate@5: 0.032605
2025-11-22 22:38:40 - GraphTrainer - INFO -   ndcg@5: 0.020536
2025-11-22 22:38:40 - GraphTrainer - INFO -   map@5: 0.016846
2025-11-22 22:38:40 - GraphTrainer - INFO -   mrr@5: 0.017540
2025-11-22 22:38:40 - GraphTrainer - INFO -   precision@10: 0.005256
2025-11-22 22:38:40 - GraphTrainer - INFO -   recall@10: 0.049949
2025-11-22 22:38:40 - GraphTrainer - INFO -   hit_rate@10: 0.052404
2025-11-22 22:38:40 - GraphTrainer - INFO -   ndcg@10: 0.026643
2025-11-22 22:38:40 - GraphTrainer - INFO -   map@10: 0.019308
2025-11-22 22:38:40 - GraphTrainer - INFO -   mrr@10: 0.020125
2025-11-22 22:38:40 - GraphTrainer - INFO -   precision@20: 0.004135
2025-11-22 22:38:40 - GraphTrainer - INFO -   recall@20: 0.078213
2025-11-22 22:38:40 - GraphTrainer - INFO -   hit_rate@20: 0.082283
2025-11-22 22:38:40 - GraphTrainer - INFO -   ndcg@20: 0.033802
2025-11-22 22:38:40 - GraphTrainer - INFO -   map@20: 0.021209
2025-11-22 22:38:40 - GraphTrainer - INFO -   mrr@20: 0.022128
2025-11-22 22:38:40 - GraphTrainer - INFO - 第 144 轮训练完成
2025-11-22 22:38:40 - GraphTrainer - INFO - train_loss: 0.337328
2025-11-22 22:38:40 - GraphTrainer - INFO - precision@5: 0.006531
2025-11-22 22:38:40 - GraphTrainer - INFO - recall@5: 0.031075
2025-11-22 22:38:40 - GraphTrainer - INFO - hit_rate@5: 0.032605
2025-11-22 22:38:40 - GraphTrainer - INFO - ndcg@5: 0.020536
2025-11-22 22:38:40 - GraphTrainer - INFO - map@5: 0.016846
2025-11-22 22:38:40 - GraphTrainer - INFO - mrr@5: 0.017540
2025-11-22 22:38:40 - GraphTrainer - INFO - precision@10: 0.005256
2025-11-22 22:38:40 - GraphTrainer - INFO - recall@10: 0.049949
2025-11-22 22:38:40 - GraphTrainer - INFO - hit_rate@10: 0.052404
2025-11-22 22:38:40 - GraphTrainer - INFO - ndcg@10: 0.026643
2025-11-22 22:38:40 - GraphTrainer - INFO - map@10: 0.019308
2025-11-22 22:38:40 - GraphTrainer - INFO - mrr@10: 0.020125
2025-11-22 22:38:40 - GraphTrainer - INFO - precision@20: 0.004135
2025-11-22 22:38:40 - GraphTrainer - INFO - recall@20: 0.078213
2025-11-22 22:38:40 - GraphTrainer - INFO - hit_rate@20: 0.082283
2025-11-22 22:38:40 - GraphTrainer - INFO - ndcg@20: 0.033802
2025-11-22 22:38:40 - GraphTrainer - INFO - map@20: 0.021209
2025-11-22 22:38:40 - GraphTrainer - INFO - mrr@20: 0.022128
2025-11-22 22:38:40 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:38:40 - GraphTrainer - INFO - ============================================================
2025-11-22 22:38:40 - GraphTrainer - INFO - 开始第 145/1000 轮训练
2025-11-22 22:38:40 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3249, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3169, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3659, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3272, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3199, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3313, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3199, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3534, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3545, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3126, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3252, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3233, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3512, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3518, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3793, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3188, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3204, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3435, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3379, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3237, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3230, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3023, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
The 144 training average loss: 0.33732810154043397
2025-11-22 22:38:51 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:38:51 - GraphTrainer - INFO -   precision@5: 0.006542
2025-11-22 22:38:51 - GraphTrainer - INFO -   recall@5: 0.030985
2025-11-22 22:38:51 - GraphTrainer - INFO -   hit_rate@5: 0.032656
2025-11-22 22:38:51 - GraphTrainer - INFO -   ndcg@5: 0.020321
2025-11-22 22:38:51 - GraphTrainer - INFO -   map@5: 0.016564
2025-11-22 22:38:51 - GraphTrainer - INFO -   mrr@5: 0.017287
2025-11-22 22:38:51 - GraphTrainer - INFO -   precision@10: 0.005132
2025-11-22 22:38:51 - GraphTrainer - INFO -   recall@10: 0.048582
2025-11-22 22:38:51 - GraphTrainer - INFO -   hit_rate@10: 0.051119
2025-11-22 22:38:51 - GraphTrainer - INFO -   ndcg@10: 0.026040
2025-11-22 22:38:51 - GraphTrainer - INFO -   map@10: 0.018884
2025-11-22 22:38:51 - GraphTrainer - INFO -   mrr@10: 0.019718
2025-11-22 22:38:51 - GraphTrainer - INFO -   precision@20: 0.004114
2025-11-22 22:38:51 - GraphTrainer - INFO -   recall@20: 0.078131
2025-11-22 22:38:51 - GraphTrainer - INFO -   hit_rate@20: 0.081872
2025-11-22 22:38:51 - GraphTrainer - INFO -   ndcg@20: 0.033524
2025-11-22 22:38:51 - GraphTrainer - INFO -   map@20: 0.020892
2025-11-22 22:38:51 - GraphTrainer - INFO -   mrr@20: 0.021803
2025-11-22 22:38:51 - GraphTrainer - INFO - 第 145 轮训练完成
2025-11-22 22:38:51 - GraphTrainer - INFO - train_loss: 0.335398
2025-11-22 22:38:51 - GraphTrainer - INFO - precision@5: 0.006542
2025-11-22 22:38:51 - GraphTrainer - INFO - recall@5: 0.030985
2025-11-22 22:38:51 - GraphTrainer - INFO - hit_rate@5: 0.032656
2025-11-22 22:38:51 - GraphTrainer - INFO - ndcg@5: 0.020321
2025-11-22 22:38:51 - GraphTrainer - INFO - map@5: 0.016564
2025-11-22 22:38:51 - GraphTrainer - INFO - mrr@5: 0.017287
2025-11-22 22:38:51 - GraphTrainer - INFO - precision@10: 0.005132
2025-11-22 22:38:51 - GraphTrainer - INFO - recall@10: 0.048582
2025-11-22 22:38:51 - GraphTrainer - INFO - hit_rate@10: 0.051119
2025-11-22 22:38:51 - GraphTrainer - INFO - ndcg@10: 0.026040
2025-11-22 22:38:51 - GraphTrainer - INFO - map@10: 0.018884
2025-11-22 22:38:51 - GraphTrainer - INFO - mrr@10: 0.019718
2025-11-22 22:38:51 - GraphTrainer - INFO - precision@20: 0.004114
2025-11-22 22:38:51 - GraphTrainer - INFO - recall@20: 0.078131
2025-11-22 22:38:51 - GraphTrainer - INFO - hit_rate@20: 0.081872
2025-11-22 22:38:51 - GraphTrainer - INFO - ndcg@20: 0.033524
2025-11-22 22:38:51 - GraphTrainer - INFO - map@20: 0.020892
2025-11-22 22:38:51 - GraphTrainer - INFO - mrr@20: 0.021803
2025-11-22 22:38:51 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:38:51 - GraphTrainer - INFO - ============================================================
2025-11-22 22:38:51 - GraphTrainer - INFO - 开始第 146/1000 轮训练
2025-11-22 22:38:51 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3516, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3212, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3190, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3259, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3226, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3115, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3312, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3167, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3376, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3616, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3313, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3409, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3376, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3656, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3563, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3232, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3547, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3157, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3185, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3164, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
The 145 training average loss: 0.33539804148262947
2025-11-22 22:39:02 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:39:02 - GraphTrainer - INFO -   precision@5: 0.006624
2025-11-22 22:39:02 - GraphTrainer - INFO -   recall@5: 0.031546
2025-11-22 22:39:02 - GraphTrainer - INFO -   hit_rate@5: 0.033068
2025-11-22 22:39:02 - GraphTrainer - INFO -   ndcg@5: 0.020514
2025-11-22 22:39:02 - GraphTrainer - INFO -   map@5: 0.016650
2025-11-22 22:39:02 - GraphTrainer - INFO -   mrr@5: 0.017335
2025-11-22 22:39:02 - GraphTrainer - INFO -   precision@10: 0.005282
2025-11-22 22:39:02 - GraphTrainer - INFO -   recall@10: 0.050357
2025-11-22 22:39:02 - GraphTrainer - INFO -   hit_rate@10: 0.052661
2025-11-22 22:39:02 - GraphTrainer - INFO -   ndcg@10: 0.026582
2025-11-22 22:39:02 - GraphTrainer - INFO -   map@10: 0.019095
2025-11-22 22:39:02 - GraphTrainer - INFO -   mrr@10: 0.019877
2025-11-22 22:39:02 - GraphTrainer - INFO -   precision@20: 0.004173
2025-11-22 22:39:02 - GraphTrainer - INFO -   recall@20: 0.079228
2025-11-22 22:39:02 - GraphTrainer - INFO -   hit_rate@20: 0.082952
2025-11-22 22:39:02 - GraphTrainer - INFO -   ndcg@20: 0.033919
2025-11-22 22:39:02 - GraphTrainer - INFO -   map@20: 0.021061
2025-11-22 22:39:02 - GraphTrainer - INFO -   mrr@20: 0.021938
2025-11-22 22:39:02 - GraphTrainer - INFO - 第 146 轮训练完成
2025-11-22 22:39:02 - GraphTrainer - INFO - train_loss: 0.334220
2025-11-22 22:39:02 - GraphTrainer - INFO - precision@5: 0.006624
2025-11-22 22:39:02 - GraphTrainer - INFO - recall@5: 0.031546
2025-11-22 22:39:02 - GraphTrainer - INFO - hit_rate@5: 0.033068
2025-11-22 22:39:02 - GraphTrainer - INFO - ndcg@5: 0.020514
2025-11-22 22:39:02 - GraphTrainer - INFO - map@5: 0.016650
2025-11-22 22:39:02 - GraphTrainer - INFO - mrr@5: 0.017335
2025-11-22 22:39:02 - GraphTrainer - INFO - precision@10: 0.005282
2025-11-22 22:39:02 - GraphTrainer - INFO - recall@10: 0.050357
2025-11-22 22:39:02 - GraphTrainer - INFO - hit_rate@10: 0.052661
2025-11-22 22:39:02 - GraphTrainer - INFO - ndcg@10: 0.026582
2025-11-22 22:39:02 - GraphTrainer - INFO - map@10: 0.019095
2025-11-22 22:39:02 - GraphTrainer - INFO - mrr@10: 0.019877
2025-11-22 22:39:02 - GraphTrainer - INFO - precision@20: 0.004173
2025-11-22 22:39:02 - GraphTrainer - INFO - recall@20: 0.079228
2025-11-22 22:39:02 - GraphTrainer - INFO - hit_rate@20: 0.082952
2025-11-22 22:39:02 - GraphTrainer - INFO - ndcg@20: 0.033919
2025-11-22 22:39:02 - GraphTrainer - INFO - map@20: 0.021061
2025-11-22 22:39:02 - GraphTrainer - INFO - mrr@20: 0.021938
2025-11-22 22:39:02 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:39:02 - GraphTrainer - INFO - ============================================================
2025-11-22 22:39:02 - GraphTrainer - INFO - 开始第 147/1000 轮训练
2025-11-22 22:39:02 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3697, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3233, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3129, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3297, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3200, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3129, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3272, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3680, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3376, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3480, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3629, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3120, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3240, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3152, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3547, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3516, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3239, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3174, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3222, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3263, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3167, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3409, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3312, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3169, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3259, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3285, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3304, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3177, device='cuda:0', grad_fn=<AddBackward0>)
The 146 training average loss: 0.33421986935467557
2025-11-22 22:39:13 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:39:13 - GraphTrainer - INFO -   precision@5: 0.006655
2025-11-22 22:39:13 - GraphTrainer - INFO -   recall@5: 0.031637
2025-11-22 22:39:13 - GraphTrainer - INFO -   hit_rate@5: 0.033222
2025-11-22 22:39:13 - GraphTrainer - INFO -   ndcg@5: 0.020702
2025-11-22 22:39:13 - GraphTrainer - INFO -   map@5: 0.016873
2025-11-22 22:39:13 - GraphTrainer - INFO -   mrr@5: 0.017611
2025-11-22 22:39:13 - GraphTrainer - INFO -   precision@10: 0.005230
2025-11-22 22:39:13 - GraphTrainer - INFO -   recall@10: 0.049577
2025-11-22 22:39:13 - GraphTrainer - INFO -   hit_rate@10: 0.052147
2025-11-22 22:39:13 - GraphTrainer - INFO -   ndcg@10: 0.026520
2025-11-22 22:39:13 - GraphTrainer - INFO -   map@10: 0.019220
2025-11-22 22:39:13 - GraphTrainer - INFO -   mrr@10: 0.020092
2025-11-22 22:39:13 - GraphTrainer - INFO -   precision@20: 0.004168
2025-11-22 22:39:13 - GraphTrainer - INFO -   recall@20: 0.078941
2025-11-22 22:39:13 - GraphTrainer - INFO -   hit_rate@20: 0.082952
2025-11-22 22:39:13 - GraphTrainer - INFO -   ndcg@20: 0.033923
2025-11-22 22:39:13 - GraphTrainer - INFO -   map@20: 0.021177
2025-11-22 22:39:13 - GraphTrainer - INFO -   mrr@20: 0.022140
2025-11-22 22:39:13 - GraphTrainer - INFO - 第 147 轮训练完成
2025-11-22 22:39:13 - GraphTrainer - INFO - train_loss: 0.336769
2025-11-22 22:39:13 - GraphTrainer - INFO - precision@5: 0.006655
2025-11-22 22:39:13 - GraphTrainer - INFO - recall@5: 0.031637
2025-11-22 22:39:13 - GraphTrainer - INFO - hit_rate@5: 0.033222
2025-11-22 22:39:13 - GraphTrainer - INFO - ndcg@5: 0.020702
2025-11-22 22:39:13 - GraphTrainer - INFO - map@5: 0.016873
2025-11-22 22:39:13 - GraphTrainer - INFO - mrr@5: 0.017611
2025-11-22 22:39:13 - GraphTrainer - INFO - precision@10: 0.005230
2025-11-22 22:39:13 - GraphTrainer - INFO - recall@10: 0.049577
2025-11-22 22:39:13 - GraphTrainer - INFO - hit_rate@10: 0.052147
2025-11-22 22:39:13 - GraphTrainer - INFO - ndcg@10: 0.026520
2025-11-22 22:39:13 - GraphTrainer - INFO - map@10: 0.019220
2025-11-22 22:39:13 - GraphTrainer - INFO - mrr@10: 0.020092
2025-11-22 22:39:13 - GraphTrainer - INFO - precision@20: 0.004168
2025-11-22 22:39:13 - GraphTrainer - INFO - recall@20: 0.078941
2025-11-22 22:39:13 - GraphTrainer - INFO - hit_rate@20: 0.082952
2025-11-22 22:39:13 - GraphTrainer - INFO - ndcg@20: 0.033923
2025-11-22 22:39:13 - GraphTrainer - INFO - map@20: 0.021177
2025-11-22 22:39:13 - GraphTrainer - INFO - mrr@20: 0.022140
2025-11-22 22:39:13 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:39:13 - GraphTrainer - INFO - ============================================================
2025-11-22 22:39:13 - GraphTrainer - INFO - 开始第 148/1000 轮训练
2025-11-22 22:39:13 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3147, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3201, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3306, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3246, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3246, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3258, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3562, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3205, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3252, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3257, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3226, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3152, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3435, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3560, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3559, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3222, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3194, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3167, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3215, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3284, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3641, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3516, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3492, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3097, device='cuda:0', grad_fn=<AddBackward0>)
The 147 training average loss: 0.33676904388542833
2025-11-22 22:39:25 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:39:25 - GraphTrainer - INFO -   precision@5: 0.006387
2025-11-22 22:39:25 - GraphTrainer - INFO -   recall@5: 0.030484
2025-11-22 22:39:25 - GraphTrainer - INFO -   hit_rate@5: 0.031885
2025-11-22 22:39:25 - GraphTrainer - INFO -   ndcg@5: 0.020034
2025-11-22 22:39:25 - GraphTrainer - INFO -   map@5: 0.016382
2025-11-22 22:39:25 - GraphTrainer - INFO -   mrr@5: 0.017038
2025-11-22 22:39:25 - GraphTrainer - INFO -   precision@10: 0.005035
2025-11-22 22:39:25 - GraphTrainer - INFO -   recall@10: 0.047835
2025-11-22 22:39:25 - GraphTrainer - INFO -   hit_rate@10: 0.050193
2025-11-22 22:39:25 - GraphTrainer - INFO -   ndcg@10: 0.025645
2025-11-22 22:39:25 - GraphTrainer - INFO -   map@10: 0.018636
2025-11-22 22:39:25 - GraphTrainer - INFO -   mrr@10: 0.019416
2025-11-22 22:39:25 - GraphTrainer - INFO -   precision@20: 0.004096
2025-11-22 22:39:25 - GraphTrainer - INFO -   recall@20: 0.077784
2025-11-22 22:39:25 - GraphTrainer - INFO -   hit_rate@20: 0.081512
2025-11-22 22:39:25 - GraphTrainer - INFO -   ndcg@20: 0.033272
2025-11-22 22:39:25 - GraphTrainer - INFO -   map@20: 0.020694
2025-11-22 22:39:25 - GraphTrainer - INFO -   mrr@20: 0.021565
2025-11-22 22:39:25 - GraphTrainer - INFO - 第 148 轮训练完成
2025-11-22 22:39:25 - GraphTrainer - INFO - train_loss: 0.338760
2025-11-22 22:39:25 - GraphTrainer - INFO - precision@5: 0.006387
2025-11-22 22:39:25 - GraphTrainer - INFO - recall@5: 0.030484
2025-11-22 22:39:25 - GraphTrainer - INFO - hit_rate@5: 0.031885
2025-11-22 22:39:25 - GraphTrainer - INFO - ndcg@5: 0.020034
2025-11-22 22:39:25 - GraphTrainer - INFO - map@5: 0.016382
2025-11-22 22:39:25 - GraphTrainer - INFO - mrr@5: 0.017038
2025-11-22 22:39:25 - GraphTrainer - INFO - precision@10: 0.005035
2025-11-22 22:39:25 - GraphTrainer - INFO - recall@10: 0.047835
2025-11-22 22:39:25 - GraphTrainer - INFO - hit_rate@10: 0.050193
2025-11-22 22:39:25 - GraphTrainer - INFO - ndcg@10: 0.025645
2025-11-22 22:39:25 - GraphTrainer - INFO - map@10: 0.018636
2025-11-22 22:39:25 - GraphTrainer - INFO - mrr@10: 0.019416
2025-11-22 22:39:25 - GraphTrainer - INFO - precision@20: 0.004096
2025-11-22 22:39:25 - GraphTrainer - INFO - recall@20: 0.077784
2025-11-22 22:39:25 - GraphTrainer - INFO - hit_rate@20: 0.081512
2025-11-22 22:39:25 - GraphTrainer - INFO - ndcg@20: 0.033272
2025-11-22 22:39:25 - GraphTrainer - INFO - map@20: 0.020694
2025-11-22 22:39:25 - GraphTrainer - INFO - mrr@20: 0.021565
2025-11-22 22:39:25 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:39:25 - GraphTrainer - INFO - ============================================================
2025-11-22 22:39:25 - GraphTrainer - INFO - 开始第 149/1000 轮训练
2025-11-22 22:39:25 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3293, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3279, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3138, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3649, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3435, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3591, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3331, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3558, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3562, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3557, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3561, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3703, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3230, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3272, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3318, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3260, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3211, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3195, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3569, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3642, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3204, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3285, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3157, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3269, device='cuda:0', grad_fn=<AddBackward0>)
The 148 training average loss: 0.33875959546401585
2025-11-22 22:39:36 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:39:36 - GraphTrainer - INFO -   precision@5: 0.006212
2025-11-22 22:39:36 - GraphTrainer - INFO -   recall@5: 0.029643
2025-11-22 22:39:36 - GraphTrainer - INFO -   hit_rate@5: 0.031011
2025-11-22 22:39:36 - GraphTrainer - INFO -   ndcg@5: 0.019850
2025-11-22 22:39:36 - GraphTrainer - INFO -   map@5: 0.016399
2025-11-22 22:39:36 - GraphTrainer - INFO -   mrr@5: 0.017084
2025-11-22 22:39:36 - GraphTrainer - INFO -   precision@10: 0.005019
2025-11-22 22:39:36 - GraphTrainer - INFO -   recall@10: 0.047565
2025-11-22 22:39:36 - GraphTrainer - INFO -   hit_rate@10: 0.049987
2025-11-22 22:39:36 - GraphTrainer - INFO -   ndcg@10: 0.025701
2025-11-22 22:39:36 - GraphTrainer - INFO -   map@10: 0.018774
2025-11-22 22:39:36 - GraphTrainer - INFO -   mrr@10: 0.019598
2025-11-22 22:39:36 - GraphTrainer - INFO -   precision@20: 0.004140
2025-11-22 22:39:36 - GraphTrainer - INFO -   recall@20: 0.078424
2025-11-22 22:39:36 - GraphTrainer - INFO -   hit_rate@20: 0.082335
2025-11-22 22:39:36 - GraphTrainer - INFO -   ndcg@20: 0.033533
2025-11-22 22:39:36 - GraphTrainer - INFO -   map@20: 0.020872
2025-11-22 22:39:36 - GraphTrainer - INFO -   mrr@20: 0.021794
2025-11-22 22:39:36 - GraphTrainer - INFO - 第 149 轮训练完成
2025-11-22 22:39:36 - GraphTrainer - INFO - train_loss: 0.334473
2025-11-22 22:39:36 - GraphTrainer - INFO - precision@5: 0.006212
2025-11-22 22:39:36 - GraphTrainer - INFO - recall@5: 0.029643
2025-11-22 22:39:36 - GraphTrainer - INFO - hit_rate@5: 0.031011
2025-11-22 22:39:36 - GraphTrainer - INFO - ndcg@5: 0.019850
2025-11-22 22:39:36 - GraphTrainer - INFO - map@5: 0.016399
2025-11-22 22:39:36 - GraphTrainer - INFO - mrr@5: 0.017084
2025-11-22 22:39:36 - GraphTrainer - INFO - precision@10: 0.005019
2025-11-22 22:39:36 - GraphTrainer - INFO - recall@10: 0.047565
2025-11-22 22:39:36 - GraphTrainer - INFO - hit_rate@10: 0.049987
2025-11-22 22:39:36 - GraphTrainer - INFO - ndcg@10: 0.025701
2025-11-22 22:39:36 - GraphTrainer - INFO - map@10: 0.018774
2025-11-22 22:39:36 - GraphTrainer - INFO - mrr@10: 0.019598
2025-11-22 22:39:36 - GraphTrainer - INFO - precision@20: 0.004140
2025-11-22 22:39:36 - GraphTrainer - INFO - recall@20: 0.078424
2025-11-22 22:39:36 - GraphTrainer - INFO - hit_rate@20: 0.082335
2025-11-22 22:39:36 - GraphTrainer - INFO - ndcg@20: 0.033533
2025-11-22 22:39:36 - GraphTrainer - INFO - map@20: 0.020872
2025-11-22 22:39:36 - GraphTrainer - INFO - mrr@20: 0.021794
2025-11-22 22:39:36 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:39:36 - GraphTrainer - INFO - ============================================================
2025-11-22 22:39:36 - GraphTrainer - INFO - 开始第 150/1000 轮训练
2025-11-22 22:39:36 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3163, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3309, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3156, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3195, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3252, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3529, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3166, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3231, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3095, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3213, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3128, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3248, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3259, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3192, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3433, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3499, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3571, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3066, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3480, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3517, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3572, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3570, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3246, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3063, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3261, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3233, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
The 149 training average loss: 0.33447256221853455
2025-11-22 22:39:47 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:39:47 - GraphTrainer - INFO -   precision@5: 0.006428
2025-11-22 22:39:47 - GraphTrainer - INFO -   recall@5: 0.030670
2025-11-22 22:39:47 - GraphTrainer - INFO -   hit_rate@5: 0.032142
2025-11-22 22:39:47 - GraphTrainer - INFO -   ndcg@5: 0.020110
2025-11-22 22:39:47 - GraphTrainer - INFO -   map@5: 0.016415
2025-11-22 22:39:47 - GraphTrainer - INFO -   mrr@5: 0.017088
2025-11-22 22:39:47 - GraphTrainer - INFO -   precision@10: 0.005168
2025-11-22 22:39:47 - GraphTrainer - INFO -   recall@10: 0.049024
2025-11-22 22:39:47 - GraphTrainer - INFO -   hit_rate@10: 0.051581
2025-11-22 22:39:47 - GraphTrainer - INFO -   ndcg@10: 0.026062
2025-11-22 22:39:47 - GraphTrainer - INFO -   map@10: 0.018810
2025-11-22 22:39:47 - GraphTrainer - INFO -   mrr@10: 0.019622
2025-11-22 22:39:47 - GraphTrainer - INFO -   precision@20: 0.004132
2025-11-22 22:39:47 - GraphTrainer - INFO -   recall@20: 0.078418
2025-11-22 22:39:47 - GraphTrainer - INFO -   hit_rate@20: 0.082335
2025-11-22 22:39:47 - GraphTrainer - INFO -   ndcg@20: 0.033520
2025-11-22 22:39:47 - GraphTrainer - INFO -   map@20: 0.020811
2025-11-22 22:39:47 - GraphTrainer - INFO -   mrr@20: 0.021706
2025-11-22 22:39:47 - GraphTrainer - INFO - 第 150 轮训练完成
2025-11-22 22:39:47 - GraphTrainer - INFO - train_loss: 0.337045
2025-11-22 22:39:47 - GraphTrainer - INFO - precision@5: 0.006428
2025-11-22 22:39:47 - GraphTrainer - INFO - recall@5: 0.030670
2025-11-22 22:39:47 - GraphTrainer - INFO - hit_rate@5: 0.032142
2025-11-22 22:39:47 - GraphTrainer - INFO - ndcg@5: 0.020110
2025-11-22 22:39:47 - GraphTrainer - INFO - map@5: 0.016415
2025-11-22 22:39:47 - GraphTrainer - INFO - mrr@5: 0.017088
2025-11-22 22:39:47 - GraphTrainer - INFO - precision@10: 0.005168
2025-11-22 22:39:47 - GraphTrainer - INFO - recall@10: 0.049024
2025-11-22 22:39:47 - GraphTrainer - INFO - hit_rate@10: 0.051581
2025-11-22 22:39:47 - GraphTrainer - INFO - ndcg@10: 0.026062
2025-11-22 22:39:47 - GraphTrainer - INFO - map@10: 0.018810
2025-11-22 22:39:47 - GraphTrainer - INFO - mrr@10: 0.019622
2025-11-22 22:39:47 - GraphTrainer - INFO - precision@20: 0.004132
2025-11-22 22:39:47 - GraphTrainer - INFO - recall@20: 0.078418
2025-11-22 22:39:47 - GraphTrainer - INFO - hit_rate@20: 0.082335
2025-11-22 22:39:47 - GraphTrainer - INFO - ndcg@20: 0.033520
2025-11-22 22:39:47 - GraphTrainer - INFO - map@20: 0.020811
2025-11-22 22:39:47 - GraphTrainer - INFO - mrr@20: 0.021706
2025-11-22 22:39:47 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:39:47 - GraphTrainer - INFO - 检查点已保存: Epoch 150 -> ./checkpoints/checkpoint_epoch_150.pth
2025-11-22 22:39:47 - GraphTrainer - INFO - ============================================================
2025-11-22 22:39:47 - GraphTrainer - INFO - 开始第 151/1000 轮训练
2025-11-22 22:39:47 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3468, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3233, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3306, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3273, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3574, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3257, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3261, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3187, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2993, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3309, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3551, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3260, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3634, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3479, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3306, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3579, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3279, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3058, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3575, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3551, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3258, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3140, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3263, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)
The 150 training average loss: 0.33704537718460476
2025-11-22 22:39:58 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:39:58 - GraphTrainer - INFO -   precision@5: 0.006675
2025-11-22 22:39:58 - GraphTrainer - INFO -   recall@5: 0.031907
2025-11-22 22:39:58 - GraphTrainer - INFO -   hit_rate@5: 0.033325
2025-11-22 22:39:58 - GraphTrainer - INFO -   ndcg@5: 0.020560
2025-11-22 22:39:58 - GraphTrainer - INFO -   map@5: 0.016610
2025-11-22 22:39:58 - GraphTrainer - INFO -   mrr@5: 0.017288
2025-11-22 22:39:58 - GraphTrainer - INFO -   precision@10: 0.005117
2025-11-22 22:39:58 - GraphTrainer - INFO -   recall@10: 0.048435
2025-11-22 22:39:58 - GraphTrainer - INFO -   hit_rate@10: 0.051016
2025-11-22 22:39:58 - GraphTrainer - INFO -   ndcg@10: 0.025943
2025-11-22 22:39:58 - GraphTrainer - INFO -   map@10: 0.018777
2025-11-22 22:39:58 - GraphTrainer - INFO -   mrr@10: 0.019612
2025-11-22 22:39:58 - GraphTrainer - INFO -   precision@20: 0.004086
2025-11-22 22:39:58 - GraphTrainer - INFO -   recall@20: 0.077594
2025-11-22 22:39:58 - GraphTrainer - INFO -   hit_rate@20: 0.081358
2025-11-22 22:39:58 - GraphTrainer - INFO -   ndcg@20: 0.033318
2025-11-22 22:39:58 - GraphTrainer - INFO -   map@20: 0.020750
2025-11-22 22:39:58 - GraphTrainer - INFO -   mrr@20: 0.021660
2025-11-22 22:39:58 - GraphTrainer - INFO - 第 151 轮训练完成
2025-11-22 22:39:58 - GraphTrainer - INFO - train_loss: 0.335910
2025-11-22 22:39:58 - GraphTrainer - INFO - precision@5: 0.006675
2025-11-22 22:39:58 - GraphTrainer - INFO - recall@5: 0.031907
2025-11-22 22:39:58 - GraphTrainer - INFO - hit_rate@5: 0.033325
2025-11-22 22:39:58 - GraphTrainer - INFO - ndcg@5: 0.020560
2025-11-22 22:39:58 - GraphTrainer - INFO - map@5: 0.016610
2025-11-22 22:39:58 - GraphTrainer - INFO - mrr@5: 0.017288
2025-11-22 22:39:58 - GraphTrainer - INFO - precision@10: 0.005117
2025-11-22 22:39:58 - GraphTrainer - INFO - recall@10: 0.048435
2025-11-22 22:39:58 - GraphTrainer - INFO - hit_rate@10: 0.051016
2025-11-22 22:39:58 - GraphTrainer - INFO - ndcg@10: 0.025943
2025-11-22 22:39:58 - GraphTrainer - INFO - map@10: 0.018777
2025-11-22 22:39:58 - GraphTrainer - INFO - mrr@10: 0.019612
2025-11-22 22:39:58 - GraphTrainer - INFO - precision@20: 0.004086
2025-11-22 22:39:58 - GraphTrainer - INFO - recall@20: 0.077594
2025-11-22 22:39:58 - GraphTrainer - INFO - hit_rate@20: 0.081358
2025-11-22 22:39:58 - GraphTrainer - INFO - ndcg@20: 0.033318
2025-11-22 22:39:58 - GraphTrainer - INFO - map@20: 0.020750
2025-11-22 22:39:58 - GraphTrainer - INFO - mrr@20: 0.021660
2025-11-22 22:39:58 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:39:58 - GraphTrainer - INFO - ============================================================
2025-11-22 22:39:58 - GraphTrainer - INFO - 开始第 152/1000 轮训练
2025-11-22 22:39:58 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3376, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3232, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3239, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3035, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3536, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3080, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3596, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3174, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3529, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3333, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3290, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3421, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3121, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3133, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3296, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3299, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3479, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3529, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3240, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3154, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3284, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3187, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3304, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3547, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3599, device='cuda:0', grad_fn=<AddBackward0>)
The 151 training average loss: 0.33591015123087786
2025-11-22 22:40:09 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:40:09 - GraphTrainer - INFO -   precision@5: 0.006614
2025-11-22 22:40:09 - GraphTrainer - INFO -   recall@5: 0.031504
2025-11-22 22:40:09 - GraphTrainer - INFO -   hit_rate@5: 0.032965
2025-11-22 22:40:09 - GraphTrainer - INFO -   ndcg@5: 0.020085
2025-11-22 22:40:09 - GraphTrainer - INFO -   map@5: 0.016106
2025-11-22 22:40:09 - GraphTrainer - INFO -   mrr@5: 0.016800
2025-11-22 22:40:09 - GraphTrainer - INFO -   precision@10: 0.005230
2025-11-22 22:40:09 - GraphTrainer - INFO -   recall@10: 0.049774
2025-11-22 22:40:09 - GraphTrainer - INFO -   hit_rate@10: 0.052147
2025-11-22 22:40:09 - GraphTrainer - INFO -   ndcg@10: 0.025975
2025-11-22 22:40:09 - GraphTrainer - INFO -   map@10: 0.018467
2025-11-22 22:40:09 - GraphTrainer - INFO -   mrr@10: 0.019285
2025-11-22 22:40:09 - GraphTrainer - INFO -   precision@20: 0.004155
2025-11-22 22:40:09 - GraphTrainer - INFO -   recall@20: 0.078843
2025-11-22 22:40:09 - GraphTrainer - INFO -   hit_rate@20: 0.082643
2025-11-22 22:40:09 - GraphTrainer - INFO -   ndcg@20: 0.033318
2025-11-22 22:40:09 - GraphTrainer - INFO -   map@20: 0.020414
2025-11-22 22:40:09 - GraphTrainer - INFO -   mrr@20: 0.021329
2025-11-22 22:40:09 - GraphTrainer - INFO - 第 152 轮训练完成
2025-11-22 22:40:09 - GraphTrainer - INFO - train_loss: 0.335665
2025-11-22 22:40:09 - GraphTrainer - INFO - precision@5: 0.006614
2025-11-22 22:40:09 - GraphTrainer - INFO - recall@5: 0.031504
2025-11-22 22:40:09 - GraphTrainer - INFO - hit_rate@5: 0.032965
2025-11-22 22:40:09 - GraphTrainer - INFO - ndcg@5: 0.020085
2025-11-22 22:40:09 - GraphTrainer - INFO - map@5: 0.016106
2025-11-22 22:40:09 - GraphTrainer - INFO - mrr@5: 0.016800
2025-11-22 22:40:09 - GraphTrainer - INFO - precision@10: 0.005230
2025-11-22 22:40:09 - GraphTrainer - INFO - recall@10: 0.049774
2025-11-22 22:40:09 - GraphTrainer - INFO - hit_rate@10: 0.052147
2025-11-22 22:40:09 - GraphTrainer - INFO - ndcg@10: 0.025975
2025-11-22 22:40:09 - GraphTrainer - INFO - map@10: 0.018467
2025-11-22 22:40:09 - GraphTrainer - INFO - mrr@10: 0.019285
2025-11-22 22:40:09 - GraphTrainer - INFO - precision@20: 0.004155
2025-11-22 22:40:09 - GraphTrainer - INFO - recall@20: 0.078843
2025-11-22 22:40:09 - GraphTrainer - INFO - hit_rate@20: 0.082643
2025-11-22 22:40:09 - GraphTrainer - INFO - ndcg@20: 0.033318
2025-11-22 22:40:09 - GraphTrainer - INFO - map@20: 0.020414
2025-11-22 22:40:09 - GraphTrainer - INFO - mrr@20: 0.021329
2025-11-22 22:40:09 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:40:09 - GraphTrainer - INFO - ============================================================
2025-11-22 22:40:09 - GraphTrainer - INFO - 开始第 153/1000 轮训练
2025-11-22 22:40:09 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3218, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3718, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3249, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3466, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3299, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3279, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3435, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3246, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3214, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3230, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3303, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3215, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3056, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3174, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3560, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3110, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3182, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3223, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3185, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3492, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3331, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3625, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3543, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3282, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3179, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
The 152 training average loss: 0.3356651021488782
2025-11-22 22:40:20 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:40:20 - GraphTrainer - INFO -   precision@5: 0.006418
2025-11-22 22:40:20 - GraphTrainer - INFO -   recall@5: 0.030583
2025-11-22 22:40:20 - GraphTrainer - INFO -   hit_rate@5: 0.032039
2025-11-22 22:40:20 - GraphTrainer - INFO -   ndcg@5: 0.019869
2025-11-22 22:40:20 - GraphTrainer - INFO -   map@5: 0.016124
2025-11-22 22:40:20 - GraphTrainer - INFO -   mrr@5: 0.016824
2025-11-22 22:40:20 - GraphTrainer - INFO -   precision@10: 0.005132
2025-11-22 22:40:20 - GraphTrainer - INFO -   recall@10: 0.048568
2025-11-22 22:40:20 - GraphTrainer - INFO -   hit_rate@10: 0.051170
2025-11-22 22:40:20 - GraphTrainer - INFO -   ndcg@10: 0.025676
2025-11-22 22:40:20 - GraphTrainer - INFO -   map@10: 0.018443
2025-11-22 22:40:20 - GraphTrainer - INFO -   mrr@10: 0.019286
2025-11-22 22:40:20 - GraphTrainer - INFO -   precision@20: 0.004078
2025-11-22 22:40:20 - GraphTrainer - INFO -   recall@20: 0.076988
2025-11-22 22:40:20 - GraphTrainer - INFO -   hit_rate@20: 0.081049
2025-11-22 22:40:20 - GraphTrainer - INFO -   ndcg@20: 0.032887
2025-11-22 22:40:20 - GraphTrainer - INFO -   map@20: 0.020369
2025-11-22 22:40:20 - GraphTrainer - INFO -   mrr@20: 0.021305
2025-11-22 22:40:20 - GraphTrainer - INFO - 第 153 轮训练完成
2025-11-22 22:40:20 - GraphTrainer - INFO - train_loss: 0.333954
2025-11-22 22:40:20 - GraphTrainer - INFO - precision@5: 0.006418
2025-11-22 22:40:20 - GraphTrainer - INFO - recall@5: 0.030583
2025-11-22 22:40:20 - GraphTrainer - INFO - hit_rate@5: 0.032039
2025-11-22 22:40:20 - GraphTrainer - INFO - ndcg@5: 0.019869
2025-11-22 22:40:20 - GraphTrainer - INFO - map@5: 0.016124
2025-11-22 22:40:20 - GraphTrainer - INFO - mrr@5: 0.016824
2025-11-22 22:40:20 - GraphTrainer - INFO - precision@10: 0.005132
2025-11-22 22:40:20 - GraphTrainer - INFO - recall@10: 0.048568
2025-11-22 22:40:20 - GraphTrainer - INFO - hit_rate@10: 0.051170
2025-11-22 22:40:20 - GraphTrainer - INFO - ndcg@10: 0.025676
2025-11-22 22:40:20 - GraphTrainer - INFO - map@10: 0.018443
2025-11-22 22:40:20 - GraphTrainer - INFO - mrr@10: 0.019286
2025-11-22 22:40:20 - GraphTrainer - INFO - precision@20: 0.004078
2025-11-22 22:40:20 - GraphTrainer - INFO - recall@20: 0.076988
2025-11-22 22:40:20 - GraphTrainer - INFO - hit_rate@20: 0.081049
2025-11-22 22:40:20 - GraphTrainer - INFO - ndcg@20: 0.032887
2025-11-22 22:40:20 - GraphTrainer - INFO - map@20: 0.020369
2025-11-22 22:40:20 - GraphTrainer - INFO - mrr@20: 0.021305
2025-11-22 22:40:20 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:40:20 - GraphTrainer - INFO - ============================================================
2025-11-22 22:40:20 - GraphTrainer - INFO - 开始第 154/1000 轮训练
2025-11-22 22:40:20 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3187, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3145, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3232, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3235, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3198, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3193, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3434, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3284, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3313, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3327, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3462, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3293, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3122, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3215, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3222, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3276, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3123, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3630, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3421, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3123, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3222, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3480, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3748, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3164, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3580, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3064, device='cuda:0', grad_fn=<AddBackward0>)
The 153 training average loss: 0.3339537978172302
2025-11-22 22:40:31 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:40:31 - GraphTrainer - INFO -   precision@5: 0.006418
2025-11-22 22:40:31 - GraphTrainer - INFO -   recall@5: 0.030500
2025-11-22 22:40:31 - GraphTrainer - INFO -   hit_rate@5: 0.032039
2025-11-22 22:40:31 - GraphTrainer - INFO -   ndcg@5: 0.020276
2025-11-22 22:40:31 - GraphTrainer - INFO -   map@5: 0.016664
2025-11-22 22:40:31 - GraphTrainer - INFO -   mrr@5: 0.017414
2025-11-22 22:40:31 - GraphTrainer - INFO -   precision@10: 0.005246
2025-11-22 22:40:31 - GraphTrainer - INFO -   recall@10: 0.049772
2025-11-22 22:40:31 - GraphTrainer - INFO -   hit_rate@10: 0.052353
2025-11-22 22:40:31 - GraphTrainer - INFO -   ndcg@10: 0.026461
2025-11-22 22:40:31 - GraphTrainer - INFO -   map@10: 0.019126
2025-11-22 22:40:31 - GraphTrainer - INFO -   mrr@10: 0.020009
2025-11-22 22:40:31 - GraphTrainer - INFO -   precision@20: 0.004112
2025-11-22 22:40:31 - GraphTrainer - INFO -   recall@20: 0.077920
2025-11-22 22:40:31 - GraphTrainer - INFO -   hit_rate@20: 0.081821
2025-11-22 22:40:31 - GraphTrainer - INFO -   ndcg@20: 0.033609
2025-11-22 22:40:31 - GraphTrainer - INFO -   map@20: 0.021041
2025-11-22 22:40:31 - GraphTrainer - INFO -   mrr@20: 0.022012
2025-11-22 22:40:31 - GraphTrainer - INFO - 第 154 轮训练完成
2025-11-22 22:40:31 - GraphTrainer - INFO - train_loss: 0.337229
2025-11-22 22:40:31 - GraphTrainer - INFO - precision@5: 0.006418
2025-11-22 22:40:31 - GraphTrainer - INFO - recall@5: 0.030500
2025-11-22 22:40:31 - GraphTrainer - INFO - hit_rate@5: 0.032039
2025-11-22 22:40:31 - GraphTrainer - INFO - ndcg@5: 0.020276
2025-11-22 22:40:31 - GraphTrainer - INFO - map@5: 0.016664
2025-11-22 22:40:31 - GraphTrainer - INFO - mrr@5: 0.017414
2025-11-22 22:40:31 - GraphTrainer - INFO - precision@10: 0.005246
2025-11-22 22:40:31 - GraphTrainer - INFO - recall@10: 0.049772
2025-11-22 22:40:31 - GraphTrainer - INFO - hit_rate@10: 0.052353
2025-11-22 22:40:31 - GraphTrainer - INFO - ndcg@10: 0.026461
2025-11-22 22:40:31 - GraphTrainer - INFO - map@10: 0.019126
2025-11-22 22:40:31 - GraphTrainer - INFO - mrr@10: 0.020009
2025-11-22 22:40:31 - GraphTrainer - INFO - precision@20: 0.004112
2025-11-22 22:40:31 - GraphTrainer - INFO - recall@20: 0.077920
2025-11-22 22:40:31 - GraphTrainer - INFO - hit_rate@20: 0.081821
2025-11-22 22:40:31 - GraphTrainer - INFO - ndcg@20: 0.033609
2025-11-22 22:40:31 - GraphTrainer - INFO - map@20: 0.021041
2025-11-22 22:40:31 - GraphTrainer - INFO - mrr@20: 0.022012
2025-11-22 22:40:31 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:40:31 - GraphTrainer - INFO - ============================================================
2025-11-22 22:40:31 - GraphTrainer - INFO - 开始第 155/1000 轮训练
2025-11-22 22:40:31 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3112, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3184, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3135, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3510, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3421, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3274, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3590, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3695, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3558, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3212, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3409, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3565, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3290, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3155, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3480, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3226, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3239, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3092, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3309, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3529, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3203, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3241, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3268, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3279, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3550, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3194, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
The 154 training average loss: 0.33722897747467306
2025-11-22 22:40:43 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:40:43 - GraphTrainer - INFO -   precision@5: 0.006470
2025-11-22 22:40:43 - GraphTrainer - INFO -   recall@5: 0.030786
2025-11-22 22:40:43 - GraphTrainer - INFO -   hit_rate@5: 0.032296
2025-11-22 22:40:43 - GraphTrainer - INFO -   ndcg@5: 0.020544
2025-11-22 22:40:43 - GraphTrainer - INFO -   map@5: 0.016938
2025-11-22 22:40:43 - GraphTrainer - INFO -   mrr@5: 0.017634
2025-11-22 22:40:43 - GraphTrainer - INFO -   precision@10: 0.005220
2025-11-22 22:40:43 - GraphTrainer - INFO -   recall@10: 0.049424
2025-11-22 22:40:43 - GraphTrainer - INFO -   hit_rate@10: 0.051993
2025-11-22 22:40:43 - GraphTrainer - INFO -   ndcg@10: 0.026601
2025-11-22 22:40:43 - GraphTrainer - INFO -   map@10: 0.019386
2025-11-22 22:40:43 - GraphTrainer - INFO -   mrr@10: 0.020221
2025-11-22 22:40:43 - GraphTrainer - INFO -   precision@20: 0.004119
2025-11-22 22:40:43 - GraphTrainer - INFO -   recall@20: 0.077956
2025-11-22 22:40:43 - GraphTrainer - INFO -   hit_rate@20: 0.082026
2025-11-22 22:40:43 - GraphTrainer - INFO -   ndcg@20: 0.033839
2025-11-22 22:40:43 - GraphTrainer - INFO -   map@20: 0.021320
2025-11-22 22:40:43 - GraphTrainer - INFO -   mrr@20: 0.022256
2025-11-22 22:40:43 - GraphTrainer - INFO - 第 155 轮训练完成
2025-11-22 22:40:43 - GraphTrainer - INFO - train_loss: 0.336231
2025-11-22 22:40:43 - GraphTrainer - INFO - precision@5: 0.006470
2025-11-22 22:40:43 - GraphTrainer - INFO - recall@5: 0.030786
2025-11-22 22:40:43 - GraphTrainer - INFO - hit_rate@5: 0.032296
2025-11-22 22:40:43 - GraphTrainer - INFO - ndcg@5: 0.020544
2025-11-22 22:40:43 - GraphTrainer - INFO - map@5: 0.016938
2025-11-22 22:40:43 - GraphTrainer - INFO - mrr@5: 0.017634
2025-11-22 22:40:43 - GraphTrainer - INFO - precision@10: 0.005220
2025-11-22 22:40:43 - GraphTrainer - INFO - recall@10: 0.049424
2025-11-22 22:40:43 - GraphTrainer - INFO - hit_rate@10: 0.051993
2025-11-22 22:40:43 - GraphTrainer - INFO - ndcg@10: 0.026601
2025-11-22 22:40:43 - GraphTrainer - INFO - map@10: 0.019386
2025-11-22 22:40:43 - GraphTrainer - INFO - mrr@10: 0.020221
2025-11-22 22:40:43 - GraphTrainer - INFO - precision@20: 0.004119
2025-11-22 22:40:43 - GraphTrainer - INFO - recall@20: 0.077956
2025-11-22 22:40:43 - GraphTrainer - INFO - hit_rate@20: 0.082026
2025-11-22 22:40:43 - GraphTrainer - INFO - ndcg@20: 0.033839
2025-11-22 22:40:43 - GraphTrainer - INFO - map@20: 0.021320
2025-11-22 22:40:43 - GraphTrainer - INFO - mrr@20: 0.022256
2025-11-22 22:40:43 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:40:43 - GraphTrainer - INFO - ============================================================
2025-11-22 22:40:43 - GraphTrainer - INFO - 开始第 156/1000 轮训练
2025-11-22 22:40:43 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3641, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3055, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3579, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3379, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3183, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3434, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3302, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3203, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3373, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3543, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3198, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3303, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3262, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3296, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3130, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3204, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3189, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3333, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3197, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2986, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3793, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3537, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
The 155 training average loss: 0.336230652085666
2025-11-22 22:40:54 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:40:54 - GraphTrainer - INFO -   precision@5: 0.006562
2025-11-22 22:40:54 - GraphTrainer - INFO -   recall@5: 0.031246
2025-11-22 22:40:54 - GraphTrainer - INFO -   hit_rate@5: 0.032759
2025-11-22 22:40:54 - GraphTrainer - INFO -   ndcg@5: 0.020674
2025-11-22 22:40:54 - GraphTrainer - INFO -   map@5: 0.016951
2025-11-22 22:40:54 - GraphTrainer - INFO -   mrr@5: 0.017674
2025-11-22 22:40:54 - GraphTrainer - INFO -   precision@10: 0.005256
2025-11-22 22:40:54 - GraphTrainer - INFO -   recall@10: 0.049848
2025-11-22 22:40:54 - GraphTrainer - INFO -   hit_rate@10: 0.052353
2025-11-22 22:40:54 - GraphTrainer - INFO -   ndcg@10: 0.026687
2025-11-22 22:40:54 - GraphTrainer - INFO -   map@10: 0.019368
2025-11-22 22:40:54 - GraphTrainer - INFO -   mrr@10: 0.020216
2025-11-22 22:40:54 - GraphTrainer - INFO -   precision@20: 0.004124
2025-11-22 22:40:54 - GraphTrainer - INFO -   recall@20: 0.078089
2025-11-22 22:40:54 - GraphTrainer - INFO -   hit_rate@20: 0.081975
2025-11-22 22:40:54 - GraphTrainer - INFO -   ndcg@20: 0.033854
2025-11-22 22:40:54 - GraphTrainer - INFO -   map@20: 0.021286
2025-11-22 22:40:54 - GraphTrainer - INFO -   mrr@20: 0.022222
2025-11-22 22:40:54 - GraphTrainer - INFO - 第 156 轮训练完成
2025-11-22 22:40:54 - GraphTrainer - INFO - train_loss: 0.338616
2025-11-22 22:40:54 - GraphTrainer - INFO - precision@5: 0.006562
2025-11-22 22:40:54 - GraphTrainer - INFO - recall@5: 0.031246
2025-11-22 22:40:54 - GraphTrainer - INFO - hit_rate@5: 0.032759
2025-11-22 22:40:54 - GraphTrainer - INFO - ndcg@5: 0.020674
2025-11-22 22:40:54 - GraphTrainer - INFO - map@5: 0.016951
2025-11-22 22:40:54 - GraphTrainer - INFO - mrr@5: 0.017674
2025-11-22 22:40:54 - GraphTrainer - INFO - precision@10: 0.005256
2025-11-22 22:40:54 - GraphTrainer - INFO - recall@10: 0.049848
2025-11-22 22:40:54 - GraphTrainer - INFO - hit_rate@10: 0.052353
2025-11-22 22:40:54 - GraphTrainer - INFO - ndcg@10: 0.026687
2025-11-22 22:40:54 - GraphTrainer - INFO - map@10: 0.019368
2025-11-22 22:40:54 - GraphTrainer - INFO - mrr@10: 0.020216
2025-11-22 22:40:54 - GraphTrainer - INFO - precision@20: 0.004124
2025-11-22 22:40:54 - GraphTrainer - INFO - recall@20: 0.078089
2025-11-22 22:40:54 - GraphTrainer - INFO - hit_rate@20: 0.081975
2025-11-22 22:40:54 - GraphTrainer - INFO - ndcg@20: 0.033854
2025-11-22 22:40:54 - GraphTrainer - INFO - map@20: 0.021286
2025-11-22 22:40:54 - GraphTrainer - INFO - mrr@20: 0.022222
2025-11-22 22:40:54 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:40:54 - GraphTrainer - INFO - ============================================================
2025-11-22 22:40:54 - GraphTrainer - INFO - 开始第 157/1000 轮训练
2025-11-22 22:40:54 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3225, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3611, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3293, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3677, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3611, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3177, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3221, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3543, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3506, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3555, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3262, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3473, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3274, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3135, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3636, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3241, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3244, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3206, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3272, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3167, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3204, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3531, device='cuda:0', grad_fn=<AddBackward0>)
The 156 training average loss: 0.33861558704540645
2025-11-22 22:41:05 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:41:05 - GraphTrainer - INFO -   precision@5: 0.006655
2025-11-22 22:41:05 - GraphTrainer - INFO -   recall@5: 0.031837
2025-11-22 22:41:05 - GraphTrainer - INFO -   hit_rate@5: 0.033222
2025-11-22 22:41:05 - GraphTrainer - INFO -   ndcg@5: 0.021036
2025-11-22 22:41:05 - GraphTrainer - INFO -   map@5: 0.017243
2025-11-22 22:41:05 - GraphTrainer - INFO -   mrr@5: 0.017945
2025-11-22 22:41:05 - GraphTrainer - INFO -   precision@10: 0.005246
2025-11-22 22:41:05 - GraphTrainer - INFO -   recall@10: 0.049882
2025-11-22 22:41:05 - GraphTrainer - INFO -   hit_rate@10: 0.052301
2025-11-22 22:41:05 - GraphTrainer - INFO -   ndcg@10: 0.026874
2025-11-22 22:41:05 - GraphTrainer - INFO -   map@10: 0.019588
2025-11-22 22:41:05 - GraphTrainer - INFO -   mrr@10: 0.020426
2025-11-22 22:41:05 - GraphTrainer - INFO -   precision@20: 0.004207
2025-11-22 22:41:05 - GraphTrainer - INFO -   recall@20: 0.079652
2025-11-22 22:41:05 - GraphTrainer - INFO -   hit_rate@20: 0.083723
2025-11-22 22:41:05 - GraphTrainer - INFO -   ndcg@20: 0.034403
2025-11-22 22:41:05 - GraphTrainer - INFO -   map@20: 0.021581
2025-11-22 22:41:05 - GraphTrainer - INFO -   mrr@20: 0.022527
2025-11-22 22:41:05 - GraphTrainer - INFO - 第 157 轮训练完成
2025-11-22 22:41:05 - GraphTrainer - INFO - train_loss: 0.333183
2025-11-22 22:41:05 - GraphTrainer - INFO - precision@5: 0.006655
2025-11-22 22:41:05 - GraphTrainer - INFO - recall@5: 0.031837
2025-11-22 22:41:05 - GraphTrainer - INFO - hit_rate@5: 0.033222
2025-11-22 22:41:05 - GraphTrainer - INFO - ndcg@5: 0.021036
2025-11-22 22:41:05 - GraphTrainer - INFO - map@5: 0.017243
2025-11-22 22:41:05 - GraphTrainer - INFO - mrr@5: 0.017945
2025-11-22 22:41:05 - GraphTrainer - INFO - precision@10: 0.005246
2025-11-22 22:41:05 - GraphTrainer - INFO - recall@10: 0.049882
2025-11-22 22:41:05 - GraphTrainer - INFO - hit_rate@10: 0.052301
2025-11-22 22:41:05 - GraphTrainer - INFO - ndcg@10: 0.026874
2025-11-22 22:41:05 - GraphTrainer - INFO - map@10: 0.019588
2025-11-22 22:41:05 - GraphTrainer - INFO - mrr@10: 0.020426
2025-11-22 22:41:05 - GraphTrainer - INFO - precision@20: 0.004207
2025-11-22 22:41:05 - GraphTrainer - INFO - recall@20: 0.079652
2025-11-22 22:41:05 - GraphTrainer - INFO - hit_rate@20: 0.083723
2025-11-22 22:41:05 - GraphTrainer - INFO - ndcg@20: 0.034403
2025-11-22 22:41:05 - GraphTrainer - INFO - map@20: 0.021581
2025-11-22 22:41:05 - GraphTrainer - INFO - mrr@20: 0.022527
2025-11-22 22:41:05 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:41:05 - GraphTrainer - INFO - ============================================================
2025-11-22 22:41:05 - GraphTrainer - INFO - 开始第 158/1000 轮训练
2025-11-22 22:41:05 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3049, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3185, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3054, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3288, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3232, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3110, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3509, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3047, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3543, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3197, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3306, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3167, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3457, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3189, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3221, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3273, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3152, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3256, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3234, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3180, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3194, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3306, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3268, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3632, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3140, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
The 157 training average loss: 0.3331834329613324
2025-11-22 22:41:17 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:41:17 - GraphTrainer - INFO -   precision@5: 0.006562
2025-11-22 22:41:17 - GraphTrainer - INFO -   recall@5: 0.031488
2025-11-22 22:41:17 - GraphTrainer - INFO -   hit_rate@5: 0.032810
2025-11-22 22:41:17 - GraphTrainer - INFO -   ndcg@5: 0.020631
2025-11-22 22:41:17 - GraphTrainer - INFO -   map@5: 0.016856
2025-11-22 22:41:17 - GraphTrainer - INFO -   mrr@5: 0.017454
2025-11-22 22:41:17 - GraphTrainer - INFO -   precision@10: 0.005184
2025-11-22 22:41:17 - GraphTrainer - INFO -   recall@10: 0.049232
2025-11-22 22:41:17 - GraphTrainer - INFO -   hit_rate@10: 0.051684
2025-11-22 22:41:17 - GraphTrainer - INFO -   ndcg@10: 0.026368
2025-11-22 22:41:17 - GraphTrainer - INFO -   map@10: 0.019148
2025-11-22 22:41:17 - GraphTrainer - INFO -   mrr@10: 0.019886
2025-11-22 22:41:17 - GraphTrainer - INFO -   precision@20: 0.004158
2025-11-22 22:41:17 - GraphTrainer - INFO -   recall@20: 0.078654
2025-11-22 22:41:17 - GraphTrainer - INFO -   hit_rate@20: 0.082540
2025-11-22 22:41:17 - GraphTrainer - INFO -   ndcg@20: 0.033838
2025-11-22 22:41:17 - GraphTrainer - INFO -   map@20: 0.021147
2025-11-22 22:41:17 - GraphTrainer - INFO -   mrr@20: 0.021973
2025-11-22 22:41:17 - GraphTrainer - INFO - 第 158 轮训练完成
2025-11-22 22:41:17 - GraphTrainer - INFO - train_loss: 0.336489
2025-11-22 22:41:17 - GraphTrainer - INFO - precision@5: 0.006562
2025-11-22 22:41:17 - GraphTrainer - INFO - recall@5: 0.031488
2025-11-22 22:41:17 - GraphTrainer - INFO - hit_rate@5: 0.032810
2025-11-22 22:41:17 - GraphTrainer - INFO - ndcg@5: 0.020631
2025-11-22 22:41:17 - GraphTrainer - INFO - map@5: 0.016856
2025-11-22 22:41:17 - GraphTrainer - INFO - mrr@5: 0.017454
2025-11-22 22:41:17 - GraphTrainer - INFO - precision@10: 0.005184
2025-11-22 22:41:17 - GraphTrainer - INFO - recall@10: 0.049232
2025-11-22 22:41:17 - GraphTrainer - INFO - hit_rate@10: 0.051684
2025-11-22 22:41:17 - GraphTrainer - INFO - ndcg@10: 0.026368
2025-11-22 22:41:17 - GraphTrainer - INFO - map@10: 0.019148
2025-11-22 22:41:17 - GraphTrainer - INFO - mrr@10: 0.019886
2025-11-22 22:41:17 - GraphTrainer - INFO - precision@20: 0.004158
2025-11-22 22:41:17 - GraphTrainer - INFO - recall@20: 0.078654
2025-11-22 22:41:17 - GraphTrainer - INFO - hit_rate@20: 0.082540
2025-11-22 22:41:17 - GraphTrainer - INFO - ndcg@20: 0.033838
2025-11-22 22:41:17 - GraphTrainer - INFO - map@20: 0.021147
2025-11-22 22:41:17 - GraphTrainer - INFO - mrr@20: 0.021973
2025-11-22 22:41:17 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:41:17 - GraphTrainer - INFO - ============================================================
2025-11-22 22:41:17 - GraphTrainer - INFO - 开始第 159/1000 轮训练
2025-11-22 22:41:17 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3473, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3232, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3262, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3170, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3221, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3554, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3285, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3718, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3240, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3233, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3529, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3376, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3502, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3278, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3237, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3099, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3214, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3184, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3455, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3548, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3187, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3658, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3211, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3256, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3055, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3299, device='cuda:0', grad_fn=<AddBackward0>)
The 158 training average loss: 0.33648873454537886
2025-11-22 22:41:28 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:41:28 - GraphTrainer - INFO -   precision@5: 0.006603
2025-11-22 22:41:28 - GraphTrainer - INFO -   recall@5: 0.031346
2025-11-22 22:41:28 - GraphTrainer - INFO -   hit_rate@5: 0.032965
2025-11-22 22:41:28 - GraphTrainer - INFO -   ndcg@5: 0.020349
2025-11-22 22:41:28 - GraphTrainer - INFO -   map@5: 0.016484
2025-11-22 22:41:28 - GraphTrainer - INFO -   mrr@5: 0.017208
2025-11-22 22:41:28 - GraphTrainer - INFO -   precision@10: 0.005230
2025-11-22 22:41:28 - GraphTrainer - INFO -   recall@10: 0.049583
2025-11-22 22:41:28 - GraphTrainer - INFO -   hit_rate@10: 0.052147
2025-11-22 22:41:28 - GraphTrainer - INFO -   ndcg@10: 0.026283
2025-11-22 22:41:28 - GraphTrainer - INFO -   map@10: 0.018895
2025-11-22 22:41:28 - GraphTrainer - INFO -   mrr@10: 0.019736
2025-11-22 22:41:28 - GraphTrainer - INFO -   precision@20: 0.004119
2025-11-22 22:41:28 - GraphTrainer - INFO -   recall@20: 0.078016
2025-11-22 22:41:28 - GraphTrainer - INFO -   hit_rate@20: 0.081975
2025-11-22 22:41:28 - GraphTrainer - INFO -   ndcg@20: 0.033432
2025-11-22 22:41:28 - GraphTrainer - INFO -   map@20: 0.020773
2025-11-22 22:41:28 - GraphTrainer - INFO -   mrr@20: 0.021700
2025-11-22 22:41:28 - GraphTrainer - INFO - 第 159 轮训练完成
2025-11-22 22:41:28 - GraphTrainer - INFO - train_loss: 0.335035
2025-11-22 22:41:28 - GraphTrainer - INFO - precision@5: 0.006603
2025-11-22 22:41:28 - GraphTrainer - INFO - recall@5: 0.031346
2025-11-22 22:41:28 - GraphTrainer - INFO - hit_rate@5: 0.032965
2025-11-22 22:41:28 - GraphTrainer - INFO - ndcg@5: 0.020349
2025-11-22 22:41:28 - GraphTrainer - INFO - map@5: 0.016484
2025-11-22 22:41:28 - GraphTrainer - INFO - mrr@5: 0.017208
2025-11-22 22:41:28 - GraphTrainer - INFO - precision@10: 0.005230
2025-11-22 22:41:28 - GraphTrainer - INFO - recall@10: 0.049583
2025-11-22 22:41:28 - GraphTrainer - INFO - hit_rate@10: 0.052147
2025-11-22 22:41:28 - GraphTrainer - INFO - ndcg@10: 0.026283
2025-11-22 22:41:28 - GraphTrainer - INFO - map@10: 0.018895
2025-11-22 22:41:28 - GraphTrainer - INFO - mrr@10: 0.019736
2025-11-22 22:41:28 - GraphTrainer - INFO - precision@20: 0.004119
2025-11-22 22:41:28 - GraphTrainer - INFO - recall@20: 0.078016
2025-11-22 22:41:28 - GraphTrainer - INFO - hit_rate@20: 0.081975
2025-11-22 22:41:28 - GraphTrainer - INFO - ndcg@20: 0.033432
2025-11-22 22:41:28 - GraphTrainer - INFO - map@20: 0.020773
2025-11-22 22:41:28 - GraphTrainer - INFO - mrr@20: 0.021700
2025-11-22 22:41:28 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:41:28 - GraphTrainer - INFO - ============================================================
2025-11-22 22:41:28 - GraphTrainer - INFO - 开始第 160/1000 轮训练
2025-11-22 22:41:28 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3517, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3020, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3125, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3176, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3379, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3139, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3695, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3096, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3544, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3024, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3467, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3168, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3276, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3258, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3208, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3296, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3244, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3288, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3592, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3333, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3168, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3479, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3626, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3216, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3213, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3462, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3191, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3588, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3076, device='cuda:0', grad_fn=<AddBackward0>)
The 159 training average loss: 0.33503495670598127
2025-11-22 22:41:39 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:41:39 - GraphTrainer - INFO -   precision@5: 0.006799
2025-11-22 22:41:39 - GraphTrainer - INFO -   recall@5: 0.032463
2025-11-22 22:41:39 - GraphTrainer - INFO -   hit_rate@5: 0.033942
2025-11-22 22:41:39 - GraphTrainer - INFO -   ndcg@5: 0.021148
2025-11-22 22:41:39 - GraphTrainer - INFO -   map@5: 0.017200
2025-11-22 22:41:39 - GraphTrainer - INFO -   mrr@5: 0.017885
2025-11-22 22:41:39 - GraphTrainer - INFO -   precision@10: 0.005266
2025-11-22 22:41:39 - GraphTrainer - INFO -   recall@10: 0.049872
2025-11-22 22:41:39 - GraphTrainer - INFO -   hit_rate@10: 0.052507
2025-11-22 22:41:39 - GraphTrainer - INFO -   ndcg@10: 0.026764
2025-11-22 22:41:39 - GraphTrainer - INFO -   map@10: 0.019435
2025-11-22 22:41:39 - GraphTrainer - INFO -   mrr@10: 0.020265
2025-11-22 22:41:39 - GraphTrainer - INFO -   precision@20: 0.004155
2025-11-22 22:41:39 - GraphTrainer - INFO -   recall@20: 0.078751
2025-11-22 22:41:39 - GraphTrainer - INFO -   hit_rate@20: 0.082695
2025-11-22 22:41:39 - GraphTrainer - INFO -   ndcg@20: 0.034061
2025-11-22 22:41:39 - GraphTrainer - INFO -   map@20: 0.021377
2025-11-22 22:41:39 - GraphTrainer - INFO -   mrr@20: 0.022289
2025-11-22 22:41:39 - GraphTrainer - INFO - 第 160 轮训练完成
2025-11-22 22:41:39 - GraphTrainer - INFO - train_loss: 0.337028
2025-11-22 22:41:39 - GraphTrainer - INFO - precision@5: 0.006799
2025-11-22 22:41:39 - GraphTrainer - INFO - recall@5: 0.032463
2025-11-22 22:41:39 - GraphTrainer - INFO - hit_rate@5: 0.033942
2025-11-22 22:41:39 - GraphTrainer - INFO - ndcg@5: 0.021148
2025-11-22 22:41:39 - GraphTrainer - INFO - map@5: 0.017200
2025-11-22 22:41:39 - GraphTrainer - INFO - mrr@5: 0.017885
2025-11-22 22:41:39 - GraphTrainer - INFO - precision@10: 0.005266
2025-11-22 22:41:39 - GraphTrainer - INFO - recall@10: 0.049872
2025-11-22 22:41:39 - GraphTrainer - INFO - hit_rate@10: 0.052507
2025-11-22 22:41:39 - GraphTrainer - INFO - ndcg@10: 0.026764
2025-11-22 22:41:39 - GraphTrainer - INFO - map@10: 0.019435
2025-11-22 22:41:39 - GraphTrainer - INFO - mrr@10: 0.020265
2025-11-22 22:41:39 - GraphTrainer - INFO - precision@20: 0.004155
2025-11-22 22:41:39 - GraphTrainer - INFO - recall@20: 0.078751
2025-11-22 22:41:39 - GraphTrainer - INFO - hit_rate@20: 0.082695
2025-11-22 22:41:39 - GraphTrainer - INFO - ndcg@20: 0.034061
2025-11-22 22:41:39 - GraphTrainer - INFO - map@20: 0.021377
2025-11-22 22:41:39 - GraphTrainer - INFO - mrr@20: 0.022289
2025-11-22 22:41:39 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:41:39 - GraphTrainer - INFO - 检查点已保存: Epoch 160 -> ./checkpoints/checkpoint_epoch_160.pth
2025-11-22 22:41:39 - GraphTrainer - INFO - ============================================================
2025-11-22 22:41:39 - GraphTrainer - INFO - 开始第 161/1000 轮训练
2025-11-22 22:41:39 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3502, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3207, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3457, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3261, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3464, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3196, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3434, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3256, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3525, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3246, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3217, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3464, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3605, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3150, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3188, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3466, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3434, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3101, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3647, device='cuda:0', grad_fn=<AddBackward0>)
The 160 training average loss: 0.3370277665812394
2025-11-22 22:41:50 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:41:50 - GraphTrainer - INFO -   precision@5: 0.006470
2025-11-22 22:41:50 - GraphTrainer - INFO -   recall@5: 0.030702
2025-11-22 22:41:50 - GraphTrainer - INFO -   hit_rate@5: 0.032296
2025-11-22 22:41:50 - GraphTrainer - INFO -   ndcg@5: 0.020801
2025-11-22 22:41:50 - GraphTrainer - INFO -   map@5: 0.017298
2025-11-22 22:41:50 - GraphTrainer - INFO -   mrr@5: 0.017963
2025-11-22 22:41:50 - GraphTrainer - INFO -   precision@10: 0.005251
2025-11-22 22:41:50 - GraphTrainer - INFO -   recall@10: 0.049852
2025-11-22 22:41:50 - GraphTrainer - INFO -   hit_rate@10: 0.052353
2025-11-22 22:41:50 - GraphTrainer - INFO -   ndcg@10: 0.027006
2025-11-22 22:41:50 - GraphTrainer - INFO -   map@10: 0.019807
2025-11-22 22:41:50 - GraphTrainer - INFO -   mrr@10: 0.020588
2025-11-22 22:41:50 - GraphTrainer - INFO -   precision@20: 0.004135
2025-11-22 22:41:50 - GraphTrainer - INFO -   recall@20: 0.078198
2025-11-22 22:41:50 - GraphTrainer - INFO -   hit_rate@20: 0.082232
2025-11-22 22:41:50 - GraphTrainer - INFO -   ndcg@20: 0.034202
2025-11-22 22:41:50 - GraphTrainer - INFO -   map@20: 0.021729
2025-11-22 22:41:50 - GraphTrainer - INFO -   mrr@20: 0.022608
2025-11-22 22:41:50 - GraphTrainer - INFO - 第 161 轮训练完成
2025-11-22 22:41:50 - GraphTrainer - INFO - train_loss: 0.335249
2025-11-22 22:41:50 - GraphTrainer - INFO - precision@5: 0.006470
2025-11-22 22:41:50 - GraphTrainer - INFO - recall@5: 0.030702
2025-11-22 22:41:50 - GraphTrainer - INFO - hit_rate@5: 0.032296
2025-11-22 22:41:50 - GraphTrainer - INFO - ndcg@5: 0.020801
2025-11-22 22:41:50 - GraphTrainer - INFO - map@5: 0.017298
2025-11-22 22:41:50 - GraphTrainer - INFO - mrr@5: 0.017963
2025-11-22 22:41:50 - GraphTrainer - INFO - precision@10: 0.005251
2025-11-22 22:41:50 - GraphTrainer - INFO - recall@10: 0.049852
2025-11-22 22:41:50 - GraphTrainer - INFO - hit_rate@10: 0.052353
2025-11-22 22:41:50 - GraphTrainer - INFO - ndcg@10: 0.027006
2025-11-22 22:41:50 - GraphTrainer - INFO - map@10: 0.019807
2025-11-22 22:41:50 - GraphTrainer - INFO - mrr@10: 0.020588
2025-11-22 22:41:50 - GraphTrainer - INFO - precision@20: 0.004135
2025-11-22 22:41:50 - GraphTrainer - INFO - recall@20: 0.078198
2025-11-22 22:41:50 - GraphTrainer - INFO - hit_rate@20: 0.082232
2025-11-22 22:41:50 - GraphTrainer - INFO - ndcg@20: 0.034202
2025-11-22 22:41:50 - GraphTrainer - INFO - map@20: 0.021729
2025-11-22 22:41:50 - GraphTrainer - INFO - mrr@20: 0.022608
2025-11-22 22:41:50 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:41:50 - GraphTrainer - INFO - ============================================================
2025-11-22 22:41:50 - GraphTrainer - INFO - 开始第 162/1000 轮训练
2025-11-22 22:41:50 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3652, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3187, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3467, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3533, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3640, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2987, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3296, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3146, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3274, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3576, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3467, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3190, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3121, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3234, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3209, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3209, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3172, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3531, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3263, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3152, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3647, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3316, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3202, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3249, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3302, device='cuda:0', grad_fn=<AddBackward0>)
The 161 training average loss: 0.3352487477762946
2025-11-22 22:42:01 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:42:01 - GraphTrainer - INFO -   precision@5: 0.006500
2025-11-22 22:42:01 - GraphTrainer - INFO -   recall@5: 0.030926
2025-11-22 22:42:01 - GraphTrainer - INFO -   hit_rate@5: 0.032451
2025-11-22 22:42:01 - GraphTrainer - INFO -   ndcg@5: 0.020507
2025-11-22 22:42:01 - GraphTrainer - INFO -   map@5: 0.016829
2025-11-22 22:42:01 - GraphTrainer - INFO -   mrr@5: 0.017554
2025-11-22 22:42:01 - GraphTrainer - INFO -   precision@10: 0.005199
2025-11-22 22:42:01 - GraphTrainer - INFO -   recall@10: 0.049357
2025-11-22 22:42:01 - GraphTrainer - INFO -   hit_rate@10: 0.051787
2025-11-22 22:42:01 - GraphTrainer - INFO -   ndcg@10: 0.026465
2025-11-22 22:42:01 - GraphTrainer - INFO -   map@10: 0.019225
2025-11-22 22:42:01 - GraphTrainer - INFO -   mrr@10: 0.020070
2025-11-22 22:42:01 - GraphTrainer - INFO -   precision@20: 0.004166
2025-11-22 22:42:01 - GraphTrainer - INFO -   recall@20: 0.078819
2025-11-22 22:42:01 - GraphTrainer - INFO -   hit_rate@20: 0.082849
2025-11-22 22:42:01 - GraphTrainer - INFO -   ndcg@20: 0.033929
2025-11-22 22:42:01 - GraphTrainer - INFO -   map@20: 0.021213
2025-11-22 22:42:01 - GraphTrainer - INFO -   mrr@20: 0.022157
2025-11-22 22:42:01 - GraphTrainer - INFO - 第 162 轮训练完成
2025-11-22 22:42:01 - GraphTrainer - INFO - train_loss: 0.332203
2025-11-22 22:42:01 - GraphTrainer - INFO - precision@5: 0.006500
2025-11-22 22:42:01 - GraphTrainer - INFO - recall@5: 0.030926
2025-11-22 22:42:01 - GraphTrainer - INFO - hit_rate@5: 0.032451
2025-11-22 22:42:01 - GraphTrainer - INFO - ndcg@5: 0.020507
2025-11-22 22:42:01 - GraphTrainer - INFO - map@5: 0.016829
2025-11-22 22:42:01 - GraphTrainer - INFO - mrr@5: 0.017554
2025-11-22 22:42:01 - GraphTrainer - INFO - precision@10: 0.005199
2025-11-22 22:42:01 - GraphTrainer - INFO - recall@10: 0.049357
2025-11-22 22:42:01 - GraphTrainer - INFO - hit_rate@10: 0.051787
2025-11-22 22:42:01 - GraphTrainer - INFO - ndcg@10: 0.026465
2025-11-22 22:42:01 - GraphTrainer - INFO - map@10: 0.019225
2025-11-22 22:42:01 - GraphTrainer - INFO - mrr@10: 0.020070
2025-11-22 22:42:01 - GraphTrainer - INFO - precision@20: 0.004166
2025-11-22 22:42:01 - GraphTrainer - INFO - recall@20: 0.078819
2025-11-22 22:42:01 - GraphTrainer - INFO - hit_rate@20: 0.082849
2025-11-22 22:42:01 - GraphTrainer - INFO - ndcg@20: 0.033929
2025-11-22 22:42:01 - GraphTrainer - INFO - map@20: 0.021213
2025-11-22 22:42:01 - GraphTrainer - INFO - mrr@20: 0.022157
2025-11-22 22:42:01 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:42:01 - GraphTrainer - INFO - ============================================================
2025-11-22 22:42:01 - GraphTrainer - INFO - 开始第 163/1000 轮训练
2025-11-22 22:42:01 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3645, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2952, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3227, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3176, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3101, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3316, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3379, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3182, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3163, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3199, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3302, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3304, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3290, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3222, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3333, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3433, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3260, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3190, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3194, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3715, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3284, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3165, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3077, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3649, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3297, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3136, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3020, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3099, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3142, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3462, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
The 162 training average loss: 0.3322025044211026
2025-11-22 22:42:12 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:42:12 - GraphTrainer - INFO -   precision@5: 0.006326
2025-11-22 22:42:12 - GraphTrainer - INFO -   recall@5: 0.030113
2025-11-22 22:42:12 - GraphTrainer - INFO -   hit_rate@5: 0.031576
2025-11-22 22:42:12 - GraphTrainer - INFO -   ndcg@5: 0.020009
2025-11-22 22:42:12 - GraphTrainer - INFO -   map@5: 0.016437
2025-11-22 22:42:12 - GraphTrainer - INFO -   mrr@5: 0.017125
2025-11-22 22:42:12 - GraphTrainer - INFO -   precision@10: 0.005266
2025-11-22 22:42:12 - GraphTrainer - INFO -   recall@10: 0.049789
2025-11-22 22:42:12 - GraphTrainer - INFO -   hit_rate@10: 0.052456
2025-11-22 22:42:12 - GraphTrainer - INFO -   ndcg@10: 0.026414
2025-11-22 22:42:12 - GraphTrainer - INFO -   map@10: 0.019026
2025-11-22 22:42:12 - GraphTrainer - INFO -   mrr@10: 0.019876
2025-11-22 22:42:12 - GraphTrainer - INFO -   precision@20: 0.004083
2025-11-22 22:42:12 - GraphTrainer - INFO -   recall@20: 0.077123
2025-11-22 22:42:12 - GraphTrainer - INFO -   hit_rate@20: 0.081203
2025-11-22 22:42:12 - GraphTrainer - INFO -   ndcg@20: 0.033340
2025-11-22 22:42:12 - GraphTrainer - INFO -   map@20: 0.020872
2025-11-22 22:42:12 - GraphTrainer - INFO -   mrr@20: 0.021812
2025-11-22 22:42:12 - GraphTrainer - INFO - 第 163 轮训练完成
2025-11-22 22:42:12 - GraphTrainer - INFO - train_loss: 0.332485
2025-11-22 22:42:12 - GraphTrainer - INFO - precision@5: 0.006326
2025-11-22 22:42:12 - GraphTrainer - INFO - recall@5: 0.030113
2025-11-22 22:42:12 - GraphTrainer - INFO - hit_rate@5: 0.031576
2025-11-22 22:42:12 - GraphTrainer - INFO - ndcg@5: 0.020009
2025-11-22 22:42:12 - GraphTrainer - INFO - map@5: 0.016437
2025-11-22 22:42:12 - GraphTrainer - INFO - mrr@5: 0.017125
2025-11-22 22:42:12 - GraphTrainer - INFO - precision@10: 0.005266
2025-11-22 22:42:12 - GraphTrainer - INFO - recall@10: 0.049789
2025-11-22 22:42:12 - GraphTrainer - INFO - hit_rate@10: 0.052456
2025-11-22 22:42:12 - GraphTrainer - INFO - ndcg@10: 0.026414
2025-11-22 22:42:12 - GraphTrainer - INFO - map@10: 0.019026
2025-11-22 22:42:12 - GraphTrainer - INFO - mrr@10: 0.019876
2025-11-22 22:42:12 - GraphTrainer - INFO - precision@20: 0.004083
2025-11-22 22:42:12 - GraphTrainer - INFO - recall@20: 0.077123
2025-11-22 22:42:12 - GraphTrainer - INFO - hit_rate@20: 0.081203
2025-11-22 22:42:12 - GraphTrainer - INFO - ndcg@20: 0.033340
2025-11-22 22:42:12 - GraphTrainer - INFO - map@20: 0.020872
2025-11-22 22:42:12 - GraphTrainer - INFO - mrr@20: 0.021812
2025-11-22 22:42:12 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:42:12 - GraphTrainer - INFO - ============================================================
2025-11-22 22:42:12 - GraphTrainer - INFO - 开始第 164/1000 轮训练
2025-11-22 22:42:12 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3612, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3273, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3457, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3249, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3133, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3241, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3282, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3149, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3225, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3103, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3102, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3261, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3572, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3228, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3165, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3161, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3246, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3628, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3207, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3046, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3521, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3245, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3226, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3132, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3182, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3164, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3494, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3654, device='cuda:0', grad_fn=<AddBackward0>)
The 163 training average loss: 0.3324850869589838
2025-11-22 22:42:23 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:42:23 - GraphTrainer - INFO -   precision@5: 0.006655
2025-11-22 22:42:23 - GraphTrainer - INFO -   recall@5: 0.031809
2025-11-22 22:42:23 - GraphTrainer - INFO -   hit_rate@5: 0.033222
2025-11-22 22:42:23 - GraphTrainer - INFO -   ndcg@5: 0.020740
2025-11-22 22:42:23 - GraphTrainer - INFO -   map@5: 0.016860
2025-11-22 22:42:23 - GraphTrainer - INFO -   mrr@5: 0.017579
2025-11-22 22:42:23 - GraphTrainer - INFO -   precision@10: 0.005225
2025-11-22 22:42:23 - GraphTrainer - INFO -   recall@10: 0.049541
2025-11-22 22:42:23 - GraphTrainer - INFO -   hit_rate@10: 0.052147
2025-11-22 22:42:23 - GraphTrainer - INFO -   ndcg@10: 0.026485
2025-11-22 22:42:23 - GraphTrainer - INFO -   map@10: 0.019164
2025-11-22 22:42:23 - GraphTrainer - INFO -   mrr@10: 0.020040
2025-11-22 22:42:23 - GraphTrainer - INFO -   precision@20: 0.004168
2025-11-22 22:42:23 - GraphTrainer - INFO -   recall@20: 0.078830
2025-11-22 22:42:23 - GraphTrainer - INFO -   hit_rate@20: 0.083003
2025-11-22 22:42:23 - GraphTrainer - INFO -   ndcg@20: 0.033954
2025-11-22 22:42:23 - GraphTrainer - INFO -   map@20: 0.021177
2025-11-22 22:42:23 - GraphTrainer - INFO -   mrr@20: 0.022155
2025-11-22 22:42:23 - GraphTrainer - INFO - 第 164 轮训练完成
2025-11-22 22:42:23 - GraphTrainer - INFO - train_loss: 0.334555
2025-11-22 22:42:23 - GraphTrainer - INFO - precision@5: 0.006655
2025-11-22 22:42:23 - GraphTrainer - INFO - recall@5: 0.031809
2025-11-22 22:42:23 - GraphTrainer - INFO - hit_rate@5: 0.033222
2025-11-22 22:42:23 - GraphTrainer - INFO - ndcg@5: 0.020740
2025-11-22 22:42:23 - GraphTrainer - INFO - map@5: 0.016860
2025-11-22 22:42:23 - GraphTrainer - INFO - mrr@5: 0.017579
2025-11-22 22:42:23 - GraphTrainer - INFO - precision@10: 0.005225
2025-11-22 22:42:23 - GraphTrainer - INFO - recall@10: 0.049541
2025-11-22 22:42:23 - GraphTrainer - INFO - hit_rate@10: 0.052147
2025-11-22 22:42:23 - GraphTrainer - INFO - ndcg@10: 0.026485
2025-11-22 22:42:23 - GraphTrainer - INFO - map@10: 0.019164
2025-11-22 22:42:23 - GraphTrainer - INFO - mrr@10: 0.020040
2025-11-22 22:42:23 - GraphTrainer - INFO - precision@20: 0.004168
2025-11-22 22:42:23 - GraphTrainer - INFO - recall@20: 0.078830
2025-11-22 22:42:23 - GraphTrainer - INFO - hit_rate@20: 0.083003
2025-11-22 22:42:23 - GraphTrainer - INFO - ndcg@20: 0.033954
2025-11-22 22:42:23 - GraphTrainer - INFO - map@20: 0.021177
2025-11-22 22:42:23 - GraphTrainer - INFO - mrr@20: 0.022155
2025-11-22 22:42:23 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:42:23 - GraphTrainer - INFO - ============================================================
2025-11-22 22:42:23 - GraphTrainer - INFO - 开始第 165/1000 轮训练
2025-11-22 22:42:23 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3232, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3421, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3273, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3236, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3239, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3128, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3467, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3263, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3342, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3188, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3170, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3592, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3525, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3457, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3685, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3118, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3466, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3175, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3258, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3211, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3502, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3512, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3225, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3138, device='cuda:0', grad_fn=<AddBackward0>)
The 164 training average loss: 0.33455533765513323
2025-11-22 22:42:34 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:42:34 - GraphTrainer - INFO -   precision@5: 0.006686
2025-11-22 22:42:34 - GraphTrainer - INFO -   recall@5: 0.031834
2025-11-22 22:42:34 - GraphTrainer - INFO -   hit_rate@5: 0.033376
2025-11-22 22:42:34 - GraphTrainer - INFO -   ndcg@5: 0.020736
2025-11-22 22:42:34 - GraphTrainer - INFO -   map@5: 0.016838
2025-11-22 22:42:34 - GraphTrainer - INFO -   mrr@5: 0.017565
2025-11-22 22:42:34 - GraphTrainer - INFO -   precision@10: 0.005271
2025-11-22 22:42:34 - GraphTrainer - INFO -   recall@10: 0.049865
2025-11-22 22:42:34 - GraphTrainer - INFO -   hit_rate@10: 0.052507
2025-11-22 22:42:34 - GraphTrainer - INFO -   ndcg@10: 0.026586
2025-11-22 22:42:34 - GraphTrainer - INFO -   map@10: 0.019190
2025-11-22 22:42:34 - GraphTrainer - INFO -   mrr@10: 0.020064
2025-11-22 22:42:34 - GraphTrainer - INFO -   precision@20: 0.004160
2025-11-22 22:42:34 - GraphTrainer - INFO -   recall@20: 0.078660
2025-11-22 22:42:34 - GraphTrainer - INFO -   hit_rate@20: 0.082746
2025-11-22 22:42:34 - GraphTrainer - INFO -   ndcg@20: 0.033912
2025-11-22 22:42:34 - GraphTrainer - INFO -   map@20: 0.021159
2025-11-22 22:42:34 - GraphTrainer - INFO -   mrr@20: 0.022127
2025-11-22 22:42:34 - GraphTrainer - INFO - 第 165 轮训练完成
2025-11-22 22:42:34 - GraphTrainer - INFO - train_loss: 0.333671
2025-11-22 22:42:34 - GraphTrainer - INFO - precision@5: 0.006686
2025-11-22 22:42:34 - GraphTrainer - INFO - recall@5: 0.031834
2025-11-22 22:42:34 - GraphTrainer - INFO - hit_rate@5: 0.033376
2025-11-22 22:42:34 - GraphTrainer - INFO - ndcg@5: 0.020736
2025-11-22 22:42:34 - GraphTrainer - INFO - map@5: 0.016838
2025-11-22 22:42:34 - GraphTrainer - INFO - mrr@5: 0.017565
2025-11-22 22:42:34 - GraphTrainer - INFO - precision@10: 0.005271
2025-11-22 22:42:34 - GraphTrainer - INFO - recall@10: 0.049865
2025-11-22 22:42:34 - GraphTrainer - INFO - hit_rate@10: 0.052507
2025-11-22 22:42:34 - GraphTrainer - INFO - ndcg@10: 0.026586
2025-11-22 22:42:34 - GraphTrainer - INFO - map@10: 0.019190
2025-11-22 22:42:34 - GraphTrainer - INFO - mrr@10: 0.020064
2025-11-22 22:42:34 - GraphTrainer - INFO - precision@20: 0.004160
2025-11-22 22:42:34 - GraphTrainer - INFO - recall@20: 0.078660
2025-11-22 22:42:34 - GraphTrainer - INFO - hit_rate@20: 0.082746
2025-11-22 22:42:34 - GraphTrainer - INFO - ndcg@20: 0.033912
2025-11-22 22:42:34 - GraphTrainer - INFO - map@20: 0.021159
2025-11-22 22:42:34 - GraphTrainer - INFO - mrr@20: 0.022127
2025-11-22 22:42:34 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:42:34 - GraphTrainer - INFO - ============================================================
2025-11-22 22:42:34 - GraphTrainer - INFO - 开始第 166/1000 轮训练
2025-11-22 22:42:34 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3499, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3109, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3281, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3258, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3584, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3073, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3209, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3193, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3318, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3278, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3272, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3158, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3306, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3175, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3480, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3220, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3373, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3113, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3257, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3244, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3234, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3333, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3611, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3204, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3200, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3151, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3091, device='cuda:0', grad_fn=<AddBackward0>)
The 165 training average loss: 0.33367082579382534
2025-11-22 22:42:45 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:42:45 - GraphTrainer - INFO -   precision@5: 0.006737
2025-11-22 22:42:45 - GraphTrainer - INFO -   recall@5: 0.031966
2025-11-22 22:42:45 - GraphTrainer - INFO -   hit_rate@5: 0.033633
2025-11-22 22:42:45 - GraphTrainer - INFO -   ndcg@5: 0.020923
2025-11-22 22:42:45 - GraphTrainer - INFO -   map@5: 0.017029
2025-11-22 22:42:45 - GraphTrainer - INFO -   mrr@5: 0.017757
2025-11-22 22:42:45 - GraphTrainer - INFO -   precision@10: 0.005333
2025-11-22 22:42:45 - GraphTrainer - INFO -   recall@10: 0.050597
2025-11-22 22:42:45 - GraphTrainer - INFO -   hit_rate@10: 0.053124
2025-11-22 22:42:45 - GraphTrainer - INFO -   ndcg@10: 0.026946
2025-11-22 22:42:45 - GraphTrainer - INFO -   map@10: 0.019458
2025-11-22 22:42:45 - GraphTrainer - INFO -   mrr@10: 0.020295
2025-11-22 22:42:45 - GraphTrainer - INFO -   precision@20: 0.004181
2025-11-22 22:42:45 - GraphTrainer - INFO -   recall@20: 0.079119
2025-11-22 22:42:45 - GraphTrainer - INFO -   hit_rate@20: 0.083106
2025-11-22 22:42:45 - GraphTrainer - INFO -   ndcg@20: 0.034170
2025-11-22 22:42:45 - GraphTrainer - INFO -   map@20: 0.021381
2025-11-22 22:42:45 - GraphTrainer - INFO -   mrr@20: 0.022310
2025-11-22 22:42:45 - GraphTrainer - INFO - 第 166 轮训练完成
2025-11-22 22:42:45 - GraphTrainer - INFO - train_loss: 0.333438
2025-11-22 22:42:45 - GraphTrainer - INFO - precision@5: 0.006737
2025-11-22 22:42:45 - GraphTrainer - INFO - recall@5: 0.031966
2025-11-22 22:42:45 - GraphTrainer - INFO - hit_rate@5: 0.033633
2025-11-22 22:42:45 - GraphTrainer - INFO - ndcg@5: 0.020923
2025-11-22 22:42:45 - GraphTrainer - INFO - map@5: 0.017029
2025-11-22 22:42:45 - GraphTrainer - INFO - mrr@5: 0.017757
2025-11-22 22:42:45 - GraphTrainer - INFO - precision@10: 0.005333
2025-11-22 22:42:45 - GraphTrainer - INFO - recall@10: 0.050597
2025-11-22 22:42:45 - GraphTrainer - INFO - hit_rate@10: 0.053124
2025-11-22 22:42:45 - GraphTrainer - INFO - ndcg@10: 0.026946
2025-11-22 22:42:45 - GraphTrainer - INFO - map@10: 0.019458
2025-11-22 22:42:45 - GraphTrainer - INFO - mrr@10: 0.020295
2025-11-22 22:42:45 - GraphTrainer - INFO - precision@20: 0.004181
2025-11-22 22:42:45 - GraphTrainer - INFO - recall@20: 0.079119
2025-11-22 22:42:45 - GraphTrainer - INFO - hit_rate@20: 0.083106
2025-11-22 22:42:45 - GraphTrainer - INFO - ndcg@20: 0.034170
2025-11-22 22:42:45 - GraphTrainer - INFO - map@20: 0.021381
2025-11-22 22:42:45 - GraphTrainer - INFO - mrr@20: 0.022310
2025-11-22 22:42:45 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:42:45 - GraphTrainer - INFO - ============================================================
2025-11-22 22:42:45 - GraphTrainer - INFO - 开始第 167/1000 轮训练
2025-11-22 22:42:45 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3194, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3260, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3200, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3611, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3104, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3185, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3161, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3206, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3089, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3284, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3139, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3484, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3153, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3327, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3236, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3252, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3093, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3186, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3112, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3252, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3316, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3179, device='cuda:0', grad_fn=<AddBackward0>)
The 166 training average loss: 0.3334378435693938
2025-11-22 22:42:56 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:42:56 - GraphTrainer - INFO -   precision@5: 0.006562
2025-11-22 22:42:56 - GraphTrainer - INFO -   recall@5: 0.031456
2025-11-22 22:42:56 - GraphTrainer - INFO -   hit_rate@5: 0.032759
2025-11-22 22:42:56 - GraphTrainer - INFO -   ndcg@5: 0.020837
2025-11-22 22:42:56 - GraphTrainer - INFO -   map@5: 0.017145
2025-11-22 22:42:56 - GraphTrainer - INFO -   mrr@5: 0.017720
2025-11-22 22:42:56 - GraphTrainer - INFO -   precision@10: 0.005297
2025-11-22 22:42:56 - GraphTrainer - INFO -   recall@10: 0.050294
2025-11-22 22:42:56 - GraphTrainer - INFO -   hit_rate@10: 0.052816
2025-11-22 22:42:56 - GraphTrainer - INFO -   ndcg@10: 0.026943
2025-11-22 22:42:56 - GraphTrainer - INFO -   map@10: 0.019594
2025-11-22 22:42:56 - GraphTrainer - INFO -   mrr@10: 0.020336
2025-11-22 22:42:56 - GraphTrainer - INFO -   precision@20: 0.004176
2025-11-22 22:42:56 - GraphTrainer - INFO -   recall@20: 0.078974
2025-11-22 22:42:56 - GraphTrainer - INFO -   hit_rate@20: 0.082900
2025-11-22 22:42:56 - GraphTrainer - INFO -   ndcg@20: 0.034184
2025-11-22 22:42:56 - GraphTrainer - INFO -   map@20: 0.021509
2025-11-22 22:42:56 - GraphTrainer - INFO -   mrr@20: 0.022334
2025-11-22 22:42:56 - GraphTrainer - INFO - 第 167 轮训练完成
2025-11-22 22:42:56 - GraphTrainer - INFO - train_loss: 0.335090
2025-11-22 22:42:56 - GraphTrainer - INFO - precision@5: 0.006562
2025-11-22 22:42:56 - GraphTrainer - INFO - recall@5: 0.031456
2025-11-22 22:42:56 - GraphTrainer - INFO - hit_rate@5: 0.032759
2025-11-22 22:42:56 - GraphTrainer - INFO - ndcg@5: 0.020837
2025-11-22 22:42:56 - GraphTrainer - INFO - map@5: 0.017145
2025-11-22 22:42:56 - GraphTrainer - INFO - mrr@5: 0.017720
2025-11-22 22:42:56 - GraphTrainer - INFO - precision@10: 0.005297
2025-11-22 22:42:56 - GraphTrainer - INFO - recall@10: 0.050294
2025-11-22 22:42:56 - GraphTrainer - INFO - hit_rate@10: 0.052816
2025-11-22 22:42:56 - GraphTrainer - INFO - ndcg@10: 0.026943
2025-11-22 22:42:56 - GraphTrainer - INFO - map@10: 0.019594
2025-11-22 22:42:56 - GraphTrainer - INFO - mrr@10: 0.020336
2025-11-22 22:42:56 - GraphTrainer - INFO - precision@20: 0.004176
2025-11-22 22:42:56 - GraphTrainer - INFO - recall@20: 0.078974
2025-11-22 22:42:56 - GraphTrainer - INFO - hit_rate@20: 0.082900
2025-11-22 22:42:56 - GraphTrainer - INFO - ndcg@20: 0.034184
2025-11-22 22:42:56 - GraphTrainer - INFO - map@20: 0.021509
2025-11-22 22:42:56 - GraphTrainer - INFO - mrr@20: 0.022334
2025-11-22 22:42:56 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:42:56 - GraphTrainer - INFO - ============================================================
2025-11-22 22:42:56 - GraphTrainer - INFO - 开始第 168/1000 轮训练
2025-11-22 22:42:56 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3258, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3599, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3327, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3123, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3206, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3226, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3551, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3327, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3468, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3290, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3536, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3176, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3666, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3379, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3180, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3570, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3179, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3209, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3214, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3206, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3248, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3276, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3230, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3220, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3610, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3192, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3192, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3207, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3110, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3316, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3256, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3220, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3342, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3376, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3667, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3227, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
The 167 training average loss: 0.3350901218323872
2025-11-22 22:43:07 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:43:07 - GraphTrainer - INFO -   precision@5: 0.006500
2025-11-22 22:43:07 - GraphTrainer - INFO -   recall@5: 0.030966
2025-11-22 22:43:07 - GraphTrainer - INFO -   hit_rate@5: 0.032451
2025-11-22 22:43:07 - GraphTrainer - INFO -   ndcg@5: 0.020687
2025-11-22 22:43:07 - GraphTrainer - INFO -   map@5: 0.017061
2025-11-22 22:43:07 - GraphTrainer - INFO -   mrr@5: 0.017738
2025-11-22 22:43:07 - GraphTrainer - INFO -   precision@10: 0.005338
2025-11-22 22:43:07 - GraphTrainer - INFO -   recall@10: 0.050732
2025-11-22 22:43:07 - GraphTrainer - INFO -   hit_rate@10: 0.053227
2025-11-22 22:43:07 - GraphTrainer - INFO -   ndcg@10: 0.027088
2025-11-22 22:43:07 - GraphTrainer - INFO -   map@10: 0.019645
2025-11-22 22:43:07 - GraphTrainer - INFO -   mrr@10: 0.020452
2025-11-22 22:43:07 - GraphTrainer - INFO -   precision@20: 0.004173
2025-11-22 22:43:07 - GraphTrainer - INFO -   recall@20: 0.079108
2025-11-22 22:43:07 - GraphTrainer - INFO -   hit_rate@20: 0.082900
2025-11-22 22:43:07 - GraphTrainer - INFO -   ndcg@20: 0.034286
2025-11-22 22:43:07 - GraphTrainer - INFO -   map@20: 0.021572
2025-11-22 22:43:07 - GraphTrainer - INFO -   mrr@20: 0.022460
2025-11-22 22:43:07 - GraphTrainer - INFO - 第 168 轮训练完成
2025-11-22 22:43:07 - GraphTrainer - INFO - train_loss: 0.329128
2025-11-22 22:43:07 - GraphTrainer - INFO - precision@5: 0.006500
2025-11-22 22:43:07 - GraphTrainer - INFO - recall@5: 0.030966
2025-11-22 22:43:07 - GraphTrainer - INFO - hit_rate@5: 0.032451
2025-11-22 22:43:07 - GraphTrainer - INFO - ndcg@5: 0.020687
2025-11-22 22:43:07 - GraphTrainer - INFO - map@5: 0.017061
2025-11-22 22:43:07 - GraphTrainer - INFO - mrr@5: 0.017738
2025-11-22 22:43:07 - GraphTrainer - INFO - precision@10: 0.005338
2025-11-22 22:43:07 - GraphTrainer - INFO - recall@10: 0.050732
2025-11-22 22:43:07 - GraphTrainer - INFO - hit_rate@10: 0.053227
2025-11-22 22:43:07 - GraphTrainer - INFO - ndcg@10: 0.027088
2025-11-22 22:43:07 - GraphTrainer - INFO - map@10: 0.019645
2025-11-22 22:43:07 - GraphTrainer - INFO - mrr@10: 0.020452
2025-11-22 22:43:07 - GraphTrainer - INFO - precision@20: 0.004173
2025-11-22 22:43:07 - GraphTrainer - INFO - recall@20: 0.079108
2025-11-22 22:43:07 - GraphTrainer - INFO - hit_rate@20: 0.082900
2025-11-22 22:43:07 - GraphTrainer - INFO - ndcg@20: 0.034286
2025-11-22 22:43:07 - GraphTrainer - INFO - map@20: 0.021572
2025-11-22 22:43:07 - GraphTrainer - INFO - mrr@20: 0.022460
2025-11-22 22:43:07 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:43:07 - GraphTrainer - INFO - ============================================================
2025-11-22 22:43:07 - GraphTrainer - INFO - 开始第 169/1000 轮训练
2025-11-22 22:43:07 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3176, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3144, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3221, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3473, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3154, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3005, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3223, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3258, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3269, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3061, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3252, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3254, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3210, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3435, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3272, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3170, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3225, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3240, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3162, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3162, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3163, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3249, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3288, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3573, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3129, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3063, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3313, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3276, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3226, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3276, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3235, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3027, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3309, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3586, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3174, device='cuda:0', grad_fn=<AddBackward0>)
The 168 training average loss: 0.32912829723851433
2025-11-22 22:43:18 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:43:18 - GraphTrainer - INFO -   precision@5: 0.006449
2025-11-22 22:43:18 - GraphTrainer - INFO -   recall@5: 0.030773
2025-11-22 22:43:18 - GraphTrainer - INFO -   hit_rate@5: 0.032193
2025-11-22 22:43:18 - GraphTrainer - INFO -   ndcg@5: 0.020523
2025-11-22 22:43:18 - GraphTrainer - INFO -   map@5: 0.016917
2025-11-22 22:43:18 - GraphTrainer - INFO -   mrr@5: 0.017575
2025-11-22 22:43:18 - GraphTrainer - INFO -   precision@10: 0.005292
2025-11-22 22:43:18 - GraphTrainer - INFO -   recall@10: 0.050386
2025-11-22 22:43:18 - GraphTrainer - INFO -   hit_rate@10: 0.052764
2025-11-22 22:43:18 - GraphTrainer - INFO -   ndcg@10: 0.026858
2025-11-22 22:43:18 - GraphTrainer - INFO -   map@10: 0.019466
2025-11-22 22:43:18 - GraphTrainer - INFO -   mrr@10: 0.020254
2025-11-22 22:43:18 - GraphTrainer - INFO -   precision@20: 0.004235
2025-11-22 22:43:18 - GraphTrainer - INFO -   recall@20: 0.080163
2025-11-22 22:43:18 - GraphTrainer - INFO -   hit_rate@20: 0.084238
2025-11-22 22:43:18 - GraphTrainer - INFO -   ndcg@20: 0.034427
2025-11-22 22:43:18 - GraphTrainer - INFO -   map@20: 0.021488
2025-11-22 22:43:18 - GraphTrainer - INFO -   mrr@20: 0.022385
2025-11-22 22:43:18 - GraphTrainer - INFO - 第 169 轮训练完成
2025-11-22 22:43:18 - GraphTrainer - INFO - train_loss: 0.332002
2025-11-22 22:43:18 - GraphTrainer - INFO - precision@5: 0.006449
2025-11-22 22:43:18 - GraphTrainer - INFO - recall@5: 0.030773
2025-11-22 22:43:18 - GraphTrainer - INFO - hit_rate@5: 0.032193
2025-11-22 22:43:18 - GraphTrainer - INFO - ndcg@5: 0.020523
2025-11-22 22:43:18 - GraphTrainer - INFO - map@5: 0.016917
2025-11-22 22:43:18 - GraphTrainer - INFO - mrr@5: 0.017575
2025-11-22 22:43:18 - GraphTrainer - INFO - precision@10: 0.005292
2025-11-22 22:43:18 - GraphTrainer - INFO - recall@10: 0.050386
2025-11-22 22:43:18 - GraphTrainer - INFO - hit_rate@10: 0.052764
2025-11-22 22:43:18 - GraphTrainer - INFO - ndcg@10: 0.026858
2025-11-22 22:43:18 - GraphTrainer - INFO - map@10: 0.019466
2025-11-22 22:43:18 - GraphTrainer - INFO - mrr@10: 0.020254
2025-11-22 22:43:18 - GraphTrainer - INFO - precision@20: 0.004235
2025-11-22 22:43:18 - GraphTrainer - INFO - recall@20: 0.080163
2025-11-22 22:43:18 - GraphTrainer - INFO - hit_rate@20: 0.084238
2025-11-22 22:43:18 - GraphTrainer - INFO - ndcg@20: 0.034427
2025-11-22 22:43:18 - GraphTrainer - INFO - map@20: 0.021488
2025-11-22 22:43:18 - GraphTrainer - INFO - mrr@20: 0.022385
2025-11-22 22:43:18 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:43:18 - GraphTrainer - INFO - ============================================================
2025-11-22 22:43:18 - GraphTrainer - INFO - 开始第 170/1000 轮训练
2025-11-22 22:43:18 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3282, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3480, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3502, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3268, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3260, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3240, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3166, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3268, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3210, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3651, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3182, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3241, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3207, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3192, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3260, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3191, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3220, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3034, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3161, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3214, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3257, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3199, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3191, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3186, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3613, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3152, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3147, device='cuda:0', grad_fn=<AddBackward0>)
The 169 training average loss: 0.3320024404032477
2025-11-22 22:43:29 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:43:29 - GraphTrainer - INFO -   precision@5: 0.006634
2025-11-22 22:43:29 - GraphTrainer - INFO -   recall@5: 0.031627
2025-11-22 22:43:29 - GraphTrainer - INFO -   hit_rate@5: 0.033119
2025-11-22 22:43:29 - GraphTrainer - INFO -   ndcg@5: 0.020825
2025-11-22 22:43:29 - GraphTrainer - INFO -   map@5: 0.017027
2025-11-22 22:43:29 - GraphTrainer - INFO -   mrr@5: 0.017781
2025-11-22 22:43:29 - GraphTrainer - INFO -   precision@10: 0.005312
2025-11-22 22:43:29 - GraphTrainer - INFO -   recall@10: 0.050446
2025-11-22 22:43:29 - GraphTrainer - INFO -   hit_rate@10: 0.052918
2025-11-22 22:43:29 - GraphTrainer - INFO -   ndcg@10: 0.026875
2025-11-22 22:43:29 - GraphTrainer - INFO -   map@10: 0.019439
2025-11-22 22:43:29 - GraphTrainer - INFO -   mrr@10: 0.020319
2025-11-22 22:43:29 - GraphTrainer - INFO -   precision@20: 0.004217
2025-11-22 22:43:29 - GraphTrainer - INFO -   recall@20: 0.079989
2025-11-22 22:43:29 - GraphTrainer - INFO -   hit_rate@20: 0.083929
2025-11-22 22:43:29 - GraphTrainer - INFO -   ndcg@20: 0.034376
2025-11-22 22:43:29 - GraphTrainer - INFO -   map@20: 0.021450
2025-11-22 22:43:29 - GraphTrainer - INFO -   mrr@20: 0.022427
2025-11-22 22:43:29 - GraphTrainer - INFO - 第 170 轮训练完成
2025-11-22 22:43:29 - GraphTrainer - INFO - train_loss: 0.331843
2025-11-22 22:43:29 - GraphTrainer - INFO - precision@5: 0.006634
2025-11-22 22:43:29 - GraphTrainer - INFO - recall@5: 0.031627
2025-11-22 22:43:29 - GraphTrainer - INFO - hit_rate@5: 0.033119
2025-11-22 22:43:29 - GraphTrainer - INFO - ndcg@5: 0.020825
2025-11-22 22:43:29 - GraphTrainer - INFO - map@5: 0.017027
2025-11-22 22:43:29 - GraphTrainer - INFO - mrr@5: 0.017781
2025-11-22 22:43:29 - GraphTrainer - INFO - precision@10: 0.005312
2025-11-22 22:43:29 - GraphTrainer - INFO - recall@10: 0.050446
2025-11-22 22:43:29 - GraphTrainer - INFO - hit_rate@10: 0.052918
2025-11-22 22:43:29 - GraphTrainer - INFO - ndcg@10: 0.026875
2025-11-22 22:43:29 - GraphTrainer - INFO - map@10: 0.019439
2025-11-22 22:43:29 - GraphTrainer - INFO - mrr@10: 0.020319
2025-11-22 22:43:29 - GraphTrainer - INFO - precision@20: 0.004217
2025-11-22 22:43:29 - GraphTrainer - INFO - recall@20: 0.079989
2025-11-22 22:43:29 - GraphTrainer - INFO - hit_rate@20: 0.083929
2025-11-22 22:43:29 - GraphTrainer - INFO - ndcg@20: 0.034376
2025-11-22 22:43:29 - GraphTrainer - INFO - map@20: 0.021450
2025-11-22 22:43:29 - GraphTrainer - INFO - mrr@20: 0.022427
2025-11-22 22:43:29 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:43:30 - GraphTrainer - INFO - 检查点已保存: Epoch 170 -> ./checkpoints/checkpoint_epoch_170.pth
2025-11-22 22:43:30 - GraphTrainer - INFO - ============================================================
2025-11-22 22:43:30 - GraphTrainer - INFO - 开始第 171/1000 轮训练
2025-11-22 22:43:30 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3268, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3115, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3219, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3297, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3194, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3293, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3205, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3290, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3162, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3260, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3304, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3185, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3549, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3464, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3516, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3196, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3464, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3146, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3131, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3288, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3212, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3180, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3327, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3290, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3232, device='cuda:0', grad_fn=<AddBackward0>)
The 170 training average loss: 0.3318428109432089
2025-11-22 22:43:40 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:43:40 - GraphTrainer - INFO -   precision@5: 0.006614
2025-11-22 22:43:40 - GraphTrainer - INFO -   recall@5: 0.031366
2025-11-22 22:43:40 - GraphTrainer - INFO -   hit_rate@5: 0.033016
2025-11-22 22:43:40 - GraphTrainer - INFO -   ndcg@5: 0.020767
2025-11-22 22:43:40 - GraphTrainer - INFO -   map@5: 0.017030
2025-11-22 22:43:40 - GraphTrainer - INFO -   mrr@5: 0.017750
2025-11-22 22:43:40 - GraphTrainer - INFO -   precision@10: 0.005307
2025-11-22 22:43:40 - GraphTrainer - INFO -   recall@10: 0.050485
2025-11-22 22:43:40 - GraphTrainer - INFO -   hit_rate@10: 0.052918
2025-11-22 22:43:40 - GraphTrainer - INFO -   ndcg@10: 0.026924
2025-11-22 22:43:40 - GraphTrainer - INFO -   map@10: 0.019508
2025-11-22 22:43:40 - GraphTrainer - INFO -   mrr@10: 0.020329
2025-11-22 22:43:40 - GraphTrainer - INFO -   precision@20: 0.004189
2025-11-22 22:43:40 - GraphTrainer - INFO -   recall@20: 0.079287
2025-11-22 22:43:40 - GraphTrainer - INFO -   hit_rate@20: 0.083312
2025-11-22 22:43:40 - GraphTrainer - INFO -   ndcg@20: 0.034198
2025-11-22 22:43:40 - GraphTrainer - INFO -   map@20: 0.021429
2025-11-22 22:43:40 - GraphTrainer - INFO -   mrr@20: 0.022352
2025-11-22 22:43:40 - GraphTrainer - INFO - 第 171 轮训练完成
2025-11-22 22:43:40 - GraphTrainer - INFO - train_loss: 0.332088
2025-11-22 22:43:40 - GraphTrainer - INFO - precision@5: 0.006614
2025-11-22 22:43:40 - GraphTrainer - INFO - recall@5: 0.031366
2025-11-22 22:43:40 - GraphTrainer - INFO - hit_rate@5: 0.033016
2025-11-22 22:43:40 - GraphTrainer - INFO - ndcg@5: 0.020767
2025-11-22 22:43:40 - GraphTrainer - INFO - map@5: 0.017030
2025-11-22 22:43:40 - GraphTrainer - INFO - mrr@5: 0.017750
2025-11-22 22:43:40 - GraphTrainer - INFO - precision@10: 0.005307
2025-11-22 22:43:40 - GraphTrainer - INFO - recall@10: 0.050485
2025-11-22 22:43:40 - GraphTrainer - INFO - hit_rate@10: 0.052918
2025-11-22 22:43:40 - GraphTrainer - INFO - ndcg@10: 0.026924
2025-11-22 22:43:40 - GraphTrainer - INFO - map@10: 0.019508
2025-11-22 22:43:40 - GraphTrainer - INFO - mrr@10: 0.020329
2025-11-22 22:43:40 - GraphTrainer - INFO - precision@20: 0.004189
2025-11-22 22:43:40 - GraphTrainer - INFO - recall@20: 0.079287
2025-11-22 22:43:40 - GraphTrainer - INFO - hit_rate@20: 0.083312
2025-11-22 22:43:40 - GraphTrainer - INFO - ndcg@20: 0.034198
2025-11-22 22:43:40 - GraphTrainer - INFO - map@20: 0.021429
2025-11-22 22:43:40 - GraphTrainer - INFO - mrr@20: 0.022352
2025-11-22 22:43:40 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:43:40 - GraphTrainer - INFO - ============================================================
2025-11-22 22:43:40 - GraphTrainer - INFO - 开始第 172/1000 轮训练
2025-11-22 22:43:40 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3203, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3272, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3213, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3279, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3282, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3239, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3172, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3464, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3288, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3120, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3591, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3248, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3214, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2939, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3288, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3331, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3282, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3098, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3506, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3184, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3262, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3212, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3342, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3246, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
The 171 training average loss: 0.33208837539985264
2025-11-22 22:43:51 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:43:51 - GraphTrainer - INFO -   precision@5: 0.006459
2025-11-22 22:43:51 - GraphTrainer - INFO -   recall@5: 0.030680
2025-11-22 22:43:51 - GraphTrainer - INFO -   hit_rate@5: 0.032245
2025-11-22 22:43:51 - GraphTrainer - INFO -   ndcg@5: 0.020304
2025-11-22 22:43:51 - GraphTrainer - INFO -   map@5: 0.016641
2025-11-22 22:43:51 - GraphTrainer - INFO -   mrr@5: 0.017301
2025-11-22 22:43:51 - GraphTrainer - INFO -   precision@10: 0.005287
2025-11-22 22:43:51 - GraphTrainer - INFO -   recall@10: 0.050183
2025-11-22 22:43:51 - GraphTrainer - INFO -   hit_rate@10: 0.052764
2025-11-22 22:43:51 - GraphTrainer - INFO -   ndcg@10: 0.026623
2025-11-22 22:43:51 - GraphTrainer - INFO -   map@10: 0.019195
2025-11-22 22:43:51 - GraphTrainer - INFO -   mrr@10: 0.019990
2025-11-22 22:43:51 - GraphTrainer - INFO -   precision@20: 0.004145
2025-11-22 22:43:51 - GraphTrainer - INFO -   recall@20: 0.078499
2025-11-22 22:43:51 - GraphTrainer - INFO -   hit_rate@20: 0.082438
2025-11-22 22:43:51 - GraphTrainer - INFO -   ndcg@20: 0.033804
2025-11-22 22:43:51 - GraphTrainer - INFO -   map@20: 0.021114
2025-11-22 22:43:51 - GraphTrainer - INFO -   mrr@20: 0.021993
2025-11-22 22:43:51 - GraphTrainer - INFO - 第 172 轮训练完成
2025-11-22 22:43:51 - GraphTrainer - INFO - train_loss: 0.331787
2025-11-22 22:43:51 - GraphTrainer - INFO - precision@5: 0.006459
2025-11-22 22:43:51 - GraphTrainer - INFO - recall@5: 0.030680
2025-11-22 22:43:51 - GraphTrainer - INFO - hit_rate@5: 0.032245
2025-11-22 22:43:51 - GraphTrainer - INFO - ndcg@5: 0.020304
2025-11-22 22:43:51 - GraphTrainer - INFO - map@5: 0.016641
2025-11-22 22:43:51 - GraphTrainer - INFO - mrr@5: 0.017301
2025-11-22 22:43:51 - GraphTrainer - INFO - precision@10: 0.005287
2025-11-22 22:43:51 - GraphTrainer - INFO - recall@10: 0.050183
2025-11-22 22:43:51 - GraphTrainer - INFO - hit_rate@10: 0.052764
2025-11-22 22:43:51 - GraphTrainer - INFO - ndcg@10: 0.026623
2025-11-22 22:43:51 - GraphTrainer - INFO - map@10: 0.019195
2025-11-22 22:43:51 - GraphTrainer - INFO - mrr@10: 0.019990
2025-11-22 22:43:51 - GraphTrainer - INFO - precision@20: 0.004145
2025-11-22 22:43:51 - GraphTrainer - INFO - recall@20: 0.078499
2025-11-22 22:43:51 - GraphTrainer - INFO - hit_rate@20: 0.082438
2025-11-22 22:43:51 - GraphTrainer - INFO - ndcg@20: 0.033804
2025-11-22 22:43:51 - GraphTrainer - INFO - map@20: 0.021114
2025-11-22 22:43:51 - GraphTrainer - INFO - mrr@20: 0.021993
2025-11-22 22:43:51 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:43:51 - GraphTrainer - INFO - ============================================================
2025-11-22 22:43:51 - GraphTrainer - INFO - 开始第 173/1000 轮训练
2025-11-22 22:43:51 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3121, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3409, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3089, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3262, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3537, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3225, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3236, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3231, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3188, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3281, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3316, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3236, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3206, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3205, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3312, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3274, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3080, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3636, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3299, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3502, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3282, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3154, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3171, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3200, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3187, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3507, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3115, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3184, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3342, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3234, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3598, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3621, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
The 172 training average loss: 0.3317868802054175
2025-11-22 22:44:02 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:44:02 - GraphTrainer - INFO -   precision@5: 0.006655
2025-11-22 22:44:02 - GraphTrainer - INFO -   recall@5: 0.031653
2025-11-22 22:44:02 - GraphTrainer - INFO -   hit_rate@5: 0.033222
2025-11-22 22:44:02 - GraphTrainer - INFO -   ndcg@5: 0.020933
2025-11-22 22:44:02 - GraphTrainer - INFO -   map@5: 0.017166
2025-11-22 22:44:02 - GraphTrainer - INFO -   mrr@5: 0.017850
2025-11-22 22:44:02 - GraphTrainer - INFO -   precision@10: 0.005343
2025-11-22 22:44:02 - GraphTrainer - INFO -   recall@10: 0.050642
2025-11-22 22:44:02 - GraphTrainer - INFO -   hit_rate@10: 0.053176
2025-11-22 22:44:02 - GraphTrainer - INFO -   ndcg@10: 0.027083
2025-11-22 22:44:02 - GraphTrainer - INFO -   map@10: 0.019645
2025-11-22 22:44:02 - GraphTrainer - INFO -   mrr@10: 0.020454
2025-11-22 22:44:02 - GraphTrainer - INFO -   precision@20: 0.004189
2025-11-22 22:44:02 - GraphTrainer - INFO -   recall@20: 0.079582
2025-11-22 22:44:02 - GraphTrainer - INFO -   hit_rate@20: 0.083363
2025-11-22 22:44:02 - GraphTrainer - INFO -   ndcg@20: 0.034391
2025-11-22 22:44:02 - GraphTrainer - INFO -   map@20: 0.021593
2025-11-22 22:44:02 - GraphTrainer - INFO -   mrr@20: 0.022479
2025-11-22 22:44:02 - GraphTrainer - INFO - 第 173 轮训练完成
2025-11-22 22:44:02 - GraphTrainer - INFO - train_loss: 0.331183
2025-11-22 22:44:02 - GraphTrainer - INFO - precision@5: 0.006655
2025-11-22 22:44:02 - GraphTrainer - INFO - recall@5: 0.031653
2025-11-22 22:44:02 - GraphTrainer - INFO - hit_rate@5: 0.033222
2025-11-22 22:44:02 - GraphTrainer - INFO - ndcg@5: 0.020933
2025-11-22 22:44:02 - GraphTrainer - INFO - map@5: 0.017166
2025-11-22 22:44:02 - GraphTrainer - INFO - mrr@5: 0.017850
2025-11-22 22:44:02 - GraphTrainer - INFO - precision@10: 0.005343
2025-11-22 22:44:02 - GraphTrainer - INFO - recall@10: 0.050642
2025-11-22 22:44:02 - GraphTrainer - INFO - hit_rate@10: 0.053176
2025-11-22 22:44:02 - GraphTrainer - INFO - ndcg@10: 0.027083
2025-11-22 22:44:02 - GraphTrainer - INFO - map@10: 0.019645
2025-11-22 22:44:02 - GraphTrainer - INFO - mrr@10: 0.020454
2025-11-22 22:44:02 - GraphTrainer - INFO - precision@20: 0.004189
2025-11-22 22:44:02 - GraphTrainer - INFO - recall@20: 0.079582
2025-11-22 22:44:02 - GraphTrainer - INFO - hit_rate@20: 0.083363
2025-11-22 22:44:02 - GraphTrainer - INFO - ndcg@20: 0.034391
2025-11-22 22:44:02 - GraphTrainer - INFO - map@20: 0.021593
2025-11-22 22:44:02 - GraphTrainer - INFO - mrr@20: 0.022479
2025-11-22 22:44:02 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:44:02 - GraphTrainer - INFO - ============================================================
2025-11-22 22:44:02 - GraphTrainer - INFO - 开始第 174/1000 轮训练
2025-11-22 22:44:02 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3213, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3039, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3518, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3409, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3521, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3309, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3136, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3241, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3210, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3284, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3256, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3516, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3181, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3285, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3204, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3502, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3037, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3000, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3053, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3128, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3518, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3256, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3163, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3231, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3532, device='cuda:0', grad_fn=<AddBackward0>)
The 173 training average loss: 0.33118284416609794
2025-11-22 22:44:14 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:44:14 - GraphTrainer - INFO -   precision@5: 0.006758
2025-11-22 22:44:14 - GraphTrainer - INFO -   recall@5: 0.032079
2025-11-22 22:44:14 - GraphTrainer - INFO -   hit_rate@5: 0.033736
2025-11-22 22:44:14 - GraphTrainer - INFO -   ndcg@5: 0.021170
2025-11-22 22:44:14 - GraphTrainer - INFO -   map@5: 0.017349
2025-11-22 22:44:14 - GraphTrainer - INFO -   mrr@5: 0.018041
2025-11-22 22:44:14 - GraphTrainer - INFO -   precision@10: 0.005225
2025-11-22 22:44:14 - GraphTrainer - INFO -   recall@10: 0.049563
2025-11-22 22:44:14 - GraphTrainer - INFO -   hit_rate@10: 0.052096
2025-11-22 22:44:14 - GraphTrainer - INFO -   ndcg@10: 0.026849
2025-11-22 22:44:14 - GraphTrainer - INFO -   map@10: 0.019651
2025-11-22 22:44:14 - GraphTrainer - INFO -   mrr@10: 0.020464
2025-11-22 22:44:14 - GraphTrainer - INFO -   precision@20: 0.004171
2025-11-22 22:44:14 - GraphTrainer - INFO -   recall@20: 0.078787
2025-11-22 22:44:14 - GraphTrainer - INFO -   hit_rate@20: 0.082900
2025-11-22 22:44:14 - GraphTrainer - INFO -   ndcg@20: 0.034287
2025-11-22 22:44:14 - GraphTrainer - INFO -   map@20: 0.021645
2025-11-22 22:44:14 - GraphTrainer - INFO -   mrr@20: 0.022559
2025-11-22 22:44:14 - GraphTrainer - INFO - 第 174 轮训练完成
2025-11-22 22:44:14 - GraphTrainer - INFO - train_loss: 0.329856
2025-11-22 22:44:14 - GraphTrainer - INFO - precision@5: 0.006758
2025-11-22 22:44:14 - GraphTrainer - INFO - recall@5: 0.032079
2025-11-22 22:44:14 - GraphTrainer - INFO - hit_rate@5: 0.033736
2025-11-22 22:44:14 - GraphTrainer - INFO - ndcg@5: 0.021170
2025-11-22 22:44:14 - GraphTrainer - INFO - map@5: 0.017349
2025-11-22 22:44:14 - GraphTrainer - INFO - mrr@5: 0.018041
2025-11-22 22:44:14 - GraphTrainer - INFO - precision@10: 0.005225
2025-11-22 22:44:14 - GraphTrainer - INFO - recall@10: 0.049563
2025-11-22 22:44:14 - GraphTrainer - INFO - hit_rate@10: 0.052096
2025-11-22 22:44:14 - GraphTrainer - INFO - ndcg@10: 0.026849
2025-11-22 22:44:14 - GraphTrainer - INFO - map@10: 0.019651
2025-11-22 22:44:14 - GraphTrainer - INFO - mrr@10: 0.020464
2025-11-22 22:44:14 - GraphTrainer - INFO - precision@20: 0.004171
2025-11-22 22:44:14 - GraphTrainer - INFO - recall@20: 0.078787
2025-11-22 22:44:14 - GraphTrainer - INFO - hit_rate@20: 0.082900
2025-11-22 22:44:14 - GraphTrainer - INFO - ndcg@20: 0.034287
2025-11-22 22:44:14 - GraphTrainer - INFO - map@20: 0.021645
2025-11-22 22:44:14 - GraphTrainer - INFO - mrr@20: 0.022559
2025-11-22 22:44:14 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:44:14 - GraphTrainer - INFO - ============================================================
2025-11-22 22:44:14 - GraphTrainer - INFO - 开始第 175/1000 轮训练
2025-11-22 22:44:14 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3490, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3006, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3303, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3239, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3468, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3009, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3214, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3171, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3126, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3123, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3073, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3231, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3240, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3132, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3248, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3094, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3032, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3421, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3206, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3204, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3232, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3228, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3297, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3518, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3455, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3089, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3101, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3516, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
The 174 training average loss: 0.32985600161141365
2025-11-22 22:44:24 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:44:24 - GraphTrainer - INFO -   precision@5: 0.006788
2025-11-22 22:44:24 - GraphTrainer - INFO -   recall@5: 0.032172
2025-11-22 22:44:24 - GraphTrainer - INFO -   hit_rate@5: 0.033890
2025-11-22 22:44:24 - GraphTrainer - INFO -   ndcg@5: 0.021146
2025-11-22 22:44:24 - GraphTrainer - INFO -   map@5: 0.017269
2025-11-22 22:44:24 - GraphTrainer - INFO -   mrr@5: 0.018024
2025-11-22 22:44:24 - GraphTrainer - INFO -   precision@10: 0.005184
2025-11-22 22:44:24 - GraphTrainer - INFO -   recall@10: 0.049108
2025-11-22 22:44:24 - GraphTrainer - INFO -   hit_rate@10: 0.051684
2025-11-22 22:44:24 - GraphTrainer - INFO -   ndcg@10: 0.026626
2025-11-22 22:44:24 - GraphTrainer - INFO -   map@10: 0.019477
2025-11-22 22:44:24 - GraphTrainer - INFO -   mrr@10: 0.020344
2025-11-22 22:44:24 - GraphTrainer - INFO -   precision@20: 0.004232
2025-11-22 22:44:24 - GraphTrainer - INFO -   recall@20: 0.080131
2025-11-22 22:44:24 - GraphTrainer - INFO -   hit_rate@20: 0.084186
2025-11-22 22:44:24 - GraphTrainer - INFO -   ndcg@20: 0.034478
2025-11-22 22:44:24 - GraphTrainer - INFO -   map@20: 0.021570
2025-11-22 22:44:24 - GraphTrainer - INFO -   mrr@20: 0.022527
2025-11-22 22:44:24 - GraphTrainer - INFO - 第 175 轮训练完成
2025-11-22 22:44:24 - GraphTrainer - INFO - train_loss: 0.333085
2025-11-22 22:44:24 - GraphTrainer - INFO - precision@5: 0.006788
2025-11-22 22:44:24 - GraphTrainer - INFO - recall@5: 0.032172
2025-11-22 22:44:24 - GraphTrainer - INFO - hit_rate@5: 0.033890
2025-11-22 22:44:24 - GraphTrainer - INFO - ndcg@5: 0.021146
2025-11-22 22:44:24 - GraphTrainer - INFO - map@5: 0.017269
2025-11-22 22:44:24 - GraphTrainer - INFO - mrr@5: 0.018024
2025-11-22 22:44:24 - GraphTrainer - INFO - precision@10: 0.005184
2025-11-22 22:44:24 - GraphTrainer - INFO - recall@10: 0.049108
2025-11-22 22:44:24 - GraphTrainer - INFO - hit_rate@10: 0.051684
2025-11-22 22:44:24 - GraphTrainer - INFO - ndcg@10: 0.026626
2025-11-22 22:44:24 - GraphTrainer - INFO - map@10: 0.019477
2025-11-22 22:44:24 - GraphTrainer - INFO - mrr@10: 0.020344
2025-11-22 22:44:24 - GraphTrainer - INFO - precision@20: 0.004232
2025-11-22 22:44:24 - GraphTrainer - INFO - recall@20: 0.080131
2025-11-22 22:44:24 - GraphTrainer - INFO - hit_rate@20: 0.084186
2025-11-22 22:44:24 - GraphTrainer - INFO - ndcg@20: 0.034478
2025-11-22 22:44:24 - GraphTrainer - INFO - map@20: 0.021570
2025-11-22 22:44:24 - GraphTrainer - INFO - mrr@20: 0.022527
2025-11-22 22:44:24 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:44:24 - GraphTrainer - INFO - ============================================================
2025-11-22 22:44:24 - GraphTrainer - INFO - 开始第 176/1000 轮训练
2025-11-22 22:44:24 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3545, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3276, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3241, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3197, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3161, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3312, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3260, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3302, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3177, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3175, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3210, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3098, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3220, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3313, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3279, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3105, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3273, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3276, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3179, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3516, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3126, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3279, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3248, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3156, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3468, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3598, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3582, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3189, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3166, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3232, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3225, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
The 175 training average loss: 0.3330847708315685
2025-11-22 22:44:35 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:44:35 - GraphTrainer - INFO -   precision@5: 0.006614
2025-11-22 22:44:35 - GraphTrainer - INFO -   recall@5: 0.031323
2025-11-22 22:44:35 - GraphTrainer - INFO -   hit_rate@5: 0.033016
2025-11-22 22:44:35 - GraphTrainer - INFO -   ndcg@5: 0.021015
2025-11-22 22:44:35 - GraphTrainer - INFO -   map@5: 0.017371
2025-11-22 22:44:35 - GraphTrainer - INFO -   mrr@5: 0.018104
2025-11-22 22:44:35 - GraphTrainer - INFO -   precision@10: 0.005256
2025-11-22 22:44:35 - GraphTrainer - INFO -   recall@10: 0.049901
2025-11-22 22:44:35 - GraphTrainer - INFO -   hit_rate@10: 0.052404
2025-11-22 22:44:35 - GraphTrainer - INFO -   ndcg@10: 0.026984
2025-11-22 22:44:35 - GraphTrainer - INFO -   map@10: 0.019760
2025-11-22 22:44:35 - GraphTrainer - INFO -   mrr@10: 0.020597
2025-11-22 22:44:35 - GraphTrainer - INFO -   precision@20: 0.004150
2025-11-22 22:44:35 - GraphTrainer - INFO -   recall@20: 0.078597
2025-11-22 22:44:35 - GraphTrainer - INFO -   hit_rate@20: 0.082489
2025-11-22 22:44:35 - GraphTrainer - INFO -   ndcg@20: 0.034255
2025-11-22 22:44:35 - GraphTrainer - INFO -   map@20: 0.021699
2025-11-22 22:44:35 - GraphTrainer - INFO -   mrr@20: 0.022624
2025-11-22 22:44:35 - GraphTrainer - INFO - 第 176 轮训练完成
2025-11-22 22:44:35 - GraphTrainer - INFO - train_loss: 0.331421
2025-11-22 22:44:35 - GraphTrainer - INFO - precision@5: 0.006614
2025-11-22 22:44:35 - GraphTrainer - INFO - recall@5: 0.031323
2025-11-22 22:44:35 - GraphTrainer - INFO - hit_rate@5: 0.033016
2025-11-22 22:44:35 - GraphTrainer - INFO - ndcg@5: 0.021015
2025-11-22 22:44:35 - GraphTrainer - INFO - map@5: 0.017371
2025-11-22 22:44:35 - GraphTrainer - INFO - mrr@5: 0.018104
2025-11-22 22:44:35 - GraphTrainer - INFO - precision@10: 0.005256
2025-11-22 22:44:35 - GraphTrainer - INFO - recall@10: 0.049901
2025-11-22 22:44:35 - GraphTrainer - INFO - hit_rate@10: 0.052404
2025-11-22 22:44:35 - GraphTrainer - INFO - ndcg@10: 0.026984
2025-11-22 22:44:35 - GraphTrainer - INFO - map@10: 0.019760
2025-11-22 22:44:35 - GraphTrainer - INFO - mrr@10: 0.020597
2025-11-22 22:44:35 - GraphTrainer - INFO - precision@20: 0.004150
2025-11-22 22:44:35 - GraphTrainer - INFO - recall@20: 0.078597
2025-11-22 22:44:35 - GraphTrainer - INFO - hit_rate@20: 0.082489
2025-11-22 22:44:35 - GraphTrainer - INFO - ndcg@20: 0.034255
2025-11-22 22:44:35 - GraphTrainer - INFO - map@20: 0.021699
2025-11-22 22:44:35 - GraphTrainer - INFO - mrr@20: 0.022624
2025-11-22 22:44:35 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:44:35 - GraphTrainer - INFO - ============================================================
2025-11-22 22:44:35 - GraphTrainer - INFO - 开始第 177/1000 轮训练
2025-11-22 22:44:35 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3262, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3189, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3081, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3233, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3296, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3288, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3176, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3457, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3273, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3241, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3342, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3571, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3262, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3218, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3166, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3189, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3128, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3252, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3202, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3202, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3316, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3211, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3175, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3232, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3197, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
The 176 training average loss: 0.33142064820075856
2025-11-22 22:44:46 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:44:46 - GraphTrainer - INFO -   precision@5: 0.006583
2025-11-22 22:44:46 - GraphTrainer - INFO -   recall@5: 0.031143
2025-11-22 22:44:46 - GraphTrainer - INFO -   hit_rate@5: 0.032913
2025-11-22 22:44:46 - GraphTrainer - INFO -   ndcg@5: 0.020336
2025-11-22 22:44:46 - GraphTrainer - INFO -   map@5: 0.016533
2025-11-22 22:44:46 - GraphTrainer - INFO -   mrr@5: 0.017196
2025-11-22 22:44:46 - GraphTrainer - INFO -   precision@10: 0.005055
2025-11-22 22:44:46 - GraphTrainer - INFO -   recall@10: 0.048003
2025-11-22 22:44:46 - GraphTrainer - INFO -   hit_rate@10: 0.050501
2025-11-22 22:44:46 - GraphTrainer - INFO -   ndcg@10: 0.025831
2025-11-22 22:44:46 - GraphTrainer - INFO -   map@10: 0.018782
2025-11-22 22:44:46 - GraphTrainer - INFO -   mrr@10: 0.019537
2025-11-22 22:44:46 - GraphTrainer - INFO -   precision@20: 0.004217
2025-11-22 22:44:46 - GraphTrainer - INFO -   recall@20: 0.079842
2025-11-22 22:44:46 - GraphTrainer - INFO -   hit_rate@20: 0.083878
2025-11-22 22:44:46 - GraphTrainer - INFO -   ndcg@20: 0.033924
2025-11-22 22:44:46 - GraphTrainer - INFO -   map@20: 0.020954
2025-11-22 22:44:46 - GraphTrainer - INFO -   mrr@20: 0.021802
2025-11-22 22:44:46 - GraphTrainer - INFO - 第 177 轮训练完成
2025-11-22 22:44:46 - GraphTrainer - INFO - train_loss: 0.333789
2025-11-22 22:44:46 - GraphTrainer - INFO - precision@5: 0.006583
2025-11-22 22:44:46 - GraphTrainer - INFO - recall@5: 0.031143
2025-11-22 22:44:46 - GraphTrainer - INFO - hit_rate@5: 0.032913
2025-11-22 22:44:46 - GraphTrainer - INFO - ndcg@5: 0.020336
2025-11-22 22:44:46 - GraphTrainer - INFO - map@5: 0.016533
2025-11-22 22:44:46 - GraphTrainer - INFO - mrr@5: 0.017196
2025-11-22 22:44:46 - GraphTrainer - INFO - precision@10: 0.005055
2025-11-22 22:44:46 - GraphTrainer - INFO - recall@10: 0.048003
2025-11-22 22:44:46 - GraphTrainer - INFO - hit_rate@10: 0.050501
2025-11-22 22:44:46 - GraphTrainer - INFO - ndcg@10: 0.025831
2025-11-22 22:44:46 - GraphTrainer - INFO - map@10: 0.018782
2025-11-22 22:44:46 - GraphTrainer - INFO - mrr@10: 0.019537
2025-11-22 22:44:46 - GraphTrainer - INFO - precision@20: 0.004217
2025-11-22 22:44:46 - GraphTrainer - INFO - recall@20: 0.079842
2025-11-22 22:44:46 - GraphTrainer - INFO - hit_rate@20: 0.083878
2025-11-22 22:44:46 - GraphTrainer - INFO - ndcg@20: 0.033924
2025-11-22 22:44:46 - GraphTrainer - INFO - map@20: 0.020954
2025-11-22 22:44:46 - GraphTrainer - INFO - mrr@20: 0.021802
2025-11-22 22:44:46 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:44:46 - GraphTrainer - INFO - ============================================================
2025-11-22 22:44:46 - GraphTrainer - INFO - 开始第 178/1000 轮训练
2025-11-22 22:44:46 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3079, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3278, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3313, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3225, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3256, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3174, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3164, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3457, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3473, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3551, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3435, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3316, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3199, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3173, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3373, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3158, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3149, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3191, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3435, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3090, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3216, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3117, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3198, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3142, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3588, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
The 177 training average loss: 0.33378942516343346
2025-11-22 22:44:58 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:44:58 - GraphTrainer - INFO -   precision@5: 0.006562
2025-11-22 22:44:58 - GraphTrainer - INFO -   recall@5: 0.031123
2025-11-22 22:44:58 - GraphTrainer - INFO -   hit_rate@5: 0.032759
2025-11-22 22:44:58 - GraphTrainer - INFO -   ndcg@5: 0.020323
2025-11-22 22:44:58 - GraphTrainer - INFO -   map@5: 0.016520
2025-11-22 22:44:58 - GraphTrainer - INFO -   mrr@5: 0.017223
2025-11-22 22:44:58 - GraphTrainer - INFO -   precision@10: 0.005266
2025-11-22 22:44:58 - GraphTrainer - INFO -   recall@10: 0.050068
2025-11-22 22:44:58 - GraphTrainer - INFO -   hit_rate@10: 0.052558
2025-11-22 22:44:58 - GraphTrainer - INFO -   ndcg@10: 0.026464
2025-11-22 22:44:58 - GraphTrainer - INFO -   map@10: 0.019009
2025-11-22 22:44:58 - GraphTrainer - INFO -   mrr@10: 0.019824
2025-11-22 22:44:58 - GraphTrainer - INFO -   precision@20: 0.004217
2025-11-22 22:44:58 - GraphTrainer - INFO -   recall@20: 0.079857
2025-11-22 22:44:58 - GraphTrainer - INFO -   hit_rate@20: 0.083826
2025-11-22 22:44:58 - GraphTrainer - INFO -   ndcg@20: 0.034003
2025-11-22 22:44:58 - GraphTrainer - INFO -   map@20: 0.021013
2025-11-22 22:44:58 - GraphTrainer - INFO -   mrr@20: 0.021917
2025-11-22 22:44:58 - GraphTrainer - INFO - 第 178 轮训练完成
2025-11-22 22:44:58 - GraphTrainer - INFO - train_loss: 0.330731
2025-11-22 22:44:58 - GraphTrainer - INFO - precision@5: 0.006562
2025-11-22 22:44:58 - GraphTrainer - INFO - recall@5: 0.031123
2025-11-22 22:44:58 - GraphTrainer - INFO - hit_rate@5: 0.032759
2025-11-22 22:44:58 - GraphTrainer - INFO - ndcg@5: 0.020323
2025-11-22 22:44:58 - GraphTrainer - INFO - map@5: 0.016520
2025-11-22 22:44:58 - GraphTrainer - INFO - mrr@5: 0.017223
2025-11-22 22:44:58 - GraphTrainer - INFO - precision@10: 0.005266
2025-11-22 22:44:58 - GraphTrainer - INFO - recall@10: 0.050068
2025-11-22 22:44:58 - GraphTrainer - INFO - hit_rate@10: 0.052558
2025-11-22 22:44:58 - GraphTrainer - INFO - ndcg@10: 0.026464
2025-11-22 22:44:58 - GraphTrainer - INFO - map@10: 0.019009
2025-11-22 22:44:58 - GraphTrainer - INFO - mrr@10: 0.019824
2025-11-22 22:44:58 - GraphTrainer - INFO - precision@20: 0.004217
2025-11-22 22:44:58 - GraphTrainer - INFO - recall@20: 0.079857
2025-11-22 22:44:58 - GraphTrainer - INFO - hit_rate@20: 0.083826
2025-11-22 22:44:58 - GraphTrainer - INFO - ndcg@20: 0.034003
2025-11-22 22:44:58 - GraphTrainer - INFO - map@20: 0.021013
2025-11-22 22:44:58 - GraphTrainer - INFO - mrr@20: 0.021917
2025-11-22 22:44:58 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:44:58 - GraphTrainer - INFO - ============================================================
2025-11-22 22:44:58 - GraphTrainer - INFO - 开始第 179/1000 轮训练
2025-11-22 22:44:58 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3237, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3532, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3245, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3204, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3479, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3161, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3107, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3077, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3093, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3571, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3195, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3480, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3303, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3303, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3122, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3151, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3090, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3342, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3105, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3102, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3306, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3232, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3252, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3223, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3170, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3154, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3235, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3494, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3126, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3379, device='cuda:0', grad_fn=<AddBackward0>)
The 178 training average loss: 0.33073082720411234
2025-11-22 22:45:09 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:45:09 - GraphTrainer - INFO -   precision@5: 0.006727
2025-11-22 22:45:09 - GraphTrainer - INFO -   recall@5: 0.032164
2025-11-22 22:45:09 - GraphTrainer - INFO -   hit_rate@5: 0.033582
2025-11-22 22:45:09 - GraphTrainer - INFO -   ndcg@5: 0.020851
2025-11-22 22:45:09 - GraphTrainer - INFO -   map@5: 0.016897
2025-11-22 22:45:09 - GraphTrainer - INFO -   mrr@5: 0.017632
2025-11-22 22:45:09 - GraphTrainer - INFO -   precision@10: 0.005333
2025-11-22 22:45:09 - GraphTrainer - INFO -   recall@10: 0.050693
2025-11-22 22:45:09 - GraphTrainer - INFO -   hit_rate@10: 0.053227
2025-11-22 22:45:09 - GraphTrainer - INFO -   ndcg@10: 0.026806
2025-11-22 22:45:09 - GraphTrainer - INFO -   map@10: 0.019262
2025-11-22 22:45:09 - GraphTrainer - INFO -   mrr@10: 0.020147
2025-11-22 22:45:09 - GraphTrainer - INFO -   precision@20: 0.004178
2025-11-22 22:45:09 - GraphTrainer - INFO -   recall@20: 0.079222
2025-11-22 22:45:09 - GraphTrainer - INFO -   hit_rate@20: 0.083158
2025-11-22 22:45:09 - GraphTrainer - INFO -   ndcg@20: 0.034040
2025-11-22 22:45:09 - GraphTrainer - INFO -   map@20: 0.021194
2025-11-22 22:45:09 - GraphTrainer - INFO -   mrr@20: 0.022168
2025-11-22 22:45:09 - GraphTrainer - INFO - 第 179 轮训练完成
2025-11-22 22:45:09 - GraphTrainer - INFO - train_loss: 0.329399
2025-11-22 22:45:09 - GraphTrainer - INFO - precision@5: 0.006727
2025-11-22 22:45:09 - GraphTrainer - INFO - recall@5: 0.032164
2025-11-22 22:45:09 - GraphTrainer - INFO - hit_rate@5: 0.033582
2025-11-22 22:45:09 - GraphTrainer - INFO - ndcg@5: 0.020851
2025-11-22 22:45:09 - GraphTrainer - INFO - map@5: 0.016897
2025-11-22 22:45:09 - GraphTrainer - INFO - mrr@5: 0.017632
2025-11-22 22:45:09 - GraphTrainer - INFO - precision@10: 0.005333
2025-11-22 22:45:09 - GraphTrainer - INFO - recall@10: 0.050693
2025-11-22 22:45:09 - GraphTrainer - INFO - hit_rate@10: 0.053227
2025-11-22 22:45:09 - GraphTrainer - INFO - ndcg@10: 0.026806
2025-11-22 22:45:09 - GraphTrainer - INFO - map@10: 0.019262
2025-11-22 22:45:09 - GraphTrainer - INFO - mrr@10: 0.020147
2025-11-22 22:45:09 - GraphTrainer - INFO - precision@20: 0.004178
2025-11-22 22:45:09 - GraphTrainer - INFO - recall@20: 0.079222
2025-11-22 22:45:09 - GraphTrainer - INFO - hit_rate@20: 0.083158
2025-11-22 22:45:09 - GraphTrainer - INFO - ndcg@20: 0.034040
2025-11-22 22:45:09 - GraphTrainer - INFO - map@20: 0.021194
2025-11-22 22:45:09 - GraphTrainer - INFO - mrr@20: 0.022168
2025-11-22 22:45:09 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:45:09 - GraphTrainer - INFO - ============================================================
2025-11-22 22:45:09 - GraphTrainer - INFO - 开始第 180/1000 轮训练
2025-11-22 22:45:09 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3114, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3112, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3256, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3290, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3297, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3185, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3120, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3136, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2918, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3525, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3299, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3509, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3155, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3237, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3077, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3223, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3309, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3710, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3227, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3473, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3233, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3131, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3223, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3231, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3227, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3147, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3566, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3118, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3296, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3282, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3026, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3231, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3303, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3151, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3303, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
The 179 training average loss: 0.3293992358035055
2025-11-22 22:45:20 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:45:20 - GraphTrainer - INFO -   precision@5: 0.006572
2025-11-22 22:45:20 - GraphTrainer - INFO -   recall@5: 0.031220
2025-11-22 22:45:20 - GraphTrainer - INFO -   hit_rate@5: 0.032810
2025-11-22 22:45:20 - GraphTrainer - INFO -   ndcg@5: 0.020797
2025-11-22 22:45:20 - GraphTrainer - INFO -   map@5: 0.017113
2025-11-22 22:45:20 - GraphTrainer - INFO -   mrr@5: 0.017832
2025-11-22 22:45:20 - GraphTrainer - INFO -   precision@10: 0.005204
2025-11-22 22:45:20 - GraphTrainer - INFO -   recall@10: 0.049322
2025-11-22 22:45:20 - GraphTrainer - INFO -   hit_rate@10: 0.051890
2025-11-22 22:45:20 - GraphTrainer - INFO -   ndcg@10: 0.026702
2025-11-22 22:45:20 - GraphTrainer - INFO -   map@10: 0.019517
2025-11-22 22:45:20 - GraphTrainer - INFO -   mrr@10: 0.020362
2025-11-22 22:45:20 - GraphTrainer - INFO -   precision@20: 0.004166
2025-11-22 22:45:20 - GraphTrainer - INFO -   recall@20: 0.078817
2025-11-22 22:45:20 - GraphTrainer - INFO -   hit_rate@20: 0.082798
2025-11-22 22:45:20 - GraphTrainer - INFO -   ndcg@20: 0.034179
2025-11-22 22:45:20 - GraphTrainer - INFO -   map@20: 0.021516
2025-11-22 22:45:20 - GraphTrainer - INFO -   mrr@20: 0.022448
2025-11-22 22:45:20 - GraphTrainer - INFO - 第 180 轮训练完成
2025-11-22 22:45:20 - GraphTrainer - INFO - train_loss: 0.331951
2025-11-22 22:45:20 - GraphTrainer - INFO - precision@5: 0.006572
2025-11-22 22:45:20 - GraphTrainer - INFO - recall@5: 0.031220
2025-11-22 22:45:20 - GraphTrainer - INFO - hit_rate@5: 0.032810
2025-11-22 22:45:20 - GraphTrainer - INFO - ndcg@5: 0.020797
2025-11-22 22:45:20 - GraphTrainer - INFO - map@5: 0.017113
2025-11-22 22:45:20 - GraphTrainer - INFO - mrr@5: 0.017832
2025-11-22 22:45:20 - GraphTrainer - INFO - precision@10: 0.005204
2025-11-22 22:45:20 - GraphTrainer - INFO - recall@10: 0.049322
2025-11-22 22:45:20 - GraphTrainer - INFO - hit_rate@10: 0.051890
2025-11-22 22:45:20 - GraphTrainer - INFO - ndcg@10: 0.026702
2025-11-22 22:45:20 - GraphTrainer - INFO - map@10: 0.019517
2025-11-22 22:45:20 - GraphTrainer - INFO - mrr@10: 0.020362
2025-11-22 22:45:20 - GraphTrainer - INFO - precision@20: 0.004166
2025-11-22 22:45:20 - GraphTrainer - INFO - recall@20: 0.078817
2025-11-22 22:45:20 - GraphTrainer - INFO - hit_rate@20: 0.082798
2025-11-22 22:45:20 - GraphTrainer - INFO - ndcg@20: 0.034179
2025-11-22 22:45:20 - GraphTrainer - INFO - map@20: 0.021516
2025-11-22 22:45:20 - GraphTrainer - INFO - mrr@20: 0.022448
2025-11-22 22:45:20 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:45:20 - GraphTrainer - INFO - 检查点已保存: Epoch 180 -> ./checkpoints/checkpoint_epoch_180.pth
2025-11-22 22:45:20 - GraphTrainer - INFO - ============================================================
2025-11-22 22:45:20 - GraphTrainer - INFO - 开始第 181/1000 轮训练
2025-11-22 22:45:20 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3261, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3165, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3582, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3259, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3089, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3232, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3274, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3067, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3379, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3235, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3055, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3536, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3628, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3144, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3142, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3566, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3244, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3152, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3249, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3212, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3120, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3556, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3086, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3184, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3249, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3244, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
The 180 training average loss: 0.3319513972463279
2025-11-22 22:45:31 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:45:31 - GraphTrainer - INFO -   precision@5: 0.006686
2025-11-22 22:45:31 - GraphTrainer - INFO -   recall@5: 0.031680
2025-11-22 22:45:31 - GraphTrainer - INFO -   hit_rate@5: 0.033376
2025-11-22 22:45:31 - GraphTrainer - INFO -   ndcg@5: 0.021011
2025-11-22 22:45:31 - GraphTrainer - INFO -   map@5: 0.017248
2025-11-22 22:45:31 - GraphTrainer - INFO -   mrr@5: 0.017954
2025-11-22 22:45:31 - GraphTrainer - INFO -   precision@10: 0.005292
2025-11-22 22:45:31 - GraphTrainer - INFO -   recall@10: 0.050155
2025-11-22 22:45:31 - GraphTrainer - INFO -   hit_rate@10: 0.052764
2025-11-22 22:45:31 - GraphTrainer - INFO -   ndcg@10: 0.027002
2025-11-22 22:45:31 - GraphTrainer - INFO -   map@10: 0.019671
2025-11-22 22:45:31 - GraphTrainer - INFO -   mrr@10: 0.020496
2025-11-22 22:45:31 - GraphTrainer - INFO -   precision@20: 0.004135
2025-11-22 22:45:31 - GraphTrainer - INFO -   recall@20: 0.078230
2025-11-22 22:45:31 - GraphTrainer - INFO -   hit_rate@20: 0.082232
2025-11-22 22:45:31 - GraphTrainer - INFO -   ndcg@20: 0.034131
2025-11-22 22:45:31 - GraphTrainer - INFO -   map@20: 0.021580
2025-11-22 22:45:31 - GraphTrainer - INFO -   mrr@20: 0.022494
2025-11-22 22:45:31 - GraphTrainer - INFO - 第 181 轮训练完成
2025-11-22 22:45:31 - GraphTrainer - INFO - train_loss: 0.329377
2025-11-22 22:45:31 - GraphTrainer - INFO - precision@5: 0.006686
2025-11-22 22:45:31 - GraphTrainer - INFO - recall@5: 0.031680
2025-11-22 22:45:31 - GraphTrainer - INFO - hit_rate@5: 0.033376
2025-11-22 22:45:31 - GraphTrainer - INFO - ndcg@5: 0.021011
2025-11-22 22:45:31 - GraphTrainer - INFO - map@5: 0.017248
2025-11-22 22:45:31 - GraphTrainer - INFO - mrr@5: 0.017954
2025-11-22 22:45:31 - GraphTrainer - INFO - precision@10: 0.005292
2025-11-22 22:45:31 - GraphTrainer - INFO - recall@10: 0.050155
2025-11-22 22:45:31 - GraphTrainer - INFO - hit_rate@10: 0.052764
2025-11-22 22:45:31 - GraphTrainer - INFO - ndcg@10: 0.027002
2025-11-22 22:45:31 - GraphTrainer - INFO - map@10: 0.019671
2025-11-22 22:45:31 - GraphTrainer - INFO - mrr@10: 0.020496
2025-11-22 22:45:31 - GraphTrainer - INFO - precision@20: 0.004135
2025-11-22 22:45:31 - GraphTrainer - INFO - recall@20: 0.078230
2025-11-22 22:45:31 - GraphTrainer - INFO - hit_rate@20: 0.082232
2025-11-22 22:45:31 - GraphTrainer - INFO - ndcg@20: 0.034131
2025-11-22 22:45:31 - GraphTrainer - INFO - map@20: 0.021580
2025-11-22 22:45:31 - GraphTrainer - INFO - mrr@20: 0.022494
2025-11-22 22:45:31 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:45:31 - GraphTrainer - INFO - ============================================================
2025-11-22 22:45:31 - GraphTrainer - INFO - 开始第 182/1000 轮训练
2025-11-22 22:45:31 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3248, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3435, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3204, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3127, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3067, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3082, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3191, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3187, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3604, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3178, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3105, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3206, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3195, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3185, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3186, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3186, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3299, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3208, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3128, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3076, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3187, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3544, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3166, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3158, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3282, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3297, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3179, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3186, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3188, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
The 181 training average loss: 0.3293773028357276
2025-11-22 22:45:42 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:45:42 - GraphTrainer - INFO -   precision@5: 0.006603
2025-11-22 22:45:42 - GraphTrainer - INFO -   recall@5: 0.031380
2025-11-22 22:45:42 - GraphTrainer - INFO -   hit_rate@5: 0.032965
2025-11-22 22:45:42 - GraphTrainer - INFO -   ndcg@5: 0.020629
2025-11-22 22:45:42 - GraphTrainer - INFO -   map@5: 0.016835
2025-11-22 22:45:42 - GraphTrainer - INFO -   mrr@5: 0.017588
2025-11-22 22:45:42 - GraphTrainer - INFO -   precision@10: 0.005292
2025-11-22 22:45:42 - GraphTrainer - INFO -   recall@10: 0.050145
2025-11-22 22:45:42 - GraphTrainer - INFO -   hit_rate@10: 0.052713
2025-11-22 22:45:42 - GraphTrainer - INFO -   ndcg@10: 0.026710
2025-11-22 22:45:42 - GraphTrainer - INFO -   map@10: 0.019289
2025-11-22 22:45:42 - GraphTrainer - INFO -   mrr@10: 0.020167
2025-11-22 22:45:42 - GraphTrainer - INFO -   precision@20: 0.004132
2025-11-22 22:45:42 - GraphTrainer - INFO -   recall@20: 0.078226
2025-11-22 22:45:42 - GraphTrainer - INFO -   hit_rate@20: 0.082129
2025-11-22 22:45:42 - GraphTrainer - INFO -   ndcg@20: 0.033840
2025-11-22 22:45:42 - GraphTrainer - INFO -   map@20: 0.021200
2025-11-22 22:45:42 - GraphTrainer - INFO -   mrr@20: 0.022164
2025-11-22 22:45:42 - GraphTrainer - INFO - 第 182 轮训练完成
2025-11-22 22:45:42 - GraphTrainer - INFO - train_loss: 0.329646
2025-11-22 22:45:42 - GraphTrainer - INFO - precision@5: 0.006603
2025-11-22 22:45:42 - GraphTrainer - INFO - recall@5: 0.031380
2025-11-22 22:45:42 - GraphTrainer - INFO - hit_rate@5: 0.032965
2025-11-22 22:45:42 - GraphTrainer - INFO - ndcg@5: 0.020629
2025-11-22 22:45:42 - GraphTrainer - INFO - map@5: 0.016835
2025-11-22 22:45:42 - GraphTrainer - INFO - mrr@5: 0.017588
2025-11-22 22:45:42 - GraphTrainer - INFO - precision@10: 0.005292
2025-11-22 22:45:42 - GraphTrainer - INFO - recall@10: 0.050145
2025-11-22 22:45:42 - GraphTrainer - INFO - hit_rate@10: 0.052713
2025-11-22 22:45:42 - GraphTrainer - INFO - ndcg@10: 0.026710
2025-11-22 22:45:42 - GraphTrainer - INFO - map@10: 0.019289
2025-11-22 22:45:42 - GraphTrainer - INFO - mrr@10: 0.020167
2025-11-22 22:45:42 - GraphTrainer - INFO - precision@20: 0.004132
2025-11-22 22:45:42 - GraphTrainer - INFO - recall@20: 0.078226
2025-11-22 22:45:42 - GraphTrainer - INFO - hit_rate@20: 0.082129
2025-11-22 22:45:42 - GraphTrainer - INFO - ndcg@20: 0.033840
2025-11-22 22:45:42 - GraphTrainer - INFO - map@20: 0.021200
2025-11-22 22:45:42 - GraphTrainer - INFO - mrr@20: 0.022164
2025-11-22 22:45:42 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:45:42 - GraphTrainer - INFO - ============================================================
2025-11-22 22:45:42 - GraphTrainer - INFO - 开始第 183/1000 轮训练
2025-11-22 22:45:42 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3240, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3268, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3421, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3236, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3156, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3123, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3225, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3188, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3293, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3302, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3636, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3091, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3206, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3379, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3115, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3421, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3156, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2994, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3140, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3137, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3136, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3094, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3531, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3069, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3201, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3186, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3217, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3150, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3272, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3529, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3181, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3282, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3237, device='cuda:0', grad_fn=<AddBackward0>)
The 182 training average loss: 0.3296458577287608
2025-11-22 22:45:53 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:45:53 - GraphTrainer - INFO -   precision@5: 0.006686
2025-11-22 22:45:53 - GraphTrainer - INFO -   recall@5: 0.031667
2025-11-22 22:45:53 - GraphTrainer - INFO -   hit_rate@5: 0.033376
2025-11-22 22:45:53 - GraphTrainer - INFO -   ndcg@5: 0.020912
2025-11-22 22:45:53 - GraphTrainer - INFO -   map@5: 0.017102
2025-11-22 22:45:53 - GraphTrainer - INFO -   mrr@5: 0.017836
2025-11-22 22:45:53 - GraphTrainer - INFO -   precision@10: 0.005276
2025-11-22 22:45:53 - GraphTrainer - INFO -   recall@10: 0.050112
2025-11-22 22:45:53 - GraphTrainer - INFO -   hit_rate@10: 0.052610
2025-11-22 22:45:53 - GraphTrainer - INFO -   ndcg@10: 0.026874
2025-11-22 22:45:53 - GraphTrainer - INFO -   map@10: 0.019510
2025-11-22 22:45:53 - GraphTrainer - INFO -   mrr@10: 0.020351
2025-11-22 22:45:53 - GraphTrainer - INFO -   precision@20: 0.004186
2025-11-22 22:45:53 - GraphTrainer - INFO -   recall@20: 0.079185
2025-11-22 22:45:53 - GraphTrainer - INFO -   hit_rate@20: 0.083209
2025-11-22 22:45:53 - GraphTrainer - INFO -   ndcg@20: 0.034232
2025-11-22 22:45:53 - GraphTrainer - INFO -   map@20: 0.021463
2025-11-22 22:45:53 - GraphTrainer - INFO -   mrr@20: 0.022402
2025-11-22 22:45:53 - GraphTrainer - INFO - 第 183 轮训练完成
2025-11-22 22:45:53 - GraphTrainer - INFO - train_loss: 0.330537
2025-11-22 22:45:53 - GraphTrainer - INFO - precision@5: 0.006686
2025-11-22 22:45:53 - GraphTrainer - INFO - recall@5: 0.031667
2025-11-22 22:45:53 - GraphTrainer - INFO - hit_rate@5: 0.033376
2025-11-22 22:45:53 - GraphTrainer - INFO - ndcg@5: 0.020912
2025-11-22 22:45:53 - GraphTrainer - INFO - map@5: 0.017102
2025-11-22 22:45:53 - GraphTrainer - INFO - mrr@5: 0.017836
2025-11-22 22:45:53 - GraphTrainer - INFO - precision@10: 0.005276
2025-11-22 22:45:53 - GraphTrainer - INFO - recall@10: 0.050112
2025-11-22 22:45:53 - GraphTrainer - INFO - hit_rate@10: 0.052610
2025-11-22 22:45:53 - GraphTrainer - INFO - ndcg@10: 0.026874
2025-11-22 22:45:53 - GraphTrainer - INFO - map@10: 0.019510
2025-11-22 22:45:53 - GraphTrainer - INFO - mrr@10: 0.020351
2025-11-22 22:45:53 - GraphTrainer - INFO - precision@20: 0.004186
2025-11-22 22:45:53 - GraphTrainer - INFO - recall@20: 0.079185
2025-11-22 22:45:53 - GraphTrainer - INFO - hit_rate@20: 0.083209
2025-11-22 22:45:53 - GraphTrainer - INFO - ndcg@20: 0.034232
2025-11-22 22:45:53 - GraphTrainer - INFO - map@20: 0.021463
2025-11-22 22:45:53 - GraphTrainer - INFO - mrr@20: 0.022402
2025-11-22 22:45:53 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:45:53 - GraphTrainer - INFO - ============================================================
2025-11-22 22:45:53 - GraphTrainer - INFO - 开始第 184/1000 轮训练
2025-11-22 22:45:53 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3164, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3244, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3318, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3192, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3147, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3559, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3103, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3512, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3237, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3296, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3518, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3111, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3136, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3244, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3106, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3433, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3556, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3190, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3278, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3148, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3282, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3184, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3281, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3208, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3082, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3259, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3142, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3204, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
The 183 training average loss: 0.3305373155865176
2025-11-22 22:46:04 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:46:04 - GraphTrainer - INFO -   precision@5: 0.006593
2025-11-22 22:46:04 - GraphTrainer - INFO -   recall@5: 0.031329
2025-11-22 22:46:04 - GraphTrainer - INFO -   hit_rate@5: 0.032913
2025-11-22 22:46:04 - GraphTrainer - INFO -   ndcg@5: 0.020679
2025-11-22 22:46:04 - GraphTrainer - INFO -   map@5: 0.016924
2025-11-22 22:46:04 - GraphTrainer - INFO -   mrr@5: 0.017621
2025-11-22 22:46:04 - GraphTrainer - INFO -   precision@10: 0.005271
2025-11-22 22:46:04 - GraphTrainer - INFO -   recall@10: 0.049956
2025-11-22 22:46:04 - GraphTrainer - INFO -   hit_rate@10: 0.052558
2025-11-22 22:46:04 - GraphTrainer - INFO -   ndcg@10: 0.026734
2025-11-22 22:46:04 - GraphTrainer - INFO -   map@10: 0.019378
2025-11-22 22:46:04 - GraphTrainer - INFO -   mrr@10: 0.020208
2025-11-22 22:46:04 - GraphTrainer - INFO -   precision@20: 0.004178
2025-11-22 22:46:04 - GraphTrainer - INFO -   recall@20: 0.078961
2025-11-22 22:46:04 - GraphTrainer - INFO -   hit_rate@20: 0.083055
2025-11-22 22:46:04 - GraphTrainer - INFO -   ndcg@20: 0.034110
2025-11-22 22:46:04 - GraphTrainer - INFO -   map@20: 0.021354
2025-11-22 22:46:04 - GraphTrainer - INFO -   mrr@20: 0.022277
2025-11-22 22:46:04 - GraphTrainer - INFO - 第 184 轮训练完成
2025-11-22 22:46:04 - GraphTrainer - INFO - train_loss: 0.328903
2025-11-22 22:46:04 - GraphTrainer - INFO - precision@5: 0.006593
2025-11-22 22:46:04 - GraphTrainer - INFO - recall@5: 0.031329
2025-11-22 22:46:04 - GraphTrainer - INFO - hit_rate@5: 0.032913
2025-11-22 22:46:04 - GraphTrainer - INFO - ndcg@5: 0.020679
2025-11-22 22:46:04 - GraphTrainer - INFO - map@5: 0.016924
2025-11-22 22:46:04 - GraphTrainer - INFO - mrr@5: 0.017621
2025-11-22 22:46:04 - GraphTrainer - INFO - precision@10: 0.005271
2025-11-22 22:46:04 - GraphTrainer - INFO - recall@10: 0.049956
2025-11-22 22:46:04 - GraphTrainer - INFO - hit_rate@10: 0.052558
2025-11-22 22:46:04 - GraphTrainer - INFO - ndcg@10: 0.026734
2025-11-22 22:46:04 - GraphTrainer - INFO - map@10: 0.019378
2025-11-22 22:46:04 - GraphTrainer - INFO - mrr@10: 0.020208
2025-11-22 22:46:04 - GraphTrainer - INFO - precision@20: 0.004178
2025-11-22 22:46:04 - GraphTrainer - INFO - recall@20: 0.078961
2025-11-22 22:46:04 - GraphTrainer - INFO - hit_rate@20: 0.083055
2025-11-22 22:46:04 - GraphTrainer - INFO - ndcg@20: 0.034110
2025-11-22 22:46:04 - GraphTrainer - INFO - map@20: 0.021354
2025-11-22 22:46:04 - GraphTrainer - INFO - mrr@20: 0.022277
2025-11-22 22:46:04 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:46:04 - GraphTrainer - INFO - ============================================================
2025-11-22 22:46:04 - GraphTrainer - INFO - 开始第 185/1000 轮训练
2025-11-22 22:46:04 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3110, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3252, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3379, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3160, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3241, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3221, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3213, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2992, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3085, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3197, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3194, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3110, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3302, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3603, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3170, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3150, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3529, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3304, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3225, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3563, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3279, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3106, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2997, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3179, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3466, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3134, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3240, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3228, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3245, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3302, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3213, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3044, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3434, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3061, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3248, device='cuda:0', grad_fn=<AddBackward0>)
The 184 training average loss: 0.32890281081199646
2025-11-22 22:46:16 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:46:16 - GraphTrainer - INFO -   precision@5: 0.006634
2025-11-22 22:46:16 - GraphTrainer - INFO -   recall@5: 0.031556
2025-11-22 22:46:16 - GraphTrainer - INFO -   hit_rate@5: 0.033119
2025-11-22 22:46:16 - GraphTrainer - INFO -   ndcg@5: 0.020816
2025-11-22 22:46:16 - GraphTrainer - INFO -   map@5: 0.017029
2025-11-22 22:46:16 - GraphTrainer - INFO -   mrr@5: 0.017727
2025-11-22 22:46:16 - GraphTrainer - INFO -   precision@10: 0.005225
2025-11-22 22:46:16 - GraphTrainer - INFO -   recall@10: 0.049512
2025-11-22 22:46:16 - GraphTrainer - INFO -   hit_rate@10: 0.052096
2025-11-22 22:46:16 - GraphTrainer - INFO -   ndcg@10: 0.026637
2025-11-22 22:46:16 - GraphTrainer - INFO -   map@10: 0.019373
2025-11-22 22:46:16 - GraphTrainer - INFO -   mrr@10: 0.020210
2025-11-22 22:46:16 - GraphTrainer - INFO -   precision@20: 0.004214
2025-11-22 22:46:16 - GraphTrainer - INFO -   recall@20: 0.079865
2025-11-22 22:46:16 - GraphTrainer - INFO -   hit_rate@20: 0.083775
2025-11-22 22:46:16 - GraphTrainer - INFO -   ndcg@20: 0.034336
2025-11-22 22:46:16 - GraphTrainer - INFO -   map@20: 0.021438
2025-11-22 22:46:16 - GraphTrainer - INFO -   mrr@20: 0.022358
2025-11-22 22:46:16 - GraphTrainer - INFO - 第 185 轮训练完成
2025-11-22 22:46:16 - GraphTrainer - INFO - train_loss: 0.328694
2025-11-22 22:46:16 - GraphTrainer - INFO - precision@5: 0.006634
2025-11-22 22:46:16 - GraphTrainer - INFO - recall@5: 0.031556
2025-11-22 22:46:16 - GraphTrainer - INFO - hit_rate@5: 0.033119
2025-11-22 22:46:16 - GraphTrainer - INFO - ndcg@5: 0.020816
2025-11-22 22:46:16 - GraphTrainer - INFO - map@5: 0.017029
2025-11-22 22:46:16 - GraphTrainer - INFO - mrr@5: 0.017727
2025-11-22 22:46:16 - GraphTrainer - INFO - precision@10: 0.005225
2025-11-22 22:46:16 - GraphTrainer - INFO - recall@10: 0.049512
2025-11-22 22:46:16 - GraphTrainer - INFO - hit_rate@10: 0.052096
2025-11-22 22:46:16 - GraphTrainer - INFO - ndcg@10: 0.026637
2025-11-22 22:46:16 - GraphTrainer - INFO - map@10: 0.019373
2025-11-22 22:46:16 - GraphTrainer - INFO - mrr@10: 0.020210
2025-11-22 22:46:16 - GraphTrainer - INFO - precision@20: 0.004214
2025-11-22 22:46:16 - GraphTrainer - INFO - recall@20: 0.079865
2025-11-22 22:46:16 - GraphTrainer - INFO - hit_rate@20: 0.083775
2025-11-22 22:46:16 - GraphTrainer - INFO - ndcg@20: 0.034336
2025-11-22 22:46:16 - GraphTrainer - INFO - map@20: 0.021438
2025-11-22 22:46:16 - GraphTrainer - INFO - mrr@20: 0.022358
2025-11-22 22:46:16 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:46:16 - GraphTrainer - INFO - ============================================================
2025-11-22 22:46:16 - GraphTrainer - INFO - 开始第 186/1000 轮训练
2025-11-22 22:46:16 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3142, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3166, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3272, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3248, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3536, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3161, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3191, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3216, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3112, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3163, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3121, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3088, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3167, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3263, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3067, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3006, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3018, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3309, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3131, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3223, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3333, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3202, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3237, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3562, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3373, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3181, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3288, device='cuda:0', grad_fn=<AddBackward0>)
The 185 training average loss: 0.32869393609721087
2025-11-22 22:46:27 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:46:27 - GraphTrainer - INFO -   precision@5: 0.006737
2025-11-22 22:46:27 - GraphTrainer - INFO -   recall@5: 0.031941
2025-11-22 22:46:27 - GraphTrainer - INFO -   hit_rate@5: 0.033633
2025-11-22 22:46:27 - GraphTrainer - INFO -   ndcg@5: 0.021057
2025-11-22 22:46:27 - GraphTrainer - INFO -   map@5: 0.017223
2025-11-22 22:46:27 - GraphTrainer - INFO -   mrr@5: 0.017934
2025-11-22 22:46:27 - GraphTrainer - INFO -   precision@10: 0.005276
2025-11-22 22:46:27 - GraphTrainer - INFO -   recall@10: 0.050016
2025-11-22 22:46:27 - GraphTrainer - INFO -   hit_rate@10: 0.052610
2025-11-22 22:46:27 - GraphTrainer - INFO -   ndcg@10: 0.026886
2025-11-22 22:46:27 - GraphTrainer - INFO -   map@10: 0.019563
2025-11-22 22:46:27 - GraphTrainer - INFO -   mrr@10: 0.020389
2025-11-22 22:46:27 - GraphTrainer - INFO -   precision@20: 0.004191
2025-11-22 22:46:27 - GraphTrainer - INFO -   recall@20: 0.079177
2025-11-22 22:46:27 - GraphTrainer - INFO -   hit_rate@20: 0.083312
2025-11-22 22:46:27 - GraphTrainer - INFO -   ndcg@20: 0.034303
2025-11-22 22:46:27 - GraphTrainer - INFO -   map@20: 0.021551
2025-11-22 22:46:27 - GraphTrainer - INFO -   mrr@20: 0.022473
2025-11-22 22:46:27 - GraphTrainer - INFO - 第 186 轮训练完成
2025-11-22 22:46:27 - GraphTrainer - INFO - train_loss: 0.328753
2025-11-22 22:46:27 - GraphTrainer - INFO - precision@5: 0.006737
2025-11-22 22:46:27 - GraphTrainer - INFO - recall@5: 0.031941
2025-11-22 22:46:27 - GraphTrainer - INFO - hit_rate@5: 0.033633
2025-11-22 22:46:27 - GraphTrainer - INFO - ndcg@5: 0.021057
2025-11-22 22:46:27 - GraphTrainer - INFO - map@5: 0.017223
2025-11-22 22:46:27 - GraphTrainer - INFO - mrr@5: 0.017934
2025-11-22 22:46:27 - GraphTrainer - INFO - precision@10: 0.005276
2025-11-22 22:46:27 - GraphTrainer - INFO - recall@10: 0.050016
2025-11-22 22:46:27 - GraphTrainer - INFO - hit_rate@10: 0.052610
2025-11-22 22:46:27 - GraphTrainer - INFO - ndcg@10: 0.026886
2025-11-22 22:46:27 - GraphTrainer - INFO - map@10: 0.019563
2025-11-22 22:46:27 - GraphTrainer - INFO - mrr@10: 0.020389
2025-11-22 22:46:27 - GraphTrainer - INFO - precision@20: 0.004191
2025-11-22 22:46:27 - GraphTrainer - INFO - recall@20: 0.079177
2025-11-22 22:46:27 - GraphTrainer - INFO - hit_rate@20: 0.083312
2025-11-22 22:46:27 - GraphTrainer - INFO - ndcg@20: 0.034303
2025-11-22 22:46:27 - GraphTrainer - INFO - map@20: 0.021551
2025-11-22 22:46:27 - GraphTrainer - INFO - mrr@20: 0.022473
2025-11-22 22:46:27 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:46:27 - GraphTrainer - INFO - ============================================================
2025-11-22 22:46:27 - GraphTrainer - INFO - 开始第 187/1000 轮训练
2025-11-22 22:46:27 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3215, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3168, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3252, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3202, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3075, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3312, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3123, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3105, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3433, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3165, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3226, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3455, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3156, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3208, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3225, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3222, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3172, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3162, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3012, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3209, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3246, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3464, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3182, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3466, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3421, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3285, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3104, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3191, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3194, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3192, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3246, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3269, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3457, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
The 186 training average loss: 0.3287527730752682
2025-11-22 22:46:38 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:46:38 - GraphTrainer - INFO -   precision@5: 0.006747
2025-11-22 22:46:38 - GraphTrainer - INFO -   recall@5: 0.032220
2025-11-22 22:46:38 - GraphTrainer - INFO -   hit_rate@5: 0.033685
2025-11-22 22:46:38 - GraphTrainer - INFO -   ndcg@5: 0.021253
2025-11-22 22:46:38 - GraphTrainer - INFO -   map@5: 0.017427
2025-11-22 22:46:38 - GraphTrainer - INFO -   mrr@5: 0.018061
2025-11-22 22:46:38 - GraphTrainer - INFO -   precision@10: 0.005307
2025-11-22 22:46:38 - GraphTrainer - INFO -   recall@10: 0.050285
2025-11-22 22:46:38 - GraphTrainer - INFO -   hit_rate@10: 0.052918
2025-11-22 22:46:38 - GraphTrainer - INFO -   ndcg@10: 0.027079
2025-11-22 22:46:38 - GraphTrainer - INFO -   map@10: 0.019746
2025-11-22 22:46:38 - GraphTrainer - INFO -   mrr@10: 0.020538
2025-11-22 22:46:38 - GraphTrainer - INFO -   precision@20: 0.004196
2025-11-22 22:46:38 - GraphTrainer - INFO -   recall@20: 0.079509
2025-11-22 22:46:38 - GraphTrainer - INFO -   hit_rate@20: 0.083466
2025-11-22 22:46:38 - GraphTrainer - INFO -   ndcg@20: 0.034450
2025-11-22 22:46:38 - GraphTrainer - INFO -   map@20: 0.021698
2025-11-22 22:46:38 - GraphTrainer - INFO -   mrr@20: 0.022572
2025-11-22 22:46:38 - GraphTrainer - INFO - 第 187 轮训练完成
2025-11-22 22:46:38 - GraphTrainer - INFO - train_loss: 0.329815
2025-11-22 22:46:38 - GraphTrainer - INFO - precision@5: 0.006747
2025-11-22 22:46:38 - GraphTrainer - INFO - recall@5: 0.032220
2025-11-22 22:46:38 - GraphTrainer - INFO - hit_rate@5: 0.033685
2025-11-22 22:46:38 - GraphTrainer - INFO - ndcg@5: 0.021253
2025-11-22 22:46:38 - GraphTrainer - INFO - map@5: 0.017427
2025-11-22 22:46:38 - GraphTrainer - INFO - mrr@5: 0.018061
2025-11-22 22:46:38 - GraphTrainer - INFO - precision@10: 0.005307
2025-11-22 22:46:38 - GraphTrainer - INFO - recall@10: 0.050285
2025-11-22 22:46:38 - GraphTrainer - INFO - hit_rate@10: 0.052918
2025-11-22 22:46:38 - GraphTrainer - INFO - ndcg@10: 0.027079
2025-11-22 22:46:38 - GraphTrainer - INFO - map@10: 0.019746
2025-11-22 22:46:38 - GraphTrainer - INFO - mrr@10: 0.020538
2025-11-22 22:46:38 - GraphTrainer - INFO - precision@20: 0.004196
2025-11-22 22:46:38 - GraphTrainer - INFO - recall@20: 0.079509
2025-11-22 22:46:38 - GraphTrainer - INFO - hit_rate@20: 0.083466
2025-11-22 22:46:38 - GraphTrainer - INFO - ndcg@20: 0.034450
2025-11-22 22:46:38 - GraphTrainer - INFO - map@20: 0.021698
2025-11-22 22:46:38 - GraphTrainer - INFO - mrr@20: 0.022572
2025-11-22 22:46:38 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:46:38 - GraphTrainer - INFO - ============================================================
2025-11-22 22:46:38 - GraphTrainer - INFO - 开始第 188/1000 轮训练
2025-11-22 22:46:38 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3240, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3434, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3252, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3076, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3306, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3312, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3174, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3313, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3208, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3373, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3124, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3044, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3101, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3093, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3245, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3331, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3214, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3232, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3312, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3177, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3218, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3144, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3191, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3248, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3517, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3163, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3257, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3466, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3226, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)
The 187 training average loss: 0.32981481171887495
2025-11-22 22:46:50 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:46:50 - GraphTrainer - INFO -   precision@5: 0.006655
2025-11-22 22:46:50 - GraphTrainer - INFO -   recall@5: 0.031663
2025-11-22 22:46:50 - GraphTrainer - INFO -   hit_rate@5: 0.033222
2025-11-22 22:46:50 - GraphTrainer - INFO -   ndcg@5: 0.020831
2025-11-22 22:46:50 - GraphTrainer - INFO -   map@5: 0.017025
2025-11-22 22:46:50 - GraphTrainer - INFO -   mrr@5: 0.017703
2025-11-22 22:46:50 - GraphTrainer - INFO -   precision@10: 0.005302
2025-11-22 22:46:50 - GraphTrainer - INFO -   recall@10: 0.050390
2025-11-22 22:46:50 - GraphTrainer - INFO -   hit_rate@10: 0.052867
2025-11-22 22:46:50 - GraphTrainer - INFO -   ndcg@10: 0.026856
2025-11-22 22:46:50 - GraphTrainer - INFO -   map@10: 0.019433
2025-11-22 22:46:50 - GraphTrainer - INFO -   mrr@10: 0.020240
2025-11-22 22:46:50 - GraphTrainer - INFO -   precision@20: 0.004202
2025-11-22 22:46:50 - GraphTrainer - INFO -   recall@20: 0.079595
2025-11-22 22:46:50 - GraphTrainer - INFO -   hit_rate@20: 0.083518
2025-11-22 22:46:50 - GraphTrainer - INFO -   ndcg@20: 0.034230
2025-11-22 22:46:50 - GraphTrainer - INFO -   map@20: 0.021386
2025-11-22 22:46:50 - GraphTrainer - INFO -   mrr@20: 0.022282
2025-11-22 22:46:50 - GraphTrainer - INFO - 第 188 轮训练完成
2025-11-22 22:46:50 - GraphTrainer - INFO - train_loss: 0.327122
2025-11-22 22:46:50 - GraphTrainer - INFO - precision@5: 0.006655
2025-11-22 22:46:50 - GraphTrainer - INFO - recall@5: 0.031663
2025-11-22 22:46:50 - GraphTrainer - INFO - hit_rate@5: 0.033222
2025-11-22 22:46:50 - GraphTrainer - INFO - ndcg@5: 0.020831
2025-11-22 22:46:50 - GraphTrainer - INFO - map@5: 0.017025
2025-11-22 22:46:50 - GraphTrainer - INFO - mrr@5: 0.017703
2025-11-22 22:46:50 - GraphTrainer - INFO - precision@10: 0.005302
2025-11-22 22:46:50 - GraphTrainer - INFO - recall@10: 0.050390
2025-11-22 22:46:50 - GraphTrainer - INFO - hit_rate@10: 0.052867
2025-11-22 22:46:50 - GraphTrainer - INFO - ndcg@10: 0.026856
2025-11-22 22:46:50 - GraphTrainer - INFO - map@10: 0.019433
2025-11-22 22:46:50 - GraphTrainer - INFO - mrr@10: 0.020240
2025-11-22 22:46:50 - GraphTrainer - INFO - precision@20: 0.004202
2025-11-22 22:46:50 - GraphTrainer - INFO - recall@20: 0.079595
2025-11-22 22:46:50 - GraphTrainer - INFO - hit_rate@20: 0.083518
2025-11-22 22:46:50 - GraphTrainer - INFO - ndcg@20: 0.034230
2025-11-22 22:46:50 - GraphTrainer - INFO - map@20: 0.021386
2025-11-22 22:46:50 - GraphTrainer - INFO - mrr@20: 0.022282
2025-11-22 22:46:50 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:46:50 - GraphTrainer - INFO - ============================================================
2025-11-22 22:46:50 - GraphTrainer - INFO - 开始第 189/1000 轮训练
2025-11-22 22:46:50 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3288, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3207, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3187, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3202, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3189, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3272, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3126, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3281, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3210, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3304, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3069, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3175, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3183, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3101, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3249, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3245, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3274, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3225, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3462, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3316, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3194, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3235, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3100, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3062, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3187, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3081, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3148, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3099, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3290, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3257, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3472, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3010, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3026, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3233, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3379, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
The 188 training average loss: 0.32712207580434866
2025-11-22 22:47:00 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:47:00 - GraphTrainer - INFO -   precision@5: 0.006624
2025-11-22 22:47:00 - GraphTrainer - INFO -   recall@5: 0.031440
2025-11-22 22:47:00 - GraphTrainer - INFO -   hit_rate@5: 0.033068
2025-11-22 22:47:00 - GraphTrainer - INFO -   ndcg@5: 0.020623
2025-11-22 22:47:00 - GraphTrainer - INFO -   map@5: 0.016806
2025-11-22 22:47:00 - GraphTrainer - INFO -   mrr@5: 0.017491
2025-11-22 22:47:00 - GraphTrainer - INFO -   precision@10: 0.005271
2025-11-22 22:47:00 - GraphTrainer - INFO -   recall@10: 0.050019
2025-11-22 22:47:00 - GraphTrainer - INFO -   hit_rate@10: 0.052610
2025-11-22 22:47:00 - GraphTrainer - INFO -   ndcg@10: 0.026658
2025-11-22 22:47:00 - GraphTrainer - INFO -   map@10: 0.019253
2025-11-22 22:47:00 - GraphTrainer - INFO -   mrr@10: 0.020065
2025-11-22 22:47:00 - GraphTrainer - INFO -   precision@20: 0.004209
2025-11-22 22:47:00 - GraphTrainer - INFO -   recall@20: 0.079708
2025-11-22 22:47:00 - GraphTrainer - INFO -   hit_rate@20: 0.083723
2025-11-22 22:47:00 - GraphTrainer - INFO -   ndcg@20: 0.034170
2025-11-22 22:47:00 - GraphTrainer - INFO -   map@20: 0.021253
2025-11-22 22:47:00 - GraphTrainer - INFO -   mrr@20: 0.022152
2025-11-22 22:47:00 - GraphTrainer - INFO - 第 189 轮训练完成
2025-11-22 22:47:00 - GraphTrainer - INFO - train_loss: 0.329093
2025-11-22 22:47:00 - GraphTrainer - INFO - precision@5: 0.006624
2025-11-22 22:47:00 - GraphTrainer - INFO - recall@5: 0.031440
2025-11-22 22:47:00 - GraphTrainer - INFO - hit_rate@5: 0.033068
2025-11-22 22:47:00 - GraphTrainer - INFO - ndcg@5: 0.020623
2025-11-22 22:47:00 - GraphTrainer - INFO - map@5: 0.016806
2025-11-22 22:47:00 - GraphTrainer - INFO - mrr@5: 0.017491
2025-11-22 22:47:00 - GraphTrainer - INFO - precision@10: 0.005271
2025-11-22 22:47:00 - GraphTrainer - INFO - recall@10: 0.050019
2025-11-22 22:47:00 - GraphTrainer - INFO - hit_rate@10: 0.052610
2025-11-22 22:47:00 - GraphTrainer - INFO - ndcg@10: 0.026658
2025-11-22 22:47:00 - GraphTrainer - INFO - map@10: 0.019253
2025-11-22 22:47:00 - GraphTrainer - INFO - mrr@10: 0.020065
2025-11-22 22:47:00 - GraphTrainer - INFO - precision@20: 0.004209
2025-11-22 22:47:00 - GraphTrainer - INFO - recall@20: 0.079708
2025-11-22 22:47:00 - GraphTrainer - INFO - hit_rate@20: 0.083723
2025-11-22 22:47:00 - GraphTrainer - INFO - ndcg@20: 0.034170
2025-11-22 22:47:00 - GraphTrainer - INFO - map@20: 0.021253
2025-11-22 22:47:00 - GraphTrainer - INFO - mrr@20: 0.022152
2025-11-22 22:47:00 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:47:00 - GraphTrainer - WARNING - 早停触发 - 第 189 轮，最佳指标: 0.080163
2025-11-22 22:47:00 - GraphTrainer - INFO - ============================================================
2025-11-22 22:47:00 - GraphTrainer - INFO - 训练完成!
2025-11-22 22:47:00 - GraphTrainer - INFO - 总训练时间: 0.58 hours
2025-11-22 22:47:00 - GraphTrainer - INFO - 最佳指标:
2025-11-22 22:47:00 - GraphTrainer - INFO -   best_precision@5: 0.006624
2025-11-22 22:47:00 - GraphTrainer - INFO -   best_recall@5: 0.031440
2025-11-22 22:47:00 - GraphTrainer - INFO -   best_hit_rate@5: 0.033068
2025-11-22 22:47:00 - GraphTrainer - INFO -   best_ndcg@5: 0.020623
2025-11-22 22:47:00 - GraphTrainer - INFO -   best_map@5: 0.016806
2025-11-22 22:47:00 - GraphTrainer - INFO -   best_mrr@5: 0.017491
2025-11-22 22:47:00 - GraphTrainer - INFO -   best_precision@10: 0.005271
2025-11-22 22:47:00 - GraphTrainer - INFO -   best_recall@10: 0.050019
2025-11-22 22:47:00 - GraphTrainer - INFO -   best_hit_rate@10: 0.052610
2025-11-22 22:47:00 - GraphTrainer - INFO -   best_ndcg@10: 0.026658
2025-11-22 22:47:00 - GraphTrainer - INFO -   best_map@10: 0.019253
2025-11-22 22:47:00 - GraphTrainer - INFO -   best_mrr@10: 0.020065
2025-11-22 22:47:00 - GraphTrainer - INFO -   best_precision@20: 0.004209
2025-11-22 22:47:00 - GraphTrainer - INFO -   best_recall@20: 0.079708
2025-11-22 22:47:00 - GraphTrainer - INFO -   best_hit_rate@20: 0.083723
2025-11-22 22:47:00 - GraphTrainer - INFO -   best_ndcg@20: 0.034170
2025-11-22 22:47:00 - GraphTrainer - INFO -   best_map@20: 0.021253
2025-11-22 22:47:00 - GraphTrainer - INFO -   best_mrr@20: 0.022152
2025-11-22 22:47:00 - GraphTrainer - INFO - ============================================================
2025-11-22 22:47:00 - GraphTrainer - INFO - Loaded best model from epoch 169
[I 2025-11-22 22:47:03,307] Trial 2 finished with value: 0.08016346395015717 and parameters: {'model.layer_num': 3, 'graph.v_k': 8, 'graph.t_k': 6, 'model.gcn_v_k': 10, 'model.gcn_t_k': 10, 'model.k': 8, 'model.alpha': 0.3431001252000459, 'model.hidden_unit': 512}. Best is trial 0 with value: 0.08310925960540771.
2025-11-22 22:47:21 - GraphTrainer - INFO - Starting training...
2025-11-22 22:47:21 - GraphTrainer - INFO - 模型: SGrec
2025-11-22 22:47:21 - GraphTrainer - INFO - 总参数量: 4,056,128
2025-11-22 22:47:21 - GraphTrainer - INFO - 可训练参数量: 4,056,128
2025-11-22 22:47:21 - GraphTrainer - INFO - ============================================================
2025-11-22 22:47:21 - GraphTrainer - INFO - 开始第 1/1000 轮训练
2025-11-22 22:47:21 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3563, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3227, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3649, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3092, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3284, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3233, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3273, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3160, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3182, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3159, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3172, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3079, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3139, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3245, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3064, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3145, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3312, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3494, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3226, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3108, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3207, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3260, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3199, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3290, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3102, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3281, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3122, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2968, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3159, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3181, device='cuda:0', grad_fn=<AddBackward0>)
The 189 training average loss: 0.3290925616848058

============================================================
FINAL RESULTS
============================================================
Training Results:
  Best epoch: 169
  Best validation metric: 0.0802
  Training time: 0.58 hours

Test Metrics:
  precision@5: 0.0072
  recall@5: 0.0330
  hit_rate@5: 0.0359
  ndcg@5: 0.0214
  map@5: 0.0171
  mrr@5: 0.0187
  precision@10: 0.0057
  recall@10: 0.0522
  hit_rate@10: 0.0571
  ndcg@10: 0.0277
  map@10: 0.0196
  mrr@10: 0.0215
  precision@20: 0.0046
  recall@20: 0.0837
  hit_rate@20: 0.0916
  ndcg@20: 0.0358
  map@20: 0.0218
  mrr@20: 0.0238
Saving results...
Results saved to ./results/results_20251122_2247.json

Training completed successfully!

############################################################
Optuna Trial 3
############################################################
Trial config (partial):
  lr=0.001, wd=0, layer_num=2, graph_v_k=5, graph_t_k=6, gcn_v_k=2, gcn_t_k=4, k=9, alpha=0.3713311299617067, beta=0.6286688700382933, hidden_unit=256
Using GPU: NVIDIA GeForce RTX 3080
============================================================
Graph-based Recommendation System
============================================================
Dataset: baby
Device: cuda
Model: SGrec
Embedding dim: 64
Epochs: 1000
============================================================
Loading data...
Initializing full dataset from ../autodl-tmp/data/ori_data/baby
Loading interaction data from ../autodl-tmp/data/ori_data/baby
Loading features from ../autodl-tmp/data/ori_data/baby
Building user-item interaction index...
Dataset Statistics:
  num_users: 19445
  num_items: 7050
  num_interactions: 160792
  sparsity: 0.9988270827520429
  user_features: []
  item_features_dimensions: {'image_feat': 4096, 'text_feat': 384}
  user_feature_dimensions: {}
  train_ratio: 0.737294143987263
  val_ratio: 0.12786083884770386
  test_ratio: 0.13484501716503308
Full dataset initialized: 160792 interactions, 19445 users, 7050 items
Splitting dataset into train/val/test...
Initializing subset dataset (mode: train) with 118551 interactions
Initializing subset dataset (mode: val) with 20559 interactions
Initializing subset dataset (mode: test) with 21682 interactions
Split results - Train: 118551 interactions, Val: 20559, Test: 21682
Data loaders created - Train batches: 58, Val batches: 11, Test batches: 11
Data loaded: 19445 users, 7050 items
User features: []
Item features: ['image_feat', 'text_feat']
Building graph and model...
Extracting training interactions for graph construction...
Extracted 118551 positive interactions for graph construction
Graph built from training data only: 26495 nodes, 263597 edges
⚠️  Important: Graph constructed using only training data to prevent data leakage
SGrec(
  (user_emb): Embedding(19445, 64)
  (item_emb): Embedding(7050, 64)
  (graph): Graph(
    (input_feat_dropout): Dropout(p=0.1, inplace=False)
    (v_ffn): Sequential(
      (0): Linear(in_features=4096, out_features=512, bias=True)
      (1): Linear(in_features=512, out_features=64, bias=True)
    )
    (t_ffn): Sequential(
      (0): Linear(in_features=384, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=64, bias=True)
    )
    (v_gcn): II_GCN(
      (x_dropout): Dropout(p=0.3, inplace=False)
      (edge_dropout): Dropout(p=0.2, inplace=False)
      (z_dropout): Dropout(p=0.3, inplace=False)
    )
    (t_gcn): II_GCN(
      (x_dropout): Dropout(p=0.3, inplace=False)
      (edge_dropout): Dropout(p=0.2, inplace=False)
      (z_dropout): Dropout(p=0.3, inplace=False)
    )
    (iu_gcn): IU_GCN(
      (x_dropout): Dropout(p=0.3, inplace=False)
      (edge_dropout): Dropout(p=0.2, inplace=False)
      (z_dropout): Dropout(p=0.3, inplace=False)
    )
    (activate): ReLU()
  )
)
Model parameters: 4,056,128
init trainer,verifier,tester
2025-11-22 22:47:32 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:47:32 - GraphTrainer - INFO -   precision@5: 0.002448
2025-11-22 22:47:32 - GraphTrainer - INFO -   recall@5: 0.011861
2025-11-22 22:47:32 - GraphTrainer - INFO -   hit_rate@5: 0.012240
2025-11-22 22:47:32 - GraphTrainer - INFO -   ndcg@5: 0.009025
2025-11-22 22:47:32 - GraphTrainer - INFO -   map@5: 0.008021
2025-11-22 22:47:32 - GraphTrainer - INFO -   mrr@5: 0.008268
2025-11-22 22:47:32 - GraphTrainer - INFO -   precision@10: 0.001759
2025-11-22 22:47:32 - GraphTrainer - INFO -   recall@10: 0.016801
2025-11-22 22:47:32 - GraphTrainer - INFO -   hit_rate@10: 0.017537
2025-11-22 22:47:32 - GraphTrainer - INFO -   ndcg@10: 0.010620
2025-11-22 22:47:32 - GraphTrainer - INFO -   map@10: 0.008656
2025-11-22 22:47:32 - GraphTrainer - INFO -   mrr@10: 0.008950
2025-11-22 22:47:32 - GraphTrainer - INFO -   precision@20: 0.001355
2025-11-22 22:47:32 - GraphTrainer - INFO -   recall@20: 0.025392
2025-11-22 22:47:32 - GraphTrainer - INFO -   hit_rate@20: 0.026948
2025-11-22 22:47:32 - GraphTrainer - INFO -   ndcg@20: 0.012824
2025-11-22 22:47:32 - GraphTrainer - INFO -   map@20: 0.009241
2025-11-22 22:47:32 - GraphTrainer - INFO -   mrr@20: 0.009596
2025-11-22 22:47:32 - GraphTrainer - INFO - 第 1 轮训练完成
2025-11-22 22:47:32 - GraphTrainer - INFO - train_loss: 0.667950
2025-11-22 22:47:32 - GraphTrainer - INFO - precision@5: 0.002448
2025-11-22 22:47:32 - GraphTrainer - INFO - recall@5: 0.011861
2025-11-22 22:47:32 - GraphTrainer - INFO - hit_rate@5: 0.012240
2025-11-22 22:47:32 - GraphTrainer - INFO - ndcg@5: 0.009025
2025-11-22 22:47:32 - GraphTrainer - INFO - map@5: 0.008021
2025-11-22 22:47:32 - GraphTrainer - INFO - mrr@5: 0.008268
2025-11-22 22:47:32 - GraphTrainer - INFO - precision@10: 0.001759
2025-11-22 22:47:32 - GraphTrainer - INFO - recall@10: 0.016801
2025-11-22 22:47:32 - GraphTrainer - INFO - hit_rate@10: 0.017537
2025-11-22 22:47:32 - GraphTrainer - INFO - ndcg@10: 0.010620
2025-11-22 22:47:32 - GraphTrainer - INFO - map@10: 0.008656
2025-11-22 22:47:32 - GraphTrainer - INFO - mrr@10: 0.008950
2025-11-22 22:47:32 - GraphTrainer - INFO - precision@20: 0.001355
2025-11-22 22:47:32 - GraphTrainer - INFO - recall@20: 0.025392
2025-11-22 22:47:32 - GraphTrainer - INFO - hit_rate@20: 0.026948
2025-11-22 22:47:32 - GraphTrainer - INFO - ndcg@20: 0.012824
2025-11-22 22:47:32 - GraphTrainer - INFO - map@20: 0.009241
2025-11-22 22:47:32 - GraphTrainer - INFO - mrr@20: 0.009596
2025-11-22 22:47:32 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:47:32 - GraphTrainer - INFO - ============================================================
2025-11-22 22:47:32 - GraphTrainer - INFO - 开始第 2/1000 轮训练
2025-11-22 22:47:32 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.6932, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.6935, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.6912, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.6936, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.6922, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.7031, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.6857, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.6804, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.6818, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.6830, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.6866, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.6803, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.6818, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.6877, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.6867, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.6856, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.6911, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.6839, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.6768, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.6772, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.6768, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.6839, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.6756, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.6726, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.6690, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.6717, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.6753, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.6632, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.6623, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.6657, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.6681, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.6611, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.6626, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.6590, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.6643, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.6416, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.6615, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.6547, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.6655, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.6552, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.6578, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.6467, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.6598, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.6524, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.6532, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.6573, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.6517, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.6476, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.6440, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.6489, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.6550, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.6523, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.6558, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.6380, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.6479, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.6506, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.6401, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.6369, device='cuda:0', grad_fn=<AddBackward0>)
The 1 training average loss: 0.6679501841808188
2025-11-22 22:47:43 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:47:43 - GraphTrainer - INFO -   precision@5: 0.002849
2025-11-22 22:47:43 - GraphTrainer - INFO -   recall@5: 0.013424
2025-11-22 22:47:43 - GraphTrainer - INFO -   hit_rate@5: 0.014194
2025-11-22 22:47:43 - GraphTrainer - INFO -   ndcg@5: 0.009538
2025-11-22 22:47:43 - GraphTrainer - INFO -   map@5: 0.008148
2025-11-22 22:47:43 - GraphTrainer - INFO -   mrr@5: 0.008531
2025-11-22 22:47:43 - GraphTrainer - INFO -   precision@10: 0.002175
2025-11-22 22:47:43 - GraphTrainer - INFO -   recall@10: 0.020555
2025-11-22 22:47:43 - GraphTrainer - INFO -   hit_rate@10: 0.021651
2025-11-22 22:47:43 - GraphTrainer - INFO -   ndcg@10: 0.011873
2025-11-22 22:47:43 - GraphTrainer - INFO -   map@10: 0.009108
2025-11-22 22:47:43 - GraphTrainer - INFO -   mrr@10: 0.009538
2025-11-22 22:47:43 - GraphTrainer - INFO -   precision@20: 0.001785
2025-11-22 22:47:43 - GraphTrainer - INFO -   recall@20: 0.033664
2025-11-22 22:47:43 - GraphTrainer - INFO -   hit_rate@20: 0.035485
2025-11-22 22:47:43 - GraphTrainer - INFO -   ndcg@20: 0.015206
2025-11-22 22:47:43 - GraphTrainer - INFO -   map@20: 0.009999
2025-11-22 22:47:43 - GraphTrainer - INFO -   mrr@20: 0.010477
2025-11-22 22:47:43 - GraphTrainer - INFO - 第 2 轮训练完成
2025-11-22 22:47:43 - GraphTrainer - INFO - train_loss: 0.618306
2025-11-22 22:47:43 - GraphTrainer - INFO - precision@5: 0.002849
2025-11-22 22:47:43 - GraphTrainer - INFO - recall@5: 0.013424
2025-11-22 22:47:43 - GraphTrainer - INFO - hit_rate@5: 0.014194
2025-11-22 22:47:43 - GraphTrainer - INFO - ndcg@5: 0.009538
2025-11-22 22:47:43 - GraphTrainer - INFO - map@5: 0.008148
2025-11-22 22:47:43 - GraphTrainer - INFO - mrr@5: 0.008531
2025-11-22 22:47:43 - GraphTrainer - INFO - precision@10: 0.002175
2025-11-22 22:47:43 - GraphTrainer - INFO - recall@10: 0.020555
2025-11-22 22:47:43 - GraphTrainer - INFO - hit_rate@10: 0.021651
2025-11-22 22:47:43 - GraphTrainer - INFO - ndcg@10: 0.011873
2025-11-22 22:47:43 - GraphTrainer - INFO - map@10: 0.009108
2025-11-22 22:47:43 - GraphTrainer - INFO - mrr@10: 0.009538
2025-11-22 22:47:43 - GraphTrainer - INFO - precision@20: 0.001785
2025-11-22 22:47:43 - GraphTrainer - INFO - recall@20: 0.033664
2025-11-22 22:47:43 - GraphTrainer - INFO - hit_rate@20: 0.035485
2025-11-22 22:47:43 - GraphTrainer - INFO - ndcg@20: 0.015206
2025-11-22 22:47:43 - GraphTrainer - INFO - map@20: 0.009999
2025-11-22 22:47:43 - GraphTrainer - INFO - mrr@20: 0.010477
2025-11-22 22:47:43 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:47:43 - GraphTrainer - INFO - ============================================================
2025-11-22 22:47:43 - GraphTrainer - INFO - 开始第 3/1000 轮训练
2025-11-22 22:47:43 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.6387, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.6354, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.6387, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.6387, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.6273, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.6384, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.6321, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.6369, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.6472, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.6382, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.6326, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.6238, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.6301, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.6391, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.6274, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.6182, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.6229, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.6276, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.6306, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.6172, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.6156, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.6269, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.6176, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.6265, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.6014, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.6227, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.6236, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.6146, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.6034, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.6223, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.6086, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.6173, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.6154, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.6025, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.6113, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.6255, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.6156, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.6058, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.6089, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.6109, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.6217, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.6111, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.5967, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.6097, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.6067, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.6091, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.6129, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.5940, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.6060, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.6061, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.6133, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.6056, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.6073, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.6053, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.6012, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.6111, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.5892, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.6171, device='cuda:0', grad_fn=<AddBackward0>)
The 2 training average loss: 0.6183056975233143
2025-11-22 22:47:54 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:47:54 - GraphTrainer - INFO -   precision@5: 0.002942
2025-11-22 22:47:54 - GraphTrainer - INFO -   recall@5: 0.013715
2025-11-22 22:47:54 - GraphTrainer - INFO -   hit_rate@5: 0.014657
2025-11-22 22:47:54 - GraphTrainer - INFO -   ndcg@5: 0.009539
2025-11-22 22:47:54 - GraphTrainer - INFO -   map@5: 0.008013
2025-11-22 22:47:54 - GraphTrainer - INFO -   mrr@5: 0.008462
2025-11-22 22:47:54 - GraphTrainer - INFO -   precision@10: 0.002417
2025-11-22 22:47:54 - GraphTrainer - INFO -   recall@10: 0.022554
2025-11-22 22:47:54 - GraphTrainer - INFO -   hit_rate@10: 0.024068
2025-11-22 22:47:54 - GraphTrainer - INFO -   ndcg@10: 0.012341
2025-11-22 22:47:54 - GraphTrainer - INFO -   map@10: 0.009106
2025-11-22 22:47:54 - GraphTrainer - INFO -   mrr@10: 0.009622
2025-11-22 22:47:54 - GraphTrainer - INFO -   precision@20: 0.002111
2025-11-22 22:47:54 - GraphTrainer - INFO -   recall@20: 0.039951
2025-11-22 22:47:54 - GraphTrainer - INFO -   hit_rate@20: 0.042067
2025-11-22 22:47:54 - GraphTrainer - INFO -   ndcg@20: 0.016814
2025-11-22 22:47:54 - GraphTrainer - INFO -   map@20: 0.010347
2025-11-22 22:47:54 - GraphTrainer - INFO -   mrr@20: 0.010904
2025-11-22 22:47:54 - GraphTrainer - INFO - 第 3 轮训练完成
2025-11-22 22:47:54 - GraphTrainer - INFO - train_loss: 0.592613
2025-11-22 22:47:54 - GraphTrainer - INFO - precision@5: 0.002942
2025-11-22 22:47:54 - GraphTrainer - INFO - recall@5: 0.013715
2025-11-22 22:47:54 - GraphTrainer - INFO - hit_rate@5: 0.014657
2025-11-22 22:47:54 - GraphTrainer - INFO - ndcg@5: 0.009539
2025-11-22 22:47:54 - GraphTrainer - INFO - map@5: 0.008013
2025-11-22 22:47:54 - GraphTrainer - INFO - mrr@5: 0.008462
2025-11-22 22:47:54 - GraphTrainer - INFO - precision@10: 0.002417
2025-11-22 22:47:54 - GraphTrainer - INFO - recall@10: 0.022554
2025-11-22 22:47:54 - GraphTrainer - INFO - hit_rate@10: 0.024068
2025-11-22 22:47:54 - GraphTrainer - INFO - ndcg@10: 0.012341
2025-11-22 22:47:54 - GraphTrainer - INFO - map@10: 0.009106
2025-11-22 22:47:54 - GraphTrainer - INFO - mrr@10: 0.009622
2025-11-22 22:47:54 - GraphTrainer - INFO - precision@20: 0.002111
2025-11-22 22:47:54 - GraphTrainer - INFO - recall@20: 0.039951
2025-11-22 22:47:54 - GraphTrainer - INFO - hit_rate@20: 0.042067
2025-11-22 22:47:54 - GraphTrainer - INFO - ndcg@20: 0.016814
2025-11-22 22:47:54 - GraphTrainer - INFO - map@20: 0.010347
2025-11-22 22:47:54 - GraphTrainer - INFO - mrr@20: 0.010904
2025-11-22 22:47:54 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:47:54 - GraphTrainer - INFO - ============================================================
2025-11-22 22:47:54 - GraphTrainer - INFO - 开始第 4/1000 轮训练
2025-11-22 22:47:54 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.6034, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.6198, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.5923, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.5945, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.5966, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.5940, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.6222, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.5912, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.6200, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.5997, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.6119, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.6089, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.6007, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.5974, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.5976, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.6062, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.5871, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.5935, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.5930, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.6005, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.5915, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.5778, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.5870, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.6018, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.5831, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.5922, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.5733, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.6001, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.6051, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.5797, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.5945, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.5843, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.5793, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.5849, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.5894, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.5748, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.5895, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.5862, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.5914, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.5932, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.5934, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.5772, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.5906, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.5890, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.6004, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.6002, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.5826, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.5909, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.5883, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.5652, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.5896, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.5792, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.5887, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.5830, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.5927, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.5941, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.5968, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.5799, device='cuda:0', grad_fn=<AddBackward0>)
The 3 training average loss: 0.5926130249582487
2025-11-22 22:48:05 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:48:05 - GraphTrainer - INFO -   precision@5: 0.003044
2025-11-22 22:48:05 - GraphTrainer - INFO -   recall@5: 0.014232
2025-11-22 22:48:05 - GraphTrainer - INFO -   hit_rate@5: 0.015120
2025-11-22 22:48:05 - GraphTrainer - INFO -   ndcg@5: 0.007775
2025-11-22 22:48:05 - GraphTrainer - INFO -   map@5: 0.005541
2025-11-22 22:48:05 - GraphTrainer - INFO -   mrr@5: 0.005969
2025-11-22 22:48:05 - GraphTrainer - INFO -   precision@10: 0.002556
2025-11-22 22:48:05 - GraphTrainer - INFO -   recall@10: 0.023975
2025-11-22 22:48:05 - GraphTrainer - INFO -   hit_rate@10: 0.025405
2025-11-22 22:48:05 - GraphTrainer - INFO -   ndcg@10: 0.010950
2025-11-22 22:48:05 - GraphTrainer - INFO -   map@10: 0.006840
2025-11-22 22:48:05 - GraphTrainer - INFO -   mrr@10: 0.007336
2025-11-22 22:48:05 - GraphTrainer - INFO -   precision@20: 0.002193
2025-11-22 22:48:05 - GraphTrainer - INFO -   recall@20: 0.041505
2025-11-22 22:48:05 - GraphTrainer - INFO -   hit_rate@20: 0.043713
2025-11-22 22:48:05 - GraphTrainer - INFO -   ndcg@20: 0.015406
2025-11-22 22:48:05 - GraphTrainer - INFO -   map@20: 0.008043
2025-11-22 22:48:05 - GraphTrainer - INFO -   mrr@20: 0.008591
2025-11-22 22:48:05 - GraphTrainer - INFO - 第 4 轮训练完成
2025-11-22 22:48:05 - GraphTrainer - INFO - train_loss: 0.572640
2025-11-22 22:48:05 - GraphTrainer - INFO - precision@5: 0.003044
2025-11-22 22:48:05 - GraphTrainer - INFO - recall@5: 0.014232
2025-11-22 22:48:05 - GraphTrainer - INFO - hit_rate@5: 0.015120
2025-11-22 22:48:05 - GraphTrainer - INFO - ndcg@5: 0.007775
2025-11-22 22:48:05 - GraphTrainer - INFO - map@5: 0.005541
2025-11-22 22:48:05 - GraphTrainer - INFO - mrr@5: 0.005969
2025-11-22 22:48:05 - GraphTrainer - INFO - precision@10: 0.002556
2025-11-22 22:48:05 - GraphTrainer - INFO - recall@10: 0.023975
2025-11-22 22:48:05 - GraphTrainer - INFO - hit_rate@10: 0.025405
2025-11-22 22:48:05 - GraphTrainer - INFO - ndcg@10: 0.010950
2025-11-22 22:48:05 - GraphTrainer - INFO - map@10: 0.006840
2025-11-22 22:48:05 - GraphTrainer - INFO - mrr@10: 0.007336
2025-11-22 22:48:05 - GraphTrainer - INFO - precision@20: 0.002193
2025-11-22 22:48:05 - GraphTrainer - INFO - recall@20: 0.041505
2025-11-22 22:48:05 - GraphTrainer - INFO - hit_rate@20: 0.043713
2025-11-22 22:48:05 - GraphTrainer - INFO - ndcg@20: 0.015406
2025-11-22 22:48:05 - GraphTrainer - INFO - map@20: 0.008043
2025-11-22 22:48:05 - GraphTrainer - INFO - mrr@20: 0.008591
2025-11-22 22:48:05 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:48:05 - GraphTrainer - INFO - ============================================================
2025-11-22 22:48:05 - GraphTrainer - INFO - 开始第 5/1000 轮训练
2025-11-22 22:48:05 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.5658, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.5772, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.5591, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.5680, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.5894, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.5742, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.5650, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.5722, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.5696, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.5953, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.5854, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.5875, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.5689, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.5717, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.5808, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.5722, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.5883, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.5640, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.5780, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.5791, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.5748, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.5830, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.5834, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.5709, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.5708, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.5611, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.5802, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.5752, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.5790, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.5759, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.5825, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.5829, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.5706, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.5730, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.5651, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.5634, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.5930, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.5741, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.5718, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.5643, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.5623, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.5668, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.6030, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.5655, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.5635, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.5754, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.5893, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.5746, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.5685, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.5640, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.5693, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.5690, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.5586, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.5575, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.5518, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.5717, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.5611, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.5342, device='cuda:0', grad_fn=<AddBackward0>)
The 4 training average loss: 0.5726401795601023
2025-11-22 22:48:16 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:48:16 - GraphTrainer - INFO -   precision@5: 0.003219
2025-11-22 22:48:16 - GraphTrainer - INFO -   recall@5: 0.015216
2025-11-22 22:48:16 - GraphTrainer - INFO -   hit_rate@5: 0.016097
2025-11-22 22:48:16 - GraphTrainer - INFO -   ndcg@5: 0.010113
2025-11-22 22:48:16 - GraphTrainer - INFO -   map@5: 0.008291
2025-11-22 22:48:16 - GraphTrainer - INFO -   mrr@5: 0.008737
2025-11-22 22:48:16 - GraphTrainer - INFO -   precision@10: 0.002792
2025-11-22 22:48:16 - GraphTrainer - INFO -   recall@10: 0.026399
2025-11-22 22:48:16 - GraphTrainer - INFO -   hit_rate@10: 0.027822
2025-11-22 22:48:16 - GraphTrainer - INFO -   ndcg@10: 0.013795
2025-11-22 22:48:16 - GraphTrainer - INFO -   map@10: 0.009813
2025-11-22 22:48:16 - GraphTrainer - INFO -   mrr@10: 0.010329
2025-11-22 22:48:16 - GraphTrainer - INFO -   precision@20: 0.002201
2025-11-22 22:48:16 - GraphTrainer - INFO -   recall@20: 0.041650
2025-11-22 22:48:16 - GraphTrainer - INFO -   hit_rate@20: 0.043816
2025-11-22 22:48:16 - GraphTrainer - INFO -   ndcg@20: 0.017650
2025-11-22 22:48:16 - GraphTrainer - INFO -   map@20: 0.010838
2025-11-22 22:48:16 - GraphTrainer - INFO -   mrr@20: 0.011400
2025-11-22 22:48:16 - GraphTrainer - INFO - 第 5 轮训练完成
2025-11-22 22:48:16 - GraphTrainer - INFO - train_loss: 0.561368
2025-11-22 22:48:16 - GraphTrainer - INFO - precision@5: 0.003219
2025-11-22 22:48:16 - GraphTrainer - INFO - recall@5: 0.015216
2025-11-22 22:48:16 - GraphTrainer - INFO - hit_rate@5: 0.016097
2025-11-22 22:48:16 - GraphTrainer - INFO - ndcg@5: 0.010113
2025-11-22 22:48:16 - GraphTrainer - INFO - map@5: 0.008291
2025-11-22 22:48:16 - GraphTrainer - INFO - mrr@5: 0.008737
2025-11-22 22:48:16 - GraphTrainer - INFO - precision@10: 0.002792
2025-11-22 22:48:16 - GraphTrainer - INFO - recall@10: 0.026399
2025-11-22 22:48:16 - GraphTrainer - INFO - hit_rate@10: 0.027822
2025-11-22 22:48:16 - GraphTrainer - INFO - ndcg@10: 0.013795
2025-11-22 22:48:16 - GraphTrainer - INFO - map@10: 0.009813
2025-11-22 22:48:16 - GraphTrainer - INFO - mrr@10: 0.010329
2025-11-22 22:48:16 - GraphTrainer - INFO - precision@20: 0.002201
2025-11-22 22:48:16 - GraphTrainer - INFO - recall@20: 0.041650
2025-11-22 22:48:16 - GraphTrainer - INFO - hit_rate@20: 0.043816
2025-11-22 22:48:16 - GraphTrainer - INFO - ndcg@20: 0.017650
2025-11-22 22:48:16 - GraphTrainer - INFO - map@20: 0.010838
2025-11-22 22:48:16 - GraphTrainer - INFO - mrr@20: 0.011400
2025-11-22 22:48:16 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:48:16 - GraphTrainer - INFO - ============================================================
2025-11-22 22:48:16 - GraphTrainer - INFO - 开始第 6/1000 轮训练
2025-11-22 22:48:16 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.5681, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.5738, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.5580, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.5732, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.5459, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.5666, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.5740, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.5636, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.5498, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.5550, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.5669, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.5458, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.5762, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.5614, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.5616, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.5627, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.5735, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.5650, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.5440, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.5464, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.5349, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.5722, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.5499, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.5669, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.5648, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.5664, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.5902, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.5835, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.5711, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.5495, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.5600, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.5470, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.5598, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.5797, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.5681, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.5574, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.5426, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.5569, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.5677, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.5553, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.5690, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.5530, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.5573, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.5638, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.5548, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.5727, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.5544, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.5579, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.5514, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.5694, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.5599, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.5634, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.5500, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.5588, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.5537, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.5628, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.5685, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.5634, device='cuda:0', grad_fn=<AddBackward0>)
The 5 training average loss: 0.5613676772035402
2025-11-22 22:48:27 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:48:27 - GraphTrainer - INFO -   precision@5: 0.003466
2025-11-22 22:48:27 - GraphTrainer - INFO -   recall@5: 0.016575
2025-11-22 22:48:27 - GraphTrainer - INFO -   hit_rate@5: 0.017331
2025-11-22 22:48:27 - GraphTrainer - INFO -   ndcg@5: 0.010054
2025-11-22 22:48:27 - GraphTrainer - INFO -   map@5: 0.007795
2025-11-22 22:48:27 - GraphTrainer - INFO -   mrr@5: 0.008096
2025-11-22 22:48:27 - GraphTrainer - INFO -   precision@10: 0.003003
2025-11-22 22:48:27 - GraphTrainer - INFO -   recall@10: 0.028675
2025-11-22 22:48:27 - GraphTrainer - INFO -   hit_rate@10: 0.029879
2025-11-22 22:48:27 - GraphTrainer - INFO -   ndcg@10: 0.013951
2025-11-22 22:48:27 - GraphTrainer - INFO -   map@10: 0.009364
2025-11-22 22:48:27 - GraphTrainer - INFO -   mrr@10: 0.009717
2025-11-22 22:48:27 - GraphTrainer - INFO -   precision@20: 0.002499
2025-11-22 22:48:27 - GraphTrainer - INFO -   recall@20: 0.047625
2025-11-22 22:48:27 - GraphTrainer - INFO -   hit_rate@20: 0.049730
2025-11-22 22:48:27 - GraphTrainer - INFO -   ndcg@20: 0.018744
2025-11-22 22:48:27 - GraphTrainer - INFO -   map@20: 0.010642
2025-11-22 22:48:27 - GraphTrainer - INFO -   mrr@20: 0.011054
2025-11-22 22:48:27 - GraphTrainer - INFO - 第 6 轮训练完成
2025-11-22 22:48:27 - GraphTrainer - INFO - train_loss: 0.548486
2025-11-22 22:48:27 - GraphTrainer - INFO - precision@5: 0.003466
2025-11-22 22:48:27 - GraphTrainer - INFO - recall@5: 0.016575
2025-11-22 22:48:27 - GraphTrainer - INFO - hit_rate@5: 0.017331
2025-11-22 22:48:27 - GraphTrainer - INFO - ndcg@5: 0.010054
2025-11-22 22:48:27 - GraphTrainer - INFO - map@5: 0.007795
2025-11-22 22:48:27 - GraphTrainer - INFO - mrr@5: 0.008096
2025-11-22 22:48:27 - GraphTrainer - INFO - precision@10: 0.003003
2025-11-22 22:48:27 - GraphTrainer - INFO - recall@10: 0.028675
2025-11-22 22:48:27 - GraphTrainer - INFO - hit_rate@10: 0.029879
2025-11-22 22:48:27 - GraphTrainer - INFO - ndcg@10: 0.013951
2025-11-22 22:48:27 - GraphTrainer - INFO - map@10: 0.009364
2025-11-22 22:48:27 - GraphTrainer - INFO - mrr@10: 0.009717
2025-11-22 22:48:27 - GraphTrainer - INFO - precision@20: 0.002499
2025-11-22 22:48:27 - GraphTrainer - INFO - recall@20: 0.047625
2025-11-22 22:48:27 - GraphTrainer - INFO - hit_rate@20: 0.049730
2025-11-22 22:48:27 - GraphTrainer - INFO - ndcg@20: 0.018744
2025-11-22 22:48:27 - GraphTrainer - INFO - map@20: 0.010642
2025-11-22 22:48:27 - GraphTrainer - INFO - mrr@20: 0.011054
2025-11-22 22:48:27 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:48:27 - GraphTrainer - INFO - ============================================================
2025-11-22 22:48:27 - GraphTrainer - INFO - 开始第 7/1000 轮训练
2025-11-22 22:48:27 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.5702, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.5518, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.5595, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.5567, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.5533, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.5532, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.5357, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.5521, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.5630, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.5462, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.5738, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.5419, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.5562, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.5462, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.5589, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.5306, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.5548, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.5392, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.5517, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.5534, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.5386, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.5545, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.5365, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.5442, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.5718, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.5447, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.5426, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.5204, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.5467, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.5500, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.5514, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.5497, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.5358, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.5244, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.5653, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.5458, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.5709, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.5510, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.5439, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.5622, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.5586, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.5597, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.5479, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.5332, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.5365, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.5521, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.5508, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.5371, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.5510, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.5421, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.5274, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.5366, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.5411, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.5430, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.5368, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.5621, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.5507, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.5466, device='cuda:0', grad_fn=<AddBackward0>)
The 6 training average loss: 0.5484860662756295
2025-11-22 22:48:38 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:48:38 - GraphTrainer - INFO -   precision@5: 0.003723
2025-11-22 22:48:38 - GraphTrainer - INFO -   recall@5: 0.017598
2025-11-22 22:48:38 - GraphTrainer - INFO -   hit_rate@5: 0.018514
2025-11-22 22:48:38 - GraphTrainer - INFO -   ndcg@5: 0.011760
2025-11-22 22:48:38 - GraphTrainer - INFO -   map@5: 0.009696
2025-11-22 22:48:38 - GraphTrainer - INFO -   mrr@5: 0.010141
2025-11-22 22:48:38 - GraphTrainer - INFO -   precision@10: 0.002972
2025-11-22 22:48:38 - GraphTrainer - INFO -   recall@10: 0.028059
2025-11-22 22:48:38 - GraphTrainer - INFO -   hit_rate@10: 0.029622
2025-11-22 22:48:38 - GraphTrainer - INFO -   ndcg@10: 0.015126
2025-11-22 22:48:38 - GraphTrainer - INFO -   map@10: 0.011039
2025-11-22 22:48:38 - GraphTrainer - INFO -   mrr@10: 0.011573
2025-11-22 22:48:38 - GraphTrainer - INFO -   precision@20: 0.002471
2025-11-22 22:48:38 - GraphTrainer - INFO -   recall@20: 0.046676
2025-11-22 22:48:38 - GraphTrainer - INFO -   hit_rate@20: 0.049216
2025-11-22 22:48:38 - GraphTrainer - INFO -   ndcg@20: 0.019834
2025-11-22 22:48:38 - GraphTrainer - INFO -   map@20: 0.012290
2025-11-22 22:48:38 - GraphTrainer - INFO -   mrr@20: 0.012886
2025-11-22 22:48:38 - GraphTrainer - INFO - 第 7 轮训练完成
2025-11-22 22:48:38 - GraphTrainer - INFO - train_loss: 0.539217
2025-11-22 22:48:38 - GraphTrainer - INFO - precision@5: 0.003723
2025-11-22 22:48:38 - GraphTrainer - INFO - recall@5: 0.017598
2025-11-22 22:48:38 - GraphTrainer - INFO - hit_rate@5: 0.018514
2025-11-22 22:48:38 - GraphTrainer - INFO - ndcg@5: 0.011760
2025-11-22 22:48:38 - GraphTrainer - INFO - map@5: 0.009696
2025-11-22 22:48:38 - GraphTrainer - INFO - mrr@5: 0.010141
2025-11-22 22:48:38 - GraphTrainer - INFO - precision@10: 0.002972
2025-11-22 22:48:38 - GraphTrainer - INFO - recall@10: 0.028059
2025-11-22 22:48:38 - GraphTrainer - INFO - hit_rate@10: 0.029622
2025-11-22 22:48:38 - GraphTrainer - INFO - ndcg@10: 0.015126
2025-11-22 22:48:38 - GraphTrainer - INFO - map@10: 0.011039
2025-11-22 22:48:38 - GraphTrainer - INFO - mrr@10: 0.011573
2025-11-22 22:48:38 - GraphTrainer - INFO - precision@20: 0.002471
2025-11-22 22:48:38 - GraphTrainer - INFO - recall@20: 0.046676
2025-11-22 22:48:38 - GraphTrainer - INFO - hit_rate@20: 0.049216
2025-11-22 22:48:38 - GraphTrainer - INFO - ndcg@20: 0.019834
2025-11-22 22:48:38 - GraphTrainer - INFO - map@20: 0.012290
2025-11-22 22:48:38 - GraphTrainer - INFO - mrr@20: 0.012886
2025-11-22 22:48:38 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:48:38 - GraphTrainer - INFO - ============================================================
2025-11-22 22:48:38 - GraphTrainer - INFO - 开始第 8/1000 轮训练
2025-11-22 22:48:38 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.5446, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.5422, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.5259, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.5323, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.5485, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.5406, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.5480, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.5302, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.5445, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.5430, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.5511, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.5369, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.5364, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.5387, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.5360, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.5371, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.5481, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.5266, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.5304, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.5374, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.5266, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.5346, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.5348, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.5439, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.5518, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.5411, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.5602, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.5478, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.5342, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.5570, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.5459, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.5458, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.5370, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.5314, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.5495, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.5361, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.5601, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.5386, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.5405, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.5389, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.5181, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.5308, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.5430, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.5226, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.5273, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.5275, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.5428, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.5442, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.5368, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.5710, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.5313, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.5247, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.5391, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.5424, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.5325, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.5442, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.5319, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.5302, device='cuda:0', grad_fn=<AddBackward0>)
The 7 training average loss: 0.5392170157925836
2025-11-22 22:48:49 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:48:49 - GraphTrainer - INFO -   precision@5: 0.003230
2025-11-22 22:48:49 - GraphTrainer - INFO -   recall@5: 0.015540
2025-11-22 22:48:49 - GraphTrainer - INFO -   hit_rate@5: 0.016148
2025-11-22 22:48:49 - GraphTrainer - INFO -   ndcg@5: 0.009669
2025-11-22 22:48:49 - GraphTrainer - INFO -   map@5: 0.007659
2025-11-22 22:48:49 - GraphTrainer - INFO -   mrr@5: 0.007912
2025-11-22 22:48:49 - GraphTrainer - INFO -   precision@10: 0.002890
2025-11-22 22:48:49 - GraphTrainer - INFO -   recall@10: 0.027433
2025-11-22 22:48:49 - GraphTrainer - INFO -   hit_rate@10: 0.028748
2025-11-22 22:48:49 - GraphTrainer - INFO -   ndcg@10: 0.013536
2025-11-22 22:48:49 - GraphTrainer - INFO -   map@10: 0.009218
2025-11-22 22:48:49 - GraphTrainer - INFO -   mrr@10: 0.009560
2025-11-22 22:48:49 - GraphTrainer - INFO -   precision@20: 0.002484
2025-11-22 22:48:49 - GraphTrainer - INFO -   recall@20: 0.047090
2025-11-22 22:48:49 - GraphTrainer - INFO -   hit_rate@20: 0.049421
2025-11-22 22:48:49 - GraphTrainer - INFO -   ndcg@20: 0.018522
2025-11-22 22:48:49 - GraphTrainer - INFO -   map@20: 0.010552
2025-11-22 22:48:49 - GraphTrainer - INFO -   mrr@20: 0.010958
2025-11-22 22:48:49 - GraphTrainer - INFO - 第 8 轮训练完成
2025-11-22 22:48:49 - GraphTrainer - INFO - train_loss: 0.526844
2025-11-22 22:48:49 - GraphTrainer - INFO - precision@5: 0.003230
2025-11-22 22:48:49 - GraphTrainer - INFO - recall@5: 0.015540
2025-11-22 22:48:49 - GraphTrainer - INFO - hit_rate@5: 0.016148
2025-11-22 22:48:49 - GraphTrainer - INFO - ndcg@5: 0.009669
2025-11-22 22:48:49 - GraphTrainer - INFO - map@5: 0.007659
2025-11-22 22:48:49 - GraphTrainer - INFO - mrr@5: 0.007912
2025-11-22 22:48:49 - GraphTrainer - INFO - precision@10: 0.002890
2025-11-22 22:48:49 - GraphTrainer - INFO - recall@10: 0.027433
2025-11-22 22:48:49 - GraphTrainer - INFO - hit_rate@10: 0.028748
2025-11-22 22:48:49 - GraphTrainer - INFO - ndcg@10: 0.013536
2025-11-22 22:48:49 - GraphTrainer - INFO - map@10: 0.009218
2025-11-22 22:48:49 - GraphTrainer - INFO - mrr@10: 0.009560
2025-11-22 22:48:49 - GraphTrainer - INFO - precision@20: 0.002484
2025-11-22 22:48:49 - GraphTrainer - INFO - recall@20: 0.047090
2025-11-22 22:48:49 - GraphTrainer - INFO - hit_rate@20: 0.049421
2025-11-22 22:48:49 - GraphTrainer - INFO - ndcg@20: 0.018522
2025-11-22 22:48:49 - GraphTrainer - INFO - map@20: 0.010552
2025-11-22 22:48:49 - GraphTrainer - INFO - mrr@20: 0.010958
2025-11-22 22:48:49 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:48:49 - GraphTrainer - INFO - ============================================================
2025-11-22 22:48:49 - GraphTrainer - INFO - 开始第 9/1000 轮训练
2025-11-22 22:48:49 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.5403, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.5360, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.5275, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.5381, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.5310, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.5330, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.5413, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.5386, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.5175, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.5305, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.5064, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.5251, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.5167, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.5430, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.5358, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.5104, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.5363, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.5390, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.5211, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.5214, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.5428, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.5160, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.5342, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.5402, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.5318, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.5234, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.5163, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.5203, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.5114, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.5581, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.5290, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.5359, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.5253, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.5156, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.5335, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.5214, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.5198, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.5258, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.5132, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.5266, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.5584, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.5204, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.5041, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.5214, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.5334, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.5051, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.5192, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.5245, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.5106, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.5245, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.5200, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.5059, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.5293, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.5308, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.5491, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.5201, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.5316, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.5191, device='cuda:0', grad_fn=<AddBackward0>)
The 8 training average loss: 0.5268442024444712
2025-11-22 22:49:00 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:49:00 - GraphTrainer - INFO -   precision@5: 0.003651
2025-11-22 22:49:00 - GraphTrainer - INFO -   recall@5: 0.017272
2025-11-22 22:49:00 - GraphTrainer - INFO -   hit_rate@5: 0.018205
2025-11-22 22:49:00 - GraphTrainer - INFO -   ndcg@5: 0.011187
2025-11-22 22:49:00 - GraphTrainer - INFO -   map@5: 0.009044
2025-11-22 22:49:00 - GraphTrainer - INFO -   mrr@5: 0.009457
2025-11-22 22:49:00 - GraphTrainer - INFO -   precision@10: 0.003178
2025-11-22 22:49:00 - GraphTrainer - INFO -   recall@10: 0.030252
2025-11-22 22:49:00 - GraphTrainer - INFO -   hit_rate@10: 0.031679
2025-11-22 22:49:00 - GraphTrainer - INFO -   ndcg@10: 0.015386
2025-11-22 22:49:00 - GraphTrainer - INFO -   map@10: 0.010751
2025-11-22 22:49:00 - GraphTrainer - INFO -   mrr@10: 0.011223
2025-11-22 22:49:00 - GraphTrainer - INFO -   precision@20: 0.002618
2025-11-22 22:49:00 - GraphTrainer - INFO -   recall@20: 0.049667
2025-11-22 22:49:00 - GraphTrainer - INFO -   hit_rate@20: 0.052147
2025-11-22 22:49:00 - GraphTrainer - INFO -   ndcg@20: 0.020309
2025-11-22 22:49:00 - GraphTrainer - INFO -   map@20: 0.012063
2025-11-22 22:49:00 - GraphTrainer - INFO -   mrr@20: 0.012606
2025-11-22 22:49:00 - GraphTrainer - INFO - 第 9 轮训练完成
2025-11-22 22:49:00 - GraphTrainer - INFO - train_loss: 0.518527
2025-11-22 22:49:00 - GraphTrainer - INFO - precision@5: 0.003651
2025-11-22 22:49:00 - GraphTrainer - INFO - recall@5: 0.017272
2025-11-22 22:49:00 - GraphTrainer - INFO - hit_rate@5: 0.018205
2025-11-22 22:49:00 - GraphTrainer - INFO - ndcg@5: 0.011187
2025-11-22 22:49:00 - GraphTrainer - INFO - map@5: 0.009044
2025-11-22 22:49:00 - GraphTrainer - INFO - mrr@5: 0.009457
2025-11-22 22:49:00 - GraphTrainer - INFO - precision@10: 0.003178
2025-11-22 22:49:00 - GraphTrainer - INFO - recall@10: 0.030252
2025-11-22 22:49:00 - GraphTrainer - INFO - hit_rate@10: 0.031679
2025-11-22 22:49:00 - GraphTrainer - INFO - ndcg@10: 0.015386
2025-11-22 22:49:00 - GraphTrainer - INFO - map@10: 0.010751
2025-11-22 22:49:00 - GraphTrainer - INFO - mrr@10: 0.011223
2025-11-22 22:49:00 - GraphTrainer - INFO - precision@20: 0.002618
2025-11-22 22:49:00 - GraphTrainer - INFO - recall@20: 0.049667
2025-11-22 22:49:00 - GraphTrainer - INFO - hit_rate@20: 0.052147
2025-11-22 22:49:00 - GraphTrainer - INFO - ndcg@20: 0.020309
2025-11-22 22:49:00 - GraphTrainer - INFO - map@20: 0.012063
2025-11-22 22:49:00 - GraphTrainer - INFO - mrr@20: 0.012606
2025-11-22 22:49:00 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:49:00 - GraphTrainer - INFO - ============================================================
2025-11-22 22:49:00 - GraphTrainer - INFO - 开始第 10/1000 轮训练
2025-11-22 22:49:00 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.5219, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.5158, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.5178, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.5171, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.5182, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.5165, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.5380, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.5127, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.5123, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.5371, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4996, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.5112, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.5267, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.5259, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.5134, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.5488, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.5066, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.5108, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.5207, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.5272, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.5122, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.5089, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.5005, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.5256, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.5131, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.5206, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.5112, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.5419, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.5072, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.5253, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4957, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.5254, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.5268, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4892, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.5187, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.5217, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.5252, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.5234, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.5302, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.5107, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.5001, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.5352, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.5240, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.5170, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.5081, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.5170, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.5219, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.5242, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.5218, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.5126, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.5300, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.5220, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.5207, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.5192, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4967, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.5095, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.5183, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.5448, device='cuda:0', grad_fn=<AddBackward0>)
The 9 training average loss: 0.5185266825659521
2025-11-22 22:49:11 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:49:11 - GraphTrainer - INFO -   precision@5: 0.004371
2025-11-22 22:49:11 - GraphTrainer - INFO -   recall@5: 0.020675
2025-11-22 22:49:11 - GraphTrainer - INFO -   hit_rate@5: 0.021754
2025-11-22 22:49:11 - GraphTrainer - INFO -   ndcg@5: 0.013575
2025-11-22 22:49:11 - GraphTrainer - INFO -   map@5: 0.011069
2025-11-22 22:49:11 - GraphTrainer - INFO -   mrr@5: 0.011573
2025-11-22 22:49:11 - GraphTrainer - INFO -   precision@10: 0.003343
2025-11-22 22:49:11 - GraphTrainer - INFO -   recall@10: 0.031509
2025-11-22 22:49:11 - GraphTrainer - INFO -   hit_rate@10: 0.033273
2025-11-22 22:49:11 - GraphTrainer - INFO -   ndcg@10: 0.017123
2025-11-22 22:49:11 - GraphTrainer - INFO -   map@10: 0.012520
2025-11-22 22:49:11 - GraphTrainer - INFO -   mrr@10: 0.013110
2025-11-22 22:49:11 - GraphTrainer - INFO -   precision@20: 0.002767
2025-11-22 22:49:11 - GraphTrainer - INFO -   recall@20: 0.052174
2025-11-22 22:49:11 - GraphTrainer - INFO -   hit_rate@20: 0.055130
2025-11-22 22:49:11 - GraphTrainer - INFO -   ndcg@20: 0.022353
2025-11-22 22:49:11 - GraphTrainer - INFO -   map@20: 0.013907
2025-11-22 22:49:11 - GraphTrainer - INFO -   mrr@20: 0.014575
2025-11-22 22:49:11 - GraphTrainer - INFO - 第 10 轮训练完成
2025-11-22 22:49:11 - GraphTrainer - INFO - train_loss: 0.511882
2025-11-22 22:49:11 - GraphTrainer - INFO - precision@5: 0.004371
2025-11-22 22:49:11 - GraphTrainer - INFO - recall@5: 0.020675
2025-11-22 22:49:11 - GraphTrainer - INFO - hit_rate@5: 0.021754
2025-11-22 22:49:11 - GraphTrainer - INFO - ndcg@5: 0.013575
2025-11-22 22:49:11 - GraphTrainer - INFO - map@5: 0.011069
2025-11-22 22:49:11 - GraphTrainer - INFO - mrr@5: 0.011573
2025-11-22 22:49:11 - GraphTrainer - INFO - precision@10: 0.003343
2025-11-22 22:49:11 - GraphTrainer - INFO - recall@10: 0.031509
2025-11-22 22:49:11 - GraphTrainer - INFO - hit_rate@10: 0.033273
2025-11-22 22:49:11 - GraphTrainer - INFO - ndcg@10: 0.017123
2025-11-22 22:49:11 - GraphTrainer - INFO - map@10: 0.012520
2025-11-22 22:49:11 - GraphTrainer - INFO - mrr@10: 0.013110
2025-11-22 22:49:11 - GraphTrainer - INFO - precision@20: 0.002767
2025-11-22 22:49:11 - GraphTrainer - INFO - recall@20: 0.052174
2025-11-22 22:49:11 - GraphTrainer - INFO - hit_rate@20: 0.055130
2025-11-22 22:49:11 - GraphTrainer - INFO - ndcg@20: 0.022353
2025-11-22 22:49:11 - GraphTrainer - INFO - map@20: 0.013907
2025-11-22 22:49:11 - GraphTrainer - INFO - mrr@20: 0.014575
2025-11-22 22:49:11 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:49:11 - GraphTrainer - INFO - 检查点已保存: Epoch 10 -> ./checkpoints/checkpoint_epoch_10.pth
2025-11-22 22:49:11 - GraphTrainer - INFO - ============================================================
2025-11-22 22:49:11 - GraphTrainer - INFO - 开始第 11/1000 轮训练
2025-11-22 22:49:11 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.5295, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.5141, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.5065, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.5171, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.5182, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.5126, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.5091, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.5172, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.5380, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.5141, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.5189, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.5098, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4934, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4967, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4950, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.5063, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.5019, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4827, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4888, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.5060, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.5136, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.5005, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.5248, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.5146, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.5267, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.5029, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4881, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.5323, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.5130, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.5279, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.5082, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4951, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.5335, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4949, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.5168, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.5310, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.5204, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.5211, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.5172, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.5240, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4982, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.5341, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.5062, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.5001, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.5033, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.5009, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.5085, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.5075, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.5175, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.5136, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.5054, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.5249, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.5271, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.5155, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.5223, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4923, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.5036, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.5257, device='cuda:0', grad_fn=<AddBackward0>)
The 10 training average loss: 0.5118822198489617
2025-11-22 22:49:22 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:49:22 - GraphTrainer - INFO -   precision@5: 0.004628
2025-11-22 22:49:22 - GraphTrainer - INFO -   recall@5: 0.022153
2025-11-22 22:49:22 - GraphTrainer - INFO -   hit_rate@5: 0.023091
2025-11-22 22:49:22 - GraphTrainer - INFO -   ndcg@5: 0.014652
2025-11-22 22:49:22 - GraphTrainer - INFO -   map@5: 0.012024
2025-11-22 22:49:22 - GraphTrainer - INFO -   mrr@5: 0.012508
2025-11-22 22:49:22 - GraphTrainer - INFO -   precision@10: 0.003600
2025-11-22 22:49:22 - GraphTrainer - INFO -   recall@10: 0.034234
2025-11-22 22:49:22 - GraphTrainer - INFO -   hit_rate@10: 0.035896
2025-11-22 22:49:22 - GraphTrainer - INFO -   ndcg@10: 0.018541
2025-11-22 22:49:22 - GraphTrainer - INFO -   map@10: 0.013575
2025-11-22 22:49:22 - GraphTrainer - INFO -   mrr@10: 0.014154
2025-11-22 22:49:22 - GraphTrainer - INFO -   precision@20: 0.002795
2025-11-22 22:49:22 - GraphTrainer - INFO -   recall@20: 0.052926
2025-11-22 22:49:22 - GraphTrainer - INFO -   hit_rate@20: 0.055798
2025-11-22 22:49:22 - GraphTrainer - INFO -   ndcg@20: 0.023277
2025-11-22 22:49:22 - GraphTrainer - INFO -   map@20: 0.014830
2025-11-22 22:49:22 - GraphTrainer - INFO -   mrr@20: 0.015492
2025-11-22 22:49:22 - GraphTrainer - INFO - 第 11 轮训练完成
2025-11-22 22:49:22 - GraphTrainer - INFO - train_loss: 0.501246
2025-11-22 22:49:22 - GraphTrainer - INFO - precision@5: 0.004628
2025-11-22 22:49:22 - GraphTrainer - INFO - recall@5: 0.022153
2025-11-22 22:49:22 - GraphTrainer - INFO - hit_rate@5: 0.023091
2025-11-22 22:49:22 - GraphTrainer - INFO - ndcg@5: 0.014652
2025-11-22 22:49:22 - GraphTrainer - INFO - map@5: 0.012024
2025-11-22 22:49:22 - GraphTrainer - INFO - mrr@5: 0.012508
2025-11-22 22:49:22 - GraphTrainer - INFO - precision@10: 0.003600
2025-11-22 22:49:22 - GraphTrainer - INFO - recall@10: 0.034234
2025-11-22 22:49:22 - GraphTrainer - INFO - hit_rate@10: 0.035896
2025-11-22 22:49:22 - GraphTrainer - INFO - ndcg@10: 0.018541
2025-11-22 22:49:22 - GraphTrainer - INFO - map@10: 0.013575
2025-11-22 22:49:22 - GraphTrainer - INFO - mrr@10: 0.014154
2025-11-22 22:49:22 - GraphTrainer - INFO - precision@20: 0.002795
2025-11-22 22:49:22 - GraphTrainer - INFO - recall@20: 0.052926
2025-11-22 22:49:22 - GraphTrainer - INFO - hit_rate@20: 0.055798
2025-11-22 22:49:22 - GraphTrainer - INFO - ndcg@20: 0.023277
2025-11-22 22:49:22 - GraphTrainer - INFO - map@20: 0.014830
2025-11-22 22:49:22 - GraphTrainer - INFO - mrr@20: 0.015492
2025-11-22 22:49:22 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:49:22 - GraphTrainer - INFO - ============================================================
2025-11-22 22:49:22 - GraphTrainer - INFO - 开始第 12/1000 轮训练
2025-11-22 22:49:22 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4926, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.5046, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4814, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4935, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.5013, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.5143, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4922, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4815, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4940, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4951, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4971, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4944, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4939, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.5217, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4931, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.5278, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4834, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4855, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.5140, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4987, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.5218, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.5024, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.5036, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4845, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4837, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4928, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.5074, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.5245, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.5140, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.5193, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.5128, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4945, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4906, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.5004, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.5116, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.5010, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.5101, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4994, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.5147, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4963, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.5036, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4826, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.5148, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.5004, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4865, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.5163, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4986, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.5059, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4782, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.5008, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4856, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.5100, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.5004, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.5146, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.5231, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4988, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.5100, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4967, device='cuda:0', grad_fn=<AddBackward0>)
The 11 training average loss: 0.5012464903551956
2025-11-22 22:49:33 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:49:33 - GraphTrainer - INFO -   precision@5: 0.003939
2025-11-22 22:49:33 - GraphTrainer - INFO -   recall@5: 0.018748
2025-11-22 22:49:33 - GraphTrainer - INFO -   hit_rate@5: 0.019697
2025-11-22 22:49:33 - GraphTrainer - INFO -   ndcg@5: 0.012016
2025-11-22 22:49:33 - GraphTrainer - INFO -   map@5: 0.009677
2025-11-22 22:49:33 - GraphTrainer - INFO -   mrr@5: 0.010081
2025-11-22 22:49:33 - GraphTrainer - INFO -   precision@10: 0.003343
2025-11-22 22:49:33 - GraphTrainer - INFO -   recall@10: 0.031664
2025-11-22 22:49:33 - GraphTrainer - INFO -   hit_rate@10: 0.033325
2025-11-22 22:49:33 - GraphTrainer - INFO -   ndcg@10: 0.016214
2025-11-22 22:49:33 - GraphTrainer - INFO -   map@10: 0.011373
2025-11-22 22:49:33 - GraphTrainer - INFO -   mrr@10: 0.011868
2025-11-22 22:49:33 - GraphTrainer - INFO -   precision@20: 0.002720
2025-11-22 22:49:33 - GraphTrainer - INFO -   recall@20: 0.051377
2025-11-22 22:49:33 - GraphTrainer - INFO -   hit_rate@20: 0.054153
2025-11-22 22:49:33 - GraphTrainer - INFO -   ndcg@20: 0.021234
2025-11-22 22:49:33 - GraphTrainer - INFO -   map@20: 0.012721
2025-11-22 22:49:33 - GraphTrainer - INFO -   mrr@20: 0.013290
2025-11-22 22:49:33 - GraphTrainer - INFO - 第 12 轮训练完成
2025-11-22 22:49:33 - GraphTrainer - INFO - train_loss: 0.497356
2025-11-22 22:49:33 - GraphTrainer - INFO - precision@5: 0.003939
2025-11-22 22:49:33 - GraphTrainer - INFO - recall@5: 0.018748
2025-11-22 22:49:33 - GraphTrainer - INFO - hit_rate@5: 0.019697
2025-11-22 22:49:33 - GraphTrainer - INFO - ndcg@5: 0.012016
2025-11-22 22:49:33 - GraphTrainer - INFO - map@5: 0.009677
2025-11-22 22:49:33 - GraphTrainer - INFO - mrr@5: 0.010081
2025-11-22 22:49:33 - GraphTrainer - INFO - precision@10: 0.003343
2025-11-22 22:49:33 - GraphTrainer - INFO - recall@10: 0.031664
2025-11-22 22:49:33 - GraphTrainer - INFO - hit_rate@10: 0.033325
2025-11-22 22:49:33 - GraphTrainer - INFO - ndcg@10: 0.016214
2025-11-22 22:49:33 - GraphTrainer - INFO - map@10: 0.011373
2025-11-22 22:49:33 - GraphTrainer - INFO - mrr@10: 0.011868
2025-11-22 22:49:33 - GraphTrainer - INFO - precision@20: 0.002720
2025-11-22 22:49:33 - GraphTrainer - INFO - recall@20: 0.051377
2025-11-22 22:49:33 - GraphTrainer - INFO - hit_rate@20: 0.054153
2025-11-22 22:49:33 - GraphTrainer - INFO - ndcg@20: 0.021234
2025-11-22 22:49:33 - GraphTrainer - INFO - map@20: 0.012721
2025-11-22 22:49:33 - GraphTrainer - INFO - mrr@20: 0.013290
2025-11-22 22:49:33 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:49:33 - GraphTrainer - INFO - ============================================================
2025-11-22 22:49:33 - GraphTrainer - INFO - 开始第 13/1000 轮训练
2025-11-22 22:49:33 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4986, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4703, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.5052, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4696, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.5247, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4947, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.5103, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.5117, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.5189, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4887, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4869, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.5095, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4979, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.5100, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.5110, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.5286, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.5071, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4830, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4804, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4878, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.5037, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4999, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4999, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4883, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4895, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.5008, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4961, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.5001, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4801, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.5120, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.5055, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4754, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4920, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.5134, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4963, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4974, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4897, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4862, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4948, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.5062, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.5087, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4975, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4999, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4828, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.5017, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4902, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4951, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.5149, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.5116, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4670, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.5052, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4861, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.5038, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4841, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4880, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4988, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4938, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4955, device='cuda:0', grad_fn=<AddBackward0>)
The 12 training average loss: 0.49735643329291507
2025-11-22 22:49:44 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:49:44 - GraphTrainer - INFO -   precision@5: 0.004032
2025-11-22 22:49:44 - GraphTrainer - INFO -   recall@5: 0.019093
2025-11-22 22:49:44 - GraphTrainer - INFO -   hit_rate@5: 0.020108
2025-11-22 22:49:44 - GraphTrainer - INFO -   ndcg@5: 0.012306
2025-11-22 22:49:44 - GraphTrainer - INFO -   map@5: 0.009912
2025-11-22 22:49:44 - GraphTrainer - INFO -   mrr@5: 0.010447
2025-11-22 22:49:44 - GraphTrainer - INFO -   precision@10: 0.003348
2025-11-22 22:49:44 - GraphTrainer - INFO -   recall@10: 0.031605
2025-11-22 22:49:44 - GraphTrainer - INFO -   hit_rate@10: 0.033428
2025-11-22 22:49:44 - GraphTrainer - INFO -   ndcg@10: 0.016395
2025-11-22 22:49:44 - GraphTrainer - INFO -   map@10: 0.011578
2025-11-22 22:49:44 - GraphTrainer - INFO -   mrr@10: 0.012222
2025-11-22 22:49:44 - GraphTrainer - INFO -   precision@20: 0.002713
2025-11-22 22:49:44 - GraphTrainer - INFO -   recall@20: 0.051320
2025-11-22 22:49:44 - GraphTrainer - INFO -   hit_rate@20: 0.054050
2025-11-22 22:49:44 - GraphTrainer - INFO -   ndcg@20: 0.021391
2025-11-22 22:49:44 - GraphTrainer - INFO -   map@20: 0.012914
2025-11-22 22:49:44 - GraphTrainer - INFO -   mrr@20: 0.013618
2025-11-22 22:49:44 - GraphTrainer - INFO - 第 13 轮训练完成
2025-11-22 22:49:44 - GraphTrainer - INFO - train_loss: 0.489171
2025-11-22 22:49:44 - GraphTrainer - INFO - precision@5: 0.004032
2025-11-22 22:49:44 - GraphTrainer - INFO - recall@5: 0.019093
2025-11-22 22:49:44 - GraphTrainer - INFO - hit_rate@5: 0.020108
2025-11-22 22:49:44 - GraphTrainer - INFO - ndcg@5: 0.012306
2025-11-22 22:49:44 - GraphTrainer - INFO - map@5: 0.009912
2025-11-22 22:49:44 - GraphTrainer - INFO - mrr@5: 0.010447
2025-11-22 22:49:44 - GraphTrainer - INFO - precision@10: 0.003348
2025-11-22 22:49:44 - GraphTrainer - INFO - recall@10: 0.031605
2025-11-22 22:49:44 - GraphTrainer - INFO - hit_rate@10: 0.033428
2025-11-22 22:49:44 - GraphTrainer - INFO - ndcg@10: 0.016395
2025-11-22 22:49:44 - GraphTrainer - INFO - map@10: 0.011578
2025-11-22 22:49:44 - GraphTrainer - INFO - mrr@10: 0.012222
2025-11-22 22:49:44 - GraphTrainer - INFO - precision@20: 0.002713
2025-11-22 22:49:44 - GraphTrainer - INFO - recall@20: 0.051320
2025-11-22 22:49:44 - GraphTrainer - INFO - hit_rate@20: 0.054050
2025-11-22 22:49:44 - GraphTrainer - INFO - ndcg@20: 0.021391
2025-11-22 22:49:44 - GraphTrainer - INFO - map@20: 0.012914
2025-11-22 22:49:44 - GraphTrainer - INFO - mrr@20: 0.013618
2025-11-22 22:49:44 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:49:44 - GraphTrainer - INFO - ============================================================
2025-11-22 22:49:44 - GraphTrainer - INFO - 开始第 14/1000 轮训练
2025-11-22 22:49:44 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4959, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4938, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4719, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4833, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4903, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4918, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4968, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.5116, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.5013, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4799, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.5151, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4826, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4913, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4830, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4938, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4845, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4969, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4958, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4685, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4583, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.5107, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4928, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.5042, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4881, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4875, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4902, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4740, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4802, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4896, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4867, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.5075, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4851, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4887, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4645, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4843, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4939, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4933, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.5004, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4954, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4883, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.5038, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4809, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4809, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4907, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4881, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4768, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4961, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.5016, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.4709, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4797, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4732, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4910, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4778, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4852, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.4770, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.5010, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4966, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.5086, device='cuda:0', grad_fn=<AddBackward0>)
The 13 training average loss: 0.4891710461213671
2025-11-22 22:49:55 - GraphTrainer - INFO - 验证结果:
2025-11-22 22:49:55 - GraphTrainer - INFO -   precision@5: 0.004196
2025-11-22 22:49:55 - GraphTrainer - INFO -   recall@5: 0.019648
2025-11-22 22:49:55 - GraphTrainer - INFO -   hit_rate@5: 0.020931
2025-11-22 22:49:55 - GraphTrainer - INFO -   ndcg@5: 0.013068
2025-11-22 22:49:55 - GraphTrainer - INFO -   map@5: 0.010728
2025-11-22 22:49:55 - GraphTrainer - INFO -   mrr@5: 0.011280
2025-11-22 22:49:55 - GraphTrainer - INFO -   precision@10: 0.003548
2025-11-22 22:49:55 - GraphTrainer - INFO -   recall@10: 0.033385
2025-11-22 22:49:55 - GraphTrainer - INFO -   hit_rate@10: 0.035330
2025-11-22 22:49:55 - GraphTrainer - INFO -   ndcg@10: 0.017527
2025-11-22 22:49:55 - GraphTrainer - INFO -   map@10: 0.012542
2025-11-22 22:49:55 - GraphTrainer - INFO -   mrr@10: 0.013173
2025-11-22 22:49:55 - GraphTrainer - INFO -   precision@20: 0.002913
2025-11-22 22:49:55 - GraphTrainer - INFO -   recall@20: 0.055089
2025-11-22 22:49:55 - GraphTrainer - INFO -   hit_rate@20: 0.057907
2025-11-22 22:49:55 - GraphTrainer - INFO -   ndcg@20: 0.023031
2025-11-22 22:49:55 - GraphTrainer - INFO -   map@20: 0.014018
2025-11-22 22:49:55 - GraphTrainer - INFO -   mrr@20: 0.014709
2025-11-22 22:49:55 - GraphTrainer - INFO - 第 14 轮训练完成
2025-11-22 22:49:55 - GraphTrainer - INFO - train_loss: 0.485282
2025-11-22 22:49:55 - GraphTrainer - INFO - precision@5: 0.004196
2025-11-22 22:49:55 - GraphTrainer - INFO - recall@5: 0.019648
2025-11-22 22:49:55 - GraphTrainer - INFO - hit_rate@5: 0.020931
2025-11-22 22:49:55 - GraphTrainer - INFO - ndcg@5: 0.013068
2025-11-22 22:49:55 - GraphTrainer - INFO - map@5: 0.010728
2025-11-22 22:49:55 - GraphTrainer - INFO - mrr@5: 0.011280
2025-11-22 22:49:55 - GraphTrainer - INFO - precision@10: 0.003548
2025-11-22 22:49:55 - GraphTrainer - INFO - recall@10: 0.033385
2025-11-22 22:49:55 - GraphTrainer - INFO - hit_rate@10: 0.035330
2025-11-22 22:49:55 - GraphTrainer - INFO - ndcg@10: 0.017527
2025-11-22 22:49:55 - GraphTrainer - INFO - map@10: 0.012542
2025-11-22 22:49:55 - GraphTrainer - INFO - mrr@10: 0.013173
2025-11-22 22:49:55 - GraphTrainer - INFO - precision@20: 0.002913
2025-11-22 22:49:55 - GraphTrainer - INFO - recall@20: 0.055089
2025-11-22 22:49:55 - GraphTrainer - INFO - hit_rate@20: 0.057907
2025-11-22 22:49:55 - GraphTrainer - INFO - ndcg@20: 0.023031
2025-11-22 22:49:55 - GraphTrainer - INFO - map@20: 0.014018
2025-11-22 22:49:55 - GraphTrainer - INFO - mrr@20: 0.014709
2025-11-22 22:49:55 - GraphTrainer - INFO - ------------------------------------------------------------
2025-11-22 22:49:55 - GraphTrainer - INFO - ============================================================
2025-11-22 22:49:55 - GraphTrainer - INFO - 开始第 15/1000 轮训练
2025-11-22 22:49:55 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.4821, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.4995, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4863, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4927, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4892, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4915, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4756, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4853, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4985, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4632, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4774, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4671, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4635, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.4880, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.5011, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4929, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.5201, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.4929, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4897, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4816, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.5011, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4600, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.4809, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.4960, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.4933, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.4854, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.4925, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.4949, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.4730, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.4845, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.4875, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.4812, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.4786, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4959, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4795, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.4857, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.4713, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.4907, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.4847, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.4683, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.4996, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.4787, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.4997, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.4795, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.4864, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.4837, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.4833, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.4693, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.5083, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.4787, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.4799, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4583, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.4792, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.4950, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.5038, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.4853, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.4758, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.4787, device='cuda:0', grad_fn=<AddBackward0>)
The 14 training average loss: 0.48528222893846445
[W 2025-11-22 22:50:00,639] Trial 3 failed with parameters: {'model.layer_num': 2, 'graph.v_k': 5, 'graph.t_k': 6, 'model.gcn_v_k': 2, 'model.gcn_t_k': 4, 'model.k': 9, 'model.alpha': 0.3713311299617067, 'model.hidden_unit': 256} because of the following error: AssertionError('pos_score contains NaN').
Traceback (most recent call last):
  File "/root/miniconda3/envs/py310/lib/python3.10/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
  File "/root/recommend/main.py", line 404, in objective
    result = run_single_experiment(config, args.dataset)
  File "/root/recommend/main.py", line 289, in run_single_experiment
    training_results = trainer.train(verifier)
  File "/root/recommend/train/graph_trainer.py", line 194, in train
    train_loss = self.train_epoch()
  File "/root/recommend/train/graph_trainer.py", line 148, in train_epoch
    loss = self._loss_func(outputs, batch)
  File "/root/recommend/model/Main_Model.py", line 844, in loss_func
    assert not torch.isnan(pos_score).any(), "pos_score contains NaN"
AssertionError: pos_score contains NaN
[W 2025-11-22 22:50:00,640] Trial 3 failed with value None.
0 train_loss tensor(0.4842, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.5042, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4686, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4736, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.4604, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4671, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4922, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4982, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4778, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4819, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.4978, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.4858, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4959, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.5014, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.4815, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.4873, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.4877, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.5125, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4769, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.4605, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4627, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(inf, device='cuda:0', grad_fn=<AddBackward0>)
Traceback (most recent call last):
  File "/root/recommend/main.py", line 495, in <module>
    exit(main())
  File "/root/recommend/main.py", line 432, in main
    study.optimize(objective, n_trials=args.max_trials)
  File "/root/miniconda3/envs/py310/lib/python3.10/site-packages/optuna/study/study.py", line 490, in optimize
    _optimize(
  File "/root/miniconda3/envs/py310/lib/python3.10/site-packages/optuna/study/_optimize.py", line 67, in _optimize
    _optimize_sequential(
  File "/root/miniconda3/envs/py310/lib/python3.10/site-packages/optuna/study/_optimize.py", line 164, in _optimize_sequential
    frozen_trial_id = _run_trial(study, func, catch)
  File "/root/miniconda3/envs/py310/lib/python3.10/site-packages/optuna/study/_optimize.py", line 262, in _run_trial
    raise func_err
  File "/root/miniconda3/envs/py310/lib/python3.10/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
  File "/root/recommend/main.py", line 404, in objective
    result = run_single_experiment(config, args.dataset)
  File "/root/recommend/main.py", line 289, in run_single_experiment
    training_results = trainer.train(verifier)
  File "/root/recommend/train/graph_trainer.py", line 194, in train
    train_loss = self.train_epoch()
  File "/root/recommend/train/graph_trainer.py", line 148, in train_epoch
    loss = self._loss_func(outputs, batch)
  File "/root/recommend/model/Main_Model.py", line 844, in loss_func
    assert not torch.isnan(pos_score).any(), "pos_score contains NaN"
AssertionError: pos_score contains NaN
2025-11-22 22:50:00 - torch._dynamo.utils - INFO - TorchDynamo compilation metrics:
Function, Runtimes (s)
[2025-11-22 22:50:00,642] torch._dynamo.utils: [INFO] TorchDynamo compilation metrics:
[2025-11-22 22:50:00,642] torch._dynamo.utils: [INFO] Function, Runtimes (s)

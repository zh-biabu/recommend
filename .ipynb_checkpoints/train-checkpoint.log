nohup: ignoring input
2025-12-15 19:55:06 - GraphTrainer - INFO - Starting training...
2025-12-15 19:55:06 - GraphTrainer - INFO - 模型: SGrec
2025-12-15 19:55:06 - GraphTrainer - INFO - 总参数量: 4,313,664
2025-12-15 19:55:06 - GraphTrainer - INFO - 可训练参数量: 4,313,664
2025-12-15 19:55:06 - GraphTrainer - INFO - ============================================================
2025-12-15 19:55:06 - GraphTrainer - INFO - 开始第 1/1000 轮训练
2025-12-15 19:55:06 - GraphTrainer - INFO - ============================================================

############################################################
Grid Trial 0
############################################################
Trial config (partial):
  lr=0.001, wd=0, k=2, v_layer=1, t_layer=2
Using GPU: NVIDIA GeForce RTX 3090
============================================================
Graph-based Recommendation System
============================================================
Dataset: baby
Device: cuda
Model: SGrec
Embedding dim: 64
Epochs: 1000
============================================================
Loading data...
Initializing full dataset from ../autodl-tmp/data/ori_data/baby
Loading interaction data from ../autodl-tmp/data/ori_data/baby
Loading features from ../autodl-tmp/data/ori_data/baby
Building user-item interaction index...
Dataset Statistics:
  num_users: 19445
  num_items: 7050
  num_interactions: 160792
  sparsity: 0.9988270827520429
  user_features: []
  item_features_dimensions: {'image_feat': 4096, 'text_feat': 384}
  user_feature_dimensions: {}
  train_ratio: 0.737294143987263
  val_ratio: 0.12786083884770386
  test_ratio: 0.13484501716503308
Full dataset initialized: 160792 interactions, 19445 users, 7050 items
Splitting dataset into train/val/test...
Initializing subset dataset (mode: train) with 118551 interactions
Initializing subset dataset (mode: val) with 20559 interactions
Initializing subset dataset (mode: test) with 21682 interactions
Split results - Train: 118551 interactions, Val: 20559, Test: 21682
Data loaders created - Train batches: 58, Val batches: 11, Test batches: 11
Data loaded: 19445 users, 7050 items
User features: []
Item features: ['image_feat', 'text_feat']
Building graph and model...
Extracting training interactions for graph construction...
Extracted 118551 positive interactions for graph construction
Graph built from training data only: 26495 nodes, 263597 edges
⚠️  Important: Graph constructed using only training data to prevent data leakage
SGrec(
  (user_emb): Embedding(19445, 64)
  (item_emb): Embedding(7050, 64)
  (graph): Graph(
    (input_feat_dropout): Dropout(p=0.1, inplace=False)
    (v_ffn): Sequential(
      (0): Linear(in_features=4096, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=64, bias=True)
      (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (t_ffn): Sequential(
      (0): Linear(in_features=384, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=64, bias=True)
      (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (iu_gcn): IU_GCN(
      (x_dropout): Dropout(p=0.3, inplace=False)
      (edge_dropout): Dropout(p=0.2, inplace=False)
      (z_dropout): Dropout(p=0.3, inplace=False)
    )
    (v_transformer): SpatialTransformer(
      (transformer_blocks): ModuleList(
        (0): SpatialTransformerBlock(
          (attention): MultiHeadSelfAttention(
            (q_linear): Linear(in_features=64, out_features=64, bias=True)
            (k_linear): Linear(in_features=64, out_features=64, bias=True)
            (v_linear): Linear(in_features=64, out_features=64, bias=True)
            (o_linear): Linear(in_features=64, out_features=64, bias=True)
            (attn_dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (linear1): Linear(in_features=64, out_features=512, bias=True)
            (linear2): Linear(in_features=512, out_features=64, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (output_dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (t_transformer): SpatialTransformer(
      (transformer_blocks): ModuleList(
        (0-1): 2 x SpatialTransformerBlock(
          (attention): MultiHeadSelfAttention(
            (q_linear): Linear(in_features=64, out_features=64, bias=True)
            (k_linear): Linear(in_features=64, out_features=64, bias=True)
            (v_linear): Linear(in_features=64, out_features=64, bias=True)
            (o_linear): Linear(in_features=64, out_features=64, bias=True)
            (attn_dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (linear1): Linear(in_features=64, out_features=512, bias=True)
            (linear2): Linear(in_features=512, out_features=64, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (output_dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (outl): Linear(in_features=128, out_features=64, bias=True)
    (activate): ReLU()
  )
)
Model parameters: 4,313,664
init trainer,verifier,tester
2025-12-15 19:55:14 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:55:14 - GraphTrainer - INFO -   precision@5: 0.004978
2025-12-15 19:55:14 - GraphTrainer - INFO -   recall@5: 0.023965
2025-12-15 19:55:14 - GraphTrainer - INFO -   hit_rate@5: 0.024891
2025-12-15 19:55:14 - GraphTrainer - INFO -   ndcg@5: 0.015100
2025-12-15 19:55:14 - GraphTrainer - INFO -   map@5: 0.012039
2025-12-15 19:55:14 - GraphTrainer - INFO -   mrr@5: 0.012442
2025-12-15 19:55:14 - GraphTrainer - INFO -   precision@10: 0.004088
2025-12-15 19:55:14 - GraphTrainer - INFO -   recall@10: 0.038904
2025-12-15 19:55:14 - GraphTrainer - INFO -   hit_rate@10: 0.040885
2025-12-15 19:55:14 - GraphTrainer - INFO -   ndcg@10: 0.019967
2025-12-15 19:55:14 - GraphTrainer - INFO -   map@10: 0.014002
2025-12-15 19:55:14 - GraphTrainer - INFO -   mrr@10: 0.014541
2025-12-15 19:55:14 - GraphTrainer - INFO -   precision@20: 0.003194
2025-12-15 19:55:14 - GraphTrainer - INFO -   recall@20: 0.060557
2025-12-15 19:55:14 - GraphTrainer - INFO -   hit_rate@20: 0.063718
2025-12-15 19:55:14 - GraphTrainer - INFO -   ndcg@20: 0.025450
2025-12-15 19:55:14 - GraphTrainer - INFO -   map@20: 0.015459
2025-12-15 19:55:14 - GraphTrainer - INFO -   mrr@20: 0.016073
2025-12-15 19:55:14 - GraphTrainer - INFO - 第 1 轮训练完成
2025-12-15 19:55:14 - GraphTrainer - INFO - train_loss: 0.389561
2025-12-15 19:55:14 - GraphTrainer - INFO - precision@5: 0.004978
2025-12-15 19:55:14 - GraphTrainer - INFO - recall@5: 0.023965
2025-12-15 19:55:14 - GraphTrainer - INFO - hit_rate@5: 0.024891
2025-12-15 19:55:14 - GraphTrainer - INFO - ndcg@5: 0.015100
2025-12-15 19:55:14 - GraphTrainer - INFO - map@5: 0.012039
2025-12-15 19:55:14 - GraphTrainer - INFO - mrr@5: 0.012442
2025-12-15 19:55:14 - GraphTrainer - INFO - precision@10: 0.004088
2025-12-15 19:55:14 - GraphTrainer - INFO - recall@10: 0.038904
2025-12-15 19:55:14 - GraphTrainer - INFO - hit_rate@10: 0.040885
2025-12-15 19:55:14 - GraphTrainer - INFO - ndcg@10: 0.019967
2025-12-15 19:55:14 - GraphTrainer - INFO - map@10: 0.014002
2025-12-15 19:55:14 - GraphTrainer - INFO - mrr@10: 0.014541
2025-12-15 19:55:14 - GraphTrainer - INFO - precision@20: 0.003194
2025-12-15 19:55:14 - GraphTrainer - INFO - recall@20: 0.060557
2025-12-15 19:55:14 - GraphTrainer - INFO - hit_rate@20: 0.063718
2025-12-15 19:55:14 - GraphTrainer - INFO - ndcg@20: 0.025450
2025-12-15 19:55:14 - GraphTrainer - INFO - map@20: 0.015459
2025-12-15 19:55:14 - GraphTrainer - INFO - mrr@20: 0.016073
2025-12-15 19:55:14 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:55:14 - GraphTrainer - INFO - ============================================================
2025-12-15 19:55:14 - GraphTrainer - INFO - 开始第 2/1000 轮训练
2025-12-15 19:55:14 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.5137, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.5949, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4065, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.4045, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3741, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3739, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4041, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3846, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3988, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3835, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3947, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3973, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.4049, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3986, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3951, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3810, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3850, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3951, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.4110, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3911, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3973, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.4081, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3877, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3766, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3903, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3877, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3597, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3749, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3736, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3807, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3683, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3563, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.4031, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3815, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3796, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3726, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3874, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3762, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3644, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3927, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3725, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3670, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3822, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3830, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3628, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3636, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3718, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3877, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3710, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3741, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.4040, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3876, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3887, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3759, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3641, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3713, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3881, device='cuda:0', grad_fn=<AddBackward0>)
The 1 training average loss: 0.3895610473279295
2025-12-15 19:55:21 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:55:21 - GraphTrainer - INFO -   precision@5: 0.005739
2025-12-15 19:55:21 - GraphTrainer - INFO -   recall@5: 0.027430
2025-12-15 19:55:21 - GraphTrainer - INFO -   hit_rate@5: 0.028696
2025-12-15 19:55:21 - GraphTrainer - INFO -   ndcg@5: 0.017851
2025-12-15 19:55:21 - GraphTrainer - INFO -   map@5: 0.014487
2025-12-15 19:55:21 - GraphTrainer - INFO -   mrr@5: 0.015105
2025-12-15 19:55:21 - GraphTrainer - INFO -   precision@10: 0.004587
2025-12-15 19:55:21 - GraphTrainer - INFO -   recall@10: 0.043476
2025-12-15 19:55:21 - GraphTrainer - INFO -   hit_rate@10: 0.045719
2025-12-15 19:55:21 - GraphTrainer - INFO -   ndcg@10: 0.023038
2025-12-15 19:55:21 - GraphTrainer - INFO -   map@10: 0.016561
2025-12-15 19:55:21 - GraphTrainer - INFO -   mrr@10: 0.017305
2025-12-15 19:55:21 - GraphTrainer - INFO -   precision@20: 0.003592
2025-12-15 19:55:21 - GraphTrainer - INFO -   recall@20: 0.068120
2025-12-15 19:55:21 - GraphTrainer - INFO -   hit_rate@20: 0.071432
2025-12-15 19:55:21 - GraphTrainer - INFO -   ndcg@20: 0.029286
2025-12-15 19:55:21 - GraphTrainer - INFO -   map@20: 0.018236
2025-12-15 19:55:21 - GraphTrainer - INFO -   mrr@20: 0.019046
2025-12-15 19:55:22 - GraphTrainer - INFO - 第 2 轮训练完成
2025-12-15 19:55:22 - GraphTrainer - INFO - train_loss: 0.355604
2025-12-15 19:55:22 - GraphTrainer - INFO - precision@5: 0.005739
2025-12-15 19:55:22 - GraphTrainer - INFO - recall@5: 0.027430
2025-12-15 19:55:22 - GraphTrainer - INFO - hit_rate@5: 0.028696
2025-12-15 19:55:22 - GraphTrainer - INFO - ndcg@5: 0.017851
2025-12-15 19:55:22 - GraphTrainer - INFO - map@5: 0.014487
2025-12-15 19:55:22 - GraphTrainer - INFO - mrr@5: 0.015105
2025-12-15 19:55:22 - GraphTrainer - INFO - precision@10: 0.004587
2025-12-15 19:55:22 - GraphTrainer - INFO - recall@10: 0.043476
2025-12-15 19:55:22 - GraphTrainer - INFO - hit_rate@10: 0.045719
2025-12-15 19:55:22 - GraphTrainer - INFO - ndcg@10: 0.023038
2025-12-15 19:55:22 - GraphTrainer - INFO - map@10: 0.016561
2025-12-15 19:55:22 - GraphTrainer - INFO - mrr@10: 0.017305
2025-12-15 19:55:22 - GraphTrainer - INFO - precision@20: 0.003592
2025-12-15 19:55:22 - GraphTrainer - INFO - recall@20: 0.068120
2025-12-15 19:55:22 - GraphTrainer - INFO - hit_rate@20: 0.071432
2025-12-15 19:55:22 - GraphTrainer - INFO - ndcg@20: 0.029286
2025-12-15 19:55:22 - GraphTrainer - INFO - map@20: 0.018236
2025-12-15 19:55:22 - GraphTrainer - INFO - mrr@20: 0.019046
2025-12-15 19:55:22 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:55:22 - GraphTrainer - INFO - ============================================================
2025-12-15 19:55:22 - GraphTrainer - INFO - 开始第 3/1000 轮训练
2025-12-15 19:55:22 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3807, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3658, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3582, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3703, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4010, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3619, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3674, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3845, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3631, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3534, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3573, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3732, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3580, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3532, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3611, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3747, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3262, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3799, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3624, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3467, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3588, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3802, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3688, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3537, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3682, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3710, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3649, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3630, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3457, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3752, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3548, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3672, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)
The 2 training average loss: 0.3556043803691864
2025-12-15 19:55:29 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:55:29 - GraphTrainer - INFO -   precision@5: 0.005739
2025-12-15 19:55:29 - GraphTrainer - INFO -   recall@5: 0.027621
2025-12-15 19:55:29 - GraphTrainer - INFO -   hit_rate@5: 0.028696
2025-12-15 19:55:29 - GraphTrainer - INFO -   ndcg@5: 0.018013
2025-12-15 19:55:29 - GraphTrainer - INFO -   map@5: 0.014679
2025-12-15 19:55:29 - GraphTrainer - INFO -   mrr@5: 0.015198
2025-12-15 19:55:29 - GraphTrainer - INFO -   precision@10: 0.004711
2025-12-15 19:55:29 - GraphTrainer - INFO -   recall@10: 0.044917
2025-12-15 19:55:29 - GraphTrainer - INFO -   hit_rate@10: 0.047056
2025-12-15 19:55:29 - GraphTrainer - INFO -   ndcg@10: 0.023628
2025-12-15 19:55:29 - GraphTrainer - INFO -   map@10: 0.016942
2025-12-15 19:55:29 - GraphTrainer - INFO -   mrr@10: 0.017599
2025-12-15 19:55:29 - GraphTrainer - INFO -   precision@20: 0.003672
2025-12-15 19:55:29 - GraphTrainer - INFO -   recall@20: 0.069761
2025-12-15 19:55:29 - GraphTrainer - INFO -   hit_rate@20: 0.073026
2025-12-15 19:55:29 - GraphTrainer - INFO -   ndcg@20: 0.029937
2025-12-15 19:55:29 - GraphTrainer - INFO -   map@20: 0.018631
2025-12-15 19:55:29 - GraphTrainer - INFO -   mrr@20: 0.019361
2025-12-15 19:55:29 - GraphTrainer - INFO - 第 3 轮训练完成
2025-12-15 19:55:29 - GraphTrainer - INFO - train_loss: 0.339615
2025-12-15 19:55:29 - GraphTrainer - INFO - precision@5: 0.005739
2025-12-15 19:55:29 - GraphTrainer - INFO - recall@5: 0.027621
2025-12-15 19:55:29 - GraphTrainer - INFO - hit_rate@5: 0.028696
2025-12-15 19:55:29 - GraphTrainer - INFO - ndcg@5: 0.018013
2025-12-15 19:55:29 - GraphTrainer - INFO - map@5: 0.014679
2025-12-15 19:55:29 - GraphTrainer - INFO - mrr@5: 0.015198
2025-12-15 19:55:29 - GraphTrainer - INFO - precision@10: 0.004711
2025-12-15 19:55:29 - GraphTrainer - INFO - recall@10: 0.044917
2025-12-15 19:55:29 - GraphTrainer - INFO - hit_rate@10: 0.047056
2025-12-15 19:55:29 - GraphTrainer - INFO - ndcg@10: 0.023628
2025-12-15 19:55:29 - GraphTrainer - INFO - map@10: 0.016942
2025-12-15 19:55:29 - GraphTrainer - INFO - mrr@10: 0.017599
2025-12-15 19:55:29 - GraphTrainer - INFO - precision@20: 0.003672
2025-12-15 19:55:29 - GraphTrainer - INFO - recall@20: 0.069761
2025-12-15 19:55:29 - GraphTrainer - INFO - hit_rate@20: 0.073026
2025-12-15 19:55:29 - GraphTrainer - INFO - ndcg@20: 0.029937
2025-12-15 19:55:29 - GraphTrainer - INFO - map@20: 0.018631
2025-12-15 19:55:29 - GraphTrainer - INFO - mrr@20: 0.019361
2025-12-15 19:55:29 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:55:29 - GraphTrainer - INFO - ============================================================
2025-12-15 19:55:29 - GraphTrainer - INFO - 开始第 4/1000 轮训练
2025-12-15 19:55:29 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3616, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3719, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3473, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3177, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3473, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3556, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3244, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3331, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3537, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3261, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3433, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3457, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3167, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3245, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3608, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3130, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3218, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3579, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3257, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3499, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3318, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3516, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3245, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3591, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3288, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3548, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3248, device='cuda:0', grad_fn=<AddBackward0>)
The 3 training average loss: 0.3396151918789436
2025-12-15 19:55:38 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:55:38 - GraphTrainer - INFO -   precision@5: 0.006068
2025-12-15 19:55:38 - GraphTrainer - INFO -   recall@5: 0.028963
2025-12-15 19:55:38 - GraphTrainer - INFO -   hit_rate@5: 0.030291
2025-12-15 19:55:38 - GraphTrainer - INFO -   ndcg@5: 0.018953
2025-12-15 19:55:38 - GraphTrainer - INFO -   map@5: 0.015454
2025-12-15 19:55:38 - GraphTrainer - INFO -   mrr@5: 0.016059
2025-12-15 19:55:38 - GraphTrainer - INFO -   precision@10: 0.004880
2025-12-15 19:55:38 - GraphTrainer - INFO -   recall@10: 0.046260
2025-12-15 19:55:38 - GraphTrainer - INFO -   hit_rate@10: 0.048599
2025-12-15 19:55:38 - GraphTrainer - INFO -   ndcg@10: 0.024560
2025-12-15 19:55:38 - GraphTrainer - INFO -   map@10: 0.017712
2025-12-15 19:55:38 - GraphTrainer - INFO -   mrr@10: 0.018440
2025-12-15 19:55:38 - GraphTrainer - INFO -   precision@20: 0.003839
2025-12-15 19:55:38 - GraphTrainer - INFO -   recall@20: 0.072672
2025-12-15 19:55:38 - GraphTrainer - INFO -   hit_rate@20: 0.076266
2025-12-15 19:55:38 - GraphTrainer - INFO -   ndcg@20: 0.031266
2025-12-15 19:55:38 - GraphTrainer - INFO -   map@20: 0.019510
2025-12-15 19:55:38 - GraphTrainer - INFO -   mrr@20: 0.020315
2025-12-15 19:55:38 - GraphTrainer - INFO - 第 4 轮训练完成
2025-12-15 19:55:38 - GraphTrainer - INFO - train_loss: 0.331013
2025-12-15 19:55:38 - GraphTrainer - INFO - precision@5: 0.006068
2025-12-15 19:55:38 - GraphTrainer - INFO - recall@5: 0.028963
2025-12-15 19:55:38 - GraphTrainer - INFO - hit_rate@5: 0.030291
2025-12-15 19:55:38 - GraphTrainer - INFO - ndcg@5: 0.018953
2025-12-15 19:55:38 - GraphTrainer - INFO - map@5: 0.015454
2025-12-15 19:55:38 - GraphTrainer - INFO - mrr@5: 0.016059
2025-12-15 19:55:38 - GraphTrainer - INFO - precision@10: 0.004880
2025-12-15 19:55:38 - GraphTrainer - INFO - recall@10: 0.046260
2025-12-15 19:55:38 - GraphTrainer - INFO - hit_rate@10: 0.048599
2025-12-15 19:55:38 - GraphTrainer - INFO - ndcg@10: 0.024560
2025-12-15 19:55:38 - GraphTrainer - INFO - map@10: 0.017712
2025-12-15 19:55:38 - GraphTrainer - INFO - mrr@10: 0.018440
2025-12-15 19:55:38 - GraphTrainer - INFO - precision@20: 0.003839
2025-12-15 19:55:38 - GraphTrainer - INFO - recall@20: 0.072672
2025-12-15 19:55:38 - GraphTrainer - INFO - hit_rate@20: 0.076266
2025-12-15 19:55:38 - GraphTrainer - INFO - ndcg@20: 0.031266
2025-12-15 19:55:38 - GraphTrainer - INFO - map@20: 0.019510
2025-12-15 19:55:38 - GraphTrainer - INFO - mrr@20: 0.020315
2025-12-15 19:55:38 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:55:38 - GraphTrainer - INFO - ============================================================
2025-12-15 19:55:38 - GraphTrainer - INFO - 开始第 5/1000 轮训练
2025-12-15 19:55:38 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3499, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3181, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3231, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3559, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3252, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3236, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3547, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3273, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3457, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3207, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3124, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3159, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3222, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3245, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3331, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3282, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3479, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3260, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3070, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3096, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3318, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3227, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3205, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3129, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3220, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3036, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3189, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3257, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3152, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3410, device='cuda:0', grad_fn=<AddBackward0>)
The 4 training average loss: 0.331012558320473
2025-12-15 19:55:46 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:55:46 - GraphTrainer - INFO -   precision@5: 0.006079
2025-12-15 19:55:46 - GraphTrainer - INFO -   recall@5: 0.029063
2025-12-15 19:55:46 - GraphTrainer - INFO -   hit_rate@5: 0.030342
2025-12-15 19:55:46 - GraphTrainer - INFO -   ndcg@5: 0.019003
2025-12-15 19:55:46 - GraphTrainer - INFO -   map@5: 0.015483
2025-12-15 19:55:46 - GraphTrainer - INFO -   mrr@5: 0.016059
2025-12-15 19:55:46 - GraphTrainer - INFO -   precision@10: 0.005107
2025-12-15 19:55:46 - GraphTrainer - INFO -   recall@10: 0.048580
2025-12-15 19:55:46 - GraphTrainer - INFO -   hit_rate@10: 0.050913
2025-12-15 19:55:46 - GraphTrainer - INFO -   ndcg@10: 0.025315
2025-12-15 19:55:46 - GraphTrainer - INFO -   map@10: 0.018020
2025-12-15 19:55:46 - GraphTrainer - INFO -   mrr@10: 0.018731
2025-12-15 19:55:46 - GraphTrainer - INFO -   precision@20: 0.003934
2025-12-15 19:55:46 - GraphTrainer - INFO -   recall@20: 0.074551
2025-12-15 19:55:46 - GraphTrainer - INFO -   hit_rate@20: 0.078221
2025-12-15 19:55:46 - GraphTrainer - INFO -   ndcg@20: 0.031913
2025-12-15 19:55:46 - GraphTrainer - INFO -   map@20: 0.019786
2025-12-15 19:55:46 - GraphTrainer - INFO -   mrr@20: 0.020580
2025-12-15 19:55:46 - GraphTrainer - INFO - 第 5 轮训练完成
2025-12-15 19:55:46 - GraphTrainer - INFO - train_loss: 0.319998
2025-12-15 19:55:46 - GraphTrainer - INFO - precision@5: 0.006079
2025-12-15 19:55:46 - GraphTrainer - INFO - recall@5: 0.029063
2025-12-15 19:55:46 - GraphTrainer - INFO - hit_rate@5: 0.030342
2025-12-15 19:55:46 - GraphTrainer - INFO - ndcg@5: 0.019003
2025-12-15 19:55:46 - GraphTrainer - INFO - map@5: 0.015483
2025-12-15 19:55:46 - GraphTrainer - INFO - mrr@5: 0.016059
2025-12-15 19:55:46 - GraphTrainer - INFO - precision@10: 0.005107
2025-12-15 19:55:46 - GraphTrainer - INFO - recall@10: 0.048580
2025-12-15 19:55:46 - GraphTrainer - INFO - hit_rate@10: 0.050913
2025-12-15 19:55:46 - GraphTrainer - INFO - ndcg@10: 0.025315
2025-12-15 19:55:46 - GraphTrainer - INFO - map@10: 0.018020
2025-12-15 19:55:46 - GraphTrainer - INFO - mrr@10: 0.018731
2025-12-15 19:55:46 - GraphTrainer - INFO - precision@20: 0.003934
2025-12-15 19:55:46 - GraphTrainer - INFO - recall@20: 0.074551
2025-12-15 19:55:46 - GraphTrainer - INFO - hit_rate@20: 0.078221
2025-12-15 19:55:46 - GraphTrainer - INFO - ndcg@20: 0.031913
2025-12-15 19:55:46 - GraphTrainer - INFO - map@20: 0.019786
2025-12-15 19:55:46 - GraphTrainer - INFO - mrr@20: 0.020580
2025-12-15 19:55:46 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:55:46 - GraphTrainer - INFO - ============================================================
2025-12-15 19:55:46 - GraphTrainer - INFO - 开始第 6/1000 轮训练
2025-12-15 19:55:46 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3046, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3199, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3209, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3518, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3167, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3131, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3214, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3082, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3373, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3061, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3082, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3455, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3163, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3194, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3035, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3002, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3185, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3163, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3217, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3179, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3192, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2959, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3192, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3236, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3020, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3055, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3176, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3051, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3033, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3097, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3274, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3284, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3154, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2979, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3136, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3020, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3184, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3135, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3072, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3580, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2990, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3215, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3072, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2954, device='cuda:0', grad_fn=<AddBackward0>)
The 5 training average loss: 0.3199976523374689
2025-12-15 19:55:54 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:55:54 - GraphTrainer - INFO -   precision@5: 0.006264
2025-12-15 19:55:54 - GraphTrainer - INFO -   recall@5: 0.029924
2025-12-15 19:55:54 - GraphTrainer - INFO -   hit_rate@5: 0.031268
2025-12-15 19:55:54 - GraphTrainer - INFO -   ndcg@5: 0.019736
2025-12-15 19:55:54 - GraphTrainer - INFO -   map@5: 0.016186
2025-12-15 19:55:54 - GraphTrainer - INFO -   mrr@5: 0.016751
2025-12-15 19:55:54 - GraphTrainer - INFO -   precision@10: 0.005066
2025-12-15 19:55:54 - GraphTrainer - INFO -   recall@10: 0.048150
2025-12-15 19:55:54 - GraphTrainer - INFO -   hit_rate@10: 0.050450
2025-12-15 19:55:54 - GraphTrainer - INFO -   ndcg@10: 0.025639
2025-12-15 19:55:54 - GraphTrainer - INFO -   map@10: 0.018565
2025-12-15 19:55:54 - GraphTrainer - INFO -   mrr@10: 0.019248
2025-12-15 19:55:54 - GraphTrainer - INFO -   precision@20: 0.003852
2025-12-15 19:55:54 - GraphTrainer - INFO -   recall@20: 0.073082
2025-12-15 19:55:54 - GraphTrainer - INFO -   hit_rate@20: 0.076524
2025-12-15 19:55:54 - GraphTrainer - INFO -   ndcg@20: 0.031959
2025-12-15 19:55:54 - GraphTrainer - INFO -   map@20: 0.020255
2025-12-15 19:55:54 - GraphTrainer - INFO -   mrr@20: 0.021010
2025-12-15 19:55:54 - GraphTrainer - INFO - 第 6 轮训练完成
2025-12-15 19:55:54 - GraphTrainer - INFO - train_loss: 0.314829
2025-12-15 19:55:54 - GraphTrainer - INFO - precision@5: 0.006264
2025-12-15 19:55:54 - GraphTrainer - INFO - recall@5: 0.029924
2025-12-15 19:55:54 - GraphTrainer - INFO - hit_rate@5: 0.031268
2025-12-15 19:55:54 - GraphTrainer - INFO - ndcg@5: 0.019736
2025-12-15 19:55:54 - GraphTrainer - INFO - map@5: 0.016186
2025-12-15 19:55:54 - GraphTrainer - INFO - mrr@5: 0.016751
2025-12-15 19:55:54 - GraphTrainer - INFO - precision@10: 0.005066
2025-12-15 19:55:54 - GraphTrainer - INFO - recall@10: 0.048150
2025-12-15 19:55:54 - GraphTrainer - INFO - hit_rate@10: 0.050450
2025-12-15 19:55:54 - GraphTrainer - INFO - ndcg@10: 0.025639
2025-12-15 19:55:54 - GraphTrainer - INFO - map@10: 0.018565
2025-12-15 19:55:54 - GraphTrainer - INFO - mrr@10: 0.019248
2025-12-15 19:55:54 - GraphTrainer - INFO - precision@20: 0.003852
2025-12-15 19:55:54 - GraphTrainer - INFO - recall@20: 0.073082
2025-12-15 19:55:54 - GraphTrainer - INFO - hit_rate@20: 0.076524
2025-12-15 19:55:54 - GraphTrainer - INFO - ndcg@20: 0.031959
2025-12-15 19:55:54 - GraphTrainer - INFO - map@20: 0.020255
2025-12-15 19:55:54 - GraphTrainer - INFO - mrr@20: 0.021010
2025-12-15 19:55:54 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:55:54 - GraphTrainer - INFO - ============================================================
2025-12-15 19:55:54 - GraphTrainer - INFO - 开始第 7/1000 轮训练
2025-12-15 19:55:54 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3158, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3045, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3236, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3146, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3135, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3168, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3166, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2968, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3213, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3150, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3246, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3246, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3186, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3183, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3155, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2994, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3168, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3066, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3157, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2893, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3104, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3025, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3088, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2970, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3184, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3098, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3203, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3174, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3121, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3212, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3457, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3103, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3062, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2830, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3033, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3051, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3166, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3232, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2996, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3119, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3087, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3184, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3030, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3013, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3052, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3248, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3037, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3042, device='cuda:0', grad_fn=<AddBackward0>)
The 6 training average loss: 0.31482869746356174
2025-12-15 19:56:03 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:56:03 - GraphTrainer - INFO -   precision@5: 0.006274
2025-12-15 19:56:03 - GraphTrainer - INFO -   recall@5: 0.030027
2025-12-15 19:56:03 - GraphTrainer - INFO -   hit_rate@5: 0.031319
2025-12-15 19:56:03 - GraphTrainer - INFO -   ndcg@5: 0.019745
2025-12-15 19:56:03 - GraphTrainer - INFO -   map@5: 0.016155
2025-12-15 19:56:03 - GraphTrainer - INFO -   mrr@5: 0.016799
2025-12-15 19:56:03 - GraphTrainer - INFO -   precision@10: 0.005066
2025-12-15 19:56:03 - GraphTrainer - INFO -   recall@10: 0.048155
2025-12-15 19:56:03 - GraphTrainer - INFO -   hit_rate@10: 0.050399
2025-12-15 19:56:03 - GraphTrainer - INFO -   ndcg@10: 0.025626
2025-12-15 19:56:03 - GraphTrainer - INFO -   map@10: 0.018529
2025-12-15 19:56:03 - GraphTrainer - INFO -   mrr@10: 0.019296
2025-12-15 19:56:03 - GraphTrainer - INFO -   precision@20: 0.003960
2025-12-15 19:56:03 - GraphTrainer - INFO -   recall@20: 0.075015
2025-12-15 19:56:03 - GraphTrainer - INFO -   hit_rate@20: 0.078632
2025-12-15 19:56:03 - GraphTrainer - INFO -   ndcg@20: 0.032435
2025-12-15 19:56:03 - GraphTrainer - INFO -   map@20: 0.020343
2025-12-15 19:56:03 - GraphTrainer - INFO -   mrr@20: 0.021201
2025-12-15 19:56:03 - GraphTrainer - INFO - 第 7 轮训练完成
2025-12-15 19:56:03 - GraphTrainer - INFO - train_loss: 0.308484
2025-12-15 19:56:03 - GraphTrainer - INFO - precision@5: 0.006274
2025-12-15 19:56:03 - GraphTrainer - INFO - recall@5: 0.030027
2025-12-15 19:56:03 - GraphTrainer - INFO - hit_rate@5: 0.031319
2025-12-15 19:56:03 - GraphTrainer - INFO - ndcg@5: 0.019745
2025-12-15 19:56:03 - GraphTrainer - INFO - map@5: 0.016155
2025-12-15 19:56:03 - GraphTrainer - INFO - mrr@5: 0.016799
2025-12-15 19:56:03 - GraphTrainer - INFO - precision@10: 0.005066
2025-12-15 19:56:03 - GraphTrainer - INFO - recall@10: 0.048155
2025-12-15 19:56:03 - GraphTrainer - INFO - hit_rate@10: 0.050399
2025-12-15 19:56:03 - GraphTrainer - INFO - ndcg@10: 0.025626
2025-12-15 19:56:03 - GraphTrainer - INFO - map@10: 0.018529
2025-12-15 19:56:03 - GraphTrainer - INFO - mrr@10: 0.019296
2025-12-15 19:56:03 - GraphTrainer - INFO - precision@20: 0.003960
2025-12-15 19:56:03 - GraphTrainer - INFO - recall@20: 0.075015
2025-12-15 19:56:03 - GraphTrainer - INFO - hit_rate@20: 0.078632
2025-12-15 19:56:03 - GraphTrainer - INFO - ndcg@20: 0.032435
2025-12-15 19:56:03 - GraphTrainer - INFO - map@20: 0.020343
2025-12-15 19:56:03 - GraphTrainer - INFO - mrr@20: 0.021201
2025-12-15 19:56:03 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:56:03 - GraphTrainer - INFO - ============================================================
2025-12-15 19:56:03 - GraphTrainer - INFO - 开始第 8/1000 轮训练
2025-12-15 19:56:03 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3091, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3039, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3066, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3029, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3050, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3090, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3097, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3165, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3010, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3234, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3177, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3196, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3099, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3099, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2933, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3028, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3130, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3053, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3142, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3140, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3208, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2928, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3052, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3044, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3090, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3262, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2996, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2959, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2983, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3120, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2897, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2984, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3105, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2932, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3169, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2981, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3141, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3059, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3126, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3027, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3147, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3279, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3207, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3244, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3140, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2965, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3081, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3081, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2976, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2944, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3282, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2920, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3021, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2982, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2995, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2964, device='cuda:0', grad_fn=<AddBackward0>)
The 7 training average loss: 0.30848406306628523
2025-12-15 19:56:11 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:56:11 - GraphTrainer - INFO -   precision@5: 0.006336
2025-12-15 19:56:11 - GraphTrainer - INFO -   recall@5: 0.030263
2025-12-15 19:56:11 - GraphTrainer - INFO -   hit_rate@5: 0.031628
2025-12-15 19:56:11 - GraphTrainer - INFO -   ndcg@5: 0.019846
2025-12-15 19:56:11 - GraphTrainer - INFO -   map@5: 0.016225
2025-12-15 19:56:11 - GraphTrainer - INFO -   mrr@5: 0.016826
2025-12-15 19:56:11 - GraphTrainer - INFO -   precision@10: 0.004932
2025-12-15 19:56:11 - GraphTrainer - INFO -   recall@10: 0.046914
2025-12-15 19:56:11 - GraphTrainer - INFO -   hit_rate@10: 0.049164
2025-12-15 19:56:11 - GraphTrainer - INFO -   ndcg@10: 0.025233
2025-12-15 19:56:11 - GraphTrainer - INFO -   map@10: 0.018390
2025-12-15 19:56:11 - GraphTrainer - INFO -   mrr@10: 0.019104
2025-12-15 19:56:11 - GraphTrainer - INFO -   precision@20: 0.003875
2025-12-15 19:56:11 - GraphTrainer - INFO -   recall@20: 0.073282
2025-12-15 19:56:11 - GraphTrainer - INFO -   hit_rate@20: 0.076935
2025-12-15 19:56:11 - GraphTrainer - INFO -   ndcg@20: 0.031945
2025-12-15 19:56:11 - GraphTrainer - INFO -   map@20: 0.020191
2025-12-15 19:56:11 - GraphTrainer - INFO -   mrr@20: 0.020990
2025-12-15 19:56:11 - GraphTrainer - INFO - 第 8 轮训练完成
2025-12-15 19:56:11 - GraphTrainer - INFO - train_loss: 0.301175
2025-12-15 19:56:11 - GraphTrainer - INFO - precision@5: 0.006336
2025-12-15 19:56:11 - GraphTrainer - INFO - recall@5: 0.030263
2025-12-15 19:56:11 - GraphTrainer - INFO - hit_rate@5: 0.031628
2025-12-15 19:56:11 - GraphTrainer - INFO - ndcg@5: 0.019846
2025-12-15 19:56:11 - GraphTrainer - INFO - map@5: 0.016225
2025-12-15 19:56:11 - GraphTrainer - INFO - mrr@5: 0.016826
2025-12-15 19:56:11 - GraphTrainer - INFO - precision@10: 0.004932
2025-12-15 19:56:11 - GraphTrainer - INFO - recall@10: 0.046914
2025-12-15 19:56:11 - GraphTrainer - INFO - hit_rate@10: 0.049164
2025-12-15 19:56:11 - GraphTrainer - INFO - ndcg@10: 0.025233
2025-12-15 19:56:11 - GraphTrainer - INFO - map@10: 0.018390
2025-12-15 19:56:11 - GraphTrainer - INFO - mrr@10: 0.019104
2025-12-15 19:56:11 - GraphTrainer - INFO - precision@20: 0.003875
2025-12-15 19:56:11 - GraphTrainer - INFO - recall@20: 0.073282
2025-12-15 19:56:11 - GraphTrainer - INFO - hit_rate@20: 0.076935
2025-12-15 19:56:11 - GraphTrainer - INFO - ndcg@20: 0.031945
2025-12-15 19:56:11 - GraphTrainer - INFO - map@20: 0.020191
2025-12-15 19:56:11 - GraphTrainer - INFO - mrr@20: 0.020990
2025-12-15 19:56:11 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:56:11 - GraphTrainer - INFO - ============================================================
2025-12-15 19:56:11 - GraphTrainer - INFO - 开始第 9/1000 轮训练
2025-12-15 19:56:11 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2917, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3109, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3196, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2871, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3000, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3081, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2949, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3102, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3121, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3001, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3092, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2853, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3257, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2702, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2917, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3008, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2860, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3121, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2718, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3193, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2949, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2816, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3043, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3114, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2901, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3176, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3060, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2978, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2905, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2819, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2906, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2773, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3045, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2968, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2894, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2926, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3223, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3073, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3005, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2954, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3025, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3122, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3209, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2995, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3056, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2965, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2986, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3034, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2875, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2995, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3216, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2929, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3007, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3025, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2944, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3114, device='cuda:0', grad_fn=<AddBackward0>)
The 8 training average loss: 0.30117471773048926
2025-12-15 19:56:19 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:56:19 - GraphTrainer - INFO -   precision@5: 0.006305
2025-12-15 19:56:19 - GraphTrainer - INFO -   recall@5: 0.029991
2025-12-15 19:56:19 - GraphTrainer - INFO -   hit_rate@5: 0.031525
2025-12-15 19:56:19 - GraphTrainer - INFO -   ndcg@5: 0.019947
2025-12-15 19:56:19 - GraphTrainer - INFO -   map@5: 0.016388
2025-12-15 19:56:19 - GraphTrainer - INFO -   mrr@5: 0.017166
2025-12-15 19:56:19 - GraphTrainer - INFO -   precision@10: 0.005030
2025-12-15 19:56:19 - GraphTrainer - INFO -   recall@10: 0.047534
2025-12-15 19:56:19 - GraphTrainer - INFO -   hit_rate@10: 0.050090
2025-12-15 19:56:19 - GraphTrainer - INFO -   ndcg@10: 0.025677
2025-12-15 19:56:19 - GraphTrainer - INFO -   map@10: 0.018717
2025-12-15 19:56:19 - GraphTrainer - INFO -   mrr@10: 0.019623
2025-12-15 19:56:19 - GraphTrainer - INFO -   precision@20: 0.004063
2025-12-15 19:56:19 - GraphTrainer - INFO -   recall@20: 0.076691
2025-12-15 19:56:19 - GraphTrainer - INFO -   hit_rate@20: 0.080792
2025-12-15 19:56:19 - GraphTrainer - INFO -   ndcg@20: 0.033102
2025-12-15 19:56:19 - GraphTrainer - INFO -   map@20: 0.020713
2025-12-15 19:56:19 - GraphTrainer - INFO -   mrr@20: 0.021718
2025-12-15 19:56:19 - GraphTrainer - INFO - 第 9 轮训练完成
2025-12-15 19:56:19 - GraphTrainer - INFO - train_loss: 0.295610
2025-12-15 19:56:19 - GraphTrainer - INFO - precision@5: 0.006305
2025-12-15 19:56:19 - GraphTrainer - INFO - recall@5: 0.029991
2025-12-15 19:56:19 - GraphTrainer - INFO - hit_rate@5: 0.031525
2025-12-15 19:56:19 - GraphTrainer - INFO - ndcg@5: 0.019947
2025-12-15 19:56:19 - GraphTrainer - INFO - map@5: 0.016388
2025-12-15 19:56:19 - GraphTrainer - INFO - mrr@5: 0.017166
2025-12-15 19:56:19 - GraphTrainer - INFO - precision@10: 0.005030
2025-12-15 19:56:19 - GraphTrainer - INFO - recall@10: 0.047534
2025-12-15 19:56:19 - GraphTrainer - INFO - hit_rate@10: 0.050090
2025-12-15 19:56:19 - GraphTrainer - INFO - ndcg@10: 0.025677
2025-12-15 19:56:19 - GraphTrainer - INFO - map@10: 0.018717
2025-12-15 19:56:19 - GraphTrainer - INFO - mrr@10: 0.019623
2025-12-15 19:56:19 - GraphTrainer - INFO - precision@20: 0.004063
2025-12-15 19:56:19 - GraphTrainer - INFO - recall@20: 0.076691
2025-12-15 19:56:19 - GraphTrainer - INFO - hit_rate@20: 0.080792
2025-12-15 19:56:19 - GraphTrainer - INFO - ndcg@20: 0.033102
2025-12-15 19:56:19 - GraphTrainer - INFO - map@20: 0.020713
2025-12-15 19:56:19 - GraphTrainer - INFO - mrr@20: 0.021718
2025-12-15 19:56:19 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:56:19 - GraphTrainer - INFO - ============================================================
2025-12-15 19:56:19 - GraphTrainer - INFO - 开始第 10/1000 轮训练
2025-12-15 19:56:19 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3003, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3078, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2953, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2748, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3210, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3060, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2862, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3045, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2938, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2948, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3021, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2887, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2918, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2711, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3146, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3063, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3099, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2972, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3024, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2793, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2845, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2953, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2854, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3036, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2840, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2902, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2866, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2900, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2992, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2976, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2991, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2591, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2930, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2958, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2821, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2904, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3036, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2879, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3086, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2754, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3028, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3007, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3038, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3111, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2916, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2989, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2745, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2797, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3003, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2898, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2909, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2882, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2914, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2965, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3125, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2957, device='cuda:0', grad_fn=<AddBackward0>)
The 9 training average loss: 0.29561041809361555
2025-12-15 19:56:27 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:56:27 - GraphTrainer - INFO -   precision@5: 0.006480
2025-12-15 19:56:27 - GraphTrainer - INFO -   recall@5: 0.030977
2025-12-15 19:56:27 - GraphTrainer - INFO -   hit_rate@5: 0.032399
2025-12-15 19:56:27 - GraphTrainer - INFO -   ndcg@5: 0.020243
2025-12-15 19:56:27 - GraphTrainer - INFO -   map@5: 0.016488
2025-12-15 19:56:27 - GraphTrainer - INFO -   mrr@5: 0.017230
2025-12-15 19:56:27 - GraphTrainer - INFO -   precision@10: 0.005240
2025-12-15 19:56:27 - GraphTrainer - INFO -   recall@10: 0.049750
2025-12-15 19:56:27 - GraphTrainer - INFO -   hit_rate@10: 0.052353
2025-12-15 19:56:27 - GraphTrainer - INFO -   ndcg@10: 0.026317
2025-12-15 19:56:27 - GraphTrainer - INFO -   map@10: 0.018923
2025-12-15 19:56:27 - GraphTrainer - INFO -   mrr@10: 0.019810
2025-12-15 19:56:27 - GraphTrainer - INFO -   precision@20: 0.004127
2025-12-15 19:56:27 - GraphTrainer - INFO -   recall@20: 0.078131
2025-12-15 19:56:27 - GraphTrainer - INFO -   hit_rate@20: 0.082078
2025-12-15 19:56:27 - GraphTrainer - INFO -   ndcg@20: 0.033573
2025-12-15 19:56:27 - GraphTrainer - INFO -   map@20: 0.020892
2025-12-15 19:56:27 - GraphTrainer - INFO -   mrr@20: 0.021864
2025-12-15 19:56:27 - GraphTrainer - INFO - 第 10 轮训练完成
2025-12-15 19:56:27 - GraphTrainer - INFO - train_loss: 0.291758
2025-12-15 19:56:27 - GraphTrainer - INFO - precision@5: 0.006480
2025-12-15 19:56:27 - GraphTrainer - INFO - recall@5: 0.030977
2025-12-15 19:56:27 - GraphTrainer - INFO - hit_rate@5: 0.032399
2025-12-15 19:56:27 - GraphTrainer - INFO - ndcg@5: 0.020243
2025-12-15 19:56:27 - GraphTrainer - INFO - map@5: 0.016488
2025-12-15 19:56:27 - GraphTrainer - INFO - mrr@5: 0.017230
2025-12-15 19:56:27 - GraphTrainer - INFO - precision@10: 0.005240
2025-12-15 19:56:27 - GraphTrainer - INFO - recall@10: 0.049750
2025-12-15 19:56:27 - GraphTrainer - INFO - hit_rate@10: 0.052353
2025-12-15 19:56:27 - GraphTrainer - INFO - ndcg@10: 0.026317
2025-12-15 19:56:27 - GraphTrainer - INFO - map@10: 0.018923
2025-12-15 19:56:27 - GraphTrainer - INFO - mrr@10: 0.019810
2025-12-15 19:56:27 - GraphTrainer - INFO - precision@20: 0.004127
2025-12-15 19:56:27 - GraphTrainer - INFO - recall@20: 0.078131
2025-12-15 19:56:27 - GraphTrainer - INFO - hit_rate@20: 0.082078
2025-12-15 19:56:27 - GraphTrainer - INFO - ndcg@20: 0.033573
2025-12-15 19:56:27 - GraphTrainer - INFO - map@20: 0.020892
2025-12-15 19:56:27 - GraphTrainer - INFO - mrr@20: 0.021864
2025-12-15 19:56:27 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:56:27 - GraphTrainer - INFO - 检查点已保存: Epoch 10 -> ./checkpoints/checkpoint_epoch_10.pth
2025-12-15 19:56:27 - GraphTrainer - INFO - ============================================================
2025-12-15 19:56:27 - GraphTrainer - INFO - 开始第 11/1000 轮训练
2025-12-15 19:56:27 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2908, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3096, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2885, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2906, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2732, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2674, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3053, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2973, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2899, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2836, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2991, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2779, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3003, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2937, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2933, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2800, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2951, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2915, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2850, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3167, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3177, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2958, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2907, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2921, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3181, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2892, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2774, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2800, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2885, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2998, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3016, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2869, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3012, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2700, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3116, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2954, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2964, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3053, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3013, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2861, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2789, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2821, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2614, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3023, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2797, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2847, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2766, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2925, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3220, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3040, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2856, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2777, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2641, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2773, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2992, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3118, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3148, device='cuda:0', grad_fn=<AddBackward0>)
The 10 training average loss: 0.2917578097047477
2025-12-15 19:56:35 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:56:35 - GraphTrainer - INFO -   precision@5: 0.006583
2025-12-15 19:56:35 - GraphTrainer - INFO -   recall@5: 0.031574
2025-12-15 19:56:35 - GraphTrainer - INFO -   hit_rate@5: 0.032862
2025-12-15 19:56:35 - GraphTrainer - INFO -   ndcg@5: 0.020470
2025-12-15 19:56:35 - GraphTrainer - INFO -   map@5: 0.016598
2025-12-15 19:56:35 - GraphTrainer - INFO -   mrr@5: 0.017298
2025-12-15 19:56:35 - GraphTrainer - INFO -   precision@10: 0.005307
2025-12-15 19:56:35 - GraphTrainer - INFO -   recall@10: 0.050315
2025-12-15 19:56:35 - GraphTrainer - INFO -   hit_rate@10: 0.052970
2025-12-15 19:56:35 - GraphTrainer - INFO -   ndcg@10: 0.026551
2025-12-15 19:56:35 - GraphTrainer - INFO -   map@10: 0.019034
2025-12-15 19:56:35 - GraphTrainer - INFO -   mrr@10: 0.019908
2025-12-15 19:56:35 - GraphTrainer - INFO -   precision@20: 0.004153
2025-12-15 19:56:35 - GraphTrainer - INFO -   recall@20: 0.078636
2025-12-15 19:56:35 - GraphTrainer - INFO -   hit_rate@20: 0.082592
2025-12-15 19:56:35 - GraphTrainer - INFO -   ndcg@20: 0.033734
2025-12-15 19:56:35 - GraphTrainer - INFO -   map@20: 0.020956
2025-12-15 19:56:35 - GraphTrainer - INFO -   mrr@20: 0.021908
2025-12-15 19:56:35 - GraphTrainer - INFO - 第 11 轮训练完成
2025-12-15 19:56:35 - GraphTrainer - INFO - train_loss: 0.286905
2025-12-15 19:56:35 - GraphTrainer - INFO - precision@5: 0.006583
2025-12-15 19:56:35 - GraphTrainer - INFO - recall@5: 0.031574
2025-12-15 19:56:35 - GraphTrainer - INFO - hit_rate@5: 0.032862
2025-12-15 19:56:35 - GraphTrainer - INFO - ndcg@5: 0.020470
2025-12-15 19:56:35 - GraphTrainer - INFO - map@5: 0.016598
2025-12-15 19:56:35 - GraphTrainer - INFO - mrr@5: 0.017298
2025-12-15 19:56:35 - GraphTrainer - INFO - precision@10: 0.005307
2025-12-15 19:56:35 - GraphTrainer - INFO - recall@10: 0.050315
2025-12-15 19:56:35 - GraphTrainer - INFO - hit_rate@10: 0.052970
2025-12-15 19:56:35 - GraphTrainer - INFO - ndcg@10: 0.026551
2025-12-15 19:56:35 - GraphTrainer - INFO - map@10: 0.019034
2025-12-15 19:56:35 - GraphTrainer - INFO - mrr@10: 0.019908
2025-12-15 19:56:35 - GraphTrainer - INFO - precision@20: 0.004153
2025-12-15 19:56:35 - GraphTrainer - INFO - recall@20: 0.078636
2025-12-15 19:56:35 - GraphTrainer - INFO - hit_rate@20: 0.082592
2025-12-15 19:56:35 - GraphTrainer - INFO - ndcg@20: 0.033734
2025-12-15 19:56:35 - GraphTrainer - INFO - map@20: 0.020956
2025-12-15 19:56:35 - GraphTrainer - INFO - mrr@20: 0.021908
2025-12-15 19:56:35 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:56:35 - GraphTrainer - INFO - ============================================================
2025-12-15 19:56:35 - GraphTrainer - INFO - 开始第 12/1000 轮训练
2025-12-15 19:56:35 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2871, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3186, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2926, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2711, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3087, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2861, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3006, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2818, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2988, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2812, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2762, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2729, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2706, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3077, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2991, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2795, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2704, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2958, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2757, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2893, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3004, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3044, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2836, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2711, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2673, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2811, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2703, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2810, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2685, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3028, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2932, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2817, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2745, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2928, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2860, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2841, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2896, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2820, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2849, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2709, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2910, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2982, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2980, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2834, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2948, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2980, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2881, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3053, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3087, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2703, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2872, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2891, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2915, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2952, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2917, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2644, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2861, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2655, device='cuda:0', grad_fn=<AddBackward0>)
The 11 training average loss: 0.2869052141904831
2025-12-15 19:56:43 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:56:43 - GraphTrainer - INFO -   precision@5: 0.006428
2025-12-15 19:56:43 - GraphTrainer - INFO -   recall@5: 0.030577
2025-12-15 19:56:43 - GraphTrainer - INFO -   hit_rate@5: 0.032142
2025-12-15 19:56:43 - GraphTrainer - INFO -   ndcg@5: 0.020279
2025-12-15 19:56:43 - GraphTrainer - INFO -   map@5: 0.016638
2025-12-15 19:56:43 - GraphTrainer - INFO -   mrr@5: 0.017381
2025-12-15 19:56:43 - GraphTrainer - INFO -   precision@10: 0.005261
2025-12-15 19:56:43 - GraphTrainer - INFO -   recall@10: 0.049922
2025-12-15 19:56:43 - GraphTrainer - INFO -   hit_rate@10: 0.052404
2025-12-15 19:56:43 - GraphTrainer - INFO -   ndcg@10: 0.026590
2025-12-15 19:56:43 - GraphTrainer - INFO -   map@10: 0.019212
2025-12-15 19:56:43 - GraphTrainer - INFO -   mrr@10: 0.020065
2025-12-15 19:56:43 - GraphTrainer - INFO -   precision@20: 0.004166
2025-12-15 19:56:43 - GraphTrainer - INFO -   recall@20: 0.079052
2025-12-15 19:56:43 - GraphTrainer - INFO -   hit_rate@20: 0.083055
2025-12-15 19:56:43 - GraphTrainer - INFO -   ndcg@20: 0.033957
2025-12-15 19:56:43 - GraphTrainer - INFO -   map@20: 0.021170
2025-12-15 19:56:43 - GraphTrainer - INFO -   mrr@20: 0.022126
2025-12-15 19:56:43 - GraphTrainer - INFO - 第 12 轮训练完成
2025-12-15 19:56:43 - GraphTrainer - INFO - train_loss: 0.284119
2025-12-15 19:56:43 - GraphTrainer - INFO - precision@5: 0.006428
2025-12-15 19:56:43 - GraphTrainer - INFO - recall@5: 0.030577
2025-12-15 19:56:43 - GraphTrainer - INFO - hit_rate@5: 0.032142
2025-12-15 19:56:43 - GraphTrainer - INFO - ndcg@5: 0.020279
2025-12-15 19:56:43 - GraphTrainer - INFO - map@5: 0.016638
2025-12-15 19:56:43 - GraphTrainer - INFO - mrr@5: 0.017381
2025-12-15 19:56:43 - GraphTrainer - INFO - precision@10: 0.005261
2025-12-15 19:56:43 - GraphTrainer - INFO - recall@10: 0.049922
2025-12-15 19:56:43 - GraphTrainer - INFO - hit_rate@10: 0.052404
2025-12-15 19:56:43 - GraphTrainer - INFO - ndcg@10: 0.026590
2025-12-15 19:56:43 - GraphTrainer - INFO - map@10: 0.019212
2025-12-15 19:56:43 - GraphTrainer - INFO - mrr@10: 0.020065
2025-12-15 19:56:43 - GraphTrainer - INFO - precision@20: 0.004166
2025-12-15 19:56:43 - GraphTrainer - INFO - recall@20: 0.079052
2025-12-15 19:56:43 - GraphTrainer - INFO - hit_rate@20: 0.083055
2025-12-15 19:56:43 - GraphTrainer - INFO - ndcg@20: 0.033957
2025-12-15 19:56:43 - GraphTrainer - INFO - map@20: 0.021170
2025-12-15 19:56:43 - GraphTrainer - INFO - mrr@20: 0.022126
2025-12-15 19:56:43 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:56:43 - GraphTrainer - INFO - ============================================================
2025-12-15 19:56:43 - GraphTrainer - INFO - 开始第 13/1000 轮训练
2025-12-15 19:56:43 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2878, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2967, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2946, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2726, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2981, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2697, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2849, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2915, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2973, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2803, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2926, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2802, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2741, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2716, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2865, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3085, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2774, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2895, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2893, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3025, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2673, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2726, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3003, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2815, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2770, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2753, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2694, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2730, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2973, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2719, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2803, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2835, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3140, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2856, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2746, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2995, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2989, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2849, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2720, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2911, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3041, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2794, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2742, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2721, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2895, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2995, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2771, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2670, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2771, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2864, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3050, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2731, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2752, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2713, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2705, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2898, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2865, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2655, device='cuda:0', grad_fn=<AddBackward0>)
The 12 training average loss: 0.2841186831737387
2025-12-15 19:56:51 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:56:51 - GraphTrainer - INFO -   precision@5: 0.006490
2025-12-15 19:56:51 - GraphTrainer - INFO -   recall@5: 0.031097
2025-12-15 19:56:51 - GraphTrainer - INFO -   hit_rate@5: 0.032451
2025-12-15 19:56:51 - GraphTrainer - INFO -   ndcg@5: 0.020620
2025-12-15 19:56:51 - GraphTrainer - INFO -   map@5: 0.016953
2025-12-15 19:56:51 - GraphTrainer - INFO -   mrr@5: 0.017686
2025-12-15 19:56:51 - GraphTrainer - INFO -   precision@10: 0.005189
2025-12-15 19:56:51 - GraphTrainer - INFO -   recall@10: 0.049497
2025-12-15 19:56:51 - GraphTrainer - INFO -   hit_rate@10: 0.051839
2025-12-15 19:56:51 - GraphTrainer - INFO -   ndcg@10: 0.026592
2025-12-15 19:56:51 - GraphTrainer - INFO -   map@10: 0.019368
2025-12-15 19:56:51 - GraphTrainer - INFO -   mrr@10: 0.020224
2025-12-15 19:56:51 - GraphTrainer - INFO -   precision@20: 0.004181
2025-12-15 19:56:51 - GraphTrainer - INFO -   recall@20: 0.079182
2025-12-15 19:56:51 - GraphTrainer - INFO -   hit_rate@20: 0.083260
2025-12-15 19:56:51 - GraphTrainer - INFO -   ndcg@20: 0.034168
2025-12-15 19:56:51 - GraphTrainer - INFO -   map@20: 0.021405
2025-12-15 19:56:51 - GraphTrainer - INFO -   mrr@20: 0.022376
2025-12-15 19:56:51 - GraphTrainer - INFO - 第 13 轮训练完成
2025-12-15 19:56:51 - GraphTrainer - INFO - train_loss: 0.282154
2025-12-15 19:56:51 - GraphTrainer - INFO - precision@5: 0.006490
2025-12-15 19:56:51 - GraphTrainer - INFO - recall@5: 0.031097
2025-12-15 19:56:51 - GraphTrainer - INFO - hit_rate@5: 0.032451
2025-12-15 19:56:51 - GraphTrainer - INFO - ndcg@5: 0.020620
2025-12-15 19:56:51 - GraphTrainer - INFO - map@5: 0.016953
2025-12-15 19:56:51 - GraphTrainer - INFO - mrr@5: 0.017686
2025-12-15 19:56:51 - GraphTrainer - INFO - precision@10: 0.005189
2025-12-15 19:56:51 - GraphTrainer - INFO - recall@10: 0.049497
2025-12-15 19:56:51 - GraphTrainer - INFO - hit_rate@10: 0.051839
2025-12-15 19:56:51 - GraphTrainer - INFO - ndcg@10: 0.026592
2025-12-15 19:56:51 - GraphTrainer - INFO - map@10: 0.019368
2025-12-15 19:56:51 - GraphTrainer - INFO - mrr@10: 0.020224
2025-12-15 19:56:51 - GraphTrainer - INFO - precision@20: 0.004181
2025-12-15 19:56:51 - GraphTrainer - INFO - recall@20: 0.079182
2025-12-15 19:56:51 - GraphTrainer - INFO - hit_rate@20: 0.083260
2025-12-15 19:56:51 - GraphTrainer - INFO - ndcg@20: 0.034168
2025-12-15 19:56:51 - GraphTrainer - INFO - map@20: 0.021405
2025-12-15 19:56:51 - GraphTrainer - INFO - mrr@20: 0.022376
2025-12-15 19:56:51 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:56:51 - GraphTrainer - INFO - ============================================================
2025-12-15 19:56:51 - GraphTrainer - INFO - 开始第 14/1000 轮训练
2025-12-15 19:56:51 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2926, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2735, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3032, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2771, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2864, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2747, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2830, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2938, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2856, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2942, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2690, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2871, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2805, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2984, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2798, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2892, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3038, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3007, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2834, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2849, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2895, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2736, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2794, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2968, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2812, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2830, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3011, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2684, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2786, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2760, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2933, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2615, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2832, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2806, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2953, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3061, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2822, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2949, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2813, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2615, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2690, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2884, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2805, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2838, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2539, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2754, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2713, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2779, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2933, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2936, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2653, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2725, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2648, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2842, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2728, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2484, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2878, device='cuda:0', grad_fn=<AddBackward0>)
The 13 training average loss: 0.282154377678345
2025-12-15 19:56:59 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:56:59 - GraphTrainer - INFO -   precision@5: 0.006531
2025-12-15 19:56:59 - GraphTrainer - INFO -   recall@5: 0.031228
2025-12-15 19:56:59 - GraphTrainer - INFO -   hit_rate@5: 0.032656
2025-12-15 19:56:59 - GraphTrainer - INFO -   ndcg@5: 0.020122
2025-12-15 19:56:59 - GraphTrainer - INFO -   map@5: 0.016234
2025-12-15 19:56:59 - GraphTrainer - INFO -   mrr@5: 0.017015
2025-12-15 19:56:59 - GraphTrainer - INFO -   precision@10: 0.005210
2025-12-15 19:56:59 - GraphTrainer - INFO -   recall@10: 0.049449
2025-12-15 19:56:59 - GraphTrainer - INFO -   hit_rate@10: 0.051993
2025-12-15 19:56:59 - GraphTrainer - INFO -   ndcg@10: 0.026057
2025-12-15 19:56:59 - GraphTrainer - INFO -   map@10: 0.018636
2025-12-15 19:56:59 - GraphTrainer - INFO -   mrr@10: 0.019559
2025-12-15 19:56:59 - GraphTrainer - INFO -   precision@20: 0.004155
2025-12-15 19:56:59 - GraphTrainer - INFO -   recall@20: 0.078578
2025-12-15 19:56:59 - GraphTrainer - INFO -   hit_rate@20: 0.082643
2025-12-15 19:56:59 - GraphTrainer - INFO -   ndcg@20: 0.033476
2025-12-15 19:56:59 - GraphTrainer - INFO -   map@20: 0.020631
2025-12-15 19:56:59 - GraphTrainer - INFO -   mrr@20: 0.021651
2025-12-15 19:56:59 - GraphTrainer - INFO - 第 14 轮训练完成
2025-12-15 19:56:59 - GraphTrainer - INFO - train_loss: 0.277352
2025-12-15 19:56:59 - GraphTrainer - INFO - precision@5: 0.006531
2025-12-15 19:56:59 - GraphTrainer - INFO - recall@5: 0.031228
2025-12-15 19:56:59 - GraphTrainer - INFO - hit_rate@5: 0.032656
2025-12-15 19:56:59 - GraphTrainer - INFO - ndcg@5: 0.020122
2025-12-15 19:56:59 - GraphTrainer - INFO - map@5: 0.016234
2025-12-15 19:56:59 - GraphTrainer - INFO - mrr@5: 0.017015
2025-12-15 19:56:59 - GraphTrainer - INFO - precision@10: 0.005210
2025-12-15 19:56:59 - GraphTrainer - INFO - recall@10: 0.049449
2025-12-15 19:56:59 - GraphTrainer - INFO - hit_rate@10: 0.051993
2025-12-15 19:56:59 - GraphTrainer - INFO - ndcg@10: 0.026057
2025-12-15 19:56:59 - GraphTrainer - INFO - map@10: 0.018636
2025-12-15 19:56:59 - GraphTrainer - INFO - mrr@10: 0.019559
2025-12-15 19:56:59 - GraphTrainer - INFO - precision@20: 0.004155
2025-12-15 19:56:59 - GraphTrainer - INFO - recall@20: 0.078578
2025-12-15 19:56:59 - GraphTrainer - INFO - hit_rate@20: 0.082643
2025-12-15 19:56:59 - GraphTrainer - INFO - ndcg@20: 0.033476
2025-12-15 19:56:59 - GraphTrainer - INFO - map@20: 0.020631
2025-12-15 19:56:59 - GraphTrainer - INFO - mrr@20: 0.021651
2025-12-15 19:56:59 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:56:59 - GraphTrainer - INFO - ============================================================
2025-12-15 19:56:59 - GraphTrainer - INFO - 开始第 15/1000 轮训练
2025-12-15 19:56:59 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2731, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2908, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2940, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2826, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2974, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2944, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2846, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2922, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2987, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2755, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2753, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2728, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2787, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2898, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2871, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2564, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2621, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2631, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2673, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2990, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2655, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2717, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2617, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2710, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2706, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2949, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2573, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2771, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2885, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2669, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2507, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2873, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2520, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2557, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2748, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2945, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2646, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3046, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2793, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2865, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2553, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2628, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2697, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2773, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2682, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2717, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2751, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3020, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2978, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2808, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2972, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2662, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2875, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2510, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2907, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2849, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2720, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2660, device='cuda:0', grad_fn=<AddBackward0>)
The 14 training average loss: 0.27735195385998695
2025-12-15 19:57:07 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:57:07 - GraphTrainer - INFO -   precision@5: 0.006747
2025-12-15 19:57:07 - GraphTrainer - INFO -   recall@5: 0.032318
2025-12-15 19:57:07 - GraphTrainer - INFO -   hit_rate@5: 0.033736
2025-12-15 19:57:07 - GraphTrainer - INFO -   ndcg@5: 0.021108
2025-12-15 19:57:07 - GraphTrainer - INFO -   map@5: 0.017196
2025-12-15 19:57:07 - GraphTrainer - INFO -   mrr@5: 0.017953
2025-12-15 19:57:07 - GraphTrainer - INFO -   precision@10: 0.005379
2025-12-15 19:57:07 - GraphTrainer - INFO -   recall@10: 0.051168
2025-12-15 19:57:07 - GraphTrainer - INFO -   hit_rate@10: 0.053638
2025-12-15 19:57:07 - GraphTrainer - INFO -   ndcg@10: 0.027213
2025-12-15 19:57:07 - GraphTrainer - INFO -   map@10: 0.019650
2025-12-15 19:57:07 - GraphTrainer - INFO -   mrr@10: 0.020543
2025-12-15 19:57:07 - GraphTrainer - INFO -   precision@20: 0.004196
2025-12-15 19:57:07 - GraphTrainer - INFO -   recall@20: 0.079365
2025-12-15 19:57:07 - GraphTrainer - INFO -   hit_rate@20: 0.083466
2025-12-15 19:57:07 - GraphTrainer - INFO -   ndcg@20: 0.034425
2025-12-15 19:57:07 - GraphTrainer - INFO -   map@20: 0.021598
2025-12-15 19:57:07 - GraphTrainer - INFO -   mrr@20: 0.022601
2025-12-15 19:57:07 - GraphTrainer - INFO - 第 15 轮训练完成
2025-12-15 19:57:07 - GraphTrainer - INFO - train_loss: 0.272987
2025-12-15 19:57:07 - GraphTrainer - INFO - precision@5: 0.006747
2025-12-15 19:57:07 - GraphTrainer - INFO - recall@5: 0.032318
2025-12-15 19:57:07 - GraphTrainer - INFO - hit_rate@5: 0.033736
2025-12-15 19:57:07 - GraphTrainer - INFO - ndcg@5: 0.021108
2025-12-15 19:57:07 - GraphTrainer - INFO - map@5: 0.017196
2025-12-15 19:57:07 - GraphTrainer - INFO - mrr@5: 0.017953
2025-12-15 19:57:07 - GraphTrainer - INFO - precision@10: 0.005379
2025-12-15 19:57:07 - GraphTrainer - INFO - recall@10: 0.051168
2025-12-15 19:57:07 - GraphTrainer - INFO - hit_rate@10: 0.053638
2025-12-15 19:57:07 - GraphTrainer - INFO - ndcg@10: 0.027213
2025-12-15 19:57:07 - GraphTrainer - INFO - map@10: 0.019650
2025-12-15 19:57:07 - GraphTrainer - INFO - mrr@10: 0.020543
2025-12-15 19:57:07 - GraphTrainer - INFO - precision@20: 0.004196
2025-12-15 19:57:07 - GraphTrainer - INFO - recall@20: 0.079365
2025-12-15 19:57:07 - GraphTrainer - INFO - hit_rate@20: 0.083466
2025-12-15 19:57:07 - GraphTrainer - INFO - ndcg@20: 0.034425
2025-12-15 19:57:07 - GraphTrainer - INFO - map@20: 0.021598
2025-12-15 19:57:07 - GraphTrainer - INFO - mrr@20: 0.022601
2025-12-15 19:57:07 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:57:07 - GraphTrainer - INFO - ============================================================
2025-12-15 19:57:07 - GraphTrainer - INFO - 开始第 16/1000 轮训练
2025-12-15 19:57:07 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2735, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2590, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2502, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2671, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2825, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2540, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2722, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2864, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2879, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2758, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2705, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2815, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2866, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2714, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2830, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2812, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2827, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2807, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2749, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2812, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2772, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2710, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2742, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2861, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2666, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2851, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2687, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2795, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2648, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2714, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2751, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2651, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2633, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2723, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2676, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2638, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2622, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2711, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2567, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2638, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2906, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2683, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2763, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2736, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2737, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2597, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2710, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2827, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2726, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2753, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2685, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2550, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2699, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2899, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2950, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2585, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2725, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2724, device='cuda:0', grad_fn=<AddBackward0>)
The 15 training average loss: 0.2729872660390262
2025-12-15 19:57:15 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:57:15 - GraphTrainer - INFO -   precision@5: 0.006449
2025-12-15 19:57:15 - GraphTrainer - INFO -   recall@5: 0.030805
2025-12-15 19:57:15 - GraphTrainer - INFO -   hit_rate@5: 0.032245
2025-12-15 19:57:15 - GraphTrainer - INFO -   ndcg@5: 0.020327
2025-12-15 19:57:15 - GraphTrainer - INFO -   map@5: 0.016631
2025-12-15 19:57:15 - GraphTrainer - INFO -   mrr@5: 0.017430
2025-12-15 19:57:15 - GraphTrainer - INFO -   precision@10: 0.005323
2025-12-15 19:57:15 - GraphTrainer - INFO -   recall@10: 0.050633
2025-12-15 19:57:15 - GraphTrainer - INFO -   hit_rate@10: 0.053176
2025-12-15 19:57:15 - GraphTrainer - INFO -   ndcg@10: 0.026750
2025-12-15 19:57:15 - GraphTrainer - INFO -   map@10: 0.019218
2025-12-15 19:57:15 - GraphTrainer - INFO -   mrr@10: 0.020158
2025-12-15 19:57:15 - GraphTrainer - INFO -   precision@20: 0.004230
2025-12-15 19:57:15 - GraphTrainer - INFO -   recall@20: 0.079944
2025-12-15 19:57:15 - GraphTrainer - INFO -   hit_rate@20: 0.084238
2025-12-15 19:57:15 - GraphTrainer - INFO -   ndcg@20: 0.034205
2025-12-15 19:57:15 - GraphTrainer - INFO -   map@20: 0.021209
2025-12-15 19:57:15 - GraphTrainer - INFO -   mrr@20: 0.022259
2025-12-15 19:57:15 - GraphTrainer - INFO - 第 16 轮训练完成
2025-12-15 19:57:15 - GraphTrainer - INFO - train_loss: 0.269978
2025-12-15 19:57:15 - GraphTrainer - INFO - precision@5: 0.006449
2025-12-15 19:57:15 - GraphTrainer - INFO - recall@5: 0.030805
2025-12-15 19:57:15 - GraphTrainer - INFO - hit_rate@5: 0.032245
2025-12-15 19:57:15 - GraphTrainer - INFO - ndcg@5: 0.020327
2025-12-15 19:57:15 - GraphTrainer - INFO - map@5: 0.016631
2025-12-15 19:57:15 - GraphTrainer - INFO - mrr@5: 0.017430
2025-12-15 19:57:15 - GraphTrainer - INFO - precision@10: 0.005323
2025-12-15 19:57:15 - GraphTrainer - INFO - recall@10: 0.050633
2025-12-15 19:57:15 - GraphTrainer - INFO - hit_rate@10: 0.053176
2025-12-15 19:57:15 - GraphTrainer - INFO - ndcg@10: 0.026750
2025-12-15 19:57:15 - GraphTrainer - INFO - map@10: 0.019218
2025-12-15 19:57:15 - GraphTrainer - INFO - mrr@10: 0.020158
2025-12-15 19:57:15 - GraphTrainer - INFO - precision@20: 0.004230
2025-12-15 19:57:15 - GraphTrainer - INFO - recall@20: 0.079944
2025-12-15 19:57:15 - GraphTrainer - INFO - hit_rate@20: 0.084238
2025-12-15 19:57:15 - GraphTrainer - INFO - ndcg@20: 0.034205
2025-12-15 19:57:15 - GraphTrainer - INFO - map@20: 0.021209
2025-12-15 19:57:15 - GraphTrainer - INFO - mrr@20: 0.022259
2025-12-15 19:57:15 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:57:15 - GraphTrainer - INFO - ============================================================
2025-12-15 19:57:15 - GraphTrainer - INFO - 开始第 17/1000 轮训练
2025-12-15 19:57:15 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2526, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2728, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2795, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2753, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2841, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2758, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2657, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2539, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2473, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2914, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2807, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2765, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2726, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2807, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2736, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2751, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2712, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2815, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2783, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2663, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2462, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2582, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2903, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2673, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2610, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2655, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2838, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2821, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2786, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2558, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2588, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2723, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2839, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2552, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2685, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2707, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2487, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2592, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2616, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2928, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2610, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2839, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2717, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2495, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2734, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2664, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2800, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2670, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2434, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2713, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2625, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2765, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2902, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2696, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2631, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2675, device='cuda:0', grad_fn=<AddBackward0>)
The 16 training average loss: 0.26997826402557307
2025-12-15 19:57:23 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:57:23 - GraphTrainer - INFO -   precision@5: 0.006521
2025-12-15 19:57:23 - GraphTrainer - INFO -   recall@5: 0.031028
2025-12-15 19:57:23 - GraphTrainer - INFO -   hit_rate@5: 0.032605
2025-12-15 19:57:23 - GraphTrainer - INFO -   ndcg@5: 0.020786
2025-12-15 19:57:23 - GraphTrainer - INFO -   map@5: 0.017148
2025-12-15 19:57:23 - GraphTrainer - INFO -   mrr@5: 0.017969
2025-12-15 19:57:23 - GraphTrainer - INFO -   precision@10: 0.005400
2025-12-15 19:57:23 - GraphTrainer - INFO -   recall@10: 0.051436
2025-12-15 19:57:23 - GraphTrainer - INFO -   hit_rate@10: 0.053947
2025-12-15 19:57:23 - GraphTrainer - INFO -   ndcg@10: 0.027326
2025-12-15 19:57:23 - GraphTrainer - INFO -   map@10: 0.019755
2025-12-15 19:57:23 - GraphTrainer - INFO -   mrr@10: 0.020695
2025-12-15 19:57:23 - GraphTrainer - INFO -   precision@20: 0.004315
2025-12-15 19:57:23 - GraphTrainer - INFO -   recall@20: 0.081641
2025-12-15 19:57:23 - GraphTrainer - INFO -   hit_rate@20: 0.085883
2025-12-15 19:57:23 - GraphTrainer - INFO -   ndcg@20: 0.035025
2025-12-15 19:57:23 - GraphTrainer - INFO -   map@20: 0.021822
2025-12-15 19:57:23 - GraphTrainer - INFO -   mrr@20: 0.022871
2025-12-15 19:57:23 - GraphTrainer - INFO - 第 17 轮训练完成
2025-12-15 19:57:23 - GraphTrainer - INFO - train_loss: 0.268486
2025-12-15 19:57:23 - GraphTrainer - INFO - precision@5: 0.006521
2025-12-15 19:57:23 - GraphTrainer - INFO - recall@5: 0.031028
2025-12-15 19:57:23 - GraphTrainer - INFO - hit_rate@5: 0.032605
2025-12-15 19:57:23 - GraphTrainer - INFO - ndcg@5: 0.020786
2025-12-15 19:57:23 - GraphTrainer - INFO - map@5: 0.017148
2025-12-15 19:57:23 - GraphTrainer - INFO - mrr@5: 0.017969
2025-12-15 19:57:23 - GraphTrainer - INFO - precision@10: 0.005400
2025-12-15 19:57:23 - GraphTrainer - INFO - recall@10: 0.051436
2025-12-15 19:57:23 - GraphTrainer - INFO - hit_rate@10: 0.053947
2025-12-15 19:57:23 - GraphTrainer - INFO - ndcg@10: 0.027326
2025-12-15 19:57:23 - GraphTrainer - INFO - map@10: 0.019755
2025-12-15 19:57:23 - GraphTrainer - INFO - mrr@10: 0.020695
2025-12-15 19:57:23 - GraphTrainer - INFO - precision@20: 0.004315
2025-12-15 19:57:23 - GraphTrainer - INFO - recall@20: 0.081641
2025-12-15 19:57:23 - GraphTrainer - INFO - hit_rate@20: 0.085883
2025-12-15 19:57:23 - GraphTrainer - INFO - ndcg@20: 0.035025
2025-12-15 19:57:23 - GraphTrainer - INFO - map@20: 0.021822
2025-12-15 19:57:23 - GraphTrainer - INFO - mrr@20: 0.022871
2025-12-15 19:57:23 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:57:23 - GraphTrainer - INFO - ============================================================
2025-12-15 19:57:23 - GraphTrainer - INFO - 开始第 18/1000 轮训练
2025-12-15 19:57:23 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2707, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2730, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2747, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2690, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2667, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2688, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2710, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2771, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2472, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2421, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2936, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2879, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2720, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2632, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2680, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2607, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2598, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2774, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2658, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2737, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2664, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2702, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2550, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2747, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2638, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2851, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2618, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2711, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2718, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2582, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2711, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2552, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2718, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2705, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2630, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2620, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2827, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2796, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2567, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2697, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2625, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2443, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2606, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2705, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2749, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2691, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2679, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2933, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2676, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2711, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2654, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2447, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2887, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2769, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2989, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2539, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2573, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2615, device='cuda:0', grad_fn=<AddBackward0>)
The 17 training average loss: 0.26848628012270764
2025-12-15 19:57:31 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:57:31 - GraphTrainer - INFO -   precision@5: 0.006552
2025-12-15 19:57:31 - GraphTrainer - INFO -   recall@5: 0.031281
2025-12-15 19:57:31 - GraphTrainer - INFO -   hit_rate@5: 0.032759
2025-12-15 19:57:31 - GraphTrainer - INFO -   ndcg@5: 0.020559
2025-12-15 19:57:31 - GraphTrainer - INFO -   map@5: 0.016791
2025-12-15 19:57:31 - GraphTrainer - INFO -   mrr@5: 0.017588
2025-12-15 19:57:31 - GraphTrainer - INFO -   precision@10: 0.005492
2025-12-15 19:57:31 - GraphTrainer - INFO -   recall@10: 0.052130
2025-12-15 19:57:31 - GraphTrainer - INFO -   hit_rate@10: 0.054821
2025-12-15 19:57:31 - GraphTrainer - INFO -   ndcg@10: 0.027302
2025-12-15 19:57:31 - GraphTrainer - INFO -   map@10: 0.019496
2025-12-15 19:57:31 - GraphTrainer - INFO -   mrr@10: 0.020448
2025-12-15 19:57:31 - GraphTrainer - INFO -   precision@20: 0.004292
2025-12-15 19:57:31 - GraphTrainer - INFO -   recall@20: 0.081254
2025-12-15 19:57:31 - GraphTrainer - INFO -   hit_rate@20: 0.085420
2025-12-15 19:57:31 - GraphTrainer - INFO -   ndcg@20: 0.034697
2025-12-15 19:57:31 - GraphTrainer - INFO -   map@20: 0.021475
2025-12-15 19:57:31 - GraphTrainer - INFO -   mrr@20: 0.022525
2025-12-15 19:57:31 - GraphTrainer - INFO - 第 18 轮训练完成
2025-12-15 19:57:31 - GraphTrainer - INFO - train_loss: 0.266575
2025-12-15 19:57:31 - GraphTrainer - INFO - precision@5: 0.006552
2025-12-15 19:57:31 - GraphTrainer - INFO - recall@5: 0.031281
2025-12-15 19:57:31 - GraphTrainer - INFO - hit_rate@5: 0.032759
2025-12-15 19:57:31 - GraphTrainer - INFO - ndcg@5: 0.020559
2025-12-15 19:57:31 - GraphTrainer - INFO - map@5: 0.016791
2025-12-15 19:57:31 - GraphTrainer - INFO - mrr@5: 0.017588
2025-12-15 19:57:31 - GraphTrainer - INFO - precision@10: 0.005492
2025-12-15 19:57:31 - GraphTrainer - INFO - recall@10: 0.052130
2025-12-15 19:57:31 - GraphTrainer - INFO - hit_rate@10: 0.054821
2025-12-15 19:57:31 - GraphTrainer - INFO - ndcg@10: 0.027302
2025-12-15 19:57:31 - GraphTrainer - INFO - map@10: 0.019496
2025-12-15 19:57:31 - GraphTrainer - INFO - mrr@10: 0.020448
2025-12-15 19:57:31 - GraphTrainer - INFO - precision@20: 0.004292
2025-12-15 19:57:31 - GraphTrainer - INFO - recall@20: 0.081254
2025-12-15 19:57:31 - GraphTrainer - INFO - hit_rate@20: 0.085420
2025-12-15 19:57:31 - GraphTrainer - INFO - ndcg@20: 0.034697
2025-12-15 19:57:31 - GraphTrainer - INFO - map@20: 0.021475
2025-12-15 19:57:31 - GraphTrainer - INFO - mrr@20: 0.022525
2025-12-15 19:57:31 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:57:31 - GraphTrainer - INFO - ============================================================
2025-12-15 19:57:31 - GraphTrainer - INFO - 开始第 19/1000 轮训练
2025-12-15 19:57:31 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2631, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2776, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2518, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2587, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2723, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2702, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2600, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2725, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2751, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2685, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2681, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2678, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2402, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2653, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2754, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2587, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2608, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2875, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2777, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2668, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2716, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2681, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2451, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2662, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2577, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2634, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2465, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2579, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2568, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2659, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2765, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2485, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2765, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2552, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2798, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2627, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2611, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2758, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2547, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2764, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2688, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2578, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2904, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2522, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2486, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2684, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2529, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2808, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3008, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2748, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2571, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2847, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2605, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2760, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2639, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2799, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2515, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2877, device='cuda:0', grad_fn=<AddBackward0>)
The 18 training average loss: 0.2665746391847216
2025-12-15 19:57:39 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:57:39 - GraphTrainer - INFO -   precision@5: 0.006490
2025-12-15 19:57:39 - GraphTrainer - INFO -   recall@5: 0.031057
2025-12-15 19:57:39 - GraphTrainer - INFO -   hit_rate@5: 0.032451
2025-12-15 19:57:39 - GraphTrainer - INFO -   ndcg@5: 0.020520
2025-12-15 19:57:39 - GraphTrainer - INFO -   map@5: 0.016834
2025-12-15 19:57:39 - GraphTrainer - INFO -   mrr@5: 0.017526
2025-12-15 19:57:39 - GraphTrainer - INFO -   precision@10: 0.005415
2025-12-15 19:57:39 - GraphTrainer - INFO -   recall@10: 0.051416
2025-12-15 19:57:39 - GraphTrainer - INFO -   hit_rate@10: 0.054050
2025-12-15 19:57:39 - GraphTrainer - INFO -   ndcg@10: 0.027161
2025-12-15 19:57:39 - GraphTrainer - INFO -   map@10: 0.019529
2025-12-15 19:57:39 - GraphTrainer - INFO -   mrr@10: 0.020378
2025-12-15 19:57:39 - GraphTrainer - INFO -   precision@20: 0.004299
2025-12-15 19:57:39 - GraphTrainer - INFO -   recall@20: 0.081479
2025-12-15 19:57:39 - GraphTrainer - INFO -   hit_rate@20: 0.085575
2025-12-15 19:57:39 - GraphTrainer - INFO -   ndcg@20: 0.034802
2025-12-15 19:57:39 - GraphTrainer - INFO -   map@20: 0.021579
2025-12-15 19:57:39 - GraphTrainer - INFO -   mrr@20: 0.022526
2025-12-15 19:57:39 - GraphTrainer - INFO - 第 19 轮训练完成
2025-12-15 19:57:39 - GraphTrainer - INFO - train_loss: 0.269270
2025-12-15 19:57:39 - GraphTrainer - INFO - precision@5: 0.006490
2025-12-15 19:57:39 - GraphTrainer - INFO - recall@5: 0.031057
2025-12-15 19:57:39 - GraphTrainer - INFO - hit_rate@5: 0.032451
2025-12-15 19:57:39 - GraphTrainer - INFO - ndcg@5: 0.020520
2025-12-15 19:57:39 - GraphTrainer - INFO - map@5: 0.016834
2025-12-15 19:57:39 - GraphTrainer - INFO - mrr@5: 0.017526
2025-12-15 19:57:39 - GraphTrainer - INFO - precision@10: 0.005415
2025-12-15 19:57:39 - GraphTrainer - INFO - recall@10: 0.051416
2025-12-15 19:57:39 - GraphTrainer - INFO - hit_rate@10: 0.054050
2025-12-15 19:57:39 - GraphTrainer - INFO - ndcg@10: 0.027161
2025-12-15 19:57:39 - GraphTrainer - INFO - map@10: 0.019529
2025-12-15 19:57:39 - GraphTrainer - INFO - mrr@10: 0.020378
2025-12-15 19:57:39 - GraphTrainer - INFO - precision@20: 0.004299
2025-12-15 19:57:39 - GraphTrainer - INFO - recall@20: 0.081479
2025-12-15 19:57:39 - GraphTrainer - INFO - hit_rate@20: 0.085575
2025-12-15 19:57:39 - GraphTrainer - INFO - ndcg@20: 0.034802
2025-12-15 19:57:39 - GraphTrainer - INFO - map@20: 0.021579
2025-12-15 19:57:39 - GraphTrainer - INFO - mrr@20: 0.022526
2025-12-15 19:57:39 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:57:39 - GraphTrainer - INFO - ============================================================
2025-12-15 19:57:39 - GraphTrainer - INFO - 开始第 20/1000 轮训练
2025-12-15 19:57:39 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2583, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2788, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2562, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2599, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2885, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2803, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2425, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2738, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2558, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2545, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2799, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2932, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2552, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2611, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2751, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2445, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2698, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2950, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2820, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2556, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2693, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2588, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2826, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2847, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2662, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2781, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2797, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2728, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2452, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2718, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2686, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2691, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2939, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2676, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2771, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2743, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2504, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2652, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2729, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2643, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2627, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2655, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2946, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2689, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2591, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2845, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2472, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2680, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2717, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2527, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2792, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2765, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2723, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2742, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2560, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2654, device='cuda:0', grad_fn=<AddBackward0>)
The 19 training average loss: 0.26926963647891733
2025-12-15 19:57:47 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:57:47 - GraphTrainer - INFO -   precision@5: 0.006552
2025-12-15 19:57:47 - GraphTrainer - INFO -   recall@5: 0.031285
2025-12-15 19:57:47 - GraphTrainer - INFO -   hit_rate@5: 0.032759
2025-12-15 19:57:47 - GraphTrainer - INFO -   ndcg@5: 0.020736
2025-12-15 19:57:47 - GraphTrainer - INFO -   map@5: 0.017045
2025-12-15 19:57:47 - GraphTrainer - INFO -   mrr@5: 0.017819
2025-12-15 19:57:47 - GraphTrainer - INFO -   precision@10: 0.005472
2025-12-15 19:57:47 - GraphTrainer - INFO -   recall@10: 0.051935
2025-12-15 19:57:47 - GraphTrainer - INFO -   hit_rate@10: 0.054616
2025-12-15 19:57:47 - GraphTrainer - INFO -   ndcg@10: 0.027452
2025-12-15 19:57:47 - GraphTrainer - INFO -   map@10: 0.019760
2025-12-15 19:57:47 - GraphTrainer - INFO -   mrr@10: 0.020691
2025-12-15 19:57:47 - GraphTrainer - INFO -   precision@20: 0.004394
2025-12-15 19:57:47 - GraphTrainer - INFO -   recall@20: 0.083321
2025-12-15 19:57:47 - GraphTrainer - INFO -   hit_rate@20: 0.087375
2025-12-15 19:57:47 - GraphTrainer - INFO -   ndcg@20: 0.035418
2025-12-15 19:57:47 - GraphTrainer - INFO -   map@20: 0.021898
2025-12-15 19:57:47 - GraphTrainer - INFO -   mrr@20: 0.022914
2025-12-15 19:57:47 - GraphTrainer - INFO - 第 20 轮训练完成
2025-12-15 19:57:47 - GraphTrainer - INFO - train_loss: 0.259157
2025-12-15 19:57:47 - GraphTrainer - INFO - precision@5: 0.006552
2025-12-15 19:57:47 - GraphTrainer - INFO - recall@5: 0.031285
2025-12-15 19:57:47 - GraphTrainer - INFO - hit_rate@5: 0.032759
2025-12-15 19:57:47 - GraphTrainer - INFO - ndcg@5: 0.020736
2025-12-15 19:57:47 - GraphTrainer - INFO - map@5: 0.017045
2025-12-15 19:57:47 - GraphTrainer - INFO - mrr@5: 0.017819
2025-12-15 19:57:47 - GraphTrainer - INFO - precision@10: 0.005472
2025-12-15 19:57:47 - GraphTrainer - INFO - recall@10: 0.051935
2025-12-15 19:57:47 - GraphTrainer - INFO - hit_rate@10: 0.054616
2025-12-15 19:57:47 - GraphTrainer - INFO - ndcg@10: 0.027452
2025-12-15 19:57:47 - GraphTrainer - INFO - map@10: 0.019760
2025-12-15 19:57:47 - GraphTrainer - INFO - mrr@10: 0.020691
2025-12-15 19:57:47 - GraphTrainer - INFO - precision@20: 0.004394
2025-12-15 19:57:47 - GraphTrainer - INFO - recall@20: 0.083321
2025-12-15 19:57:47 - GraphTrainer - INFO - hit_rate@20: 0.087375
2025-12-15 19:57:47 - GraphTrainer - INFO - ndcg@20: 0.035418
2025-12-15 19:57:47 - GraphTrainer - INFO - map@20: 0.021898
2025-12-15 19:57:47 - GraphTrainer - INFO - mrr@20: 0.022914
2025-12-15 19:57:47 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:57:47 - GraphTrainer - INFO - 检查点已保存: Epoch 20 -> ./checkpoints/checkpoint_epoch_20.pth
2025-12-15 19:57:47 - GraphTrainer - INFO - ============================================================
2025-12-15 19:57:47 - GraphTrainer - INFO - 开始第 21/1000 轮训练
2025-12-15 19:57:47 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2700, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2804, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2749, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2591, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2576, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2588, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2556, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2376, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2638, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2550, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2553, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2521, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2561, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2631, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2429, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2572, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2748, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2651, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2599, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2407, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2643, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2587, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2783, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2459, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2412, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2648, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2644, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2663, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2553, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2602, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2698, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2596, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2601, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2574, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2670, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2462, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2534, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2762, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2640, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2601, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2523, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2638, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2506, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2664, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2326, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2529, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2595, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2506, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2441, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2533, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2348, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2663, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2437, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2845, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2765, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2491, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2954, device='cuda:0', grad_fn=<AddBackward0>)
The 20 training average loss: 0.2591571504699773
2025-12-15 19:57:56 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:57:56 - GraphTrainer - INFO -   precision@5: 0.006562
2025-12-15 19:57:56 - GraphTrainer - INFO -   recall@5: 0.031440
2025-12-15 19:57:56 - GraphTrainer - INFO -   hit_rate@5: 0.032810
2025-12-15 19:57:56 - GraphTrainer - INFO -   ndcg@5: 0.020903
2025-12-15 19:57:56 - GraphTrainer - INFO -   map@5: 0.017216
2025-12-15 19:57:56 - GraphTrainer - INFO -   mrr@5: 0.017937
2025-12-15 19:57:56 - GraphTrainer - INFO -   precision@10: 0.005369
2025-12-15 19:57:56 - GraphTrainer - INFO -   recall@10: 0.050979
2025-12-15 19:57:56 - GraphTrainer - INFO -   hit_rate@10: 0.053587
2025-12-15 19:57:56 - GraphTrainer - INFO -   ndcg@10: 0.027277
2025-12-15 19:57:56 - GraphTrainer - INFO -   map@10: 0.019797
2025-12-15 19:57:56 - GraphTrainer - INFO -   mrr@10: 0.020682
2025-12-15 19:57:56 - GraphTrainer - INFO -   precision@20: 0.004333
2025-12-15 19:57:56 - GraphTrainer - INFO -   recall@20: 0.082202
2025-12-15 19:57:56 - GraphTrainer - INFO -   hit_rate@20: 0.086243
2025-12-15 19:57:56 - GraphTrainer - INFO -   ndcg@20: 0.035196
2025-12-15 19:57:56 - GraphTrainer - INFO -   map@20: 0.021918
2025-12-15 19:57:56 - GraphTrainer - INFO -   mrr@20: 0.022897
2025-12-15 19:57:56 - GraphTrainer - INFO - 第 21 轮训练完成
2025-12-15 19:57:56 - GraphTrainer - INFO - train_loss: 0.262336
2025-12-15 19:57:56 - GraphTrainer - INFO - precision@5: 0.006562
2025-12-15 19:57:56 - GraphTrainer - INFO - recall@5: 0.031440
2025-12-15 19:57:56 - GraphTrainer - INFO - hit_rate@5: 0.032810
2025-12-15 19:57:56 - GraphTrainer - INFO - ndcg@5: 0.020903
2025-12-15 19:57:56 - GraphTrainer - INFO - map@5: 0.017216
2025-12-15 19:57:56 - GraphTrainer - INFO - mrr@5: 0.017937
2025-12-15 19:57:56 - GraphTrainer - INFO - precision@10: 0.005369
2025-12-15 19:57:56 - GraphTrainer - INFO - recall@10: 0.050979
2025-12-15 19:57:56 - GraphTrainer - INFO - hit_rate@10: 0.053587
2025-12-15 19:57:56 - GraphTrainer - INFO - ndcg@10: 0.027277
2025-12-15 19:57:56 - GraphTrainer - INFO - map@10: 0.019797
2025-12-15 19:57:56 - GraphTrainer - INFO - mrr@10: 0.020682
2025-12-15 19:57:56 - GraphTrainer - INFO - precision@20: 0.004333
2025-12-15 19:57:56 - GraphTrainer - INFO - recall@20: 0.082202
2025-12-15 19:57:56 - GraphTrainer - INFO - hit_rate@20: 0.086243
2025-12-15 19:57:56 - GraphTrainer - INFO - ndcg@20: 0.035196
2025-12-15 19:57:56 - GraphTrainer - INFO - map@20: 0.021918
2025-12-15 19:57:56 - GraphTrainer - INFO - mrr@20: 0.022897
2025-12-15 19:57:56 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:57:56 - GraphTrainer - INFO - ============================================================
2025-12-15 19:57:56 - GraphTrainer - INFO - 开始第 22/1000 轮训练
2025-12-15 19:57:56 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2735, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2566, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2740, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2760, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2619, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2461, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2907, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2565, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2527, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2512, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2646, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2689, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2633, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2453, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2371, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2676, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2508, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2782, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2724, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2746, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2794, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2762, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2548, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2712, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2531, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2540, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2548, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2601, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2528, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2578, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2625, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2688, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2798, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2501, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2762, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2541, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2589, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2660, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2664, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2565, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2711, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2573, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2418, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2790, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2678, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2630, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2773, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2595, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2640, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2448, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2652, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2381, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2551, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2704, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2572, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2559, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2820, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2507, device='cuda:0', grad_fn=<AddBackward0>)
The 21 training average loss: 0.2623358137648681
2025-12-15 19:58:03 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:58:03 - GraphTrainer - INFO -   precision@5: 0.006593
2025-12-15 19:58:03 - GraphTrainer - INFO -   recall@5: 0.031641
2025-12-15 19:58:03 - GraphTrainer - INFO -   hit_rate@5: 0.032965
2025-12-15 19:58:03 - GraphTrainer - INFO -   ndcg@5: 0.020798
2025-12-15 19:58:03 - GraphTrainer - INFO -   map@5: 0.016999
2025-12-15 19:58:03 - GraphTrainer - INFO -   mrr@5: 0.017724
2025-12-15 19:58:03 - GraphTrainer - INFO -   precision@10: 0.005436
2025-12-15 19:58:03 - GraphTrainer - INFO -   recall@10: 0.051525
2025-12-15 19:58:03 - GraphTrainer - INFO -   hit_rate@10: 0.054153
2025-12-15 19:58:03 - GraphTrainer - INFO -   ndcg@10: 0.027286
2025-12-15 19:58:03 - GraphTrainer - INFO -   map@10: 0.019623
2025-12-15 19:58:03 - GraphTrainer - INFO -   mrr@10: 0.020512
2025-12-15 19:58:03 - GraphTrainer - INFO -   precision@20: 0.004274
2025-12-15 19:58:03 - GraphTrainer - INFO -   recall@20: 0.080941
2025-12-15 19:58:03 - GraphTrainer - INFO -   hit_rate@20: 0.084906
2025-12-15 19:58:03 - GraphTrainer - INFO -   ndcg@20: 0.034763
2025-12-15 19:58:03 - GraphTrainer - INFO -   map@20: 0.021634
2025-12-15 19:58:03 - GraphTrainer - INFO -   mrr@20: 0.022605
2025-12-15 19:58:03 - GraphTrainer - INFO - 第 22 轮训练完成
2025-12-15 19:58:03 - GraphTrainer - INFO - train_loss: 0.261441
2025-12-15 19:58:03 - GraphTrainer - INFO - precision@5: 0.006593
2025-12-15 19:58:03 - GraphTrainer - INFO - recall@5: 0.031641
2025-12-15 19:58:03 - GraphTrainer - INFO - hit_rate@5: 0.032965
2025-12-15 19:58:03 - GraphTrainer - INFO - ndcg@5: 0.020798
2025-12-15 19:58:03 - GraphTrainer - INFO - map@5: 0.016999
2025-12-15 19:58:03 - GraphTrainer - INFO - mrr@5: 0.017724
2025-12-15 19:58:03 - GraphTrainer - INFO - precision@10: 0.005436
2025-12-15 19:58:03 - GraphTrainer - INFO - recall@10: 0.051525
2025-12-15 19:58:03 - GraphTrainer - INFO - hit_rate@10: 0.054153
2025-12-15 19:58:03 - GraphTrainer - INFO - ndcg@10: 0.027286
2025-12-15 19:58:03 - GraphTrainer - INFO - map@10: 0.019623
2025-12-15 19:58:03 - GraphTrainer - INFO - mrr@10: 0.020512
2025-12-15 19:58:03 - GraphTrainer - INFO - precision@20: 0.004274
2025-12-15 19:58:03 - GraphTrainer - INFO - recall@20: 0.080941
2025-12-15 19:58:03 - GraphTrainer - INFO - hit_rate@20: 0.084906
2025-12-15 19:58:03 - GraphTrainer - INFO - ndcg@20: 0.034763
2025-12-15 19:58:03 - GraphTrainer - INFO - map@20: 0.021634
2025-12-15 19:58:03 - GraphTrainer - INFO - mrr@20: 0.022605
2025-12-15 19:58:03 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:58:03 - GraphTrainer - INFO - ============================================================
2025-12-15 19:58:03 - GraphTrainer - INFO - 开始第 23/1000 轮训练
2025-12-15 19:58:03 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2448, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2641, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2290, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2697, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2533, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2682, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2653, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2579, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2609, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2522, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2631, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2505, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2530, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2417, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2555, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2665, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2691, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2694, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2724, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2745, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2578, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2546, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2933, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2353, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2447, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2803, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2587, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2725, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2908, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2565, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2557, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2804, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2617, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2604, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2646, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2478, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2559, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2580, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2614, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2573, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2520, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2697, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2391, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2505, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2648, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2649, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2525, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2513, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2745, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2492, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2779, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2759, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2529, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2726, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2619, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2485, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2887, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2880, device='cuda:0', grad_fn=<AddBackward0>)
The 22 training average loss: 0.26144053761301367
2025-12-15 19:58:12 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:58:12 - GraphTrainer - INFO -   precision@5: 0.006500
2025-12-15 19:58:12 - GraphTrainer - INFO -   recall@5: 0.031367
2025-12-15 19:58:12 - GraphTrainer - INFO -   hit_rate@5: 0.032502
2025-12-15 19:58:12 - GraphTrainer - INFO -   ndcg@5: 0.020805
2025-12-15 19:58:12 - GraphTrainer - INFO -   map@5: 0.017130
2025-12-15 19:58:12 - GraphTrainer - INFO -   mrr@5: 0.017817
2025-12-15 19:58:12 - GraphTrainer - INFO -   precision@10: 0.005492
2025-12-15 19:58:12 - GraphTrainer - INFO -   recall@10: 0.052169
2025-12-15 19:58:12 - GraphTrainer - INFO -   hit_rate@10: 0.054770
2025-12-15 19:58:12 - GraphTrainer - INFO -   ndcg@10: 0.027593
2025-12-15 19:58:12 - GraphTrainer - INFO -   map@10: 0.019869
2025-12-15 19:58:12 - GraphTrainer - INFO -   mrr@10: 0.020747
2025-12-15 19:58:12 - GraphTrainer - INFO -   precision@20: 0.004459
2025-12-15 19:58:12 - GraphTrainer - INFO -   recall@20: 0.084463
2025-12-15 19:58:12 - GraphTrainer - INFO -   hit_rate@20: 0.088712
2025-12-15 19:58:12 - GraphTrainer - INFO -   ndcg@20: 0.035798
2025-12-15 19:58:12 - GraphTrainer - INFO -   map@20: 0.022066
2025-12-15 19:58:12 - GraphTrainer - INFO -   mrr@20: 0.023051
2025-12-15 19:58:12 - GraphTrainer - INFO - 第 23 轮训练完成
2025-12-15 19:58:12 - GraphTrainer - INFO - train_loss: 0.258247
2025-12-15 19:58:12 - GraphTrainer - INFO - precision@5: 0.006500
2025-12-15 19:58:12 - GraphTrainer - INFO - recall@5: 0.031367
2025-12-15 19:58:12 - GraphTrainer - INFO - hit_rate@5: 0.032502
2025-12-15 19:58:12 - GraphTrainer - INFO - ndcg@5: 0.020805
2025-12-15 19:58:12 - GraphTrainer - INFO - map@5: 0.017130
2025-12-15 19:58:12 - GraphTrainer - INFO - mrr@5: 0.017817
2025-12-15 19:58:12 - GraphTrainer - INFO - precision@10: 0.005492
2025-12-15 19:58:12 - GraphTrainer - INFO - recall@10: 0.052169
2025-12-15 19:58:12 - GraphTrainer - INFO - hit_rate@10: 0.054770
2025-12-15 19:58:12 - GraphTrainer - INFO - ndcg@10: 0.027593
2025-12-15 19:58:12 - GraphTrainer - INFO - map@10: 0.019869
2025-12-15 19:58:12 - GraphTrainer - INFO - mrr@10: 0.020747
2025-12-15 19:58:12 - GraphTrainer - INFO - precision@20: 0.004459
2025-12-15 19:58:12 - GraphTrainer - INFO - recall@20: 0.084463
2025-12-15 19:58:12 - GraphTrainer - INFO - hit_rate@20: 0.088712
2025-12-15 19:58:12 - GraphTrainer - INFO - ndcg@20: 0.035798
2025-12-15 19:58:12 - GraphTrainer - INFO - map@20: 0.022066
2025-12-15 19:58:12 - GraphTrainer - INFO - mrr@20: 0.023051
2025-12-15 19:58:12 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:58:12 - GraphTrainer - INFO - ============================================================
2025-12-15 19:58:12 - GraphTrainer - INFO - 开始第 24/1000 轮训练
2025-12-15 19:58:12 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2441, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2405, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2383, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2521, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2463, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2707, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2387, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2552, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2514, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2664, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2647, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2608, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2739, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2624, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2538, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2547, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2326, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2659, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2572, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2541, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2827, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2581, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2878, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2578, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2573, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2612, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2529, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2426, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2723, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2691, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2469, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2740, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2887, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2430, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2541, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2548, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2667, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2488, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2771, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2646, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2496, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2652, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2551, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2584, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2569, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2533, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2729, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2575, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2620, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2481, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2516, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2589, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2750, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2720, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2469, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2471, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2548, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2487, device='cuda:0', grad_fn=<AddBackward0>)
The 23 training average loss: 0.2582470792634734
2025-12-15 19:58:20 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:58:20 - GraphTrainer - INFO -   precision@5: 0.006614
2025-12-15 19:58:20 - GraphTrainer - INFO -   recall@5: 0.031641
2025-12-15 19:58:20 - GraphTrainer - INFO -   hit_rate@5: 0.033068
2025-12-15 19:58:20 - GraphTrainer - INFO -   ndcg@5: 0.020926
2025-12-15 19:58:20 - GraphTrainer - INFO -   map@5: 0.017180
2025-12-15 19:58:20 - GraphTrainer - INFO -   mrr@5: 0.017911
2025-12-15 19:58:20 - GraphTrainer - INFO -   precision@10: 0.005441
2025-12-15 19:58:20 - GraphTrainer - INFO -   recall@10: 0.051585
2025-12-15 19:58:20 - GraphTrainer - INFO -   hit_rate@10: 0.054256
2025-12-15 19:58:20 - GraphTrainer - INFO -   ndcg@10: 0.027400
2025-12-15 19:58:20 - GraphTrainer - INFO -   map@10: 0.019784
2025-12-15 19:58:20 - GraphTrainer - INFO -   mrr@10: 0.020673
2025-12-15 19:58:20 - GraphTrainer - INFO -   precision@20: 0.004469
2025-12-15 19:58:20 - GraphTrainer - INFO -   recall@20: 0.084763
2025-12-15 19:58:20 - GraphTrainer - INFO -   hit_rate@20: 0.088917
2025-12-15 19:58:20 - GraphTrainer - INFO -   ndcg@20: 0.035806
2025-12-15 19:58:20 - GraphTrainer - INFO -   map@20: 0.022032
2025-12-15 19:58:20 - GraphTrainer - INFO -   mrr@20: 0.023013
2025-12-15 19:58:20 - GraphTrainer - INFO - 第 24 轮训练完成
2025-12-15 19:58:20 - GraphTrainer - INFO - train_loss: 0.255772
2025-12-15 19:58:20 - GraphTrainer - INFO - precision@5: 0.006614
2025-12-15 19:58:20 - GraphTrainer - INFO - recall@5: 0.031641
2025-12-15 19:58:20 - GraphTrainer - INFO - hit_rate@5: 0.033068
2025-12-15 19:58:20 - GraphTrainer - INFO - ndcg@5: 0.020926
2025-12-15 19:58:20 - GraphTrainer - INFO - map@5: 0.017180
2025-12-15 19:58:20 - GraphTrainer - INFO - mrr@5: 0.017911
2025-12-15 19:58:20 - GraphTrainer - INFO - precision@10: 0.005441
2025-12-15 19:58:20 - GraphTrainer - INFO - recall@10: 0.051585
2025-12-15 19:58:20 - GraphTrainer - INFO - hit_rate@10: 0.054256
2025-12-15 19:58:20 - GraphTrainer - INFO - ndcg@10: 0.027400
2025-12-15 19:58:20 - GraphTrainer - INFO - map@10: 0.019784
2025-12-15 19:58:20 - GraphTrainer - INFO - mrr@10: 0.020673
2025-12-15 19:58:20 - GraphTrainer - INFO - precision@20: 0.004469
2025-12-15 19:58:20 - GraphTrainer - INFO - recall@20: 0.084763
2025-12-15 19:58:20 - GraphTrainer - INFO - hit_rate@20: 0.088917
2025-12-15 19:58:20 - GraphTrainer - INFO - ndcg@20: 0.035806
2025-12-15 19:58:20 - GraphTrainer - INFO - map@20: 0.022032
2025-12-15 19:58:20 - GraphTrainer - INFO - mrr@20: 0.023013
2025-12-15 19:58:20 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:58:20 - GraphTrainer - INFO - ============================================================
2025-12-15 19:58:20 - GraphTrainer - INFO - 开始第 25/1000 轮训练
2025-12-15 19:58:20 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2661, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2356, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2531, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2592, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2602, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2535, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2758, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2640, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2580, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2634, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2648, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2577, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2554, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2599, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2497, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2261, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2545, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2530, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2623, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2672, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2577, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2703, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2737, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2575, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2444, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2466, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2455, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2362, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2649, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2321, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2412, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2558, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2791, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2573, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2461, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2397, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2518, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2555, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2569, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2520, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2458, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2506, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2598, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2409, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2759, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2534, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2693, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2908, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2601, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2838, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2463, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2666, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2605, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2509, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2636, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2460, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2319, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2347, device='cuda:0', grad_fn=<AddBackward0>)
The 24 training average loss: 0.25577157838591214
2025-12-15 19:58:28 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:58:28 - GraphTrainer - INFO -   precision@5: 0.006994
2025-12-15 19:58:28 - GraphTrainer - INFO -   recall@5: 0.033531
2025-12-15 19:58:28 - GraphTrainer - INFO -   hit_rate@5: 0.034970
2025-12-15 19:58:28 - GraphTrainer - INFO -   ndcg@5: 0.022116
2025-12-15 19:58:28 - GraphTrainer - INFO -   map@5: 0.018133
2025-12-15 19:58:28 - GraphTrainer - INFO -   mrr@5: 0.018924
2025-12-15 19:58:28 - GraphTrainer - INFO -   precision@10: 0.005441
2025-12-15 19:58:28 - GraphTrainer - INFO -   recall@10: 0.051764
2025-12-15 19:58:28 - GraphTrainer - INFO -   hit_rate@10: 0.054307
2025-12-15 19:58:28 - GraphTrainer - INFO -   ndcg@10: 0.028071
2025-12-15 19:58:28 - GraphTrainer - INFO -   map@10: 0.020550
2025-12-15 19:58:28 - GraphTrainer - INFO -   mrr@10: 0.021492
2025-12-15 19:58:28 - GraphTrainer - INFO -   precision@20: 0.004407
2025-12-15 19:58:28 - GraphTrainer - INFO -   recall@20: 0.083534
2025-12-15 19:58:28 - GraphTrainer - INFO -   hit_rate@20: 0.087735
2025-12-15 19:58:28 - GraphTrainer - INFO -   ndcg@20: 0.036158
2025-12-15 19:58:28 - GraphTrainer - INFO -   map@20: 0.022722
2025-12-15 19:58:28 - GraphTrainer - INFO -   mrr@20: 0.023775
2025-12-15 19:58:28 - GraphTrainer - INFO - 第 25 轮训练完成
2025-12-15 19:58:28 - GraphTrainer - INFO - train_loss: 0.255803
2025-12-15 19:58:28 - GraphTrainer - INFO - precision@5: 0.006994
2025-12-15 19:58:28 - GraphTrainer - INFO - recall@5: 0.033531
2025-12-15 19:58:28 - GraphTrainer - INFO - hit_rate@5: 0.034970
2025-12-15 19:58:28 - GraphTrainer - INFO - ndcg@5: 0.022116
2025-12-15 19:58:28 - GraphTrainer - INFO - map@5: 0.018133
2025-12-15 19:58:28 - GraphTrainer - INFO - mrr@5: 0.018924
2025-12-15 19:58:28 - GraphTrainer - INFO - precision@10: 0.005441
2025-12-15 19:58:28 - GraphTrainer - INFO - recall@10: 0.051764
2025-12-15 19:58:28 - GraphTrainer - INFO - hit_rate@10: 0.054307
2025-12-15 19:58:28 - GraphTrainer - INFO - ndcg@10: 0.028071
2025-12-15 19:58:28 - GraphTrainer - INFO - map@10: 0.020550
2025-12-15 19:58:28 - GraphTrainer - INFO - mrr@10: 0.021492
2025-12-15 19:58:28 - GraphTrainer - INFO - precision@20: 0.004407
2025-12-15 19:58:28 - GraphTrainer - INFO - recall@20: 0.083534
2025-12-15 19:58:28 - GraphTrainer - INFO - hit_rate@20: 0.087735
2025-12-15 19:58:28 - GraphTrainer - INFO - ndcg@20: 0.036158
2025-12-15 19:58:28 - GraphTrainer - INFO - map@20: 0.022722
2025-12-15 19:58:28 - GraphTrainer - INFO - mrr@20: 0.023775
2025-12-15 19:58:28 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:58:28 - GraphTrainer - INFO - ============================================================
2025-12-15 19:58:28 - GraphTrainer - INFO - 开始第 26/1000 轮训练
2025-12-15 19:58:28 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2442, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2378, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2494, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2437, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2543, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2554, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2421, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2688, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2503, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2654, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2652, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2503, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2311, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2755, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2487, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2762, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2737, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2516, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2523, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2399, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2499, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2565, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2579, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2556, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2354, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2770, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2551, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2435, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2578, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2586, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2373, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2545, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2608, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2661, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2687, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2616, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2565, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2502, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2612, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2498, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2464, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2379, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2523, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2663, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2566, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2605, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2510, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2685, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2513, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2525, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2498, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2976, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2569, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2634, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2405, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2724, device='cuda:0', grad_fn=<AddBackward0>)
The 25 training average loss: 0.2558031053892497
2025-12-15 19:58:36 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:58:36 - GraphTrainer - INFO -   precision@5: 0.006809
2025-12-15 19:58:36 - GraphTrainer - INFO -   recall@5: 0.032587
2025-12-15 19:58:36 - GraphTrainer - INFO -   hit_rate@5: 0.033993
2025-12-15 19:58:36 - GraphTrainer - INFO -   ndcg@5: 0.022095
2025-12-15 19:58:36 - GraphTrainer - INFO -   map@5: 0.018419
2025-12-15 19:58:36 - GraphTrainer - INFO -   mrr@5: 0.019168
2025-12-15 19:58:36 - GraphTrainer - INFO -   precision@10: 0.005436
2025-12-15 19:58:36 - GraphTrainer - INFO -   recall@10: 0.051537
2025-12-15 19:58:36 - GraphTrainer - INFO -   hit_rate@10: 0.054256
2025-12-15 19:58:36 - GraphTrainer - INFO -   ndcg@10: 0.028268
2025-12-15 19:58:36 - GraphTrainer - INFO -   map@10: 0.020910
2025-12-15 19:58:36 - GraphTrainer - INFO -   mrr@10: 0.021829
2025-12-15 19:58:36 - GraphTrainer - INFO -   precision@20: 0.004448
2025-12-15 19:58:36 - GraphTrainer - INFO -   recall@20: 0.084398
2025-12-15 19:58:36 - GraphTrainer - INFO -   hit_rate@20: 0.088609
2025-12-15 19:58:36 - GraphTrainer - INFO -   ndcg@20: 0.036608
2025-12-15 19:58:36 - GraphTrainer - INFO -   map@20: 0.023148
2025-12-15 19:58:36 - GraphTrainer - INFO -   mrr@20: 0.024160
2025-12-15 19:58:36 - GraphTrainer - INFO - 第 26 轮训练完成
2025-12-15 19:58:36 - GraphTrainer - INFO - train_loss: 0.251477
2025-12-15 19:58:36 - GraphTrainer - INFO - precision@5: 0.006809
2025-12-15 19:58:36 - GraphTrainer - INFO - recall@5: 0.032587
2025-12-15 19:58:36 - GraphTrainer - INFO - hit_rate@5: 0.033993
2025-12-15 19:58:36 - GraphTrainer - INFO - ndcg@5: 0.022095
2025-12-15 19:58:36 - GraphTrainer - INFO - map@5: 0.018419
2025-12-15 19:58:36 - GraphTrainer - INFO - mrr@5: 0.019168
2025-12-15 19:58:36 - GraphTrainer - INFO - precision@10: 0.005436
2025-12-15 19:58:36 - GraphTrainer - INFO - recall@10: 0.051537
2025-12-15 19:58:36 - GraphTrainer - INFO - hit_rate@10: 0.054256
2025-12-15 19:58:36 - GraphTrainer - INFO - ndcg@10: 0.028268
2025-12-15 19:58:36 - GraphTrainer - INFO - map@10: 0.020910
2025-12-15 19:58:36 - GraphTrainer - INFO - mrr@10: 0.021829
2025-12-15 19:58:36 - GraphTrainer - INFO - precision@20: 0.004448
2025-12-15 19:58:36 - GraphTrainer - INFO - recall@20: 0.084398
2025-12-15 19:58:36 - GraphTrainer - INFO - hit_rate@20: 0.088609
2025-12-15 19:58:36 - GraphTrainer - INFO - ndcg@20: 0.036608
2025-12-15 19:58:36 - GraphTrainer - INFO - map@20: 0.023148
2025-12-15 19:58:36 - GraphTrainer - INFO - mrr@20: 0.024160
2025-12-15 19:58:36 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:58:36 - GraphTrainer - INFO - ============================================================
2025-12-15 19:58:36 - GraphTrainer - INFO - 开始第 27/1000 轮训练
2025-12-15 19:58:36 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2585, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2423, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2507, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2489, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2399, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2628, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2441, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2544, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2787, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2478, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2521, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2358, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2266, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2712, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2465, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2541, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2602, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2401, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2411, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2291, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2485, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2383, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2511, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2442, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2406, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2500, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2639, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2544, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2593, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2435, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2564, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2601, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2497, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2315, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2807, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2495, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2536, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2706, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2408, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2620, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2687, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2426, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2424, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2558, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2510, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2552, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2450, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2474, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2515, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2505, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2519, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2462, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2606, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2469, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2523, device='cuda:0', grad_fn=<AddBackward0>)
The 26 training average loss: 0.25147718525138396
2025-12-15 19:58:44 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:58:44 - GraphTrainer - INFO -   precision@5: 0.006727
2025-12-15 19:58:44 - GraphTrainer - INFO -   recall@5: 0.032094
2025-12-15 19:58:44 - GraphTrainer - INFO -   hit_rate@5: 0.033582
2025-12-15 19:58:44 - GraphTrainer - INFO -   ndcg@5: 0.021462
2025-12-15 19:58:44 - GraphTrainer - INFO -   map@5: 0.017717
2025-12-15 19:58:44 - GraphTrainer - INFO -   mrr@5: 0.018512
2025-12-15 19:58:44 - GraphTrainer - INFO -   precision@10: 0.005662
2025-12-15 19:58:44 - GraphTrainer - INFO -   recall@10: 0.053906
2025-12-15 19:58:44 - GraphTrainer - INFO -   hit_rate@10: 0.056518
2025-12-15 19:58:44 - GraphTrainer - INFO -   ndcg@10: 0.028526
2025-12-15 19:58:44 - GraphTrainer - INFO -   map@10: 0.020565
2025-12-15 19:58:44 - GraphTrainer - INFO -   mrr@10: 0.021512
2025-12-15 19:58:44 - GraphTrainer - INFO -   precision@20: 0.004448
2025-12-15 19:58:44 - GraphTrainer - INFO -   recall@20: 0.084440
2025-12-15 19:58:44 - GraphTrainer - INFO -   hit_rate@20: 0.088506
2025-12-15 19:58:44 - GraphTrainer - INFO -   ndcg@20: 0.036255
2025-12-15 19:58:44 - GraphTrainer - INFO -   map@20: 0.022624
2025-12-15 19:58:44 - GraphTrainer - INFO -   mrr@20: 0.023661
2025-12-15 19:58:44 - GraphTrainer - INFO - 第 27 轮训练完成
2025-12-15 19:58:44 - GraphTrainer - INFO - train_loss: 0.249613
2025-12-15 19:58:44 - GraphTrainer - INFO - precision@5: 0.006727
2025-12-15 19:58:44 - GraphTrainer - INFO - recall@5: 0.032094
2025-12-15 19:58:44 - GraphTrainer - INFO - hit_rate@5: 0.033582
2025-12-15 19:58:44 - GraphTrainer - INFO - ndcg@5: 0.021462
2025-12-15 19:58:44 - GraphTrainer - INFO - map@5: 0.017717
2025-12-15 19:58:44 - GraphTrainer - INFO - mrr@5: 0.018512
2025-12-15 19:58:44 - GraphTrainer - INFO - precision@10: 0.005662
2025-12-15 19:58:44 - GraphTrainer - INFO - recall@10: 0.053906
2025-12-15 19:58:44 - GraphTrainer - INFO - hit_rate@10: 0.056518
2025-12-15 19:58:44 - GraphTrainer - INFO - ndcg@10: 0.028526
2025-12-15 19:58:44 - GraphTrainer - INFO - map@10: 0.020565
2025-12-15 19:58:44 - GraphTrainer - INFO - mrr@10: 0.021512
2025-12-15 19:58:44 - GraphTrainer - INFO - precision@20: 0.004448
2025-12-15 19:58:44 - GraphTrainer - INFO - recall@20: 0.084440
2025-12-15 19:58:44 - GraphTrainer - INFO - hit_rate@20: 0.088506
2025-12-15 19:58:44 - GraphTrainer - INFO - ndcg@20: 0.036255
2025-12-15 19:58:44 - GraphTrainer - INFO - map@20: 0.022624
2025-12-15 19:58:44 - GraphTrainer - INFO - mrr@20: 0.023661
2025-12-15 19:58:44 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:58:44 - GraphTrainer - INFO - ============================================================
2025-12-15 19:58:44 - GraphTrainer - INFO - 开始第 28/1000 轮训练
2025-12-15 19:58:44 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2609, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2498, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2395, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2448, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2506, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2477, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2426, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2309, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2536, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2678, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2387, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2416, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2574, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2467, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2505, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2462, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2335, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2617, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2592, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2320, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2634, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2837, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2407, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2399, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2786, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2600, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2347, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2446, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2595, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2727, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2483, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2620, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2483, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2527, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2622, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2452, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2462, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2507, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2317, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2505, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2398, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2482, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2452, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2437, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2408, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2635, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2704, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2407, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2281, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2450, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2601, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2336, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2436, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2523, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2325, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2466, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2499, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2624, device='cuda:0', grad_fn=<AddBackward0>)
The 27 training average loss: 0.2496128986621725
2025-12-15 19:58:52 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:58:52 - GraphTrainer - INFO -   precision@5: 0.006768
2025-12-15 19:58:52 - GraphTrainer - INFO -   recall@5: 0.032387
2025-12-15 19:58:52 - GraphTrainer - INFO -   hit_rate@5: 0.033839
2025-12-15 19:58:52 - GraphTrainer - INFO -   ndcg@5: 0.021421
2025-12-15 19:58:52 - GraphTrainer - INFO -   map@5: 0.017597
2025-12-15 19:58:52 - GraphTrainer - INFO -   mrr@5: 0.018353
2025-12-15 19:58:52 - GraphTrainer - INFO -   precision@10: 0.005446
2025-12-15 19:58:52 - GraphTrainer - INFO -   recall@10: 0.051715
2025-12-15 19:58:52 - GraphTrainer - INFO -   hit_rate@10: 0.054307
2025-12-15 19:58:52 - GraphTrainer - INFO -   ndcg@10: 0.027702
2025-12-15 19:58:52 - GraphTrainer - INFO -   map@10: 0.020130
2025-12-15 19:58:52 - GraphTrainer - INFO -   mrr@10: 0.021033
2025-12-15 19:58:52 - GraphTrainer - INFO -   precision@20: 0.004356
2025-12-15 19:58:52 - GraphTrainer - INFO -   recall@20: 0.082758
2025-12-15 19:58:52 - GraphTrainer - INFO -   hit_rate@20: 0.086655
2025-12-15 19:58:52 - GraphTrainer - INFO -   ndcg@20: 0.035567
2025-12-15 19:58:52 - GraphTrainer - INFO -   map@20: 0.022238
2025-12-15 19:58:52 - GraphTrainer - INFO -   mrr@20: 0.023223
2025-12-15 19:58:52 - GraphTrainer - INFO - 第 28 轮训练完成
2025-12-15 19:58:52 - GraphTrainer - INFO - train_loss: 0.250127
2025-12-15 19:58:52 - GraphTrainer - INFO - precision@5: 0.006768
2025-12-15 19:58:52 - GraphTrainer - INFO - recall@5: 0.032387
2025-12-15 19:58:52 - GraphTrainer - INFO - hit_rate@5: 0.033839
2025-12-15 19:58:52 - GraphTrainer - INFO - ndcg@5: 0.021421
2025-12-15 19:58:52 - GraphTrainer - INFO - map@5: 0.017597
2025-12-15 19:58:52 - GraphTrainer - INFO - mrr@5: 0.018353
2025-12-15 19:58:52 - GraphTrainer - INFO - precision@10: 0.005446
2025-12-15 19:58:52 - GraphTrainer - INFO - recall@10: 0.051715
2025-12-15 19:58:52 - GraphTrainer - INFO - hit_rate@10: 0.054307
2025-12-15 19:58:52 - GraphTrainer - INFO - ndcg@10: 0.027702
2025-12-15 19:58:52 - GraphTrainer - INFO - map@10: 0.020130
2025-12-15 19:58:52 - GraphTrainer - INFO - mrr@10: 0.021033
2025-12-15 19:58:52 - GraphTrainer - INFO - precision@20: 0.004356
2025-12-15 19:58:52 - GraphTrainer - INFO - recall@20: 0.082758
2025-12-15 19:58:52 - GraphTrainer - INFO - hit_rate@20: 0.086655
2025-12-15 19:58:52 - GraphTrainer - INFO - ndcg@20: 0.035567
2025-12-15 19:58:52 - GraphTrainer - INFO - map@20: 0.022238
2025-12-15 19:58:52 - GraphTrainer - INFO - mrr@20: 0.023223
2025-12-15 19:58:52 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:58:52 - GraphTrainer - INFO - ============================================================
2025-12-15 19:58:52 - GraphTrainer - INFO - 开始第 29/1000 轮训练
2025-12-15 19:58:52 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2388, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2626, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2578, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2482, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2380, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2476, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2473, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2615, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2357, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2417, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2438, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2516, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2312, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2536, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2324, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2637, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2571, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2302, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2580, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2441, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2467, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2503, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2321, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2344, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2746, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2444, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2832, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2409, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2513, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2453, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2628, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2501, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2478, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2593, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2707, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2514, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2429, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2392, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2501, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2585, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2699, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2564, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2543, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2313, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2464, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2494, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2516, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2321, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2793, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2484, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2628, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2586, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2638, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2507, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2360, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2398, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2343, device='cuda:0', grad_fn=<AddBackward0>)
The 28 training average loss: 0.25012677548260526
2025-12-15 19:59:00 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:59:00 - GraphTrainer - INFO -   precision@5: 0.006778
2025-12-15 19:59:00 - GraphTrainer - INFO -   recall@5: 0.032481
2025-12-15 19:59:00 - GraphTrainer - INFO -   hit_rate@5: 0.033890
2025-12-15 19:59:00 - GraphTrainer - INFO -   ndcg@5: 0.021635
2025-12-15 19:59:00 - GraphTrainer - INFO -   map@5: 0.017854
2025-12-15 19:59:00 - GraphTrainer - INFO -   mrr@5: 0.018567
2025-12-15 19:59:00 - GraphTrainer - INFO -   precision@10: 0.005554
2025-12-15 19:59:00 - GraphTrainer - INFO -   recall@10: 0.052533
2025-12-15 19:59:00 - GraphTrainer - INFO -   hit_rate@10: 0.055336
2025-12-15 19:59:00 - GraphTrainer - INFO -   ndcg@10: 0.028154
2025-12-15 19:59:00 - GraphTrainer - INFO -   map@10: 0.020471
2025-12-15 19:59:00 - GraphTrainer - INFO -   mrr@10: 0.021355
2025-12-15 19:59:00 - GraphTrainer - INFO -   precision@20: 0.004474
2025-12-15 19:59:00 - GraphTrainer - INFO -   recall@20: 0.084695
2025-12-15 19:59:00 - GraphTrainer - INFO -   hit_rate@20: 0.088917
2025-12-15 19:59:00 - GraphTrainer - INFO -   ndcg@20: 0.036312
2025-12-15 19:59:00 - GraphTrainer - INFO -   map@20: 0.022658
2025-12-15 19:59:00 - GraphTrainer - INFO -   mrr@20: 0.023634
2025-12-15 19:59:00 - GraphTrainer - INFO - 第 29 轮训练完成
2025-12-15 19:59:00 - GraphTrainer - INFO - train_loss: 0.248610
2025-12-15 19:59:00 - GraphTrainer - INFO - precision@5: 0.006778
2025-12-15 19:59:00 - GraphTrainer - INFO - recall@5: 0.032481
2025-12-15 19:59:00 - GraphTrainer - INFO - hit_rate@5: 0.033890
2025-12-15 19:59:00 - GraphTrainer - INFO - ndcg@5: 0.021635
2025-12-15 19:59:00 - GraphTrainer - INFO - map@5: 0.017854
2025-12-15 19:59:00 - GraphTrainer - INFO - mrr@5: 0.018567
2025-12-15 19:59:00 - GraphTrainer - INFO - precision@10: 0.005554
2025-12-15 19:59:00 - GraphTrainer - INFO - recall@10: 0.052533
2025-12-15 19:59:00 - GraphTrainer - INFO - hit_rate@10: 0.055336
2025-12-15 19:59:00 - GraphTrainer - INFO - ndcg@10: 0.028154
2025-12-15 19:59:00 - GraphTrainer - INFO - map@10: 0.020471
2025-12-15 19:59:00 - GraphTrainer - INFO - mrr@10: 0.021355
2025-12-15 19:59:00 - GraphTrainer - INFO - precision@20: 0.004474
2025-12-15 19:59:00 - GraphTrainer - INFO - recall@20: 0.084695
2025-12-15 19:59:00 - GraphTrainer - INFO - hit_rate@20: 0.088917
2025-12-15 19:59:00 - GraphTrainer - INFO - ndcg@20: 0.036312
2025-12-15 19:59:00 - GraphTrainer - INFO - map@20: 0.022658
2025-12-15 19:59:00 - GraphTrainer - INFO - mrr@20: 0.023634
2025-12-15 19:59:00 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:59:00 - GraphTrainer - INFO - ============================================================
2025-12-15 19:59:00 - GraphTrainer - INFO - 开始第 30/1000 轮训练
2025-12-15 19:59:00 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2599, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2692, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2436, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2569, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2217, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2511, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2417, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2467, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2291, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2459, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2407, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2372, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2675, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2614, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2605, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2629, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2678, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2288, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2435, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2416, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2619, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2643, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2622, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2620, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2516, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2676, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2386, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2507, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2482, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2416, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2539, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2364, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2578, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2490, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2587, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2532, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2399, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2418, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2424, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2422, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2413, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2673, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2496, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2373, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2313, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2534, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2269, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2477, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2506, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2202, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2577, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2581, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2489, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2295, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2603, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2414, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2395, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2568, device='cuda:0', grad_fn=<AddBackward0>)
The 29 training average loss: 0.24860972474361287
2025-12-15 19:59:08 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:59:08 - GraphTrainer - INFO -   precision@5: 0.006788
2025-12-15 19:59:08 - GraphTrainer - INFO -   recall@5: 0.032524
2025-12-15 19:59:08 - GraphTrainer - INFO -   hit_rate@5: 0.033942
2025-12-15 19:59:08 - GraphTrainer - INFO -   ndcg@5: 0.021738
2025-12-15 19:59:08 - GraphTrainer - INFO -   map@5: 0.017974
2025-12-15 19:59:08 - GraphTrainer - INFO -   mrr@5: 0.018711
2025-12-15 19:59:08 - GraphTrainer - INFO -   precision@10: 0.005487
2025-12-15 19:59:08 - GraphTrainer - INFO -   recall@10: 0.052157
2025-12-15 19:59:08 - GraphTrainer - INFO -   hit_rate@10: 0.054821
2025-12-15 19:59:08 - GraphTrainer - INFO -   ndcg@10: 0.028084
2025-12-15 19:59:08 - GraphTrainer - INFO -   map@10: 0.020509
2025-12-15 19:59:08 - GraphTrainer - INFO -   mrr@10: 0.021411
2025-12-15 19:59:08 - GraphTrainer - INFO -   precision@20: 0.004582
2025-12-15 19:59:08 - GraphTrainer - INFO -   recall@20: 0.086994
2025-12-15 19:59:08 - GraphTrainer - INFO -   hit_rate@20: 0.091232
2025-12-15 19:59:08 - GraphTrainer - INFO -   ndcg@20: 0.036926
2025-12-15 19:59:08 - GraphTrainer - INFO -   map@20: 0.022880
2025-12-15 19:59:08 - GraphTrainer - INFO -   mrr@20: 0.023884
2025-12-15 19:59:08 - GraphTrainer - INFO - 第 30 轮训练完成
2025-12-15 19:59:08 - GraphTrainer - INFO - train_loss: 0.247195
2025-12-15 19:59:08 - GraphTrainer - INFO - precision@5: 0.006788
2025-12-15 19:59:08 - GraphTrainer - INFO - recall@5: 0.032524
2025-12-15 19:59:08 - GraphTrainer - INFO - hit_rate@5: 0.033942
2025-12-15 19:59:08 - GraphTrainer - INFO - ndcg@5: 0.021738
2025-12-15 19:59:08 - GraphTrainer - INFO - map@5: 0.017974
2025-12-15 19:59:08 - GraphTrainer - INFO - mrr@5: 0.018711
2025-12-15 19:59:08 - GraphTrainer - INFO - precision@10: 0.005487
2025-12-15 19:59:08 - GraphTrainer - INFO - recall@10: 0.052157
2025-12-15 19:59:08 - GraphTrainer - INFO - hit_rate@10: 0.054821
2025-12-15 19:59:08 - GraphTrainer - INFO - ndcg@10: 0.028084
2025-12-15 19:59:08 - GraphTrainer - INFO - map@10: 0.020509
2025-12-15 19:59:08 - GraphTrainer - INFO - mrr@10: 0.021411
2025-12-15 19:59:08 - GraphTrainer - INFO - precision@20: 0.004582
2025-12-15 19:59:08 - GraphTrainer - INFO - recall@20: 0.086994
2025-12-15 19:59:08 - GraphTrainer - INFO - hit_rate@20: 0.091232
2025-12-15 19:59:08 - GraphTrainer - INFO - ndcg@20: 0.036926
2025-12-15 19:59:08 - GraphTrainer - INFO - map@20: 0.022880
2025-12-15 19:59:08 - GraphTrainer - INFO - mrr@20: 0.023884
2025-12-15 19:59:08 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:59:08 - GraphTrainer - INFO - 检查点已保存: Epoch 30 -> ./checkpoints/checkpoint_epoch_30.pth
2025-12-15 19:59:08 - GraphTrainer - INFO - ============================================================
2025-12-15 19:59:08 - GraphTrainer - INFO - 开始第 31/1000 轮训练
2025-12-15 19:59:08 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2487, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2547, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2551, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2337, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2631, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2361, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2381, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2520, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2470, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2424, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2588, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2588, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2829, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2537, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2487, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2427, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2529, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2632, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2421, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2492, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2464, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2344, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2548, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2481, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2421, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2390, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2421, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2565, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2365, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2513, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2540, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2457, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2534, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2524, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2231, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2280, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2339, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2482, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2444, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2434, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2758, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2451, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2355, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2367, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2656, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2516, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2422, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2513, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2530, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2566, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2472, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2354, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2320, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2451, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2360, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2424, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2357, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2485, device='cuda:0', grad_fn=<AddBackward0>)
The 30 training average loss: 0.2471948671957542
2025-12-15 19:59:16 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:59:16 - GraphTrainer - INFO -   precision@5: 0.006902
2025-12-15 19:59:16 - GraphTrainer - INFO -   recall@5: 0.032943
2025-12-15 19:59:16 - GraphTrainer - INFO -   hit_rate@5: 0.034508
2025-12-15 19:59:16 - GraphTrainer - INFO -   ndcg@5: 0.021846
2025-12-15 19:59:16 - GraphTrainer - INFO -   map@5: 0.017942
2025-12-15 19:59:16 - GraphTrainer - INFO -   mrr@5: 0.018747
2025-12-15 19:59:16 - GraphTrainer - INFO -   precision@10: 0.005539
2025-12-15 19:59:16 - GraphTrainer - INFO -   recall@10: 0.052568
2025-12-15 19:59:16 - GraphTrainer - INFO -   hit_rate@10: 0.055336
2025-12-15 19:59:16 - GraphTrainer - INFO -   ndcg@10: 0.028249
2025-12-15 19:59:16 - GraphTrainer - INFO -   map@10: 0.020540
2025-12-15 19:59:16 - GraphTrainer - INFO -   mrr@10: 0.021503
2025-12-15 19:59:16 - GraphTrainer - INFO -   precision@20: 0.004520
2025-12-15 19:59:16 - GraphTrainer - INFO -   recall@20: 0.085863
2025-12-15 19:59:16 - GraphTrainer - INFO -   hit_rate@20: 0.090049
2025-12-15 19:59:16 - GraphTrainer - INFO -   ndcg@20: 0.036685
2025-12-15 19:59:16 - GraphTrainer - INFO -   map@20: 0.022799
2025-12-15 19:59:16 - GraphTrainer - INFO -   mrr@20: 0.023857
2025-12-15 19:59:16 - GraphTrainer - INFO - 第 31 轮训练完成
2025-12-15 19:59:16 - GraphTrainer - INFO - train_loss: 0.240817
2025-12-15 19:59:16 - GraphTrainer - INFO - precision@5: 0.006902
2025-12-15 19:59:16 - GraphTrainer - INFO - recall@5: 0.032943
2025-12-15 19:59:16 - GraphTrainer - INFO - hit_rate@5: 0.034508
2025-12-15 19:59:16 - GraphTrainer - INFO - ndcg@5: 0.021846
2025-12-15 19:59:16 - GraphTrainer - INFO - map@5: 0.017942
2025-12-15 19:59:16 - GraphTrainer - INFO - mrr@5: 0.018747
2025-12-15 19:59:16 - GraphTrainer - INFO - precision@10: 0.005539
2025-12-15 19:59:16 - GraphTrainer - INFO - recall@10: 0.052568
2025-12-15 19:59:16 - GraphTrainer - INFO - hit_rate@10: 0.055336
2025-12-15 19:59:16 - GraphTrainer - INFO - ndcg@10: 0.028249
2025-12-15 19:59:16 - GraphTrainer - INFO - map@10: 0.020540
2025-12-15 19:59:16 - GraphTrainer - INFO - mrr@10: 0.021503
2025-12-15 19:59:16 - GraphTrainer - INFO - precision@20: 0.004520
2025-12-15 19:59:16 - GraphTrainer - INFO - recall@20: 0.085863
2025-12-15 19:59:16 - GraphTrainer - INFO - hit_rate@20: 0.090049
2025-12-15 19:59:16 - GraphTrainer - INFO - ndcg@20: 0.036685
2025-12-15 19:59:16 - GraphTrainer - INFO - map@20: 0.022799
2025-12-15 19:59:16 - GraphTrainer - INFO - mrr@20: 0.023857
2025-12-15 19:59:16 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:59:16 - GraphTrainer - INFO - ============================================================
2025-12-15 19:59:16 - GraphTrainer - INFO - 开始第 32/1000 轮训练
2025-12-15 19:59:16 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2160, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2382, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2429, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2356, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2265, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2175, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2336, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2479, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2325, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2417, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2475, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2309, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2375, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2408, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2637, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2223, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2389, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2346, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2475, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2367, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2184, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2129, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2432, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2284, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2165, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2504, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2554, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2544, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2401, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2297, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2404, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2458, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2445, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2480, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2675, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2438, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2522, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2440, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2564, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2397, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2388, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2497, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2312, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2389, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2389, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2575, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2308, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2460, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2572, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2461, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2532, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2342, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2464, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2521, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2429, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2323, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2380, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2683, device='cuda:0', grad_fn=<AddBackward0>)
The 31 training average loss: 0.2408169782881079
2025-12-15 19:59:24 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:59:24 - GraphTrainer - INFO -   precision@5: 0.006737
2025-12-15 19:59:24 - GraphTrainer - INFO -   recall@5: 0.032115
2025-12-15 19:59:24 - GraphTrainer - INFO -   hit_rate@5: 0.033685
2025-12-15 19:59:24 - GraphTrainer - INFO -   ndcg@5: 0.021497
2025-12-15 19:59:24 - GraphTrainer - INFO -   map@5: 0.017760
2025-12-15 19:59:24 - GraphTrainer - INFO -   mrr@5: 0.018547
2025-12-15 19:59:24 - GraphTrainer - INFO -   precision@10: 0.005590
2025-12-15 19:59:24 - GraphTrainer - INFO -   recall@10: 0.053013
2025-12-15 19:59:24 - GraphTrainer - INFO -   hit_rate@10: 0.055798
2025-12-15 19:59:24 - GraphTrainer - INFO -   ndcg@10: 0.028264
2025-12-15 19:59:24 - GraphTrainer - INFO -   map@10: 0.020480
2025-12-15 19:59:24 - GraphTrainer - INFO -   mrr@10: 0.021427
2025-12-15 19:59:24 - GraphTrainer - INFO -   precision@20: 0.004418
2025-12-15 19:59:24 - GraphTrainer - INFO -   recall@20: 0.083654
2025-12-15 19:59:24 - GraphTrainer - INFO -   hit_rate@20: 0.088043
2025-12-15 19:59:24 - GraphTrainer - INFO -   ndcg@20: 0.036055
2025-12-15 19:59:24 - GraphTrainer - INFO -   map@20: 0.022571
2025-12-15 19:59:24 - GraphTrainer - INFO -   mrr@20: 0.023621
2025-12-15 19:59:24 - GraphTrainer - INFO - 第 32 轮训练完成
2025-12-15 19:59:24 - GraphTrainer - INFO - train_loss: 0.243508
2025-12-15 19:59:24 - GraphTrainer - INFO - precision@5: 0.006737
2025-12-15 19:59:24 - GraphTrainer - INFO - recall@5: 0.032115
2025-12-15 19:59:24 - GraphTrainer - INFO - hit_rate@5: 0.033685
2025-12-15 19:59:24 - GraphTrainer - INFO - ndcg@5: 0.021497
2025-12-15 19:59:24 - GraphTrainer - INFO - map@5: 0.017760
2025-12-15 19:59:24 - GraphTrainer - INFO - mrr@5: 0.018547
2025-12-15 19:59:24 - GraphTrainer - INFO - precision@10: 0.005590
2025-12-15 19:59:24 - GraphTrainer - INFO - recall@10: 0.053013
2025-12-15 19:59:24 - GraphTrainer - INFO - hit_rate@10: 0.055798
2025-12-15 19:59:24 - GraphTrainer - INFO - ndcg@10: 0.028264
2025-12-15 19:59:24 - GraphTrainer - INFO - map@10: 0.020480
2025-12-15 19:59:24 - GraphTrainer - INFO - mrr@10: 0.021427
2025-12-15 19:59:24 - GraphTrainer - INFO - precision@20: 0.004418
2025-12-15 19:59:24 - GraphTrainer - INFO - recall@20: 0.083654
2025-12-15 19:59:24 - GraphTrainer - INFO - hit_rate@20: 0.088043
2025-12-15 19:59:24 - GraphTrainer - INFO - ndcg@20: 0.036055
2025-12-15 19:59:24 - GraphTrainer - INFO - map@20: 0.022571
2025-12-15 19:59:24 - GraphTrainer - INFO - mrr@20: 0.023621
2025-12-15 19:59:24 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:59:24 - GraphTrainer - INFO - ============================================================
2025-12-15 19:59:24 - GraphTrainer - INFO - 开始第 33/1000 轮训练
2025-12-15 19:59:24 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2312, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2672, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2432, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2313, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2447, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2328, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2200, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2512, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2403, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2485, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2531, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2608, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2576, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2488, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2259, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2520, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2354, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2535, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2364, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2329, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2439, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2283, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2630, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2374, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2394, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2251, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2401, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2603, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2325, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2582, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2626, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2226, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2504, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2543, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2494, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2551, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2478, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2274, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2406, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2447, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2253, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2570, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2274, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2288, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2499, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2493, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2371, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2364, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2470, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2602, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2442, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2408, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2239, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2419, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2770, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2279, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2557, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2438, device='cuda:0', grad_fn=<AddBackward0>)
The 32 training average loss: 0.24350762572781792
2025-12-15 19:59:32 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:59:32 - GraphTrainer - INFO -   precision@5: 0.006778
2025-12-15 19:59:32 - GraphTrainer - INFO -   recall@5: 0.032464
2025-12-15 19:59:32 - GraphTrainer - INFO -   hit_rate@5: 0.033890
2025-12-15 19:59:32 - GraphTrainer - INFO -   ndcg@5: 0.021648
2025-12-15 19:59:32 - GraphTrainer - INFO -   map@5: 0.017863
2025-12-15 19:59:32 - GraphTrainer - INFO -   mrr@5: 0.018666
2025-12-15 19:59:32 - GraphTrainer - INFO -   precision@10: 0.005672
2025-12-15 19:59:32 - GraphTrainer - INFO -   recall@10: 0.053861
2025-12-15 19:59:32 - GraphTrainer - INFO -   hit_rate@10: 0.056724
2025-12-15 19:59:32 - GraphTrainer - INFO -   ndcg@10: 0.028629
2025-12-15 19:59:32 - GraphTrainer - INFO -   map@10: 0.020687
2025-12-15 19:59:32 - GraphTrainer - INFO -   mrr@10: 0.021680
2025-12-15 19:59:32 - GraphTrainer - INFO -   precision@20: 0.004572
2025-12-15 19:59:32 - GraphTrainer - INFO -   recall@20: 0.086621
2025-12-15 19:59:32 - GraphTrainer - INFO -   hit_rate@20: 0.091077
2025-12-15 19:59:32 - GraphTrainer - INFO -   ndcg@20: 0.036943
2025-12-15 19:59:32 - GraphTrainer - INFO -   map@20: 0.022914
2025-12-15 19:59:32 - GraphTrainer - INFO -   mrr@20: 0.024009
2025-12-15 19:59:32 - GraphTrainer - INFO - 第 33 轮训练完成
2025-12-15 19:59:32 - GraphTrainer - INFO - train_loss: 0.242850
2025-12-15 19:59:32 - GraphTrainer - INFO - precision@5: 0.006778
2025-12-15 19:59:32 - GraphTrainer - INFO - recall@5: 0.032464
2025-12-15 19:59:32 - GraphTrainer - INFO - hit_rate@5: 0.033890
2025-12-15 19:59:32 - GraphTrainer - INFO - ndcg@5: 0.021648
2025-12-15 19:59:32 - GraphTrainer - INFO - map@5: 0.017863
2025-12-15 19:59:32 - GraphTrainer - INFO - mrr@5: 0.018666
2025-12-15 19:59:32 - GraphTrainer - INFO - precision@10: 0.005672
2025-12-15 19:59:32 - GraphTrainer - INFO - recall@10: 0.053861
2025-12-15 19:59:32 - GraphTrainer - INFO - hit_rate@10: 0.056724
2025-12-15 19:59:32 - GraphTrainer - INFO - ndcg@10: 0.028629
2025-12-15 19:59:32 - GraphTrainer - INFO - map@10: 0.020687
2025-12-15 19:59:32 - GraphTrainer - INFO - mrr@10: 0.021680
2025-12-15 19:59:32 - GraphTrainer - INFO - precision@20: 0.004572
2025-12-15 19:59:32 - GraphTrainer - INFO - recall@20: 0.086621
2025-12-15 19:59:32 - GraphTrainer - INFO - hit_rate@20: 0.091077
2025-12-15 19:59:32 - GraphTrainer - INFO - ndcg@20: 0.036943
2025-12-15 19:59:32 - GraphTrainer - INFO - map@20: 0.022914
2025-12-15 19:59:32 - GraphTrainer - INFO - mrr@20: 0.024009
2025-12-15 19:59:32 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:59:32 - GraphTrainer - INFO - ============================================================
2025-12-15 19:59:32 - GraphTrainer - INFO - 开始第 34/1000 轮训练
2025-12-15 19:59:32 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2345, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2424, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2429, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2225, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2294, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2299, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2390, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2502, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2669, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2379, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2550, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2239, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2334, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2736, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2440, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2318, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2443, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2293, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2458, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2440, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2572, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2403, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2655, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2275, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2491, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2273, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2362, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2514, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2464, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2416, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2550, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2513, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2509, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2537, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2386, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2533, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2548, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2369, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2447, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2453, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2333, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2536, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2502, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2470, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2667, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2430, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2305, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2467, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2378, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2495, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2379, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2430, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2169, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2222, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2465, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2291, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2602, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2239, device='cuda:0', grad_fn=<AddBackward0>)
The 33 training average loss: 0.24285014513237724
2025-12-15 19:59:40 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:59:40 - GraphTrainer - INFO -   precision@5: 0.006788
2025-12-15 19:59:40 - GraphTrainer - INFO -   recall@5: 0.032475
2025-12-15 19:59:40 - GraphTrainer - INFO -   hit_rate@5: 0.033942
2025-12-15 19:59:40 - GraphTrainer - INFO -   ndcg@5: 0.021653
2025-12-15 19:59:40 - GraphTrainer - INFO -   map@5: 0.017853
2025-12-15 19:59:40 - GraphTrainer - INFO -   mrr@5: 0.018648
2025-12-15 19:59:40 - GraphTrainer - INFO -   precision@10: 0.005600
2025-12-15 19:59:40 - GraphTrainer - INFO -   recall@10: 0.052986
2025-12-15 19:59:40 - GraphTrainer - INFO -   hit_rate@10: 0.055850
2025-12-15 19:59:40 - GraphTrainer - INFO -   ndcg@10: 0.028313
2025-12-15 19:59:40 - GraphTrainer - INFO -   map@10: 0.020526
2025-12-15 19:59:40 - GraphTrainer - INFO -   mrr@10: 0.021501
2025-12-15 19:59:40 - GraphTrainer - INFO -   precision@20: 0.004562
2025-12-15 19:59:40 - GraphTrainer - INFO -   recall@20: 0.086295
2025-12-15 19:59:40 - GraphTrainer - INFO -   hit_rate@20: 0.090769
2025-12-15 19:59:40 - GraphTrainer - INFO -   ndcg@20: 0.036791
2025-12-15 19:59:40 - GraphTrainer - INFO -   map@20: 0.022808
2025-12-15 19:59:40 - GraphTrainer - INFO -   mrr@20: 0.023888
2025-12-15 19:59:40 - GraphTrainer - INFO - 第 34 轮训练完成
2025-12-15 19:59:40 - GraphTrainer - INFO - train_loss: 0.241879
2025-12-15 19:59:40 - GraphTrainer - INFO - precision@5: 0.006788
2025-12-15 19:59:40 - GraphTrainer - INFO - recall@5: 0.032475
2025-12-15 19:59:40 - GraphTrainer - INFO - hit_rate@5: 0.033942
2025-12-15 19:59:40 - GraphTrainer - INFO - ndcg@5: 0.021653
2025-12-15 19:59:40 - GraphTrainer - INFO - map@5: 0.017853
2025-12-15 19:59:40 - GraphTrainer - INFO - mrr@5: 0.018648
2025-12-15 19:59:40 - GraphTrainer - INFO - precision@10: 0.005600
2025-12-15 19:59:40 - GraphTrainer - INFO - recall@10: 0.052986
2025-12-15 19:59:40 - GraphTrainer - INFO - hit_rate@10: 0.055850
2025-12-15 19:59:40 - GraphTrainer - INFO - ndcg@10: 0.028313
2025-12-15 19:59:40 - GraphTrainer - INFO - map@10: 0.020526
2025-12-15 19:59:40 - GraphTrainer - INFO - mrr@10: 0.021501
2025-12-15 19:59:40 - GraphTrainer - INFO - precision@20: 0.004562
2025-12-15 19:59:40 - GraphTrainer - INFO - recall@20: 0.086295
2025-12-15 19:59:40 - GraphTrainer - INFO - hit_rate@20: 0.090769
2025-12-15 19:59:40 - GraphTrainer - INFO - ndcg@20: 0.036791
2025-12-15 19:59:40 - GraphTrainer - INFO - map@20: 0.022808
2025-12-15 19:59:40 - GraphTrainer - INFO - mrr@20: 0.023888
2025-12-15 19:59:40 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:59:40 - GraphTrainer - INFO - ============================================================
2025-12-15 19:59:40 - GraphTrainer - INFO - 开始第 35/1000 轮训练
2025-12-15 19:59:40 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2608, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2255, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2569, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2367, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2370, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2435, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2265, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2266, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2350, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2482, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2423, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2372, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2576, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2582, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2638, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2294, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2145, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2257, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2387, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2389, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2691, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2461, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2301, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2717, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2413, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2523, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2502, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2391, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2409, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2492, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2382, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2368, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2520, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2313, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2413, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2595, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2502, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2538, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2522, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2176, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2265, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2387, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2510, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2470, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2406, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2480, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2529, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2444, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2415, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2350, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2448, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2384, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2157, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2362, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2446, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2259, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2436, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2282, device='cuda:0', grad_fn=<AddBackward0>)
The 34 training average loss: 0.24187864311810198
2025-12-15 19:59:48 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:59:48 - GraphTrainer - INFO -   precision@5: 0.006634
2025-12-15 19:59:48 - GraphTrainer - INFO -   recall@5: 0.031602
2025-12-15 19:59:48 - GraphTrainer - INFO -   hit_rate@5: 0.033170
2025-12-15 19:59:48 - GraphTrainer - INFO -   ndcg@5: 0.021222
2025-12-15 19:59:48 - GraphTrainer - INFO -   map@5: 0.017561
2025-12-15 19:59:48 - GraphTrainer - INFO -   mrr@5: 0.018378
2025-12-15 19:59:48 - GraphTrainer - INFO -   precision@10: 0.005580
2025-12-15 19:59:48 - GraphTrainer - INFO -   recall@10: 0.052793
2025-12-15 19:59:48 - GraphTrainer - INFO -   hit_rate@10: 0.055644
2025-12-15 19:59:48 - GraphTrainer - INFO -   ndcg@10: 0.028080
2025-12-15 19:59:48 - GraphTrainer - INFO -   map@10: 0.020311
2025-12-15 19:59:48 - GraphTrainer - INFO -   mrr@10: 0.021288
2025-12-15 19:59:48 - GraphTrainer - INFO -   precision@20: 0.004608
2025-12-15 19:59:48 - GraphTrainer - INFO -   recall@20: 0.087188
2025-12-15 19:59:48 - GraphTrainer - INFO -   hit_rate@20: 0.091797
2025-12-15 19:59:48 - GraphTrainer - INFO -   ndcg@20: 0.036795
2025-12-15 19:59:48 - GraphTrainer - INFO -   map@20: 0.022636
2025-12-15 19:59:48 - GraphTrainer - INFO -   mrr@20: 0.023723
2025-12-15 19:59:48 - GraphTrainer - INFO - 第 35 轮训练完成
2025-12-15 19:59:48 - GraphTrainer - INFO - train_loss: 0.239680
2025-12-15 19:59:48 - GraphTrainer - INFO - precision@5: 0.006634
2025-12-15 19:59:48 - GraphTrainer - INFO - recall@5: 0.031602
2025-12-15 19:59:48 - GraphTrainer - INFO - hit_rate@5: 0.033170
2025-12-15 19:59:48 - GraphTrainer - INFO - ndcg@5: 0.021222
2025-12-15 19:59:48 - GraphTrainer - INFO - map@5: 0.017561
2025-12-15 19:59:48 - GraphTrainer - INFO - mrr@5: 0.018378
2025-12-15 19:59:48 - GraphTrainer - INFO - precision@10: 0.005580
2025-12-15 19:59:48 - GraphTrainer - INFO - recall@10: 0.052793
2025-12-15 19:59:48 - GraphTrainer - INFO - hit_rate@10: 0.055644
2025-12-15 19:59:48 - GraphTrainer - INFO - ndcg@10: 0.028080
2025-12-15 19:59:48 - GraphTrainer - INFO - map@10: 0.020311
2025-12-15 19:59:48 - GraphTrainer - INFO - mrr@10: 0.021288
2025-12-15 19:59:48 - GraphTrainer - INFO - precision@20: 0.004608
2025-12-15 19:59:48 - GraphTrainer - INFO - recall@20: 0.087188
2025-12-15 19:59:48 - GraphTrainer - INFO - hit_rate@20: 0.091797
2025-12-15 19:59:48 - GraphTrainer - INFO - ndcg@20: 0.036795
2025-12-15 19:59:48 - GraphTrainer - INFO - map@20: 0.022636
2025-12-15 19:59:48 - GraphTrainer - INFO - mrr@20: 0.023723
2025-12-15 19:59:48 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:59:48 - GraphTrainer - INFO - ============================================================
2025-12-15 19:59:48 - GraphTrainer - INFO - 开始第 36/1000 轮训练
2025-12-15 19:59:48 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2535, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2441, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2382, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2387, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2369, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2342, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2499, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2452, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2346, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2120, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2522, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2612, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2303, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2367, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2426, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2431, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2386, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2209, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2508, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2354, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2604, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2315, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2564, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2701, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2112, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2295, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2514, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2340, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2390, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2353, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2521, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2584, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2214, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2416, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2268, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2302, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2366, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2405, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2673, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2316, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2436, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2424, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2328, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2320, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2538, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2194, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2348, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2425, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2479, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2266, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2381, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2421, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2395, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2465, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2203, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2409, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2385, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2357, device='cuda:0', grad_fn=<AddBackward0>)
The 35 training average loss: 0.23968033389798526
2025-12-15 19:59:57 - GraphTrainer - INFO - 验证结果:
2025-12-15 19:59:57 - GraphTrainer - INFO -   precision@5: 0.006943
2025-12-15 19:59:57 - GraphTrainer - INFO -   recall@5: 0.033023
2025-12-15 19:59:57 - GraphTrainer - INFO -   hit_rate@5: 0.034713
2025-12-15 19:59:57 - GraphTrainer - INFO -   ndcg@5: 0.022139
2025-12-15 19:59:57 - GraphTrainer - INFO -   map@5: 0.018290
2025-12-15 19:59:57 - GraphTrainer - INFO -   mrr@5: 0.019187
2025-12-15 19:59:57 - GraphTrainer - INFO -   precision@10: 0.005672
2025-12-15 19:59:57 - GraphTrainer - INFO -   recall@10: 0.053809
2025-12-15 19:59:57 - GraphTrainer - INFO -   hit_rate@10: 0.056724
2025-12-15 19:59:57 - GraphTrainer - INFO -   ndcg@10: 0.028879
2025-12-15 19:59:57 - GraphTrainer - INFO -   map@10: 0.021003
2025-12-15 19:59:57 - GraphTrainer - INFO -   mrr@10: 0.022067
2025-12-15 19:59:57 - GraphTrainer - INFO -   precision@20: 0.004574
2025-12-15 19:59:57 - GraphTrainer - INFO -   recall@20: 0.086571
2025-12-15 19:59:57 - GraphTrainer - INFO -   hit_rate@20: 0.091077
2025-12-15 19:59:57 - GraphTrainer - INFO -   ndcg@20: 0.037203
2025-12-15 19:59:57 - GraphTrainer - INFO -   map@20: 0.023234
2025-12-15 19:59:57 - GraphTrainer - INFO -   mrr@20: 0.024401
2025-12-15 19:59:57 - GraphTrainer - INFO - 第 36 轮训练完成
2025-12-15 19:59:57 - GraphTrainer - INFO - train_loss: 0.237221
2025-12-15 19:59:57 - GraphTrainer - INFO - precision@5: 0.006943
2025-12-15 19:59:57 - GraphTrainer - INFO - recall@5: 0.033023
2025-12-15 19:59:57 - GraphTrainer - INFO - hit_rate@5: 0.034713
2025-12-15 19:59:57 - GraphTrainer - INFO - ndcg@5: 0.022139
2025-12-15 19:59:57 - GraphTrainer - INFO - map@5: 0.018290
2025-12-15 19:59:57 - GraphTrainer - INFO - mrr@5: 0.019187
2025-12-15 19:59:57 - GraphTrainer - INFO - precision@10: 0.005672
2025-12-15 19:59:57 - GraphTrainer - INFO - recall@10: 0.053809
2025-12-15 19:59:57 - GraphTrainer - INFO - hit_rate@10: 0.056724
2025-12-15 19:59:57 - GraphTrainer - INFO - ndcg@10: 0.028879
2025-12-15 19:59:57 - GraphTrainer - INFO - map@10: 0.021003
2025-12-15 19:59:57 - GraphTrainer - INFO - mrr@10: 0.022067
2025-12-15 19:59:57 - GraphTrainer - INFO - precision@20: 0.004574
2025-12-15 19:59:57 - GraphTrainer - INFO - recall@20: 0.086571
2025-12-15 19:59:57 - GraphTrainer - INFO - hit_rate@20: 0.091077
2025-12-15 19:59:57 - GraphTrainer - INFO - ndcg@20: 0.037203
2025-12-15 19:59:57 - GraphTrainer - INFO - map@20: 0.023234
2025-12-15 19:59:57 - GraphTrainer - INFO - mrr@20: 0.024401
2025-12-15 19:59:57 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 19:59:57 - GraphTrainer - INFO - ============================================================
2025-12-15 19:59:57 - GraphTrainer - INFO - 开始第 37/1000 轮训练
2025-12-15 19:59:57 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2444, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2228, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2558, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2262, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2399, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2424, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2370, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2447, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2378, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2369, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2371, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2409, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2196, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2186, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2394, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2369, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2426, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2502, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2422, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2406, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2639, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2384, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2450, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2477, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2415, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2438, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2326, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2321, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2234, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2301, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2169, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2489, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2318, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2294, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2338, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2349, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2277, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2329, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2231, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2293, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2418, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2346, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2289, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2371, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2474, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2327, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2520, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2352, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2422, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2388, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2253, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2345, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2347, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2340, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2510, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2431, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2383, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2440, device='cuda:0', grad_fn=<AddBackward0>)
The 36 training average loss: 0.237221189614
2025-12-15 20:00:05 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:00:05 - GraphTrainer - INFO -   precision@5: 0.006953
2025-12-15 20:00:05 - GraphTrainer - INFO -   recall@5: 0.033143
2025-12-15 20:00:05 - GraphTrainer - INFO -   hit_rate@5: 0.034713
2025-12-15 20:00:05 - GraphTrainer - INFO -   ndcg@5: 0.022304
2025-12-15 20:00:05 - GraphTrainer - INFO -   map@5: 0.018482
2025-12-15 20:00:05 - GraphTrainer - INFO -   mrr@5: 0.019289
2025-12-15 20:00:05 - GraphTrainer - INFO -   precision@10: 0.005667
2025-12-15 20:00:05 - GraphTrainer - INFO -   recall@10: 0.053688
2025-12-15 20:00:05 - GraphTrainer - INFO -   hit_rate@10: 0.056518
2025-12-15 20:00:05 - GraphTrainer - INFO -   ndcg@10: 0.028994
2025-12-15 20:00:05 - GraphTrainer - INFO -   map@10: 0.021189
2025-12-15 20:00:05 - GraphTrainer - INFO -   mrr@10: 0.022159
2025-12-15 20:00:05 - GraphTrainer - INFO -   precision@20: 0.004572
2025-12-15 20:00:05 - GraphTrainer - INFO -   recall@20: 0.086123
2025-12-15 20:00:05 - GraphTrainer - INFO -   hit_rate@20: 0.090872
2025-12-15 20:00:05 - GraphTrainer - INFO -   ndcg@20: 0.037274
2025-12-15 20:00:05 - GraphTrainer - INFO -   map@20: 0.023415
2025-12-15 20:00:05 - GraphTrainer - INFO -   mrr@20: 0.024509
2025-12-15 20:00:05 - GraphTrainer - INFO - 第 37 轮训练完成
2025-12-15 20:00:05 - GraphTrainer - INFO - train_loss: 0.236917
2025-12-15 20:00:05 - GraphTrainer - INFO - precision@5: 0.006953
2025-12-15 20:00:05 - GraphTrainer - INFO - recall@5: 0.033143
2025-12-15 20:00:05 - GraphTrainer - INFO - hit_rate@5: 0.034713
2025-12-15 20:00:05 - GraphTrainer - INFO - ndcg@5: 0.022304
2025-12-15 20:00:05 - GraphTrainer - INFO - map@5: 0.018482
2025-12-15 20:00:05 - GraphTrainer - INFO - mrr@5: 0.019289
2025-12-15 20:00:05 - GraphTrainer - INFO - precision@10: 0.005667
2025-12-15 20:00:05 - GraphTrainer - INFO - recall@10: 0.053688
2025-12-15 20:00:05 - GraphTrainer - INFO - hit_rate@10: 0.056518
2025-12-15 20:00:05 - GraphTrainer - INFO - ndcg@10: 0.028994
2025-12-15 20:00:05 - GraphTrainer - INFO - map@10: 0.021189
2025-12-15 20:00:05 - GraphTrainer - INFO - mrr@10: 0.022159
2025-12-15 20:00:05 - GraphTrainer - INFO - precision@20: 0.004572
2025-12-15 20:00:05 - GraphTrainer - INFO - recall@20: 0.086123
2025-12-15 20:00:05 - GraphTrainer - INFO - hit_rate@20: 0.090872
2025-12-15 20:00:05 - GraphTrainer - INFO - ndcg@20: 0.037274
2025-12-15 20:00:05 - GraphTrainer - INFO - map@20: 0.023415
2025-12-15 20:00:05 - GraphTrainer - INFO - mrr@20: 0.024509
2025-12-15 20:00:05 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:00:05 - GraphTrainer - INFO - ============================================================
2025-12-15 20:00:05 - GraphTrainer - INFO - 开始第 38/1000 轮训练
2025-12-15 20:00:05 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2382, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2303, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2266, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2232, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2584, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2366, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2279, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2420, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2267, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2298, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2330, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2388, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2465, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2209, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2420, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2305, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2631, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2163, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2276, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2441, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2412, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2501, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2344, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2496, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2345, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2360, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2401, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2395, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2380, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2515, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2465, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2486, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2260, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2467, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2506, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2323, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2371, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2256, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2438, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2340, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2243, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2272, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2439, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2360, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2416, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2342, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2302, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2300, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2345, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2503, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2448, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2472, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2262, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2397, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2468, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2048, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2337, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2373, device='cuda:0', grad_fn=<AddBackward0>)
The 37 training average loss: 0.2369169952540562
2025-12-15 20:00:13 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:00:13 - GraphTrainer - INFO -   precision@5: 0.006840
2025-12-15 20:00:13 - GraphTrainer - INFO -   recall@5: 0.032798
2025-12-15 20:00:13 - GraphTrainer - INFO -   hit_rate@5: 0.034199
2025-12-15 20:00:13 - GraphTrainer - INFO -   ndcg@5: 0.022508
2025-12-15 20:00:13 - GraphTrainer - INFO -   map@5: 0.018902
2025-12-15 20:00:13 - GraphTrainer - INFO -   mrr@5: 0.019657
2025-12-15 20:00:13 - GraphTrainer - INFO -   precision@10: 0.005832
2025-12-15 20:00:13 - GraphTrainer - INFO -   recall@10: 0.055204
2025-12-15 20:00:13 - GraphTrainer - INFO -   hit_rate@10: 0.058113
2025-12-15 20:00:13 - GraphTrainer - INFO -   ndcg@10: 0.029762
2025-12-15 20:00:13 - GraphTrainer - INFO -   map@10: 0.021797
2025-12-15 20:00:13 - GraphTrainer - INFO -   mrr@10: 0.022751
2025-12-15 20:00:13 - GraphTrainer - INFO -   precision@20: 0.004590
2025-12-15 20:00:13 - GraphTrainer - INFO -   recall@20: 0.086910
2025-12-15 20:00:13 - GraphTrainer - INFO -   hit_rate@20: 0.091283
2025-12-15 20:00:13 - GraphTrainer - INFO -   ndcg@20: 0.037813
2025-12-15 20:00:13 - GraphTrainer - INFO -   map@20: 0.023957
2025-12-15 20:00:13 - GraphTrainer - INFO -   mrr@20: 0.025010
2025-12-15 20:00:13 - GraphTrainer - INFO - 第 38 轮训练完成
2025-12-15 20:00:13 - GraphTrainer - INFO - train_loss: 0.237543
2025-12-15 20:00:13 - GraphTrainer - INFO - precision@5: 0.006840
2025-12-15 20:00:13 - GraphTrainer - INFO - recall@5: 0.032798
2025-12-15 20:00:13 - GraphTrainer - INFO - hit_rate@5: 0.034199
2025-12-15 20:00:13 - GraphTrainer - INFO - ndcg@5: 0.022508
2025-12-15 20:00:13 - GraphTrainer - INFO - map@5: 0.018902
2025-12-15 20:00:13 - GraphTrainer - INFO - mrr@5: 0.019657
2025-12-15 20:00:13 - GraphTrainer - INFO - precision@10: 0.005832
2025-12-15 20:00:13 - GraphTrainer - INFO - recall@10: 0.055204
2025-12-15 20:00:13 - GraphTrainer - INFO - hit_rate@10: 0.058113
2025-12-15 20:00:13 - GraphTrainer - INFO - ndcg@10: 0.029762
2025-12-15 20:00:13 - GraphTrainer - INFO - map@10: 0.021797
2025-12-15 20:00:13 - GraphTrainer - INFO - mrr@10: 0.022751
2025-12-15 20:00:13 - GraphTrainer - INFO - precision@20: 0.004590
2025-12-15 20:00:13 - GraphTrainer - INFO - recall@20: 0.086910
2025-12-15 20:00:13 - GraphTrainer - INFO - hit_rate@20: 0.091283
2025-12-15 20:00:13 - GraphTrainer - INFO - ndcg@20: 0.037813
2025-12-15 20:00:13 - GraphTrainer - INFO - map@20: 0.023957
2025-12-15 20:00:13 - GraphTrainer - INFO - mrr@20: 0.025010
2025-12-15 20:00:13 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:00:13 - GraphTrainer - INFO - ============================================================
2025-12-15 20:00:13 - GraphTrainer - INFO - 开始第 39/1000 轮训练
2025-12-15 20:00:13 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2276, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2293, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2504, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2468, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2295, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2421, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2288, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2254, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2407, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2161, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2281, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2437, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2359, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2633, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2291, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2468, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2413, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2440, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2345, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2266, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2472, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2407, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2358, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2542, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2474, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2353, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2529, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2480, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2356, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2479, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2245, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2557, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2265, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2321, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2401, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2429, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2271, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2374, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2254, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2453, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2448, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2250, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2261, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2308, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2446, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2243, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2412, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2345, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2547, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2305, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2304, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2400, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2346, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2070, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2288, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2450, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2637, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2397, device='cuda:0', grad_fn=<AddBackward0>)
The 38 training average loss: 0.23754303080254588
2025-12-15 20:00:20 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:00:20 - GraphTrainer - INFO -   precision@5: 0.006603
2025-12-15 20:00:20 - GraphTrainer - INFO -   recall@5: 0.031323
2025-12-15 20:00:20 - GraphTrainer - INFO -   hit_rate@5: 0.032965
2025-12-15 20:00:20 - GraphTrainer - INFO -   ndcg@5: 0.021205
2025-12-15 20:00:20 - GraphTrainer - INFO -   map@5: 0.017604
2025-12-15 20:00:20 - GraphTrainer - INFO -   mrr@5: 0.018495
2025-12-15 20:00:20 - GraphTrainer - INFO -   precision@10: 0.005678
2025-12-15 20:00:20 - GraphTrainer - INFO -   recall@10: 0.053810
2025-12-15 20:00:20 - GraphTrainer - INFO -   hit_rate@10: 0.056724
2025-12-15 20:00:20 - GraphTrainer - INFO -   ndcg@10: 0.028541
2025-12-15 20:00:20 - GraphTrainer - INFO -   map@10: 0.020591
2025-12-15 20:00:20 - GraphTrainer - INFO -   mrr@10: 0.021647
2025-12-15 20:00:20 - GraphTrainer - INFO -   precision@20: 0.004520
2025-12-15 20:00:20 - GraphTrainer - INFO -   recall@20: 0.085544
2025-12-15 20:00:20 - GraphTrainer - INFO -   hit_rate@20: 0.089946
2025-12-15 20:00:20 - GraphTrainer - INFO -   ndcg@20: 0.036588
2025-12-15 20:00:20 - GraphTrainer - INFO -   map@20: 0.022742
2025-12-15 20:00:20 - GraphTrainer - INFO -   mrr@20: 0.023891
2025-12-15 20:00:20 - GraphTrainer - INFO - 第 39 轮训练完成
2025-12-15 20:00:20 - GraphTrainer - INFO - train_loss: 0.234353
2025-12-15 20:00:20 - GraphTrainer - INFO - precision@5: 0.006603
2025-12-15 20:00:20 - GraphTrainer - INFO - recall@5: 0.031323
2025-12-15 20:00:20 - GraphTrainer - INFO - hit_rate@5: 0.032965
2025-12-15 20:00:20 - GraphTrainer - INFO - ndcg@5: 0.021205
2025-12-15 20:00:20 - GraphTrainer - INFO - map@5: 0.017604
2025-12-15 20:00:20 - GraphTrainer - INFO - mrr@5: 0.018495
2025-12-15 20:00:20 - GraphTrainer - INFO - precision@10: 0.005678
2025-12-15 20:00:20 - GraphTrainer - INFO - recall@10: 0.053810
2025-12-15 20:00:20 - GraphTrainer - INFO - hit_rate@10: 0.056724
2025-12-15 20:00:20 - GraphTrainer - INFO - ndcg@10: 0.028541
2025-12-15 20:00:20 - GraphTrainer - INFO - map@10: 0.020591
2025-12-15 20:00:20 - GraphTrainer - INFO - mrr@10: 0.021647
2025-12-15 20:00:20 - GraphTrainer - INFO - precision@20: 0.004520
2025-12-15 20:00:20 - GraphTrainer - INFO - recall@20: 0.085544
2025-12-15 20:00:20 - GraphTrainer - INFO - hit_rate@20: 0.089946
2025-12-15 20:00:20 - GraphTrainer - INFO - ndcg@20: 0.036588
2025-12-15 20:00:20 - GraphTrainer - INFO - map@20: 0.022742
2025-12-15 20:00:20 - GraphTrainer - INFO - mrr@20: 0.023891
2025-12-15 20:00:20 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:00:20 - GraphTrainer - INFO - ============================================================
2025-12-15 20:00:20 - GraphTrainer - INFO - 开始第 40/1000 轮训练
2025-12-15 20:00:20 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2395, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2261, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2273, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2226, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2292, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2572, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2322, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2369, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2273, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2326, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2433, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2352, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2291, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2388, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2377, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2569, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2462, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2126, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2632, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2297, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2229, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2356, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2210, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2330, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2221, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2543, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2257, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2357, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2060, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2414, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2308, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2130, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2212, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2216, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2195, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2404, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2205, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2192, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2343, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2478, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2143, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2386, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2522, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2218, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2364, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2236, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2351, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2823, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2586, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2472, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2214, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2385, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2320, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2471, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2316, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2377, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2278, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2570, device='cuda:0', grad_fn=<AddBackward0>)
The 39 training average loss: 0.23435334116220474
2025-12-15 20:00:28 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:00:28 - GraphTrainer - INFO -   precision@5: 0.006974
2025-12-15 20:00:28 - GraphTrainer - INFO -   recall@5: 0.033113
2025-12-15 20:00:28 - GraphTrainer - INFO -   hit_rate@5: 0.034816
2025-12-15 20:00:28 - GraphTrainer - INFO -   ndcg@5: 0.022186
2025-12-15 20:00:28 - GraphTrainer - INFO -   map@5: 0.018334
2025-12-15 20:00:28 - GraphTrainer - INFO -   mrr@5: 0.019168
2025-12-15 20:00:28 - GraphTrainer - INFO -   precision@10: 0.005739
2025-12-15 20:00:28 - GraphTrainer - INFO -   recall@10: 0.054375
2025-12-15 20:00:28 - GraphTrainer - INFO -   hit_rate@10: 0.057341
2025-12-15 20:00:28 - GraphTrainer - INFO -   ndcg@10: 0.029104
2025-12-15 20:00:28 - GraphTrainer - INFO -   map@10: 0.021136
2025-12-15 20:00:28 - GraphTrainer - INFO -   mrr@10: 0.022139
2025-12-15 20:00:28 - GraphTrainer - INFO -   precision@20: 0.004580
2025-12-15 20:00:28 - GraphTrainer - INFO -   recall@20: 0.086966
2025-12-15 20:00:28 - GraphTrainer - INFO -   hit_rate@20: 0.091232
2025-12-15 20:00:28 - GraphTrainer - INFO -   ndcg@20: 0.037376
2025-12-15 20:00:28 - GraphTrainer - INFO -   map@20: 0.023360
2025-12-15 20:00:28 - GraphTrainer - INFO -   mrr@20: 0.024448
2025-12-15 20:00:28 - GraphTrainer - INFO - 第 40 轮训练完成
2025-12-15 20:00:28 - GraphTrainer - INFO - train_loss: 0.235724
2025-12-15 20:00:28 - GraphTrainer - INFO - precision@5: 0.006974
2025-12-15 20:00:28 - GraphTrainer - INFO - recall@5: 0.033113
2025-12-15 20:00:28 - GraphTrainer - INFO - hit_rate@5: 0.034816
2025-12-15 20:00:28 - GraphTrainer - INFO - ndcg@5: 0.022186
2025-12-15 20:00:28 - GraphTrainer - INFO - map@5: 0.018334
2025-12-15 20:00:28 - GraphTrainer - INFO - mrr@5: 0.019168
2025-12-15 20:00:28 - GraphTrainer - INFO - precision@10: 0.005739
2025-12-15 20:00:28 - GraphTrainer - INFO - recall@10: 0.054375
2025-12-15 20:00:28 - GraphTrainer - INFO - hit_rate@10: 0.057341
2025-12-15 20:00:28 - GraphTrainer - INFO - ndcg@10: 0.029104
2025-12-15 20:00:28 - GraphTrainer - INFO - map@10: 0.021136
2025-12-15 20:00:28 - GraphTrainer - INFO - mrr@10: 0.022139
2025-12-15 20:00:28 - GraphTrainer - INFO - precision@20: 0.004580
2025-12-15 20:00:28 - GraphTrainer - INFO - recall@20: 0.086966
2025-12-15 20:00:28 - GraphTrainer - INFO - hit_rate@20: 0.091232
2025-12-15 20:00:28 - GraphTrainer - INFO - ndcg@20: 0.037376
2025-12-15 20:00:28 - GraphTrainer - INFO - map@20: 0.023360
2025-12-15 20:00:28 - GraphTrainer - INFO - mrr@20: 0.024448
2025-12-15 20:00:28 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:00:28 - GraphTrainer - INFO - 检查点已保存: Epoch 40 -> ./checkpoints/checkpoint_epoch_40.pth
2025-12-15 20:00:28 - GraphTrainer - INFO - ============================================================
2025-12-15 20:00:28 - GraphTrainer - INFO - 开始第 41/1000 轮训练
2025-12-15 20:00:28 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2486, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2371, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2326, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2264, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2346, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2227, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2358, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2599, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2384, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2682, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2465, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2492, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2391, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2358, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2400, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2373, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2273, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2507, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2442, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2344, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2181, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2438, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2212, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2357, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2438, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2338, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2413, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2321, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2136, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2263, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2403, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2394, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2228, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2420, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2545, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2504, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2194, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2321, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2465, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2138, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2257, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2448, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2475, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2475, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2348, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2261, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2268, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2489, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2273, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2264, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2239, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2119, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2221, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2213, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2556, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2349, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2193, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2474, device='cuda:0', grad_fn=<AddBackward0>)
The 40 training average loss: 0.23572369099690996
2025-12-15 20:00:36 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:00:36 - GraphTrainer - INFO -   precision@5: 0.006830
2025-12-15 20:00:36 - GraphTrainer - INFO -   recall@5: 0.032407
2025-12-15 20:00:36 - GraphTrainer - INFO -   hit_rate@5: 0.034096
2025-12-15 20:00:36 - GraphTrainer - INFO -   ndcg@5: 0.021788
2025-12-15 20:00:36 - GraphTrainer - INFO -   map@5: 0.018014
2025-12-15 20:00:36 - GraphTrainer - INFO -   mrr@5: 0.018866
2025-12-15 20:00:36 - GraphTrainer - INFO -   precision@10: 0.005780
2025-12-15 20:00:36 - GraphTrainer - INFO -   recall@10: 0.054702
2025-12-15 20:00:36 - GraphTrainer - INFO -   hit_rate@10: 0.057753
2025-12-15 20:00:36 - GraphTrainer - INFO -   ndcg@10: 0.029064
2025-12-15 20:00:36 - GraphTrainer - INFO -   map@10: 0.020970
2025-12-15 20:00:36 - GraphTrainer - INFO -   mrr@10: 0.021999
2025-12-15 20:00:36 - GraphTrainer - INFO -   precision@20: 0.004495
2025-12-15 20:00:36 - GraphTrainer - INFO -   recall@20: 0.085196
2025-12-15 20:00:36 - GraphTrainer - INFO -   hit_rate@20: 0.089432
2025-12-15 20:00:36 - GraphTrainer - INFO -   ndcg@20: 0.036799
2025-12-15 20:00:36 - GraphTrainer - INFO -   map@20: 0.023047
2025-12-15 20:00:36 - GraphTrainer - INFO -   mrr@20: 0.024154
2025-12-15 20:00:36 - GraphTrainer - INFO - 第 41 轮训练完成
2025-12-15 20:00:36 - GraphTrainer - INFO - train_loss: 0.230986
2025-12-15 20:00:36 - GraphTrainer - INFO - precision@5: 0.006830
2025-12-15 20:00:36 - GraphTrainer - INFO - recall@5: 0.032407
2025-12-15 20:00:36 - GraphTrainer - INFO - hit_rate@5: 0.034096
2025-12-15 20:00:36 - GraphTrainer - INFO - ndcg@5: 0.021788
2025-12-15 20:00:36 - GraphTrainer - INFO - map@5: 0.018014
2025-12-15 20:00:36 - GraphTrainer - INFO - mrr@5: 0.018866
2025-12-15 20:00:36 - GraphTrainer - INFO - precision@10: 0.005780
2025-12-15 20:00:36 - GraphTrainer - INFO - recall@10: 0.054702
2025-12-15 20:00:36 - GraphTrainer - INFO - hit_rate@10: 0.057753
2025-12-15 20:00:36 - GraphTrainer - INFO - ndcg@10: 0.029064
2025-12-15 20:00:36 - GraphTrainer - INFO - map@10: 0.020970
2025-12-15 20:00:36 - GraphTrainer - INFO - mrr@10: 0.021999
2025-12-15 20:00:36 - GraphTrainer - INFO - precision@20: 0.004495
2025-12-15 20:00:36 - GraphTrainer - INFO - recall@20: 0.085196
2025-12-15 20:00:36 - GraphTrainer - INFO - hit_rate@20: 0.089432
2025-12-15 20:00:36 - GraphTrainer - INFO - ndcg@20: 0.036799
2025-12-15 20:00:36 - GraphTrainer - INFO - map@20: 0.023047
2025-12-15 20:00:36 - GraphTrainer - INFO - mrr@20: 0.024154
2025-12-15 20:00:36 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:00:36 - GraphTrainer - INFO - ============================================================
2025-12-15 20:00:36 - GraphTrainer - INFO - 开始第 42/1000 轮训练
2025-12-15 20:00:36 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2293, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2327, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2234, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2415, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2355, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2219, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2292, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2142, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2521, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2284, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2353, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2203, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2207, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2400, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2267, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2312, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2295, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2193, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2436, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2097, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2086, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2535, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2327, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2458, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2212, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2306, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2494, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2226, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2311, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2256, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2221, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2549, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2407, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2533, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2332, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2283, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2292, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2182, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2479, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2121, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2241, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2279, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2343, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2270, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2229, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2166, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2395, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2442, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2342, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2492, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2348, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2392, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2244, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2131, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2405, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2235, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2262, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2301, device='cuda:0', grad_fn=<AddBackward0>)
The 41 training average loss: 0.2309861016170732
2025-12-15 20:00:44 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:00:44 - GraphTrainer - INFO -   precision@5: 0.006984
2025-12-15 20:00:44 - GraphTrainer - INFO -   recall@5: 0.033176
2025-12-15 20:00:44 - GraphTrainer - INFO -   hit_rate@5: 0.034868
2025-12-15 20:00:44 - GraphTrainer - INFO -   ndcg@5: 0.022097
2025-12-15 20:00:44 - GraphTrainer - INFO -   map@5: 0.018181
2025-12-15 20:00:44 - GraphTrainer - INFO -   mrr@5: 0.019030
2025-12-15 20:00:44 - GraphTrainer - INFO -   precision@10: 0.005708
2025-12-15 20:00:44 - GraphTrainer - INFO -   recall@10: 0.053977
2025-12-15 20:00:44 - GraphTrainer - INFO -   hit_rate@10: 0.056981
2025-12-15 20:00:44 - GraphTrainer - INFO -   ndcg@10: 0.028842
2025-12-15 20:00:44 - GraphTrainer - INFO -   map@10: 0.020892
2025-12-15 20:00:44 - GraphTrainer - INFO -   mrr@10: 0.021910
2025-12-15 20:00:44 - GraphTrainer - INFO -   precision@20: 0.004508
2025-12-15 20:00:44 - GraphTrainer - INFO -   recall@20: 0.085416
2025-12-15 20:00:44 - GraphTrainer - INFO -   hit_rate@20: 0.089740
2025-12-15 20:00:44 - GraphTrainer - INFO -   ndcg@20: 0.036836
2025-12-15 20:00:44 - GraphTrainer - INFO -   map@20: 0.023050
2025-12-15 20:00:44 - GraphTrainer - INFO -   mrr@20: 0.024152
2025-12-15 20:00:44 - GraphTrainer - INFO - 第 42 轮训练完成
2025-12-15 20:00:44 - GraphTrainer - INFO - train_loss: 0.231895
2025-12-15 20:00:44 - GraphTrainer - INFO - precision@5: 0.006984
2025-12-15 20:00:44 - GraphTrainer - INFO - recall@5: 0.033176
2025-12-15 20:00:44 - GraphTrainer - INFO - hit_rate@5: 0.034868
2025-12-15 20:00:44 - GraphTrainer - INFO - ndcg@5: 0.022097
2025-12-15 20:00:44 - GraphTrainer - INFO - map@5: 0.018181
2025-12-15 20:00:44 - GraphTrainer - INFO - mrr@5: 0.019030
2025-12-15 20:00:44 - GraphTrainer - INFO - precision@10: 0.005708
2025-12-15 20:00:44 - GraphTrainer - INFO - recall@10: 0.053977
2025-12-15 20:00:44 - GraphTrainer - INFO - hit_rate@10: 0.056981
2025-12-15 20:00:44 - GraphTrainer - INFO - ndcg@10: 0.028842
2025-12-15 20:00:44 - GraphTrainer - INFO - map@10: 0.020892
2025-12-15 20:00:44 - GraphTrainer - INFO - mrr@10: 0.021910
2025-12-15 20:00:44 - GraphTrainer - INFO - precision@20: 0.004508
2025-12-15 20:00:44 - GraphTrainer - INFO - recall@20: 0.085416
2025-12-15 20:00:44 - GraphTrainer - INFO - hit_rate@20: 0.089740
2025-12-15 20:00:44 - GraphTrainer - INFO - ndcg@20: 0.036836
2025-12-15 20:00:44 - GraphTrainer - INFO - map@20: 0.023050
2025-12-15 20:00:44 - GraphTrainer - INFO - mrr@20: 0.024152
2025-12-15 20:00:44 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:00:44 - GraphTrainer - INFO - ============================================================
2025-12-15 20:00:44 - GraphTrainer - INFO - 开始第 43/1000 轮训练
2025-12-15 20:00:44 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2271, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2601, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2269, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2449, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2436, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2219, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2204, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2424, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2174, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2314, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2466, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2176, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2249, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2395, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2408, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2399, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2457, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2133, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2208, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2352, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2426, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2377, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2073, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2227, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2549, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2328, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2337, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2206, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2363, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2174, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2299, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2214, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2468, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2209, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2267, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2120, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2353, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2430, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2351, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2500, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2170, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2348, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2261, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2593, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2402, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2290, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2505, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2271, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2422, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2156, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2224, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2235, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2411, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2260, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2271, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2152, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2256, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2400, device='cuda:0', grad_fn=<AddBackward0>)
The 42 training average loss: 0.23189518241019086
2025-12-15 20:00:53 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:00:53 - GraphTrainer - INFO -   precision@5: 0.007015
2025-12-15 20:00:53 - GraphTrainer - INFO -   recall@5: 0.033217
2025-12-15 20:00:53 - GraphTrainer - INFO -   hit_rate@5: 0.035022
2025-12-15 20:00:53 - GraphTrainer - INFO -   ndcg@5: 0.022198
2025-12-15 20:00:53 - GraphTrainer - INFO -   map@5: 0.018297
2025-12-15 20:00:53 - GraphTrainer - INFO -   mrr@5: 0.019189
2025-12-15 20:00:53 - GraphTrainer - INFO -   precision@10: 0.005734
2025-12-15 20:00:53 - GraphTrainer - INFO -   recall@10: 0.054263
2025-12-15 20:00:53 - GraphTrainer - INFO -   hit_rate@10: 0.057290
2025-12-15 20:00:53 - GraphTrainer - INFO -   ndcg@10: 0.028990
2025-12-15 20:00:53 - GraphTrainer - INFO -   map@10: 0.021016
2025-12-15 20:00:53 - GraphTrainer - INFO -   mrr@10: 0.022072
2025-12-15 20:00:53 - GraphTrainer - INFO -   precision@20: 0.004695
2025-12-15 20:00:53 - GraphTrainer - INFO -   recall@20: 0.089062
2025-12-15 20:00:53 - GraphTrainer - INFO -   hit_rate@20: 0.093443
2025-12-15 20:00:53 - GraphTrainer - INFO -   ndcg@20: 0.037817
2025-12-15 20:00:53 - GraphTrainer - INFO -   map@20: 0.023389
2025-12-15 20:00:53 - GraphTrainer - INFO -   mrr@20: 0.024531
2025-12-15 20:00:53 - GraphTrainer - INFO - 第 43 轮训练完成
2025-12-15 20:00:53 - GraphTrainer - INFO - train_loss: 0.230747
2025-12-15 20:00:53 - GraphTrainer - INFO - precision@5: 0.007015
2025-12-15 20:00:53 - GraphTrainer - INFO - recall@5: 0.033217
2025-12-15 20:00:53 - GraphTrainer - INFO - hit_rate@5: 0.035022
2025-12-15 20:00:53 - GraphTrainer - INFO - ndcg@5: 0.022198
2025-12-15 20:00:53 - GraphTrainer - INFO - map@5: 0.018297
2025-12-15 20:00:53 - GraphTrainer - INFO - mrr@5: 0.019189
2025-12-15 20:00:53 - GraphTrainer - INFO - precision@10: 0.005734
2025-12-15 20:00:53 - GraphTrainer - INFO - recall@10: 0.054263
2025-12-15 20:00:53 - GraphTrainer - INFO - hit_rate@10: 0.057290
2025-12-15 20:00:53 - GraphTrainer - INFO - ndcg@10: 0.028990
2025-12-15 20:00:53 - GraphTrainer - INFO - map@10: 0.021016
2025-12-15 20:00:53 - GraphTrainer - INFO - mrr@10: 0.022072
2025-12-15 20:00:53 - GraphTrainer - INFO - precision@20: 0.004695
2025-12-15 20:00:53 - GraphTrainer - INFO - recall@20: 0.089062
2025-12-15 20:00:53 - GraphTrainer - INFO - hit_rate@20: 0.093443
2025-12-15 20:00:53 - GraphTrainer - INFO - ndcg@20: 0.037817
2025-12-15 20:00:53 - GraphTrainer - INFO - map@20: 0.023389
2025-12-15 20:00:53 - GraphTrainer - INFO - mrr@20: 0.024531
2025-12-15 20:00:53 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:00:53 - GraphTrainer - INFO - ============================================================
2025-12-15 20:00:53 - GraphTrainer - INFO - 开始第 44/1000 轮训练
2025-12-15 20:00:53 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2325, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2169, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2353, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2544, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2370, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2375, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2411, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2087, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2243, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2473, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2453, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2319, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2458, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2204, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2270, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2177, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2281, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2364, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2495, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2208, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2499, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2380, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2309, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2266, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2379, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2120, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2147, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2583, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2317, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2395, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2277, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2077, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2157, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2149, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2343, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2262, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2288, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2375, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2398, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2339, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2198, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2182, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2206, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2453, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2162, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2243, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2526, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2395, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2306, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2222, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2209, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2477, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2481, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2293, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2330, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2171, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2180, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2163, device='cuda:0', grad_fn=<AddBackward0>)
The 43 training average loss: 0.2307467917943823
2025-12-15 20:01:01 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:01:01 - GraphTrainer - INFO -   precision@5: 0.006850
2025-12-15 20:01:01 - GraphTrainer - INFO -   recall@5: 0.032545
2025-12-15 20:01:01 - GraphTrainer - INFO -   hit_rate@5: 0.034199
2025-12-15 20:01:01 - GraphTrainer - INFO -   ndcg@5: 0.022119
2025-12-15 20:01:01 - GraphTrainer - INFO -   map@5: 0.018401
2025-12-15 20:01:01 - GraphTrainer - INFO -   mrr@5: 0.019312
2025-12-15 20:01:01 - GraphTrainer - INFO -   precision@10: 0.005801
2025-12-15 20:01:01 - GraphTrainer - INFO -   recall@10: 0.054969
2025-12-15 20:01:01 - GraphTrainer - INFO -   hit_rate@10: 0.057907
2025-12-15 20:01:01 - GraphTrainer - INFO -   ndcg@10: 0.029369
2025-12-15 20:01:01 - GraphTrainer - INFO -   map@10: 0.021313
2025-12-15 20:01:01 - GraphTrainer - INFO -   mrr@10: 0.022385
2025-12-15 20:01:01 - GraphTrainer - INFO -   precision@20: 0.004546
2025-12-15 20:01:01 - GraphTrainer - INFO -   recall@20: 0.086031
2025-12-15 20:01:01 - GraphTrainer - INFO -   hit_rate@20: 0.090409
2025-12-15 20:01:01 - GraphTrainer - INFO -   ndcg@20: 0.037290
2025-12-15 20:01:01 - GraphTrainer - INFO -   map@20: 0.023453
2025-12-15 20:01:01 - GraphTrainer - INFO -   mrr@20: 0.024616
2025-12-15 20:01:01 - GraphTrainer - INFO - 第 44 轮训练完成
2025-12-15 20:01:01 - GraphTrainer - INFO - train_loss: 0.229239
2025-12-15 20:01:01 - GraphTrainer - INFO - precision@5: 0.006850
2025-12-15 20:01:01 - GraphTrainer - INFO - recall@5: 0.032545
2025-12-15 20:01:01 - GraphTrainer - INFO - hit_rate@5: 0.034199
2025-12-15 20:01:01 - GraphTrainer - INFO - ndcg@5: 0.022119
2025-12-15 20:01:01 - GraphTrainer - INFO - map@5: 0.018401
2025-12-15 20:01:01 - GraphTrainer - INFO - mrr@5: 0.019312
2025-12-15 20:01:01 - GraphTrainer - INFO - precision@10: 0.005801
2025-12-15 20:01:01 - GraphTrainer - INFO - recall@10: 0.054969
2025-12-15 20:01:01 - GraphTrainer - INFO - hit_rate@10: 0.057907
2025-12-15 20:01:01 - GraphTrainer - INFO - ndcg@10: 0.029369
2025-12-15 20:01:01 - GraphTrainer - INFO - map@10: 0.021313
2025-12-15 20:01:01 - GraphTrainer - INFO - mrr@10: 0.022385
2025-12-15 20:01:01 - GraphTrainer - INFO - precision@20: 0.004546
2025-12-15 20:01:01 - GraphTrainer - INFO - recall@20: 0.086031
2025-12-15 20:01:01 - GraphTrainer - INFO - hit_rate@20: 0.090409
2025-12-15 20:01:01 - GraphTrainer - INFO - ndcg@20: 0.037290
2025-12-15 20:01:01 - GraphTrainer - INFO - map@20: 0.023453
2025-12-15 20:01:01 - GraphTrainer - INFO - mrr@20: 0.024616
2025-12-15 20:01:01 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:01:01 - GraphTrainer - INFO - ============================================================
2025-12-15 20:01:01 - GraphTrainer - INFO - 开始第 45/1000 轮训练
2025-12-15 20:01:01 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2366, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2349, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2193, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2184, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2401, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2495, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2502, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2219, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1962, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2208, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2180, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2157, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2072, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2357, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2568, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2292, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2395, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2318, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2387, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2441, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2192, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2241, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2321, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2203, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2445, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2313, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2530, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2110, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2521, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2149, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2211, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2206, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2223, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2238, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2129, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2305, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2054, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2105, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2385, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2272, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2233, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2441, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2253, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2238, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2203, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.1965, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2297, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2454, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2470, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2148, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2509, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2251, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2474, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2510, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2212, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2454, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2156, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2490, device='cuda:0', grad_fn=<AddBackward0>)
The 44 training average loss: 0.22923944967574086
2025-12-15 20:01:09 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:01:09 - GraphTrainer - INFO -   precision@5: 0.006943
2025-12-15 20:01:09 - GraphTrainer - INFO -   recall@5: 0.033080
2025-12-15 20:01:09 - GraphTrainer - INFO -   hit_rate@5: 0.034662
2025-12-15 20:01:09 - GraphTrainer - INFO -   ndcg@5: 0.022418
2025-12-15 20:01:09 - GraphTrainer - INFO -   map@5: 0.018659
2025-12-15 20:01:09 - GraphTrainer - INFO -   mrr@5: 0.019489
2025-12-15 20:01:09 - GraphTrainer - INFO -   precision@10: 0.005755
2025-12-15 20:01:09 - GraphTrainer - INFO -   recall@10: 0.054757
2025-12-15 20:01:09 - GraphTrainer - INFO -   hit_rate@10: 0.057496
2025-12-15 20:01:09 - GraphTrainer - INFO -   ndcg@10: 0.029405
2025-12-15 20:01:09 - GraphTrainer - INFO -   map@10: 0.021457
2025-12-15 20:01:09 - GraphTrainer - INFO -   mrr@10: 0.022445
2025-12-15 20:01:09 - GraphTrainer - INFO -   precision@20: 0.004541
2025-12-15 20:01:09 - GraphTrainer - INFO -   recall@20: 0.086120
2025-12-15 20:01:09 - GraphTrainer - INFO -   hit_rate@20: 0.090409
2025-12-15 20:01:09 - GraphTrainer - INFO -   ndcg@20: 0.037386
2025-12-15 20:01:09 - GraphTrainer - INFO -   map@20: 0.023601
2025-12-15 20:01:09 - GraphTrainer - INFO -   mrr@20: 0.024696
2025-12-15 20:01:09 - GraphTrainer - INFO - 第 45 轮训练完成
2025-12-15 20:01:09 - GraphTrainer - INFO - train_loss: 0.224403
2025-12-15 20:01:09 - GraphTrainer - INFO - precision@5: 0.006943
2025-12-15 20:01:09 - GraphTrainer - INFO - recall@5: 0.033080
2025-12-15 20:01:09 - GraphTrainer - INFO - hit_rate@5: 0.034662
2025-12-15 20:01:09 - GraphTrainer - INFO - ndcg@5: 0.022418
2025-12-15 20:01:09 - GraphTrainer - INFO - map@5: 0.018659
2025-12-15 20:01:09 - GraphTrainer - INFO - mrr@5: 0.019489
2025-12-15 20:01:09 - GraphTrainer - INFO - precision@10: 0.005755
2025-12-15 20:01:09 - GraphTrainer - INFO - recall@10: 0.054757
2025-12-15 20:01:09 - GraphTrainer - INFO - hit_rate@10: 0.057496
2025-12-15 20:01:09 - GraphTrainer - INFO - ndcg@10: 0.029405
2025-12-15 20:01:09 - GraphTrainer - INFO - map@10: 0.021457
2025-12-15 20:01:09 - GraphTrainer - INFO - mrr@10: 0.022445
2025-12-15 20:01:09 - GraphTrainer - INFO - precision@20: 0.004541
2025-12-15 20:01:09 - GraphTrainer - INFO - recall@20: 0.086120
2025-12-15 20:01:09 - GraphTrainer - INFO - hit_rate@20: 0.090409
2025-12-15 20:01:09 - GraphTrainer - INFO - ndcg@20: 0.037386
2025-12-15 20:01:09 - GraphTrainer - INFO - map@20: 0.023601
2025-12-15 20:01:09 - GraphTrainer - INFO - mrr@20: 0.024696
2025-12-15 20:01:09 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:01:09 - GraphTrainer - INFO - ============================================================
2025-12-15 20:01:09 - GraphTrainer - INFO - 开始第 46/1000 轮训练
2025-12-15 20:01:09 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2396, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2053, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2206, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.1975, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2213, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2213, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2295, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2342, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2181, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2328, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2235, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2363, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2124, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2223, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2161, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2079, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2331, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2376, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2246, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2352, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2222, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2060, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2234, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2332, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2189, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2292, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2416, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2006, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2237, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2217, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2293, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2025, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2296, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2102, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2086, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2353, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2135, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2429, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2314, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2275, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2131, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2478, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2160, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2092, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2315, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2140, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2253, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2204, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2405, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2381, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2312, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2157, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2341, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2324, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2220, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2269, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2275, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2491, device='cuda:0', grad_fn=<AddBackward0>)
The 45 training average loss: 0.22440281510353088
2025-12-15 20:01:16 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:01:16 - GraphTrainer - INFO -   precision@5: 0.006984
2025-12-15 20:01:16 - GraphTrainer - INFO -   recall@5: 0.033260
2025-12-15 20:01:16 - GraphTrainer - INFO -   hit_rate@5: 0.034919
2025-12-15 20:01:16 - GraphTrainer - INFO -   ndcg@5: 0.022324
2025-12-15 20:01:16 - GraphTrainer - INFO -   map@5: 0.018480
2025-12-15 20:01:16 - GraphTrainer - INFO -   mrr@5: 0.019305
2025-12-15 20:01:16 - GraphTrainer - INFO -   precision@10: 0.005714
2025-12-15 20:01:16 - GraphTrainer - INFO -   recall@10: 0.054129
2025-12-15 20:01:16 - GraphTrainer - INFO -   hit_rate@10: 0.057033
2025-12-15 20:01:16 - GraphTrainer - INFO -   ndcg@10: 0.029042
2025-12-15 20:01:16 - GraphTrainer - INFO -   map@10: 0.021151
2025-12-15 20:01:16 - GraphTrainer - INFO -   mrr@10: 0.022140
2025-12-15 20:01:16 - GraphTrainer - INFO -   precision@20: 0.004582
2025-12-15 20:01:16 - GraphTrainer - INFO -   recall@20: 0.086722
2025-12-15 20:01:16 - GraphTrainer - INFO -   hit_rate@20: 0.091180
2025-12-15 20:01:16 - GraphTrainer - INFO -   ndcg@20: 0.037306
2025-12-15 20:01:16 - GraphTrainer - INFO -   map@20: 0.023359
2025-12-15 20:01:16 - GraphTrainer - INFO -   mrr@20: 0.024452
2025-12-15 20:01:16 - GraphTrainer - INFO - 第 46 轮训练完成
2025-12-15 20:01:16 - GraphTrainer - INFO - train_loss: 0.225919
2025-12-15 20:01:16 - GraphTrainer - INFO - precision@5: 0.006984
2025-12-15 20:01:16 - GraphTrainer - INFO - recall@5: 0.033260
2025-12-15 20:01:16 - GraphTrainer - INFO - hit_rate@5: 0.034919
2025-12-15 20:01:16 - GraphTrainer - INFO - ndcg@5: 0.022324
2025-12-15 20:01:16 - GraphTrainer - INFO - map@5: 0.018480
2025-12-15 20:01:16 - GraphTrainer - INFO - mrr@5: 0.019305
2025-12-15 20:01:16 - GraphTrainer - INFO - precision@10: 0.005714
2025-12-15 20:01:16 - GraphTrainer - INFO - recall@10: 0.054129
2025-12-15 20:01:16 - GraphTrainer - INFO - hit_rate@10: 0.057033
2025-12-15 20:01:16 - GraphTrainer - INFO - ndcg@10: 0.029042
2025-12-15 20:01:16 - GraphTrainer - INFO - map@10: 0.021151
2025-12-15 20:01:16 - GraphTrainer - INFO - mrr@10: 0.022140
2025-12-15 20:01:16 - GraphTrainer - INFO - precision@20: 0.004582
2025-12-15 20:01:16 - GraphTrainer - INFO - recall@20: 0.086722
2025-12-15 20:01:16 - GraphTrainer - INFO - hit_rate@20: 0.091180
2025-12-15 20:01:16 - GraphTrainer - INFO - ndcg@20: 0.037306
2025-12-15 20:01:16 - GraphTrainer - INFO - map@20: 0.023359
2025-12-15 20:01:16 - GraphTrainer - INFO - mrr@20: 0.024452
2025-12-15 20:01:16 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:01:16 - GraphTrainer - INFO - ============================================================
2025-12-15 20:01:16 - GraphTrainer - INFO - 开始第 47/1000 轮训练
2025-12-15 20:01:16 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2419, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2159, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2291, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2233, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2299, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2349, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2393, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2182, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2265, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2491, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2088, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2183, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2186, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2140, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2369, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2309, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2163, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2232, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2175, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2145, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2290, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2335, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2385, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2300, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2176, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2236, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2146, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2222, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2366, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2321, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2086, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2168, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2285, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2327, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2089, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2012, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2123, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2466, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2176, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2228, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2492, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2289, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2309, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2288, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2413, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2314, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2288, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2373, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2181, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2198, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2338, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2354, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2118, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2123, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2357, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2198, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2313, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2284, device='cuda:0', grad_fn=<AddBackward0>)
The 46 training average loss: 0.22591921738509474
2025-12-15 20:01:24 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:01:24 - GraphTrainer - INFO -   precision@5: 0.007118
2025-12-15 20:01:24 - GraphTrainer - INFO -   recall@5: 0.033991
2025-12-15 20:01:24 - GraphTrainer - INFO -   hit_rate@5: 0.035588
2025-12-15 20:01:24 - GraphTrainer - INFO -   ndcg@5: 0.022589
2025-12-15 20:01:24 - GraphTrainer - INFO -   map@5: 0.018561
2025-12-15 20:01:24 - GraphTrainer - INFO -   mrr@5: 0.019480
2025-12-15 20:01:24 - GraphTrainer - INFO -   precision@10: 0.005570
2025-12-15 20:01:24 - GraphTrainer - INFO -   recall@10: 0.052894
2025-12-15 20:01:24 - GraphTrainer - INFO -   hit_rate@10: 0.055644
2025-12-15 20:01:24 - GraphTrainer - INFO -   ndcg@10: 0.028721
2025-12-15 20:01:24 - GraphTrainer - INFO -   map@10: 0.021028
2025-12-15 20:01:24 - GraphTrainer - INFO -   mrr@10: 0.022097
2025-12-15 20:01:24 - GraphTrainer - INFO -   precision@20: 0.004526
2025-12-15 20:01:24 - GraphTrainer - INFO -   recall@20: 0.085731
2025-12-15 20:01:24 - GraphTrainer - INFO -   hit_rate@20: 0.089997
2025-12-15 20:01:24 - GraphTrainer - INFO -   ndcg@20: 0.037063
2025-12-15 20:01:24 - GraphTrainer - INFO -   map@20: 0.023267
2025-12-15 20:01:24 - GraphTrainer - INFO -   mrr@20: 0.024430
2025-12-15 20:01:24 - GraphTrainer - INFO - 第 47 轮训练完成
2025-12-15 20:01:24 - GraphTrainer - INFO - train_loss: 0.225011
2025-12-15 20:01:24 - GraphTrainer - INFO - precision@5: 0.007118
2025-12-15 20:01:24 - GraphTrainer - INFO - recall@5: 0.033991
2025-12-15 20:01:24 - GraphTrainer - INFO - hit_rate@5: 0.035588
2025-12-15 20:01:24 - GraphTrainer - INFO - ndcg@5: 0.022589
2025-12-15 20:01:24 - GraphTrainer - INFO - map@5: 0.018561
2025-12-15 20:01:24 - GraphTrainer - INFO - mrr@5: 0.019480
2025-12-15 20:01:24 - GraphTrainer - INFO - precision@10: 0.005570
2025-12-15 20:01:24 - GraphTrainer - INFO - recall@10: 0.052894
2025-12-15 20:01:24 - GraphTrainer - INFO - hit_rate@10: 0.055644
2025-12-15 20:01:24 - GraphTrainer - INFO - ndcg@10: 0.028721
2025-12-15 20:01:24 - GraphTrainer - INFO - map@10: 0.021028
2025-12-15 20:01:24 - GraphTrainer - INFO - mrr@10: 0.022097
2025-12-15 20:01:24 - GraphTrainer - INFO - precision@20: 0.004526
2025-12-15 20:01:24 - GraphTrainer - INFO - recall@20: 0.085731
2025-12-15 20:01:24 - GraphTrainer - INFO - hit_rate@20: 0.089997
2025-12-15 20:01:24 - GraphTrainer - INFO - ndcg@20: 0.037063
2025-12-15 20:01:24 - GraphTrainer - INFO - map@20: 0.023267
2025-12-15 20:01:24 - GraphTrainer - INFO - mrr@20: 0.024430
2025-12-15 20:01:24 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:01:24 - GraphTrainer - INFO - ============================================================
2025-12-15 20:01:24 - GraphTrainer - INFO - 开始第 48/1000 轮训练
2025-12-15 20:01:24 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2184, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2335, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2312, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2176, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2076, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2268, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2261, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2045, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2180, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2237, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2019, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2254, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2430, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2478, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2238, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2306, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2185, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2204, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2011, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2317, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2295, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2314, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2314, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2320, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2525, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2293, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2280, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2265, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2088, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2435, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2140, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2354, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2234, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2688, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2136, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2128, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2145, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2489, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2174, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2084, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1977, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2362, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2146, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2178, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2343, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2353, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2283, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2501, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2224, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2292, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2235, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2106, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2344, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2281, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2127, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2169, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2311, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2056, device='cuda:0', grad_fn=<AddBackward0>)
The 47 training average loss: 0.22501144840799528
2025-12-15 20:01:32 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:01:32 - GraphTrainer - INFO -   precision@5: 0.007138
2025-12-15 20:01:32 - GraphTrainer - INFO -   recall@5: 0.033984
2025-12-15 20:01:32 - GraphTrainer - INFO -   hit_rate@5: 0.035639
2025-12-15 20:01:32 - GraphTrainer - INFO -   ndcg@5: 0.023017
2025-12-15 20:01:32 - GraphTrainer - INFO -   map@5: 0.019150
2025-12-15 20:01:32 - GraphTrainer - INFO -   mrr@5: 0.020020
2025-12-15 20:01:32 - GraphTrainer - INFO -   precision@10: 0.005775
2025-12-15 20:01:32 - GraphTrainer - INFO -   recall@10: 0.054676
2025-12-15 20:01:32 - GraphTrainer - INFO -   hit_rate@10: 0.057650
2025-12-15 20:01:32 - GraphTrainer - INFO -   ndcg@10: 0.029717
2025-12-15 20:01:32 - GraphTrainer - INFO -   map@10: 0.021836
2025-12-15 20:01:32 - GraphTrainer - INFO -   mrr@10: 0.022874
2025-12-15 20:01:32 - GraphTrainer - INFO -   precision@20: 0.004598
2025-12-15 20:01:32 - GraphTrainer - INFO -   recall@20: 0.087055
2025-12-15 20:01:32 - GraphTrainer - INFO -   hit_rate@20: 0.091437
2025-12-15 20:01:32 - GraphTrainer - INFO -   ndcg@20: 0.037933
2025-12-15 20:01:32 - GraphTrainer - INFO -   map@20: 0.024039
2025-12-15 20:01:32 - GraphTrainer - INFO -   mrr@20: 0.025165
2025-12-15 20:01:32 - GraphTrainer - INFO - 第 48 轮训练完成
2025-12-15 20:01:32 - GraphTrainer - INFO - train_loss: 0.225055
2025-12-15 20:01:32 - GraphTrainer - INFO - precision@5: 0.007138
2025-12-15 20:01:32 - GraphTrainer - INFO - recall@5: 0.033984
2025-12-15 20:01:32 - GraphTrainer - INFO - hit_rate@5: 0.035639
2025-12-15 20:01:32 - GraphTrainer - INFO - ndcg@5: 0.023017
2025-12-15 20:01:32 - GraphTrainer - INFO - map@5: 0.019150
2025-12-15 20:01:32 - GraphTrainer - INFO - mrr@5: 0.020020
2025-12-15 20:01:32 - GraphTrainer - INFO - precision@10: 0.005775
2025-12-15 20:01:32 - GraphTrainer - INFO - recall@10: 0.054676
2025-12-15 20:01:32 - GraphTrainer - INFO - hit_rate@10: 0.057650
2025-12-15 20:01:32 - GraphTrainer - INFO - ndcg@10: 0.029717
2025-12-15 20:01:32 - GraphTrainer - INFO - map@10: 0.021836
2025-12-15 20:01:32 - GraphTrainer - INFO - mrr@10: 0.022874
2025-12-15 20:01:32 - GraphTrainer - INFO - precision@20: 0.004598
2025-12-15 20:01:32 - GraphTrainer - INFO - recall@20: 0.087055
2025-12-15 20:01:32 - GraphTrainer - INFO - hit_rate@20: 0.091437
2025-12-15 20:01:32 - GraphTrainer - INFO - ndcg@20: 0.037933
2025-12-15 20:01:32 - GraphTrainer - INFO - map@20: 0.024039
2025-12-15 20:01:32 - GraphTrainer - INFO - mrr@20: 0.025165
2025-12-15 20:01:32 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:01:32 - GraphTrainer - INFO - ============================================================
2025-12-15 20:01:32 - GraphTrainer - INFO - 开始第 49/1000 轮训练
2025-12-15 20:01:32 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2275, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2261, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2385, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.1982, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2359, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2169, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.1945, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2293, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2271, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2270, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2257, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2300, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2435, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2299, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2124, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2152, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2184, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2332, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2256, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2242, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2285, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2333, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2308, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2216, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2199, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2194, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2369, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2254, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2283, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2316, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2307, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2094, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2379, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2217, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2187, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2382, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2358, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2031, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2193, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2290, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2230, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2216, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2168, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2234, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2244, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2563, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2139, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2041, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2186, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2161, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2356, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2028, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2490, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2311, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2250, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2389, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2300, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2243, device='cuda:0', grad_fn=<AddBackward0>)
The 48 training average loss: 0.22505505999614453
2025-12-15 20:01:40 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:01:40 - GraphTrainer - INFO -   precision@5: 0.007087
2025-12-15 20:01:40 - GraphTrainer - INFO -   recall@5: 0.033760
2025-12-15 20:01:40 - GraphTrainer - INFO -   hit_rate@5: 0.035433
2025-12-15 20:01:40 - GraphTrainer - INFO -   ndcg@5: 0.022347
2025-12-15 20:01:40 - GraphTrainer - INFO -   map@5: 0.018326
2025-12-15 20:01:40 - GraphTrainer - INFO -   mrr@5: 0.019177
2025-12-15 20:01:40 - GraphTrainer - INFO -   precision@10: 0.005739
2025-12-15 20:01:40 - GraphTrainer - INFO -   recall@10: 0.054479
2025-12-15 20:01:40 - GraphTrainer - INFO -   hit_rate@10: 0.057341
2025-12-15 20:01:40 - GraphTrainer - INFO -   ndcg@10: 0.029072
2025-12-15 20:01:40 - GraphTrainer - INFO -   map@10: 0.021038
2025-12-15 20:01:40 - GraphTrainer - INFO -   mrr@10: 0.022048
2025-12-15 20:01:40 - GraphTrainer - INFO -   precision@20: 0.004580
2025-12-15 20:01:40 - GraphTrainer - INFO -   recall@20: 0.086642
2025-12-15 20:01:40 - GraphTrainer - INFO -   hit_rate@20: 0.091026
2025-12-15 20:01:40 - GraphTrainer - INFO -   ndcg@20: 0.037260
2025-12-15 20:01:40 - GraphTrainer - INFO -   map@20: 0.023241
2025-12-15 20:01:40 - GraphTrainer - INFO -   mrr@20: 0.024346
2025-12-15 20:01:40 - GraphTrainer - INFO - 第 49 轮训练完成
2025-12-15 20:01:40 - GraphTrainer - INFO - train_loss: 0.225647
2025-12-15 20:01:40 - GraphTrainer - INFO - precision@5: 0.007087
2025-12-15 20:01:40 - GraphTrainer - INFO - recall@5: 0.033760
2025-12-15 20:01:40 - GraphTrainer - INFO - hit_rate@5: 0.035433
2025-12-15 20:01:40 - GraphTrainer - INFO - ndcg@5: 0.022347
2025-12-15 20:01:40 - GraphTrainer - INFO - map@5: 0.018326
2025-12-15 20:01:40 - GraphTrainer - INFO - mrr@5: 0.019177
2025-12-15 20:01:40 - GraphTrainer - INFO - precision@10: 0.005739
2025-12-15 20:01:40 - GraphTrainer - INFO - recall@10: 0.054479
2025-12-15 20:01:40 - GraphTrainer - INFO - hit_rate@10: 0.057341
2025-12-15 20:01:40 - GraphTrainer - INFO - ndcg@10: 0.029072
2025-12-15 20:01:40 - GraphTrainer - INFO - map@10: 0.021038
2025-12-15 20:01:40 - GraphTrainer - INFO - mrr@10: 0.022048
2025-12-15 20:01:40 - GraphTrainer - INFO - precision@20: 0.004580
2025-12-15 20:01:40 - GraphTrainer - INFO - recall@20: 0.086642
2025-12-15 20:01:40 - GraphTrainer - INFO - hit_rate@20: 0.091026
2025-12-15 20:01:40 - GraphTrainer - INFO - ndcg@20: 0.037260
2025-12-15 20:01:40 - GraphTrainer - INFO - map@20: 0.023241
2025-12-15 20:01:40 - GraphTrainer - INFO - mrr@20: 0.024346
2025-12-15 20:01:40 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:01:40 - GraphTrainer - INFO - ============================================================
2025-12-15 20:01:40 - GraphTrainer - INFO - 开始第 50/1000 轮训练
2025-12-15 20:01:40 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2269, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2206, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2013, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2375, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2177, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2266, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2256, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2145, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2215, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2354, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2255, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2175, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2321, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2212, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2493, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2397, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2236, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2054, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2149, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2584, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2234, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2253, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2300, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2124, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2362, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2242, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2371, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2307, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2411, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2279, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2223, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2137, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2289, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2210, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2252, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2215, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2259, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2349, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.1952, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2207, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2296, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2266, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2291, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2065, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2262, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2154, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2394, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2320, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2255, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2367, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2299, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2366, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2194, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2146, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2158, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2427, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2101, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2385, device='cuda:0', grad_fn=<AddBackward0>)
The 49 training average loss: 0.22564661759754706
2025-12-15 20:01:48 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:01:48 - GraphTrainer - INFO -   precision@5: 0.006922
2025-12-15 20:01:48 - GraphTrainer - INFO -   recall@5: 0.032887
2025-12-15 20:01:48 - GraphTrainer - INFO -   hit_rate@5: 0.034559
2025-12-15 20:01:48 - GraphTrainer - INFO -   ndcg@5: 0.022195
2025-12-15 20:01:48 - GraphTrainer - INFO -   map@5: 0.018403
2025-12-15 20:01:48 - GraphTrainer - INFO -   mrr@5: 0.019237
2025-12-15 20:01:48 - GraphTrainer - INFO -   precision@10: 0.005806
2025-12-15 20:01:48 - GraphTrainer - INFO -   recall@10: 0.055108
2025-12-15 20:01:48 - GraphTrainer - INFO -   hit_rate@10: 0.057958
2025-12-15 20:01:48 - GraphTrainer - INFO -   ndcg@10: 0.029389
2025-12-15 20:01:48 - GraphTrainer - INFO -   map@10: 0.021302
2025-12-15 20:01:48 - GraphTrainer - INFO -   mrr@10: 0.022294
2025-12-15 20:01:48 - GraphTrainer - INFO -   precision@20: 0.004600
2025-12-15 20:01:48 - GraphTrainer - INFO -   recall@20: 0.087175
2025-12-15 20:01:48 - GraphTrainer - INFO -   hit_rate@20: 0.091592
2025-12-15 20:01:48 - GraphTrainer - INFO -   ndcg@20: 0.037535
2025-12-15 20:01:48 - GraphTrainer - INFO -   map@20: 0.023486
2025-12-15 20:01:48 - GraphTrainer - INFO -   mrr@20: 0.024582
2025-12-15 20:01:48 - GraphTrainer - INFO - 第 50 轮训练完成
2025-12-15 20:01:48 - GraphTrainer - INFO - train_loss: 0.223519
2025-12-15 20:01:48 - GraphTrainer - INFO - precision@5: 0.006922
2025-12-15 20:01:48 - GraphTrainer - INFO - recall@5: 0.032887
2025-12-15 20:01:48 - GraphTrainer - INFO - hit_rate@5: 0.034559
2025-12-15 20:01:48 - GraphTrainer - INFO - ndcg@5: 0.022195
2025-12-15 20:01:48 - GraphTrainer - INFO - map@5: 0.018403
2025-12-15 20:01:48 - GraphTrainer - INFO - mrr@5: 0.019237
2025-12-15 20:01:48 - GraphTrainer - INFO - precision@10: 0.005806
2025-12-15 20:01:48 - GraphTrainer - INFO - recall@10: 0.055108
2025-12-15 20:01:48 - GraphTrainer - INFO - hit_rate@10: 0.057958
2025-12-15 20:01:48 - GraphTrainer - INFO - ndcg@10: 0.029389
2025-12-15 20:01:48 - GraphTrainer - INFO - map@10: 0.021302
2025-12-15 20:01:48 - GraphTrainer - INFO - mrr@10: 0.022294
2025-12-15 20:01:48 - GraphTrainer - INFO - precision@20: 0.004600
2025-12-15 20:01:48 - GraphTrainer - INFO - recall@20: 0.087175
2025-12-15 20:01:48 - GraphTrainer - INFO - hit_rate@20: 0.091592
2025-12-15 20:01:48 - GraphTrainer - INFO - ndcg@20: 0.037535
2025-12-15 20:01:48 - GraphTrainer - INFO - map@20: 0.023486
2025-12-15 20:01:48 - GraphTrainer - INFO - mrr@20: 0.024582
2025-12-15 20:01:48 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:01:48 - GraphTrainer - INFO - 检查点已保存: Epoch 50 -> ./checkpoints/checkpoint_epoch_50.pth
2025-12-15 20:01:48 - GraphTrainer - INFO - ============================================================
2025-12-15 20:01:48 - GraphTrainer - INFO - 开始第 51/1000 轮训练
2025-12-15 20:01:48 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2396, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2191, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2160, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2298, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2242, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2232, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2349, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2469, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2304, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2179, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2231, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2349, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2033, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2347, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2121, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2056, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2010, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2134, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2331, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2316, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2203, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2087, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2157, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2399, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2260, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2274, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2103, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2372, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2074, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2131, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2011, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2355, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2143, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2124, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2385, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2347, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2267, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2395, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2230, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2153, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2150, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2388, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2264, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2247, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2031, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2179, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2362, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2225, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2405, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2267, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2303, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2195, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2267, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2138, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2424, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2238, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2143, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2200, device='cuda:0', grad_fn=<AddBackward0>)
The 50 training average loss: 0.2235187209885696
2025-12-15 20:01:56 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:01:56 - GraphTrainer - INFO -   precision@5: 0.007025
2025-12-15 20:01:56 - GraphTrainer - INFO -   recall@5: 0.033480
2025-12-15 20:01:56 - GraphTrainer - INFO -   hit_rate@5: 0.035073
2025-12-15 20:01:56 - GraphTrainer - INFO -   ndcg@5: 0.022366
2025-12-15 20:01:56 - GraphTrainer - INFO -   map@5: 0.018438
2025-12-15 20:01:56 - GraphTrainer - INFO -   mrr@5: 0.019314
2025-12-15 20:01:56 - GraphTrainer - INFO -   precision@10: 0.005719
2025-12-15 20:01:56 - GraphTrainer - INFO -   recall@10: 0.054187
2025-12-15 20:01:56 - GraphTrainer - INFO -   hit_rate@10: 0.057084
2025-12-15 20:01:56 - GraphTrainer - INFO -   ndcg@10: 0.029099
2025-12-15 20:01:56 - GraphTrainer - INFO -   map@10: 0.021158
2025-12-15 20:01:56 - GraphTrainer - INFO -   mrr@10: 0.022204
2025-12-15 20:01:56 - GraphTrainer - INFO -   precision@20: 0.004616
2025-12-15 20:01:56 - GraphTrainer - INFO -   recall@20: 0.087574
2025-12-15 20:01:56 - GraphTrainer - INFO -   hit_rate@20: 0.091900
2025-12-15 20:01:56 - GraphTrainer - INFO -   ndcg@20: 0.037533
2025-12-15 20:01:56 - GraphTrainer - INFO -   map@20: 0.023403
2025-12-15 20:01:56 - GraphTrainer - INFO -   mrr@20: 0.024536
2025-12-15 20:01:56 - GraphTrainer - INFO - 第 51 轮训练完成
2025-12-15 20:01:56 - GraphTrainer - INFO - train_loss: 0.222594
2025-12-15 20:01:56 - GraphTrainer - INFO - precision@5: 0.007025
2025-12-15 20:01:56 - GraphTrainer - INFO - recall@5: 0.033480
2025-12-15 20:01:56 - GraphTrainer - INFO - hit_rate@5: 0.035073
2025-12-15 20:01:56 - GraphTrainer - INFO - ndcg@5: 0.022366
2025-12-15 20:01:56 - GraphTrainer - INFO - map@5: 0.018438
2025-12-15 20:01:56 - GraphTrainer - INFO - mrr@5: 0.019314
2025-12-15 20:01:56 - GraphTrainer - INFO - precision@10: 0.005719
2025-12-15 20:01:56 - GraphTrainer - INFO - recall@10: 0.054187
2025-12-15 20:01:56 - GraphTrainer - INFO - hit_rate@10: 0.057084
2025-12-15 20:01:56 - GraphTrainer - INFO - ndcg@10: 0.029099
2025-12-15 20:01:56 - GraphTrainer - INFO - map@10: 0.021158
2025-12-15 20:01:56 - GraphTrainer - INFO - mrr@10: 0.022204
2025-12-15 20:01:56 - GraphTrainer - INFO - precision@20: 0.004616
2025-12-15 20:01:56 - GraphTrainer - INFO - recall@20: 0.087574
2025-12-15 20:01:56 - GraphTrainer - INFO - hit_rate@20: 0.091900
2025-12-15 20:01:56 - GraphTrainer - INFO - ndcg@20: 0.037533
2025-12-15 20:01:56 - GraphTrainer - INFO - map@20: 0.023403
2025-12-15 20:01:56 - GraphTrainer - INFO - mrr@20: 0.024536
2025-12-15 20:01:56 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:01:56 - GraphTrainer - INFO - ============================================================
2025-12-15 20:01:56 - GraphTrainer - INFO - 开始第 52/1000 轮训练
2025-12-15 20:01:56 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2140, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2223, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2418, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2202, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2228, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2274, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2169, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2328, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1988, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2323, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2281, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2342, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2400, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2257, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2265, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2386, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2467, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2336, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.1984, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2218, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2194, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2067, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2323, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2238, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2212, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2317, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2164, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2208, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2373, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2293, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2091, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2181, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2200, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2149, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2063, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2144, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2290, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2150, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2190, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2241, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2443, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2268, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2234, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2190, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2014, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2333, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2167, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2183, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2210, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2217, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2210, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2182, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2139, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2193, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2251, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2219, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2047, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2288, device='cuda:0', grad_fn=<AddBackward0>)
The 51 training average loss: 0.22259415300755664
2025-12-15 20:02:04 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:02:04 - GraphTrainer - INFO -   precision@5: 0.006850
2025-12-15 20:02:04 - GraphTrainer - INFO -   recall@5: 0.032534
2025-12-15 20:02:04 - GraphTrainer - INFO -   hit_rate@5: 0.034250
2025-12-15 20:02:04 - GraphTrainer - INFO -   ndcg@5: 0.021995
2025-12-15 20:02:04 - GraphTrainer - INFO -   map@5: 0.018241
2025-12-15 20:02:04 - GraphTrainer - INFO -   mrr@5: 0.019159
2025-12-15 20:02:04 - GraphTrainer - INFO -   precision@10: 0.005719
2025-12-15 20:02:04 - GraphTrainer - INFO -   recall@10: 0.054277
2025-12-15 20:02:04 - GraphTrainer - INFO -   hit_rate@10: 0.057084
2025-12-15 20:02:04 - GraphTrainer - INFO -   ndcg@10: 0.029075
2025-12-15 20:02:04 - GraphTrainer - INFO -   map@10: 0.021120
2025-12-15 20:02:04 - GraphTrainer - INFO -   mrr@10: 0.022180
2025-12-15 20:02:04 - GraphTrainer - INFO -   precision@20: 0.004667
2025-12-15 20:02:04 - GraphTrainer - INFO -   recall@20: 0.088733
2025-12-15 20:02:04 - GraphTrainer - INFO -   hit_rate@20: 0.093032
2025-12-15 20:02:04 - GraphTrainer - INFO -   ndcg@20: 0.037815
2025-12-15 20:02:04 - GraphTrainer - INFO -   map@20: 0.023468
2025-12-15 20:02:04 - GraphTrainer - INFO -   mrr@20: 0.024620
2025-12-15 20:02:04 - GraphTrainer - INFO - 第 52 轮训练完成
2025-12-15 20:02:04 - GraphTrainer - INFO - train_loss: 0.221856
2025-12-15 20:02:04 - GraphTrainer - INFO - precision@5: 0.006850
2025-12-15 20:02:04 - GraphTrainer - INFO - recall@5: 0.032534
2025-12-15 20:02:04 - GraphTrainer - INFO - hit_rate@5: 0.034250
2025-12-15 20:02:04 - GraphTrainer - INFO - ndcg@5: 0.021995
2025-12-15 20:02:04 - GraphTrainer - INFO - map@5: 0.018241
2025-12-15 20:02:04 - GraphTrainer - INFO - mrr@5: 0.019159
2025-12-15 20:02:04 - GraphTrainer - INFO - precision@10: 0.005719
2025-12-15 20:02:04 - GraphTrainer - INFO - recall@10: 0.054277
2025-12-15 20:02:04 - GraphTrainer - INFO - hit_rate@10: 0.057084
2025-12-15 20:02:04 - GraphTrainer - INFO - ndcg@10: 0.029075
2025-12-15 20:02:04 - GraphTrainer - INFO - map@10: 0.021120
2025-12-15 20:02:04 - GraphTrainer - INFO - mrr@10: 0.022180
2025-12-15 20:02:04 - GraphTrainer - INFO - precision@20: 0.004667
2025-12-15 20:02:04 - GraphTrainer - INFO - recall@20: 0.088733
2025-12-15 20:02:04 - GraphTrainer - INFO - hit_rate@20: 0.093032
2025-12-15 20:02:04 - GraphTrainer - INFO - ndcg@20: 0.037815
2025-12-15 20:02:04 - GraphTrainer - INFO - map@20: 0.023468
2025-12-15 20:02:04 - GraphTrainer - INFO - mrr@20: 0.024620
2025-12-15 20:02:04 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:02:04 - GraphTrainer - INFO - ============================================================
2025-12-15 20:02:04 - GraphTrainer - INFO - 开始第 53/1000 轮训练
2025-12-15 20:02:04 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1888, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2176, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2214, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2111, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2186, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2092, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2171, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2190, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2248, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2204, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2231, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2484, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2277, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2253, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2118, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2207, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2235, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2353, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2041, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2040, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2458, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1998, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2245, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2027, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2205, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2141, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2390, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2337, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2117, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2497, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2100, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2369, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2159, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2309, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2359, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2304, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2088, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2001, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2138, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2192, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2115, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2245, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2412, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2157, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2253, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2240, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2160, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2081, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2329, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2174, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2262, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2059, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2475, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2444, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2291, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2264, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2232, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2330, device='cuda:0', grad_fn=<AddBackward0>)
The 52 training average loss: 0.22185557695298358
2025-12-15 20:02:12 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:02:12 - GraphTrainer - INFO -   precision@5: 0.007004
2025-12-15 20:02:12 - GraphTrainer - INFO -   recall@5: 0.033381
2025-12-15 20:02:12 - GraphTrainer - INFO -   hit_rate@5: 0.035022
2025-12-15 20:02:12 - GraphTrainer - INFO -   ndcg@5: 0.022279
2025-12-15 20:02:12 - GraphTrainer - INFO -   map@5: 0.018354
2025-12-15 20:02:12 - GraphTrainer - INFO -   mrr@5: 0.019239
2025-12-15 20:02:12 - GraphTrainer - INFO -   precision@10: 0.005739
2025-12-15 20:02:12 - GraphTrainer - INFO -   recall@10: 0.054463
2025-12-15 20:02:12 - GraphTrainer - INFO -   hit_rate@10: 0.057341
2025-12-15 20:02:12 - GraphTrainer - INFO -   ndcg@10: 0.029117
2025-12-15 20:02:12 - GraphTrainer - INFO -   map@10: 0.021109
2025-12-15 20:02:12 - GraphTrainer - INFO -   mrr@10: 0.022155
2025-12-15 20:02:12 - GraphTrainer - INFO -   precision@20: 0.004654
2025-12-15 20:02:12 - GraphTrainer - INFO -   recall@20: 0.088316
2025-12-15 20:02:12 - GraphTrainer - INFO -   hit_rate@20: 0.092723
2025-12-15 20:02:12 - GraphTrainer - INFO -   ndcg@20: 0.037713
2025-12-15 20:02:12 - GraphTrainer - INFO -   map@20: 0.023414
2025-12-15 20:02:12 - GraphTrainer - INFO -   mrr@20: 0.024563
2025-12-15 20:02:12 - GraphTrainer - INFO - 第 53 轮训练完成
2025-12-15 20:02:12 - GraphTrainer - INFO - train_loss: 0.218519
2025-12-15 20:02:12 - GraphTrainer - INFO - precision@5: 0.007004
2025-12-15 20:02:12 - GraphTrainer - INFO - recall@5: 0.033381
2025-12-15 20:02:12 - GraphTrainer - INFO - hit_rate@5: 0.035022
2025-12-15 20:02:12 - GraphTrainer - INFO - ndcg@5: 0.022279
2025-12-15 20:02:12 - GraphTrainer - INFO - map@5: 0.018354
2025-12-15 20:02:12 - GraphTrainer - INFO - mrr@5: 0.019239
2025-12-15 20:02:12 - GraphTrainer - INFO - precision@10: 0.005739
2025-12-15 20:02:12 - GraphTrainer - INFO - recall@10: 0.054463
2025-12-15 20:02:12 - GraphTrainer - INFO - hit_rate@10: 0.057341
2025-12-15 20:02:12 - GraphTrainer - INFO - ndcg@10: 0.029117
2025-12-15 20:02:12 - GraphTrainer - INFO - map@10: 0.021109
2025-12-15 20:02:12 - GraphTrainer - INFO - mrr@10: 0.022155
2025-12-15 20:02:12 - GraphTrainer - INFO - precision@20: 0.004654
2025-12-15 20:02:12 - GraphTrainer - INFO - recall@20: 0.088316
2025-12-15 20:02:12 - GraphTrainer - INFO - hit_rate@20: 0.092723
2025-12-15 20:02:12 - GraphTrainer - INFO - ndcg@20: 0.037713
2025-12-15 20:02:12 - GraphTrainer - INFO - map@20: 0.023414
2025-12-15 20:02:12 - GraphTrainer - INFO - mrr@20: 0.024563
2025-12-15 20:02:12 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:02:12 - GraphTrainer - INFO - ============================================================
2025-12-15 20:02:12 - GraphTrainer - INFO - 开始第 54/1000 轮训练
2025-12-15 20:02:12 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2194, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2316, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2236, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2113, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1984, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2179, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2204, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2045, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2128, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2050, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2232, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2242, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2198, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2349, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2215, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2194, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2138, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1960, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2052, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2144, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2014, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2071, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2241, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2182, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2131, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2176, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2169, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2287, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2138, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2188, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2244, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2167, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2136, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2025, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1978, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2347, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2192, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2331, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2153, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2578, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2156, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2322, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2306, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2265, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2428, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2010, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2266, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2174, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2443, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2186, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2031, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2230, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2208, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2108, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2219, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2214, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2071, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2182, device='cuda:0', grad_fn=<AddBackward0>)
The 53 training average loss: 0.2185190101635867
2025-12-15 20:02:20 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:02:20 - GraphTrainer - INFO -   precision@5: 0.007169
2025-12-15 20:02:20 - GraphTrainer - INFO -   recall@5: 0.034096
2025-12-15 20:02:20 - GraphTrainer - INFO -   hit_rate@5: 0.035793
2025-12-15 20:02:20 - GraphTrainer - INFO -   ndcg@5: 0.022453
2025-12-15 20:02:20 - GraphTrainer - INFO -   map@5: 0.018359
2025-12-15 20:02:20 - GraphTrainer - INFO -   mrr@5: 0.019205
2025-12-15 20:02:20 - GraphTrainer - INFO -   precision@10: 0.005714
2025-12-15 20:02:20 - GraphTrainer - INFO -   recall@10: 0.054090
2025-12-15 20:02:20 - GraphTrainer - INFO -   hit_rate@10: 0.057084
2025-12-15 20:02:20 - GraphTrainer - INFO -   ndcg@10: 0.028926
2025-12-15 20:02:20 - GraphTrainer - INFO -   map@10: 0.020954
2025-12-15 20:02:20 - GraphTrainer - INFO -   mrr@10: 0.021970
2025-12-15 20:02:20 - GraphTrainer - INFO -   precision@20: 0.004605
2025-12-15 20:02:20 - GraphTrainer - INFO -   recall@20: 0.087260
2025-12-15 20:02:20 - GraphTrainer - INFO -   hit_rate@20: 0.091695
2025-12-15 20:02:20 - GraphTrainer - INFO -   ndcg@20: 0.037369
2025-12-15 20:02:20 - GraphTrainer - INFO -   map@20: 0.023234
2025-12-15 20:02:20 - GraphTrainer - INFO -   mrr@20: 0.024344
2025-12-15 20:02:20 - GraphTrainer - INFO - 第 54 轮训练完成
2025-12-15 20:02:20 - GraphTrainer - INFO - train_loss: 0.221312
2025-12-15 20:02:20 - GraphTrainer - INFO - precision@5: 0.007169
2025-12-15 20:02:20 - GraphTrainer - INFO - recall@5: 0.034096
2025-12-15 20:02:20 - GraphTrainer - INFO - hit_rate@5: 0.035793
2025-12-15 20:02:20 - GraphTrainer - INFO - ndcg@5: 0.022453
2025-12-15 20:02:20 - GraphTrainer - INFO - map@5: 0.018359
2025-12-15 20:02:20 - GraphTrainer - INFO - mrr@5: 0.019205
2025-12-15 20:02:20 - GraphTrainer - INFO - precision@10: 0.005714
2025-12-15 20:02:20 - GraphTrainer - INFO - recall@10: 0.054090
2025-12-15 20:02:20 - GraphTrainer - INFO - hit_rate@10: 0.057084
2025-12-15 20:02:20 - GraphTrainer - INFO - ndcg@10: 0.028926
2025-12-15 20:02:20 - GraphTrainer - INFO - map@10: 0.020954
2025-12-15 20:02:20 - GraphTrainer - INFO - mrr@10: 0.021970
2025-12-15 20:02:20 - GraphTrainer - INFO - precision@20: 0.004605
2025-12-15 20:02:20 - GraphTrainer - INFO - recall@20: 0.087260
2025-12-15 20:02:20 - GraphTrainer - INFO - hit_rate@20: 0.091695
2025-12-15 20:02:20 - GraphTrainer - INFO - ndcg@20: 0.037369
2025-12-15 20:02:20 - GraphTrainer - INFO - map@20: 0.023234
2025-12-15 20:02:20 - GraphTrainer - INFO - mrr@20: 0.024344
2025-12-15 20:02:20 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:02:20 - GraphTrainer - INFO - ============================================================
2025-12-15 20:02:20 - GraphTrainer - INFO - 开始第 55/1000 轮训练
2025-12-15 20:02:20 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2318, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2186, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2109, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2194, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2131, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2327, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2231, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2196, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2145, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2307, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2169, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2180, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2356, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2351, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2359, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2077, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2325, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2447, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2085, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2283, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2208, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2262, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2307, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2227, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2212, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2236, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2044, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2131, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2358, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2128, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2261, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2273, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2192, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2193, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2032, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2354, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2226, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2188, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2206, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2159, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2201, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2126, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2055, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2096, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2231, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2281, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2151, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2275, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2392, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2340, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2177, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2175, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.1936, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2354, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1964, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2134, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2278, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2221, device='cuda:0', grad_fn=<AddBackward0>)
The 54 training average loss: 0.22131231607034288
2025-12-15 20:02:28 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:02:28 - GraphTrainer - INFO -   precision@5: 0.007097
2025-12-15 20:02:28 - GraphTrainer - INFO -   recall@5: 0.033800
2025-12-15 20:02:28 - GraphTrainer - INFO -   hit_rate@5: 0.035433
2025-12-15 20:02:28 - GraphTrainer - INFO -   ndcg@5: 0.022545
2025-12-15 20:02:28 - GraphTrainer - INFO -   map@5: 0.018583
2025-12-15 20:02:28 - GraphTrainer - INFO -   mrr@5: 0.019418
2025-12-15 20:02:28 - GraphTrainer - INFO -   precision@10: 0.005811
2025-12-15 20:02:28 - GraphTrainer - INFO -   recall@10: 0.055057
2025-12-15 20:02:28 - GraphTrainer - INFO -   hit_rate@10: 0.058061
2025-12-15 20:02:28 - GraphTrainer - INFO -   ndcg@10: 0.029421
2025-12-15 20:02:28 - GraphTrainer - INFO -   map@10: 0.021334
2025-12-15 20:02:28 - GraphTrainer - INFO -   mrr@10: 0.022353
2025-12-15 20:02:28 - GraphTrainer - INFO -   precision@20: 0.004670
2025-12-15 20:02:28 - GraphTrainer - INFO -   recall@20: 0.088583
2025-12-15 20:02:28 - GraphTrainer - INFO -   hit_rate@20: 0.092877
2025-12-15 20:02:28 - GraphTrainer - INFO -   ndcg@20: 0.037953
2025-12-15 20:02:28 - GraphTrainer - INFO -   map@20: 0.023642
2025-12-15 20:02:28 - GraphTrainer - INFO -   mrr@20: 0.024738
2025-12-15 20:02:28 - GraphTrainer - INFO - 第 55 轮训练完成
2025-12-15 20:02:28 - GraphTrainer - INFO - train_loss: 0.213942
2025-12-15 20:02:28 - GraphTrainer - INFO - precision@5: 0.007097
2025-12-15 20:02:28 - GraphTrainer - INFO - recall@5: 0.033800
2025-12-15 20:02:28 - GraphTrainer - INFO - hit_rate@5: 0.035433
2025-12-15 20:02:28 - GraphTrainer - INFO - ndcg@5: 0.022545
2025-12-15 20:02:28 - GraphTrainer - INFO - map@5: 0.018583
2025-12-15 20:02:28 - GraphTrainer - INFO - mrr@5: 0.019418
2025-12-15 20:02:28 - GraphTrainer - INFO - precision@10: 0.005811
2025-12-15 20:02:28 - GraphTrainer - INFO - recall@10: 0.055057
2025-12-15 20:02:28 - GraphTrainer - INFO - hit_rate@10: 0.058061
2025-12-15 20:02:28 - GraphTrainer - INFO - ndcg@10: 0.029421
2025-12-15 20:02:28 - GraphTrainer - INFO - map@10: 0.021334
2025-12-15 20:02:28 - GraphTrainer - INFO - mrr@10: 0.022353
2025-12-15 20:02:28 - GraphTrainer - INFO - precision@20: 0.004670
2025-12-15 20:02:28 - GraphTrainer - INFO - recall@20: 0.088583
2025-12-15 20:02:28 - GraphTrainer - INFO - hit_rate@20: 0.092877
2025-12-15 20:02:28 - GraphTrainer - INFO - ndcg@20: 0.037953
2025-12-15 20:02:28 - GraphTrainer - INFO - map@20: 0.023642
2025-12-15 20:02:28 - GraphTrainer - INFO - mrr@20: 0.024738
2025-12-15 20:02:28 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:02:28 - GraphTrainer - INFO - ============================================================
2025-12-15 20:02:28 - GraphTrainer - INFO - 开始第 56/1000 轮训练
2025-12-15 20:02:28 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2203, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2208, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2222, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2107, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1991, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2141, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2168, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2324, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2129, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2188, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2200, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.1963, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2136, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2005, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2337, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2169, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1962, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2301, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2189, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2095, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2425, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2035, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2149, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.1963, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.1855, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2089, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2220, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2004, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2130, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2199, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2092, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.1855, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2127, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2200, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2152, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2144, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2191, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.1972, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2118, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2047, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2124, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2113, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2204, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2108, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2328, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2126, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2137, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2326, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2218, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2335, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2146, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2314, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2108, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2104, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1953, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2144, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2120, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2173, device='cuda:0', grad_fn=<AddBackward0>)
The 55 training average loss: 0.2139415954207552
2025-12-15 20:02:36 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:02:36 - GraphTrainer - INFO -   precision@5: 0.007220
2025-12-15 20:02:36 - GraphTrainer - INFO -   recall@5: 0.034249
2025-12-15 20:02:36 - GraphTrainer - INFO -   hit_rate@5: 0.036050
2025-12-15 20:02:36 - GraphTrainer - INFO -   ndcg@5: 0.022676
2025-12-15 20:02:36 - GraphTrainer - INFO -   map@5: 0.018607
2025-12-15 20:02:36 - GraphTrainer - INFO -   mrr@5: 0.019507
2025-12-15 20:02:36 - GraphTrainer - INFO -   precision@10: 0.005868
2025-12-15 20:02:36 - GraphTrainer - INFO -   recall@10: 0.055600
2025-12-15 20:02:36 - GraphTrainer - INFO -   hit_rate@10: 0.058627
2025-12-15 20:02:36 - GraphTrainer - INFO -   ndcg@10: 0.029568
2025-12-15 20:02:36 - GraphTrainer - INFO -   map@10: 0.021370
2025-12-15 20:02:36 - GraphTrainer - INFO -   mrr@10: 0.022431
2025-12-15 20:02:36 - GraphTrainer - INFO -   precision@20: 0.004641
2025-12-15 20:02:36 - GraphTrainer - INFO -   recall@20: 0.087969
2025-12-15 20:02:36 - GraphTrainer - INFO -   hit_rate@20: 0.092260
2025-12-15 20:02:36 - GraphTrainer - INFO -   ndcg@20: 0.037797
2025-12-15 20:02:36 - GraphTrainer - INFO -   map@20: 0.023585
2025-12-15 20:02:36 - GraphTrainer - INFO -   mrr@20: 0.024728
2025-12-15 20:02:36 - GraphTrainer - INFO - 第 56 轮训练完成
2025-12-15 20:02:36 - GraphTrainer - INFO - train_loss: 0.214437
2025-12-15 20:02:36 - GraphTrainer - INFO - precision@5: 0.007220
2025-12-15 20:02:36 - GraphTrainer - INFO - recall@5: 0.034249
2025-12-15 20:02:36 - GraphTrainer - INFO - hit_rate@5: 0.036050
2025-12-15 20:02:36 - GraphTrainer - INFO - ndcg@5: 0.022676
2025-12-15 20:02:36 - GraphTrainer - INFO - map@5: 0.018607
2025-12-15 20:02:36 - GraphTrainer - INFO - mrr@5: 0.019507
2025-12-15 20:02:36 - GraphTrainer - INFO - precision@10: 0.005868
2025-12-15 20:02:36 - GraphTrainer - INFO - recall@10: 0.055600
2025-12-15 20:02:36 - GraphTrainer - INFO - hit_rate@10: 0.058627
2025-12-15 20:02:36 - GraphTrainer - INFO - ndcg@10: 0.029568
2025-12-15 20:02:36 - GraphTrainer - INFO - map@10: 0.021370
2025-12-15 20:02:36 - GraphTrainer - INFO - mrr@10: 0.022431
2025-12-15 20:02:36 - GraphTrainer - INFO - precision@20: 0.004641
2025-12-15 20:02:36 - GraphTrainer - INFO - recall@20: 0.087969
2025-12-15 20:02:36 - GraphTrainer - INFO - hit_rate@20: 0.092260
2025-12-15 20:02:36 - GraphTrainer - INFO - ndcg@20: 0.037797
2025-12-15 20:02:36 - GraphTrainer - INFO - map@20: 0.023585
2025-12-15 20:02:36 - GraphTrainer - INFO - mrr@20: 0.024728
2025-12-15 20:02:36 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:02:36 - GraphTrainer - INFO - ============================================================
2025-12-15 20:02:36 - GraphTrainer - INFO - 开始第 57/1000 轮训练
2025-12-15 20:02:36 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2321, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2161, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2065, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2072, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2110, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2228, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.1948, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2402, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2206, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.1984, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2347, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2052, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2084, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2226, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2090, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2128, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2137, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1905, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2092, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2195, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2054, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1996, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2216, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2063, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2054, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.1802, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.1988, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2216, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2188, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2086, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2226, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2228, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2363, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2220, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2043, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2172, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2238, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2060, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2171, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2031, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2340, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.1992, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2268, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2047, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2100, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2161, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2112, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2236, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2239, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2223, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2244, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2236, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2098, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2283, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2242, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2207, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2078, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2098, device='cuda:0', grad_fn=<AddBackward0>)
The 56 training average loss: 0.21443719982073225
2025-12-15 20:02:44 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:02:44 - GraphTrainer - INFO -   precision@5: 0.007107
2025-12-15 20:02:44 - GraphTrainer - INFO -   recall@5: 0.033819
2025-12-15 20:02:44 - GraphTrainer - INFO -   hit_rate@5: 0.035485
2025-12-15 20:02:44 - GraphTrainer - INFO -   ndcg@5: 0.022719
2025-12-15 20:02:44 - GraphTrainer - INFO -   map@5: 0.018819
2025-12-15 20:02:44 - GraphTrainer - INFO -   mrr@5: 0.019664
2025-12-15 20:02:44 - GraphTrainer - INFO -   precision@10: 0.005842
2025-12-15 20:02:44 - GraphTrainer - INFO -   recall@10: 0.055383
2025-12-15 20:02:44 - GraphTrainer - INFO -   hit_rate@10: 0.058370
2025-12-15 20:02:44 - GraphTrainer - INFO -   ndcg@10: 0.029726
2025-12-15 20:02:44 - GraphTrainer - INFO -   map@10: 0.021646
2025-12-15 20:02:44 - GraphTrainer - INFO -   mrr@10: 0.022673
2025-12-15 20:02:44 - GraphTrainer - INFO -   precision@20: 0.004626
2025-12-15 20:02:44 - GraphTrainer - INFO -   recall@20: 0.087412
2025-12-15 20:02:44 - GraphTrainer - INFO -   hit_rate@20: 0.091952
2025-12-15 20:02:44 - GraphTrainer - INFO -   ndcg@20: 0.037910
2025-12-15 20:02:44 - GraphTrainer - INFO -   map@20: 0.023862
2025-12-15 20:02:44 - GraphTrainer - INFO -   mrr@20: 0.024988
2025-12-15 20:02:44 - GraphTrainer - INFO - 第 57 轮训练完成
2025-12-15 20:02:44 - GraphTrainer - INFO - train_loss: 0.210869
2025-12-15 20:02:44 - GraphTrainer - INFO - precision@5: 0.007107
2025-12-15 20:02:44 - GraphTrainer - INFO - recall@5: 0.033819
2025-12-15 20:02:44 - GraphTrainer - INFO - hit_rate@5: 0.035485
2025-12-15 20:02:44 - GraphTrainer - INFO - ndcg@5: 0.022719
2025-12-15 20:02:44 - GraphTrainer - INFO - map@5: 0.018819
2025-12-15 20:02:44 - GraphTrainer - INFO - mrr@5: 0.019664
2025-12-15 20:02:44 - GraphTrainer - INFO - precision@10: 0.005842
2025-12-15 20:02:44 - GraphTrainer - INFO - recall@10: 0.055383
2025-12-15 20:02:44 - GraphTrainer - INFO - hit_rate@10: 0.058370
2025-12-15 20:02:44 - GraphTrainer - INFO - ndcg@10: 0.029726
2025-12-15 20:02:44 - GraphTrainer - INFO - map@10: 0.021646
2025-12-15 20:02:44 - GraphTrainer - INFO - mrr@10: 0.022673
2025-12-15 20:02:44 - GraphTrainer - INFO - precision@20: 0.004626
2025-12-15 20:02:44 - GraphTrainer - INFO - recall@20: 0.087412
2025-12-15 20:02:44 - GraphTrainer - INFO - hit_rate@20: 0.091952
2025-12-15 20:02:44 - GraphTrainer - INFO - ndcg@20: 0.037910
2025-12-15 20:02:44 - GraphTrainer - INFO - map@20: 0.023862
2025-12-15 20:02:44 - GraphTrainer - INFO - mrr@20: 0.024988
2025-12-15 20:02:44 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:02:44 - GraphTrainer - INFO - ============================================================
2025-12-15 20:02:44 - GraphTrainer - INFO - 开始第 58/1000 轮训练
2025-12-15 20:02:44 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1893, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2184, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.1955, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2067, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2212, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2177, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2129, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2188, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2226, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2122, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1966, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.1850, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1934, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2340, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.1947, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2106, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2296, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2237, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2096, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2202, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2031, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1979, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2084, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.1994, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2156, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2161, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2264, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2282, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2042, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2117, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2262, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2100, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2213, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2182, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2111, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2033, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2110, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.1978, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2212, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.1978, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2282, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2005, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2104, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.1894, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.1967, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2084, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2045, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2198, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2040, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.1901, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2092, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.1944, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2133, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2242, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2330, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2184, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2283, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2157, device='cuda:0', grad_fn=<AddBackward0>)
The 57 training average loss: 0.21086879999473176
2025-12-15 20:02:52 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:02:52 - GraphTrainer - INFO -   precision@5: 0.006974
2025-12-15 20:02:52 - GraphTrainer - INFO -   recall@5: 0.033263
2025-12-15 20:02:52 - GraphTrainer - INFO -   hit_rate@5: 0.034868
2025-12-15 20:02:52 - GraphTrainer - INFO -   ndcg@5: 0.022340
2025-12-15 20:02:52 - GraphTrainer - INFO -   map@5: 0.018502
2025-12-15 20:02:52 - GraphTrainer - INFO -   mrr@5: 0.019333
2025-12-15 20:02:52 - GraphTrainer - INFO -   precision@10: 0.005930
2025-12-15 20:02:52 - GraphTrainer - INFO -   recall@10: 0.056327
2025-12-15 20:02:52 - GraphTrainer - INFO -   hit_rate@10: 0.059244
2025-12-15 20:02:52 - GraphTrainer - INFO -   ndcg@10: 0.029804
2025-12-15 20:02:52 - GraphTrainer - INFO -   map@10: 0.021500
2025-12-15 20:02:52 - GraphTrainer - INFO -   mrr@10: 0.022506
2025-12-15 20:02:52 - GraphTrainer - INFO -   precision@20: 0.004695
2025-12-15 20:02:52 - GraphTrainer - INFO -   recall@20: 0.089013
2025-12-15 20:02:52 - GraphTrainer - INFO -   hit_rate@20: 0.093289
2025-12-15 20:02:52 - GraphTrainer - INFO -   ndcg@20: 0.038123
2025-12-15 20:02:52 - GraphTrainer - INFO -   map@20: 0.023744
2025-12-15 20:02:52 - GraphTrainer - INFO -   mrr@20: 0.024835
2025-12-15 20:02:52 - GraphTrainer - INFO - 第 58 轮训练完成
2025-12-15 20:02:52 - GraphTrainer - INFO - train_loss: 0.211978
2025-12-15 20:02:52 - GraphTrainer - INFO - precision@5: 0.006974
2025-12-15 20:02:52 - GraphTrainer - INFO - recall@5: 0.033263
2025-12-15 20:02:52 - GraphTrainer - INFO - hit_rate@5: 0.034868
2025-12-15 20:02:52 - GraphTrainer - INFO - ndcg@5: 0.022340
2025-12-15 20:02:52 - GraphTrainer - INFO - map@5: 0.018502
2025-12-15 20:02:52 - GraphTrainer - INFO - mrr@5: 0.019333
2025-12-15 20:02:52 - GraphTrainer - INFO - precision@10: 0.005930
2025-12-15 20:02:52 - GraphTrainer - INFO - recall@10: 0.056327
2025-12-15 20:02:52 - GraphTrainer - INFO - hit_rate@10: 0.059244
2025-12-15 20:02:52 - GraphTrainer - INFO - ndcg@10: 0.029804
2025-12-15 20:02:52 - GraphTrainer - INFO - map@10: 0.021500
2025-12-15 20:02:52 - GraphTrainer - INFO - mrr@10: 0.022506
2025-12-15 20:02:52 - GraphTrainer - INFO - precision@20: 0.004695
2025-12-15 20:02:52 - GraphTrainer - INFO - recall@20: 0.089013
2025-12-15 20:02:52 - GraphTrainer - INFO - hit_rate@20: 0.093289
2025-12-15 20:02:52 - GraphTrainer - INFO - ndcg@20: 0.038123
2025-12-15 20:02:52 - GraphTrainer - INFO - map@20: 0.023744
2025-12-15 20:02:52 - GraphTrainer - INFO - mrr@20: 0.024835
2025-12-15 20:02:52 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:02:52 - GraphTrainer - INFO - ============================================================
2025-12-15 20:02:52 - GraphTrainer - INFO - 开始第 59/1000 轮训练
2025-12-15 20:02:52 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1946, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2089, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2049, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2035, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1994, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2280, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2170, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2105, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2345, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.1999, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2171, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2150, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2191, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2169, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2015, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2188, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2268, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2068, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2135, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2122, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2296, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1989, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2303, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.1996, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2484, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2022, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2056, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2038, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2169, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2119, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2042, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2031, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2034, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2493, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2137, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2121, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2274, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2049, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2050, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.1848, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2054, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2236, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2359, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2041, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2111, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2232, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2049, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2076, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1981, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2075, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.1962, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.1918, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2340, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2124, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2163, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.1963, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2002, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2219, device='cuda:0', grad_fn=<AddBackward0>)
The 58 training average loss: 0.21197784537899084
2025-12-15 20:02:59 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:02:59 - GraphTrainer - INFO -   precision@5: 0.007138
2025-12-15 20:02:59 - GraphTrainer - INFO -   recall@5: 0.034041
2025-12-15 20:02:59 - GraphTrainer - INFO -   hit_rate@5: 0.035639
2025-12-15 20:02:59 - GraphTrainer - INFO -   ndcg@5: 0.022631
2025-12-15 20:02:59 - GraphTrainer - INFO -   map@5: 0.018633
2025-12-15 20:02:59 - GraphTrainer - INFO -   mrr@5: 0.019437
2025-12-15 20:02:59 - GraphTrainer - INFO -   precision@10: 0.005837
2025-12-15 20:02:59 - GraphTrainer - INFO -   recall@10: 0.055426
2025-12-15 20:02:59 - GraphTrainer - INFO -   hit_rate@10: 0.058318
2025-12-15 20:02:59 - GraphTrainer - INFO -   ndcg@10: 0.029606
2025-12-15 20:02:59 - GraphTrainer - INFO -   map@10: 0.021464
2025-12-15 20:02:59 - GraphTrainer - INFO -   mrr@10: 0.022441
2025-12-15 20:02:59 - GraphTrainer - INFO -   precision@20: 0.004734
2025-12-15 20:02:59 - GraphTrainer - INFO -   recall@20: 0.089716
2025-12-15 20:02:59 - GraphTrainer - INFO -   hit_rate@20: 0.094112
2025-12-15 20:02:59 - GraphTrainer - INFO -   ndcg@20: 0.038324
2025-12-15 20:02:59 - GraphTrainer - INFO -   map@20: 0.023809
2025-12-15 20:02:59 - GraphTrainer - INFO -   mrr@20: 0.024877
2025-12-15 20:02:59 - GraphTrainer - INFO - 第 59 轮训练完成
2025-12-15 20:02:59 - GraphTrainer - INFO - train_loss: 0.208108
2025-12-15 20:02:59 - GraphTrainer - INFO - precision@5: 0.007138
2025-12-15 20:02:59 - GraphTrainer - INFO - recall@5: 0.034041
2025-12-15 20:02:59 - GraphTrainer - INFO - hit_rate@5: 0.035639
2025-12-15 20:02:59 - GraphTrainer - INFO - ndcg@5: 0.022631
2025-12-15 20:02:59 - GraphTrainer - INFO - map@5: 0.018633
2025-12-15 20:02:59 - GraphTrainer - INFO - mrr@5: 0.019437
2025-12-15 20:02:59 - GraphTrainer - INFO - precision@10: 0.005837
2025-12-15 20:02:59 - GraphTrainer - INFO - recall@10: 0.055426
2025-12-15 20:02:59 - GraphTrainer - INFO - hit_rate@10: 0.058318
2025-12-15 20:02:59 - GraphTrainer - INFO - ndcg@10: 0.029606
2025-12-15 20:02:59 - GraphTrainer - INFO - map@10: 0.021464
2025-12-15 20:02:59 - GraphTrainer - INFO - mrr@10: 0.022441
2025-12-15 20:02:59 - GraphTrainer - INFO - precision@20: 0.004734
2025-12-15 20:02:59 - GraphTrainer - INFO - recall@20: 0.089716
2025-12-15 20:02:59 - GraphTrainer - INFO - hit_rate@20: 0.094112
2025-12-15 20:02:59 - GraphTrainer - INFO - ndcg@20: 0.038324
2025-12-15 20:02:59 - GraphTrainer - INFO - map@20: 0.023809
2025-12-15 20:02:59 - GraphTrainer - INFO - mrr@20: 0.024877
2025-12-15 20:02:59 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:02:59 - GraphTrainer - INFO - ============================================================
2025-12-15 20:02:59 - GraphTrainer - INFO - 开始第 60/1000 轮训练
2025-12-15 20:02:59 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2122, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2074, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2173, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2315, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2101, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.1917, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2029, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2184, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2133, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2097, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2080, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2085, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2330, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.1986, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2032, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2054, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1913, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1991, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2151, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2268, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1965, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1901, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2022, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2075, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2040, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2050, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.1900, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.1852, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.1905, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2091, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2193, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.1968, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2147, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2077, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2242, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2129, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2172, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.1995, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2061, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2031, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1922, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2042, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2049, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2229, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2045, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2150, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2164, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2145, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2027, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2042, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2303, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2143, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2165, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1974, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2137, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.1989, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2081, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2246, device='cuda:0', grad_fn=<AddBackward0>)
The 59 training average loss: 0.20810783063543253
2025-12-15 20:03:07 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:03:07 - GraphTrainer - INFO -   precision@5: 0.007241
2025-12-15 20:03:07 - GraphTrainer - INFO -   recall@5: 0.034452
2025-12-15 20:03:07 - GraphTrainer - INFO -   hit_rate@5: 0.036153
2025-12-15 20:03:07 - GraphTrainer - INFO -   ndcg@5: 0.023014
2025-12-15 20:03:07 - GraphTrainer - INFO -   map@5: 0.018988
2025-12-15 20:03:07 - GraphTrainer - INFO -   mrr@5: 0.019862
2025-12-15 20:03:07 - GraphTrainer - INFO -   precision@10: 0.005930
2025-12-15 20:03:07 - GraphTrainer - INFO -   recall@10: 0.056323
2025-12-15 20:03:07 - GraphTrainer - INFO -   hit_rate@10: 0.059193
2025-12-15 20:03:07 - GraphTrainer - INFO -   ndcg@10: 0.030110
2025-12-15 20:03:07 - GraphTrainer - INFO -   map@10: 0.021857
2025-12-15 20:03:07 - GraphTrainer - INFO -   mrr@10: 0.022887
2025-12-15 20:03:07 - GraphTrainer - INFO -   precision@20: 0.004693
2025-12-15 20:03:07 - GraphTrainer - INFO -   recall@20: 0.088694
2025-12-15 20:03:07 - GraphTrainer - INFO -   hit_rate@20: 0.093237
2025-12-15 20:03:07 - GraphTrainer - INFO -   ndcg@20: 0.038339
2025-12-15 20:03:07 - GraphTrainer - INFO -   map@20: 0.024059
2025-12-15 20:03:07 - GraphTrainer - INFO -   mrr@20: 0.025190
2025-12-15 20:03:07 - GraphTrainer - INFO - 第 60 轮训练完成
2025-12-15 20:03:07 - GraphTrainer - INFO - train_loss: 0.208500
2025-12-15 20:03:07 - GraphTrainer - INFO - precision@5: 0.007241
2025-12-15 20:03:07 - GraphTrainer - INFO - recall@5: 0.034452
2025-12-15 20:03:07 - GraphTrainer - INFO - hit_rate@5: 0.036153
2025-12-15 20:03:07 - GraphTrainer - INFO - ndcg@5: 0.023014
2025-12-15 20:03:07 - GraphTrainer - INFO - map@5: 0.018988
2025-12-15 20:03:07 - GraphTrainer - INFO - mrr@5: 0.019862
2025-12-15 20:03:07 - GraphTrainer - INFO - precision@10: 0.005930
2025-12-15 20:03:07 - GraphTrainer - INFO - recall@10: 0.056323
2025-12-15 20:03:07 - GraphTrainer - INFO - hit_rate@10: 0.059193
2025-12-15 20:03:07 - GraphTrainer - INFO - ndcg@10: 0.030110
2025-12-15 20:03:07 - GraphTrainer - INFO - map@10: 0.021857
2025-12-15 20:03:07 - GraphTrainer - INFO - mrr@10: 0.022887
2025-12-15 20:03:07 - GraphTrainer - INFO - precision@20: 0.004693
2025-12-15 20:03:07 - GraphTrainer - INFO - recall@20: 0.088694
2025-12-15 20:03:07 - GraphTrainer - INFO - hit_rate@20: 0.093237
2025-12-15 20:03:07 - GraphTrainer - INFO - ndcg@20: 0.038339
2025-12-15 20:03:07 - GraphTrainer - INFO - map@20: 0.024059
2025-12-15 20:03:07 - GraphTrainer - INFO - mrr@20: 0.025190
2025-12-15 20:03:07 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:03:07 - GraphTrainer - INFO - 检查点已保存: Epoch 60 -> ./checkpoints/checkpoint_epoch_60.pth
2025-12-15 20:03:07 - GraphTrainer - INFO - ============================================================
2025-12-15 20:03:07 - GraphTrainer - INFO - 开始第 61/1000 轮训练
2025-12-15 20:03:07 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2064, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2078, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2144, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2236, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2078, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2181, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2038, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2071, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2092, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2073, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1987, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.1992, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2150, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2165, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2099, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1978, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2137, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1968, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.1982, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2179, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2089, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2256, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2050, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2100, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.1997, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.1907, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2305, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2017, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2232, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2197, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.1889, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.1883, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2152, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2254, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2008, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2019, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1951, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2217, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2361, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.1977, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1961, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2112, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.1949, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2306, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2115, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2270, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2044, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2099, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2063, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2034, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.1956, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2238, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2085, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1932, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2070, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2038, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2144, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.1959, device='cuda:0', grad_fn=<AddBackward0>)
The 60 training average loss: 0.20850018540333057
2025-12-15 20:03:15 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:03:15 - GraphTrainer - INFO -   precision@5: 0.007344
2025-12-15 20:03:15 - GraphTrainer - INFO -   recall@5: 0.034872
2025-12-15 20:03:15 - GraphTrainer - INFO -   hit_rate@5: 0.036719
2025-12-15 20:03:15 - GraphTrainer - INFO -   ndcg@5: 0.023187
2025-12-15 20:03:15 - GraphTrainer - INFO -   map@5: 0.019058
2025-12-15 20:03:15 - GraphTrainer - INFO -   mrr@5: 0.019967
2025-12-15 20:03:15 - GraphTrainer - INFO -   precision@10: 0.005930
2025-12-15 20:03:15 - GraphTrainer - INFO -   recall@10: 0.056436
2025-12-15 20:03:15 - GraphTrainer - INFO -   hit_rate@10: 0.059244
2025-12-15 20:03:15 - GraphTrainer - INFO -   ndcg@10: 0.030190
2025-12-15 20:03:15 - GraphTrainer - INFO -   map@10: 0.021905
2025-12-15 20:03:15 - GraphTrainer - INFO -   mrr@10: 0.022945
2025-12-15 20:03:15 - GraphTrainer - INFO -   precision@20: 0.004729
2025-12-15 20:03:15 - GraphTrainer - INFO -   recall@20: 0.089628
2025-12-15 20:03:15 - GraphTrainer - INFO -   hit_rate@20: 0.094060
2025-12-15 20:03:15 - GraphTrainer - INFO -   ndcg@20: 0.038618
2025-12-15 20:03:15 - GraphTrainer - INFO -   map@20: 0.024159
2025-12-15 20:03:15 - GraphTrainer - INFO -   mrr@20: 0.025298
2025-12-15 20:03:15 - GraphTrainer - INFO - 第 61 轮训练完成
2025-12-15 20:03:15 - GraphTrainer - INFO - train_loss: 0.211952
2025-12-15 20:03:15 - GraphTrainer - INFO - precision@5: 0.007344
2025-12-15 20:03:15 - GraphTrainer - INFO - recall@5: 0.034872
2025-12-15 20:03:15 - GraphTrainer - INFO - hit_rate@5: 0.036719
2025-12-15 20:03:15 - GraphTrainer - INFO - ndcg@5: 0.023187
2025-12-15 20:03:15 - GraphTrainer - INFO - map@5: 0.019058
2025-12-15 20:03:15 - GraphTrainer - INFO - mrr@5: 0.019967
2025-12-15 20:03:15 - GraphTrainer - INFO - precision@10: 0.005930
2025-12-15 20:03:15 - GraphTrainer - INFO - recall@10: 0.056436
2025-12-15 20:03:15 - GraphTrainer - INFO - hit_rate@10: 0.059244
2025-12-15 20:03:15 - GraphTrainer - INFO - ndcg@10: 0.030190
2025-12-15 20:03:15 - GraphTrainer - INFO - map@10: 0.021905
2025-12-15 20:03:15 - GraphTrainer - INFO - mrr@10: 0.022945
2025-12-15 20:03:15 - GraphTrainer - INFO - precision@20: 0.004729
2025-12-15 20:03:15 - GraphTrainer - INFO - recall@20: 0.089628
2025-12-15 20:03:15 - GraphTrainer - INFO - hit_rate@20: 0.094060
2025-12-15 20:03:15 - GraphTrainer - INFO - ndcg@20: 0.038618
2025-12-15 20:03:15 - GraphTrainer - INFO - map@20: 0.024159
2025-12-15 20:03:15 - GraphTrainer - INFO - mrr@20: 0.025298
2025-12-15 20:03:15 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:03:15 - GraphTrainer - INFO - ============================================================
2025-12-15 20:03:15 - GraphTrainer - INFO - 开始第 62/1000 轮训练
2025-12-15 20:03:15 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2115, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2159, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2066, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2110, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2194, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.1971, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2055, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2301, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2504, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2284, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2073, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2223, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1980, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2099, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.1865, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2251, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1931, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1891, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2117, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.1833, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1882, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2273, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2231, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2015, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2002, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2109, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2300, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2100, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2127, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2266, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2183, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2102, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2170, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2255, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2017, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2077, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2069, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2112, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2028, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2169, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2281, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2016, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2273, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2088, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2332, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2054, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2040, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2188, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1999, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2279, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2134, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2213, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2114, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1928, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1916, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2159, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2106, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2304, device='cuda:0', grad_fn=<AddBackward0>)
The 61 training average loss: 0.21195166249727382
2025-12-15 20:03:23 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:03:23 - GraphTrainer - INFO -   precision@5: 0.007292
2025-12-15 20:03:23 - GraphTrainer - INFO -   recall@5: 0.034728
2025-12-15 20:03:23 - GraphTrainer - INFO -   hit_rate@5: 0.036462
2025-12-15 20:03:23 - GraphTrainer - INFO -   ndcg@5: 0.023088
2025-12-15 20:03:23 - GraphTrainer - INFO -   map@5: 0.019001
2025-12-15 20:03:23 - GraphTrainer - INFO -   mrr@5: 0.019845
2025-12-15 20:03:23 - GraphTrainer - INFO -   precision@10: 0.005894
2025-12-15 20:03:23 - GraphTrainer - INFO -   recall@10: 0.055966
2025-12-15 20:03:23 - GraphTrainer - INFO -   hit_rate@10: 0.058884
2025-12-15 20:03:23 - GraphTrainer - INFO -   ndcg@10: 0.029973
2025-12-15 20:03:23 - GraphTrainer - INFO -   map@10: 0.021777
2025-12-15 20:03:23 - GraphTrainer - INFO -   mrr@10: 0.022779
2025-12-15 20:03:23 - GraphTrainer - INFO -   precision@20: 0.004711
2025-12-15 20:03:23 - GraphTrainer - INFO -   recall@20: 0.089287
2025-12-15 20:03:23 - GraphTrainer - INFO -   hit_rate@20: 0.093700
2025-12-15 20:03:23 - GraphTrainer - INFO -   ndcg@20: 0.038431
2025-12-15 20:03:23 - GraphTrainer - INFO -   map@20: 0.024044
2025-12-15 20:03:23 - GraphTrainer - INFO -   mrr@20: 0.025134
2025-12-15 20:03:23 - GraphTrainer - INFO - 第 62 轮训练完成
2025-12-15 20:03:23 - GraphTrainer - INFO - train_loss: 0.208890
2025-12-15 20:03:23 - GraphTrainer - INFO - precision@5: 0.007292
2025-12-15 20:03:23 - GraphTrainer - INFO - recall@5: 0.034728
2025-12-15 20:03:23 - GraphTrainer - INFO - hit_rate@5: 0.036462
2025-12-15 20:03:23 - GraphTrainer - INFO - ndcg@5: 0.023088
2025-12-15 20:03:23 - GraphTrainer - INFO - map@5: 0.019001
2025-12-15 20:03:23 - GraphTrainer - INFO - mrr@5: 0.019845
2025-12-15 20:03:23 - GraphTrainer - INFO - precision@10: 0.005894
2025-12-15 20:03:23 - GraphTrainer - INFO - recall@10: 0.055966
2025-12-15 20:03:23 - GraphTrainer - INFO - hit_rate@10: 0.058884
2025-12-15 20:03:23 - GraphTrainer - INFO - ndcg@10: 0.029973
2025-12-15 20:03:23 - GraphTrainer - INFO - map@10: 0.021777
2025-12-15 20:03:23 - GraphTrainer - INFO - mrr@10: 0.022779
2025-12-15 20:03:23 - GraphTrainer - INFO - precision@20: 0.004711
2025-12-15 20:03:23 - GraphTrainer - INFO - recall@20: 0.089287
2025-12-15 20:03:23 - GraphTrainer - INFO - hit_rate@20: 0.093700
2025-12-15 20:03:23 - GraphTrainer - INFO - ndcg@20: 0.038431
2025-12-15 20:03:23 - GraphTrainer - INFO - map@20: 0.024044
2025-12-15 20:03:23 - GraphTrainer - INFO - mrr@20: 0.025134
2025-12-15 20:03:23 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:03:23 - GraphTrainer - INFO - ============================================================
2025-12-15 20:03:23 - GraphTrainer - INFO - 开始第 63/1000 轮训练
2025-12-15 20:03:23 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1931, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.1917, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.1998, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.1877, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2294, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.1934, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2040, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2103, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1962, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.1969, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2236, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2235, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2262, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2113, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2199, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2252, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1982, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2170, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2021, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.1867, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2284, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2028, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2058, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2130, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2101, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2207, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.1973, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2329, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.1979, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2247, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2283, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.1929, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2022, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2006, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2041, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1952, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2069, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2229, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2021, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2088, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2155, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2184, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.1962, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2088, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2087, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2069, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2173, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.1960, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2176, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2102, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2449, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2016, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2080, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2059, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1900, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2081, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2120, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2159, device='cuda:0', grad_fn=<AddBackward0>)
The 62 training average loss: 0.20889042446325565
2025-12-15 20:03:31 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:03:31 - GraphTrainer - INFO -   precision@5: 0.007148
2025-12-15 20:03:31 - GraphTrainer - INFO -   recall@5: 0.033951
2025-12-15 20:03:31 - GraphTrainer - INFO -   hit_rate@5: 0.035742
2025-12-15 20:03:31 - GraphTrainer - INFO -   ndcg@5: 0.022738
2025-12-15 20:03:31 - GraphTrainer - INFO -   map@5: 0.018764
2025-12-15 20:03:31 - GraphTrainer - INFO -   mrr@5: 0.019675
2025-12-15 20:03:31 - GraphTrainer - INFO -   precision@10: 0.006012
2025-12-15 20:03:31 - GraphTrainer - INFO -   recall@10: 0.057116
2025-12-15 20:03:31 - GraphTrainer - INFO -   hit_rate@10: 0.060015
2025-12-15 20:03:31 - GraphTrainer - INFO -   ndcg@10: 0.030236
2025-12-15 20:03:31 - GraphTrainer - INFO -   map@10: 0.021793
2025-12-15 20:03:31 - GraphTrainer - INFO -   mrr@10: 0.022845
2025-12-15 20:03:31 - GraphTrainer - INFO -   precision@20: 0.004739
2025-12-15 20:03:31 - GraphTrainer - INFO -   recall@20: 0.089943
2025-12-15 20:03:31 - GraphTrainer - INFO -   hit_rate@20: 0.094317
2025-12-15 20:03:31 - GraphTrainer - INFO -   ndcg@20: 0.038608
2025-12-15 20:03:31 - GraphTrainer - INFO -   map@20: 0.024058
2025-12-15 20:03:31 - GraphTrainer - INFO -   mrr@20: 0.025202
2025-12-15 20:03:31 - GraphTrainer - INFO - 第 63 轮训练完成
2025-12-15 20:03:31 - GraphTrainer - INFO - train_loss: 0.208131
2025-12-15 20:03:31 - GraphTrainer - INFO - precision@5: 0.007148
2025-12-15 20:03:31 - GraphTrainer - INFO - recall@5: 0.033951
2025-12-15 20:03:31 - GraphTrainer - INFO - hit_rate@5: 0.035742
2025-12-15 20:03:31 - GraphTrainer - INFO - ndcg@5: 0.022738
2025-12-15 20:03:31 - GraphTrainer - INFO - map@5: 0.018764
2025-12-15 20:03:31 - GraphTrainer - INFO - mrr@5: 0.019675
2025-12-15 20:03:31 - GraphTrainer - INFO - precision@10: 0.006012
2025-12-15 20:03:31 - GraphTrainer - INFO - recall@10: 0.057116
2025-12-15 20:03:31 - GraphTrainer - INFO - hit_rate@10: 0.060015
2025-12-15 20:03:31 - GraphTrainer - INFO - ndcg@10: 0.030236
2025-12-15 20:03:31 - GraphTrainer - INFO - map@10: 0.021793
2025-12-15 20:03:31 - GraphTrainer - INFO - mrr@10: 0.022845
2025-12-15 20:03:31 - GraphTrainer - INFO - precision@20: 0.004739
2025-12-15 20:03:31 - GraphTrainer - INFO - recall@20: 0.089943
2025-12-15 20:03:31 - GraphTrainer - INFO - hit_rate@20: 0.094317
2025-12-15 20:03:31 - GraphTrainer - INFO - ndcg@20: 0.038608
2025-12-15 20:03:31 - GraphTrainer - INFO - map@20: 0.024058
2025-12-15 20:03:31 - GraphTrainer - INFO - mrr@20: 0.025202
2025-12-15 20:03:31 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:03:31 - GraphTrainer - INFO - ============================================================
2025-12-15 20:03:31 - GraphTrainer - INFO - 开始第 64/1000 轮训练
2025-12-15 20:03:31 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2054, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2030, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2144, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2206, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1982, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2103, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2058, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2150, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1980, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2058, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2122, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.1897, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1948, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2289, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.1970, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1979, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1984, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2196, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2122, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.1881, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1920, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2170, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2146, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2186, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2069, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2074, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2219, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.1971, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2087, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2198, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2001, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.1802, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2063, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2151, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1917, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2099, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2057, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2119, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2045, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2134, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2136, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2005, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2069, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2156, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2036, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2345, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.1984, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2427, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2077, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2144, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2059, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2099, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2044, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2093, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2095, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.1953, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2157, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2253, device='cuda:0', grad_fn=<AddBackward0>)
The 63 training average loss: 0.20813142533960013
2025-12-15 20:03:39 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:03:39 - GraphTrainer - INFO -   precision@5: 0.007303
2025-12-15 20:03:39 - GraphTrainer - INFO -   recall@5: 0.034709
2025-12-15 20:03:39 - GraphTrainer - INFO -   hit_rate@5: 0.036462
2025-12-15 20:03:39 - GraphTrainer - INFO -   ndcg@5: 0.023241
2025-12-15 20:03:39 - GraphTrainer - INFO -   map@5: 0.019210
2025-12-15 20:03:39 - GraphTrainer - INFO -   mrr@5: 0.020056
2025-12-15 20:03:39 - GraphTrainer - INFO -   precision@10: 0.006104
2025-12-15 20:03:39 - GraphTrainer - INFO -   recall@10: 0.058092
2025-12-15 20:03:39 - GraphTrainer - INFO -   hit_rate@10: 0.060993
2025-12-15 20:03:39 - GraphTrainer - INFO -   ndcg@10: 0.030764
2025-12-15 20:03:39 - GraphTrainer - INFO -   map@10: 0.022220
2025-12-15 20:03:39 - GraphTrainer - INFO -   mrr@10: 0.023226
2025-12-15 20:03:39 - GraphTrainer - INFO -   precision@20: 0.004814
2025-12-15 20:03:39 - GraphTrainer - INFO -   recall@20: 0.091265
2025-12-15 20:03:39 - GraphTrainer - INFO -   hit_rate@20: 0.095706
2025-12-15 20:03:39 - GraphTrainer - INFO -   ndcg@20: 0.039152
2025-12-15 20:03:39 - GraphTrainer - INFO -   map@20: 0.024448
2025-12-15 20:03:39 - GraphTrainer - INFO -   mrr@20: 0.025549
2025-12-15 20:03:39 - GraphTrainer - INFO - 第 64 轮训练完成
2025-12-15 20:03:39 - GraphTrainer - INFO - train_loss: 0.211375
2025-12-15 20:03:39 - GraphTrainer - INFO - precision@5: 0.007303
2025-12-15 20:03:39 - GraphTrainer - INFO - recall@5: 0.034709
2025-12-15 20:03:39 - GraphTrainer - INFO - hit_rate@5: 0.036462
2025-12-15 20:03:39 - GraphTrainer - INFO - ndcg@5: 0.023241
2025-12-15 20:03:39 - GraphTrainer - INFO - map@5: 0.019210
2025-12-15 20:03:39 - GraphTrainer - INFO - mrr@5: 0.020056
2025-12-15 20:03:39 - GraphTrainer - INFO - precision@10: 0.006104
2025-12-15 20:03:39 - GraphTrainer - INFO - recall@10: 0.058092
2025-12-15 20:03:39 - GraphTrainer - INFO - hit_rate@10: 0.060993
2025-12-15 20:03:39 - GraphTrainer - INFO - ndcg@10: 0.030764
2025-12-15 20:03:39 - GraphTrainer - INFO - map@10: 0.022220
2025-12-15 20:03:39 - GraphTrainer - INFO - mrr@10: 0.023226
2025-12-15 20:03:39 - GraphTrainer - INFO - precision@20: 0.004814
2025-12-15 20:03:39 - GraphTrainer - INFO - recall@20: 0.091265
2025-12-15 20:03:39 - GraphTrainer - INFO - hit_rate@20: 0.095706
2025-12-15 20:03:39 - GraphTrainer - INFO - ndcg@20: 0.039152
2025-12-15 20:03:39 - GraphTrainer - INFO - map@20: 0.024448
2025-12-15 20:03:39 - GraphTrainer - INFO - mrr@20: 0.025549
2025-12-15 20:03:39 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:03:39 - GraphTrainer - INFO - ============================================================
2025-12-15 20:03:39 - GraphTrainer - INFO - 开始第 65/1000 轮训练
2025-12-15 20:03:39 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2095, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2166, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2145, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.1780, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2195, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.1974, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.1947, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2080, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2199, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2139, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2120, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2221, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2215, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2138, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2426, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2084, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1942, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2372, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.1935, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2094, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1947, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2336, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2175, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2039, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.1938, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2333, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2055, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2238, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2215, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2188, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2090, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.1955, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2080, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1851, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2032, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2175, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1997, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.1978, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2079, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2212, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1943, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2169, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2085, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2036, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2135, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2297, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2154, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2295, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1825, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2318, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2343, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2153, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2128, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2108, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2200, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2143, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2058, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2029, device='cuda:0', grad_fn=<AddBackward0>)
The 64 training average loss: 0.21137453281673893
2025-12-15 20:03:47 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:03:47 - GraphTrainer - INFO -   precision@5: 0.007169
2025-12-15 20:03:47 - GraphTrainer - INFO -   recall@5: 0.034191
2025-12-15 20:03:47 - GraphTrainer - INFO -   hit_rate@5: 0.035793
2025-12-15 20:03:47 - GraphTrainer - INFO -   ndcg@5: 0.022936
2025-12-15 20:03:47 - GraphTrainer - INFO -   map@5: 0.018992
2025-12-15 20:03:47 - GraphTrainer - INFO -   mrr@5: 0.019811
2025-12-15 20:03:47 - GraphTrainer - INFO -   precision@10: 0.005966
2025-12-15 20:03:47 - GraphTrainer - INFO -   recall@10: 0.056502
2025-12-15 20:03:47 - GraphTrainer - INFO -   hit_rate@10: 0.059501
2025-12-15 20:03:47 - GraphTrainer - INFO -   ndcg@10: 0.030223
2025-12-15 20:03:47 - GraphTrainer - INFO -   map@10: 0.021950
2025-12-15 20:03:47 - GraphTrainer - INFO -   mrr@10: 0.022957
2025-12-15 20:03:47 - GraphTrainer - INFO -   precision@20: 0.004749
2025-12-15 20:03:47 - GraphTrainer - INFO -   recall@20: 0.090127
2025-12-15 20:03:47 - GraphTrainer - INFO -   hit_rate@20: 0.094472
2025-12-15 20:03:47 - GraphTrainer - INFO -   ndcg@20: 0.038760
2025-12-15 20:03:47 - GraphTrainer - INFO -   map@20: 0.024246
2025-12-15 20:03:47 - GraphTrainer - INFO -   mrr@20: 0.025340
2025-12-15 20:03:47 - GraphTrainer - INFO - 第 65 轮训练完成
2025-12-15 20:03:47 - GraphTrainer - INFO - train_loss: 0.206481
2025-12-15 20:03:47 - GraphTrainer - INFO - precision@5: 0.007169
2025-12-15 20:03:47 - GraphTrainer - INFO - recall@5: 0.034191
2025-12-15 20:03:47 - GraphTrainer - INFO - hit_rate@5: 0.035793
2025-12-15 20:03:47 - GraphTrainer - INFO - ndcg@5: 0.022936
2025-12-15 20:03:47 - GraphTrainer - INFO - map@5: 0.018992
2025-12-15 20:03:47 - GraphTrainer - INFO - mrr@5: 0.019811
2025-12-15 20:03:47 - GraphTrainer - INFO - precision@10: 0.005966
2025-12-15 20:03:47 - GraphTrainer - INFO - recall@10: 0.056502
2025-12-15 20:03:47 - GraphTrainer - INFO - hit_rate@10: 0.059501
2025-12-15 20:03:47 - GraphTrainer - INFO - ndcg@10: 0.030223
2025-12-15 20:03:47 - GraphTrainer - INFO - map@10: 0.021950
2025-12-15 20:03:47 - GraphTrainer - INFO - mrr@10: 0.022957
2025-12-15 20:03:47 - GraphTrainer - INFO - precision@20: 0.004749
2025-12-15 20:03:47 - GraphTrainer - INFO - recall@20: 0.090127
2025-12-15 20:03:47 - GraphTrainer - INFO - hit_rate@20: 0.094472
2025-12-15 20:03:47 - GraphTrainer - INFO - ndcg@20: 0.038760
2025-12-15 20:03:47 - GraphTrainer - INFO - map@20: 0.024246
2025-12-15 20:03:47 - GraphTrainer - INFO - mrr@20: 0.025340
2025-12-15 20:03:47 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:03:47 - GraphTrainer - INFO - ============================================================
2025-12-15 20:03:47 - GraphTrainer - INFO - 开始第 66/1000 轮训练
2025-12-15 20:03:47 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2035, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.1961, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2296, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2246, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2061, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2028, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2067, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.1885, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2185, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.1845, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2147, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2167, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1980, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.1998, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2089, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2046, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2010, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1972, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.1818, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2073, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2226, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1993, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2100, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2113, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.1914, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2151, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.1969, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2090, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2165, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2003, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.1969, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2161, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2144, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2174, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1998, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2062, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2067, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2102, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2127, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2097, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1821, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2016, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2130, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2195, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.1923, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2246, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.1922, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.1965, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2108, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2153, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2093, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2271, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2238, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2076, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1910, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2026, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.1949, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2181, device='cuda:0', grad_fn=<AddBackward0>)
The 65 training average loss: 0.20648103798257894
2025-12-15 20:03:55 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:03:55 - GraphTrainer - INFO -   precision@5: 0.007210
2025-12-15 20:03:55 - GraphTrainer - INFO -   recall@5: 0.034093
2025-12-15 20:03:55 - GraphTrainer - INFO -   hit_rate@5: 0.035999
2025-12-15 20:03:55 - GraphTrainer - INFO -   ndcg@5: 0.023012
2025-12-15 20:03:55 - GraphTrainer - INFO -   map@5: 0.019071
2025-12-15 20:03:55 - GraphTrainer - INFO -   mrr@5: 0.020020
2025-12-15 20:03:55 - GraphTrainer - INFO -   precision@10: 0.005955
2025-12-15 20:03:55 - GraphTrainer - INFO -   recall@10: 0.056590
2025-12-15 20:03:55 - GraphTrainer - INFO -   hit_rate@10: 0.059450
2025-12-15 20:03:55 - GraphTrainer - INFO -   ndcg@10: 0.030278
2025-12-15 20:03:55 - GraphTrainer - INFO -   map@10: 0.022005
2025-12-15 20:03:55 - GraphTrainer - INFO -   mrr@10: 0.023076
2025-12-15 20:03:55 - GraphTrainer - INFO -   precision@20: 0.004744
2025-12-15 20:03:55 - GraphTrainer - INFO -   recall@20: 0.090160
2025-12-15 20:03:55 - GraphTrainer - INFO -   hit_rate@20: 0.094420
2025-12-15 20:03:55 - GraphTrainer - INFO -   ndcg@20: 0.038779
2025-12-15 20:03:55 - GraphTrainer - INFO -   map@20: 0.024277
2025-12-15 20:03:55 - GraphTrainer - INFO -   mrr@20: 0.025444
2025-12-15 20:03:55 - GraphTrainer - INFO - 第 66 轮训练完成
2025-12-15 20:03:55 - GraphTrainer - INFO - train_loss: 0.208895
2025-12-15 20:03:55 - GraphTrainer - INFO - precision@5: 0.007210
2025-12-15 20:03:55 - GraphTrainer - INFO - recall@5: 0.034093
2025-12-15 20:03:55 - GraphTrainer - INFO - hit_rate@5: 0.035999
2025-12-15 20:03:55 - GraphTrainer - INFO - ndcg@5: 0.023012
2025-12-15 20:03:55 - GraphTrainer - INFO - map@5: 0.019071
2025-12-15 20:03:55 - GraphTrainer - INFO - mrr@5: 0.020020
2025-12-15 20:03:55 - GraphTrainer - INFO - precision@10: 0.005955
2025-12-15 20:03:55 - GraphTrainer - INFO - recall@10: 0.056590
2025-12-15 20:03:55 - GraphTrainer - INFO - hit_rate@10: 0.059450
2025-12-15 20:03:55 - GraphTrainer - INFO - ndcg@10: 0.030278
2025-12-15 20:03:55 - GraphTrainer - INFO - map@10: 0.022005
2025-12-15 20:03:55 - GraphTrainer - INFO - mrr@10: 0.023076
2025-12-15 20:03:55 - GraphTrainer - INFO - precision@20: 0.004744
2025-12-15 20:03:55 - GraphTrainer - INFO - recall@20: 0.090160
2025-12-15 20:03:55 - GraphTrainer - INFO - hit_rate@20: 0.094420
2025-12-15 20:03:55 - GraphTrainer - INFO - ndcg@20: 0.038779
2025-12-15 20:03:55 - GraphTrainer - INFO - map@20: 0.024277
2025-12-15 20:03:55 - GraphTrainer - INFO - mrr@20: 0.025444
2025-12-15 20:03:55 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:03:55 - GraphTrainer - INFO - ============================================================
2025-12-15 20:03:55 - GraphTrainer - INFO - 开始第 67/1000 轮训练
2025-12-15 20:03:55 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2054, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2056, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2050, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2190, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2042, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2040, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2078, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2054, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2146, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2110, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2122, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2066, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2222, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.1968, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2013, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2049, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2073, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2084, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2212, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2139, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2085, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2014, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2210, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2097, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2199, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2125, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2140, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.1974, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2124, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2033, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2086, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2104, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2175, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1935, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1990, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2048, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2174, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2173, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2135, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2045, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2188, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.1979, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2085, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2176, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2151, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.1966, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2186, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.1837, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2215, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2035, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2198, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2126, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2090, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1826, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2092, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2113, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2180, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2082, device='cuda:0', grad_fn=<AddBackward0>)
The 66 training average loss: 0.20889533799270105
2025-12-15 20:04:03 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:04:03 - GraphTrainer - INFO -   precision@5: 0.007179
2025-12-15 20:04:03 - GraphTrainer - INFO -   recall@5: 0.034084
2025-12-15 20:04:03 - GraphTrainer - INFO -   hit_rate@5: 0.035845
2025-12-15 20:04:03 - GraphTrainer - INFO -   ndcg@5: 0.022821
2025-12-15 20:04:03 - GraphTrainer - INFO -   map@5: 0.018824
2025-12-15 20:04:03 - GraphTrainer - INFO -   mrr@5: 0.019733
2025-12-15 20:04:03 - GraphTrainer - INFO -   precision@10: 0.005894
2025-12-15 20:04:03 - GraphTrainer - INFO -   recall@10: 0.056080
2025-12-15 20:04:03 - GraphTrainer - INFO -   hit_rate@10: 0.058833
2025-12-15 20:04:03 - GraphTrainer - INFO -   ndcg@10: 0.029917
2025-12-15 20:04:03 - GraphTrainer - INFO -   map@10: 0.021682
2025-12-15 20:04:03 - GraphTrainer - INFO -   mrr@10: 0.022723
2025-12-15 20:04:03 - GraphTrainer - INFO -   precision@20: 0.004708
2025-12-15 20:04:03 - GraphTrainer - INFO -   recall@20: 0.089146
2025-12-15 20:04:03 - GraphTrainer - INFO -   hit_rate@20: 0.093546
2025-12-15 20:04:03 - GraphTrainer - INFO -   ndcg@20: 0.038329
2025-12-15 20:04:03 - GraphTrainer - INFO -   map@20: 0.023936
2025-12-15 20:04:03 - GraphTrainer - INFO -   mrr@20: 0.025080
2025-12-15 20:04:03 - GraphTrainer - INFO - 第 67 轮训练完成
2025-12-15 20:04:03 - GraphTrainer - INFO - train_loss: 0.205480
2025-12-15 20:04:03 - GraphTrainer - INFO - precision@5: 0.007179
2025-12-15 20:04:03 - GraphTrainer - INFO - recall@5: 0.034084
2025-12-15 20:04:03 - GraphTrainer - INFO - hit_rate@5: 0.035845
2025-12-15 20:04:03 - GraphTrainer - INFO - ndcg@5: 0.022821
2025-12-15 20:04:03 - GraphTrainer - INFO - map@5: 0.018824
2025-12-15 20:04:03 - GraphTrainer - INFO - mrr@5: 0.019733
2025-12-15 20:04:03 - GraphTrainer - INFO - precision@10: 0.005894
2025-12-15 20:04:03 - GraphTrainer - INFO - recall@10: 0.056080
2025-12-15 20:04:03 - GraphTrainer - INFO - hit_rate@10: 0.058833
2025-12-15 20:04:03 - GraphTrainer - INFO - ndcg@10: 0.029917
2025-12-15 20:04:03 - GraphTrainer - INFO - map@10: 0.021682
2025-12-15 20:04:03 - GraphTrainer - INFO - mrr@10: 0.022723
2025-12-15 20:04:03 - GraphTrainer - INFO - precision@20: 0.004708
2025-12-15 20:04:03 - GraphTrainer - INFO - recall@20: 0.089146
2025-12-15 20:04:03 - GraphTrainer - INFO - hit_rate@20: 0.093546
2025-12-15 20:04:03 - GraphTrainer - INFO - ndcg@20: 0.038329
2025-12-15 20:04:03 - GraphTrainer - INFO - map@20: 0.023936
2025-12-15 20:04:03 - GraphTrainer - INFO - mrr@20: 0.025080
2025-12-15 20:04:03 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:04:03 - GraphTrainer - INFO - ============================================================
2025-12-15 20:04:03 - GraphTrainer - INFO - 开始第 68/1000 轮训练
2025-12-15 20:04:03 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2109, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2100, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2132, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2188, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2072, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2072, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2006, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2318, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1966, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2106, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2119, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.1994, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2172, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2083, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.1840, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1807, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2051, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1973, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2156, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2033, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2058, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1788, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.1839, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2104, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.1933, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2010, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2139, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2030, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2114, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.1958, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2108, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2059, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2096, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2154, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2007, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2054, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2158, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.1988, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.1969, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2115, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2077, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2284, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2113, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.1912, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.1926, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2079, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2193, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.1970, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2141, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.1927, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2116, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2141, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.1905, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2143, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1953, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2146, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2029, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2148, device='cuda:0', grad_fn=<AddBackward0>)
The 67 training average loss: 0.2054803941784234
2025-12-15 20:04:11 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:04:11 - GraphTrainer - INFO -   precision@5: 0.007179
2025-12-15 20:04:11 - GraphTrainer - INFO -   recall@5: 0.034053
2025-12-15 20:04:11 - GraphTrainer - INFO -   hit_rate@5: 0.035845
2025-12-15 20:04:11 - GraphTrainer - INFO -   ndcg@5: 0.022926
2025-12-15 20:04:11 - GraphTrainer - INFO -   map@5: 0.018983
2025-12-15 20:04:11 - GraphTrainer - INFO -   mrr@5: 0.019831
2025-12-15 20:04:11 - GraphTrainer - INFO -   precision@10: 0.005868
2025-12-15 20:04:11 - GraphTrainer - INFO -   recall@10: 0.055638
2025-12-15 20:04:11 - GraphTrainer - INFO -   hit_rate@10: 0.058524
2025-12-15 20:04:11 - GraphTrainer - INFO -   ndcg@10: 0.029906
2025-12-15 20:04:11 - GraphTrainer - INFO -   map@10: 0.021793
2025-12-15 20:04:11 - GraphTrainer - INFO -   mrr@10: 0.022786
2025-12-15 20:04:11 - GraphTrainer - INFO -   precision@20: 0.004649
2025-12-15 20:04:11 - GraphTrainer - INFO -   recall@20: 0.087989
2025-12-15 20:04:11 - GraphTrainer - INFO -   hit_rate@20: 0.092415
2025-12-15 20:04:11 - GraphTrainer - INFO -   ndcg@20: 0.038135
2025-12-15 20:04:11 - GraphTrainer - INFO -   map@20: 0.024004
2025-12-15 20:04:11 - GraphTrainer - INFO -   mrr@20: 0.025095
2025-12-15 20:04:11 - GraphTrainer - INFO - 第 68 轮训练完成
2025-12-15 20:04:11 - GraphTrainer - INFO - train_loss: 0.205947
2025-12-15 20:04:11 - GraphTrainer - INFO - precision@5: 0.007179
2025-12-15 20:04:11 - GraphTrainer - INFO - recall@5: 0.034053
2025-12-15 20:04:11 - GraphTrainer - INFO - hit_rate@5: 0.035845
2025-12-15 20:04:11 - GraphTrainer - INFO - ndcg@5: 0.022926
2025-12-15 20:04:11 - GraphTrainer - INFO - map@5: 0.018983
2025-12-15 20:04:11 - GraphTrainer - INFO - mrr@5: 0.019831
2025-12-15 20:04:11 - GraphTrainer - INFO - precision@10: 0.005868
2025-12-15 20:04:11 - GraphTrainer - INFO - recall@10: 0.055638
2025-12-15 20:04:11 - GraphTrainer - INFO - hit_rate@10: 0.058524
2025-12-15 20:04:11 - GraphTrainer - INFO - ndcg@10: 0.029906
2025-12-15 20:04:11 - GraphTrainer - INFO - map@10: 0.021793
2025-12-15 20:04:11 - GraphTrainer - INFO - mrr@10: 0.022786
2025-12-15 20:04:11 - GraphTrainer - INFO - precision@20: 0.004649
2025-12-15 20:04:11 - GraphTrainer - INFO - recall@20: 0.087989
2025-12-15 20:04:11 - GraphTrainer - INFO - hit_rate@20: 0.092415
2025-12-15 20:04:11 - GraphTrainer - INFO - ndcg@20: 0.038135
2025-12-15 20:04:11 - GraphTrainer - INFO - map@20: 0.024004
2025-12-15 20:04:11 - GraphTrainer - INFO - mrr@20: 0.025095
2025-12-15 20:04:11 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:04:11 - GraphTrainer - INFO - ============================================================
2025-12-15 20:04:11 - GraphTrainer - INFO - 开始第 69/1000 轮训练
2025-12-15 20:04:11 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2154, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2005, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2048, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2055, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2014, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2150, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2018, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2321, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2012, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.1996, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2068, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2153, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2012, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.1827, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2075, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1945, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1998, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1958, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2208, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2085, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1928, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1915, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2015, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.1979, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2118, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2243, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2060, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2084, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2037, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2011, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2078, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2074, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2207, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1981, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2278, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2147, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2042, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2126, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.1837, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2052, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1929, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.1882, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2125, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2069, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2043, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2091, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2069, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2006, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2096, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2129, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2005, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.1805, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2193, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2419, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2084, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2082, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2240, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.1867, device='cuda:0', grad_fn=<AddBackward0>)
The 68 training average loss: 0.2059470754245232
2025-12-15 20:04:19 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:04:19 - GraphTrainer - INFO -   precision@5: 0.007056
2025-12-15 20:04:19 - GraphTrainer - INFO -   recall@5: 0.033496
2025-12-15 20:04:19 - GraphTrainer - INFO -   hit_rate@5: 0.035228
2025-12-15 20:04:19 - GraphTrainer - INFO -   ndcg@5: 0.022739
2025-12-15 20:04:19 - GraphTrainer - INFO -   map@5: 0.018917
2025-12-15 20:04:19 - GraphTrainer - INFO -   mrr@5: 0.019781
2025-12-15 20:04:19 - GraphTrainer - INFO -   precision@10: 0.005919
2025-12-15 20:04:19 - GraphTrainer - INFO -   recall@10: 0.056336
2025-12-15 20:04:19 - GraphTrainer - INFO -   hit_rate@10: 0.058987
2025-12-15 20:04:19 - GraphTrainer - INFO -   ndcg@10: 0.030121
2025-12-15 20:04:19 - GraphTrainer - INFO -   map@10: 0.021898
2025-12-15 20:04:19 - GraphTrainer - INFO -   mrr@10: 0.022891
2025-12-15 20:04:19 - GraphTrainer - INFO -   precision@20: 0.004770
2025-12-15 20:04:19 - GraphTrainer - INFO -   recall@20: 0.090436
2025-12-15 20:04:19 - GraphTrainer - INFO -   hit_rate@20: 0.094832
2025-12-15 20:04:19 - GraphTrainer - INFO -   ndcg@20: 0.038782
2025-12-15 20:04:19 - GraphTrainer - INFO -   map@20: 0.024214
2025-12-15 20:04:19 - GraphTrainer - INFO -   mrr@20: 0.025325
2025-12-15 20:04:19 - GraphTrainer - INFO - 第 69 轮训练完成
2025-12-15 20:04:19 - GraphTrainer - INFO - train_loss: 0.206182
2025-12-15 20:04:19 - GraphTrainer - INFO - precision@5: 0.007056
2025-12-15 20:04:19 - GraphTrainer - INFO - recall@5: 0.033496
2025-12-15 20:04:19 - GraphTrainer - INFO - hit_rate@5: 0.035228
2025-12-15 20:04:19 - GraphTrainer - INFO - ndcg@5: 0.022739
2025-12-15 20:04:19 - GraphTrainer - INFO - map@5: 0.018917
2025-12-15 20:04:19 - GraphTrainer - INFO - mrr@5: 0.019781
2025-12-15 20:04:19 - GraphTrainer - INFO - precision@10: 0.005919
2025-12-15 20:04:19 - GraphTrainer - INFO - recall@10: 0.056336
2025-12-15 20:04:19 - GraphTrainer - INFO - hit_rate@10: 0.058987
2025-12-15 20:04:19 - GraphTrainer - INFO - ndcg@10: 0.030121
2025-12-15 20:04:19 - GraphTrainer - INFO - map@10: 0.021898
2025-12-15 20:04:19 - GraphTrainer - INFO - mrr@10: 0.022891
2025-12-15 20:04:19 - GraphTrainer - INFO - precision@20: 0.004770
2025-12-15 20:04:19 - GraphTrainer - INFO - recall@20: 0.090436
2025-12-15 20:04:19 - GraphTrainer - INFO - hit_rate@20: 0.094832
2025-12-15 20:04:19 - GraphTrainer - INFO - ndcg@20: 0.038782
2025-12-15 20:04:19 - GraphTrainer - INFO - map@20: 0.024214
2025-12-15 20:04:19 - GraphTrainer - INFO - mrr@20: 0.025325
2025-12-15 20:04:19 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:04:19 - GraphTrainer - INFO - ============================================================
2025-12-15 20:04:19 - GraphTrainer - INFO - 开始第 70/1000 轮训练
2025-12-15 20:04:19 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2077, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2052, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2234, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2076, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1944, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2059, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2133, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.1892, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1936, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2074, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1937, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2147, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2110, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2184, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2171, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2116, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1907, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1977, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2101, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2043, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2264, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2118, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2048, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.1923, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.1738, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.1950, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.1850, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2045, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2023, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2020, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2011, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.1973, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2190, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2153, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1826, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2100, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2039, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2225, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2023, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.1973, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1897, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2100, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.1938, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2048, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2122, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2051, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2075, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2316, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1986, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.1974, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2156, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2354, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2050, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2357, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2227, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2127, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2207, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.1937, device='cuda:0', grad_fn=<AddBackward0>)
The 69 training average loss: 0.206182311321127
2025-12-15 20:04:27 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:04:27 - GraphTrainer - INFO -   precision@5: 0.007097
2025-12-15 20:04:27 - GraphTrainer - INFO -   recall@5: 0.033844
2025-12-15 20:04:27 - GraphTrainer - INFO -   hit_rate@5: 0.035485
2025-12-15 20:04:27 - GraphTrainer - INFO -   ndcg@5: 0.022643
2025-12-15 20:04:27 - GraphTrainer - INFO -   map@5: 0.018696
2025-12-15 20:04:27 - GraphTrainer - INFO -   mrr@5: 0.019549
2025-12-15 20:04:27 - GraphTrainer - INFO -   precision@10: 0.005945
2025-12-15 20:04:27 - GraphTrainer - INFO -   recall@10: 0.056510
2025-12-15 20:04:27 - GraphTrainer - INFO -   hit_rate@10: 0.059347
2025-12-15 20:04:27 - GraphTrainer - INFO -   ndcg@10: 0.030021
2025-12-15 20:04:27 - GraphTrainer - INFO -   map@10: 0.021690
2025-12-15 20:04:27 - GraphTrainer - INFO -   mrr@10: 0.022705
2025-12-15 20:04:27 - GraphTrainer - INFO -   precision@20: 0.004721
2025-12-15 20:04:27 - GraphTrainer - INFO -   recall@20: 0.089360
2025-12-15 20:04:27 - GraphTrainer - INFO -   hit_rate@20: 0.093803
2025-12-15 20:04:27 - GraphTrainer - INFO -   ndcg@20: 0.038393
2025-12-15 20:04:27 - GraphTrainer - INFO -   map@20: 0.023943
2025-12-15 20:04:27 - GraphTrainer - INFO -   mrr@20: 0.025061
2025-12-15 20:04:27 - GraphTrainer - INFO - 第 70 轮训练完成
2025-12-15 20:04:27 - GraphTrainer - INFO - train_loss: 0.207064
2025-12-15 20:04:27 - GraphTrainer - INFO - precision@5: 0.007097
2025-12-15 20:04:27 - GraphTrainer - INFO - recall@5: 0.033844
2025-12-15 20:04:27 - GraphTrainer - INFO - hit_rate@5: 0.035485
2025-12-15 20:04:27 - GraphTrainer - INFO - ndcg@5: 0.022643
2025-12-15 20:04:27 - GraphTrainer - INFO - map@5: 0.018696
2025-12-15 20:04:27 - GraphTrainer - INFO - mrr@5: 0.019549
2025-12-15 20:04:27 - GraphTrainer - INFO - precision@10: 0.005945
2025-12-15 20:04:27 - GraphTrainer - INFO - recall@10: 0.056510
2025-12-15 20:04:27 - GraphTrainer - INFO - hit_rate@10: 0.059347
2025-12-15 20:04:27 - GraphTrainer - INFO - ndcg@10: 0.030021
2025-12-15 20:04:27 - GraphTrainer - INFO - map@10: 0.021690
2025-12-15 20:04:27 - GraphTrainer - INFO - mrr@10: 0.022705
2025-12-15 20:04:27 - GraphTrainer - INFO - precision@20: 0.004721
2025-12-15 20:04:27 - GraphTrainer - INFO - recall@20: 0.089360
2025-12-15 20:04:27 - GraphTrainer - INFO - hit_rate@20: 0.093803
2025-12-15 20:04:27 - GraphTrainer - INFO - ndcg@20: 0.038393
2025-12-15 20:04:27 - GraphTrainer - INFO - map@20: 0.023943
2025-12-15 20:04:27 - GraphTrainer - INFO - mrr@20: 0.025061
2025-12-15 20:04:27 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:04:27 - GraphTrainer - INFO - 检查点已保存: Epoch 70 -> ./checkpoints/checkpoint_epoch_70.pth
2025-12-15 20:04:27 - GraphTrainer - INFO - ============================================================
2025-12-15 20:04:27 - GraphTrainer - INFO - 开始第 71/1000 轮训练
2025-12-15 20:04:27 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2189, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.1960, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.1938, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.1986, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2056, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2167, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2152, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2204, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1892, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.1894, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1954, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2040, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2104, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2170, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2001, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2058, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2199, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2217, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2016, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.1931, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2167, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1997, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2288, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.1938, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2000, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2112, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2047, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2123, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2090, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2147, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2103, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2118, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.1986, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1875, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2055, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1900, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2194, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2040, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2065, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2075, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2092, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2261, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2070, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2150, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2145, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2009, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2098, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2096, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2031, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.1967, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2138, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.1958, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2023, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1954, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2118, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2039, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2028, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2472, device='cuda:0', grad_fn=<AddBackward0>)
The 70 training average loss: 0.20706379824671253
2025-12-15 20:04:35 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:04:35 - GraphTrainer - INFO -   precision@5: 0.006994
2025-12-15 20:04:35 - GraphTrainer - INFO -   recall@5: 0.033261
2025-12-15 20:04:35 - GraphTrainer - INFO -   hit_rate@5: 0.034919
2025-12-15 20:04:35 - GraphTrainer - INFO -   ndcg@5: 0.022442
2025-12-15 20:04:35 - GraphTrainer - INFO -   map@5: 0.018592
2025-12-15 20:04:35 - GraphTrainer - INFO -   mrr@5: 0.019479
2025-12-15 20:04:35 - GraphTrainer - INFO -   precision@10: 0.005873
2025-12-15 20:04:35 - GraphTrainer - INFO -   recall@10: 0.055828
2025-12-15 20:04:35 - GraphTrainer - INFO -   hit_rate@10: 0.058627
2025-12-15 20:04:35 - GraphTrainer - INFO -   ndcg@10: 0.029748
2025-12-15 20:04:35 - GraphTrainer - INFO -   map@10: 0.021542
2025-12-15 20:04:35 - GraphTrainer - INFO -   mrr@10: 0.022580
2025-12-15 20:04:35 - GraphTrainer - INFO -   precision@20: 0.004767
2025-12-15 20:04:35 - GraphTrainer - INFO -   recall@20: 0.090307
2025-12-15 20:04:35 - GraphTrainer - INFO -   hit_rate@20: 0.094832
2025-12-15 20:04:35 - GraphTrainer - INFO -   ndcg@20: 0.038531
2025-12-15 20:04:35 - GraphTrainer - INFO -   map@20: 0.023905
2025-12-15 20:04:35 - GraphTrainer - INFO -   mrr@20: 0.025055
2025-12-15 20:04:35 - GraphTrainer - INFO - 第 71 轮训练完成
2025-12-15 20:04:35 - GraphTrainer - INFO - train_loss: 0.207857
2025-12-15 20:04:35 - GraphTrainer - INFO - precision@5: 0.006994
2025-12-15 20:04:35 - GraphTrainer - INFO - recall@5: 0.033261
2025-12-15 20:04:35 - GraphTrainer - INFO - hit_rate@5: 0.034919
2025-12-15 20:04:35 - GraphTrainer - INFO - ndcg@5: 0.022442
2025-12-15 20:04:35 - GraphTrainer - INFO - map@5: 0.018592
2025-12-15 20:04:35 - GraphTrainer - INFO - mrr@5: 0.019479
2025-12-15 20:04:35 - GraphTrainer - INFO - precision@10: 0.005873
2025-12-15 20:04:35 - GraphTrainer - INFO - recall@10: 0.055828
2025-12-15 20:04:35 - GraphTrainer - INFO - hit_rate@10: 0.058627
2025-12-15 20:04:35 - GraphTrainer - INFO - ndcg@10: 0.029748
2025-12-15 20:04:35 - GraphTrainer - INFO - map@10: 0.021542
2025-12-15 20:04:35 - GraphTrainer - INFO - mrr@10: 0.022580
2025-12-15 20:04:35 - GraphTrainer - INFO - precision@20: 0.004767
2025-12-15 20:04:35 - GraphTrainer - INFO - recall@20: 0.090307
2025-12-15 20:04:35 - GraphTrainer - INFO - hit_rate@20: 0.094832
2025-12-15 20:04:35 - GraphTrainer - INFO - ndcg@20: 0.038531
2025-12-15 20:04:35 - GraphTrainer - INFO - map@20: 0.023905
2025-12-15 20:04:35 - GraphTrainer - INFO - mrr@20: 0.025055
2025-12-15 20:04:35 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:04:35 - GraphTrainer - INFO - ============================================================
2025-12-15 20:04:35 - GraphTrainer - INFO - 开始第 72/1000 轮训练
2025-12-15 20:04:35 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1989, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2210, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2146, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.1945, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2129, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2009, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.1923, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2097, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2253, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2081, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1937, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.1956, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1915, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2029, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2114, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2152, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2057, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2253, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.1960, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2092, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1921, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2124, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2196, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.1844, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2177, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2161, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2230, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2068, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2317, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.1950, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.1933, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2052, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2086, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1890, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2268, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2264, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2523, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.1968, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.1950, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2126, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1933, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.1936, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2020, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2061, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2305, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.1799, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2240, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2087, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2212, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2111, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2309, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.1869, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2069, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1952, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2098, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.1996, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2073, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2192, device='cuda:0', grad_fn=<AddBackward0>)
The 71 training average loss: 0.2078574215029848
2025-12-15 20:04:43 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:04:43 - GraphTrainer - INFO -   precision@5: 0.007128
2025-12-15 20:04:43 - GraphTrainer - INFO -   recall@5: 0.033757
2025-12-15 20:04:43 - GraphTrainer - INFO -   hit_rate@5: 0.035588
2025-12-15 20:04:43 - GraphTrainer - INFO -   ndcg@5: 0.022606
2025-12-15 20:04:43 - GraphTrainer - INFO -   map@5: 0.018652
2025-12-15 20:04:43 - GraphTrainer - INFO -   mrr@5: 0.019551
2025-12-15 20:04:43 - GraphTrainer - INFO -   precision@10: 0.005966
2025-12-15 20:04:43 - GraphTrainer - INFO -   recall@10: 0.056498
2025-12-15 20:04:43 - GraphTrainer - INFO -   hit_rate@10: 0.059501
2025-12-15 20:04:43 - GraphTrainer - INFO -   ndcg@10: 0.029969
2025-12-15 20:04:43 - GraphTrainer - INFO -   map@10: 0.021620
2025-12-15 20:04:43 - GraphTrainer - INFO -   mrr@10: 0.022671
2025-12-15 20:04:43 - GraphTrainer - INFO -   precision@20: 0.004760
2025-12-15 20:04:43 - GraphTrainer - INFO -   recall@20: 0.090260
2025-12-15 20:04:43 - GraphTrainer - INFO -   hit_rate@20: 0.094677
2025-12-15 20:04:43 - GraphTrainer - INFO -   ndcg@20: 0.038512
2025-12-15 20:04:43 - GraphTrainer - INFO -   map@20: 0.023900
2025-12-15 20:04:43 - GraphTrainer - INFO -   mrr@20: 0.025040
2025-12-15 20:04:43 - GraphTrainer - INFO - 第 72 轮训练完成
2025-12-15 20:04:43 - GraphTrainer - INFO - train_loss: 0.202241
2025-12-15 20:04:43 - GraphTrainer - INFO - precision@5: 0.007128
2025-12-15 20:04:43 - GraphTrainer - INFO - recall@5: 0.033757
2025-12-15 20:04:43 - GraphTrainer - INFO - hit_rate@5: 0.035588
2025-12-15 20:04:43 - GraphTrainer - INFO - ndcg@5: 0.022606
2025-12-15 20:04:43 - GraphTrainer - INFO - map@5: 0.018652
2025-12-15 20:04:43 - GraphTrainer - INFO - mrr@5: 0.019551
2025-12-15 20:04:43 - GraphTrainer - INFO - precision@10: 0.005966
2025-12-15 20:04:43 - GraphTrainer - INFO - recall@10: 0.056498
2025-12-15 20:04:43 - GraphTrainer - INFO - hit_rate@10: 0.059501
2025-12-15 20:04:43 - GraphTrainer - INFO - ndcg@10: 0.029969
2025-12-15 20:04:43 - GraphTrainer - INFO - map@10: 0.021620
2025-12-15 20:04:43 - GraphTrainer - INFO - mrr@10: 0.022671
2025-12-15 20:04:43 - GraphTrainer - INFO - precision@20: 0.004760
2025-12-15 20:04:43 - GraphTrainer - INFO - recall@20: 0.090260
2025-12-15 20:04:43 - GraphTrainer - INFO - hit_rate@20: 0.094677
2025-12-15 20:04:43 - GraphTrainer - INFO - ndcg@20: 0.038512
2025-12-15 20:04:43 - GraphTrainer - INFO - map@20: 0.023900
2025-12-15 20:04:43 - GraphTrainer - INFO - mrr@20: 0.025040
2025-12-15 20:04:43 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:04:43 - GraphTrainer - INFO - ============================================================
2025-12-15 20:04:43 - GraphTrainer - INFO - 开始第 73/1000 轮训练
2025-12-15 20:04:43 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2061, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.1988, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.1976, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.1853, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1975, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2013, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.1992, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2000, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2087, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.1813, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1977, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2003, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2152, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.1984, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2191, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1974, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2014, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1971, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2183, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2202, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2137, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1856, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.1981, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2047, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.1930, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.1962, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.1962, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.1884, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.1962, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.1813, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.1967, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2039, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2164, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2256, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1941, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1940, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1991, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2060, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2016, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2050, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2229, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2006, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2070, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2044, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2026, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2075, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2207, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2041, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2071, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2202, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2029, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.1797, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2174, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2118, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1799, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2117, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.1998, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.1932, device='cuda:0', grad_fn=<AddBackward0>)
The 72 training average loss: 0.20224069033203454
2025-12-15 20:04:51 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:04:51 - GraphTrainer - INFO -   precision@5: 0.007334
2025-12-15 20:04:51 - GraphTrainer - INFO -   recall@5: 0.034883
2025-12-15 20:04:51 - GraphTrainer - INFO -   hit_rate@5: 0.036668
2025-12-15 20:04:51 - GraphTrainer - INFO -   ndcg@5: 0.023285
2025-12-15 20:04:51 - GraphTrainer - INFO -   map@5: 0.019193
2025-12-15 20:04:51 - GraphTrainer - INFO -   mrr@5: 0.020088
2025-12-15 20:04:51 - GraphTrainer - INFO -   precision@10: 0.006022
2025-12-15 20:04:51 - GraphTrainer - INFO -   recall@10: 0.056982
2025-12-15 20:04:51 - GraphTrainer - INFO -   hit_rate@10: 0.060067
2025-12-15 20:04:51 - GraphTrainer - INFO -   ndcg@10: 0.030448
2025-12-15 20:04:51 - GraphTrainer - INFO -   map@10: 0.022073
2025-12-15 20:04:51 - GraphTrainer - INFO -   mrr@10: 0.023136
2025-12-15 20:04:51 - GraphTrainer - INFO -   precision@20: 0.004767
2025-12-15 20:04:51 - GraphTrainer - INFO -   recall@20: 0.090243
2025-12-15 20:04:51 - GraphTrainer - INFO -   hit_rate@20: 0.094677
2025-12-15 20:04:51 - GraphTrainer - INFO -   ndcg@20: 0.038888
2025-12-15 20:04:51 - GraphTrainer - INFO -   map@20: 0.024337
2025-12-15 20:04:51 - GraphTrainer - INFO -   mrr@20: 0.025485
2025-12-15 20:04:51 - GraphTrainer - INFO - 第 73 轮训练完成
2025-12-15 20:04:51 - GraphTrainer - INFO - train_loss: 0.201420
2025-12-15 20:04:51 - GraphTrainer - INFO - precision@5: 0.007334
2025-12-15 20:04:51 - GraphTrainer - INFO - recall@5: 0.034883
2025-12-15 20:04:51 - GraphTrainer - INFO - hit_rate@5: 0.036668
2025-12-15 20:04:51 - GraphTrainer - INFO - ndcg@5: 0.023285
2025-12-15 20:04:51 - GraphTrainer - INFO - map@5: 0.019193
2025-12-15 20:04:51 - GraphTrainer - INFO - mrr@5: 0.020088
2025-12-15 20:04:51 - GraphTrainer - INFO - precision@10: 0.006022
2025-12-15 20:04:51 - GraphTrainer - INFO - recall@10: 0.056982
2025-12-15 20:04:51 - GraphTrainer - INFO - hit_rate@10: 0.060067
2025-12-15 20:04:51 - GraphTrainer - INFO - ndcg@10: 0.030448
2025-12-15 20:04:51 - GraphTrainer - INFO - map@10: 0.022073
2025-12-15 20:04:51 - GraphTrainer - INFO - mrr@10: 0.023136
2025-12-15 20:04:51 - GraphTrainer - INFO - precision@20: 0.004767
2025-12-15 20:04:51 - GraphTrainer - INFO - recall@20: 0.090243
2025-12-15 20:04:51 - GraphTrainer - INFO - hit_rate@20: 0.094677
2025-12-15 20:04:51 - GraphTrainer - INFO - ndcg@20: 0.038888
2025-12-15 20:04:51 - GraphTrainer - INFO - map@20: 0.024337
2025-12-15 20:04:51 - GraphTrainer - INFO - mrr@20: 0.025485
2025-12-15 20:04:51 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:04:51 - GraphTrainer - INFO - ============================================================
2025-12-15 20:04:51 - GraphTrainer - INFO - 开始第 74/1000 轮训练
2025-12-15 20:04:51 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1955, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2142, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2053, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2087, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1991, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2019, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2032, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.1925, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2052, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2041, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1978, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.1970, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1863, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.1999, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2011, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2009, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1947, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1923, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.1835, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.1984, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1946, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1998, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.1880, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2020, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.1836, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2058, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.1984, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2072, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2211, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2057, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.1871, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.1999, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.1859, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1967, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1884, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1962, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2042, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2220, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2044, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2015, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2023, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2145, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2094, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2197, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.1888, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2027, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2029, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2009, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2105, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.1905, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2120, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2123, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2068, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2031, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1992, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2185, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2030, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2109, device='cuda:0', grad_fn=<AddBackward0>)
The 73 training average loss: 0.20141977457136945
2025-12-15 20:04:59 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:04:59 - GraphTrainer - INFO -   precision@5: 0.007200
2025-12-15 20:04:59 - GraphTrainer - INFO -   recall@5: 0.034191
2025-12-15 20:04:59 - GraphTrainer - INFO -   hit_rate@5: 0.035948
2025-12-15 20:04:59 - GraphTrainer - INFO -   ndcg@5: 0.023201
2025-12-15 20:04:59 - GraphTrainer - INFO -   map@5: 0.019308
2025-12-15 20:04:59 - GraphTrainer - INFO -   mrr@5: 0.020224
2025-12-15 20:04:59 - GraphTrainer - INFO -   precision@10: 0.006007
2025-12-15 20:04:59 - GraphTrainer - INFO -   recall@10: 0.056953
2025-12-15 20:04:59 - GraphTrainer - INFO -   hit_rate@10: 0.059913
2025-12-15 20:04:59 - GraphTrainer - INFO -   ndcg@10: 0.030577
2025-12-15 20:04:59 - GraphTrainer - INFO -   map@10: 0.022285
2025-12-15 20:04:59 - GraphTrainer - INFO -   mrr@10: 0.023359
2025-12-15 20:04:59 - GraphTrainer - INFO -   precision@20: 0.004749
2025-12-15 20:04:59 - GraphTrainer - INFO -   recall@20: 0.089810
2025-12-15 20:04:59 - GraphTrainer - INFO -   hit_rate@20: 0.094317
2025-12-15 20:04:59 - GraphTrainer - INFO -   ndcg@20: 0.038907
2025-12-15 20:04:59 - GraphTrainer - INFO -   map@20: 0.024505
2025-12-15 20:04:59 - GraphTrainer - INFO -   mrr@20: 0.025676
2025-12-15 20:04:59 - GraphTrainer - INFO - 第 74 轮训练完成
2025-12-15 20:04:59 - GraphTrainer - INFO - train_loss: 0.202100
2025-12-15 20:04:59 - GraphTrainer - INFO - precision@5: 0.007200
2025-12-15 20:04:59 - GraphTrainer - INFO - recall@5: 0.034191
2025-12-15 20:04:59 - GraphTrainer - INFO - hit_rate@5: 0.035948
2025-12-15 20:04:59 - GraphTrainer - INFO - ndcg@5: 0.023201
2025-12-15 20:04:59 - GraphTrainer - INFO - map@5: 0.019308
2025-12-15 20:04:59 - GraphTrainer - INFO - mrr@5: 0.020224
2025-12-15 20:04:59 - GraphTrainer - INFO - precision@10: 0.006007
2025-12-15 20:04:59 - GraphTrainer - INFO - recall@10: 0.056953
2025-12-15 20:04:59 - GraphTrainer - INFO - hit_rate@10: 0.059913
2025-12-15 20:04:59 - GraphTrainer - INFO - ndcg@10: 0.030577
2025-12-15 20:04:59 - GraphTrainer - INFO - map@10: 0.022285
2025-12-15 20:04:59 - GraphTrainer - INFO - mrr@10: 0.023359
2025-12-15 20:04:59 - GraphTrainer - INFO - precision@20: 0.004749
2025-12-15 20:04:59 - GraphTrainer - INFO - recall@20: 0.089810
2025-12-15 20:04:59 - GraphTrainer - INFO - hit_rate@20: 0.094317
2025-12-15 20:04:59 - GraphTrainer - INFO - ndcg@20: 0.038907
2025-12-15 20:04:59 - GraphTrainer - INFO - map@20: 0.024505
2025-12-15 20:04:59 - GraphTrainer - INFO - mrr@20: 0.025676
2025-12-15 20:04:59 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:04:59 - GraphTrainer - INFO - ============================================================
2025-12-15 20:04:59 - GraphTrainer - INFO - 开始第 75/1000 轮训练
2025-12-15 20:04:59 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1912, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2112, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.1963, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2135, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1934, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2035, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2224, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.1957, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2254, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2060, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2104, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2029, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1963, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.1931, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2143, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2084, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1888, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2136, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2308, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.1898, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2086, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2096, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.1934, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2059, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.1960, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2235, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.1805, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2062, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.1934, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2172, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.1819, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2037, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2027, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1955, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1933, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1973, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1868, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.1908, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2021, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2031, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1972, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.1949, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.1973, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2001, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.1904, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2039, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2021, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2223, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2048, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2075, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2038, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2023, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.1963, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2013, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2063, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.1732, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2123, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2073, device='cuda:0', grad_fn=<AddBackward0>)
The 74 training average loss: 0.20210013589982329
2025-12-15 20:05:07 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:05:07 - GraphTrainer - INFO -   precision@5: 0.007200
2025-12-15 20:05:07 - GraphTrainer - INFO -   recall@5: 0.034330
2025-12-15 20:05:07 - GraphTrainer - INFO -   hit_rate@5: 0.035948
2025-12-15 20:05:07 - GraphTrainer - INFO -   ndcg@5: 0.023324
2025-12-15 20:05:07 - GraphTrainer - INFO -   map@5: 0.019441
2025-12-15 20:05:07 - GraphTrainer - INFO -   mrr@5: 0.020316
2025-12-15 20:05:07 - GraphTrainer - INFO -   precision@10: 0.006053
2025-12-15 20:05:07 - GraphTrainer - INFO -   recall@10: 0.057511
2025-12-15 20:05:07 - GraphTrainer - INFO -   hit_rate@10: 0.060427
2025-12-15 20:05:07 - GraphTrainer - INFO -   ndcg@10: 0.030794
2025-12-15 20:05:07 - GraphTrainer - INFO -   map@10: 0.022427
2025-12-15 20:05:07 - GraphTrainer - INFO -   mrr@10: 0.023476
2025-12-15 20:05:07 - GraphTrainer - INFO -   precision@20: 0.004824
2025-12-15 20:05:07 - GraphTrainer - INFO -   recall@20: 0.091413
2025-12-15 20:05:07 - GraphTrainer - INFO -   hit_rate@20: 0.095809
2025-12-15 20:05:07 - GraphTrainer - INFO -   ndcg@20: 0.039372
2025-12-15 20:05:07 - GraphTrainer - INFO -   map@20: 0.024708
2025-12-15 20:05:07 - GraphTrainer - INFO -   mrr@20: 0.025848
2025-12-15 20:05:07 - GraphTrainer - INFO - 第 75 轮训练完成
2025-12-15 20:05:07 - GraphTrainer - INFO - train_loss: 0.202502
2025-12-15 20:05:07 - GraphTrainer - INFO - precision@5: 0.007200
2025-12-15 20:05:07 - GraphTrainer - INFO - recall@5: 0.034330
2025-12-15 20:05:07 - GraphTrainer - INFO - hit_rate@5: 0.035948
2025-12-15 20:05:07 - GraphTrainer - INFO - ndcg@5: 0.023324
2025-12-15 20:05:07 - GraphTrainer - INFO - map@5: 0.019441
2025-12-15 20:05:07 - GraphTrainer - INFO - mrr@5: 0.020316
2025-12-15 20:05:07 - GraphTrainer - INFO - precision@10: 0.006053
2025-12-15 20:05:07 - GraphTrainer - INFO - recall@10: 0.057511
2025-12-15 20:05:07 - GraphTrainer - INFO - hit_rate@10: 0.060427
2025-12-15 20:05:07 - GraphTrainer - INFO - ndcg@10: 0.030794
2025-12-15 20:05:07 - GraphTrainer - INFO - map@10: 0.022427
2025-12-15 20:05:07 - GraphTrainer - INFO - mrr@10: 0.023476
2025-12-15 20:05:07 - GraphTrainer - INFO - precision@20: 0.004824
2025-12-15 20:05:07 - GraphTrainer - INFO - recall@20: 0.091413
2025-12-15 20:05:07 - GraphTrainer - INFO - hit_rate@20: 0.095809
2025-12-15 20:05:07 - GraphTrainer - INFO - ndcg@20: 0.039372
2025-12-15 20:05:07 - GraphTrainer - INFO - map@20: 0.024708
2025-12-15 20:05:07 - GraphTrainer - INFO - mrr@20: 0.025848
2025-12-15 20:05:07 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:05:07 - GraphTrainer - INFO - ============================================================
2025-12-15 20:05:07 - GraphTrainer - INFO - 开始第 76/1000 轮训练
2025-12-15 20:05:07 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2106, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2150, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.1913, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.1973, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1842, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2339, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.1848, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2216, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2028, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2131, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1972, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.1976, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1939, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2022, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.1822, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2022, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2142, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2027, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.1815, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2056, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2040, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1979, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2250, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2350, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2126, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.1977, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2102, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2089, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2019, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2077, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.1918, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.1891, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.1996, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1984, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1959, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1987, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2014, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2194, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2051, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.1839, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1967, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2161, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2094, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2014, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.1892, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.1812, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2115, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.1925, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1972, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.1998, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2055, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2133, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2152, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1904, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2008, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.1929, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2154, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.1985, device='cuda:0', grad_fn=<AddBackward0>)
The 75 training average loss: 0.20250231233136406
2025-12-15 20:05:15 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:05:15 - GraphTrainer - INFO -   precision@5: 0.007282
2025-12-15 20:05:15 - GraphTrainer - INFO -   recall@5: 0.034770
2025-12-15 20:05:15 - GraphTrainer - INFO -   hit_rate@5: 0.036359
2025-12-15 20:05:15 - GraphTrainer - INFO -   ndcg@5: 0.023643
2025-12-15 20:05:15 - GraphTrainer - INFO -   map@5: 0.019742
2025-12-15 20:05:15 - GraphTrainer - INFO -   mrr@5: 0.020580
2025-12-15 20:05:15 - GraphTrainer - INFO -   precision@10: 0.006027
2025-12-15 20:05:15 - GraphTrainer - INFO -   recall@10: 0.057339
2025-12-15 20:05:15 - GraphTrainer - INFO -   hit_rate@10: 0.060170
2025-12-15 20:05:15 - GraphTrainer - INFO -   ndcg@10: 0.030948
2025-12-15 20:05:15 - GraphTrainer - INFO -   map@10: 0.022683
2025-12-15 20:05:15 - GraphTrainer - INFO -   mrr@10: 0.023684
2025-12-15 20:05:15 - GraphTrainer - INFO -   precision@20: 0.004770
2025-12-15 20:05:15 - GraphTrainer - INFO -   recall@20: 0.090320
2025-12-15 20:05:15 - GraphTrainer - INFO -   hit_rate@20: 0.094780
2025-12-15 20:05:15 - GraphTrainer - INFO -   ndcg@20: 0.039343
2025-12-15 20:05:15 - GraphTrainer - INFO -   map@20: 0.024935
2025-12-15 20:05:15 - GraphTrainer - INFO -   mrr@20: 0.026040
2025-12-15 20:05:15 - GraphTrainer - INFO - 第 76 轮训练完成
2025-12-15 20:05:15 - GraphTrainer - INFO - train_loss: 0.200186
2025-12-15 20:05:15 - GraphTrainer - INFO - precision@5: 0.007282
2025-12-15 20:05:15 - GraphTrainer - INFO - recall@5: 0.034770
2025-12-15 20:05:15 - GraphTrainer - INFO - hit_rate@5: 0.036359
2025-12-15 20:05:15 - GraphTrainer - INFO - ndcg@5: 0.023643
2025-12-15 20:05:15 - GraphTrainer - INFO - map@5: 0.019742
2025-12-15 20:05:15 - GraphTrainer - INFO - mrr@5: 0.020580
2025-12-15 20:05:15 - GraphTrainer - INFO - precision@10: 0.006027
2025-12-15 20:05:15 - GraphTrainer - INFO - recall@10: 0.057339
2025-12-15 20:05:15 - GraphTrainer - INFO - hit_rate@10: 0.060170
2025-12-15 20:05:15 - GraphTrainer - INFO - ndcg@10: 0.030948
2025-12-15 20:05:15 - GraphTrainer - INFO - map@10: 0.022683
2025-12-15 20:05:15 - GraphTrainer - INFO - mrr@10: 0.023684
2025-12-15 20:05:15 - GraphTrainer - INFO - precision@20: 0.004770
2025-12-15 20:05:15 - GraphTrainer - INFO - recall@20: 0.090320
2025-12-15 20:05:15 - GraphTrainer - INFO - hit_rate@20: 0.094780
2025-12-15 20:05:15 - GraphTrainer - INFO - ndcg@20: 0.039343
2025-12-15 20:05:15 - GraphTrainer - INFO - map@20: 0.024935
2025-12-15 20:05:15 - GraphTrainer - INFO - mrr@20: 0.026040
2025-12-15 20:05:15 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:05:15 - GraphTrainer - INFO - ============================================================
2025-12-15 20:05:15 - GraphTrainer - INFO - 开始第 77/1000 轮训练
2025-12-15 20:05:15 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1970, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2049, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.1902, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.1894, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2071, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.1818, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2101, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2185, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1888, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2067, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1991, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.1677, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1979, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.1818, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2133, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1891, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1996, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2024, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2106, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2085, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2317, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2024, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2014, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.1700, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2166, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.1990, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2058, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2170, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2065, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.1933, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.1951, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.1947, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2041, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1910, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1852, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1942, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1928, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2034, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2268, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.1957, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2038, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2104, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.1908, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.1900, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2004, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2199, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.1931, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.1835, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1900, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.1970, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2214, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.1862, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2052, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1986, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2027, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.1930, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2206, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2131, device='cuda:0', grad_fn=<AddBackward0>)
The 76 training average loss: 0.20018578551966568
2025-12-15 20:05:23 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:05:23 - GraphTrainer - INFO -   precision@5: 0.007323
2025-12-15 20:05:23 - GraphTrainer - INFO -   recall@5: 0.034940
2025-12-15 20:05:23 - GraphTrainer - INFO -   hit_rate@5: 0.036565
2025-12-15 20:05:23 - GraphTrainer - INFO -   ndcg@5: 0.023159
2025-12-15 20:05:23 - GraphTrainer - INFO -   map@5: 0.019035
2025-12-15 20:05:23 - GraphTrainer - INFO -   mrr@5: 0.019893
2025-12-15 20:05:23 - GraphTrainer - INFO -   precision@10: 0.005981
2025-12-15 20:05:23 - GraphTrainer - INFO -   recall@10: 0.056915
2025-12-15 20:05:23 - GraphTrainer - INFO -   hit_rate@10: 0.059707
2025-12-15 20:05:23 - GraphTrainer - INFO -   ndcg@10: 0.030282
2025-12-15 20:05:23 - GraphTrainer - INFO -   map@10: 0.021913
2025-12-15 20:05:23 - GraphTrainer - INFO -   mrr@10: 0.022923
2025-12-15 20:05:23 - GraphTrainer - INFO -   precision@20: 0.004749
2025-12-15 20:05:23 - GraphTrainer - INFO -   recall@20: 0.090053
2025-12-15 20:05:23 - GraphTrainer - INFO -   hit_rate@20: 0.094317
2025-12-15 20:05:23 - GraphTrainer - INFO -   ndcg@20: 0.038688
2025-12-15 20:05:23 - GraphTrainer - INFO -   map@20: 0.024158
2025-12-15 20:05:23 - GraphTrainer - INFO -   mrr@20: 0.025262
2025-12-15 20:05:23 - GraphTrainer - INFO - 第 77 轮训练完成
2025-12-15 20:05:23 - GraphTrainer - INFO - train_loss: 0.204423
2025-12-15 20:05:23 - GraphTrainer - INFO - precision@5: 0.007323
2025-12-15 20:05:23 - GraphTrainer - INFO - recall@5: 0.034940
2025-12-15 20:05:23 - GraphTrainer - INFO - hit_rate@5: 0.036565
2025-12-15 20:05:23 - GraphTrainer - INFO - ndcg@5: 0.023159
2025-12-15 20:05:23 - GraphTrainer - INFO - map@5: 0.019035
2025-12-15 20:05:23 - GraphTrainer - INFO - mrr@5: 0.019893
2025-12-15 20:05:23 - GraphTrainer - INFO - precision@10: 0.005981
2025-12-15 20:05:23 - GraphTrainer - INFO - recall@10: 0.056915
2025-12-15 20:05:23 - GraphTrainer - INFO - hit_rate@10: 0.059707
2025-12-15 20:05:23 - GraphTrainer - INFO - ndcg@10: 0.030282
2025-12-15 20:05:23 - GraphTrainer - INFO - map@10: 0.021913
2025-12-15 20:05:23 - GraphTrainer - INFO - mrr@10: 0.022923
2025-12-15 20:05:23 - GraphTrainer - INFO - precision@20: 0.004749
2025-12-15 20:05:23 - GraphTrainer - INFO - recall@20: 0.090053
2025-12-15 20:05:23 - GraphTrainer - INFO - hit_rate@20: 0.094317
2025-12-15 20:05:23 - GraphTrainer - INFO - ndcg@20: 0.038688
2025-12-15 20:05:23 - GraphTrainer - INFO - map@20: 0.024158
2025-12-15 20:05:23 - GraphTrainer - INFO - mrr@20: 0.025262
2025-12-15 20:05:23 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:05:23 - GraphTrainer - INFO - ============================================================
2025-12-15 20:05:23 - GraphTrainer - INFO - 开始第 78/1000 轮训练
2025-12-15 20:05:23 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2040, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.1983, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.1985, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.1974, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1955, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2089, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2158, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.1947, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1991, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2088, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1945, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2048, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1912, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.1978, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2017, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1868, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1983, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2070, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2084, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.1870, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2144, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1790, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.1886, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2047, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2297, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2102, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.1909, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2074, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2050, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2026, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2028, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2005, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2027, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2044, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2024, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1966, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1944, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2101, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2260, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.1946, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2057, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2113, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2197, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2170, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2000, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2033, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2179, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2015, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2000, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2369, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2068, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2127, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2006, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2211, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2061, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2182, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.1887, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2235, device='cuda:0', grad_fn=<AddBackward0>)
The 77 training average loss: 0.20442284746416683
2025-12-15 20:05:31 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:05:31 - GraphTrainer - INFO -   precision@5: 0.007375
2025-12-15 20:05:31 - GraphTrainer - INFO -   recall@5: 0.035002
2025-12-15 20:05:31 - GraphTrainer - INFO -   hit_rate@5: 0.036822
2025-12-15 20:05:31 - GraphTrainer - INFO -   ndcg@5: 0.023328
2025-12-15 20:05:31 - GraphTrainer - INFO -   map@5: 0.019218
2025-12-15 20:05:31 - GraphTrainer - INFO -   mrr@5: 0.020119
2025-12-15 20:05:31 - GraphTrainer - INFO -   precision@10: 0.005960
2025-12-15 20:05:31 - GraphTrainer - INFO -   recall@10: 0.056546
2025-12-15 20:05:31 - GraphTrainer - INFO -   hit_rate@10: 0.059450
2025-12-15 20:05:31 - GraphTrainer - INFO -   ndcg@10: 0.030323
2025-12-15 20:05:31 - GraphTrainer - INFO -   map@10: 0.022055
2025-12-15 20:05:31 - GraphTrainer - INFO -   mrr@10: 0.023097
2025-12-15 20:05:31 - GraphTrainer - INFO -   precision@20: 0.004716
2025-12-15 20:05:31 - GraphTrainer - INFO -   recall@20: 0.089272
2025-12-15 20:05:31 - GraphTrainer - INFO -   hit_rate@20: 0.093803
2025-12-15 20:05:31 - GraphTrainer - INFO -   ndcg@20: 0.038624
2025-12-15 20:05:31 - GraphTrainer - INFO -   map@20: 0.024269
2025-12-15 20:05:31 - GraphTrainer - INFO -   mrr@20: 0.025416
2025-12-15 20:05:31 - GraphTrainer - INFO - 第 78 轮训练完成
2025-12-15 20:05:31 - GraphTrainer - INFO - train_loss: 0.203014
2025-12-15 20:05:31 - GraphTrainer - INFO - precision@5: 0.007375
2025-12-15 20:05:31 - GraphTrainer - INFO - recall@5: 0.035002
2025-12-15 20:05:31 - GraphTrainer - INFO - hit_rate@5: 0.036822
2025-12-15 20:05:31 - GraphTrainer - INFO - ndcg@5: 0.023328
2025-12-15 20:05:31 - GraphTrainer - INFO - map@5: 0.019218
2025-12-15 20:05:31 - GraphTrainer - INFO - mrr@5: 0.020119
2025-12-15 20:05:31 - GraphTrainer - INFO - precision@10: 0.005960
2025-12-15 20:05:31 - GraphTrainer - INFO - recall@10: 0.056546
2025-12-15 20:05:31 - GraphTrainer - INFO - hit_rate@10: 0.059450
2025-12-15 20:05:31 - GraphTrainer - INFO - ndcg@10: 0.030323
2025-12-15 20:05:31 - GraphTrainer - INFO - map@10: 0.022055
2025-12-15 20:05:31 - GraphTrainer - INFO - mrr@10: 0.023097
2025-12-15 20:05:31 - GraphTrainer - INFO - precision@20: 0.004716
2025-12-15 20:05:31 - GraphTrainer - INFO - recall@20: 0.089272
2025-12-15 20:05:31 - GraphTrainer - INFO - hit_rate@20: 0.093803
2025-12-15 20:05:31 - GraphTrainer - INFO - ndcg@20: 0.038624
2025-12-15 20:05:31 - GraphTrainer - INFO - map@20: 0.024269
2025-12-15 20:05:31 - GraphTrainer - INFO - mrr@20: 0.025416
2025-12-15 20:05:31 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:05:31 - GraphTrainer - INFO - ============================================================
2025-12-15 20:05:31 - GraphTrainer - INFO - 开始第 79/1000 轮训练
2025-12-15 20:05:31 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2082, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.1816, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2161, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2256, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1902, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.1898, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2131, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.1929, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2034, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.1982, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2020, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.1932, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2007, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.1938, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.1824, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1892, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1994, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2101, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2038, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2196, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1819, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1779, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.1975, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2009, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2091, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2015, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2446, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2041, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2098, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.1919, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2148, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2039, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2020, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2099, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2264, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1897, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1921, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.1981, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2017, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2120, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1957, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.1932, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2192, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.1924, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2245, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.1767, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2193, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2066, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2040, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.1847, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2378, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.1989, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2039, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2036, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1920, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.1999, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2329, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2063, device='cuda:0', grad_fn=<AddBackward0>)
The 78 training average loss: 0.20301353032219
2025-12-15 20:05:39 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:05:39 - GraphTrainer - INFO -   precision@5: 0.007303
2025-12-15 20:05:39 - GraphTrainer - INFO -   recall@5: 0.034857
2025-12-15 20:05:39 - GraphTrainer - INFO -   hit_rate@5: 0.036513
2025-12-15 20:05:39 - GraphTrainer - INFO -   ndcg@5: 0.023201
2025-12-15 20:05:39 - GraphTrainer - INFO -   map@5: 0.019120
2025-12-15 20:05:39 - GraphTrainer - INFO -   mrr@5: 0.019976
2025-12-15 20:05:39 - GraphTrainer - INFO -   precision@10: 0.006130
2025-12-15 20:05:39 - GraphTrainer - INFO -   recall@10: 0.058263
2025-12-15 20:05:39 - GraphTrainer - INFO -   hit_rate@10: 0.061198
2025-12-15 20:05:39 - GraphTrainer - INFO -   ndcg@10: 0.030789
2025-12-15 20:05:39 - GraphTrainer - INFO -   map@10: 0.022177
2025-12-15 20:05:39 - GraphTrainer - INFO -   mrr@10: 0.023203
2025-12-15 20:05:39 - GraphTrainer - INFO -   precision@20: 0.004837
2025-12-15 20:05:39 - GraphTrainer - INFO -   recall@20: 0.091833
2025-12-15 20:05:39 - GraphTrainer - INFO -   hit_rate@20: 0.096169
2025-12-15 20:05:39 - GraphTrainer - INFO -   ndcg@20: 0.039288
2025-12-15 20:05:39 - GraphTrainer - INFO -   map@20: 0.024447
2025-12-15 20:05:39 - GraphTrainer - INFO -   mrr@20: 0.025562
2025-12-15 20:05:39 - GraphTrainer - INFO - 第 79 轮训练完成
2025-12-15 20:05:39 - GraphTrainer - INFO - train_loss: 0.200015
2025-12-15 20:05:39 - GraphTrainer - INFO - precision@5: 0.007303
2025-12-15 20:05:39 - GraphTrainer - INFO - recall@5: 0.034857
2025-12-15 20:05:39 - GraphTrainer - INFO - hit_rate@5: 0.036513
2025-12-15 20:05:39 - GraphTrainer - INFO - ndcg@5: 0.023201
2025-12-15 20:05:39 - GraphTrainer - INFO - map@5: 0.019120
2025-12-15 20:05:39 - GraphTrainer - INFO - mrr@5: 0.019976
2025-12-15 20:05:39 - GraphTrainer - INFO - precision@10: 0.006130
2025-12-15 20:05:39 - GraphTrainer - INFO - recall@10: 0.058263
2025-12-15 20:05:39 - GraphTrainer - INFO - hit_rate@10: 0.061198
2025-12-15 20:05:39 - GraphTrainer - INFO - ndcg@10: 0.030789
2025-12-15 20:05:39 - GraphTrainer - INFO - map@10: 0.022177
2025-12-15 20:05:39 - GraphTrainer - INFO - mrr@10: 0.023203
2025-12-15 20:05:39 - GraphTrainer - INFO - precision@20: 0.004837
2025-12-15 20:05:39 - GraphTrainer - INFO - recall@20: 0.091833
2025-12-15 20:05:39 - GraphTrainer - INFO - hit_rate@20: 0.096169
2025-12-15 20:05:39 - GraphTrainer - INFO - ndcg@20: 0.039288
2025-12-15 20:05:39 - GraphTrainer - INFO - map@20: 0.024447
2025-12-15 20:05:39 - GraphTrainer - INFO - mrr@20: 0.025562
2025-12-15 20:05:39 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:05:39 - GraphTrainer - INFO - ============================================================
2025-12-15 20:05:39 - GraphTrainer - INFO - 开始第 80/1000 轮训练
2025-12-15 20:05:39 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1962, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.1862, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2016, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.1912, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2015, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.1967, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.1951, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.1998, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2109, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2064, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1989, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.1968, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1852, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.1776, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.1854, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1955, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1988, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2248, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2051, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.1976, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2030, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2071, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2022, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2229, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.1812, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2052, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.1862, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2026, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2090, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.1900, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2199, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2011, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2059, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1860, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1963, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2265, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1960, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2121, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.1813, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2007, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1906, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.1983, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2126, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.1921, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.1781, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.1963, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.1956, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2036, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2000, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2173, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2082, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2077, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2084, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1948, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1875, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2079, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2208, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.1948, device='cuda:0', grad_fn=<AddBackward0>)
The 79 training average loss: 0.2000149830148138
2025-12-15 20:05:46 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:05:46 - GraphTrainer - INFO -   precision@5: 0.007354
2025-12-15 20:05:46 - GraphTrainer - INFO -   recall@5: 0.034950
2025-12-15 20:05:46 - GraphTrainer - INFO -   hit_rate@5: 0.036770
2025-12-15 20:05:46 - GraphTrainer - INFO -   ndcg@5: 0.023269
2025-12-15 20:05:46 - GraphTrainer - INFO -   map@5: 0.019150
2025-12-15 20:05:46 - GraphTrainer - INFO -   mrr@5: 0.020076
2025-12-15 20:05:46 - GraphTrainer - INFO -   precision@10: 0.006053
2025-12-15 20:05:46 - GraphTrainer - INFO -   recall@10: 0.057416
2025-12-15 20:05:46 - GraphTrainer - INFO -   hit_rate@10: 0.060375
2025-12-15 20:05:46 - GraphTrainer - INFO -   ndcg@10: 0.030556
2025-12-15 20:05:46 - GraphTrainer - INFO -   map@10: 0.022094
2025-12-15 20:05:46 - GraphTrainer - INFO -   mrr@10: 0.023164
2025-12-15 20:05:46 - GraphTrainer - INFO -   precision@20: 0.004754
2025-12-15 20:05:46 - GraphTrainer - INFO -   recall@20: 0.089840
2025-12-15 20:05:46 - GraphTrainer - INFO -   hit_rate@20: 0.094369
2025-12-15 20:05:46 - GraphTrainer - INFO -   ndcg@20: 0.038804
2025-12-15 20:05:46 - GraphTrainer - INFO -   map@20: 0.024307
2025-12-15 20:05:46 - GraphTrainer - INFO -   mrr@20: 0.025473
2025-12-15 20:05:46 - GraphTrainer - INFO - 第 80 轮训练完成
2025-12-15 20:05:46 - GraphTrainer - INFO - train_loss: 0.198682
2025-12-15 20:05:46 - GraphTrainer - INFO - precision@5: 0.007354
2025-12-15 20:05:46 - GraphTrainer - INFO - recall@5: 0.034950
2025-12-15 20:05:46 - GraphTrainer - INFO - hit_rate@5: 0.036770
2025-12-15 20:05:46 - GraphTrainer - INFO - ndcg@5: 0.023269
2025-12-15 20:05:46 - GraphTrainer - INFO - map@5: 0.019150
2025-12-15 20:05:46 - GraphTrainer - INFO - mrr@5: 0.020076
2025-12-15 20:05:46 - GraphTrainer - INFO - precision@10: 0.006053
2025-12-15 20:05:46 - GraphTrainer - INFO - recall@10: 0.057416
2025-12-15 20:05:46 - GraphTrainer - INFO - hit_rate@10: 0.060375
2025-12-15 20:05:46 - GraphTrainer - INFO - ndcg@10: 0.030556
2025-12-15 20:05:46 - GraphTrainer - INFO - map@10: 0.022094
2025-12-15 20:05:46 - GraphTrainer - INFO - mrr@10: 0.023164
2025-12-15 20:05:46 - GraphTrainer - INFO - precision@20: 0.004754
2025-12-15 20:05:46 - GraphTrainer - INFO - recall@20: 0.089840
2025-12-15 20:05:46 - GraphTrainer - INFO - hit_rate@20: 0.094369
2025-12-15 20:05:46 - GraphTrainer - INFO - ndcg@20: 0.038804
2025-12-15 20:05:46 - GraphTrainer - INFO - map@20: 0.024307
2025-12-15 20:05:46 - GraphTrainer - INFO - mrr@20: 0.025473
2025-12-15 20:05:46 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:05:46 - GraphTrainer - INFO - 检查点已保存: Epoch 80 -> ./checkpoints/checkpoint_epoch_80.pth
2025-12-15 20:05:46 - GraphTrainer - INFO - ============================================================
2025-12-15 20:05:46 - GraphTrainer - INFO - 开始第 81/1000 轮训练
2025-12-15 20:05:46 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2025, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2055, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.1956, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2101, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2114, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2045, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.1896, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.1919, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1939, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.1855, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1976, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2014, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2141, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.1911, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.1974, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2053, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2026, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1924, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.1968, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2148, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1967, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1913, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.1946, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.1781, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.1928, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.1840, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.1752, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.1943, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.1846, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2111, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2122, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2111, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2126, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1997, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1849, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1955, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1960, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.1843, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.1958, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2126, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1857, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.1940, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2062, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.1948, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.1997, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2145, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.1919, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2139, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2065, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2177, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2007, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2137, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2056, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1864, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1872, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2043, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.1839, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2057, device='cuda:0', grad_fn=<AddBackward0>)
The 80 training average loss: 0.1986823351732616
2025-12-15 20:05:54 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:05:54 - GraphTrainer - INFO -   precision@5: 0.007457
2025-12-15 20:05:54 - GraphTrainer - INFO -   recall@5: 0.035413
2025-12-15 20:05:54 - GraphTrainer - INFO -   hit_rate@5: 0.037285
2025-12-15 20:05:54 - GraphTrainer - INFO -   ndcg@5: 0.023348
2025-12-15 20:05:54 - GraphTrainer - INFO -   map@5: 0.019106
2025-12-15 20:05:54 - GraphTrainer - INFO -   mrr@5: 0.020016
2025-12-15 20:05:54 - GraphTrainer - INFO -   precision@10: 0.006074
2025-12-15 20:05:54 - GraphTrainer - INFO -   recall@10: 0.057631
2025-12-15 20:05:54 - GraphTrainer - INFO -   hit_rate@10: 0.060581
2025-12-15 20:05:54 - GraphTrainer - INFO -   ndcg@10: 0.030534
2025-12-15 20:05:54 - GraphTrainer - INFO -   map@10: 0.022001
2025-12-15 20:05:54 - GraphTrainer - INFO -   mrr@10: 0.023052
2025-12-15 20:05:54 - GraphTrainer - INFO -   precision@20: 0.004857
2025-12-15 20:05:54 - GraphTrainer - INFO -   recall@20: 0.091932
2025-12-15 20:05:54 - GraphTrainer - INFO -   hit_rate@20: 0.096477
2025-12-15 20:05:54 - GraphTrainer - INFO -   ndcg@20: 0.039257
2025-12-15 20:05:54 - GraphTrainer - INFO -   map@20: 0.024345
2025-12-15 20:05:54 - GraphTrainer - INFO -   mrr@20: 0.025488
2025-12-15 20:05:54 - GraphTrainer - INFO - 第 81 轮训练完成
2025-12-15 20:05:54 - GraphTrainer - INFO - train_loss: 0.201064
2025-12-15 20:05:54 - GraphTrainer - INFO - precision@5: 0.007457
2025-12-15 20:05:54 - GraphTrainer - INFO - recall@5: 0.035413
2025-12-15 20:05:54 - GraphTrainer - INFO - hit_rate@5: 0.037285
2025-12-15 20:05:54 - GraphTrainer - INFO - ndcg@5: 0.023348
2025-12-15 20:05:54 - GraphTrainer - INFO - map@5: 0.019106
2025-12-15 20:05:54 - GraphTrainer - INFO - mrr@5: 0.020016
2025-12-15 20:05:54 - GraphTrainer - INFO - precision@10: 0.006074
2025-12-15 20:05:54 - GraphTrainer - INFO - recall@10: 0.057631
2025-12-15 20:05:54 - GraphTrainer - INFO - hit_rate@10: 0.060581
2025-12-15 20:05:54 - GraphTrainer - INFO - ndcg@10: 0.030534
2025-12-15 20:05:54 - GraphTrainer - INFO - map@10: 0.022001
2025-12-15 20:05:54 - GraphTrainer - INFO - mrr@10: 0.023052
2025-12-15 20:05:54 - GraphTrainer - INFO - precision@20: 0.004857
2025-12-15 20:05:54 - GraphTrainer - INFO - recall@20: 0.091932
2025-12-15 20:05:54 - GraphTrainer - INFO - hit_rate@20: 0.096477
2025-12-15 20:05:54 - GraphTrainer - INFO - ndcg@20: 0.039257
2025-12-15 20:05:54 - GraphTrainer - INFO - map@20: 0.024345
2025-12-15 20:05:54 - GraphTrainer - INFO - mrr@20: 0.025488
2025-12-15 20:05:54 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:05:54 - GraphTrainer - INFO - ============================================================
2025-12-15 20:05:54 - GraphTrainer - INFO - 开始第 82/1000 轮训练
2025-12-15 20:05:54 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1890, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2045, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2038, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2043, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2038, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2002, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.1981, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2250, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1900, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.1923, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2122, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2103, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2017, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2229, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.1938, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1964, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1811, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1974, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2248, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2044, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1956, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1840, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2031, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.1942, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.1703, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2068, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2003, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.1927, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2083, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.1988, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2027, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.1902, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.1909, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2415, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1848, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2098, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2064, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2025, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2130, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2033, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1950, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2074, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.1926, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.1951, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2085, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.1921, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.1906, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2130, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2073, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.1951, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2022, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2150, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.1838, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1923, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1914, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.1961, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2031, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2255, device='cuda:0', grad_fn=<AddBackward0>)
The 81 training average loss: 0.20106366893340802
2025-12-15 20:06:02 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:06:02 - GraphTrainer - INFO -   precision@5: 0.007406
2025-12-15 20:06:02 - GraphTrainer - INFO -   recall@5: 0.035246
2025-12-15 20:06:02 - GraphTrainer - INFO -   hit_rate@5: 0.037028
2025-12-15 20:06:02 - GraphTrainer - INFO -   ndcg@5: 0.023320
2025-12-15 20:06:02 - GraphTrainer - INFO -   map@5: 0.019133
2025-12-15 20:06:02 - GraphTrainer - INFO -   mrr@5: 0.020006
2025-12-15 20:06:02 - GraphTrainer - INFO -   precision@10: 0.006058
2025-12-15 20:06:02 - GraphTrainer - INFO -   recall@10: 0.057522
2025-12-15 20:06:02 - GraphTrainer - INFO -   hit_rate@10: 0.060375
2025-12-15 20:06:02 - GraphTrainer - INFO -   ndcg@10: 0.030522
2025-12-15 20:06:02 - GraphTrainer - INFO -   map@10: 0.022032
2025-12-15 20:06:02 - GraphTrainer - INFO -   mrr@10: 0.023039
2025-12-15 20:06:02 - GraphTrainer - INFO -   precision@20: 0.004783
2025-12-15 20:06:02 - GraphTrainer - INFO -   recall@20: 0.090685
2025-12-15 20:06:02 - GraphTrainer - INFO -   hit_rate@20: 0.095089
2025-12-15 20:06:02 - GraphTrainer - INFO -   ndcg@20: 0.038964
2025-12-15 20:06:02 - GraphTrainer - INFO -   map@20: 0.024305
2025-12-15 20:06:02 - GraphTrainer - INFO -   mrr@20: 0.025413
2025-12-15 20:06:02 - GraphTrainer - INFO - 第 82 轮训练完成
2025-12-15 20:06:02 - GraphTrainer - INFO - train_loss: 0.202311
2025-12-15 20:06:02 - GraphTrainer - INFO - precision@5: 0.007406
2025-12-15 20:06:02 - GraphTrainer - INFO - recall@5: 0.035246
2025-12-15 20:06:02 - GraphTrainer - INFO - hit_rate@5: 0.037028
2025-12-15 20:06:02 - GraphTrainer - INFO - ndcg@5: 0.023320
2025-12-15 20:06:02 - GraphTrainer - INFO - map@5: 0.019133
2025-12-15 20:06:02 - GraphTrainer - INFO - mrr@5: 0.020006
2025-12-15 20:06:02 - GraphTrainer - INFO - precision@10: 0.006058
2025-12-15 20:06:02 - GraphTrainer - INFO - recall@10: 0.057522
2025-12-15 20:06:02 - GraphTrainer - INFO - hit_rate@10: 0.060375
2025-12-15 20:06:02 - GraphTrainer - INFO - ndcg@10: 0.030522
2025-12-15 20:06:02 - GraphTrainer - INFO - map@10: 0.022032
2025-12-15 20:06:02 - GraphTrainer - INFO - mrr@10: 0.023039
2025-12-15 20:06:02 - GraphTrainer - INFO - precision@20: 0.004783
2025-12-15 20:06:02 - GraphTrainer - INFO - recall@20: 0.090685
2025-12-15 20:06:02 - GraphTrainer - INFO - hit_rate@20: 0.095089
2025-12-15 20:06:02 - GraphTrainer - INFO - ndcg@20: 0.038964
2025-12-15 20:06:02 - GraphTrainer - INFO - map@20: 0.024305
2025-12-15 20:06:02 - GraphTrainer - INFO - mrr@20: 0.025413
2025-12-15 20:06:02 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:06:02 - GraphTrainer - INFO - ============================================================
2025-12-15 20:06:02 - GraphTrainer - INFO - 开始第 83/1000 轮训练
2025-12-15 20:06:02 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2106, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.1974, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.1968, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2035, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1928, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.1912, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.1895, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2010, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2004, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.1966, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2145, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.1985, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2040, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2058, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.1964, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1973, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1861, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1901, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2122, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2009, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2270, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2083, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2070, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2094, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.1859, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.1904, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2062, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.1942, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2037, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.1849, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2224, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2070, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2077, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2202, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2220, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1862, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1975, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2274, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2063, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2007, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2078, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.1852, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2013, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2040, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2211, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.1794, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.1726, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2068, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1903, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2027, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2109, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2202, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2181, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2166, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1802, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2182, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.1881, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2106, device='cuda:0', grad_fn=<AddBackward0>)
The 82 training average loss: 0.202310791046455
2025-12-15 20:06:10 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:06:10 - GraphTrainer - INFO -   precision@5: 0.007426
2025-12-15 20:06:10 - GraphTrainer - INFO -   recall@5: 0.035279
2025-12-15 20:06:10 - GraphTrainer - INFO -   hit_rate@5: 0.037130
2025-12-15 20:06:10 - GraphTrainer - INFO -   ndcg@5: 0.023251
2025-12-15 20:06:10 - GraphTrainer - INFO -   map@5: 0.019011
2025-12-15 20:06:10 - GraphTrainer - INFO -   mrr@5: 0.019931
2025-12-15 20:06:10 - GraphTrainer - INFO -   precision@10: 0.006089
2025-12-15 20:06:10 - GraphTrainer - INFO -   recall@10: 0.057596
2025-12-15 20:06:10 - GraphTrainer - INFO -   hit_rate@10: 0.060684
2025-12-15 20:06:10 - GraphTrainer - INFO -   ndcg@10: 0.030469
2025-12-15 20:06:10 - GraphTrainer - INFO -   map@10: 0.021909
2025-12-15 20:06:10 - GraphTrainer - INFO -   mrr@10: 0.022981
2025-12-15 20:06:10 - GraphTrainer - INFO -   precision@20: 0.004747
2025-12-15 20:06:10 - GraphTrainer - INFO -   recall@20: 0.089823
2025-12-15 20:06:10 - GraphTrainer - INFO -   hit_rate@20: 0.094369
2025-12-15 20:06:10 - GraphTrainer - INFO -   ndcg@20: 0.038668
2025-12-15 20:06:10 - GraphTrainer - INFO -   map@20: 0.024117
2025-12-15 20:06:10 - GraphTrainer - INFO -   mrr@20: 0.025279
2025-12-15 20:06:10 - GraphTrainer - INFO - 第 83 轮训练完成
2025-12-15 20:06:10 - GraphTrainer - INFO - train_loss: 0.198302
2025-12-15 20:06:10 - GraphTrainer - INFO - precision@5: 0.007426
2025-12-15 20:06:10 - GraphTrainer - INFO - recall@5: 0.035279
2025-12-15 20:06:10 - GraphTrainer - INFO - hit_rate@5: 0.037130
2025-12-15 20:06:10 - GraphTrainer - INFO - ndcg@5: 0.023251
2025-12-15 20:06:10 - GraphTrainer - INFO - map@5: 0.019011
2025-12-15 20:06:10 - GraphTrainer - INFO - mrr@5: 0.019931
2025-12-15 20:06:10 - GraphTrainer - INFO - precision@10: 0.006089
2025-12-15 20:06:10 - GraphTrainer - INFO - recall@10: 0.057596
2025-12-15 20:06:10 - GraphTrainer - INFO - hit_rate@10: 0.060684
2025-12-15 20:06:10 - GraphTrainer - INFO - ndcg@10: 0.030469
2025-12-15 20:06:10 - GraphTrainer - INFO - map@10: 0.021909
2025-12-15 20:06:10 - GraphTrainer - INFO - mrr@10: 0.022981
2025-12-15 20:06:10 - GraphTrainer - INFO - precision@20: 0.004747
2025-12-15 20:06:10 - GraphTrainer - INFO - recall@20: 0.089823
2025-12-15 20:06:10 - GraphTrainer - INFO - hit_rate@20: 0.094369
2025-12-15 20:06:10 - GraphTrainer - INFO - ndcg@20: 0.038668
2025-12-15 20:06:10 - GraphTrainer - INFO - map@20: 0.024117
2025-12-15 20:06:10 - GraphTrainer - INFO - mrr@20: 0.025279
2025-12-15 20:06:10 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:06:10 - GraphTrainer - INFO - ============================================================
2025-12-15 20:06:10 - GraphTrainer - INFO - 开始第 84/1000 轮训练
2025-12-15 20:06:10 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1900, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.1806, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2135, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2015, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2092, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2022, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2011, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.1835, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1833, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2028, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1759, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2019, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1962, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.1820, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.1954, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2007, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2144, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2009, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2021, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.1775, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1960, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1949, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2107, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2102, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2123, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2197, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2176, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2161, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.1748, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.1842, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2019, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.1955, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2118, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1876, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2086, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1981, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1755, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.1944, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.1877, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.1965, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2049, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2108, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2062, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2124, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.1788, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2055, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.1932, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2086, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2068, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.1920, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.1977, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.1876, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2072, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2041, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2039, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.1817, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2081, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.1832, device='cuda:0', grad_fn=<AddBackward0>)
The 83 training average loss: 0.19830165340982633
2025-12-15 20:06:18 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:06:18 - GraphTrainer - INFO -   precision@5: 0.007560
2025-12-15 20:06:18 - GraphTrainer - INFO -   recall@5: 0.035961
2025-12-15 20:06:18 - GraphTrainer - INFO -   hit_rate@5: 0.037799
2025-12-15 20:06:18 - GraphTrainer - INFO -   ndcg@5: 0.023658
2025-12-15 20:06:18 - GraphTrainer - INFO -   map@5: 0.019333
2025-12-15 20:06:18 - GraphTrainer - INFO -   mrr@5: 0.020228
2025-12-15 20:06:18 - GraphTrainer - INFO -   precision@10: 0.006084
2025-12-15 20:06:18 - GraphTrainer - INFO -   recall@10: 0.057863
2025-12-15 20:06:18 - GraphTrainer - INFO -   hit_rate@10: 0.060684
2025-12-15 20:06:18 - GraphTrainer - INFO -   ndcg@10: 0.030700
2025-12-15 20:06:18 - GraphTrainer - INFO -   map@10: 0.022149
2025-12-15 20:06:18 - GraphTrainer - INFO -   mrr@10: 0.023170
2025-12-15 20:06:18 - GraphTrainer - INFO -   precision@20: 0.004832
2025-12-15 20:06:18 - GraphTrainer - INFO -   recall@20: 0.091520
2025-12-15 20:06:18 - GraphTrainer - INFO -   hit_rate@20: 0.095963
2025-12-15 20:06:18 - GraphTrainer - INFO -   ndcg@20: 0.039268
2025-12-15 20:06:18 - GraphTrainer - INFO -   map@20: 0.024453
2025-12-15 20:06:18 - GraphTrainer - INFO -   mrr@20: 0.025573
2025-12-15 20:06:18 - GraphTrainer - INFO - 第 84 轮训练完成
2025-12-15 20:06:18 - GraphTrainer - INFO - train_loss: 0.197956
2025-12-15 20:06:18 - GraphTrainer - INFO - precision@5: 0.007560
2025-12-15 20:06:18 - GraphTrainer - INFO - recall@5: 0.035961
2025-12-15 20:06:18 - GraphTrainer - INFO - hit_rate@5: 0.037799
2025-12-15 20:06:18 - GraphTrainer - INFO - ndcg@5: 0.023658
2025-12-15 20:06:18 - GraphTrainer - INFO - map@5: 0.019333
2025-12-15 20:06:18 - GraphTrainer - INFO - mrr@5: 0.020228
2025-12-15 20:06:18 - GraphTrainer - INFO - precision@10: 0.006084
2025-12-15 20:06:18 - GraphTrainer - INFO - recall@10: 0.057863
2025-12-15 20:06:18 - GraphTrainer - INFO - hit_rate@10: 0.060684
2025-12-15 20:06:18 - GraphTrainer - INFO - ndcg@10: 0.030700
2025-12-15 20:06:18 - GraphTrainer - INFO - map@10: 0.022149
2025-12-15 20:06:18 - GraphTrainer - INFO - mrr@10: 0.023170
2025-12-15 20:06:18 - GraphTrainer - INFO - precision@20: 0.004832
2025-12-15 20:06:18 - GraphTrainer - INFO - recall@20: 0.091520
2025-12-15 20:06:18 - GraphTrainer - INFO - hit_rate@20: 0.095963
2025-12-15 20:06:18 - GraphTrainer - INFO - ndcg@20: 0.039268
2025-12-15 20:06:18 - GraphTrainer - INFO - map@20: 0.024453
2025-12-15 20:06:18 - GraphTrainer - INFO - mrr@20: 0.025573
2025-12-15 20:06:18 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:06:18 - GraphTrainer - INFO - ============================================================
2025-12-15 20:06:18 - GraphTrainer - INFO - 开始第 85/1000 轮训练
2025-12-15 20:06:18 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1989, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2025, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.1908, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.1973, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1934, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2034, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2001, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2067, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1758, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2167, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1895, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.1745, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1903, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2072, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2040, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1999, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1903, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2184, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2074, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2040, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1982, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1866, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2067, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.1869, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2077, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.1984, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.1760, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2039, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2133, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.1784, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.1820, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2063, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.1958, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1863, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1942, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1913, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2063, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2001, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2078, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2154, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2034, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2092, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2255, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.1938, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.1843, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2010, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2035, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.1847, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1824, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.1942, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2016, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2049, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.1975, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2108, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1957, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2035, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.1962, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.1762, device='cuda:0', grad_fn=<AddBackward0>)
The 84 training average loss: 0.19795606901933407
2025-12-15 20:06:26 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:06:26 - GraphTrainer - INFO -   precision@5: 0.007395
2025-12-15 20:06:26 - GraphTrainer - INFO -   recall@5: 0.035180
2025-12-15 20:06:26 - GraphTrainer - INFO -   hit_rate@5: 0.036976
2025-12-15 20:06:26 - GraphTrainer - INFO -   ndcg@5: 0.023554
2025-12-15 20:06:26 - GraphTrainer - INFO -   map@5: 0.019470
2025-12-15 20:06:26 - GraphTrainer - INFO -   mrr@5: 0.020324
2025-12-15 20:06:26 - GraphTrainer - INFO -   precision@10: 0.006007
2025-12-15 20:06:26 - GraphTrainer - INFO -   recall@10: 0.056869
2025-12-15 20:06:26 - GraphTrainer - INFO -   hit_rate@10: 0.059964
2025-12-15 20:06:26 - GraphTrainer - INFO -   ndcg@10: 0.030613
2025-12-15 20:06:26 - GraphTrainer - INFO -   map@10: 0.022327
2025-12-15 20:06:26 - GraphTrainer - INFO -   mrr@10: 0.023342
2025-12-15 20:06:26 - GraphTrainer - INFO -   precision@20: 0.004883
2025-12-15 20:06:26 - GraphTrainer - INFO -   recall@20: 0.092362
2025-12-15 20:06:26 - GraphTrainer - INFO -   hit_rate@20: 0.097094
2025-12-15 20:06:26 - GraphTrainer - INFO -   ndcg@20: 0.039639
2025-12-15 20:06:26 - GraphTrainer - INFO -   map@20: 0.024752
2025-12-15 20:06:26 - GraphTrainer - INFO -   mrr@20: 0.025868
2025-12-15 20:06:26 - GraphTrainer - INFO - 第 85 轮训练完成
2025-12-15 20:06:26 - GraphTrainer - INFO - train_loss: 0.199871
2025-12-15 20:06:26 - GraphTrainer - INFO - precision@5: 0.007395
2025-12-15 20:06:26 - GraphTrainer - INFO - recall@5: 0.035180
2025-12-15 20:06:26 - GraphTrainer - INFO - hit_rate@5: 0.036976
2025-12-15 20:06:26 - GraphTrainer - INFO - ndcg@5: 0.023554
2025-12-15 20:06:26 - GraphTrainer - INFO - map@5: 0.019470
2025-12-15 20:06:26 - GraphTrainer - INFO - mrr@5: 0.020324
2025-12-15 20:06:26 - GraphTrainer - INFO - precision@10: 0.006007
2025-12-15 20:06:26 - GraphTrainer - INFO - recall@10: 0.056869
2025-12-15 20:06:26 - GraphTrainer - INFO - hit_rate@10: 0.059964
2025-12-15 20:06:26 - GraphTrainer - INFO - ndcg@10: 0.030613
2025-12-15 20:06:26 - GraphTrainer - INFO - map@10: 0.022327
2025-12-15 20:06:26 - GraphTrainer - INFO - mrr@10: 0.023342
2025-12-15 20:06:26 - GraphTrainer - INFO - precision@20: 0.004883
2025-12-15 20:06:26 - GraphTrainer - INFO - recall@20: 0.092362
2025-12-15 20:06:26 - GraphTrainer - INFO - hit_rate@20: 0.097094
2025-12-15 20:06:26 - GraphTrainer - INFO - ndcg@20: 0.039639
2025-12-15 20:06:26 - GraphTrainer - INFO - map@20: 0.024752
2025-12-15 20:06:26 - GraphTrainer - INFO - mrr@20: 0.025868
2025-12-15 20:06:26 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:06:26 - GraphTrainer - INFO - ============================================================
2025-12-15 20:06:26 - GraphTrainer - INFO - 开始第 86/1000 轮训练
2025-12-15 20:06:26 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2006, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.1873, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.1871, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2023, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2203, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.1981, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2022, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2026, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1994, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.1969, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1934, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2086, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1870, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.1880, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2121, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1672, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2030, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2030, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2082, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2158, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1946, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1856, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2198, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2090, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2195, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2071, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.1914, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.1968, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2020, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.1966, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2120, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2029, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.1898, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2113, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2154, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1901, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1985, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2055, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.1889, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.1960, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2039, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.1954, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.1775, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.1931, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.1856, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.1960, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.1995, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2009, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2000, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2106, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.1941, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.1987, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2088, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2097, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1952, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2122, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2031, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.1923, device='cuda:0', grad_fn=<AddBackward0>)
The 85 training average loss: 0.19987072615787901
2025-12-15 20:06:34 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:06:34 - GraphTrainer - INFO -   precision@5: 0.007375
2025-12-15 20:06:34 - GraphTrainer - INFO -   recall@5: 0.035234
2025-12-15 20:06:34 - GraphTrainer - INFO -   hit_rate@5: 0.036873
2025-12-15 20:06:34 - GraphTrainer - INFO -   ndcg@5: 0.023370
2025-12-15 20:06:34 - GraphTrainer - INFO -   map@5: 0.019210
2025-12-15 20:06:34 - GraphTrainer - INFO -   mrr@5: 0.020089
2025-12-15 20:06:34 - GraphTrainer - INFO -   precision@10: 0.006089
2025-12-15 20:06:34 - GraphTrainer - INFO -   recall@10: 0.057566
2025-12-15 20:06:34 - GraphTrainer - INFO -   hit_rate@10: 0.060735
2025-12-15 20:06:34 - GraphTrainer - INFO -   ndcg@10: 0.030638
2025-12-15 20:06:34 - GraphTrainer - INFO -   map@10: 0.022135
2025-12-15 20:06:34 - GraphTrainer - INFO -   mrr@10: 0.023214
2025-12-15 20:06:34 - GraphTrainer - INFO -   precision@20: 0.004806
2025-12-15 20:06:34 - GraphTrainer - INFO -   recall@20: 0.091021
2025-12-15 20:06:34 - GraphTrainer - INFO -   hit_rate@20: 0.095500
2025-12-15 20:06:34 - GraphTrainer - INFO -   ndcg@20: 0.039120
2025-12-15 20:06:34 - GraphTrainer - INFO -   map@20: 0.024410
2025-12-15 20:06:34 - GraphTrainer - INFO -   mrr@20: 0.025568
2025-12-15 20:06:34 - GraphTrainer - INFO - 第 86 轮训练完成
2025-12-15 20:06:34 - GraphTrainer - INFO - train_loss: 0.197638
2025-12-15 20:06:34 - GraphTrainer - INFO - precision@5: 0.007375
2025-12-15 20:06:34 - GraphTrainer - INFO - recall@5: 0.035234
2025-12-15 20:06:34 - GraphTrainer - INFO - hit_rate@5: 0.036873
2025-12-15 20:06:34 - GraphTrainer - INFO - ndcg@5: 0.023370
2025-12-15 20:06:34 - GraphTrainer - INFO - map@5: 0.019210
2025-12-15 20:06:34 - GraphTrainer - INFO - mrr@5: 0.020089
2025-12-15 20:06:34 - GraphTrainer - INFO - precision@10: 0.006089
2025-12-15 20:06:34 - GraphTrainer - INFO - recall@10: 0.057566
2025-12-15 20:06:34 - GraphTrainer - INFO - hit_rate@10: 0.060735
2025-12-15 20:06:34 - GraphTrainer - INFO - ndcg@10: 0.030638
2025-12-15 20:06:34 - GraphTrainer - INFO - map@10: 0.022135
2025-12-15 20:06:34 - GraphTrainer - INFO - mrr@10: 0.023214
2025-12-15 20:06:34 - GraphTrainer - INFO - precision@20: 0.004806
2025-12-15 20:06:34 - GraphTrainer - INFO - recall@20: 0.091021
2025-12-15 20:06:34 - GraphTrainer - INFO - hit_rate@20: 0.095500
2025-12-15 20:06:34 - GraphTrainer - INFO - ndcg@20: 0.039120
2025-12-15 20:06:34 - GraphTrainer - INFO - map@20: 0.024410
2025-12-15 20:06:34 - GraphTrainer - INFO - mrr@20: 0.025568
2025-12-15 20:06:34 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:06:34 - GraphTrainer - INFO - ============================================================
2025-12-15 20:06:34 - GraphTrainer - INFO - 开始第 87/1000 轮训练
2025-12-15 20:06:34 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2032, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2160, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.1865, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2284, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1813, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.1931, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.1960, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.1816, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1945, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.1737, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1804, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.1882, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2067, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.1739, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.1935, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2015, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1996, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1918, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2109, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2061, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2038, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1892, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.1937, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.1888, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2062, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2063, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2102, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.1841, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.1932, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.1869, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2108, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.1806, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.1941, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2115, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2115, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1871, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1829, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2113, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.1995, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.1989, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1894, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2099, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2099, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2025, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2027, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2020, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2001, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.1964, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2300, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2134, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2037, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.1941, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2022, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1740, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1811, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2084, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2010, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.1847, device='cuda:0', grad_fn=<AddBackward0>)
The 86 training average loss: 0.19763795517641922
2025-12-15 20:06:42 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:06:42 - GraphTrainer - INFO -   precision@5: 0.007272
2025-12-15 20:06:42 - GraphTrainer - INFO -   recall@5: 0.034785
2025-12-15 20:06:42 - GraphTrainer - INFO -   hit_rate@5: 0.036308
2025-12-15 20:06:42 - GraphTrainer - INFO -   ndcg@5: 0.023180
2025-12-15 20:06:42 - GraphTrainer - INFO -   map@5: 0.019108
2025-12-15 20:06:42 - GraphTrainer - INFO -   mrr@5: 0.019916
2025-12-15 20:06:42 - GraphTrainer - INFO -   precision@10: 0.006002
2025-12-15 20:06:42 - GraphTrainer - INFO -   recall@10: 0.056832
2025-12-15 20:06:42 - GraphTrainer - INFO -   hit_rate@10: 0.059964
2025-12-15 20:06:42 - GraphTrainer - INFO -   ndcg@10: 0.030384
2025-12-15 20:06:42 - GraphTrainer - INFO -   map@10: 0.022022
2025-12-15 20:06:42 - GraphTrainer - INFO -   mrr@10: 0.023045
2025-12-15 20:06:42 - GraphTrainer - INFO -   precision@20: 0.004837
2025-12-15 20:06:42 - GraphTrainer - INFO -   recall@20: 0.091608
2025-12-15 20:06:42 - GraphTrainer - INFO -   hit_rate@20: 0.096220
2025-12-15 20:06:42 - GraphTrainer - INFO -   ndcg@20: 0.039252
2025-12-15 20:06:42 - GraphTrainer - INFO -   map@20: 0.024423
2025-12-15 20:06:42 - GraphTrainer - INFO -   mrr@20: 0.025539
2025-12-15 20:06:42 - GraphTrainer - INFO - 第 87 轮训练完成
2025-12-15 20:06:42 - GraphTrainer - INFO - train_loss: 0.197523
2025-12-15 20:06:42 - GraphTrainer - INFO - precision@5: 0.007272
2025-12-15 20:06:42 - GraphTrainer - INFO - recall@5: 0.034785
2025-12-15 20:06:42 - GraphTrainer - INFO - hit_rate@5: 0.036308
2025-12-15 20:06:42 - GraphTrainer - INFO - ndcg@5: 0.023180
2025-12-15 20:06:42 - GraphTrainer - INFO - map@5: 0.019108
2025-12-15 20:06:42 - GraphTrainer - INFO - mrr@5: 0.019916
2025-12-15 20:06:42 - GraphTrainer - INFO - precision@10: 0.006002
2025-12-15 20:06:42 - GraphTrainer - INFO - recall@10: 0.056832
2025-12-15 20:06:42 - GraphTrainer - INFO - hit_rate@10: 0.059964
2025-12-15 20:06:42 - GraphTrainer - INFO - ndcg@10: 0.030384
2025-12-15 20:06:42 - GraphTrainer - INFO - map@10: 0.022022
2025-12-15 20:06:42 - GraphTrainer - INFO - mrr@10: 0.023045
2025-12-15 20:06:42 - GraphTrainer - INFO - precision@20: 0.004837
2025-12-15 20:06:42 - GraphTrainer - INFO - recall@20: 0.091608
2025-12-15 20:06:42 - GraphTrainer - INFO - hit_rate@20: 0.096220
2025-12-15 20:06:42 - GraphTrainer - INFO - ndcg@20: 0.039252
2025-12-15 20:06:42 - GraphTrainer - INFO - map@20: 0.024423
2025-12-15 20:06:42 - GraphTrainer - INFO - mrr@20: 0.025539
2025-12-15 20:06:42 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:06:42 - GraphTrainer - INFO - ============================================================
2025-12-15 20:06:42 - GraphTrainer - INFO - 开始第 88/1000 轮训练
2025-12-15 20:06:42 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2137, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.1988, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2017, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2015, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1904, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2012, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2094, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2050, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1886, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.1991, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1926, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.1852, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1854, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.1884, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2100, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2252, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2083, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1865, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.1931, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2000, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1823, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2002, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2007, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2083, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2055, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.1975, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2076, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.1809, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.1882, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2053, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.1798, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2076, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.1877, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2056, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1964, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2008, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1882, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.1946, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2225, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.1856, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1904, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.1840, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2013, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.1839, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.1986, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.1964, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.1926, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2050, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1932, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.1995, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.1916, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2175, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.1962, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1890, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1947, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.1921, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2003, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2004, device='cuda:0', grad_fn=<AddBackward0>)
The 87 training average loss: 0.19752300273755502
2025-12-15 20:06:50 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:06:50 - GraphTrainer - INFO -   precision@5: 0.007251
2025-12-15 20:06:50 - GraphTrainer - INFO -   recall@5: 0.034601
2025-12-15 20:06:50 - GraphTrainer - INFO -   hit_rate@5: 0.036256
2025-12-15 20:06:50 - GraphTrainer - INFO -   ndcg@5: 0.023130
2025-12-15 20:06:50 - GraphTrainer - INFO -   map@5: 0.019098
2025-12-15 20:06:50 - GraphTrainer - INFO -   mrr@5: 0.019966
2025-12-15 20:06:50 - GraphTrainer - INFO -   precision@10: 0.006146
2025-12-15 20:06:50 - GraphTrainer - INFO -   recall@10: 0.058129
2025-12-15 20:06:50 - GraphTrainer - INFO -   hit_rate@10: 0.061250
2025-12-15 20:06:50 - GraphTrainer - INFO -   ndcg@10: 0.030781
2025-12-15 20:06:50 - GraphTrainer - INFO -   map@10: 0.022180
2025-12-15 20:06:50 - GraphTrainer - INFO -   mrr@10: 0.023235
2025-12-15 20:06:50 - GraphTrainer - INFO -   precision@20: 0.004834
2025-12-15 20:06:50 - GraphTrainer - INFO -   recall@20: 0.091360
2025-12-15 20:06:50 - GraphTrainer - INFO -   hit_rate@20: 0.096117
2025-12-15 20:06:50 - GraphTrainer - INFO -   ndcg@20: 0.039230
2025-12-15 20:06:50 - GraphTrainer - INFO -   map@20: 0.024448
2025-12-15 20:06:50 - GraphTrainer - INFO -   mrr@20: 0.025607
2025-12-15 20:06:50 - GraphTrainer - INFO - 第 88 轮训练完成
2025-12-15 20:06:50 - GraphTrainer - INFO - train_loss: 0.198025
2025-12-15 20:06:50 - GraphTrainer - INFO - precision@5: 0.007251
2025-12-15 20:06:50 - GraphTrainer - INFO - recall@5: 0.034601
2025-12-15 20:06:50 - GraphTrainer - INFO - hit_rate@5: 0.036256
2025-12-15 20:06:50 - GraphTrainer - INFO - ndcg@5: 0.023130
2025-12-15 20:06:50 - GraphTrainer - INFO - map@5: 0.019098
2025-12-15 20:06:50 - GraphTrainer - INFO - mrr@5: 0.019966
2025-12-15 20:06:50 - GraphTrainer - INFO - precision@10: 0.006146
2025-12-15 20:06:50 - GraphTrainer - INFO - recall@10: 0.058129
2025-12-15 20:06:50 - GraphTrainer - INFO - hit_rate@10: 0.061250
2025-12-15 20:06:50 - GraphTrainer - INFO - ndcg@10: 0.030781
2025-12-15 20:06:50 - GraphTrainer - INFO - map@10: 0.022180
2025-12-15 20:06:50 - GraphTrainer - INFO - mrr@10: 0.023235
2025-12-15 20:06:50 - GraphTrainer - INFO - precision@20: 0.004834
2025-12-15 20:06:50 - GraphTrainer - INFO - recall@20: 0.091360
2025-12-15 20:06:50 - GraphTrainer - INFO - hit_rate@20: 0.096117
2025-12-15 20:06:50 - GraphTrainer - INFO - ndcg@20: 0.039230
2025-12-15 20:06:50 - GraphTrainer - INFO - map@20: 0.024448
2025-12-15 20:06:50 - GraphTrainer - INFO - mrr@20: 0.025607
2025-12-15 20:06:50 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:06:50 - GraphTrainer - INFO - ============================================================
2025-12-15 20:06:50 - GraphTrainer - INFO - 开始第 89/1000 轮训练
2025-12-15 20:06:50 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1908, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.1840, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.1978, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.1923, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2060, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2049, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.1895, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.1995, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1997, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2068, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1774, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.1931, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2216, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.1859, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2025, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1905, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2011, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1914, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.1680, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.1920, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1941, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1998, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2010, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.1979, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2191, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.1974, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2166, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.1979, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.1918, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.1854, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2125, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.1991, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2261, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1995, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1988, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1907, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1978, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.1904, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2075, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2164, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1834, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2128, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.1992, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.1843, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2089, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.1895, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2092, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.1875, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1913, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.1950, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2118, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.1890, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.1893, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1941, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2090, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2081, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.1905, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.1980, device='cuda:0', grad_fn=<AddBackward0>)
The 88 training average loss: 0.19802518728478202
2025-12-15 20:06:58 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:06:58 - GraphTrainer - INFO -   precision@5: 0.007375
2025-12-15 20:06:58 - GraphTrainer - INFO -   recall@5: 0.035151
2025-12-15 20:06:58 - GraphTrainer - INFO -   hit_rate@5: 0.036873
2025-12-15 20:06:58 - GraphTrainer - INFO -   ndcg@5: 0.023421
2025-12-15 20:06:58 - GraphTrainer - INFO -   map@5: 0.019302
2025-12-15 20:06:58 - GraphTrainer - INFO -   mrr@5: 0.020165
2025-12-15 20:06:58 - GraphTrainer - INFO -   precision@10: 0.006068
2025-12-15 20:06:58 - GraphTrainer - INFO -   recall@10: 0.057419
2025-12-15 20:06:58 - GraphTrainer - INFO -   hit_rate@10: 0.060581
2025-12-15 20:06:58 - GraphTrainer - INFO -   ndcg@10: 0.030684
2025-12-15 20:06:58 - GraphTrainer - INFO -   map@10: 0.022242
2025-12-15 20:06:58 - GraphTrainer - INFO -   mrr@10: 0.023288
2025-12-15 20:06:58 - GraphTrainer - INFO -   precision@20: 0.004870
2025-12-15 20:06:58 - GraphTrainer - INFO -   recall@20: 0.092077
2025-12-15 20:06:58 - GraphTrainer - INFO -   hit_rate@20: 0.096786
2025-12-15 20:06:58 - GraphTrainer - INFO -   ndcg@20: 0.039493
2025-12-15 20:06:58 - GraphTrainer - INFO -   map@20: 0.024607
2025-12-15 20:06:58 - GraphTrainer - INFO -   mrr@20: 0.025748
2025-12-15 20:06:58 - GraphTrainer - INFO - 第 89 轮训练完成
2025-12-15 20:06:58 - GraphTrainer - INFO - train_loss: 0.196341
2025-12-15 20:06:58 - GraphTrainer - INFO - precision@5: 0.007375
2025-12-15 20:06:58 - GraphTrainer - INFO - recall@5: 0.035151
2025-12-15 20:06:58 - GraphTrainer - INFO - hit_rate@5: 0.036873
2025-12-15 20:06:58 - GraphTrainer - INFO - ndcg@5: 0.023421
2025-12-15 20:06:58 - GraphTrainer - INFO - map@5: 0.019302
2025-12-15 20:06:58 - GraphTrainer - INFO - mrr@5: 0.020165
2025-12-15 20:06:58 - GraphTrainer - INFO - precision@10: 0.006068
2025-12-15 20:06:58 - GraphTrainer - INFO - recall@10: 0.057419
2025-12-15 20:06:58 - GraphTrainer - INFO - hit_rate@10: 0.060581
2025-12-15 20:06:58 - GraphTrainer - INFO - ndcg@10: 0.030684
2025-12-15 20:06:58 - GraphTrainer - INFO - map@10: 0.022242
2025-12-15 20:06:58 - GraphTrainer - INFO - mrr@10: 0.023288
2025-12-15 20:06:58 - GraphTrainer - INFO - precision@20: 0.004870
2025-12-15 20:06:58 - GraphTrainer - INFO - recall@20: 0.092077
2025-12-15 20:06:58 - GraphTrainer - INFO - hit_rate@20: 0.096786
2025-12-15 20:06:58 - GraphTrainer - INFO - ndcg@20: 0.039493
2025-12-15 20:06:58 - GraphTrainer - INFO - map@20: 0.024607
2025-12-15 20:06:58 - GraphTrainer - INFO - mrr@20: 0.025748
2025-12-15 20:06:58 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:06:58 - GraphTrainer - INFO - ============================================================
2025-12-15 20:06:58 - GraphTrainer - INFO - 开始第 90/1000 轮训练
2025-12-15 20:06:58 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1852, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.1905, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2005, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2100, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1787, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.1979, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.1933, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.1940, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1926, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2005, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1939, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.1916, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1767, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.1943, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2066, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2013, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1881, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1980, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2233, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.1810, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1918, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2090, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2108, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.1990, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.1771, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2146, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2069, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.1998, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2002, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.1945, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.1799, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.1897, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.1902, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1843, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1854, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1915, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2086, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2151, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.1779, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2070, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1834, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.1934, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.1896, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2050, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2071, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2049, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.1944, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.1919, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2036, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2095, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.1907, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.1906, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.1640, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2165, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1720, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2100, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.1974, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2324, device='cuda:0', grad_fn=<AddBackward0>)
The 89 training average loss: 0.19634094577411126
2025-12-15 20:07:06 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:07:06 - GraphTrainer - INFO -   precision@5: 0.007251
2025-12-15 20:07:06 - GraphTrainer - INFO -   recall@5: 0.034473
2025-12-15 20:07:06 - GraphTrainer - INFO -   hit_rate@5: 0.036256
2025-12-15 20:07:06 - GraphTrainer - INFO -   ndcg@5: 0.023249
2025-12-15 20:07:06 - GraphTrainer - INFO -   map@5: 0.019274
2025-12-15 20:07:06 - GraphTrainer - INFO -   mrr@5: 0.020130
2025-12-15 20:07:06 - GraphTrainer - INFO -   precision@10: 0.006027
2025-12-15 20:07:06 - GraphTrainer - INFO -   recall@10: 0.057066
2025-12-15 20:07:06 - GraphTrainer - INFO -   hit_rate@10: 0.060118
2025-12-15 20:07:06 - GraphTrainer - INFO -   ndcg@10: 0.030606
2025-12-15 20:07:06 - GraphTrainer - INFO -   map@10: 0.022256
2025-12-15 20:07:06 - GraphTrainer - INFO -   mrr@10: 0.023276
2025-12-15 20:07:06 - GraphTrainer - INFO -   precision@20: 0.004808
2025-12-15 20:07:06 - GraphTrainer - INFO -   recall@20: 0.091003
2025-12-15 20:07:06 - GraphTrainer - INFO -   hit_rate@20: 0.095500
2025-12-15 20:07:06 - GraphTrainer - INFO -   ndcg@20: 0.039263
2025-12-15 20:07:06 - GraphTrainer - INFO -   map@20: 0.024601
2025-12-15 20:07:06 - GraphTrainer - INFO -   mrr@20: 0.025713
2025-12-15 20:07:06 - GraphTrainer - INFO - 第 90 轮训练完成
2025-12-15 20:07:06 - GraphTrainer - INFO - train_loss: 0.197567
2025-12-15 20:07:06 - GraphTrainer - INFO - precision@5: 0.007251
2025-12-15 20:07:06 - GraphTrainer - INFO - recall@5: 0.034473
2025-12-15 20:07:06 - GraphTrainer - INFO - hit_rate@5: 0.036256
2025-12-15 20:07:06 - GraphTrainer - INFO - ndcg@5: 0.023249
2025-12-15 20:07:06 - GraphTrainer - INFO - map@5: 0.019274
2025-12-15 20:07:06 - GraphTrainer - INFO - mrr@5: 0.020130
2025-12-15 20:07:06 - GraphTrainer - INFO - precision@10: 0.006027
2025-12-15 20:07:06 - GraphTrainer - INFO - recall@10: 0.057066
2025-12-15 20:07:06 - GraphTrainer - INFO - hit_rate@10: 0.060118
2025-12-15 20:07:06 - GraphTrainer - INFO - ndcg@10: 0.030606
2025-12-15 20:07:06 - GraphTrainer - INFO - map@10: 0.022256
2025-12-15 20:07:06 - GraphTrainer - INFO - mrr@10: 0.023276
2025-12-15 20:07:06 - GraphTrainer - INFO - precision@20: 0.004808
2025-12-15 20:07:06 - GraphTrainer - INFO - recall@20: 0.091003
2025-12-15 20:07:06 - GraphTrainer - INFO - hit_rate@20: 0.095500
2025-12-15 20:07:06 - GraphTrainer - INFO - ndcg@20: 0.039263
2025-12-15 20:07:06 - GraphTrainer - INFO - map@20: 0.024601
2025-12-15 20:07:06 - GraphTrainer - INFO - mrr@20: 0.025713
2025-12-15 20:07:06 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:07:06 - GraphTrainer - INFO - 检查点已保存: Epoch 90 -> ./checkpoints/checkpoint_epoch_90.pth
2025-12-15 20:07:06 - GraphTrainer - INFO - ============================================================
2025-12-15 20:07:06 - GraphTrainer - INFO - 开始第 91/1000 轮训练
2025-12-15 20:07:06 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1829, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.1940, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.1910, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2023, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1803, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.1847, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2069, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.1733, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1909, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.1990, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2114, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2122, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2021, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2057, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2015, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1978, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1949, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1886, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.1897, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.1998, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1970, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1990, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.1955, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2257, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.1841, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.1871, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2059, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.1790, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2179, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2015, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.1922, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.1935, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.1956, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1942, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1968, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1962, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2152, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.1782, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2061, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.1985, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2049, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.1851, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2220, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2131, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.1773, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.1897, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.1993, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2012, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2003, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2045, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2007, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.1873, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2065, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1932, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2013, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.1932, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2112, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.1997, device='cuda:0', grad_fn=<AddBackward0>)
The 90 training average loss: 0.19756669782359024
2025-12-15 20:07:14 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:07:14 - GraphTrainer - INFO -   precision@5: 0.007508
2025-12-15 20:07:14 - GraphTrainer - INFO -   recall@5: 0.035700
2025-12-15 20:07:14 - GraphTrainer - INFO -   hit_rate@5: 0.037542
2025-12-15 20:07:14 - GraphTrainer - INFO -   ndcg@5: 0.023593
2025-12-15 20:07:14 - GraphTrainer - INFO -   map@5: 0.019344
2025-12-15 20:07:14 - GraphTrainer - INFO -   mrr@5: 0.020230
2025-12-15 20:07:14 - GraphTrainer - INFO -   precision@10: 0.006161
2025-12-15 20:07:14 - GraphTrainer - INFO -   recall@10: 0.058360
2025-12-15 20:07:14 - GraphTrainer - INFO -   hit_rate@10: 0.061404
2025-12-15 20:07:14 - GraphTrainer - INFO -   ndcg@10: 0.030913
2025-12-15 20:07:14 - GraphTrainer - INFO -   map@10: 0.022280
2025-12-15 20:07:14 - GraphTrainer - INFO -   mrr@10: 0.023310
2025-12-15 20:07:14 - GraphTrainer - INFO -   precision@20: 0.004814
2025-12-15 20:07:14 - GraphTrainer - INFO -   recall@20: 0.090952
2025-12-15 20:07:14 - GraphTrainer - INFO -   hit_rate@20: 0.095603
2025-12-15 20:07:14 - GraphTrainer - INFO -   ndcg@20: 0.039212
2025-12-15 20:07:14 - GraphTrainer - INFO -   map@20: 0.024511
2025-12-15 20:07:14 - GraphTrainer - INFO -   mrr@20: 0.025648
2025-12-15 20:07:14 - GraphTrainer - INFO - 第 91 轮训练完成
2025-12-15 20:07:14 - GraphTrainer - INFO - train_loss: 0.194579
2025-12-15 20:07:14 - GraphTrainer - INFO - precision@5: 0.007508
2025-12-15 20:07:14 - GraphTrainer - INFO - recall@5: 0.035700
2025-12-15 20:07:14 - GraphTrainer - INFO - hit_rate@5: 0.037542
2025-12-15 20:07:14 - GraphTrainer - INFO - ndcg@5: 0.023593
2025-12-15 20:07:14 - GraphTrainer - INFO - map@5: 0.019344
2025-12-15 20:07:14 - GraphTrainer - INFO - mrr@5: 0.020230
2025-12-15 20:07:14 - GraphTrainer - INFO - precision@10: 0.006161
2025-12-15 20:07:14 - GraphTrainer - INFO - recall@10: 0.058360
2025-12-15 20:07:14 - GraphTrainer - INFO - hit_rate@10: 0.061404
2025-12-15 20:07:14 - GraphTrainer - INFO - ndcg@10: 0.030913
2025-12-15 20:07:14 - GraphTrainer - INFO - map@10: 0.022280
2025-12-15 20:07:14 - GraphTrainer - INFO - mrr@10: 0.023310
2025-12-15 20:07:14 - GraphTrainer - INFO - precision@20: 0.004814
2025-12-15 20:07:14 - GraphTrainer - INFO - recall@20: 0.090952
2025-12-15 20:07:14 - GraphTrainer - INFO - hit_rate@20: 0.095603
2025-12-15 20:07:14 - GraphTrainer - INFO - ndcg@20: 0.039212
2025-12-15 20:07:14 - GraphTrainer - INFO - map@20: 0.024511
2025-12-15 20:07:14 - GraphTrainer - INFO - mrr@20: 0.025648
2025-12-15 20:07:14 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:07:14 - GraphTrainer - INFO - ============================================================
2025-12-15 20:07:14 - GraphTrainer - INFO - 开始第 92/1000 轮训练
2025-12-15 20:07:14 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2084, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.1999, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.1620, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.1825, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1878, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.1938, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2054, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2138, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1907, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2018, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1979, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2195, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1926, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.1802, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.1997, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1913, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1777, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1779, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.1997, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.1917, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1815, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1971, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2126, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.1858, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.1945, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.1882, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2049, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.1953, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.1866, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2016, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.1954, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2131, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2010, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2030, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1855, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1785, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1728, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.1833, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2021, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.1920, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1916, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2067, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.1987, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2081, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2069, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.1777, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.1838, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.1831, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2095, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.1942, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.1824, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2053, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2048, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1969, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1818, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2076, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.1921, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2054, device='cuda:0', grad_fn=<AddBackward0>)
The 91 training average loss: 0.19457865840402142
2025-12-15 20:07:22 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:07:22 - GraphTrainer - INFO -   precision@5: 0.007436
2025-12-15 20:07:22 - GraphTrainer - INFO -   recall@5: 0.035382
2025-12-15 20:07:22 - GraphTrainer - INFO -   hit_rate@5: 0.037182
2025-12-15 20:07:22 - GraphTrainer - INFO -   ndcg@5: 0.023655
2025-12-15 20:07:22 - GraphTrainer - INFO -   map@5: 0.019536
2025-12-15 20:07:22 - GraphTrainer - INFO -   mrr@5: 0.020407
2025-12-15 20:07:22 - GraphTrainer - INFO -   precision@10: 0.006068
2025-12-15 20:07:22 - GraphTrainer - INFO -   recall@10: 0.057539
2025-12-15 20:07:22 - GraphTrainer - INFO -   hit_rate@10: 0.060478
2025-12-15 20:07:22 - GraphTrainer - INFO -   ndcg@10: 0.030832
2025-12-15 20:07:22 - GraphTrainer - INFO -   map@10: 0.022430
2025-12-15 20:07:22 - GraphTrainer - INFO -   mrr@10: 0.023439
2025-12-15 20:07:22 - GraphTrainer - INFO -   precision@20: 0.004752
2025-12-15 20:07:22 - GraphTrainer - INFO -   recall@20: 0.089763
2025-12-15 20:07:22 - GraphTrainer - INFO -   hit_rate@20: 0.094369
2025-12-15 20:07:22 - GraphTrainer - INFO -   ndcg@20: 0.039035
2025-12-15 20:07:22 - GraphTrainer - INFO -   map@20: 0.024630
2025-12-15 20:07:22 - GraphTrainer - INFO -   mrr@20: 0.025748
2025-12-15 20:07:22 - GraphTrainer - INFO - 第 92 轮训练完成
2025-12-15 20:07:22 - GraphTrainer - INFO - train_loss: 0.195911
2025-12-15 20:07:22 - GraphTrainer - INFO - precision@5: 0.007436
2025-12-15 20:07:22 - GraphTrainer - INFO - recall@5: 0.035382
2025-12-15 20:07:22 - GraphTrainer - INFO - hit_rate@5: 0.037182
2025-12-15 20:07:22 - GraphTrainer - INFO - ndcg@5: 0.023655
2025-12-15 20:07:22 - GraphTrainer - INFO - map@5: 0.019536
2025-12-15 20:07:22 - GraphTrainer - INFO - mrr@5: 0.020407
2025-12-15 20:07:22 - GraphTrainer - INFO - precision@10: 0.006068
2025-12-15 20:07:22 - GraphTrainer - INFO - recall@10: 0.057539
2025-12-15 20:07:22 - GraphTrainer - INFO - hit_rate@10: 0.060478
2025-12-15 20:07:22 - GraphTrainer - INFO - ndcg@10: 0.030832
2025-12-15 20:07:22 - GraphTrainer - INFO - map@10: 0.022430
2025-12-15 20:07:22 - GraphTrainer - INFO - mrr@10: 0.023439
2025-12-15 20:07:22 - GraphTrainer - INFO - precision@20: 0.004752
2025-12-15 20:07:22 - GraphTrainer - INFO - recall@20: 0.089763
2025-12-15 20:07:22 - GraphTrainer - INFO - hit_rate@20: 0.094369
2025-12-15 20:07:22 - GraphTrainer - INFO - ndcg@20: 0.039035
2025-12-15 20:07:22 - GraphTrainer - INFO - map@20: 0.024630
2025-12-15 20:07:22 - GraphTrainer - INFO - mrr@20: 0.025748
2025-12-15 20:07:22 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:07:22 - GraphTrainer - INFO - ============================================================
2025-12-15 20:07:22 - GraphTrainer - INFO - 开始第 93/1000 轮训练
2025-12-15 20:07:22 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1656, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2112, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2061, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.1802, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2225, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.1848, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2060, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.1916, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1999, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.1922, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1762, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2075, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1984, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.1995, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.1849, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2040, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1902, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1877, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2117, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.1969, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2004, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1931, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.1881, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.1838, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.1979, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2086, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.1992, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2084, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.1992, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.1877, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.1977, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2069, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.1918, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1966, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1938, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1734, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1956, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.1943, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.1938, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.1912, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1879, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.1915, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.1989, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.1800, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2038, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2045, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.1761, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2006, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2267, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.1774, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2066, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.1975, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.1984, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1926, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2045, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.1840, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.1981, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2154, device='cuda:0', grad_fn=<AddBackward0>)
The 92 training average loss: 0.19591108709573746
2025-12-15 20:07:30 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:07:30 - GraphTrainer - INFO -   precision@5: 0.007272
2025-12-15 20:07:30 - GraphTrainer - INFO -   recall@5: 0.034681
2025-12-15 20:07:30 - GraphTrainer - INFO -   hit_rate@5: 0.036359
2025-12-15 20:07:30 - GraphTrainer - INFO -   ndcg@5: 0.023351
2025-12-15 20:07:30 - GraphTrainer - INFO -   map@5: 0.019363
2025-12-15 20:07:30 - GraphTrainer - INFO -   mrr@5: 0.020182
2025-12-15 20:07:30 - GraphTrainer - INFO -   precision@10: 0.006099
2025-12-15 20:07:30 - GraphTrainer - INFO -   recall@10: 0.057773
2025-12-15 20:07:30 - GraphTrainer - INFO -   hit_rate@10: 0.060838
2025-12-15 20:07:30 - GraphTrainer - INFO -   ndcg@10: 0.030849
2025-12-15 20:07:30 - GraphTrainer - INFO -   map@10: 0.022384
2025-12-15 20:07:30 - GraphTrainer - INFO -   mrr@10: 0.023377
2025-12-15 20:07:30 - GraphTrainer - INFO -   precision@20: 0.004747
2025-12-15 20:07:30 - GraphTrainer - INFO -   recall@20: 0.089574
2025-12-15 20:07:30 - GraphTrainer - INFO -   hit_rate@20: 0.094163
2025-12-15 20:07:30 - GraphTrainer - INFO -   ndcg@20: 0.038937
2025-12-15 20:07:30 - GraphTrainer - INFO -   map@20: 0.024552
2025-12-15 20:07:30 - GraphTrainer - INFO -   mrr@20: 0.025640
2025-12-15 20:07:30 - GraphTrainer - INFO - 第 93 轮训练完成
2025-12-15 20:07:30 - GraphTrainer - INFO - train_loss: 0.196298
2025-12-15 20:07:30 - GraphTrainer - INFO - precision@5: 0.007272
2025-12-15 20:07:30 - GraphTrainer - INFO - recall@5: 0.034681
2025-12-15 20:07:30 - GraphTrainer - INFO - hit_rate@5: 0.036359
2025-12-15 20:07:30 - GraphTrainer - INFO - ndcg@5: 0.023351
2025-12-15 20:07:30 - GraphTrainer - INFO - map@5: 0.019363
2025-12-15 20:07:30 - GraphTrainer - INFO - mrr@5: 0.020182
2025-12-15 20:07:30 - GraphTrainer - INFO - precision@10: 0.006099
2025-12-15 20:07:30 - GraphTrainer - INFO - recall@10: 0.057773
2025-12-15 20:07:30 - GraphTrainer - INFO - hit_rate@10: 0.060838
2025-12-15 20:07:30 - GraphTrainer - INFO - ndcg@10: 0.030849
2025-12-15 20:07:30 - GraphTrainer - INFO - map@10: 0.022384
2025-12-15 20:07:30 - GraphTrainer - INFO - mrr@10: 0.023377
2025-12-15 20:07:30 - GraphTrainer - INFO - precision@20: 0.004747
2025-12-15 20:07:30 - GraphTrainer - INFO - recall@20: 0.089574
2025-12-15 20:07:30 - GraphTrainer - INFO - hit_rate@20: 0.094163
2025-12-15 20:07:30 - GraphTrainer - INFO - ndcg@20: 0.038937
2025-12-15 20:07:30 - GraphTrainer - INFO - map@20: 0.024552
2025-12-15 20:07:30 - GraphTrainer - INFO - mrr@20: 0.025640
2025-12-15 20:07:30 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:07:30 - GraphTrainer - INFO - ============================================================
2025-12-15 20:07:30 - GraphTrainer - INFO - 开始第 94/1000 轮训练
2025-12-15 20:07:30 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1957, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.1903, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2172, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.1902, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1805, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2071, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.1976, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.1908, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2081, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2093, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2084, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2004, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2097, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.1967, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.1875, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1886, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2048, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1979, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.1849, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.1956, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1909, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1794, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.1929, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2178, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2052, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.1941, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.1863, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.1953, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.1872, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2223, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.1883, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.1990, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.1974, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2007, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1919, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1781, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1941, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.1947, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2003, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.1965, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1726, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.1803, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.1966, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.1843, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.1813, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2190, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.1864, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2182, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1848, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2004, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.1855, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2077, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.1935, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2092, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2225, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.1875, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.1943, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.1876, device='cuda:0', grad_fn=<AddBackward0>)
The 93 training average loss: 0.19629812959966988
2025-12-15 20:07:38 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:07:38 - GraphTrainer - INFO -   precision@5: 0.007467
2025-12-15 20:07:38 - GraphTrainer - INFO -   recall@5: 0.035516
2025-12-15 20:07:38 - GraphTrainer - INFO -   hit_rate@5: 0.037336
2025-12-15 20:07:38 - GraphTrainer - INFO -   ndcg@5: 0.023505
2025-12-15 20:07:38 - GraphTrainer - INFO -   map@5: 0.019267
2025-12-15 20:07:38 - GraphTrainer - INFO -   mrr@5: 0.020145
2025-12-15 20:07:38 - GraphTrainer - INFO -   precision@10: 0.006104
2025-12-15 20:07:38 - GraphTrainer - INFO -   recall@10: 0.057842
2025-12-15 20:07:38 - GraphTrainer - INFO -   hit_rate@10: 0.060838
2025-12-15 20:07:38 - GraphTrainer - INFO -   ndcg@10: 0.030727
2025-12-15 20:07:38 - GraphTrainer - INFO -   map@10: 0.022171
2025-12-15 20:07:38 - GraphTrainer - INFO -   mrr@10: 0.023197
2025-12-15 20:07:38 - GraphTrainer - INFO -   precision@20: 0.004785
2025-12-15 20:07:38 - GraphTrainer - INFO -   recall@20: 0.090621
2025-12-15 20:07:38 - GraphTrainer - INFO -   hit_rate@20: 0.095037
2025-12-15 20:07:38 - GraphTrainer - INFO -   ndcg@20: 0.039032
2025-12-15 20:07:38 - GraphTrainer - INFO -   map@20: 0.024392
2025-12-15 20:07:38 - GraphTrainer - INFO -   mrr@20: 0.025501
2025-12-15 20:07:38 - GraphTrainer - INFO - 第 94 轮训练完成
2025-12-15 20:07:38 - GraphTrainer - INFO - train_loss: 0.192838
2025-12-15 20:07:38 - GraphTrainer - INFO - precision@5: 0.007467
2025-12-15 20:07:38 - GraphTrainer - INFO - recall@5: 0.035516
2025-12-15 20:07:38 - GraphTrainer - INFO - hit_rate@5: 0.037336
2025-12-15 20:07:38 - GraphTrainer - INFO - ndcg@5: 0.023505
2025-12-15 20:07:38 - GraphTrainer - INFO - map@5: 0.019267
2025-12-15 20:07:38 - GraphTrainer - INFO - mrr@5: 0.020145
2025-12-15 20:07:38 - GraphTrainer - INFO - precision@10: 0.006104
2025-12-15 20:07:38 - GraphTrainer - INFO - recall@10: 0.057842
2025-12-15 20:07:38 - GraphTrainer - INFO - hit_rate@10: 0.060838
2025-12-15 20:07:38 - GraphTrainer - INFO - ndcg@10: 0.030727
2025-12-15 20:07:38 - GraphTrainer - INFO - map@10: 0.022171
2025-12-15 20:07:38 - GraphTrainer - INFO - mrr@10: 0.023197
2025-12-15 20:07:38 - GraphTrainer - INFO - precision@20: 0.004785
2025-12-15 20:07:38 - GraphTrainer - INFO - recall@20: 0.090621
2025-12-15 20:07:38 - GraphTrainer - INFO - hit_rate@20: 0.095037
2025-12-15 20:07:38 - GraphTrainer - INFO - ndcg@20: 0.039032
2025-12-15 20:07:38 - GraphTrainer - INFO - map@20: 0.024392
2025-12-15 20:07:38 - GraphTrainer - INFO - mrr@20: 0.025501
2025-12-15 20:07:38 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:07:38 - GraphTrainer - INFO - ============================================================
2025-12-15 20:07:38 - GraphTrainer - INFO - 开始第 95/1000 轮训练
2025-12-15 20:07:38 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1730, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.1989, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.1926, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.1843, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1929, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.1910, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.1953, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.1998, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1842, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.1958, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1845, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.1941, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1876, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2075, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2138, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1765, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1806, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2019, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.1957, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.1940, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1752, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2041, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.1704, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2023, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.1981, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.1979, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.1846, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.1934, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.1899, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.1945, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2075, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2062, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.1763, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1944, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2070, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1900, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1901, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2036, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.1903, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.1959, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1928, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.1941, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.1937, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.1824, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.1837, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.1902, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.1946, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.1961, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1808, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.1871, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2230, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.1843, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.1922, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1993, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1943, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.1985, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.1801, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2017, device='cuda:0', grad_fn=<AddBackward0>)
The 94 training average loss: 0.19283834819135995
2025-12-15 20:07:46 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:07:46 - GraphTrainer - INFO -   precision@5: 0.007262
2025-12-15 20:07:46 - GraphTrainer - INFO -   recall@5: 0.034534
2025-12-15 20:07:46 - GraphTrainer - INFO -   hit_rate@5: 0.036308
2025-12-15 20:07:46 - GraphTrainer - INFO -   ndcg@5: 0.023107
2025-12-15 20:07:46 - GraphTrainer - INFO -   map@5: 0.019064
2025-12-15 20:07:46 - GraphTrainer - INFO -   mrr@5: 0.019935
2025-12-15 20:07:46 - GraphTrainer - INFO -   precision@10: 0.006017
2025-12-15 20:07:46 - GraphTrainer - INFO -   recall@10: 0.056986
2025-12-15 20:07:46 - GraphTrainer - INFO -   hit_rate@10: 0.059964
2025-12-15 20:07:46 - GraphTrainer - INFO -   ndcg@10: 0.030355
2025-12-15 20:07:46 - GraphTrainer - INFO -   map@10: 0.021969
2025-12-15 20:07:46 - GraphTrainer - INFO -   mrr@10: 0.022989
2025-12-15 20:07:46 - GraphTrainer - INFO -   precision@20: 0.004731
2025-12-15 20:07:46 - GraphTrainer - INFO -   recall@20: 0.089562
2025-12-15 20:07:46 - GraphTrainer - INFO -   hit_rate@20: 0.094112
2025-12-15 20:07:46 - GraphTrainer - INFO -   ndcg@20: 0.038662
2025-12-15 20:07:46 - GraphTrainer - INFO -   map@20: 0.024212
2025-12-15 20:07:46 - GraphTrainer - INFO -   mrr@20: 0.025335
2025-12-15 20:07:46 - GraphTrainer - INFO - 第 95 轮训练完成
2025-12-15 20:07:46 - GraphTrainer - INFO - train_loss: 0.196521
2025-12-15 20:07:46 - GraphTrainer - INFO - precision@5: 0.007262
2025-12-15 20:07:46 - GraphTrainer - INFO - recall@5: 0.034534
2025-12-15 20:07:46 - GraphTrainer - INFO - hit_rate@5: 0.036308
2025-12-15 20:07:46 - GraphTrainer - INFO - ndcg@5: 0.023107
2025-12-15 20:07:46 - GraphTrainer - INFO - map@5: 0.019064
2025-12-15 20:07:46 - GraphTrainer - INFO - mrr@5: 0.019935
2025-12-15 20:07:46 - GraphTrainer - INFO - precision@10: 0.006017
2025-12-15 20:07:46 - GraphTrainer - INFO - recall@10: 0.056986
2025-12-15 20:07:46 - GraphTrainer - INFO - hit_rate@10: 0.059964
2025-12-15 20:07:46 - GraphTrainer - INFO - ndcg@10: 0.030355
2025-12-15 20:07:46 - GraphTrainer - INFO - map@10: 0.021969
2025-12-15 20:07:46 - GraphTrainer - INFO - mrr@10: 0.022989
2025-12-15 20:07:46 - GraphTrainer - INFO - precision@20: 0.004731
2025-12-15 20:07:46 - GraphTrainer - INFO - recall@20: 0.089562
2025-12-15 20:07:46 - GraphTrainer - INFO - hit_rate@20: 0.094112
2025-12-15 20:07:46 - GraphTrainer - INFO - ndcg@20: 0.038662
2025-12-15 20:07:46 - GraphTrainer - INFO - map@20: 0.024212
2025-12-15 20:07:46 - GraphTrainer - INFO - mrr@20: 0.025335
2025-12-15 20:07:46 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:07:46 - GraphTrainer - INFO - ============================================================
2025-12-15 20:07:46 - GraphTrainer - INFO - 开始第 96/1000 轮训练
2025-12-15 20:07:46 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2186, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.1951, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2008, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.1830, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1857, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.1840, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2007, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.1721, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1894, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.1854, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2007, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.1931, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1778, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2087, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.1739, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1898, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2190, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2177, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.1982, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2108, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2064, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1739, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.1904, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2035, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2110, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2132, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.1994, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.1839, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.1811, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.1874, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2099, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2001, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2136, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1958, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1678, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2072, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2039, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.1833, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.1813, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2018, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1970, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.1914, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.1870, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2171, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2016, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.1838, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.1857, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.1880, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1954, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2199, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.1962, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2205, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.1888, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1954, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2038, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2068, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.1932, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2074, device='cuda:0', grad_fn=<AddBackward0>)
The 95 training average loss: 0.19652105431104527
2025-12-15 20:07:54 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:07:54 - GraphTrainer - INFO -   precision@5: 0.007303
2025-12-15 20:07:54 - GraphTrainer - INFO -   recall@5: 0.034796
2025-12-15 20:07:54 - GraphTrainer - INFO -   hit_rate@5: 0.036513
2025-12-15 20:07:54 - GraphTrainer - INFO -   ndcg@5: 0.022877
2025-12-15 20:07:54 - GraphTrainer - INFO -   map@5: 0.018680
2025-12-15 20:07:54 - GraphTrainer - INFO -   mrr@5: 0.019560
2025-12-15 20:07:54 - GraphTrainer - INFO -   precision@10: 0.006048
2025-12-15 20:07:54 - GraphTrainer - INFO -   recall@10: 0.057211
2025-12-15 20:07:54 - GraphTrainer - INFO -   hit_rate@10: 0.060273
2025-12-15 20:07:54 - GraphTrainer - INFO -   ndcg@10: 0.030158
2025-12-15 20:07:54 - GraphTrainer - INFO -   map@10: 0.021615
2025-12-15 20:07:54 - GraphTrainer - INFO -   mrr@10: 0.022666
2025-12-15 20:07:54 - GraphTrainer - INFO -   precision@20: 0.004785
2025-12-15 20:07:54 - GraphTrainer - INFO -   recall@20: 0.090385
2025-12-15 20:07:54 - GraphTrainer - INFO -   hit_rate@20: 0.094934
2025-12-15 20:07:54 - GraphTrainer - INFO -   ndcg@20: 0.038586
2025-12-15 20:07:54 - GraphTrainer - INFO -   map@20: 0.023876
2025-12-15 20:07:54 - GraphTrainer - INFO -   mrr@20: 0.025016
2025-12-15 20:07:54 - GraphTrainer - INFO - 第 96 轮训练完成
2025-12-15 20:07:54 - GraphTrainer - INFO - train_loss: 0.193176
2025-12-15 20:07:54 - GraphTrainer - INFO - precision@5: 0.007303
2025-12-15 20:07:54 - GraphTrainer - INFO - recall@5: 0.034796
2025-12-15 20:07:54 - GraphTrainer - INFO - hit_rate@5: 0.036513
2025-12-15 20:07:54 - GraphTrainer - INFO - ndcg@5: 0.022877
2025-12-15 20:07:54 - GraphTrainer - INFO - map@5: 0.018680
2025-12-15 20:07:54 - GraphTrainer - INFO - mrr@5: 0.019560
2025-12-15 20:07:54 - GraphTrainer - INFO - precision@10: 0.006048
2025-12-15 20:07:54 - GraphTrainer - INFO - recall@10: 0.057211
2025-12-15 20:07:54 - GraphTrainer - INFO - hit_rate@10: 0.060273
2025-12-15 20:07:54 - GraphTrainer - INFO - ndcg@10: 0.030158
2025-12-15 20:07:54 - GraphTrainer - INFO - map@10: 0.021615
2025-12-15 20:07:54 - GraphTrainer - INFO - mrr@10: 0.022666
2025-12-15 20:07:54 - GraphTrainer - INFO - precision@20: 0.004785
2025-12-15 20:07:54 - GraphTrainer - INFO - recall@20: 0.090385
2025-12-15 20:07:54 - GraphTrainer - INFO - hit_rate@20: 0.094934
2025-12-15 20:07:54 - GraphTrainer - INFO - ndcg@20: 0.038586
2025-12-15 20:07:54 - GraphTrainer - INFO - map@20: 0.023876
2025-12-15 20:07:54 - GraphTrainer - INFO - mrr@20: 0.025016
2025-12-15 20:07:54 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:07:54 - GraphTrainer - INFO - ============================================================
2025-12-15 20:07:54 - GraphTrainer - INFO - 开始第 97/1000 轮训练
2025-12-15 20:07:54 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1992, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.1855, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.1836, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.1756, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1966, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.1997, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.1918, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.1833, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1935, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2092, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1942, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.1919, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1910, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.1934, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.1876, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1834, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1917, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1748, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.1741, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2058, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2001, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1885, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.1855, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2026, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2057, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.1946, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.1954, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.1837, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2166, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.1820, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2043, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2053, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2001, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1960, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1722, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2151, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1797, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.1961, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.1872, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2040, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1898, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.1881, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.1842, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.1999, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2068, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.1948, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.1970, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.1730, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1862, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.1946, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.1792, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.1941, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.1796, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2078, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2124, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2016, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2080, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.1862, device='cuda:0', grad_fn=<AddBackward0>)
The 96 training average loss: 0.1931756562713919
2025-12-15 20:08:02 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:08:02 - GraphTrainer - INFO -   precision@5: 0.007334
2025-12-15 20:08:02 - GraphTrainer - INFO -   recall@5: 0.034984
2025-12-15 20:08:02 - GraphTrainer - INFO -   hit_rate@5: 0.036668
2025-12-15 20:08:02 - GraphTrainer - INFO -   ndcg@5: 0.023231
2025-12-15 20:08:02 - GraphTrainer - INFO -   map@5: 0.019102
2025-12-15 20:08:02 - GraphTrainer - INFO -   mrr@5: 0.019953
2025-12-15 20:08:02 - GraphTrainer - INFO -   precision@10: 0.005971
2025-12-15 20:08:02 - GraphTrainer - INFO -   recall@10: 0.056428
2025-12-15 20:08:02 - GraphTrainer - INFO -   hit_rate@10: 0.059553
2025-12-15 20:08:02 - GraphTrainer - INFO -   ndcg@10: 0.030174
2025-12-15 20:08:02 - GraphTrainer - INFO -   map@10: 0.021878
2025-12-15 20:08:02 - GraphTrainer - INFO -   mrr@10: 0.022910
2025-12-15 20:08:02 - GraphTrainer - INFO -   precision@20: 0.004806
2025-12-15 20:08:02 - GraphTrainer - INFO -   recall@20: 0.091067
2025-12-15 20:08:02 - GraphTrainer - INFO -   hit_rate@20: 0.095603
2025-12-15 20:08:02 - GraphTrainer - INFO -   ndcg@20: 0.038999
2025-12-15 20:08:02 - GraphTrainer - INFO -   map@20: 0.024267
2025-12-15 20:08:02 - GraphTrainer - INFO -   mrr@20: 0.025390
2025-12-15 20:08:02 - GraphTrainer - INFO - 第 97 轮训练完成
2025-12-15 20:08:02 - GraphTrainer - INFO - train_loss: 0.191379
2025-12-15 20:08:02 - GraphTrainer - INFO - precision@5: 0.007334
2025-12-15 20:08:02 - GraphTrainer - INFO - recall@5: 0.034984
2025-12-15 20:08:02 - GraphTrainer - INFO - hit_rate@5: 0.036668
2025-12-15 20:08:02 - GraphTrainer - INFO - ndcg@5: 0.023231
2025-12-15 20:08:02 - GraphTrainer - INFO - map@5: 0.019102
2025-12-15 20:08:02 - GraphTrainer - INFO - mrr@5: 0.019953
2025-12-15 20:08:02 - GraphTrainer - INFO - precision@10: 0.005971
2025-12-15 20:08:02 - GraphTrainer - INFO - recall@10: 0.056428
2025-12-15 20:08:02 - GraphTrainer - INFO - hit_rate@10: 0.059553
2025-12-15 20:08:02 - GraphTrainer - INFO - ndcg@10: 0.030174
2025-12-15 20:08:02 - GraphTrainer - INFO - map@10: 0.021878
2025-12-15 20:08:02 - GraphTrainer - INFO - mrr@10: 0.022910
2025-12-15 20:08:02 - GraphTrainer - INFO - precision@20: 0.004806
2025-12-15 20:08:02 - GraphTrainer - INFO - recall@20: 0.091067
2025-12-15 20:08:02 - GraphTrainer - INFO - hit_rate@20: 0.095603
2025-12-15 20:08:02 - GraphTrainer - INFO - ndcg@20: 0.038999
2025-12-15 20:08:02 - GraphTrainer - INFO - map@20: 0.024267
2025-12-15 20:08:02 - GraphTrainer - INFO - mrr@20: 0.025390
2025-12-15 20:08:02 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:08:02 - GraphTrainer - INFO - ============================================================
2025-12-15 20:08:02 - GraphTrainer - INFO - 开始第 98/1000 轮训练
2025-12-15 20:08:02 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1962, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.1888, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.1802, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.1914, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1992, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2102, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.1828, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2039, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2022, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.1900, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1985, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2125, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2139, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2119, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.1861, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2141, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1928, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1955, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.1951, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.1931, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1945, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1936, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.1975, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.1817, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.1817, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.1941, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.1810, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.1693, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.1786, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.1784, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.1799, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.1912, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.1754, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1794, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2120, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1788, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1926, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.1713, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.1787, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.1849, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2033, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.1858, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.1834, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.1950, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2098, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.1898, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.1860, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.1915, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1888, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2112, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.1657, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.1975, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.1680, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2163, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1887, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.1846, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2035, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.1781, device='cuda:0', grad_fn=<AddBackward0>)
The 97 training average loss: 0.19137949034057813
2025-12-15 20:08:11 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:08:11 - GraphTrainer - INFO -   precision@5: 0.007354
2025-12-15 20:08:11 - GraphTrainer - INFO -   recall@5: 0.035066
2025-12-15 20:08:11 - GraphTrainer - INFO -   hit_rate@5: 0.036770
2025-12-15 20:08:11 - GraphTrainer - INFO -   ndcg@5: 0.023422
2025-12-15 20:08:11 - GraphTrainer - INFO -   map@5: 0.019320
2025-12-15 20:08:11 - GraphTrainer - INFO -   mrr@5: 0.020225
2025-12-15 20:08:11 - GraphTrainer - INFO -   precision@10: 0.006007
2025-12-15 20:08:11 - GraphTrainer - INFO -   recall@10: 0.056732
2025-12-15 20:08:11 - GraphTrainer - INFO -   hit_rate@10: 0.059913
2025-12-15 20:08:11 - GraphTrainer - INFO -   ndcg@10: 0.030463
2025-12-15 20:08:11 - GraphTrainer - INFO -   map@10: 0.022148
2025-12-15 20:08:11 - GraphTrainer - INFO -   mrr@10: 0.023248
2025-12-15 20:08:11 - GraphTrainer - INFO -   precision@20: 0.004839
2025-12-15 20:08:11 - GraphTrainer - INFO -   recall@20: 0.091627
2025-12-15 20:08:11 - GraphTrainer - INFO -   hit_rate@20: 0.096220
2025-12-15 20:08:11 - GraphTrainer - INFO -   ndcg@20: 0.039353
2025-12-15 20:08:11 - GraphTrainer - INFO -   map@20: 0.024556
2025-12-15 20:08:11 - GraphTrainer - INFO -   mrr@20: 0.025740
2025-12-15 20:08:11 - GraphTrainer - INFO - 第 98 轮训练完成
2025-12-15 20:08:11 - GraphTrainer - INFO - train_loss: 0.189101
2025-12-15 20:08:11 - GraphTrainer - INFO - precision@5: 0.007354
2025-12-15 20:08:11 - GraphTrainer - INFO - recall@5: 0.035066
2025-12-15 20:08:11 - GraphTrainer - INFO - hit_rate@5: 0.036770
2025-12-15 20:08:11 - GraphTrainer - INFO - ndcg@5: 0.023422
2025-12-15 20:08:11 - GraphTrainer - INFO - map@5: 0.019320
2025-12-15 20:08:11 - GraphTrainer - INFO - mrr@5: 0.020225
2025-12-15 20:08:11 - GraphTrainer - INFO - precision@10: 0.006007
2025-12-15 20:08:11 - GraphTrainer - INFO - recall@10: 0.056732
2025-12-15 20:08:11 - GraphTrainer - INFO - hit_rate@10: 0.059913
2025-12-15 20:08:11 - GraphTrainer - INFO - ndcg@10: 0.030463
2025-12-15 20:08:11 - GraphTrainer - INFO - map@10: 0.022148
2025-12-15 20:08:11 - GraphTrainer - INFO - mrr@10: 0.023248
2025-12-15 20:08:11 - GraphTrainer - INFO - precision@20: 0.004839
2025-12-15 20:08:11 - GraphTrainer - INFO - recall@20: 0.091627
2025-12-15 20:08:11 - GraphTrainer - INFO - hit_rate@20: 0.096220
2025-12-15 20:08:11 - GraphTrainer - INFO - ndcg@20: 0.039353
2025-12-15 20:08:11 - GraphTrainer - INFO - map@20: 0.024556
2025-12-15 20:08:11 - GraphTrainer - INFO - mrr@20: 0.025740
2025-12-15 20:08:11 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:08:11 - GraphTrainer - INFO - ============================================================
2025-12-15 20:08:11 - GraphTrainer - INFO - 开始第 99/1000 轮训练
2025-12-15 20:08:11 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1731, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.1861, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.1875, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.1850, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1809, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2014, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.1883, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.1829, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1892, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.1808, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1748, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.1874, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1914, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2017, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2009, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1844, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1840, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2141, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.1829, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.1738, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1875, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1983, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.1911, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.1967, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.1960, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.1712, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.1888, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.1973, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.1856, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.1750, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2077, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.1965, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.1803, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1696, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1856, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1936, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1895, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.1746, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.1819, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2020, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1896, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.1878, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.1996, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.1799, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2133, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.1675, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.1897, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.1999, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2058, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.1716, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.1989, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.1879, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2008, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1978, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1852, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.1698, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2038, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.1993, device='cuda:0', grad_fn=<AddBackward0>)
The 98 training average loss: 0.1891006087434703
2025-12-15 20:08:19 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:08:19 - GraphTrainer - INFO -   precision@5: 0.007467
2025-12-15 20:08:19 - GraphTrainer - INFO -   recall@5: 0.035534
2025-12-15 20:08:19 - GraphTrainer - INFO -   hit_rate@5: 0.037285
2025-12-15 20:08:19 - GraphTrainer - INFO -   ndcg@5: 0.023562
2025-12-15 20:08:19 - GraphTrainer - INFO -   map@5: 0.019355
2025-12-15 20:08:19 - GraphTrainer - INFO -   mrr@5: 0.020242
2025-12-15 20:08:19 - GraphTrainer - INFO -   precision@10: 0.005976
2025-12-15 20:08:19 - GraphTrainer - INFO -   recall@10: 0.056439
2025-12-15 20:08:19 - GraphTrainer - INFO -   hit_rate@10: 0.059553
2025-12-15 20:08:19 - GraphTrainer - INFO -   ndcg@10: 0.030381
2025-12-15 20:08:19 - GraphTrainer - INFO -   map@10: 0.022115
2025-12-15 20:08:19 - GraphTrainer - INFO -   mrr@10: 0.023183
2025-12-15 20:08:19 - GraphTrainer - INFO -   precision@20: 0.004850
2025-12-15 20:08:19 - GraphTrainer - INFO -   recall@20: 0.091761
2025-12-15 20:08:19 - GraphTrainer - INFO -   hit_rate@20: 0.096272
2025-12-15 20:08:19 - GraphTrainer - INFO -   ndcg@20: 0.039378
2025-12-15 20:08:19 - GraphTrainer - INFO -   map@20: 0.024549
2025-12-15 20:08:19 - GraphTrainer - INFO -   mrr@20: 0.025701
2025-12-15 20:08:19 - GraphTrainer - INFO - 第 99 轮训练完成
2025-12-15 20:08:19 - GraphTrainer - INFO - train_loss: 0.191386
2025-12-15 20:08:19 - GraphTrainer - INFO - precision@5: 0.007467
2025-12-15 20:08:19 - GraphTrainer - INFO - recall@5: 0.035534
2025-12-15 20:08:19 - GraphTrainer - INFO - hit_rate@5: 0.037285
2025-12-15 20:08:19 - GraphTrainer - INFO - ndcg@5: 0.023562
2025-12-15 20:08:19 - GraphTrainer - INFO - map@5: 0.019355
2025-12-15 20:08:19 - GraphTrainer - INFO - mrr@5: 0.020242
2025-12-15 20:08:19 - GraphTrainer - INFO - precision@10: 0.005976
2025-12-15 20:08:19 - GraphTrainer - INFO - recall@10: 0.056439
2025-12-15 20:08:19 - GraphTrainer - INFO - hit_rate@10: 0.059553
2025-12-15 20:08:19 - GraphTrainer - INFO - ndcg@10: 0.030381
2025-12-15 20:08:19 - GraphTrainer - INFO - map@10: 0.022115
2025-12-15 20:08:19 - GraphTrainer - INFO - mrr@10: 0.023183
2025-12-15 20:08:19 - GraphTrainer - INFO - precision@20: 0.004850
2025-12-15 20:08:19 - GraphTrainer - INFO - recall@20: 0.091761
2025-12-15 20:08:19 - GraphTrainer - INFO - hit_rate@20: 0.096272
2025-12-15 20:08:19 - GraphTrainer - INFO - ndcg@20: 0.039378
2025-12-15 20:08:19 - GraphTrainer - INFO - map@20: 0.024549
2025-12-15 20:08:19 - GraphTrainer - INFO - mrr@20: 0.025701
2025-12-15 20:08:19 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:08:19 - GraphTrainer - INFO - ============================================================
2025-12-15 20:08:19 - GraphTrainer - INFO - 开始第 100/1000 轮训练
2025-12-15 20:08:19 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1862, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.1660, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.1917, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.1872, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1862, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.1779, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.1879, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2042, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1941, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.1874, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1981, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.1942, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1756, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2002, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.1906, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2168, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1904, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1908, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.1888, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.1715, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1971, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2046, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2031, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.1939, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2052, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.1947, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2032, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2010, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.1944, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.1917, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.1893, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.1974, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.1925, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1847, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1967, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1800, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1956, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.1992, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.1744, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.1982, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1882, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2002, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.1800, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.1949, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.1911, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.1754, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.1804, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2064, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1866, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.1940, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2115, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.1705, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.1875, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1805, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1884, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2003, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.1860, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.1959, device='cuda:0', grad_fn=<AddBackward0>)
The 99 training average loss: 0.19138551503419876
2025-12-15 20:08:28 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:08:28 - GraphTrainer - INFO -   precision@5: 0.007467
2025-12-15 20:08:28 - GraphTrainer - INFO -   recall@5: 0.035551
2025-12-15 20:08:28 - GraphTrainer - INFO -   hit_rate@5: 0.037285
2025-12-15 20:08:28 - GraphTrainer - INFO -   ndcg@5: 0.023551
2025-12-15 20:08:28 - GraphTrainer - INFO -   map@5: 0.019336
2025-12-15 20:08:28 - GraphTrainer - INFO -   mrr@5: 0.020230
2025-12-15 20:08:28 - GraphTrainer - INFO -   precision@10: 0.006058
2025-12-15 20:08:28 - GraphTrainer - INFO -   recall@10: 0.057091
2025-12-15 20:08:28 - GraphTrainer - INFO -   hit_rate@10: 0.060324
2025-12-15 20:08:28 - GraphTrainer - INFO -   ndcg@10: 0.030528
2025-12-15 20:08:28 - GraphTrainer - INFO -   map@10: 0.022123
2025-12-15 20:08:28 - GraphTrainer - INFO -   mrr@10: 0.023213
2025-12-15 20:08:28 - GraphTrainer - INFO -   precision@20: 0.004862
2025-12-15 20:08:28 - GraphTrainer - INFO -   recall@20: 0.091970
2025-12-15 20:08:28 - GraphTrainer - INFO -   hit_rate@20: 0.096529
2025-12-15 20:08:28 - GraphTrainer - INFO -   ndcg@20: 0.039414
2025-12-15 20:08:28 - GraphTrainer - INFO -   map@20: 0.024532
2025-12-15 20:08:28 - GraphTrainer - INFO -   mrr@20: 0.025700
2025-12-15 20:08:28 - GraphTrainer - INFO - 第 100 轮训练完成
2025-12-15 20:08:28 - GraphTrainer - INFO - train_loss: 0.191070
2025-12-15 20:08:28 - GraphTrainer - INFO - precision@5: 0.007467
2025-12-15 20:08:28 - GraphTrainer - INFO - recall@5: 0.035551
2025-12-15 20:08:28 - GraphTrainer - INFO - hit_rate@5: 0.037285
2025-12-15 20:08:28 - GraphTrainer - INFO - ndcg@5: 0.023551
2025-12-15 20:08:28 - GraphTrainer - INFO - map@5: 0.019336
2025-12-15 20:08:28 - GraphTrainer - INFO - mrr@5: 0.020230
2025-12-15 20:08:28 - GraphTrainer - INFO - precision@10: 0.006058
2025-12-15 20:08:28 - GraphTrainer - INFO - recall@10: 0.057091
2025-12-15 20:08:28 - GraphTrainer - INFO - hit_rate@10: 0.060324
2025-12-15 20:08:28 - GraphTrainer - INFO - ndcg@10: 0.030528
2025-12-15 20:08:28 - GraphTrainer - INFO - map@10: 0.022123
2025-12-15 20:08:28 - GraphTrainer - INFO - mrr@10: 0.023213
2025-12-15 20:08:28 - GraphTrainer - INFO - precision@20: 0.004862
2025-12-15 20:08:28 - GraphTrainer - INFO - recall@20: 0.091970
2025-12-15 20:08:28 - GraphTrainer - INFO - hit_rate@20: 0.096529
2025-12-15 20:08:28 - GraphTrainer - INFO - ndcg@20: 0.039414
2025-12-15 20:08:28 - GraphTrainer - INFO - map@20: 0.024532
2025-12-15 20:08:28 - GraphTrainer - INFO - mrr@20: 0.025700
2025-12-15 20:08:28 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:08:28 - GraphTrainer - INFO - 检查点已保存: Epoch 100 -> ./checkpoints/checkpoint_epoch_100.pth
2025-12-15 20:08:28 - GraphTrainer - INFO - ============================================================
2025-12-15 20:08:28 - GraphTrainer - INFO - 开始第 101/1000 轮训练
2025-12-15 20:08:28 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1745, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.1954, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.1874, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.1986, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1771, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.1894, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.1832, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.1922, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1926, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.1950, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1994, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.1955, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1864, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2089, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.1968, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1737, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2064, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1994, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.1897, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.1789, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1904, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2091, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.1870, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.1850, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2113, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.1757, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.1884, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.1910, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.1730, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2073, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.1888, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.1855, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.1951, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1967, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1965, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2016, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1870, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.1868, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.1955, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.1972, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1857, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2137, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2030, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.1627, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.1851, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.1930, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.1870, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.1961, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1808, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2027, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.1979, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.1992, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.1773, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1903, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1764, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.1819, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.1828, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.1968, device='cuda:0', grad_fn=<AddBackward0>)
The 100 training average loss: 0.1910704852178179
2025-12-15 20:08:36 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:08:36 - GraphTrainer - INFO -   precision@5: 0.007334
2025-12-15 20:08:36 - GraphTrainer - INFO -   recall@5: 0.034798
2025-12-15 20:08:36 - GraphTrainer - INFO -   hit_rate@5: 0.036616
2025-12-15 20:08:36 - GraphTrainer - INFO -   ndcg@5: 0.023348
2025-12-15 20:08:36 - GraphTrainer - INFO -   map@5: 0.019286
2025-12-15 20:08:36 - GraphTrainer - INFO -   mrr@5: 0.020208
2025-12-15 20:08:36 - GraphTrainer - INFO -   precision@10: 0.006171
2025-12-15 20:08:36 - GraphTrainer - INFO -   recall@10: 0.058406
2025-12-15 20:08:36 - GraphTrainer - INFO -   hit_rate@10: 0.061455
2025-12-15 20:08:36 - GraphTrainer - INFO -   ndcg@10: 0.030998
2025-12-15 20:08:36 - GraphTrainer - INFO -   map@10: 0.022371
2025-12-15 20:08:36 - GraphTrainer - INFO -   mrr@10: 0.023454
2025-12-15 20:08:36 - GraphTrainer - INFO -   precision@20: 0.004850
2025-12-15 20:08:36 - GraphTrainer - INFO -   recall@20: 0.091769
2025-12-15 20:08:36 - GraphTrainer - INFO -   hit_rate@20: 0.096374
2025-12-15 20:08:36 - GraphTrainer - INFO -   ndcg@20: 0.039479
2025-12-15 20:08:36 - GraphTrainer - INFO -   map@20: 0.024649
2025-12-15 20:08:36 - GraphTrainer - INFO -   mrr@20: 0.025832
2025-12-15 20:08:36 - GraphTrainer - INFO - 第 101 轮训练完成
2025-12-15 20:08:36 - GraphTrainer - INFO - train_loss: 0.189531
2025-12-15 20:08:36 - GraphTrainer - INFO - precision@5: 0.007334
2025-12-15 20:08:36 - GraphTrainer - INFO - recall@5: 0.034798
2025-12-15 20:08:36 - GraphTrainer - INFO - hit_rate@5: 0.036616
2025-12-15 20:08:36 - GraphTrainer - INFO - ndcg@5: 0.023348
2025-12-15 20:08:36 - GraphTrainer - INFO - map@5: 0.019286
2025-12-15 20:08:36 - GraphTrainer - INFO - mrr@5: 0.020208
2025-12-15 20:08:36 - GraphTrainer - INFO - precision@10: 0.006171
2025-12-15 20:08:36 - GraphTrainer - INFO - recall@10: 0.058406
2025-12-15 20:08:36 - GraphTrainer - INFO - hit_rate@10: 0.061455
2025-12-15 20:08:36 - GraphTrainer - INFO - ndcg@10: 0.030998
2025-12-15 20:08:36 - GraphTrainer - INFO - map@10: 0.022371
2025-12-15 20:08:36 - GraphTrainer - INFO - mrr@10: 0.023454
2025-12-15 20:08:36 - GraphTrainer - INFO - precision@20: 0.004850
2025-12-15 20:08:36 - GraphTrainer - INFO - recall@20: 0.091769
2025-12-15 20:08:36 - GraphTrainer - INFO - hit_rate@20: 0.096374
2025-12-15 20:08:36 - GraphTrainer - INFO - ndcg@20: 0.039479
2025-12-15 20:08:36 - GraphTrainer - INFO - map@20: 0.024649
2025-12-15 20:08:36 - GraphTrainer - INFO - mrr@20: 0.025832
2025-12-15 20:08:36 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:08:36 - GraphTrainer - INFO - ============================================================
2025-12-15 20:08:36 - GraphTrainer - INFO - 开始第 102/1000 轮训练
2025-12-15 20:08:36 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1858, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.1870, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.1699, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.1923, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2100, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.1861, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.1810, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2072, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1877, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.1882, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1871, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.1847, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1960, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.1853, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2099, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1766, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1646, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1809, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.1671, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2067, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2113, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1926, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.1955, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.1983, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.1853, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.1962, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.1896, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.1919, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.1849, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.1947, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.1971, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.1985, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.1970, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1970, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1915, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1874, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1848, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.1870, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.1900, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.1894, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1846, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.1960, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.1832, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2034, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.1817, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2114, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.1721, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.1825, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1807, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.1809, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.1889, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.1983, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.1912, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1929, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1958, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.1823, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.1895, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.1633, device='cuda:0', grad_fn=<AddBackward0>)
The 101 training average loss: 0.18953083789554134
2025-12-15 20:08:44 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:08:44 - GraphTrainer - INFO -   precision@5: 0.007621
2025-12-15 20:08:44 - GraphTrainer - INFO -   recall@5: 0.036369
2025-12-15 20:08:44 - GraphTrainer - INFO -   hit_rate@5: 0.038107
2025-12-15 20:08:44 - GraphTrainer - INFO -   ndcg@5: 0.023959
2025-12-15 20:08:44 - GraphTrainer - INFO -   map@5: 0.019623
2025-12-15 20:08:44 - GraphTrainer - INFO -   mrr@5: 0.020501
2025-12-15 20:08:44 - GraphTrainer - INFO -   precision@10: 0.006084
2025-12-15 20:08:44 - GraphTrainer - INFO -   recall@10: 0.057640
2025-12-15 20:08:44 - GraphTrainer - INFO -   hit_rate@10: 0.060633
2025-12-15 20:08:44 - GraphTrainer - INFO -   ndcg@10: 0.030851
2025-12-15 20:08:44 - GraphTrainer - INFO -   map@10: 0.022392
2025-12-15 20:08:44 - GraphTrainer - INFO -   mrr@10: 0.023429
2025-12-15 20:08:44 - GraphTrainer - INFO -   precision@20: 0.004852
2025-12-15 20:08:44 - GraphTrainer - INFO -   recall@20: 0.091790
2025-12-15 20:08:44 - GraphTrainer - INFO -   hit_rate@20: 0.096323
2025-12-15 20:08:44 - GraphTrainer - INFO -   ndcg@20: 0.039565
2025-12-15 20:08:44 - GraphTrainer - INFO -   map@20: 0.024750
2025-12-15 20:08:44 - GraphTrainer - INFO -   mrr@20: 0.025882
2025-12-15 20:08:44 - GraphTrainer - INFO - 第 102 轮训练完成
2025-12-15 20:08:44 - GraphTrainer - INFO - train_loss: 0.187815
2025-12-15 20:08:44 - GraphTrainer - INFO - precision@5: 0.007621
2025-12-15 20:08:44 - GraphTrainer - INFO - recall@5: 0.036369
2025-12-15 20:08:44 - GraphTrainer - INFO - hit_rate@5: 0.038107
2025-12-15 20:08:44 - GraphTrainer - INFO - ndcg@5: 0.023959
2025-12-15 20:08:44 - GraphTrainer - INFO - map@5: 0.019623
2025-12-15 20:08:44 - GraphTrainer - INFO - mrr@5: 0.020501
2025-12-15 20:08:44 - GraphTrainer - INFO - precision@10: 0.006084
2025-12-15 20:08:44 - GraphTrainer - INFO - recall@10: 0.057640
2025-12-15 20:08:44 - GraphTrainer - INFO - hit_rate@10: 0.060633
2025-12-15 20:08:44 - GraphTrainer - INFO - ndcg@10: 0.030851
2025-12-15 20:08:44 - GraphTrainer - INFO - map@10: 0.022392
2025-12-15 20:08:44 - GraphTrainer - INFO - mrr@10: 0.023429
2025-12-15 20:08:44 - GraphTrainer - INFO - precision@20: 0.004852
2025-12-15 20:08:44 - GraphTrainer - INFO - recall@20: 0.091790
2025-12-15 20:08:44 - GraphTrainer - INFO - hit_rate@20: 0.096323
2025-12-15 20:08:44 - GraphTrainer - INFO - ndcg@20: 0.039565
2025-12-15 20:08:44 - GraphTrainer - INFO - map@20: 0.024750
2025-12-15 20:08:44 - GraphTrainer - INFO - mrr@20: 0.025882
2025-12-15 20:08:44 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:08:44 - GraphTrainer - INFO - ============================================================
2025-12-15 20:08:44 - GraphTrainer - INFO - 开始第 103/1000 轮训练
2025-12-15 20:08:44 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1902, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.1973, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.1712, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.1892, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1887, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.1786, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.1974, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2069, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1816, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.1778, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1881, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.1839, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1933, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.1829, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2033, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1846, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1874, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1922, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2060, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.1853, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1902, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1747, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.1806, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2161, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.1821, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.1958, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.1915, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.1942, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.1866, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2025, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.1985, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.1860, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.1870, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2081, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1837, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1975, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1841, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.1773, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.1712, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.1765, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1870, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.1712, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.1817, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.1866, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.1907, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.1898, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.1848, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.1864, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1982, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.1802, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.1972, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.1888, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.1812, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1894, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1807, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.1628, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.1973, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.1689, device='cuda:0', grad_fn=<AddBackward0>)
The 102 training average loss: 0.1878148533146957
2025-12-15 20:08:52 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:08:52 - GraphTrainer - INFO -   precision@5: 0.007395
2025-12-15 20:08:52 - GraphTrainer - INFO -   recall@5: 0.035099
2025-12-15 20:08:52 - GraphTrainer - INFO -   hit_rate@5: 0.036976
2025-12-15 20:08:52 - GraphTrainer - INFO -   ndcg@5: 0.023408
2025-12-15 20:08:52 - GraphTrainer - INFO -   map@5: 0.019288
2025-12-15 20:08:52 - GraphTrainer - INFO -   mrr@5: 0.020165
2025-12-15 20:08:52 - GraphTrainer - INFO -   precision@10: 0.006192
2025-12-15 20:08:52 - GraphTrainer - INFO -   recall@10: 0.058531
2025-12-15 20:08:52 - GraphTrainer - INFO -   hit_rate@10: 0.061661
2025-12-15 20:08:52 - GraphTrainer - INFO -   ndcg@10: 0.030975
2025-12-15 20:08:52 - GraphTrainer - INFO -   map@10: 0.022319
2025-12-15 20:08:52 - GraphTrainer - INFO -   mrr@10: 0.023354
2025-12-15 20:08:52 - GraphTrainer - INFO -   precision@20: 0.004829
2025-12-15 20:08:52 - GraphTrainer - INFO -   recall@20: 0.091546
2025-12-15 20:08:52 - GraphTrainer - INFO -   hit_rate@20: 0.096014
2025-12-15 20:08:52 - GraphTrainer - INFO -   ndcg@20: 0.039358
2025-12-15 20:08:52 - GraphTrainer - INFO -   map@20: 0.024576
2025-12-15 20:08:52 - GraphTrainer - INFO -   mrr@20: 0.025696
2025-12-15 20:08:52 - GraphTrainer - INFO - 第 103 轮训练完成
2025-12-15 20:08:52 - GraphTrainer - INFO - train_loss: 0.188608
2025-12-15 20:08:52 - GraphTrainer - INFO - precision@5: 0.007395
2025-12-15 20:08:52 - GraphTrainer - INFO - recall@5: 0.035099
2025-12-15 20:08:52 - GraphTrainer - INFO - hit_rate@5: 0.036976
2025-12-15 20:08:52 - GraphTrainer - INFO - ndcg@5: 0.023408
2025-12-15 20:08:52 - GraphTrainer - INFO - map@5: 0.019288
2025-12-15 20:08:52 - GraphTrainer - INFO - mrr@5: 0.020165
2025-12-15 20:08:52 - GraphTrainer - INFO - precision@10: 0.006192
2025-12-15 20:08:52 - GraphTrainer - INFO - recall@10: 0.058531
2025-12-15 20:08:52 - GraphTrainer - INFO - hit_rate@10: 0.061661
2025-12-15 20:08:52 - GraphTrainer - INFO - ndcg@10: 0.030975
2025-12-15 20:08:52 - GraphTrainer - INFO - map@10: 0.022319
2025-12-15 20:08:52 - GraphTrainer - INFO - mrr@10: 0.023354
2025-12-15 20:08:52 - GraphTrainer - INFO - precision@20: 0.004829
2025-12-15 20:08:52 - GraphTrainer - INFO - recall@20: 0.091546
2025-12-15 20:08:52 - GraphTrainer - INFO - hit_rate@20: 0.096014
2025-12-15 20:08:52 - GraphTrainer - INFO - ndcg@20: 0.039358
2025-12-15 20:08:52 - GraphTrainer - INFO - map@20: 0.024576
2025-12-15 20:08:52 - GraphTrainer - INFO - mrr@20: 0.025696
2025-12-15 20:08:52 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:08:52 - GraphTrainer - INFO - ============================================================
2025-12-15 20:08:52 - GraphTrainer - INFO - 开始第 104/1000 轮训练
2025-12-15 20:08:52 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1821, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.1943, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.1791, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.1958, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1897, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.1823, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.1889, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.1894, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1995, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.1839, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1886, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.1840, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1636, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2164, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.1804, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1691, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1953, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1879, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.1784, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.1955, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1846, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1934, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.1820, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.1888, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.1788, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.1905, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.1835, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.1846, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.1842, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.1920, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.1839, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.1789, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.1846, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1735, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1933, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1910, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1898, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2015, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.1821, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.1901, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1854, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2066, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.1914, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.1816, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.1962, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.1887, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.1845, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2116, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1720, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.1870, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.1929, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2160, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.1976, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1968, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1738, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.1912, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.1913, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.1991, device='cuda:0', grad_fn=<AddBackward0>)
The 103 training average loss: 0.18860791006992603
2025-12-15 20:09:00 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:09:00 - GraphTrainer - INFO -   precision@5: 0.007406
2025-12-15 20:09:00 - GraphTrainer - INFO -   recall@5: 0.035283
2025-12-15 20:09:00 - GraphTrainer - INFO -   hit_rate@5: 0.037028
2025-12-15 20:09:00 - GraphTrainer - INFO -   ndcg@5: 0.023530
2025-12-15 20:09:00 - GraphTrainer - INFO -   map@5: 0.019401
2025-12-15 20:09:00 - GraphTrainer - INFO -   mrr@5: 0.020278
2025-12-15 20:09:00 - GraphTrainer - INFO -   precision@10: 0.006146
2025-12-15 20:09:00 - GraphTrainer - INFO -   recall@10: 0.058216
2025-12-15 20:09:00 - GraphTrainer - INFO -   hit_rate@10: 0.061301
2025-12-15 20:09:00 - GraphTrainer - INFO -   ndcg@10: 0.030958
2025-12-15 20:09:00 - GraphTrainer - INFO -   map@10: 0.022385
2025-12-15 20:09:00 - GraphTrainer - INFO -   mrr@10: 0.023433
2025-12-15 20:09:00 - GraphTrainer - INFO -   precision@20: 0.004837
2025-12-15 20:09:00 - GraphTrainer - INFO -   recall@20: 0.091460
2025-12-15 20:09:00 - GraphTrainer - INFO -   hit_rate@20: 0.096066
2025-12-15 20:09:00 - GraphTrainer - INFO -   ndcg@20: 0.039449
2025-12-15 20:09:00 - GraphTrainer - INFO -   map@20: 0.024686
2025-12-15 20:09:00 - GraphTrainer - INFO -   mrr@20: 0.025829
2025-12-15 20:09:00 - GraphTrainer - INFO - 第 104 轮训练完成
2025-12-15 20:09:00 - GraphTrainer - INFO - train_loss: 0.189928
2025-12-15 20:09:00 - GraphTrainer - INFO - precision@5: 0.007406
2025-12-15 20:09:00 - GraphTrainer - INFO - recall@5: 0.035283
2025-12-15 20:09:00 - GraphTrainer - INFO - hit_rate@5: 0.037028
2025-12-15 20:09:00 - GraphTrainer - INFO - ndcg@5: 0.023530
2025-12-15 20:09:00 - GraphTrainer - INFO - map@5: 0.019401
2025-12-15 20:09:00 - GraphTrainer - INFO - mrr@5: 0.020278
2025-12-15 20:09:00 - GraphTrainer - INFO - precision@10: 0.006146
2025-12-15 20:09:00 - GraphTrainer - INFO - recall@10: 0.058216
2025-12-15 20:09:00 - GraphTrainer - INFO - hit_rate@10: 0.061301
2025-12-15 20:09:00 - GraphTrainer - INFO - ndcg@10: 0.030958
2025-12-15 20:09:00 - GraphTrainer - INFO - map@10: 0.022385
2025-12-15 20:09:00 - GraphTrainer - INFO - mrr@10: 0.023433
2025-12-15 20:09:00 - GraphTrainer - INFO - precision@20: 0.004837
2025-12-15 20:09:00 - GraphTrainer - INFO - recall@20: 0.091460
2025-12-15 20:09:00 - GraphTrainer - INFO - hit_rate@20: 0.096066
2025-12-15 20:09:00 - GraphTrainer - INFO - ndcg@20: 0.039449
2025-12-15 20:09:00 - GraphTrainer - INFO - map@20: 0.024686
2025-12-15 20:09:00 - GraphTrainer - INFO - mrr@20: 0.025829
2025-12-15 20:09:00 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:09:00 - GraphTrainer - INFO - ============================================================
2025-12-15 20:09:00 - GraphTrainer - INFO - 开始第 105/1000 轮训练
2025-12-15 20:09:00 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1850, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.1758, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.1933, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.1941, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1771, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.1843, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.1876, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.1869, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1965, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.1991, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1989, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2061, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2135, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.1951, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.1828, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1789, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1763, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1785, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.1924, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.1884, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1820, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1761, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.1876, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2036, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.1673, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.1916, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.1857, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2000, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.1900, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.1886, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2086, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.1993, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2052, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1813, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1769, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1839, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1849, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.1962, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.1790, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.1989, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1851, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2067, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.1501, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.1747, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.1777, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.1909, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.1793, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.1951, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2078, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.1945, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.1915, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.1834, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.1986, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1883, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1953, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2030, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2072, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2092, device='cuda:0', grad_fn=<AddBackward0>)
The 104 training average loss: 0.18992759903957104
2025-12-15 20:09:08 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:09:08 - GraphTrainer - INFO -   precision@5: 0.007375
2025-12-15 20:09:08 - GraphTrainer - INFO -   recall@5: 0.035040
2025-12-15 20:09:08 - GraphTrainer - INFO -   hit_rate@5: 0.036873
2025-12-15 20:09:08 - GraphTrainer - INFO -   ndcg@5: 0.023430
2025-12-15 20:09:08 - GraphTrainer - INFO -   map@5: 0.019321
2025-12-15 20:09:08 - GraphTrainer - INFO -   mrr@5: 0.020253
2025-12-15 20:09:08 - GraphTrainer - INFO -   precision@10: 0.006084
2025-12-15 20:09:08 - GraphTrainer - INFO -   recall@10: 0.057572
2025-12-15 20:09:08 - GraphTrainer - INFO -   hit_rate@10: 0.060581
2025-12-15 20:09:08 - GraphTrainer - INFO -   ndcg@10: 0.030732
2025-12-15 20:09:08 - GraphTrainer - INFO -   map@10: 0.022264
2025-12-15 20:09:08 - GraphTrainer - INFO -   mrr@10: 0.023341
2025-12-15 20:09:08 - GraphTrainer - INFO -   precision@20: 0.004852
2025-12-15 20:09:08 - GraphTrainer - INFO -   recall@20: 0.091591
2025-12-15 20:09:08 - GraphTrainer - INFO -   hit_rate@20: 0.096374
2025-12-15 20:09:08 - GraphTrainer - INFO -   ndcg@20: 0.039415
2025-12-15 20:09:08 - GraphTrainer - INFO -   map@20: 0.024607
2025-12-15 20:09:08 - GraphTrainer - INFO -   mrr@20: 0.025799
2025-12-15 20:09:08 - GraphTrainer - INFO - 第 105 轮训练完成
2025-12-15 20:09:08 - GraphTrainer - INFO - train_loss: 0.188514
2025-12-15 20:09:08 - GraphTrainer - INFO - precision@5: 0.007375
2025-12-15 20:09:08 - GraphTrainer - INFO - recall@5: 0.035040
2025-12-15 20:09:08 - GraphTrainer - INFO - hit_rate@5: 0.036873
2025-12-15 20:09:08 - GraphTrainer - INFO - ndcg@5: 0.023430
2025-12-15 20:09:08 - GraphTrainer - INFO - map@5: 0.019321
2025-12-15 20:09:08 - GraphTrainer - INFO - mrr@5: 0.020253
2025-12-15 20:09:08 - GraphTrainer - INFO - precision@10: 0.006084
2025-12-15 20:09:08 - GraphTrainer - INFO - recall@10: 0.057572
2025-12-15 20:09:08 - GraphTrainer - INFO - hit_rate@10: 0.060581
2025-12-15 20:09:08 - GraphTrainer - INFO - ndcg@10: 0.030732
2025-12-15 20:09:08 - GraphTrainer - INFO - map@10: 0.022264
2025-12-15 20:09:08 - GraphTrainer - INFO - mrr@10: 0.023341
2025-12-15 20:09:08 - GraphTrainer - INFO - precision@20: 0.004852
2025-12-15 20:09:08 - GraphTrainer - INFO - recall@20: 0.091591
2025-12-15 20:09:08 - GraphTrainer - INFO - hit_rate@20: 0.096374
2025-12-15 20:09:08 - GraphTrainer - INFO - ndcg@20: 0.039415
2025-12-15 20:09:08 - GraphTrainer - INFO - map@20: 0.024607
2025-12-15 20:09:08 - GraphTrainer - INFO - mrr@20: 0.025799
2025-12-15 20:09:08 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:09:08 - GraphTrainer - WARNING - 早停触发 - 第 105 轮，最佳指标: 0.092362
2025-12-15 20:09:08 - GraphTrainer - INFO - ============================================================
2025-12-15 20:09:08 - GraphTrainer - INFO - 训练完成!
2025-12-15 20:09:08 - GraphTrainer - INFO - 总训练时间: 0.23 hours
2025-12-15 20:09:08 - GraphTrainer - INFO - 最佳指标:
2025-12-15 20:09:08 - GraphTrainer - INFO -   best_precision@5: 0.007375
2025-12-15 20:09:08 - GraphTrainer - INFO -   best_recall@5: 0.035040
2025-12-15 20:09:08 - GraphTrainer - INFO -   best_hit_rate@5: 0.036873
2025-12-15 20:09:08 - GraphTrainer - INFO -   best_ndcg@5: 0.023430
2025-12-15 20:09:08 - GraphTrainer - INFO -   best_map@5: 0.019321
2025-12-15 20:09:08 - GraphTrainer - INFO -   best_mrr@5: 0.020253
2025-12-15 20:09:08 - GraphTrainer - INFO -   best_precision@10: 0.006084
2025-12-15 20:09:08 - GraphTrainer - INFO -   best_recall@10: 0.057572
2025-12-15 20:09:08 - GraphTrainer - INFO -   best_hit_rate@10: 0.060581
2025-12-15 20:09:08 - GraphTrainer - INFO -   best_ndcg@10: 0.030732
2025-12-15 20:09:08 - GraphTrainer - INFO -   best_map@10: 0.022264
2025-12-15 20:09:08 - GraphTrainer - INFO -   best_mrr@10: 0.023341
2025-12-15 20:09:08 - GraphTrainer - INFO -   best_precision@20: 0.004852
2025-12-15 20:09:08 - GraphTrainer - INFO -   best_recall@20: 0.091591
2025-12-15 20:09:08 - GraphTrainer - INFO -   best_hit_rate@20: 0.096374
2025-12-15 20:09:08 - GraphTrainer - INFO -   best_ndcg@20: 0.039415
2025-12-15 20:09:08 - GraphTrainer - INFO -   best_map@20: 0.024607
2025-12-15 20:09:08 - GraphTrainer - INFO -   best_mrr@20: 0.025799
2025-12-15 20:09:08 - GraphTrainer - INFO - ============================================================
2025-12-15 20:09:08 - GraphTrainer - INFO - Loaded best model from epoch 85
0 train_loss tensor(0.1710, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.1822, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.1789, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2045, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1880, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.1902, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.1860, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.1617, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1779, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2055, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1858, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.1876, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1872, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.1895, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2058, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1966, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1890, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2115, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.1860, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.1916, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1820, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1874, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2162, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.1716, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.1863, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.1939, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.1818, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.1937, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.1754, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2034, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.1841, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2031, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.1843, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1719, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1712, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1746, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1881, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.1883, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.1993, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.1935, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1770, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.1750, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.1744, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.1855, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.1881, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.1990, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2102, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.1942, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1870, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.1776, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.1868, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.1937, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.1839, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2130, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1859, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.1955, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.1851, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.1953, device='cuda:0', grad_fn=<AddBackward0>)
The 105 training average loss: 0.18851360010689702

============================================================
FINAL RESULTS
============================================================
Training Results:
  Best epoch: 85
  Best validation metric: 0.0924
  Training time: 0.23 hours

Test Metrics:
  precision@5: 0.0081
  recall@5: 0.0364
  hit_rate@5: 0.0404
  ndcg@5: 0.0241
  map@5: 0.0193
  mrr@5: 0.0213
  precision@10: 0.0066
  recall@10: 0.0594
  hit_rate@10: 0.0652
  ndcg@10: 0.0316
  map@10: 0.0223
  mrr@10: 0.0246
  precision@20: 0.0052
  recall@20: 0.0938
  hit_rate@20: 0.1028
  ndcg@20: 0.0404
  map@20: 0.0247
  mrr@20: 0.0272
Saving results...
Results saved to ./results/results_20251215_2009.json

Training completed successfully!

############################################################
Grid Trial 1
############################################################
Trial config (partial):
  lr=0.001, wd=0, k=2, v_layer=2, t_layer=2
Using GPU: NVIDIA GeForce RTX 3090
============================================================
Graph-based Recommendation System
============================================================
Dataset: baby
Device: cuda
Model: SGrec
Embedding dim: 64
Epochs: 1000
============================================================
Loading data...
Initializing full dataset from ../autodl-tmp/data/ori_data/baby
Loading interaction data from ../autodl-tmp/data/ori_data/baby
Loading features from ../autodl-tmp/data/ori_data/baby
Building user-item interaction index...
Dataset Statistics:
  num_users: 19445
  num_items: 7050
  num_interactions: 160792
  sparsity: 0.9988270827520429
  user_features: []
  item_features_dimensions: {'image_feat': 4096, 'text_feat': 384}
  user_feature_dimensions: {}
  train_ratio: 0.737294143987263
  val_ratio: 0.12786083884770386
  test_ratio: 0.13484501716503308
Full dataset initialized: 160792 interactions, 19445 users, 7050 items
Splitting dataset into train/val/test...
Initializing subset dataset (mode: train) with 118551 interactions
Initializing subset dataset (mode: val) with 20559 interactions
Initializing subset dataset (mode: test) with 21682 interactions
Split results - Train: 118551 interactions, Val: 20559, Test: 21682
Data loaders created - Train batches: 58, Val batches: 11, Test batches: 11
Data loaded: 19445 users, 7050 items
User features: []
Item features: ['image_feat', 'text_feat']
Building graph and model...
Extracting training interactions for graph construction...
Extracted 118551 positive interactions for graph construction
Graph built from training data only: 26495 nodes, 263597 edges
⚠️  Important: Graph constructed using only training data to prevent data leakage
2025-12-15 20:09:25 - GraphTrainer - INFO - Starting training...
2025-12-15 20:09:25 - GraphTrainer - INFO - 模型: SGrec
2025-12-15 20:09:25 - GraphTrainer - INFO - 总参数量: 4,396,672
2025-12-15 20:09:25 - GraphTrainer - INFO - 可训练参数量: 4,396,672
2025-12-15 20:09:25 - GraphTrainer - INFO - ============================================================
2025-12-15 20:09:25 - GraphTrainer - INFO - 开始第 1/1000 轮训练
2025-12-15 20:09:25 - GraphTrainer - INFO - ============================================================
SGrec(
  (user_emb): Embedding(19445, 64)
  (item_emb): Embedding(7050, 64)
  (graph): Graph(
    (input_feat_dropout): Dropout(p=0.1, inplace=False)
    (v_ffn): Sequential(
      (0): Linear(in_features=4096, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=64, bias=True)
      (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (t_ffn): Sequential(
      (0): Linear(in_features=384, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=64, bias=True)
      (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (iu_gcn): IU_GCN(
      (x_dropout): Dropout(p=0.3, inplace=False)
      (edge_dropout): Dropout(p=0.2, inplace=False)
      (z_dropout): Dropout(p=0.3, inplace=False)
    )
    (v_transformer): SpatialTransformer(
      (transformer_blocks): ModuleList(
        (0-1): 2 x SpatialTransformerBlock(
          (attention): MultiHeadSelfAttention(
            (q_linear): Linear(in_features=64, out_features=64, bias=True)
            (k_linear): Linear(in_features=64, out_features=64, bias=True)
            (v_linear): Linear(in_features=64, out_features=64, bias=True)
            (o_linear): Linear(in_features=64, out_features=64, bias=True)
            (attn_dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (linear1): Linear(in_features=64, out_features=512, bias=True)
            (linear2): Linear(in_features=512, out_features=64, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (output_dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (t_transformer): SpatialTransformer(
      (transformer_blocks): ModuleList(
        (0-1): 2 x SpatialTransformerBlock(
          (attention): MultiHeadSelfAttention(
            (q_linear): Linear(in_features=64, out_features=64, bias=True)
            (k_linear): Linear(in_features=64, out_features=64, bias=True)
            (v_linear): Linear(in_features=64, out_features=64, bias=True)
            (o_linear): Linear(in_features=64, out_features=64, bias=True)
            (attn_dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (linear1): Linear(in_features=64, out_features=512, bias=True)
            (linear2): Linear(in_features=512, out_features=64, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (output_dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (outl): Linear(in_features=128, out_features=64, bias=True)
    (activate): ReLU()
  )
)
Model parameters: 4,396,672
init trainer,verifier,tester
2025-12-15 20:09:33 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:09:33 - GraphTrainer - INFO -   precision@5: 0.005204
2025-12-15 20:09:33 - GraphTrainer - INFO -   recall@5: 0.024867
2025-12-15 20:09:33 - GraphTrainer - INFO -   hit_rate@5: 0.026022
2025-12-15 20:09:33 - GraphTrainer - INFO -   ndcg@5: 0.016169
2025-12-15 20:09:33 - GraphTrainer - INFO -   map@5: 0.013127
2025-12-15 20:09:33 - GraphTrainer - INFO -   mrr@5: 0.013674
2025-12-15 20:09:33 - GraphTrainer - INFO -   precision@10: 0.004073
2025-12-15 20:09:33 - GraphTrainer - INFO -   recall@10: 0.038831
2025-12-15 20:09:33 - GraphTrainer - INFO -   hit_rate@10: 0.040730
2025-12-15 20:09:33 - GraphTrainer - INFO -   ndcg@10: 0.020648
2025-12-15 20:09:33 - GraphTrainer - INFO -   map@10: 0.014909
2025-12-15 20:09:33 - GraphTrainer - INFO -   mrr@10: 0.015549
2025-12-15 20:09:33 - GraphTrainer - INFO -   precision@20: 0.003276
2025-12-15 20:09:33 - GraphTrainer - INFO -   recall@20: 0.062418
2025-12-15 20:09:33 - GraphTrainer - INFO -   hit_rate@20: 0.065312
2025-12-15 20:09:33 - GraphTrainer - INFO -   ndcg@20: 0.026639
2025-12-15 20:09:33 - GraphTrainer - INFO -   map@20: 0.016521
2025-12-15 20:09:33 - GraphTrainer - INFO -   mrr@20: 0.017225
2025-12-15 20:09:33 - GraphTrainer - INFO - 第 1 轮训练完成
2025-12-15 20:09:33 - GraphTrainer - INFO - train_loss: 0.390950
2025-12-15 20:09:33 - GraphTrainer - INFO - precision@5: 0.005204
2025-12-15 20:09:33 - GraphTrainer - INFO - recall@5: 0.024867
2025-12-15 20:09:33 - GraphTrainer - INFO - hit_rate@5: 0.026022
2025-12-15 20:09:33 - GraphTrainer - INFO - ndcg@5: 0.016169
2025-12-15 20:09:33 - GraphTrainer - INFO - map@5: 0.013127
2025-12-15 20:09:33 - GraphTrainer - INFO - mrr@5: 0.013674
2025-12-15 20:09:33 - GraphTrainer - INFO - precision@10: 0.004073
2025-12-15 20:09:33 - GraphTrainer - INFO - recall@10: 0.038831
2025-12-15 20:09:33 - GraphTrainer - INFO - hit_rate@10: 0.040730
2025-12-15 20:09:33 - GraphTrainer - INFO - ndcg@10: 0.020648
2025-12-15 20:09:33 - GraphTrainer - INFO - map@10: 0.014909
2025-12-15 20:09:33 - GraphTrainer - INFO - mrr@10: 0.015549
2025-12-15 20:09:33 - GraphTrainer - INFO - precision@20: 0.003276
2025-12-15 20:09:33 - GraphTrainer - INFO - recall@20: 0.062418
2025-12-15 20:09:33 - GraphTrainer - INFO - hit_rate@20: 0.065312
2025-12-15 20:09:33 - GraphTrainer - INFO - ndcg@20: 0.026639
2025-12-15 20:09:33 - GraphTrainer - INFO - map@20: 0.016521
2025-12-15 20:09:33 - GraphTrainer - INFO - mrr@20: 0.017225
2025-12-15 20:09:33 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:09:33 - GraphTrainer - INFO - ============================================================
2025-12-15 20:09:33 - GraphTrainer - INFO - 开始第 2/1000 轮训练
2025-12-15 20:09:33 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.7314, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.6069, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.4637, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3944, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.5214, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.4030, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.4073, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.4002, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.4006, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.4040, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3889, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3887, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3796, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3931, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3959, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3747, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3986, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3829, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3787, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3780, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.4031, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3797, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3767, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3687, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3601, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3735, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3762, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3828, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3984, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3836, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3812, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3713, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3762, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.4049, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3833, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3742, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3633, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3701, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3691, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3736, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3775, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3765, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3674, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3664, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3610, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3644, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3740, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3630, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3507, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3730, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3720, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3718, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3631, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)
The 1 training average loss: 0.39095013717125204
2025-12-15 20:09:41 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:09:41 - GraphTrainer - INFO -   precision@5: 0.005822
2025-12-15 20:09:41 - GraphTrainer - INFO -   recall@5: 0.027943
2025-12-15 20:09:41 - GraphTrainer - INFO -   hit_rate@5: 0.029108
2025-12-15 20:09:41 - GraphTrainer - INFO -   ndcg@5: 0.018090
2025-12-15 20:09:41 - GraphTrainer - INFO -   map@5: 0.014673
2025-12-15 20:09:41 - GraphTrainer - INFO -   mrr@5: 0.015195
2025-12-15 20:09:41 - GraphTrainer - INFO -   precision@10: 0.004613
2025-12-15 20:09:41 - GraphTrainer - INFO -   recall@10: 0.044009
2025-12-15 20:09:41 - GraphTrainer - INFO -   hit_rate@10: 0.046079
2025-12-15 20:09:41 - GraphTrainer - INFO -   ndcg@10: 0.023307
2025-12-15 20:09:41 - GraphTrainer - INFO -   map@10: 0.016781
2025-12-15 20:09:41 - GraphTrainer - INFO -   mrr@10: 0.017422
2025-12-15 20:09:41 - GraphTrainer - INFO -   precision@20: 0.003662
2025-12-15 20:09:41 - GraphTrainer - INFO -   recall@20: 0.069784
2025-12-15 20:09:41 - GraphTrainer - INFO -   hit_rate@20: 0.072924
2025-12-15 20:09:41 - GraphTrainer - INFO -   ndcg@20: 0.029821
2025-12-15 20:09:41 - GraphTrainer - INFO -   map@20: 0.018517
2025-12-15 20:09:41 - GraphTrainer - INFO -   mrr@20: 0.019224
2025-12-15 20:09:41 - GraphTrainer - INFO - 第 2 轮训练完成
2025-12-15 20:09:41 - GraphTrainer - INFO - train_loss: 0.351137
2025-12-15 20:09:41 - GraphTrainer - INFO - precision@5: 0.005822
2025-12-15 20:09:41 - GraphTrainer - INFO - recall@5: 0.027943
2025-12-15 20:09:41 - GraphTrainer - INFO - hit_rate@5: 0.029108
2025-12-15 20:09:41 - GraphTrainer - INFO - ndcg@5: 0.018090
2025-12-15 20:09:41 - GraphTrainer - INFO - map@5: 0.014673
2025-12-15 20:09:41 - GraphTrainer - INFO - mrr@5: 0.015195
2025-12-15 20:09:41 - GraphTrainer - INFO - precision@10: 0.004613
2025-12-15 20:09:41 - GraphTrainer - INFO - recall@10: 0.044009
2025-12-15 20:09:41 - GraphTrainer - INFO - hit_rate@10: 0.046079
2025-12-15 20:09:41 - GraphTrainer - INFO - ndcg@10: 0.023307
2025-12-15 20:09:41 - GraphTrainer - INFO - map@10: 0.016781
2025-12-15 20:09:41 - GraphTrainer - INFO - mrr@10: 0.017422
2025-12-15 20:09:41 - GraphTrainer - INFO - precision@20: 0.003662
2025-12-15 20:09:41 - GraphTrainer - INFO - recall@20: 0.069784
2025-12-15 20:09:41 - GraphTrainer - INFO - hit_rate@20: 0.072924
2025-12-15 20:09:41 - GraphTrainer - INFO - ndcg@20: 0.029821
2025-12-15 20:09:41 - GraphTrainer - INFO - map@20: 0.018517
2025-12-15 20:09:41 - GraphTrainer - INFO - mrr@20: 0.019224
2025-12-15 20:09:41 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:09:41 - GraphTrainer - INFO - ============================================================
2025-12-15 20:09:41 - GraphTrainer - INFO - 开始第 3/1000 轮训练
2025-12-15 20:09:41 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3750, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3789, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3750, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3639, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3529, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3762, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3634, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3608, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3641, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3269, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3690, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3642, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3534, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3574, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3621, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3537, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3517, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3717, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3455, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3577, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3296, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3494, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3512, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3506, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3512, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3582, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3572, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3521, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3551, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)
The 2 training average loss: 0.3511370389625944
2025-12-15 20:09:49 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:09:49 - GraphTrainer - INFO -   precision@5: 0.006171
2025-12-15 20:09:49 - GraphTrainer - INFO -   recall@5: 0.029440
2025-12-15 20:09:49 - GraphTrainer - INFO -   hit_rate@5: 0.030805
2025-12-15 20:09:49 - GraphTrainer - INFO -   ndcg@5: 0.018879
2025-12-15 20:09:49 - GraphTrainer - INFO -   map@5: 0.015199
2025-12-15 20:09:49 - GraphTrainer - INFO -   mrr@5: 0.015846
2025-12-15 20:09:49 - GraphTrainer - INFO -   precision@10: 0.004916
2025-12-15 20:09:49 - GraphTrainer - INFO -   recall@10: 0.046934
2025-12-15 20:09:49 - GraphTrainer - INFO -   hit_rate@10: 0.049010
2025-12-15 20:09:49 - GraphTrainer - INFO -   ndcg@10: 0.024496
2025-12-15 20:09:49 - GraphTrainer - INFO -   map@10: 0.017447
2025-12-15 20:09:49 - GraphTrainer - INFO -   mrr@10: 0.018186
2025-12-15 20:09:49 - GraphTrainer - INFO -   precision@20: 0.003816
2025-12-15 20:09:49 - GraphTrainer - INFO -   recall@20: 0.072231
2025-12-15 20:09:49 - GraphTrainer - INFO -   hit_rate@20: 0.075855
2025-12-15 20:09:49 - GraphTrainer - INFO -   ndcg@20: 0.030945
2025-12-15 20:09:49 - GraphTrainer - INFO -   map@20: 0.019174
2025-12-15 20:09:49 - GraphTrainer - INFO -   mrr@20: 0.020012
2025-12-15 20:09:49 - GraphTrainer - INFO - 第 3 轮训练完成
2025-12-15 20:09:49 - GraphTrainer - INFO - train_loss: 0.331027
2025-12-15 20:09:49 - GraphTrainer - INFO - precision@5: 0.006171
2025-12-15 20:09:49 - GraphTrainer - INFO - recall@5: 0.029440
2025-12-15 20:09:49 - GraphTrainer - INFO - hit_rate@5: 0.030805
2025-12-15 20:09:49 - GraphTrainer - INFO - ndcg@5: 0.018879
2025-12-15 20:09:49 - GraphTrainer - INFO - map@5: 0.015199
2025-12-15 20:09:49 - GraphTrainer - INFO - mrr@5: 0.015846
2025-12-15 20:09:49 - GraphTrainer - INFO - precision@10: 0.004916
2025-12-15 20:09:49 - GraphTrainer - INFO - recall@10: 0.046934
2025-12-15 20:09:49 - GraphTrainer - INFO - hit_rate@10: 0.049010
2025-12-15 20:09:49 - GraphTrainer - INFO - ndcg@10: 0.024496
2025-12-15 20:09:49 - GraphTrainer - INFO - map@10: 0.017447
2025-12-15 20:09:49 - GraphTrainer - INFO - mrr@10: 0.018186
2025-12-15 20:09:49 - GraphTrainer - INFO - precision@20: 0.003816
2025-12-15 20:09:49 - GraphTrainer - INFO - recall@20: 0.072231
2025-12-15 20:09:49 - GraphTrainer - INFO - hit_rate@20: 0.075855
2025-12-15 20:09:49 - GraphTrainer - INFO - ndcg@20: 0.030945
2025-12-15 20:09:49 - GraphTrainer - INFO - map@20: 0.019174
2025-12-15 20:09:49 - GraphTrainer - INFO - mrr@20: 0.020012
2025-12-15 20:09:49 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:09:49 - GraphTrainer - INFO - ============================================================
2025-12-15 20:09:49 - GraphTrainer - INFO - 开始第 4/1000 轮训练
2025-12-15 20:09:49 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3201, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3263, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3435, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3576, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3284, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3376, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3219, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3054, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3222, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3220, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3186, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3268, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3171, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3030, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3249, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3135, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3124, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3066, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3233, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3105, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3199, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3113, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3118, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3117, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3189, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3168, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3544, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3313, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
The 3 training average loss: 0.33102718098410244
2025-12-15 20:09:58 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:09:58 - GraphTrainer - INFO -   precision@5: 0.006212
2025-12-15 20:09:58 - GraphTrainer - INFO -   recall@5: 0.029591
2025-12-15 20:09:58 - GraphTrainer - INFO -   hit_rate@5: 0.031011
2025-12-15 20:09:58 - GraphTrainer - INFO -   ndcg@5: 0.019388
2025-12-15 20:09:58 - GraphTrainer - INFO -   map@5: 0.015809
2025-12-15 20:09:58 - GraphTrainer - INFO -   mrr@5: 0.016471
2025-12-15 20:09:58 - GraphTrainer - INFO -   precision@10: 0.004834
2025-12-15 20:09:58 - GraphTrainer - INFO -   recall@10: 0.045957
2025-12-15 20:09:58 - GraphTrainer - INFO -   hit_rate@10: 0.048187
2025-12-15 20:09:58 - GraphTrainer - INFO -   ndcg@10: 0.024675
2025-12-15 20:09:58 - GraphTrainer - INFO -   map@10: 0.017937
2025-12-15 20:09:58 - GraphTrainer - INFO -   mrr@10: 0.018698
2025-12-15 20:09:58 - GraphTrainer - INFO -   precision@20: 0.003798
2025-12-15 20:09:58 - GraphTrainer - INFO -   recall@20: 0.072096
2025-12-15 20:09:58 - GraphTrainer - INFO -   hit_rate@20: 0.075495
2025-12-15 20:09:58 - GraphTrainer - INFO -   ndcg@20: 0.031320
2025-12-15 20:09:58 - GraphTrainer - INFO -   map@20: 0.019724
2025-12-15 20:09:58 - GraphTrainer - INFO -   mrr@20: 0.020557
2025-12-15 20:09:58 - GraphTrainer - INFO - 第 4 轮训练完成
2025-12-15 20:09:58 - GraphTrainer - INFO - train_loss: 0.319988
2025-12-15 20:09:58 - GraphTrainer - INFO - precision@5: 0.006212
2025-12-15 20:09:58 - GraphTrainer - INFO - recall@5: 0.029591
2025-12-15 20:09:58 - GraphTrainer - INFO - hit_rate@5: 0.031011
2025-12-15 20:09:58 - GraphTrainer - INFO - ndcg@5: 0.019388
2025-12-15 20:09:58 - GraphTrainer - INFO - map@5: 0.015809
2025-12-15 20:09:58 - GraphTrainer - INFO - mrr@5: 0.016471
2025-12-15 20:09:58 - GraphTrainer - INFO - precision@10: 0.004834
2025-12-15 20:09:58 - GraphTrainer - INFO - recall@10: 0.045957
2025-12-15 20:09:58 - GraphTrainer - INFO - hit_rate@10: 0.048187
2025-12-15 20:09:58 - GraphTrainer - INFO - ndcg@10: 0.024675
2025-12-15 20:09:58 - GraphTrainer - INFO - map@10: 0.017937
2025-12-15 20:09:58 - GraphTrainer - INFO - mrr@10: 0.018698
2025-12-15 20:09:58 - GraphTrainer - INFO - precision@20: 0.003798
2025-12-15 20:09:58 - GraphTrainer - INFO - recall@20: 0.072096
2025-12-15 20:09:58 - GraphTrainer - INFO - hit_rate@20: 0.075495
2025-12-15 20:09:58 - GraphTrainer - INFO - ndcg@20: 0.031320
2025-12-15 20:09:58 - GraphTrainer - INFO - map@20: 0.019724
2025-12-15 20:09:58 - GraphTrainer - INFO - mrr@20: 0.020557
2025-12-15 20:09:58 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:09:58 - GraphTrainer - INFO - ============================================================
2025-12-15 20:09:58 - GraphTrainer - INFO - 开始第 5/1000 轮训练
2025-12-15 20:09:58 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3240, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3215, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3222, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3249, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3126, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3173, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3199, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3198, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3173, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3145, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3172, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3199, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3175, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3240, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3293, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3231, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3273, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3048, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3512, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3117, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3197, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3066, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3198, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3073, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3074, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2901, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3151, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3052, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3011, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3003, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3198, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3233, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3127, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3090, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3126, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3043, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3102, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3131, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3083, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3333, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2900, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3067, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3151, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
The 4 training average loss: 0.3199875472948469
2025-12-15 20:10:06 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:10:06 - GraphTrainer - INFO -   precision@5: 0.006192
2025-12-15 20:10:06 - GraphTrainer - INFO -   recall@5: 0.029600
2025-12-15 20:10:06 - GraphTrainer - INFO -   hit_rate@5: 0.030908
2025-12-15 20:10:06 - GraphTrainer - INFO -   ndcg@5: 0.019317
2025-12-15 20:10:06 - GraphTrainer - INFO -   map@5: 0.015722
2025-12-15 20:10:06 - GraphTrainer - INFO -   mrr@5: 0.016387
2025-12-15 20:10:06 - GraphTrainer - INFO -   precision@10: 0.004911
2025-12-15 20:10:06 - GraphTrainer - INFO -   recall@10: 0.046586
2025-12-15 20:10:06 - GraphTrainer - INFO -   hit_rate@10: 0.048907
2025-12-15 20:10:06 - GraphTrainer - INFO -   ndcg@10: 0.024822
2025-12-15 20:10:06 - GraphTrainer - INFO -   map@10: 0.017933
2025-12-15 20:10:06 - GraphTrainer - INFO -   mrr@10: 0.018730
2025-12-15 20:10:06 - GraphTrainer - INFO -   precision@20: 0.003844
2025-12-15 20:10:06 - GraphTrainer - INFO -   recall@20: 0.072681
2025-12-15 20:10:06 - GraphTrainer - INFO -   hit_rate@20: 0.076318
2025-12-15 20:10:06 - GraphTrainer - INFO -   ndcg@20: 0.031503
2025-12-15 20:10:06 - GraphTrainer - INFO -   map@20: 0.019749
2025-12-15 20:10:06 - GraphTrainer - INFO -   mrr@20: 0.020629
2025-12-15 20:10:06 - GraphTrainer - INFO - 第 5 轮训练完成
2025-12-15 20:10:06 - GraphTrainer - INFO - train_loss: 0.313806
2025-12-15 20:10:06 - GraphTrainer - INFO - precision@5: 0.006192
2025-12-15 20:10:06 - GraphTrainer - INFO - recall@5: 0.029600
2025-12-15 20:10:06 - GraphTrainer - INFO - hit_rate@5: 0.030908
2025-12-15 20:10:06 - GraphTrainer - INFO - ndcg@5: 0.019317
2025-12-15 20:10:06 - GraphTrainer - INFO - map@5: 0.015722
2025-12-15 20:10:06 - GraphTrainer - INFO - mrr@5: 0.016387
2025-12-15 20:10:06 - GraphTrainer - INFO - precision@10: 0.004911
2025-12-15 20:10:06 - GraphTrainer - INFO - recall@10: 0.046586
2025-12-15 20:10:06 - GraphTrainer - INFO - hit_rate@10: 0.048907
2025-12-15 20:10:06 - GraphTrainer - INFO - ndcg@10: 0.024822
2025-12-15 20:10:06 - GraphTrainer - INFO - map@10: 0.017933
2025-12-15 20:10:06 - GraphTrainer - INFO - mrr@10: 0.018730
2025-12-15 20:10:06 - GraphTrainer - INFO - precision@20: 0.003844
2025-12-15 20:10:06 - GraphTrainer - INFO - recall@20: 0.072681
2025-12-15 20:10:06 - GraphTrainer - INFO - hit_rate@20: 0.076318
2025-12-15 20:10:06 - GraphTrainer - INFO - ndcg@20: 0.031503
2025-12-15 20:10:06 - GraphTrainer - INFO - map@20: 0.019749
2025-12-15 20:10:06 - GraphTrainer - INFO - mrr@20: 0.020629
2025-12-15 20:10:06 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:10:06 - GraphTrainer - INFO - ============================================================
2025-12-15 20:10:06 - GraphTrainer - INFO - 开始第 6/1000 轮训练
2025-12-15 20:10:06 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3225, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3015, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3199, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3113, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.3025, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3111, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3214, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3373, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3135, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3111, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3098, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.3135, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3105, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3065, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3024, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3180, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3207, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3033, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2977, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3185, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3074, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2960, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3086, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2969, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3145, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3165, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2796, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2965, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3116, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2818, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3093, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.3156, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3117, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3249, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3149, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3200, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3163, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3047, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3072, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3210, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3127, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3248, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2952, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3115, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3161, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3061, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3129, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2829, device='cuda:0', grad_fn=<AddBackward0>)
The 5 training average loss: 0.31380620907092915
2025-12-15 20:10:15 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:10:15 - GraphTrainer - INFO -   precision@5: 0.006387
2025-12-15 20:10:15 - GraphTrainer - INFO -   recall@5: 0.030600
2025-12-15 20:10:15 - GraphTrainer - INFO -   hit_rate@5: 0.031936
2025-12-15 20:10:15 - GraphTrainer - INFO -   ndcg@5: 0.020112
2025-12-15 20:10:15 - GraphTrainer - INFO -   map@5: 0.016442
2025-12-15 20:10:15 - GraphTrainer - INFO -   mrr@5: 0.017182
2025-12-15 20:10:15 - GraphTrainer - INFO -   precision@10: 0.005210
2025-12-15 20:10:15 - GraphTrainer - INFO -   recall@10: 0.049757
2025-12-15 20:10:15 - GraphTrainer - INFO -   hit_rate@10: 0.052044
2025-12-15 20:10:15 - GraphTrainer - INFO -   ndcg@10: 0.026312
2025-12-15 20:10:15 - GraphTrainer - INFO -   map@10: 0.018943
2025-12-15 20:10:15 - GraphTrainer - INFO -   mrr@10: 0.019809
2025-12-15 20:10:15 - GraphTrainer - INFO -   precision@20: 0.004135
2025-12-15 20:10:15 - GraphTrainer - INFO -   recall@20: 0.078374
2025-12-15 20:10:15 - GraphTrainer - INFO -   hit_rate@20: 0.082386
2025-12-15 20:10:15 - GraphTrainer - INFO -   ndcg@20: 0.033600
2025-12-15 20:10:15 - GraphTrainer - INFO -   map@20: 0.020895
2025-12-15 20:10:15 - GraphTrainer - INFO -   mrr@20: 0.021874
2025-12-15 20:10:15 - GraphTrainer - INFO - 第 6 轮训练完成
2025-12-15 20:10:15 - GraphTrainer - INFO - train_loss: 0.303126
2025-12-15 20:10:15 - GraphTrainer - INFO - precision@5: 0.006387
2025-12-15 20:10:15 - GraphTrainer - INFO - recall@5: 0.030600
2025-12-15 20:10:15 - GraphTrainer - INFO - hit_rate@5: 0.031936
2025-12-15 20:10:15 - GraphTrainer - INFO - ndcg@5: 0.020112
2025-12-15 20:10:15 - GraphTrainer - INFO - map@5: 0.016442
2025-12-15 20:10:15 - GraphTrainer - INFO - mrr@5: 0.017182
2025-12-15 20:10:15 - GraphTrainer - INFO - precision@10: 0.005210
2025-12-15 20:10:15 - GraphTrainer - INFO - recall@10: 0.049757
2025-12-15 20:10:15 - GraphTrainer - INFO - hit_rate@10: 0.052044
2025-12-15 20:10:15 - GraphTrainer - INFO - ndcg@10: 0.026312
2025-12-15 20:10:15 - GraphTrainer - INFO - map@10: 0.018943
2025-12-15 20:10:15 - GraphTrainer - INFO - mrr@10: 0.019809
2025-12-15 20:10:15 - GraphTrainer - INFO - precision@20: 0.004135
2025-12-15 20:10:15 - GraphTrainer - INFO - recall@20: 0.078374
2025-12-15 20:10:15 - GraphTrainer - INFO - hit_rate@20: 0.082386
2025-12-15 20:10:15 - GraphTrainer - INFO - ndcg@20: 0.033600
2025-12-15 20:10:15 - GraphTrainer - INFO - map@20: 0.020895
2025-12-15 20:10:15 - GraphTrainer - INFO - mrr@20: 0.021874
2025-12-15 20:10:15 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:10:15 - GraphTrainer - INFO - ============================================================
2025-12-15 20:10:15 - GraphTrainer - INFO - 开始第 7/1000 轮训练
2025-12-15 20:10:15 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3128, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.3039, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.3171, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.3036, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3067, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2957, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.3128, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2983, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.3023, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3081, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3134, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3129, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2925, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2772, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3056, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3003, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3049, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2953, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3068, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2832, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3064, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3066, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.3225, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3024, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2909, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3011, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3299, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3024, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3144, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2933, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3038, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3053, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2815, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2950, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3193, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2954, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2984, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3211, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3084, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2946, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3060, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2927, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3085, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3039, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2917, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3093, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.3097, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.3194, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3022, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2993, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3055, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3218, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2844, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2777, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.3070, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2836, device='cuda:0', grad_fn=<AddBackward0>)
The 6 training average loss: 0.30312616403760584
2025-12-15 20:10:23 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:10:23 - GraphTrainer - INFO -   precision@5: 0.006264
2025-12-15 20:10:23 - GraphTrainer - INFO -   recall@5: 0.029877
2025-12-15 20:10:23 - GraphTrainer - INFO -   hit_rate@5: 0.031319
2025-12-15 20:10:23 - GraphTrainer - INFO -   ndcg@5: 0.019528
2025-12-15 20:10:23 - GraphTrainer - INFO -   map@5: 0.015907
2025-12-15 20:10:23 - GraphTrainer - INFO -   mrr@5: 0.016543
2025-12-15 20:10:23 - GraphTrainer - INFO -   precision@10: 0.004968
2025-12-15 20:10:23 - GraphTrainer - INFO -   recall@10: 0.047238
2025-12-15 20:10:23 - GraphTrainer - INFO -   hit_rate@10: 0.049473
2025-12-15 20:10:23 - GraphTrainer - INFO -   ndcg@10: 0.025125
2025-12-15 20:10:23 - GraphTrainer - INFO -   map@10: 0.018155
2025-12-15 20:10:23 - GraphTrainer - INFO -   mrr@10: 0.018885
2025-12-15 20:10:23 - GraphTrainer - INFO -   precision@20: 0.003883
2025-12-15 20:10:23 - GraphTrainer - INFO -   recall@20: 0.073550
2025-12-15 20:10:23 - GraphTrainer - INFO -   hit_rate@20: 0.077244
2025-12-15 20:10:23 - GraphTrainer - INFO -   ndcg@20: 0.031816
2025-12-15 20:10:23 - GraphTrainer - INFO -   map@20: 0.019948
2025-12-15 20:10:23 - GraphTrainer - INFO -   mrr@20: 0.020770
2025-12-15 20:10:23 - GraphTrainer - INFO - 第 7 轮训练完成
2025-12-15 20:10:23 - GraphTrainer - INFO - train_loss: 0.299754
2025-12-15 20:10:23 - GraphTrainer - INFO - precision@5: 0.006264
2025-12-15 20:10:23 - GraphTrainer - INFO - recall@5: 0.029877
2025-12-15 20:10:23 - GraphTrainer - INFO - hit_rate@5: 0.031319
2025-12-15 20:10:23 - GraphTrainer - INFO - ndcg@5: 0.019528
2025-12-15 20:10:23 - GraphTrainer - INFO - map@5: 0.015907
2025-12-15 20:10:23 - GraphTrainer - INFO - mrr@5: 0.016543
2025-12-15 20:10:23 - GraphTrainer - INFO - precision@10: 0.004968
2025-12-15 20:10:23 - GraphTrainer - INFO - recall@10: 0.047238
2025-12-15 20:10:23 - GraphTrainer - INFO - hit_rate@10: 0.049473
2025-12-15 20:10:23 - GraphTrainer - INFO - ndcg@10: 0.025125
2025-12-15 20:10:23 - GraphTrainer - INFO - map@10: 0.018155
2025-12-15 20:10:23 - GraphTrainer - INFO - mrr@10: 0.018885
2025-12-15 20:10:23 - GraphTrainer - INFO - precision@20: 0.003883
2025-12-15 20:10:23 - GraphTrainer - INFO - recall@20: 0.073550
2025-12-15 20:10:23 - GraphTrainer - INFO - hit_rate@20: 0.077244
2025-12-15 20:10:23 - GraphTrainer - INFO - ndcg@20: 0.031816
2025-12-15 20:10:23 - GraphTrainer - INFO - map@20: 0.019948
2025-12-15 20:10:23 - GraphTrainer - INFO - mrr@20: 0.020770
2025-12-15 20:10:23 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:10:23 - GraphTrainer - INFO - ============================================================
2025-12-15 20:10:23 - GraphTrainer - INFO - 开始第 8/1000 轮训练
2025-12-15 20:10:23 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3030, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2968, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2897, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2963, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3012, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2973, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2985, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3049, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2964, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2994, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3021, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3090, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.3245, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2914, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.3045, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3174, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2904, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3037, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3051, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.3065, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2742, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3103, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.3014, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2860, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.3070, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.3063, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2892, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3124, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.3033, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3081, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3107, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2917, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2885, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.3148, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2750, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2854, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2867, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.3005, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3098, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2969, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3169, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2914, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.3007, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2881, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3071, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.3051, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.3147, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2912, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2929, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2842, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.3022, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2988, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2747, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2858, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2767, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.3057, device='cuda:0', grad_fn=<AddBackward0>)
The 7 training average loss: 0.2997539423663041
2025-12-15 20:10:31 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:10:31 - GraphTrainer - INFO -   precision@5: 0.006500
2025-12-15 20:10:31 - GraphTrainer - INFO -   recall@5: 0.031084
2025-12-15 20:10:31 - GraphTrainer - INFO -   hit_rate@5: 0.032502
2025-12-15 20:10:31 - GraphTrainer - INFO -   ndcg@5: 0.020350
2025-12-15 20:10:31 - GraphTrainer - INFO -   map@5: 0.016592
2025-12-15 20:10:31 - GraphTrainer - INFO -   mrr@5: 0.017340
2025-12-15 20:10:31 - GraphTrainer - INFO -   precision@10: 0.005122
2025-12-15 20:10:31 - GraphTrainer - INFO -   recall@10: 0.048790
2025-12-15 20:10:31 - GraphTrainer - INFO -   hit_rate@10: 0.051016
2025-12-15 20:10:31 - GraphTrainer - INFO -   ndcg@10: 0.026083
2025-12-15 20:10:31 - GraphTrainer - INFO -   map@10: 0.018907
2025-12-15 20:10:31 - GraphTrainer - INFO -   mrr@10: 0.019758
2025-12-15 20:10:31 - GraphTrainer - INFO -   precision@20: 0.004050
2025-12-15 20:10:31 - GraphTrainer - INFO -   recall@20: 0.076592
2025-12-15 20:10:31 - GraphTrainer - INFO -   hit_rate@20: 0.080432
2025-12-15 20:10:31 - GraphTrainer - INFO -   ndcg@20: 0.033166
2025-12-15 20:10:31 - GraphTrainer - INFO -   map@20: 0.020807
2025-12-15 20:10:31 - GraphTrainer - INFO -   mrr@20: 0.021761
2025-12-15 20:10:31 - GraphTrainer - INFO - 第 8 轮训练完成
2025-12-15 20:10:31 - GraphTrainer - INFO - train_loss: 0.289952
2025-12-15 20:10:31 - GraphTrainer - INFO - precision@5: 0.006500
2025-12-15 20:10:31 - GraphTrainer - INFO - recall@5: 0.031084
2025-12-15 20:10:31 - GraphTrainer - INFO - hit_rate@5: 0.032502
2025-12-15 20:10:31 - GraphTrainer - INFO - ndcg@5: 0.020350
2025-12-15 20:10:31 - GraphTrainer - INFO - map@5: 0.016592
2025-12-15 20:10:31 - GraphTrainer - INFO - mrr@5: 0.017340
2025-12-15 20:10:31 - GraphTrainer - INFO - precision@10: 0.005122
2025-12-15 20:10:31 - GraphTrainer - INFO - recall@10: 0.048790
2025-12-15 20:10:31 - GraphTrainer - INFO - hit_rate@10: 0.051016
2025-12-15 20:10:31 - GraphTrainer - INFO - ndcg@10: 0.026083
2025-12-15 20:10:31 - GraphTrainer - INFO - map@10: 0.018907
2025-12-15 20:10:31 - GraphTrainer - INFO - mrr@10: 0.019758
2025-12-15 20:10:31 - GraphTrainer - INFO - precision@20: 0.004050
2025-12-15 20:10:31 - GraphTrainer - INFO - recall@20: 0.076592
2025-12-15 20:10:31 - GraphTrainer - INFO - hit_rate@20: 0.080432
2025-12-15 20:10:31 - GraphTrainer - INFO - ndcg@20: 0.033166
2025-12-15 20:10:31 - GraphTrainer - INFO - map@20: 0.020807
2025-12-15 20:10:31 - GraphTrainer - INFO - mrr@20: 0.021761
2025-12-15 20:10:31 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:10:31 - GraphTrainer - INFO - ============================================================
2025-12-15 20:10:31 - GraphTrainer - INFO - 开始第 9/1000 轮训练
2025-12-15 20:10:31 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.3016, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2978, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2898, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2790, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3111, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2891, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2927, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.3008, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2989, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2857, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.3262, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2812, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2919, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2829, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2771, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2771, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3013, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2796, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2823, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2879, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.3002, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.3081, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2927, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2685, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.3058, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2905, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2777, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.3268, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.3077, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2554, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2922, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2709, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2784, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3003, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2981, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2690, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.3181, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2819, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2926, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2720, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.3000, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.3086, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2709, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2724, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2923, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.3062, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2954, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2857, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2796, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2720, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.3104, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2644, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2677, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3020, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2916, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2763, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2844, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2964, device='cuda:0', grad_fn=<AddBackward0>)
The 8 training average loss: 0.2899521419714237
2025-12-15 20:10:40 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:10:40 - GraphTrainer - INFO -   precision@5: 0.006408
2025-12-15 20:10:40 - GraphTrainer - INFO -   recall@5: 0.030856
2025-12-15 20:10:40 - GraphTrainer - INFO -   hit_rate@5: 0.032039
2025-12-15 20:10:40 - GraphTrainer - INFO -   ndcg@5: 0.020232
2025-12-15 20:10:40 - GraphTrainer - INFO -   map@5: 0.016530
2025-12-15 20:10:40 - GraphTrainer - INFO -   mrr@5: 0.017194
2025-12-15 20:10:40 - GraphTrainer - INFO -   precision@10: 0.005184
2025-12-15 20:10:40 - GraphTrainer - INFO -   recall@10: 0.049380
2025-12-15 20:10:40 - GraphTrainer - INFO -   hit_rate@10: 0.051633
2025-12-15 20:10:40 - GraphTrainer - INFO -   ndcg@10: 0.026223
2025-12-15 20:10:40 - GraphTrainer - INFO -   map@10: 0.018928
2025-12-15 20:10:40 - GraphTrainer - INFO -   mrr@10: 0.019732
2025-12-15 20:10:40 - GraphTrainer - INFO -   precision@20: 0.004122
2025-12-15 20:10:40 - GraphTrainer - INFO -   recall@20: 0.078222
2025-12-15 20:10:40 - GraphTrainer - INFO -   hit_rate@20: 0.081975
2025-12-15 20:10:40 - GraphTrainer - INFO -   ndcg@20: 0.033568
2025-12-15 20:10:40 - GraphTrainer - INFO -   map@20: 0.020903
2025-12-15 20:10:40 - GraphTrainer - INFO -   mrr@20: 0.021809
2025-12-15 20:10:40 - GraphTrainer - INFO - 第 9 轮训练完成
2025-12-15 20:10:40 - GraphTrainer - INFO - train_loss: 0.289354
2025-12-15 20:10:40 - GraphTrainer - INFO - precision@5: 0.006408
2025-12-15 20:10:40 - GraphTrainer - INFO - recall@5: 0.030856
2025-12-15 20:10:40 - GraphTrainer - INFO - hit_rate@5: 0.032039
2025-12-15 20:10:40 - GraphTrainer - INFO - ndcg@5: 0.020232
2025-12-15 20:10:40 - GraphTrainer - INFO - map@5: 0.016530
2025-12-15 20:10:40 - GraphTrainer - INFO - mrr@5: 0.017194
2025-12-15 20:10:40 - GraphTrainer - INFO - precision@10: 0.005184
2025-12-15 20:10:40 - GraphTrainer - INFO - recall@10: 0.049380
2025-12-15 20:10:40 - GraphTrainer - INFO - hit_rate@10: 0.051633
2025-12-15 20:10:40 - GraphTrainer - INFO - ndcg@10: 0.026223
2025-12-15 20:10:40 - GraphTrainer - INFO - map@10: 0.018928
2025-12-15 20:10:40 - GraphTrainer - INFO - mrr@10: 0.019732
2025-12-15 20:10:40 - GraphTrainer - INFO - precision@20: 0.004122
2025-12-15 20:10:40 - GraphTrainer - INFO - recall@20: 0.078222
2025-12-15 20:10:40 - GraphTrainer - INFO - hit_rate@20: 0.081975
2025-12-15 20:10:40 - GraphTrainer - INFO - ndcg@20: 0.033568
2025-12-15 20:10:40 - GraphTrainer - INFO - map@20: 0.020903
2025-12-15 20:10:40 - GraphTrainer - INFO - mrr@20: 0.021809
2025-12-15 20:10:40 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:10:40 - GraphTrainer - INFO - ============================================================
2025-12-15 20:10:40 - GraphTrainer - INFO - 开始第 10/1000 轮训练
2025-12-15 20:10:40 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2778, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2975, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2888, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2766, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2794, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2908, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2858, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2965, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2862, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2904, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2674, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2809, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2680, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2855, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.3092, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.3116, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.3234, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2813, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2876, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2933, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2666, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2675, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2771, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2772, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2899, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2753, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2638, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2968, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2806, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.3095, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.3000, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3032, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2875, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2771, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2946, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2850, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2884, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2933, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2974, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2829, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.3040, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2928, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2970, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2849, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2994, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2887, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2892, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2684, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2894, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2888, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2978, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.3093, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.3020, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2668, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2762, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2862, device='cuda:0', grad_fn=<AddBackward0>)
The 9 training average loss: 0.28935411880756245
2025-12-15 20:10:48 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:10:48 - GraphTrainer - INFO -   precision@5: 0.006305
2025-12-15 20:10:48 - GraphTrainer - INFO -   recall@5: 0.030191
2025-12-15 20:10:48 - GraphTrainer - INFO -   hit_rate@5: 0.031525
2025-12-15 20:10:48 - GraphTrainer - INFO -   ndcg@5: 0.020179
2025-12-15 20:10:48 - GraphTrainer - INFO -   map@5: 0.016667
2025-12-15 20:10:48 - GraphTrainer - INFO -   mrr@5: 0.017361
2025-12-15 20:10:48 - GraphTrainer - INFO -   precision@10: 0.005168
2025-12-15 20:10:48 - GraphTrainer - INFO -   recall@10: 0.049148
2025-12-15 20:10:48 - GraphTrainer - INFO -   hit_rate@10: 0.051427
2025-12-15 20:10:48 - GraphTrainer - INFO -   ndcg@10: 0.026323
2025-12-15 20:10:48 - GraphTrainer - INFO -   map@10: 0.019141
2025-12-15 20:10:48 - GraphTrainer - INFO -   mrr@10: 0.019955
2025-12-15 20:10:48 - GraphTrainer - INFO -   precision@20: 0.004124
2025-12-15 20:10:48 - GraphTrainer - INFO -   recall@20: 0.077980
2025-12-15 20:10:48 - GraphTrainer - INFO -   hit_rate@20: 0.081923
2025-12-15 20:10:48 - GraphTrainer - INFO -   ndcg@20: 0.033662
2025-12-15 20:10:48 - GraphTrainer - INFO -   map@20: 0.021108
2025-12-15 20:10:48 - GraphTrainer - INFO -   mrr@20: 0.022032
2025-12-15 20:10:48 - GraphTrainer - INFO - 第 10 轮训练完成
2025-12-15 20:10:48 - GraphTrainer - INFO - train_loss: 0.279700
2025-12-15 20:10:48 - GraphTrainer - INFO - precision@5: 0.006305
2025-12-15 20:10:48 - GraphTrainer - INFO - recall@5: 0.030191
2025-12-15 20:10:48 - GraphTrainer - INFO - hit_rate@5: 0.031525
2025-12-15 20:10:48 - GraphTrainer - INFO - ndcg@5: 0.020179
2025-12-15 20:10:48 - GraphTrainer - INFO - map@5: 0.016667
2025-12-15 20:10:48 - GraphTrainer - INFO - mrr@5: 0.017361
2025-12-15 20:10:48 - GraphTrainer - INFO - precision@10: 0.005168
2025-12-15 20:10:48 - GraphTrainer - INFO - recall@10: 0.049148
2025-12-15 20:10:48 - GraphTrainer - INFO - hit_rate@10: 0.051427
2025-12-15 20:10:48 - GraphTrainer - INFO - ndcg@10: 0.026323
2025-12-15 20:10:48 - GraphTrainer - INFO - map@10: 0.019141
2025-12-15 20:10:48 - GraphTrainer - INFO - mrr@10: 0.019955
2025-12-15 20:10:48 - GraphTrainer - INFO - precision@20: 0.004124
2025-12-15 20:10:48 - GraphTrainer - INFO - recall@20: 0.077980
2025-12-15 20:10:48 - GraphTrainer - INFO - hit_rate@20: 0.081923
2025-12-15 20:10:48 - GraphTrainer - INFO - ndcg@20: 0.033662
2025-12-15 20:10:48 - GraphTrainer - INFO - map@20: 0.021108
2025-12-15 20:10:48 - GraphTrainer - INFO - mrr@20: 0.022032
2025-12-15 20:10:48 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:10:48 - GraphTrainer - INFO - 检查点已保存: Epoch 10 -> ./checkpoints/checkpoint_epoch_10.pth
2025-12-15 20:10:48 - GraphTrainer - INFO - ============================================================
2025-12-15 20:10:48 - GraphTrainer - INFO - 开始第 11/1000 轮训练
2025-12-15 20:10:48 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2649, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2904, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2624, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2818, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2656, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2846, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2997, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2920, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2616, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2573, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2942, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2779, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2899, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2750, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2621, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2754, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2980, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2818, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.3047, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2804, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2732, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2836, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2754, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2648, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2996, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2549, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2807, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2805, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2821, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2597, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2840, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2920, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2789, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2732, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.3026, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2704, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2908, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2663, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2596, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2817, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2711, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2580, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2729, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.3015, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2795, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2997, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2910, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2916, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2771, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2591, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.3052, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2766, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2615, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2881, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2941, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2878, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2810, device='cuda:0', grad_fn=<AddBackward0>)
The 10 training average loss: 0.27970012457206334
2025-12-15 20:10:57 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:10:57 - GraphTrainer - INFO -   precision@5: 0.006428
2025-12-15 20:10:57 - GraphTrainer - INFO -   recall@5: 0.030867
2025-12-15 20:10:57 - GraphTrainer - INFO -   hit_rate@5: 0.032091
2025-12-15 20:10:57 - GraphTrainer - INFO -   ndcg@5: 0.020394
2025-12-15 20:10:57 - GraphTrainer - INFO -   map@5: 0.016739
2025-12-15 20:10:57 - GraphTrainer - INFO -   mrr@5: 0.017418
2025-12-15 20:10:57 - GraphTrainer - INFO -   precision@10: 0.005379
2025-12-15 20:10:57 - GraphTrainer - INFO -   recall@10: 0.051076
2025-12-15 20:10:57 - GraphTrainer - INFO -   hit_rate@10: 0.053638
2025-12-15 20:10:57 - GraphTrainer - INFO -   ndcg@10: 0.026928
2025-12-15 20:10:57 - GraphTrainer - INFO -   map@10: 0.019347
2025-12-15 20:10:57 - GraphTrainer - INFO -   mrr@10: 0.020200
2025-12-15 20:10:57 - GraphTrainer - INFO -   precision@20: 0.004199
2025-12-15 20:10:57 - GraphTrainer - INFO -   recall@20: 0.079422
2025-12-15 20:10:57 - GraphTrainer - INFO -   hit_rate@20: 0.083466
2025-12-15 20:10:57 - GraphTrainer - INFO -   ndcg@20: 0.034178
2025-12-15 20:10:57 - GraphTrainer - INFO -   map@20: 0.021312
2025-12-15 20:10:57 - GraphTrainer - INFO -   mrr@20: 0.022262
2025-12-15 20:10:57 - GraphTrainer - INFO - 第 11 轮训练完成
2025-12-15 20:10:57 - GraphTrainer - INFO - train_loss: 0.274098
2025-12-15 20:10:57 - GraphTrainer - INFO - precision@5: 0.006428
2025-12-15 20:10:57 - GraphTrainer - INFO - recall@5: 0.030867
2025-12-15 20:10:57 - GraphTrainer - INFO - hit_rate@5: 0.032091
2025-12-15 20:10:57 - GraphTrainer - INFO - ndcg@5: 0.020394
2025-12-15 20:10:57 - GraphTrainer - INFO - map@5: 0.016739
2025-12-15 20:10:57 - GraphTrainer - INFO - mrr@5: 0.017418
2025-12-15 20:10:57 - GraphTrainer - INFO - precision@10: 0.005379
2025-12-15 20:10:57 - GraphTrainer - INFO - recall@10: 0.051076
2025-12-15 20:10:57 - GraphTrainer - INFO - hit_rate@10: 0.053638
2025-12-15 20:10:57 - GraphTrainer - INFO - ndcg@10: 0.026928
2025-12-15 20:10:57 - GraphTrainer - INFO - map@10: 0.019347
2025-12-15 20:10:57 - GraphTrainer - INFO - mrr@10: 0.020200
2025-12-15 20:10:57 - GraphTrainer - INFO - precision@20: 0.004199
2025-12-15 20:10:57 - GraphTrainer - INFO - recall@20: 0.079422
2025-12-15 20:10:57 - GraphTrainer - INFO - hit_rate@20: 0.083466
2025-12-15 20:10:57 - GraphTrainer - INFO - ndcg@20: 0.034178
2025-12-15 20:10:57 - GraphTrainer - INFO - map@20: 0.021312
2025-12-15 20:10:57 - GraphTrainer - INFO - mrr@20: 0.022262
2025-12-15 20:10:57 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:10:57 - GraphTrainer - INFO - ============================================================
2025-12-15 20:10:57 - GraphTrainer - INFO - 开始第 12/1000 轮训练
2025-12-15 20:10:57 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2959, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2795, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2815, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2735, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2797, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2954, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2868, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2848, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2771, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2863, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2698, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.3008, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2630, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2581, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2852, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2722, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2806, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2732, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2539, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2610, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2788, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2709, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2860, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2676, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2519, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2752, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2592, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2778, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2749, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2556, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2804, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2727, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2597, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.3123, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2704, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2834, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2893, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2725, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2772, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2667, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2665, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2718, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2603, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2562, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2627, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2860, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2710, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2457, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2856, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2635, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2508, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2702, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2851, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2913, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2696, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2695, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2810, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2698, device='cuda:0', grad_fn=<AddBackward0>)
The 11 training average loss: 0.27409750814067907
2025-12-15 20:11:05 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:11:05 - GraphTrainer - INFO -   precision@5: 0.006336
2025-12-15 20:11:05 - GraphTrainer - INFO -   recall@5: 0.030237
2025-12-15 20:11:05 - GraphTrainer - INFO -   hit_rate@5: 0.031628
2025-12-15 20:11:05 - GraphTrainer - INFO -   ndcg@5: 0.019967
2025-12-15 20:11:05 - GraphTrainer - INFO -   map@5: 0.016345
2025-12-15 20:11:05 - GraphTrainer - INFO -   mrr@5: 0.017115
2025-12-15 20:11:05 - GraphTrainer - INFO -   precision@10: 0.005297
2025-12-15 20:11:05 - GraphTrainer - INFO -   recall@10: 0.050370
2025-12-15 20:11:05 - GraphTrainer - INFO -   hit_rate@10: 0.052816
2025-12-15 20:11:05 - GraphTrainer - INFO -   ndcg@10: 0.026489
2025-12-15 20:11:05 - GraphTrainer - INFO -   map@10: 0.018976
2025-12-15 20:11:05 - GraphTrainer - INFO -   mrr@10: 0.019884
2025-12-15 20:11:05 - GraphTrainer - INFO -   precision@20: 0.004256
2025-12-15 20:11:05 - GraphTrainer - INFO -   recall@20: 0.080537
2025-12-15 20:11:05 - GraphTrainer - INFO -   hit_rate@20: 0.084649
2025-12-15 20:11:05 - GraphTrainer - INFO -   ndcg@20: 0.034151
2025-12-15 20:11:05 - GraphTrainer - INFO -   map@20: 0.021023
2025-12-15 20:11:05 - GraphTrainer - INFO -   mrr@20: 0.022040
2025-12-15 20:11:05 - GraphTrainer - INFO - 第 12 轮训练完成
2025-12-15 20:11:05 - GraphTrainer - INFO - train_loss: 0.273456
2025-12-15 20:11:05 - GraphTrainer - INFO - precision@5: 0.006336
2025-12-15 20:11:05 - GraphTrainer - INFO - recall@5: 0.030237
2025-12-15 20:11:05 - GraphTrainer - INFO - hit_rate@5: 0.031628
2025-12-15 20:11:05 - GraphTrainer - INFO - ndcg@5: 0.019967
2025-12-15 20:11:05 - GraphTrainer - INFO - map@5: 0.016345
2025-12-15 20:11:05 - GraphTrainer - INFO - mrr@5: 0.017115
2025-12-15 20:11:05 - GraphTrainer - INFO - precision@10: 0.005297
2025-12-15 20:11:05 - GraphTrainer - INFO - recall@10: 0.050370
2025-12-15 20:11:05 - GraphTrainer - INFO - hit_rate@10: 0.052816
2025-12-15 20:11:05 - GraphTrainer - INFO - ndcg@10: 0.026489
2025-12-15 20:11:05 - GraphTrainer - INFO - map@10: 0.018976
2025-12-15 20:11:05 - GraphTrainer - INFO - mrr@10: 0.019884
2025-12-15 20:11:05 - GraphTrainer - INFO - precision@20: 0.004256
2025-12-15 20:11:05 - GraphTrainer - INFO - recall@20: 0.080537
2025-12-15 20:11:05 - GraphTrainer - INFO - hit_rate@20: 0.084649
2025-12-15 20:11:05 - GraphTrainer - INFO - ndcg@20: 0.034151
2025-12-15 20:11:05 - GraphTrainer - INFO - map@20: 0.021023
2025-12-15 20:11:05 - GraphTrainer - INFO - mrr@20: 0.022040
2025-12-15 20:11:05 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:11:05 - GraphTrainer - INFO - ============================================================
2025-12-15 20:11:05 - GraphTrainer - INFO - 开始第 13/1000 轮训练
2025-12-15 20:11:05 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2670, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2684, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2948, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2522, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2671, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2791, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2653, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2424, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2565, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2670, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2936, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2885, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2887, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2489, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2778, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2892, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2610, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2897, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2842, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2608, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2852, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2904, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2526, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2669, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2927, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2555, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2687, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2671, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2812, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2846, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2674, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2637, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2933, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2787, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2619, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2695, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2699, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2632, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2689, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2700, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2926, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2833, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2800, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2671, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2923, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2626, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2787, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2815, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2793, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2676, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2652, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2941, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2806, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2568, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2735, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2763, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2794, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2563, device='cuda:0', grad_fn=<AddBackward0>)
The 12 training average loss: 0.2734563674392371
2025-12-15 20:11:13 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:11:13 - GraphTrainer - INFO -   precision@5: 0.006439
2025-12-15 20:11:13 - GraphTrainer - INFO -   recall@5: 0.030796
2025-12-15 20:11:13 - GraphTrainer - INFO -   hit_rate@5: 0.032193
2025-12-15 20:11:13 - GraphTrainer - INFO -   ndcg@5: 0.020554
2025-12-15 20:11:13 - GraphTrainer - INFO -   map@5: 0.016934
2025-12-15 20:11:13 - GraphTrainer - INFO -   mrr@5: 0.017713
2025-12-15 20:11:13 - GraphTrainer - INFO -   precision@10: 0.005246
2025-12-15 20:11:13 - GraphTrainer - INFO -   recall@10: 0.049874
2025-12-15 20:11:13 - GraphTrainer - INFO -   hit_rate@10: 0.052353
2025-12-15 20:11:13 - GraphTrainer - INFO -   ndcg@10: 0.026765
2025-12-15 20:11:13 - GraphTrainer - INFO -   map@10: 0.019450
2025-12-15 20:11:13 - GraphTrainer - INFO -   mrr@10: 0.020367
2025-12-15 20:11:13 - GraphTrainer - INFO -   precision@20: 0.004268
2025-12-15 20:11:13 - GraphTrainer - INFO -   recall@20: 0.080624
2025-12-15 20:11:13 - GraphTrainer - INFO -   hit_rate@20: 0.084803
2025-12-15 20:11:13 - GraphTrainer - INFO -   ndcg@20: 0.034591
2025-12-15 20:11:13 - GraphTrainer - INFO -   map@20: 0.021545
2025-12-15 20:11:13 - GraphTrainer - INFO -   mrr@20: 0.022573
2025-12-15 20:11:13 - GraphTrainer - INFO - 第 13 轮训练完成
2025-12-15 20:11:13 - GraphTrainer - INFO - train_loss: 0.271505
2025-12-15 20:11:13 - GraphTrainer - INFO - precision@5: 0.006439
2025-12-15 20:11:13 - GraphTrainer - INFO - recall@5: 0.030796
2025-12-15 20:11:13 - GraphTrainer - INFO - hit_rate@5: 0.032193
2025-12-15 20:11:13 - GraphTrainer - INFO - ndcg@5: 0.020554
2025-12-15 20:11:13 - GraphTrainer - INFO - map@5: 0.016934
2025-12-15 20:11:13 - GraphTrainer - INFO - mrr@5: 0.017713
2025-12-15 20:11:13 - GraphTrainer - INFO - precision@10: 0.005246
2025-12-15 20:11:13 - GraphTrainer - INFO - recall@10: 0.049874
2025-12-15 20:11:13 - GraphTrainer - INFO - hit_rate@10: 0.052353
2025-12-15 20:11:13 - GraphTrainer - INFO - ndcg@10: 0.026765
2025-12-15 20:11:13 - GraphTrainer - INFO - map@10: 0.019450
2025-12-15 20:11:13 - GraphTrainer - INFO - mrr@10: 0.020367
2025-12-15 20:11:13 - GraphTrainer - INFO - precision@20: 0.004268
2025-12-15 20:11:13 - GraphTrainer - INFO - recall@20: 0.080624
2025-12-15 20:11:13 - GraphTrainer - INFO - hit_rate@20: 0.084803
2025-12-15 20:11:13 - GraphTrainer - INFO - ndcg@20: 0.034591
2025-12-15 20:11:13 - GraphTrainer - INFO - map@20: 0.021545
2025-12-15 20:11:13 - GraphTrainer - INFO - mrr@20: 0.022573
2025-12-15 20:11:13 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:11:13 - GraphTrainer - INFO - ============================================================
2025-12-15 20:11:13 - GraphTrainer - INFO - 开始第 14/1000 轮训练
2025-12-15 20:11:13 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2872, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2624, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2526, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2601, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2567, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2671, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2809, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2795, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2803, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2795, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2754, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2681, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2492, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2783, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2694, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2774, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2872, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2666, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2755, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2473, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2706, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2989, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2695, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2698, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2533, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2647, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2697, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2725, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2947, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2840, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2778, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2508, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2647, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2726, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2747, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2723, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2808, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2881, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.3013, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2735, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2734, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2630, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2618, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2727, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2818, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2555, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2692, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2789, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2777, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2739, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2788, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2557, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2833, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2553, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2828, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2532, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2643, device='cuda:0', grad_fn=<AddBackward0>)
The 13 training average loss: 0.2715045527137559
2025-12-15 20:11:22 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:11:22 - GraphTrainer - INFO -   precision@5: 0.006500
2025-12-15 20:11:22 - GraphTrainer - INFO -   recall@5: 0.031066
2025-12-15 20:11:22 - GraphTrainer - INFO -   hit_rate@5: 0.032451
2025-12-15 20:11:22 - GraphTrainer - INFO -   ndcg@5: 0.020754
2025-12-15 20:11:22 - GraphTrainer - INFO -   map@5: 0.017115
2025-12-15 20:11:22 - GraphTrainer - INFO -   mrr@5: 0.017911
2025-12-15 20:11:22 - GraphTrainer - INFO -   precision@10: 0.005415
2025-12-15 20:11:22 - GraphTrainer - INFO -   recall@10: 0.051549
2025-12-15 20:11:22 - GraphTrainer - INFO -   hit_rate@10: 0.053998
2025-12-15 20:11:22 - GraphTrainer - INFO -   ndcg@10: 0.027350
2025-12-15 20:11:22 - GraphTrainer - INFO -   map@10: 0.019752
2025-12-15 20:11:22 - GraphTrainer - INFO -   mrr@10: 0.020684
2025-12-15 20:11:22 - GraphTrainer - INFO -   precision@20: 0.004340
2025-12-15 20:11:22 - GraphTrainer - INFO -   recall@20: 0.082328
2025-12-15 20:11:22 - GraphTrainer - INFO -   hit_rate@20: 0.086346
2025-12-15 20:11:22 - GraphTrainer - INFO -   ndcg@20: 0.035195
2025-12-15 20:11:22 - GraphTrainer - INFO -   map@20: 0.021867
2025-12-15 20:11:22 - GraphTrainer - INFO -   mrr@20: 0.022902
2025-12-15 20:11:22 - GraphTrainer - INFO - 第 14 轮训练完成
2025-12-15 20:11:22 - GraphTrainer - INFO - train_loss: 0.267208
2025-12-15 20:11:22 - GraphTrainer - INFO - precision@5: 0.006500
2025-12-15 20:11:22 - GraphTrainer - INFO - recall@5: 0.031066
2025-12-15 20:11:22 - GraphTrainer - INFO - hit_rate@5: 0.032451
2025-12-15 20:11:22 - GraphTrainer - INFO - ndcg@5: 0.020754
2025-12-15 20:11:22 - GraphTrainer - INFO - map@5: 0.017115
2025-12-15 20:11:22 - GraphTrainer - INFO - mrr@5: 0.017911
2025-12-15 20:11:22 - GraphTrainer - INFO - precision@10: 0.005415
2025-12-15 20:11:22 - GraphTrainer - INFO - recall@10: 0.051549
2025-12-15 20:11:22 - GraphTrainer - INFO - hit_rate@10: 0.053998
2025-12-15 20:11:22 - GraphTrainer - INFO - ndcg@10: 0.027350
2025-12-15 20:11:22 - GraphTrainer - INFO - map@10: 0.019752
2025-12-15 20:11:22 - GraphTrainer - INFO - mrr@10: 0.020684
2025-12-15 20:11:22 - GraphTrainer - INFO - precision@20: 0.004340
2025-12-15 20:11:22 - GraphTrainer - INFO - recall@20: 0.082328
2025-12-15 20:11:22 - GraphTrainer - INFO - hit_rate@20: 0.086346
2025-12-15 20:11:22 - GraphTrainer - INFO - ndcg@20: 0.035195
2025-12-15 20:11:22 - GraphTrainer - INFO - map@20: 0.021867
2025-12-15 20:11:22 - GraphTrainer - INFO - mrr@20: 0.022902
2025-12-15 20:11:22 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:11:22 - GraphTrainer - INFO - ============================================================
2025-12-15 20:11:22 - GraphTrainer - INFO - 开始第 15/1000 轮训练
2025-12-15 20:11:22 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2576, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2552, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2532, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2710, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2448, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2833, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2781, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2867, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2659, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2638, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2554, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2657, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2744, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2625, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2618, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2798, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2686, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2937, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2815, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2619, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2622, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2787, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2698, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2607, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2753, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2861, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2609, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2401, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2679, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2659, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2962, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2525, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2600, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2585, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2582, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2697, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2672, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2514, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2688, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2680, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2741, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2808, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2819, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2788, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2476, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2554, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2651, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2879, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2982, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2675, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2482, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2535, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2480, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2553, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2833, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2802, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2481, device='cuda:0', grad_fn=<AddBackward0>)
The 14 training average loss: 0.2672080944838195
2025-12-15 20:11:30 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:11:30 - GraphTrainer - INFO -   precision@5: 0.006356
2025-12-15 20:11:30 - GraphTrainer - INFO -   recall@5: 0.030642
2025-12-15 20:11:30 - GraphTrainer - INFO -   hit_rate@5: 0.031782
2025-12-15 20:11:30 - GraphTrainer - INFO -   ndcg@5: 0.020549
2025-12-15 20:11:30 - GraphTrainer - INFO -   map@5: 0.017032
2025-12-15 20:11:30 - GraphTrainer - INFO -   mrr@5: 0.017727
2025-12-15 20:11:30 - GraphTrainer - INFO -   precision@10: 0.005379
2025-12-15 20:11:30 - GraphTrainer - INFO -   recall@10: 0.051320
2025-12-15 20:11:30 - GraphTrainer - INFO -   hit_rate@10: 0.053741
2025-12-15 20:11:30 - GraphTrainer - INFO -   ndcg@10: 0.027254
2025-12-15 20:11:30 - GraphTrainer - INFO -   map@10: 0.019729
2025-12-15 20:11:30 - GraphTrainer - INFO -   mrr@10: 0.020583
2025-12-15 20:11:30 - GraphTrainer - INFO -   precision@20: 0.004312
2025-12-15 20:11:30 - GraphTrainer - INFO -   recall@20: 0.081635
2025-12-15 20:11:30 - GraphTrainer - INFO -   hit_rate@20: 0.085780
2025-12-15 20:11:30 - GraphTrainer - INFO -   ndcg@20: 0.034937
2025-12-15 20:11:30 - GraphTrainer - INFO -   map@20: 0.021765
2025-12-15 20:11:30 - GraphTrainer - INFO -   mrr@20: 0.022730
2025-12-15 20:11:30 - GraphTrainer - INFO - 第 15 轮训练完成
2025-12-15 20:11:30 - GraphTrainer - INFO - train_loss: 0.264760
2025-12-15 20:11:30 - GraphTrainer - INFO - precision@5: 0.006356
2025-12-15 20:11:30 - GraphTrainer - INFO - recall@5: 0.030642
2025-12-15 20:11:30 - GraphTrainer - INFO - hit_rate@5: 0.031782
2025-12-15 20:11:30 - GraphTrainer - INFO - ndcg@5: 0.020549
2025-12-15 20:11:30 - GraphTrainer - INFO - map@5: 0.017032
2025-12-15 20:11:30 - GraphTrainer - INFO - mrr@5: 0.017727
2025-12-15 20:11:30 - GraphTrainer - INFO - precision@10: 0.005379
2025-12-15 20:11:30 - GraphTrainer - INFO - recall@10: 0.051320
2025-12-15 20:11:30 - GraphTrainer - INFO - hit_rate@10: 0.053741
2025-12-15 20:11:30 - GraphTrainer - INFO - ndcg@10: 0.027254
2025-12-15 20:11:30 - GraphTrainer - INFO - map@10: 0.019729
2025-12-15 20:11:30 - GraphTrainer - INFO - mrr@10: 0.020583
2025-12-15 20:11:30 - GraphTrainer - INFO - precision@20: 0.004312
2025-12-15 20:11:30 - GraphTrainer - INFO - recall@20: 0.081635
2025-12-15 20:11:30 - GraphTrainer - INFO - hit_rate@20: 0.085780
2025-12-15 20:11:30 - GraphTrainer - INFO - ndcg@20: 0.034937
2025-12-15 20:11:30 - GraphTrainer - INFO - map@20: 0.021765
2025-12-15 20:11:30 - GraphTrainer - INFO - mrr@20: 0.022730
2025-12-15 20:11:30 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:11:30 - GraphTrainer - INFO - ============================================================
2025-12-15 20:11:30 - GraphTrainer - INFO - 开始第 16/1000 轮训练
2025-12-15 20:11:30 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2495, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2774, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2734, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2665, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2508, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2675, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2759, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2710, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2577, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2554, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2917, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2665, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2721, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2836, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2728, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2694, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2640, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2674, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2532, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2476, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2592, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2488, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2491, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2716, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2666, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2395, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2592, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2761, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2625, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2695, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2421, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2774, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2636, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2550, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2547, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2446, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2500, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2564, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2599, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2530, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2730, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2590, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2739, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2781, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2717, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2925, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2404, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2706, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2483, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2741, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2805, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2579, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2788, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2699, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2651, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2721, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2694, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2884, device='cuda:0', grad_fn=<AddBackward0>)
The 15 training average loss: 0.2647602601811804
2025-12-15 20:11:38 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:11:38 - GraphTrainer - INFO -   precision@5: 0.006778
2025-12-15 20:11:38 - GraphTrainer - INFO -   recall@5: 0.032494
2025-12-15 20:11:38 - GraphTrainer - INFO -   hit_rate@5: 0.033890
2025-12-15 20:11:38 - GraphTrainer - INFO -   ndcg@5: 0.021506
2025-12-15 20:11:38 - GraphTrainer - INFO -   map@5: 0.017652
2025-12-15 20:11:38 - GraphTrainer - INFO -   mrr@5: 0.018472
2025-12-15 20:11:38 - GraphTrainer - INFO -   precision@10: 0.005384
2025-12-15 20:11:38 - GraphTrainer - INFO -   recall@10: 0.051390
2025-12-15 20:11:38 - GraphTrainer - INFO -   hit_rate@10: 0.053690
2025-12-15 20:11:38 - GraphTrainer - INFO -   ndcg@10: 0.027630
2025-12-15 20:11:38 - GraphTrainer - INFO -   map@10: 0.020127
2025-12-15 20:11:38 - GraphTrainer - INFO -   mrr@10: 0.021061
2025-12-15 20:11:38 - GraphTrainer - INFO -   precision@20: 0.004361
2025-12-15 20:11:38 - GraphTrainer - INFO -   recall@20: 0.082697
2025-12-15 20:11:38 - GraphTrainer - INFO -   hit_rate@20: 0.086809
2025-12-15 20:11:38 - GraphTrainer - INFO -   ndcg@20: 0.035588
2025-12-15 20:11:38 - GraphTrainer - INFO -   map@20: 0.022252
2025-12-15 20:11:38 - GraphTrainer - INFO -   mrr@20: 0.023303
2025-12-15 20:11:38 - GraphTrainer - INFO - 第 16 轮训练完成
2025-12-15 20:11:38 - GraphTrainer - INFO - train_loss: 0.263563
2025-12-15 20:11:38 - GraphTrainer - INFO - precision@5: 0.006778
2025-12-15 20:11:38 - GraphTrainer - INFO - recall@5: 0.032494
2025-12-15 20:11:38 - GraphTrainer - INFO - hit_rate@5: 0.033890
2025-12-15 20:11:38 - GraphTrainer - INFO - ndcg@5: 0.021506
2025-12-15 20:11:38 - GraphTrainer - INFO - map@5: 0.017652
2025-12-15 20:11:38 - GraphTrainer - INFO - mrr@5: 0.018472
2025-12-15 20:11:38 - GraphTrainer - INFO - precision@10: 0.005384
2025-12-15 20:11:38 - GraphTrainer - INFO - recall@10: 0.051390
2025-12-15 20:11:38 - GraphTrainer - INFO - hit_rate@10: 0.053690
2025-12-15 20:11:38 - GraphTrainer - INFO - ndcg@10: 0.027630
2025-12-15 20:11:38 - GraphTrainer - INFO - map@10: 0.020127
2025-12-15 20:11:38 - GraphTrainer - INFO - mrr@10: 0.021061
2025-12-15 20:11:38 - GraphTrainer - INFO - precision@20: 0.004361
2025-12-15 20:11:38 - GraphTrainer - INFO - recall@20: 0.082697
2025-12-15 20:11:38 - GraphTrainer - INFO - hit_rate@20: 0.086809
2025-12-15 20:11:38 - GraphTrainer - INFO - ndcg@20: 0.035588
2025-12-15 20:11:38 - GraphTrainer - INFO - map@20: 0.022252
2025-12-15 20:11:38 - GraphTrainer - INFO - mrr@20: 0.023303
2025-12-15 20:11:38 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:11:38 - GraphTrainer - INFO - ============================================================
2025-12-15 20:11:38 - GraphTrainer - INFO - 开始第 17/1000 轮训练
2025-12-15 20:11:38 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2610, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2629, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2671, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2533, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2379, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2604, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2728, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2713, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2572, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2664, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2528, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2678, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2563, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2494, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2546, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2790, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2644, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2523, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2617, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2594, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2688, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2701, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2710, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2484, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2626, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2647, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2662, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2679, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2740, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2661, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2762, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2714, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2699, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2649, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2794, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2671, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2670, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2758, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2725, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2505, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2578, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2497, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2559, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2968, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2678, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2564, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2462, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2711, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2587, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2347, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2492, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2594, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2765, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2578, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2695, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2631, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2924, device='cuda:0', grad_fn=<AddBackward0>)
The 16 training average loss: 0.2635625110104166
2025-12-15 20:11:47 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:11:47 - GraphTrainer - INFO -   precision@5: 0.006490
2025-12-15 20:11:47 - GraphTrainer - INFO -   recall@5: 0.031105
2025-12-15 20:11:47 - GraphTrainer - INFO -   hit_rate@5: 0.032451
2025-12-15 20:11:47 - GraphTrainer - INFO -   ndcg@5: 0.020601
2025-12-15 20:11:47 - GraphTrainer - INFO -   map@5: 0.016919
2025-12-15 20:11:47 - GraphTrainer - INFO -   mrr@5: 0.017672
2025-12-15 20:11:47 - GraphTrainer - INFO -   precision@10: 0.005410
2025-12-15 20:11:47 - GraphTrainer - INFO -   recall@10: 0.051388
2025-12-15 20:11:47 - GraphTrainer - INFO -   hit_rate@10: 0.053998
2025-12-15 20:11:47 - GraphTrainer - INFO -   ndcg@10: 0.027155
2025-12-15 20:11:47 - GraphTrainer - INFO -   map@10: 0.019536
2025-12-15 20:11:47 - GraphTrainer - INFO -   mrr@10: 0.020453
2025-12-15 20:11:47 - GraphTrainer - INFO -   precision@20: 0.004330
2025-12-15 20:11:47 - GraphTrainer - INFO -   recall@20: 0.082051
2025-12-15 20:11:47 - GraphTrainer - INFO -   hit_rate@20: 0.086038
2025-12-15 20:11:47 - GraphTrainer - INFO -   ndcg@20: 0.034920
2025-12-15 20:11:47 - GraphTrainer - INFO -   map@20: 0.021609
2025-12-15 20:11:47 - GraphTrainer - INFO -   mrr@20: 0.022614
2025-12-15 20:11:47 - GraphTrainer - INFO - 第 17 轮训练完成
2025-12-15 20:11:47 - GraphTrainer - INFO - train_loss: 0.258686
2025-12-15 20:11:47 - GraphTrainer - INFO - precision@5: 0.006490
2025-12-15 20:11:47 - GraphTrainer - INFO - recall@5: 0.031105
2025-12-15 20:11:47 - GraphTrainer - INFO - hit_rate@5: 0.032451
2025-12-15 20:11:47 - GraphTrainer - INFO - ndcg@5: 0.020601
2025-12-15 20:11:47 - GraphTrainer - INFO - map@5: 0.016919
2025-12-15 20:11:47 - GraphTrainer - INFO - mrr@5: 0.017672
2025-12-15 20:11:47 - GraphTrainer - INFO - precision@10: 0.005410
2025-12-15 20:11:47 - GraphTrainer - INFO - recall@10: 0.051388
2025-12-15 20:11:47 - GraphTrainer - INFO - hit_rate@10: 0.053998
2025-12-15 20:11:47 - GraphTrainer - INFO - ndcg@10: 0.027155
2025-12-15 20:11:47 - GraphTrainer - INFO - map@10: 0.019536
2025-12-15 20:11:47 - GraphTrainer - INFO - mrr@10: 0.020453
2025-12-15 20:11:47 - GraphTrainer - INFO - precision@20: 0.004330
2025-12-15 20:11:47 - GraphTrainer - INFO - recall@20: 0.082051
2025-12-15 20:11:47 - GraphTrainer - INFO - hit_rate@20: 0.086038
2025-12-15 20:11:47 - GraphTrainer - INFO - ndcg@20: 0.034920
2025-12-15 20:11:47 - GraphTrainer - INFO - map@20: 0.021609
2025-12-15 20:11:47 - GraphTrainer - INFO - mrr@20: 0.022614
2025-12-15 20:11:47 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:11:47 - GraphTrainer - INFO - ============================================================
2025-12-15 20:11:47 - GraphTrainer - INFO - 开始第 18/1000 轮训练
2025-12-15 20:11:47 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2696, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2522, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2637, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2374, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2725, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2584, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2898, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2516, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2592, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2782, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2558, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2357, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2628, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2420, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2608, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2629, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2603, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2582, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2397, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2440, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2662, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2663, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2774, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2302, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2566, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2700, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2820, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2698, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2472, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2716, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2716, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2606, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2749, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2258, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2553, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2638, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2400, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2742, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2631, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2516, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2550, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2612, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2567, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2655, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2608, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2558, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2365, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2619, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2431, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2647, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2606, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2337, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2606, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2790, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2753, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2623, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2595, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2388, device='cuda:0', grad_fn=<AddBackward0>)
The 17 training average loss: 0.25868551150478164
2025-12-15 20:11:55 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:11:55 - GraphTrainer - INFO -   precision@5: 0.006459
2025-12-15 20:11:55 - GraphTrainer - INFO -   recall@5: 0.031140
2025-12-15 20:11:55 - GraphTrainer - INFO -   hit_rate@5: 0.032296
2025-12-15 20:11:55 - GraphTrainer - INFO -   ndcg@5: 0.020604
2025-12-15 20:11:55 - GraphTrainer - INFO -   map@5: 0.016931
2025-12-15 20:11:55 - GraphTrainer - INFO -   mrr@5: 0.017654
2025-12-15 20:11:55 - GraphTrainer - INFO -   precision@10: 0.005400
2025-12-15 20:11:55 - GraphTrainer - INFO -   recall@10: 0.051397
2025-12-15 20:11:55 - GraphTrainer - INFO -   hit_rate@10: 0.053947
2025-12-15 20:11:55 - GraphTrainer - INFO -   ndcg@10: 0.027156
2025-12-15 20:11:55 - GraphTrainer - INFO -   map@10: 0.019544
2025-12-15 20:11:55 - GraphTrainer - INFO -   mrr@10: 0.020451
2025-12-15 20:11:55 - GraphTrainer - INFO -   precision@20: 0.004304
2025-12-15 20:11:55 - GraphTrainer - INFO -   recall@20: 0.081503
2025-12-15 20:11:55 - GraphTrainer - INFO -   hit_rate@20: 0.085678
2025-12-15 20:11:55 - GraphTrainer - INFO -   ndcg@20: 0.034840
2025-12-15 20:11:55 - GraphTrainer - INFO -   map@20: 0.021617
2025-12-15 20:11:55 - GraphTrainer - INFO -   mrr@20: 0.022627
2025-12-15 20:11:55 - GraphTrainer - INFO - 第 18 轮训练完成
2025-12-15 20:11:55 - GraphTrainer - INFO - train_loss: 0.256891
2025-12-15 20:11:55 - GraphTrainer - INFO - precision@5: 0.006459
2025-12-15 20:11:55 - GraphTrainer - INFO - recall@5: 0.031140
2025-12-15 20:11:55 - GraphTrainer - INFO - hit_rate@5: 0.032296
2025-12-15 20:11:55 - GraphTrainer - INFO - ndcg@5: 0.020604
2025-12-15 20:11:55 - GraphTrainer - INFO - map@5: 0.016931
2025-12-15 20:11:55 - GraphTrainer - INFO - mrr@5: 0.017654
2025-12-15 20:11:55 - GraphTrainer - INFO - precision@10: 0.005400
2025-12-15 20:11:55 - GraphTrainer - INFO - recall@10: 0.051397
2025-12-15 20:11:55 - GraphTrainer - INFO - hit_rate@10: 0.053947
2025-12-15 20:11:55 - GraphTrainer - INFO - ndcg@10: 0.027156
2025-12-15 20:11:55 - GraphTrainer - INFO - map@10: 0.019544
2025-12-15 20:11:55 - GraphTrainer - INFO - mrr@10: 0.020451
2025-12-15 20:11:55 - GraphTrainer - INFO - precision@20: 0.004304
2025-12-15 20:11:55 - GraphTrainer - INFO - recall@20: 0.081503
2025-12-15 20:11:55 - GraphTrainer - INFO - hit_rate@20: 0.085678
2025-12-15 20:11:55 - GraphTrainer - INFO - ndcg@20: 0.034840
2025-12-15 20:11:55 - GraphTrainer - INFO - map@20: 0.021617
2025-12-15 20:11:55 - GraphTrainer - INFO - mrr@20: 0.022627
2025-12-15 20:11:55 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:11:55 - GraphTrainer - INFO - ============================================================
2025-12-15 20:11:55 - GraphTrainer - INFO - 开始第 19/1000 轮训练
2025-12-15 20:11:55 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2448, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2739, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2408, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2484, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2510, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2641, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2719, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2484, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2497, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2884, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2408, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2381, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2405, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2528, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2498, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2511, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2357, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2311, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2703, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2305, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2573, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2804, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2712, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2461, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2837, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2381, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2702, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2757, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2754, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2722, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2664, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2551, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2433, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2526, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2453, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2747, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2516, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2645, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2596, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2680, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2518, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2368, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2859, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2373, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2715, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2685, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2536, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2418, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2414, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2551, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2619, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2591, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2693, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2643, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2717, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2551, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2396, device='cuda:0', grad_fn=<AddBackward0>)
The 18 training average loss: 0.2568912824680065
2025-12-15 20:12:03 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:12:03 - GraphTrainer - INFO -   precision@5: 0.006634
2025-12-15 20:12:03 - GraphTrainer - INFO -   recall@5: 0.031803
2025-12-15 20:12:03 - GraphTrainer - INFO -   hit_rate@5: 0.033170
2025-12-15 20:12:03 - GraphTrainer - INFO -   ndcg@5: 0.020951
2025-12-15 20:12:03 - GraphTrainer - INFO -   map@5: 0.017163
2025-12-15 20:12:03 - GraphTrainer - INFO -   mrr@5: 0.017882
2025-12-15 20:12:03 - GraphTrainer - INFO -   precision@10: 0.005384
2025-12-15 20:12:03 - GraphTrainer - INFO -   recall@10: 0.051088
2025-12-15 20:12:03 - GraphTrainer - INFO -   hit_rate@10: 0.053690
2025-12-15 20:12:03 - GraphTrainer - INFO -   ndcg@10: 0.027222
2025-12-15 20:12:03 - GraphTrainer - INFO -   map@10: 0.019689
2025-12-15 20:12:03 - GraphTrainer - INFO -   mrr@10: 0.020562
2025-12-15 20:12:03 - GraphTrainer - INFO -   precision@20: 0.004315
2025-12-15 20:12:03 - GraphTrainer - INFO -   recall@20: 0.081608
2025-12-15 20:12:03 - GraphTrainer - INFO -   hit_rate@20: 0.085832
2025-12-15 20:12:03 - GraphTrainer - INFO -   ndcg@20: 0.034968
2025-12-15 20:12:03 - GraphTrainer - INFO -   map@20: 0.021757
2025-12-15 20:12:03 - GraphTrainer - INFO -   mrr@20: 0.022738
2025-12-15 20:12:03 - GraphTrainer - INFO - 第 19 轮训练完成
2025-12-15 20:12:03 - GraphTrainer - INFO - train_loss: 0.255478
2025-12-15 20:12:03 - GraphTrainer - INFO - precision@5: 0.006634
2025-12-15 20:12:03 - GraphTrainer - INFO - recall@5: 0.031803
2025-12-15 20:12:03 - GraphTrainer - INFO - hit_rate@5: 0.033170
2025-12-15 20:12:03 - GraphTrainer - INFO - ndcg@5: 0.020951
2025-12-15 20:12:03 - GraphTrainer - INFO - map@5: 0.017163
2025-12-15 20:12:03 - GraphTrainer - INFO - mrr@5: 0.017882
2025-12-15 20:12:03 - GraphTrainer - INFO - precision@10: 0.005384
2025-12-15 20:12:03 - GraphTrainer - INFO - recall@10: 0.051088
2025-12-15 20:12:03 - GraphTrainer - INFO - hit_rate@10: 0.053690
2025-12-15 20:12:03 - GraphTrainer - INFO - ndcg@10: 0.027222
2025-12-15 20:12:03 - GraphTrainer - INFO - map@10: 0.019689
2025-12-15 20:12:03 - GraphTrainer - INFO - mrr@10: 0.020562
2025-12-15 20:12:03 - GraphTrainer - INFO - precision@20: 0.004315
2025-12-15 20:12:03 - GraphTrainer - INFO - recall@20: 0.081608
2025-12-15 20:12:03 - GraphTrainer - INFO - hit_rate@20: 0.085832
2025-12-15 20:12:03 - GraphTrainer - INFO - ndcg@20: 0.034968
2025-12-15 20:12:03 - GraphTrainer - INFO - map@20: 0.021757
2025-12-15 20:12:03 - GraphTrainer - INFO - mrr@20: 0.022738
2025-12-15 20:12:03 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:12:03 - GraphTrainer - INFO - ============================================================
2025-12-15 20:12:03 - GraphTrainer - INFO - 开始第 20/1000 轮训练
2025-12-15 20:12:03 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2588, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2493, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2728, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2497, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2544, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2646, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2513, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2545, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2608, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2558, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2215, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2640, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2453, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2725, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2558, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2577, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2423, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2620, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2686, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2372, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2660, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2852, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2453, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2501, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2643, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2464, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2507, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2495, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2764, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2511, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2483, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2449, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2635, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2480, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2496, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2447, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2773, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2552, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2528, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2485, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2633, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2298, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2634, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2711, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2570, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2646, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2705, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2646, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2519, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2484, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2622, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2548, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2349, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2450, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2500, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2394, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2504, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2798, device='cuda:0', grad_fn=<AddBackward0>)
The 19 training average loss: 0.255478429383245
2025-12-15 20:12:11 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:12:11 - GraphTrainer - INFO -   precision@5: 0.006727
2025-12-15 20:12:11 - GraphTrainer - INFO -   recall@5: 0.032188
2025-12-15 20:12:11 - GraphTrainer - INFO -   hit_rate@5: 0.033633
2025-12-15 20:12:11 - GraphTrainer - INFO -   ndcg@5: 0.021431
2025-12-15 20:12:11 - GraphTrainer - INFO -   map@5: 0.017651
2025-12-15 20:12:11 - GraphTrainer - INFO -   mrr@5: 0.018432
2025-12-15 20:12:11 - GraphTrainer - INFO -   precision@10: 0.005487
2025-12-15 20:12:11 - GraphTrainer - INFO -   recall@10: 0.052075
2025-12-15 20:12:11 - GraphTrainer - INFO -   hit_rate@10: 0.054770
2025-12-15 20:12:11 - GraphTrainer - INFO -   ndcg@10: 0.027863
2025-12-15 20:12:11 - GraphTrainer - INFO -   map@10: 0.020225
2025-12-15 20:12:11 - GraphTrainer - INFO -   mrr@10: 0.021164
2025-12-15 20:12:11 - GraphTrainer - INFO -   precision@20: 0.004366
2025-12-15 20:12:11 - GraphTrainer - INFO -   recall@20: 0.082707
2025-12-15 20:12:11 - GraphTrainer - INFO -   hit_rate@20: 0.086809
2025-12-15 20:12:11 - GraphTrainer - INFO -   ndcg@20: 0.035632
2025-12-15 20:12:11 - GraphTrainer - INFO -   map@20: 0.022302
2025-12-15 20:12:11 - GraphTrainer - INFO -   mrr@20: 0.023337
2025-12-15 20:12:11 - GraphTrainer - INFO - 第 20 轮训练完成
2025-12-15 20:12:11 - GraphTrainer - INFO - train_loss: 0.252849
2025-12-15 20:12:11 - GraphTrainer - INFO - precision@5: 0.006727
2025-12-15 20:12:11 - GraphTrainer - INFO - recall@5: 0.032188
2025-12-15 20:12:11 - GraphTrainer - INFO - hit_rate@5: 0.033633
2025-12-15 20:12:11 - GraphTrainer - INFO - ndcg@5: 0.021431
2025-12-15 20:12:11 - GraphTrainer - INFO - map@5: 0.017651
2025-12-15 20:12:11 - GraphTrainer - INFO - mrr@5: 0.018432
2025-12-15 20:12:11 - GraphTrainer - INFO - precision@10: 0.005487
2025-12-15 20:12:11 - GraphTrainer - INFO - recall@10: 0.052075
2025-12-15 20:12:11 - GraphTrainer - INFO - hit_rate@10: 0.054770
2025-12-15 20:12:11 - GraphTrainer - INFO - ndcg@10: 0.027863
2025-12-15 20:12:11 - GraphTrainer - INFO - map@10: 0.020225
2025-12-15 20:12:11 - GraphTrainer - INFO - mrr@10: 0.021164
2025-12-15 20:12:11 - GraphTrainer - INFO - precision@20: 0.004366
2025-12-15 20:12:11 - GraphTrainer - INFO - recall@20: 0.082707
2025-12-15 20:12:11 - GraphTrainer - INFO - hit_rate@20: 0.086809
2025-12-15 20:12:11 - GraphTrainer - INFO - ndcg@20: 0.035632
2025-12-15 20:12:11 - GraphTrainer - INFO - map@20: 0.022302
2025-12-15 20:12:11 - GraphTrainer - INFO - mrr@20: 0.023337
2025-12-15 20:12:11 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:12:12 - GraphTrainer - INFO - 检查点已保存: Epoch 20 -> ./checkpoints/checkpoint_epoch_20.pth
2025-12-15 20:12:12 - GraphTrainer - INFO - ============================================================
2025-12-15 20:12:12 - GraphTrainer - INFO - 开始第 21/1000 轮训练
2025-12-15 20:12:12 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2654, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2576, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2406, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2621, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2412, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2335, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2467, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2515, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2456, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2450, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2753, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2566, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2521, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2743, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2571, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2423, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2625, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2600, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2766, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2441, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2616, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2529, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2308, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2445, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2306, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2546, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2513, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2320, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2591, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2712, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2737, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2652, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2432, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2390, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2720, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2521, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2459, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2626, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2445, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2346, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2547, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2479, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2594, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2579, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2407, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2593, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2565, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2475, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2413, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2452, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2592, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2356, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2597, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2555, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2715, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2536, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2467, device='cuda:0', grad_fn=<AddBackward0>)
The 20 training average loss: 0.252848985893973
2025-12-15 20:12:20 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:12:20 - GraphTrainer - INFO -   precision@5: 0.006788
2025-12-15 20:12:20 - GraphTrainer - INFO -   recall@5: 0.032221
2025-12-15 20:12:20 - GraphTrainer - INFO -   hit_rate@5: 0.033890
2025-12-15 20:12:20 - GraphTrainer - INFO -   ndcg@5: 0.020776
2025-12-15 20:12:20 - GraphTrainer - INFO -   map@5: 0.016762
2025-12-15 20:12:20 - GraphTrainer - INFO -   mrr@5: 0.017574
2025-12-15 20:12:20 - GraphTrainer - INFO -   precision@10: 0.005600
2025-12-15 20:12:20 - GraphTrainer - INFO -   recall@10: 0.053253
2025-12-15 20:12:20 - GraphTrainer - INFO -   hit_rate@10: 0.055901
2025-12-15 20:12:20 - GraphTrainer - INFO -   ndcg@10: 0.027552
2025-12-15 20:12:20 - GraphTrainer - INFO -   map@10: 0.019482
2025-12-15 20:12:20 - GraphTrainer - INFO -   mrr@10: 0.020422
2025-12-15 20:12:20 - GraphTrainer - INFO -   precision@20: 0.004428
2025-12-15 20:12:20 - GraphTrainer - INFO -   recall@20: 0.083988
2025-12-15 20:12:20 - GraphTrainer - INFO -   hit_rate@20: 0.088095
2025-12-15 20:12:20 - GraphTrainer - INFO -   ndcg@20: 0.035339
2025-12-15 20:12:20 - GraphTrainer - INFO -   map@20: 0.021559
2025-12-15 20:12:20 - GraphTrainer - INFO -   mrr@20: 0.022594
2025-12-15 20:12:20 - GraphTrainer - INFO - 第 21 轮训练完成
2025-12-15 20:12:20 - GraphTrainer - INFO - train_loss: 0.252787
2025-12-15 20:12:20 - GraphTrainer - INFO - precision@5: 0.006788
2025-12-15 20:12:20 - GraphTrainer - INFO - recall@5: 0.032221
2025-12-15 20:12:20 - GraphTrainer - INFO - hit_rate@5: 0.033890
2025-12-15 20:12:20 - GraphTrainer - INFO - ndcg@5: 0.020776
2025-12-15 20:12:20 - GraphTrainer - INFO - map@5: 0.016762
2025-12-15 20:12:20 - GraphTrainer - INFO - mrr@5: 0.017574
2025-12-15 20:12:20 - GraphTrainer - INFO - precision@10: 0.005600
2025-12-15 20:12:20 - GraphTrainer - INFO - recall@10: 0.053253
2025-12-15 20:12:20 - GraphTrainer - INFO - hit_rate@10: 0.055901
2025-12-15 20:12:20 - GraphTrainer - INFO - ndcg@10: 0.027552
2025-12-15 20:12:20 - GraphTrainer - INFO - map@10: 0.019482
2025-12-15 20:12:20 - GraphTrainer - INFO - mrr@10: 0.020422
2025-12-15 20:12:20 - GraphTrainer - INFO - precision@20: 0.004428
2025-12-15 20:12:20 - GraphTrainer - INFO - recall@20: 0.083988
2025-12-15 20:12:20 - GraphTrainer - INFO - hit_rate@20: 0.088095
2025-12-15 20:12:20 - GraphTrainer - INFO - ndcg@20: 0.035339
2025-12-15 20:12:20 - GraphTrainer - INFO - map@20: 0.021559
2025-12-15 20:12:20 - GraphTrainer - INFO - mrr@20: 0.022594
2025-12-15 20:12:20 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:12:20 - GraphTrainer - INFO - ============================================================
2025-12-15 20:12:20 - GraphTrainer - INFO - 开始第 22/1000 轮训练
2025-12-15 20:12:20 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2538, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2521, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2592, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2410, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2487, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2518, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2641, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2646, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2491, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2594, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2474, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2616, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2566, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2496, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2608, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2516, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2786, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2549, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2636, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2645, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2268, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2734, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2570, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2556, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2564, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2406, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2434, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2569, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2615, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2462, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2520, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2534, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2615, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2406, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2473, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2446, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2391, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2452, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2535, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2536, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2222, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2549, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2275, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2424, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2709, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2642, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2646, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2372, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2662, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2622, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2425, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2521, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2546, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2563, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2626, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2192, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2486, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2720, device='cuda:0', grad_fn=<AddBackward0>)
The 21 training average loss: 0.252787041253057
2025-12-15 20:12:28 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:12:28 - GraphTrainer - INFO -   precision@5: 0.006840
2025-12-15 20:12:28 - GraphTrainer - INFO -   recall@5: 0.032651
2025-12-15 20:12:28 - GraphTrainer - INFO -   hit_rate@5: 0.034148
2025-12-15 20:12:28 - GraphTrainer - INFO -   ndcg@5: 0.021381
2025-12-15 20:12:28 - GraphTrainer - INFO -   map@5: 0.017423
2025-12-15 20:12:28 - GraphTrainer - INFO -   mrr@5: 0.018232
2025-12-15 20:12:28 - GraphTrainer - INFO -   precision@10: 0.005590
2025-12-15 20:12:28 - GraphTrainer - INFO -   recall@10: 0.053125
2025-12-15 20:12:28 - GraphTrainer - INFO -   hit_rate@10: 0.055798
2025-12-15 20:12:28 - GraphTrainer - INFO -   ndcg@10: 0.027984
2025-12-15 20:12:28 - GraphTrainer - INFO -   map@10: 0.020063
2025-12-15 20:12:28 - GraphTrainer - INFO -   mrr@10: 0.021029
2025-12-15 20:12:28 - GraphTrainer - INFO -   precision@20: 0.004423
2025-12-15 20:12:28 - GraphTrainer - INFO -   recall@20: 0.084029
2025-12-15 20:12:28 - GraphTrainer - INFO -   hit_rate@20: 0.088197
2025-12-15 20:12:28 - GraphTrainer - INFO -   ndcg@20: 0.035819
2025-12-15 20:12:28 - GraphTrainer - INFO -   map@20: 0.022159
2025-12-15 20:12:28 - GraphTrainer - INFO -   mrr@20: 0.023225
2025-12-15 20:12:28 - GraphTrainer - INFO - 第 22 轮训练完成
2025-12-15 20:12:28 - GraphTrainer - INFO - train_loss: 0.251504
2025-12-15 20:12:28 - GraphTrainer - INFO - precision@5: 0.006840
2025-12-15 20:12:28 - GraphTrainer - INFO - recall@5: 0.032651
2025-12-15 20:12:28 - GraphTrainer - INFO - hit_rate@5: 0.034148
2025-12-15 20:12:28 - GraphTrainer - INFO - ndcg@5: 0.021381
2025-12-15 20:12:28 - GraphTrainer - INFO - map@5: 0.017423
2025-12-15 20:12:28 - GraphTrainer - INFO - mrr@5: 0.018232
2025-12-15 20:12:28 - GraphTrainer - INFO - precision@10: 0.005590
2025-12-15 20:12:28 - GraphTrainer - INFO - recall@10: 0.053125
2025-12-15 20:12:28 - GraphTrainer - INFO - hit_rate@10: 0.055798
2025-12-15 20:12:28 - GraphTrainer - INFO - ndcg@10: 0.027984
2025-12-15 20:12:28 - GraphTrainer - INFO - map@10: 0.020063
2025-12-15 20:12:28 - GraphTrainer - INFO - mrr@10: 0.021029
2025-12-15 20:12:28 - GraphTrainer - INFO - precision@20: 0.004423
2025-12-15 20:12:28 - GraphTrainer - INFO - recall@20: 0.084029
2025-12-15 20:12:28 - GraphTrainer - INFO - hit_rate@20: 0.088197
2025-12-15 20:12:28 - GraphTrainer - INFO - ndcg@20: 0.035819
2025-12-15 20:12:28 - GraphTrainer - INFO - map@20: 0.022159
2025-12-15 20:12:28 - GraphTrainer - INFO - mrr@20: 0.023225
2025-12-15 20:12:28 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:12:28 - GraphTrainer - INFO - ============================================================
2025-12-15 20:12:28 - GraphTrainer - INFO - 开始第 23/1000 轮训练
2025-12-15 20:12:28 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2520, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2510, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2298, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2627, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2730, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2794, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2666, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2495, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2638, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2486, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2886, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2413, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2524, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2566, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2469, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2493, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2419, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2538, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2590, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2730, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2502, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2364, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2459, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2478, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2695, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2523, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2538, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2652, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2439, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2432, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2478, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2616, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2624, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2652, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2523, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2412, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2336, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2458, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2294, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2619, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2482, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2416, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2259, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2330, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2429, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2486, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2626, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2635, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2386, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2484, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2490, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2388, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2558, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2383, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2612, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2417, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2393, device='cuda:0', grad_fn=<AddBackward0>)
The 22 training average loss: 0.2515036890218998
2025-12-15 20:12:36 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:12:36 - GraphTrainer - INFO -   precision@5: 0.006562
2025-12-15 20:12:36 - GraphTrainer - INFO -   recall@5: 0.031344
2025-12-15 20:12:36 - GraphTrainer - INFO -   hit_rate@5: 0.032759
2025-12-15 20:12:36 - GraphTrainer - INFO -   ndcg@5: 0.020908
2025-12-15 20:12:36 - GraphTrainer - INFO -   map@5: 0.017219
2025-12-15 20:12:36 - GraphTrainer - INFO -   mrr@5: 0.018029
2025-12-15 20:12:36 - GraphTrainer - INFO -   precision@10: 0.005528
2025-12-15 20:12:36 - GraphTrainer - INFO -   recall@10: 0.052319
2025-12-15 20:12:36 - GraphTrainer - INFO -   hit_rate@10: 0.055078
2025-12-15 20:12:36 - GraphTrainer - INFO -   ndcg@10: 0.027733
2025-12-15 20:12:36 - GraphTrainer - INFO -   map@10: 0.019974
2025-12-15 20:12:36 - GraphTrainer - INFO -   mrr@10: 0.020957
2025-12-15 20:12:36 - GraphTrainer - INFO -   precision@20: 0.004430
2025-12-15 20:12:36 - GraphTrainer - INFO -   recall@20: 0.083914
2025-12-15 20:12:36 - GraphTrainer - INFO -   hit_rate@20: 0.087992
2025-12-15 20:12:36 - GraphTrainer - INFO -   ndcg@20: 0.035791
2025-12-15 20:12:36 - GraphTrainer - INFO -   map@20: 0.022159
2025-12-15 20:12:36 - GraphTrainer - INFO -   mrr@20: 0.023221
2025-12-15 20:12:36 - GraphTrainer - INFO - 第 23 轮训练完成
2025-12-15 20:12:36 - GraphTrainer - INFO - train_loss: 0.245825
2025-12-15 20:12:36 - GraphTrainer - INFO - precision@5: 0.006562
2025-12-15 20:12:36 - GraphTrainer - INFO - recall@5: 0.031344
2025-12-15 20:12:36 - GraphTrainer - INFO - hit_rate@5: 0.032759
2025-12-15 20:12:36 - GraphTrainer - INFO - ndcg@5: 0.020908
2025-12-15 20:12:36 - GraphTrainer - INFO - map@5: 0.017219
2025-12-15 20:12:36 - GraphTrainer - INFO - mrr@5: 0.018029
2025-12-15 20:12:36 - GraphTrainer - INFO - precision@10: 0.005528
2025-12-15 20:12:36 - GraphTrainer - INFO - recall@10: 0.052319
2025-12-15 20:12:36 - GraphTrainer - INFO - hit_rate@10: 0.055078
2025-12-15 20:12:36 - GraphTrainer - INFO - ndcg@10: 0.027733
2025-12-15 20:12:36 - GraphTrainer - INFO - map@10: 0.019974
2025-12-15 20:12:36 - GraphTrainer - INFO - mrr@10: 0.020957
2025-12-15 20:12:36 - GraphTrainer - INFO - precision@20: 0.004430
2025-12-15 20:12:36 - GraphTrainer - INFO - recall@20: 0.083914
2025-12-15 20:12:36 - GraphTrainer - INFO - hit_rate@20: 0.087992
2025-12-15 20:12:36 - GraphTrainer - INFO - ndcg@20: 0.035791
2025-12-15 20:12:36 - GraphTrainer - INFO - map@20: 0.022159
2025-12-15 20:12:36 - GraphTrainer - INFO - mrr@20: 0.023221
2025-12-15 20:12:36 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:12:36 - GraphTrainer - INFO - ============================================================
2025-12-15 20:12:36 - GraphTrainer - INFO - 开始第 24/1000 轮训练
2025-12-15 20:12:36 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2323, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2365, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2532, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2348, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2465, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2320, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2499, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2617, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2361, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2562, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2602, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2595, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2359, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2594, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2484, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2351, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2283, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2358, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2579, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2448, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2369, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2487, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2450, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2389, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2511, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2281, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2662, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2434, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2453, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2641, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2470, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2511, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2476, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2551, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2521, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2371, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2370, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2719, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2385, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2605, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2363, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2417, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2383, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2314, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2561, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2438, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2543, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2402, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2376, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2384, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2483, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2499, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2568, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2557, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2413, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2367, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2473, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2336, device='cuda:0', grad_fn=<AddBackward0>)
The 23 training average loss: 0.24582458107635893
2025-12-15 20:12:45 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:12:45 - GraphTrainer - INFO -   precision@5: 0.006881
2025-12-15 20:12:45 - GraphTrainer - INFO -   recall@5: 0.032725
2025-12-15 20:12:45 - GraphTrainer - INFO -   hit_rate@5: 0.034353
2025-12-15 20:12:45 - GraphTrainer - INFO -   ndcg@5: 0.021516
2025-12-15 20:12:45 - GraphTrainer - INFO -   map@5: 0.017570
2025-12-15 20:12:45 - GraphTrainer - INFO -   mrr@5: 0.018356
2025-12-15 20:12:45 - GraphTrainer - INFO -   precision@10: 0.005600
2025-12-15 20:12:45 - GraphTrainer - INFO -   recall@10: 0.053125
2025-12-15 20:12:45 - GraphTrainer - INFO -   hit_rate@10: 0.055901
2025-12-15 20:12:45 - GraphTrainer - INFO -   ndcg@10: 0.028140
2025-12-15 20:12:45 - GraphTrainer - INFO -   map@10: 0.020249
2025-12-15 20:12:45 - GraphTrainer - INFO -   mrr@10: 0.021186
2025-12-15 20:12:45 - GraphTrainer - INFO -   precision@20: 0.004433
2025-12-15 20:12:45 - GraphTrainer - INFO -   recall@20: 0.084213
2025-12-15 20:12:45 - GraphTrainer - INFO -   hit_rate@20: 0.088249
2025-12-15 20:12:45 - GraphTrainer - INFO -   ndcg@20: 0.036006
2025-12-15 20:12:45 - GraphTrainer - INFO -   map@20: 0.022352
2025-12-15 20:12:45 - GraphTrainer - INFO -   mrr@20: 0.023370
2025-12-15 20:12:45 - GraphTrainer - INFO - 第 24 轮训练完成
2025-12-15 20:12:45 - GraphTrainer - INFO - train_loss: 0.244978
2025-12-15 20:12:45 - GraphTrainer - INFO - precision@5: 0.006881
2025-12-15 20:12:45 - GraphTrainer - INFO - recall@5: 0.032725
2025-12-15 20:12:45 - GraphTrainer - INFO - hit_rate@5: 0.034353
2025-12-15 20:12:45 - GraphTrainer - INFO - ndcg@5: 0.021516
2025-12-15 20:12:45 - GraphTrainer - INFO - map@5: 0.017570
2025-12-15 20:12:45 - GraphTrainer - INFO - mrr@5: 0.018356
2025-12-15 20:12:45 - GraphTrainer - INFO - precision@10: 0.005600
2025-12-15 20:12:45 - GraphTrainer - INFO - recall@10: 0.053125
2025-12-15 20:12:45 - GraphTrainer - INFO - hit_rate@10: 0.055901
2025-12-15 20:12:45 - GraphTrainer - INFO - ndcg@10: 0.028140
2025-12-15 20:12:45 - GraphTrainer - INFO - map@10: 0.020249
2025-12-15 20:12:45 - GraphTrainer - INFO - mrr@10: 0.021186
2025-12-15 20:12:45 - GraphTrainer - INFO - precision@20: 0.004433
2025-12-15 20:12:45 - GraphTrainer - INFO - recall@20: 0.084213
2025-12-15 20:12:45 - GraphTrainer - INFO - hit_rate@20: 0.088249
2025-12-15 20:12:45 - GraphTrainer - INFO - ndcg@20: 0.036006
2025-12-15 20:12:45 - GraphTrainer - INFO - map@20: 0.022352
2025-12-15 20:12:45 - GraphTrainer - INFO - mrr@20: 0.023370
2025-12-15 20:12:45 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:12:45 - GraphTrainer - INFO - ============================================================
2025-12-15 20:12:45 - GraphTrainer - INFO - 开始第 25/1000 轮训练
2025-12-15 20:12:45 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2196, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2523, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2431, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2412, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2399, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2522, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2303, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2653, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2355, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2308, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2575, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2650, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2501, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2500, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2446, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2431, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2321, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2582, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2392, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2461, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2406, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2486, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2286, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2455, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2486, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2666, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2504, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2509, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2494, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2745, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2204, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2310, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2351, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2305, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2742, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2443, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2529, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2131, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2534, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2264, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2310, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2327, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2640, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2385, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2327, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2312, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2548, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2740, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2320, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2489, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2442, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2311, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2671, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2464, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2594, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2342, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2498, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2557, device='cuda:0', grad_fn=<AddBackward0>)
The 24 training average loss: 0.24497775759162574
2025-12-15 20:12:53 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:12:53 - GraphTrainer - INFO -   precision@5: 0.006850
2025-12-15 20:12:53 - GraphTrainer - INFO -   recall@5: 0.032917
2025-12-15 20:12:53 - GraphTrainer - INFO -   hit_rate@5: 0.034199
2025-12-15 20:12:53 - GraphTrainer - INFO -   ndcg@5: 0.021527
2025-12-15 20:12:53 - GraphTrainer - INFO -   map@5: 0.017560
2025-12-15 20:12:53 - GraphTrainer - INFO -   mrr@5: 0.018255
2025-12-15 20:12:53 - GraphTrainer - INFO -   precision@10: 0.005580
2025-12-15 20:12:53 - GraphTrainer - INFO -   recall@10: 0.053270
2025-12-15 20:12:53 - GraphTrainer - INFO -   hit_rate@10: 0.055644
2025-12-15 20:12:53 - GraphTrainer - INFO -   ndcg@10: 0.028151
2025-12-15 20:12:53 - GraphTrainer - INFO -   map@10: 0.020248
2025-12-15 20:12:53 - GraphTrainer - INFO -   mrr@10: 0.021088
2025-12-15 20:12:53 - GraphTrainer - INFO -   precision@20: 0.004466
2025-12-15 20:12:53 - GraphTrainer - INFO -   recall@20: 0.084807
2025-12-15 20:12:53 - GraphTrainer - INFO -   hit_rate@20: 0.089072
2025-12-15 20:12:53 - GraphTrainer - INFO -   ndcg@20: 0.036148
2025-12-15 20:12:53 - GraphTrainer - INFO -   map@20: 0.022373
2025-12-15 20:12:53 - GraphTrainer - INFO -   mrr@20: 0.023342
2025-12-15 20:12:53 - GraphTrainer - INFO - 第 25 轮训练完成
2025-12-15 20:12:53 - GraphTrainer - INFO - train_loss: 0.245673
2025-12-15 20:12:53 - GraphTrainer - INFO - precision@5: 0.006850
2025-12-15 20:12:53 - GraphTrainer - INFO - recall@5: 0.032917
2025-12-15 20:12:53 - GraphTrainer - INFO - hit_rate@5: 0.034199
2025-12-15 20:12:53 - GraphTrainer - INFO - ndcg@5: 0.021527
2025-12-15 20:12:53 - GraphTrainer - INFO - map@5: 0.017560
2025-12-15 20:12:53 - GraphTrainer - INFO - mrr@5: 0.018255
2025-12-15 20:12:53 - GraphTrainer - INFO - precision@10: 0.005580
2025-12-15 20:12:53 - GraphTrainer - INFO - recall@10: 0.053270
2025-12-15 20:12:53 - GraphTrainer - INFO - hit_rate@10: 0.055644
2025-12-15 20:12:53 - GraphTrainer - INFO - ndcg@10: 0.028151
2025-12-15 20:12:53 - GraphTrainer - INFO - map@10: 0.020248
2025-12-15 20:12:53 - GraphTrainer - INFO - mrr@10: 0.021088
2025-12-15 20:12:53 - GraphTrainer - INFO - precision@20: 0.004466
2025-12-15 20:12:53 - GraphTrainer - INFO - recall@20: 0.084807
2025-12-15 20:12:53 - GraphTrainer - INFO - hit_rate@20: 0.089072
2025-12-15 20:12:53 - GraphTrainer - INFO - ndcg@20: 0.036148
2025-12-15 20:12:53 - GraphTrainer - INFO - map@20: 0.022373
2025-12-15 20:12:53 - GraphTrainer - INFO - mrr@20: 0.023342
2025-12-15 20:12:53 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:12:53 - GraphTrainer - INFO - ============================================================
2025-12-15 20:12:53 - GraphTrainer - INFO - 开始第 26/1000 轮训练
2025-12-15 20:12:53 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2473, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2308, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2408, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2397, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2502, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2388, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2451, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2346, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2279, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2397, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2305, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2830, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2375, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2784, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2618, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2592, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2500, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2325, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2607, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2214, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2432, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2153, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2580, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2553, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2599, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2323, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2347, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2378, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2415, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2272, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2304, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2417, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2334, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2450, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2531, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2381, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2726, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2592, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2362, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2314, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2412, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2674, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2529, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2507, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2513, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2485, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2590, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2522, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2452, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2479, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2359, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2390, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2497, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2678, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2647, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2305, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2370, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2521, device='cuda:0', grad_fn=<AddBackward0>)
The 25 training average loss: 0.24567300800619454
2025-12-15 20:13:02 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:13:02 - GraphTrainer - INFO -   precision@5: 0.006737
2025-12-15 20:13:02 - GraphTrainer - INFO -   recall@5: 0.032224
2025-12-15 20:13:02 - GraphTrainer - INFO -   hit_rate@5: 0.033633
2025-12-15 20:13:02 - GraphTrainer - INFO -   ndcg@5: 0.021295
2025-12-15 20:13:02 - GraphTrainer - INFO -   map@5: 0.017463
2025-12-15 20:13:02 - GraphTrainer - INFO -   mrr@5: 0.018231
2025-12-15 20:13:02 - GraphTrainer - INFO -   precision@10: 0.005606
2025-12-15 20:13:02 - GraphTrainer - INFO -   recall@10: 0.053246
2025-12-15 20:13:02 - GraphTrainer - INFO -   hit_rate@10: 0.055901
2025-12-15 20:13:02 - GraphTrainer - INFO -   ndcg@10: 0.028120
2025-12-15 20:13:02 - GraphTrainer - INFO -   map@10: 0.020216
2025-12-15 20:13:02 - GraphTrainer - INFO -   mrr@10: 0.021156
2025-12-15 20:13:02 - GraphTrainer - INFO -   precision@20: 0.004430
2025-12-15 20:13:02 - GraphTrainer - INFO -   recall@20: 0.084156
2025-12-15 20:13:02 - GraphTrainer - INFO -   hit_rate@20: 0.088146
2025-12-15 20:13:02 - GraphTrainer - INFO -   ndcg@20: 0.035940
2025-12-15 20:13:02 - GraphTrainer - INFO -   map@20: 0.022302
2025-12-15 20:13:02 - GraphTrainer - INFO -   mrr@20: 0.023327
2025-12-15 20:13:02 - GraphTrainer - INFO - 第 26 轮训练完成
2025-12-15 20:13:02 - GraphTrainer - INFO - train_loss: 0.238516
2025-12-15 20:13:02 - GraphTrainer - INFO - precision@5: 0.006737
2025-12-15 20:13:02 - GraphTrainer - INFO - recall@5: 0.032224
2025-12-15 20:13:02 - GraphTrainer - INFO - hit_rate@5: 0.033633
2025-12-15 20:13:02 - GraphTrainer - INFO - ndcg@5: 0.021295
2025-12-15 20:13:02 - GraphTrainer - INFO - map@5: 0.017463
2025-12-15 20:13:02 - GraphTrainer - INFO - mrr@5: 0.018231
2025-12-15 20:13:02 - GraphTrainer - INFO - precision@10: 0.005606
2025-12-15 20:13:02 - GraphTrainer - INFO - recall@10: 0.053246
2025-12-15 20:13:02 - GraphTrainer - INFO - hit_rate@10: 0.055901
2025-12-15 20:13:02 - GraphTrainer - INFO - ndcg@10: 0.028120
2025-12-15 20:13:02 - GraphTrainer - INFO - map@10: 0.020216
2025-12-15 20:13:02 - GraphTrainer - INFO - mrr@10: 0.021156
2025-12-15 20:13:02 - GraphTrainer - INFO - precision@20: 0.004430
2025-12-15 20:13:02 - GraphTrainer - INFO - recall@20: 0.084156
2025-12-15 20:13:02 - GraphTrainer - INFO - hit_rate@20: 0.088146
2025-12-15 20:13:02 - GraphTrainer - INFO - ndcg@20: 0.035940
2025-12-15 20:13:02 - GraphTrainer - INFO - map@20: 0.022302
2025-12-15 20:13:02 - GraphTrainer - INFO - mrr@20: 0.023327
2025-12-15 20:13:02 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:13:02 - GraphTrainer - INFO - ============================================================
2025-12-15 20:13:02 - GraphTrainer - INFO - 开始第 27/1000 轮训练
2025-12-15 20:13:02 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2314, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2436, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2412, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2279, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2129, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2404, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2586, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2209, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2423, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2364, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2455, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2730, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2404, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2371, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2502, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2350, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2195, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2318, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2360, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2187, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2276, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2416, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2439, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2458, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2417, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2464, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2281, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2284, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2153, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2580, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2278, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2319, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2452, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2435, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2373, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2353, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2537, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2597, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2567, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2333, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2271, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2591, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2465, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2513, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2511, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2321, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2423, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2388, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2371, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2496, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2249, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2434, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2320, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2299, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2300, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2317, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2487, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2141, device='cuda:0', grad_fn=<AddBackward0>)
The 26 training average loss: 0.2385156008190122
2025-12-15 20:13:11 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:13:11 - GraphTrainer - INFO -   precision@5: 0.007087
2025-12-15 20:13:11 - GraphTrainer - INFO -   recall@5: 0.033667
2025-12-15 20:13:11 - GraphTrainer - INFO -   hit_rate@5: 0.035382
2025-12-15 20:13:11 - GraphTrainer - INFO -   ndcg@5: 0.021947
2025-12-15 20:13:11 - GraphTrainer - INFO -   map@5: 0.017824
2025-12-15 20:13:11 - GraphTrainer - INFO -   mrr@5: 0.018690
2025-12-15 20:13:11 - GraphTrainer - INFO -   precision@10: 0.005693
2025-12-15 20:13:11 - GraphTrainer - INFO -   recall@10: 0.054037
2025-12-15 20:13:11 - GraphTrainer - INFO -   hit_rate@10: 0.056827
2025-12-15 20:13:11 - GraphTrainer - INFO -   ndcg@10: 0.028484
2025-12-15 20:13:11 - GraphTrainer - INFO -   map@10: 0.020424
2025-12-15 20:13:11 - GraphTrainer - INFO -   mrr@10: 0.021433
2025-12-15 20:13:11 - GraphTrainer - INFO -   precision@20: 0.004472
2025-12-15 20:13:11 - GraphTrainer - INFO -   recall@20: 0.084847
2025-12-15 20:13:11 - GraphTrainer - INFO -   hit_rate@20: 0.088969
2025-12-15 20:13:11 - GraphTrainer - INFO -   ndcg@20: 0.036272
2025-12-15 20:13:11 - GraphTrainer - INFO -   map@20: 0.022500
2025-12-15 20:13:11 - GraphTrainer - INFO -   mrr@20: 0.023592
2025-12-15 20:13:11 - GraphTrainer - INFO - 第 27 轮训练完成
2025-12-15 20:13:11 - GraphTrainer - INFO - train_loss: 0.240082
2025-12-15 20:13:11 - GraphTrainer - INFO - precision@5: 0.007087
2025-12-15 20:13:11 - GraphTrainer - INFO - recall@5: 0.033667
2025-12-15 20:13:11 - GraphTrainer - INFO - hit_rate@5: 0.035382
2025-12-15 20:13:11 - GraphTrainer - INFO - ndcg@5: 0.021947
2025-12-15 20:13:11 - GraphTrainer - INFO - map@5: 0.017824
2025-12-15 20:13:11 - GraphTrainer - INFO - mrr@5: 0.018690
2025-12-15 20:13:11 - GraphTrainer - INFO - precision@10: 0.005693
2025-12-15 20:13:11 - GraphTrainer - INFO - recall@10: 0.054037
2025-12-15 20:13:11 - GraphTrainer - INFO - hit_rate@10: 0.056827
2025-12-15 20:13:11 - GraphTrainer - INFO - ndcg@10: 0.028484
2025-12-15 20:13:11 - GraphTrainer - INFO - map@10: 0.020424
2025-12-15 20:13:11 - GraphTrainer - INFO - mrr@10: 0.021433
2025-12-15 20:13:11 - GraphTrainer - INFO - precision@20: 0.004472
2025-12-15 20:13:11 - GraphTrainer - INFO - recall@20: 0.084847
2025-12-15 20:13:11 - GraphTrainer - INFO - hit_rate@20: 0.088969
2025-12-15 20:13:11 - GraphTrainer - INFO - ndcg@20: 0.036272
2025-12-15 20:13:11 - GraphTrainer - INFO - map@20: 0.022500
2025-12-15 20:13:11 - GraphTrainer - INFO - mrr@20: 0.023592
2025-12-15 20:13:11 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:13:11 - GraphTrainer - INFO - ============================================================
2025-12-15 20:13:11 - GraphTrainer - INFO - 开始第 28/1000 轮训练
2025-12-15 20:13:11 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2450, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2334, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2516, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2360, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2306, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2495, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2417, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2556, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2396, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2422, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2266, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2611, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2270, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2438, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2581, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2461, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2355, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2121, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2387, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2310, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2273, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2294, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2537, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2517, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2339, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2318, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2435, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2409, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2380, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2722, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2375, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2385, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2463, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2378, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2281, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2346, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2446, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2433, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2238, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2382, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2380, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2222, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2524, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2406, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2610, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2391, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2408, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2280, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2472, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2308, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2448, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2407, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2417, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2462, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2352, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2364, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2177, device='cuda:0', grad_fn=<AddBackward0>)
The 27 training average loss: 0.2400817591054686
2025-12-15 20:13:19 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:13:19 - GraphTrainer - INFO -   precision@5: 0.006727
2025-12-15 20:13:19 - GraphTrainer - INFO -   recall@5: 0.031833
2025-12-15 20:13:19 - GraphTrainer - INFO -   hit_rate@5: 0.033582
2025-12-15 20:13:19 - GraphTrainer - INFO -   ndcg@5: 0.021231
2025-12-15 20:13:19 - GraphTrainer - INFO -   map@5: 0.017451
2025-12-15 20:13:19 - GraphTrainer - INFO -   mrr@5: 0.018327
2025-12-15 20:13:19 - GraphTrainer - INFO -   precision@10: 0.005667
2025-12-15 20:13:19 - GraphTrainer - INFO -   recall@10: 0.053719
2025-12-15 20:13:19 - GraphTrainer - INFO -   hit_rate@10: 0.056570
2025-12-15 20:13:19 - GraphTrainer - INFO -   ndcg@10: 0.028321
2025-12-15 20:13:19 - GraphTrainer - INFO -   map@10: 0.020315
2025-12-15 20:13:19 - GraphTrainer - INFO -   mrr@10: 0.021337
2025-12-15 20:13:19 - GraphTrainer - INFO -   precision@20: 0.004443
2025-12-15 20:13:19 - GraphTrainer - INFO -   recall@20: 0.084200
2025-12-15 20:13:19 - GraphTrainer - INFO -   hit_rate@20: 0.088403
2025-12-15 20:13:19 - GraphTrainer - INFO -   ndcg@20: 0.036084
2025-12-15 20:13:19 - GraphTrainer - INFO -   map@20: 0.022413
2025-12-15 20:13:19 - GraphTrainer - INFO -   mrr@20: 0.023515
2025-12-15 20:13:19 - GraphTrainer - INFO - 第 28 轮训练完成
2025-12-15 20:13:19 - GraphTrainer - INFO - train_loss: 0.236151
2025-12-15 20:13:19 - GraphTrainer - INFO - precision@5: 0.006727
2025-12-15 20:13:19 - GraphTrainer - INFO - recall@5: 0.031833
2025-12-15 20:13:19 - GraphTrainer - INFO - hit_rate@5: 0.033582
2025-12-15 20:13:19 - GraphTrainer - INFO - ndcg@5: 0.021231
2025-12-15 20:13:19 - GraphTrainer - INFO - map@5: 0.017451
2025-12-15 20:13:19 - GraphTrainer - INFO - mrr@5: 0.018327
2025-12-15 20:13:19 - GraphTrainer - INFO - precision@10: 0.005667
2025-12-15 20:13:19 - GraphTrainer - INFO - recall@10: 0.053719
2025-12-15 20:13:19 - GraphTrainer - INFO - hit_rate@10: 0.056570
2025-12-15 20:13:19 - GraphTrainer - INFO - ndcg@10: 0.028321
2025-12-15 20:13:19 - GraphTrainer - INFO - map@10: 0.020315
2025-12-15 20:13:19 - GraphTrainer - INFO - mrr@10: 0.021337
2025-12-15 20:13:19 - GraphTrainer - INFO - precision@20: 0.004443
2025-12-15 20:13:19 - GraphTrainer - INFO - recall@20: 0.084200
2025-12-15 20:13:19 - GraphTrainer - INFO - hit_rate@20: 0.088403
2025-12-15 20:13:19 - GraphTrainer - INFO - ndcg@20: 0.036084
2025-12-15 20:13:19 - GraphTrainer - INFO - map@20: 0.022413
2025-12-15 20:13:19 - GraphTrainer - INFO - mrr@20: 0.023515
2025-12-15 20:13:19 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:13:19 - GraphTrainer - INFO - ============================================================
2025-12-15 20:13:19 - GraphTrainer - INFO - 开始第 29/1000 轮训练
2025-12-15 20:13:19 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2264, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2436, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2492, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2374, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2133, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2494, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2388, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2419, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2307, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2300, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2288, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2266, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2503, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2351, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2094, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2272, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2447, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2456, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2454, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2263, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2177, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2427, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2442, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2515, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2218, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2357, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2444, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2266, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2295, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2247, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2392, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2303, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2517, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2524, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2301, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2183, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2487, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2319, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2294, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2424, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2336, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2027, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2429, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2346, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2354, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2329, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2326, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2388, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2465, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2388, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2299, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2318, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2228, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2178, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2563, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2438, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2593, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2830, device='cuda:0', grad_fn=<AddBackward0>)
The 28 training average loss: 0.23615149305812244
2025-12-15 20:13:28 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:13:28 - GraphTrainer - INFO -   precision@5: 0.006840
2025-12-15 20:13:28 - GraphTrainer - INFO -   recall@5: 0.032646
2025-12-15 20:13:28 - GraphTrainer - INFO -   hit_rate@5: 0.034148
2025-12-15 20:13:28 - GraphTrainer - INFO -   ndcg@5: 0.021516
2025-12-15 20:13:28 - GraphTrainer - INFO -   map@5: 0.017596
2025-12-15 20:13:28 - GraphTrainer - INFO -   mrr@5: 0.018401
2025-12-15 20:13:28 - GraphTrainer - INFO -   precision@10: 0.005606
2025-12-15 20:13:28 - GraphTrainer - INFO -   recall@10: 0.053270
2025-12-15 20:13:28 - GraphTrainer - INFO -   hit_rate@10: 0.055953
2025-12-15 20:13:28 - GraphTrainer - INFO -   ndcg@10: 0.028210
2025-12-15 20:13:28 - GraphTrainer - INFO -   map@10: 0.020299
2025-12-15 20:13:28 - GraphTrainer - INFO -   mrr@10: 0.021266
2025-12-15 20:13:28 - GraphTrainer - INFO -   precision@20: 0.004448
2025-12-15 20:13:28 - GraphTrainer - INFO -   recall@20: 0.084619
2025-12-15 20:13:28 - GraphTrainer - INFO -   hit_rate@20: 0.088557
2025-12-15 20:13:28 - GraphTrainer - INFO -   ndcg@20: 0.036153
2025-12-15 20:13:28 - GraphTrainer - INFO -   map@20: 0.022429
2025-12-15 20:13:28 - GraphTrainer - INFO -   mrr@20: 0.023475
2025-12-15 20:13:28 - GraphTrainer - INFO - 第 29 轮训练完成
2025-12-15 20:13:28 - GraphTrainer - INFO - train_loss: 0.236771
2025-12-15 20:13:28 - GraphTrainer - INFO - precision@5: 0.006840
2025-12-15 20:13:28 - GraphTrainer - INFO - recall@5: 0.032646
2025-12-15 20:13:28 - GraphTrainer - INFO - hit_rate@5: 0.034148
2025-12-15 20:13:28 - GraphTrainer - INFO - ndcg@5: 0.021516
2025-12-15 20:13:28 - GraphTrainer - INFO - map@5: 0.017596
2025-12-15 20:13:28 - GraphTrainer - INFO - mrr@5: 0.018401
2025-12-15 20:13:28 - GraphTrainer - INFO - precision@10: 0.005606
2025-12-15 20:13:28 - GraphTrainer - INFO - recall@10: 0.053270
2025-12-15 20:13:28 - GraphTrainer - INFO - hit_rate@10: 0.055953
2025-12-15 20:13:28 - GraphTrainer - INFO - ndcg@10: 0.028210
2025-12-15 20:13:28 - GraphTrainer - INFO - map@10: 0.020299
2025-12-15 20:13:28 - GraphTrainer - INFO - mrr@10: 0.021266
2025-12-15 20:13:28 - GraphTrainer - INFO - precision@20: 0.004448
2025-12-15 20:13:28 - GraphTrainer - INFO - recall@20: 0.084619
2025-12-15 20:13:28 - GraphTrainer - INFO - hit_rate@20: 0.088557
2025-12-15 20:13:28 - GraphTrainer - INFO - ndcg@20: 0.036153
2025-12-15 20:13:28 - GraphTrainer - INFO - map@20: 0.022429
2025-12-15 20:13:28 - GraphTrainer - INFO - mrr@20: 0.023475
2025-12-15 20:13:28 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:13:28 - GraphTrainer - INFO - ============================================================
2025-12-15 20:13:28 - GraphTrainer - INFO - 开始第 30/1000 轮训练
2025-12-15 20:13:28 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2492, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2346, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2297, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2457, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2168, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2489, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2224, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2285, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2428, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2441, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2222, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2260, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2618, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2461, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2401, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2335, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2331, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2136, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2466, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2482, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2295, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2490, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2362, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2490, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2347, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2426, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2337, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2400, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2078, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2413, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2447, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2169, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2293, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2363, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2181, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2348, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2572, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2215, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2283, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2565, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2438, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2507, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2353, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2422, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2506, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2447, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2381, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2191, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2486, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2637, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2426, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2423, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2371, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2207, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2310, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2162, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2254, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2391, device='cuda:0', grad_fn=<AddBackward0>)
The 29 training average loss: 0.23677108102831348
2025-12-15 20:13:36 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:13:36 - GraphTrainer - INFO -   precision@5: 0.006840
2025-12-15 20:13:36 - GraphTrainer - INFO -   recall@5: 0.032537
2025-12-15 20:13:36 - GraphTrainer - INFO -   hit_rate@5: 0.034148
2025-12-15 20:13:36 - GraphTrainer - INFO -   ndcg@5: 0.021891
2025-12-15 20:13:36 - GraphTrainer - INFO -   map@5: 0.018122
2025-12-15 20:13:36 - GraphTrainer - INFO -   mrr@5: 0.018919
2025-12-15 20:13:36 - GraphTrainer - INFO -   precision@10: 0.005662
2025-12-15 20:13:36 - GraphTrainer - INFO -   recall@10: 0.053783
2025-12-15 20:13:36 - GraphTrainer - INFO -   hit_rate@10: 0.056518
2025-12-15 20:13:36 - GraphTrainer - INFO -   ndcg@10: 0.028801
2025-12-15 20:13:36 - GraphTrainer - INFO -   map@10: 0.020925
2025-12-15 20:13:36 - GraphTrainer - INFO -   mrr@10: 0.021872
2025-12-15 20:13:36 - GraphTrainer - INFO -   precision@20: 0.004346
2025-12-15 20:13:36 - GraphTrainer - INFO -   recall@20: 0.082168
2025-12-15 20:13:36 - GraphTrainer - INFO -   hit_rate@20: 0.086449
2025-12-15 20:13:36 - GraphTrainer - INFO -   ndcg@20: 0.036031
2025-12-15 20:13:36 - GraphTrainer - INFO -   map@20: 0.022867
2025-12-15 20:13:36 - GraphTrainer - INFO -   mrr@20: 0.023914
2025-12-15 20:13:36 - GraphTrainer - INFO - 第 30 轮训练完成
2025-12-15 20:13:36 - GraphTrainer - INFO - train_loss: 0.233374
2025-12-15 20:13:36 - GraphTrainer - INFO - precision@5: 0.006840
2025-12-15 20:13:36 - GraphTrainer - INFO - recall@5: 0.032537
2025-12-15 20:13:36 - GraphTrainer - INFO - hit_rate@5: 0.034148
2025-12-15 20:13:36 - GraphTrainer - INFO - ndcg@5: 0.021891
2025-12-15 20:13:36 - GraphTrainer - INFO - map@5: 0.018122
2025-12-15 20:13:36 - GraphTrainer - INFO - mrr@5: 0.018919
2025-12-15 20:13:36 - GraphTrainer - INFO - precision@10: 0.005662
2025-12-15 20:13:36 - GraphTrainer - INFO - recall@10: 0.053783
2025-12-15 20:13:36 - GraphTrainer - INFO - hit_rate@10: 0.056518
2025-12-15 20:13:36 - GraphTrainer - INFO - ndcg@10: 0.028801
2025-12-15 20:13:36 - GraphTrainer - INFO - map@10: 0.020925
2025-12-15 20:13:36 - GraphTrainer - INFO - mrr@10: 0.021872
2025-12-15 20:13:36 - GraphTrainer - INFO - precision@20: 0.004346
2025-12-15 20:13:36 - GraphTrainer - INFO - recall@20: 0.082168
2025-12-15 20:13:36 - GraphTrainer - INFO - hit_rate@20: 0.086449
2025-12-15 20:13:36 - GraphTrainer - INFO - ndcg@20: 0.036031
2025-12-15 20:13:36 - GraphTrainer - INFO - map@20: 0.022867
2025-12-15 20:13:36 - GraphTrainer - INFO - mrr@20: 0.023914
2025-12-15 20:13:36 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:13:36 - GraphTrainer - INFO - 检查点已保存: Epoch 30 -> ./checkpoints/checkpoint_epoch_30.pth
2025-12-15 20:13:36 - GraphTrainer - INFO - ============================================================
2025-12-15 20:13:36 - GraphTrainer - INFO - 开始第 31/1000 轮训练
2025-12-15 20:13:36 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2292, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2337, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2277, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2476, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2171, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2376, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2525, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2558, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2301, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2403, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2301, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2283, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2355, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2355, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2117, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2216, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2187, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2400, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2180, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2114, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2414, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2214, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2513, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2246, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2325, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2336, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2301, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2206, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2438, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2255, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2335, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2281, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2503, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2143, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2438, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2330, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2097, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2304, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2261, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2077, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2195, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2431, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2618, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2506, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2673, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2279, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2196, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2275, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2488, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2566, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2402, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2258, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2456, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2329, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2377, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2457, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2258, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2350, device='cuda:0', grad_fn=<AddBackward0>)
The 30 training average loss: 0.23337354690864168
2025-12-15 20:13:44 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:13:44 - GraphTrainer - INFO -   precision@5: 0.006891
2025-12-15 20:13:44 - GraphTrainer - INFO -   recall@5: 0.032937
2025-12-15 20:13:44 - GraphTrainer - INFO -   hit_rate@5: 0.034456
2025-12-15 20:13:44 - GraphTrainer - INFO -   ndcg@5: 0.021556
2025-12-15 20:13:44 - GraphTrainer - INFO -   map@5: 0.017568
2025-12-15 20:13:44 - GraphTrainer - INFO -   mrr@5: 0.018370
2025-12-15 20:13:44 - GraphTrainer - INFO -   precision@10: 0.005750
2025-12-15 20:13:44 - GraphTrainer - INFO -   recall@10: 0.054231
2025-12-15 20:13:44 - GraphTrainer - INFO -   hit_rate@10: 0.057341
2025-12-15 20:13:44 - GraphTrainer - INFO -   ndcg@10: 0.028522
2025-12-15 20:13:44 - GraphTrainer - INFO -   map@10: 0.020382
2025-12-15 20:13:44 - GraphTrainer - INFO -   mrr@10: 0.021397
2025-12-15 20:13:44 - GraphTrainer - INFO -   precision@20: 0.004456
2025-12-15 20:13:44 - GraphTrainer - INFO -   recall@20: 0.084273
2025-12-15 20:13:44 - GraphTrainer - INFO -   hit_rate@20: 0.088660
2025-12-15 20:13:44 - GraphTrainer - INFO -   ndcg@20: 0.036168
2025-12-15 20:13:44 - GraphTrainer - INFO -   map@20: 0.022446
2025-12-15 20:13:44 - GraphTrainer - INFO -   mrr@20: 0.023542
2025-12-15 20:13:44 - GraphTrainer - INFO - 第 31 轮训练完成
2025-12-15 20:13:44 - GraphTrainer - INFO - train_loss: 0.236729
2025-12-15 20:13:44 - GraphTrainer - INFO - precision@5: 0.006891
2025-12-15 20:13:44 - GraphTrainer - INFO - recall@5: 0.032937
2025-12-15 20:13:44 - GraphTrainer - INFO - hit_rate@5: 0.034456
2025-12-15 20:13:44 - GraphTrainer - INFO - ndcg@5: 0.021556
2025-12-15 20:13:44 - GraphTrainer - INFO - map@5: 0.017568
2025-12-15 20:13:44 - GraphTrainer - INFO - mrr@5: 0.018370
2025-12-15 20:13:44 - GraphTrainer - INFO - precision@10: 0.005750
2025-12-15 20:13:44 - GraphTrainer - INFO - recall@10: 0.054231
2025-12-15 20:13:44 - GraphTrainer - INFO - hit_rate@10: 0.057341
2025-12-15 20:13:44 - GraphTrainer - INFO - ndcg@10: 0.028522
2025-12-15 20:13:44 - GraphTrainer - INFO - map@10: 0.020382
2025-12-15 20:13:44 - GraphTrainer - INFO - mrr@10: 0.021397
2025-12-15 20:13:44 - GraphTrainer - INFO - precision@20: 0.004456
2025-12-15 20:13:44 - GraphTrainer - INFO - recall@20: 0.084273
2025-12-15 20:13:44 - GraphTrainer - INFO - hit_rate@20: 0.088660
2025-12-15 20:13:44 - GraphTrainer - INFO - ndcg@20: 0.036168
2025-12-15 20:13:44 - GraphTrainer - INFO - map@20: 0.022446
2025-12-15 20:13:44 - GraphTrainer - INFO - mrr@20: 0.023542
2025-12-15 20:13:44 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:13:44 - GraphTrainer - INFO - ============================================================
2025-12-15 20:13:44 - GraphTrainer - INFO - 开始第 32/1000 轮训练
2025-12-15 20:13:44 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2225, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2316, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2548, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2232, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2451, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2415, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2420, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2291, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2360, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2164, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2683, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2301, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2424, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2332, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2305, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2163, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2419, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2598, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2402, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2259, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2164, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2432, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2137, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2260, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2212, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2276, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2462, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2420, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2297, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2421, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2354, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2385, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2252, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2524, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2546, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2360, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2507, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2415, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2276, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2481, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2509, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2282, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2375, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2489, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2281, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2263, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2169, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2345, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2388, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2561, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2427, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2357, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2524, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2475, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2243, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2311, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2292, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2520, device='cuda:0', grad_fn=<AddBackward0>)
The 31 training average loss: 0.2367288457422421
2025-12-15 20:13:53 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:13:53 - GraphTrainer - INFO -   precision@5: 0.006881
2025-12-15 20:13:53 - GraphTrainer - INFO -   recall@5: 0.032994
2025-12-15 20:13:53 - GraphTrainer - INFO -   hit_rate@5: 0.034353
2025-12-15 20:13:53 - GraphTrainer - INFO -   ndcg@5: 0.022100
2025-12-15 20:13:53 - GraphTrainer - INFO -   map@5: 0.018284
2025-12-15 20:13:53 - GraphTrainer - INFO -   mrr@5: 0.019062
2025-12-15 20:13:53 - GraphTrainer - INFO -   precision@10: 0.005801
2025-12-15 20:13:53 - GraphTrainer - INFO -   recall@10: 0.055073
2025-12-15 20:13:53 - GraphTrainer - INFO -   hit_rate@10: 0.057855
2025-12-15 20:13:53 - GraphTrainer - INFO -   ndcg@10: 0.029252
2025-12-15 20:13:53 - GraphTrainer - INFO -   map@10: 0.021150
2025-12-15 20:13:53 - GraphTrainer - INFO -   mrr@10: 0.022116
2025-12-15 20:13:53 - GraphTrainer - INFO -   precision@20: 0.004495
2025-12-15 20:13:53 - GraphTrainer - INFO -   recall@20: 0.085099
2025-12-15 20:13:53 - GraphTrainer - INFO -   hit_rate@20: 0.089380
2025-12-15 20:13:53 - GraphTrainer - INFO -   ndcg@20: 0.036891
2025-12-15 20:13:53 - GraphTrainer - INFO -   map@20: 0.023201
2025-12-15 20:13:53 - GraphTrainer - INFO -   mrr@20: 0.024261
2025-12-15 20:13:53 - GraphTrainer - INFO - 第 32 轮训练完成
2025-12-15 20:13:53 - GraphTrainer - INFO - train_loss: 0.233516
2025-12-15 20:13:53 - GraphTrainer - INFO - precision@5: 0.006881
2025-12-15 20:13:53 - GraphTrainer - INFO - recall@5: 0.032994
2025-12-15 20:13:53 - GraphTrainer - INFO - hit_rate@5: 0.034353
2025-12-15 20:13:53 - GraphTrainer - INFO - ndcg@5: 0.022100
2025-12-15 20:13:53 - GraphTrainer - INFO - map@5: 0.018284
2025-12-15 20:13:53 - GraphTrainer - INFO - mrr@5: 0.019062
2025-12-15 20:13:53 - GraphTrainer - INFO - precision@10: 0.005801
2025-12-15 20:13:53 - GraphTrainer - INFO - recall@10: 0.055073
2025-12-15 20:13:53 - GraphTrainer - INFO - hit_rate@10: 0.057855
2025-12-15 20:13:53 - GraphTrainer - INFO - ndcg@10: 0.029252
2025-12-15 20:13:53 - GraphTrainer - INFO - map@10: 0.021150
2025-12-15 20:13:53 - GraphTrainer - INFO - mrr@10: 0.022116
2025-12-15 20:13:53 - GraphTrainer - INFO - precision@20: 0.004495
2025-12-15 20:13:53 - GraphTrainer - INFO - recall@20: 0.085099
2025-12-15 20:13:53 - GraphTrainer - INFO - hit_rate@20: 0.089380
2025-12-15 20:13:53 - GraphTrainer - INFO - ndcg@20: 0.036891
2025-12-15 20:13:53 - GraphTrainer - INFO - map@20: 0.023201
2025-12-15 20:13:53 - GraphTrainer - INFO - mrr@20: 0.024261
2025-12-15 20:13:53 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:13:53 - GraphTrainer - INFO - ============================================================
2025-12-15 20:13:53 - GraphTrainer - INFO - 开始第 33/1000 轮训练
2025-12-15 20:13:53 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2230, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2485, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2529, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2489, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2319, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2371, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2109, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2436, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2284, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2231, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2381, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2223, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2291, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2250, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2261, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2706, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2357, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2418, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2360, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2418, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2216, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2357, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2272, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2378, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2271, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2272, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2356, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2202, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2146, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2481, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2668, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2313, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2450, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2155, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2232, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2094, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2420, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2314, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2379, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2540, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2428, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2195, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2265, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2469, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2177, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2400, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2328, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2373, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2289, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2265, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2228, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2140, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2409, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2443, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2361, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2483, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2292, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2232, device='cuda:0', grad_fn=<AddBackward0>)
The 32 training average loss: 0.23351605570521847
2025-12-15 20:14:01 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:14:01 - GraphTrainer - INFO -   precision@5: 0.006984
2025-12-15 20:14:01 - GraphTrainer - INFO -   recall@5: 0.033235
2025-12-15 20:14:01 - GraphTrainer - INFO -   hit_rate@5: 0.034868
2025-12-15 20:14:01 - GraphTrainer - INFO -   ndcg@5: 0.021997
2025-12-15 20:14:01 - GraphTrainer - INFO -   map@5: 0.018045
2025-12-15 20:14:01 - GraphTrainer - INFO -   mrr@5: 0.018875
2025-12-15 20:14:01 - GraphTrainer - INFO -   precision@10: 0.005523
2025-12-15 20:14:01 - GraphTrainer - INFO -   recall@10: 0.052480
2025-12-15 20:14:01 - GraphTrainer - INFO -   hit_rate@10: 0.055181
2025-12-15 20:14:01 - GraphTrainer - INFO -   ndcg@10: 0.028219
2025-12-15 20:14:01 - GraphTrainer - INFO -   map@10: 0.020545
2025-12-15 20:14:01 - GraphTrainer - INFO -   mrr@10: 0.021517
2025-12-15 20:14:01 - GraphTrainer - INFO -   precision@20: 0.004559
2025-12-15 20:14:01 - GraphTrainer - INFO -   recall@20: 0.086433
2025-12-15 20:14:01 - GraphTrainer - INFO -   hit_rate@20: 0.090615
2025-12-15 20:14:01 - GraphTrainer - INFO -   ndcg@20: 0.036877
2025-12-15 20:14:01 - GraphTrainer - INFO -   map@20: 0.022888
2025-12-15 20:14:01 - GraphTrainer - INFO -   mrr@20: 0.023953
2025-12-15 20:14:01 - GraphTrainer - INFO - 第 33 轮训练完成
2025-12-15 20:14:01 - GraphTrainer - INFO - train_loss: 0.230800
2025-12-15 20:14:01 - GraphTrainer - INFO - precision@5: 0.006984
2025-12-15 20:14:01 - GraphTrainer - INFO - recall@5: 0.033235
2025-12-15 20:14:01 - GraphTrainer - INFO - hit_rate@5: 0.034868
2025-12-15 20:14:01 - GraphTrainer - INFO - ndcg@5: 0.021997
2025-12-15 20:14:01 - GraphTrainer - INFO - map@5: 0.018045
2025-12-15 20:14:01 - GraphTrainer - INFO - mrr@5: 0.018875
2025-12-15 20:14:01 - GraphTrainer - INFO - precision@10: 0.005523
2025-12-15 20:14:01 - GraphTrainer - INFO - recall@10: 0.052480
2025-12-15 20:14:01 - GraphTrainer - INFO - hit_rate@10: 0.055181
2025-12-15 20:14:01 - GraphTrainer - INFO - ndcg@10: 0.028219
2025-12-15 20:14:01 - GraphTrainer - INFO - map@10: 0.020545
2025-12-15 20:14:01 - GraphTrainer - INFO - mrr@10: 0.021517
2025-12-15 20:14:01 - GraphTrainer - INFO - precision@20: 0.004559
2025-12-15 20:14:01 - GraphTrainer - INFO - recall@20: 0.086433
2025-12-15 20:14:01 - GraphTrainer - INFO - hit_rate@20: 0.090615
2025-12-15 20:14:01 - GraphTrainer - INFO - ndcg@20: 0.036877
2025-12-15 20:14:01 - GraphTrainer - INFO - map@20: 0.022888
2025-12-15 20:14:01 - GraphTrainer - INFO - mrr@20: 0.023953
2025-12-15 20:14:01 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:14:01 - GraphTrainer - INFO - ============================================================
2025-12-15 20:14:01 - GraphTrainer - INFO - 开始第 34/1000 轮训练
2025-12-15 20:14:01 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2188, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2212, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2251, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2348, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2225, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2302, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2360, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2290, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2289, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2233, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2236, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2338, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2226, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2267, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2232, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2439, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2342, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2257, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2263, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2275, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2342, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2251, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2267, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2338, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2143, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2300, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2259, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2282, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2443, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2538, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2274, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2108, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2310, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2249, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2122, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2243, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2280, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2442, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2274, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2359, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2361, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2605, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2380, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2306, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2099, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2489, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2221, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2157, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2379, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2428, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2292, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2184, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2309, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2302, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2683, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2567, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2571, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2134, device='cuda:0', grad_fn=<AddBackward0>)
The 33 training average loss: 0.23079978314966992
2025-12-15 20:14:10 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:14:10 - GraphTrainer - INFO -   precision@5: 0.006963
2025-12-15 20:14:10 - GraphTrainer - INFO -   recall@5: 0.033217
2025-12-15 20:14:10 - GraphTrainer - INFO -   hit_rate@5: 0.034765
2025-12-15 20:14:10 - GraphTrainer - INFO -   ndcg@5: 0.022166
2025-12-15 20:14:10 - GraphTrainer - INFO -   map@5: 0.018263
2025-12-15 20:14:10 - GraphTrainer - INFO -   mrr@5: 0.019109
2025-12-15 20:14:10 - GraphTrainer - INFO -   precision@10: 0.005744
2025-12-15 20:14:10 - GraphTrainer - INFO -   recall@10: 0.054236
2025-12-15 20:14:10 - GraphTrainer - INFO -   hit_rate@10: 0.057238
2025-12-15 20:14:10 - GraphTrainer - INFO -   ndcg@10: 0.029000
2025-12-15 20:14:10 - GraphTrainer - INFO -   map@10: 0.021008
2025-12-15 20:14:10 - GraphTrainer - INFO -   mrr@10: 0.022038
2025-12-15 20:14:10 - GraphTrainer - INFO -   precision@20: 0.004518
2025-12-15 20:14:10 - GraphTrainer - INFO -   recall@20: 0.085505
2025-12-15 20:14:10 - GraphTrainer - INFO -   hit_rate@20: 0.089895
2025-12-15 20:14:10 - GraphTrainer - INFO -   ndcg@20: 0.036956
2025-12-15 20:14:10 - GraphTrainer - INFO -   map@20: 0.023157
2025-12-15 20:14:10 - GraphTrainer - INFO -   mrr@20: 0.024273
2025-12-15 20:14:10 - GraphTrainer - INFO - 第 34 轮训练完成
2025-12-15 20:14:10 - GraphTrainer - INFO - train_loss: 0.228587
2025-12-15 20:14:10 - GraphTrainer - INFO - precision@5: 0.006963
2025-12-15 20:14:10 - GraphTrainer - INFO - recall@5: 0.033217
2025-12-15 20:14:10 - GraphTrainer - INFO - hit_rate@5: 0.034765
2025-12-15 20:14:10 - GraphTrainer - INFO - ndcg@5: 0.022166
2025-12-15 20:14:10 - GraphTrainer - INFO - map@5: 0.018263
2025-12-15 20:14:10 - GraphTrainer - INFO - mrr@5: 0.019109
2025-12-15 20:14:10 - GraphTrainer - INFO - precision@10: 0.005744
2025-12-15 20:14:10 - GraphTrainer - INFO - recall@10: 0.054236
2025-12-15 20:14:10 - GraphTrainer - INFO - hit_rate@10: 0.057238
2025-12-15 20:14:10 - GraphTrainer - INFO - ndcg@10: 0.029000
2025-12-15 20:14:10 - GraphTrainer - INFO - map@10: 0.021008
2025-12-15 20:14:10 - GraphTrainer - INFO - mrr@10: 0.022038
2025-12-15 20:14:10 - GraphTrainer - INFO - precision@20: 0.004518
2025-12-15 20:14:10 - GraphTrainer - INFO - recall@20: 0.085505
2025-12-15 20:14:10 - GraphTrainer - INFO - hit_rate@20: 0.089895
2025-12-15 20:14:10 - GraphTrainer - INFO - ndcg@20: 0.036956
2025-12-15 20:14:10 - GraphTrainer - INFO - map@20: 0.023157
2025-12-15 20:14:10 - GraphTrainer - INFO - mrr@20: 0.024273
2025-12-15 20:14:10 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:14:10 - GraphTrainer - INFO - ============================================================
2025-12-15 20:14:10 - GraphTrainer - INFO - 开始第 35/1000 轮训练
2025-12-15 20:14:10 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2333, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2330, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2254, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2342, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2415, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2059, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2155, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2500, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2256, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2227, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2331, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2118, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2365, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2256, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2265, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2078, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2310, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2477, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2378, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2300, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2091, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2262, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2032, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2181, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2290, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2337, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2235, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2343, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2129, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2314, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2293, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2222, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2382, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2140, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2328, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2507, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2082, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2279, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2117, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2151, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2038, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2296, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2306, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2532, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2195, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2226, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2393, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2358, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2199, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2470, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2344, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2367, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2478, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2382, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2295, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2465, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2188, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2583, device='cuda:0', grad_fn=<AddBackward0>)
The 34 training average loss: 0.22858653962612152
2025-12-15 20:14:17 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:14:17 - GraphTrainer - INFO -   precision@5: 0.007035
2025-12-15 20:14:17 - GraphTrainer - INFO -   recall@5: 0.033497
2025-12-15 20:14:17 - GraphTrainer - INFO -   hit_rate@5: 0.035125
2025-12-15 20:14:17 - GraphTrainer - INFO -   ndcg@5: 0.022215
2025-12-15 20:14:17 - GraphTrainer - INFO -   map@5: 0.018239
2025-12-15 20:14:17 - GraphTrainer - INFO -   mrr@5: 0.019079
2025-12-15 20:14:17 - GraphTrainer - INFO -   precision@10: 0.005657
2025-12-15 20:14:17 - GraphTrainer - INFO -   recall@10: 0.053349
2025-12-15 20:14:17 - GraphTrainer - INFO -   hit_rate@10: 0.056313
2025-12-15 20:14:17 - GraphTrainer - INFO -   ndcg@10: 0.028646
2025-12-15 20:14:17 - GraphTrainer - INFO -   map@10: 0.020811
2025-12-15 20:14:17 - GraphTrainer - INFO -   mrr@10: 0.021821
2025-12-15 20:14:17 - GraphTrainer - INFO -   precision@20: 0.004441
2025-12-15 20:14:17 - GraphTrainer - INFO -   recall@20: 0.084016
2025-12-15 20:14:17 - GraphTrainer - INFO -   hit_rate@20: 0.088352
2025-12-15 20:14:17 - GraphTrainer - INFO -   ndcg@20: 0.036432
2025-12-15 20:14:17 - GraphTrainer - INFO -   map@20: 0.022904
2025-12-15 20:14:17 - GraphTrainer - INFO -   mrr@20: 0.024002
2025-12-15 20:14:17 - GraphTrainer - INFO - 第 35 轮训练完成
2025-12-15 20:14:17 - GraphTrainer - INFO - train_loss: 0.230954
2025-12-15 20:14:17 - GraphTrainer - INFO - precision@5: 0.007035
2025-12-15 20:14:17 - GraphTrainer - INFO - recall@5: 0.033497
2025-12-15 20:14:17 - GraphTrainer - INFO - hit_rate@5: 0.035125
2025-12-15 20:14:17 - GraphTrainer - INFO - ndcg@5: 0.022215
2025-12-15 20:14:17 - GraphTrainer - INFO - map@5: 0.018239
2025-12-15 20:14:17 - GraphTrainer - INFO - mrr@5: 0.019079
2025-12-15 20:14:17 - GraphTrainer - INFO - precision@10: 0.005657
2025-12-15 20:14:17 - GraphTrainer - INFO - recall@10: 0.053349
2025-12-15 20:14:17 - GraphTrainer - INFO - hit_rate@10: 0.056313
2025-12-15 20:14:17 - GraphTrainer - INFO - ndcg@10: 0.028646
2025-12-15 20:14:17 - GraphTrainer - INFO - map@10: 0.020811
2025-12-15 20:14:17 - GraphTrainer - INFO - mrr@10: 0.021821
2025-12-15 20:14:17 - GraphTrainer - INFO - precision@20: 0.004441
2025-12-15 20:14:17 - GraphTrainer - INFO - recall@20: 0.084016
2025-12-15 20:14:17 - GraphTrainer - INFO - hit_rate@20: 0.088352
2025-12-15 20:14:17 - GraphTrainer - INFO - ndcg@20: 0.036432
2025-12-15 20:14:17 - GraphTrainer - INFO - map@20: 0.022904
2025-12-15 20:14:17 - GraphTrainer - INFO - mrr@20: 0.024002
2025-12-15 20:14:17 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:14:17 - GraphTrainer - INFO - ============================================================
2025-12-15 20:14:17 - GraphTrainer - INFO - 开始第 36/1000 轮训练
2025-12-15 20:14:17 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2098, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2209, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2383, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2239, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2295, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2089, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2436, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2348, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2328, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2193, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2316, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2222, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2314, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2391, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2420, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2261, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2411, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2587, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2447, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2492, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2339, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2378, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2249, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2145, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2301, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2298, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2484, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2023, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2117, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2227, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2458, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2269, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2499, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2351, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2242, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2302, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2210, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2354, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2252, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2215, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2408, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2318, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2342, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2364, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2376, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2126, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2476, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2161, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2326, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2314, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2333, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2298, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2252, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2527, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2242, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2293, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2327, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2280, device='cuda:0', grad_fn=<AddBackward0>)
The 35 training average loss: 0.2309535587656087
2025-12-15 20:14:26 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:14:26 - GraphTrainer - INFO -   precision@5: 0.007128
2025-12-15 20:14:26 - GraphTrainer - INFO -   recall@5: 0.033950
2025-12-15 20:14:26 - GraphTrainer - INFO -   hit_rate@5: 0.035588
2025-12-15 20:14:26 - GraphTrainer - INFO -   ndcg@5: 0.022522
2025-12-15 20:14:26 - GraphTrainer - INFO -   map@5: 0.018492
2025-12-15 20:14:26 - GraphTrainer - INFO -   mrr@5: 0.019335
2025-12-15 20:14:26 - GraphTrainer - INFO -   precision@10: 0.005714
2025-12-15 20:14:26 - GraphTrainer - INFO -   recall@10: 0.054355
2025-12-15 20:14:26 - GraphTrainer - INFO -   hit_rate@10: 0.056981
2025-12-15 20:14:26 - GraphTrainer - INFO -   ndcg@10: 0.029111
2025-12-15 20:14:26 - GraphTrainer - INFO -   map@10: 0.021144
2025-12-15 20:14:26 - GraphTrainer - INFO -   mrr@10: 0.022112
2025-12-15 20:14:26 - GraphTrainer - INFO -   precision@20: 0.004526
2025-12-15 20:14:26 - GraphTrainer - INFO -   recall@20: 0.085810
2025-12-15 20:14:26 - GraphTrainer - INFO -   hit_rate@20: 0.090049
2025-12-15 20:14:26 - GraphTrainer - INFO -   ndcg@20: 0.037103
2025-12-15 20:14:26 - GraphTrainer - INFO -   map@20: 0.023282
2025-12-15 20:14:26 - GraphTrainer - INFO -   mrr@20: 0.024360
2025-12-15 20:14:26 - GraphTrainer - INFO - 第 36 轮训练完成
2025-12-15 20:14:26 - GraphTrainer - INFO - train_loss: 0.227843
2025-12-15 20:14:26 - GraphTrainer - INFO - precision@5: 0.007128
2025-12-15 20:14:26 - GraphTrainer - INFO - recall@5: 0.033950
2025-12-15 20:14:26 - GraphTrainer - INFO - hit_rate@5: 0.035588
2025-12-15 20:14:26 - GraphTrainer - INFO - ndcg@5: 0.022522
2025-12-15 20:14:26 - GraphTrainer - INFO - map@5: 0.018492
2025-12-15 20:14:26 - GraphTrainer - INFO - mrr@5: 0.019335
2025-12-15 20:14:26 - GraphTrainer - INFO - precision@10: 0.005714
2025-12-15 20:14:26 - GraphTrainer - INFO - recall@10: 0.054355
2025-12-15 20:14:26 - GraphTrainer - INFO - hit_rate@10: 0.056981
2025-12-15 20:14:26 - GraphTrainer - INFO - ndcg@10: 0.029111
2025-12-15 20:14:26 - GraphTrainer - INFO - map@10: 0.021144
2025-12-15 20:14:26 - GraphTrainer - INFO - mrr@10: 0.022112
2025-12-15 20:14:26 - GraphTrainer - INFO - precision@20: 0.004526
2025-12-15 20:14:26 - GraphTrainer - INFO - recall@20: 0.085810
2025-12-15 20:14:26 - GraphTrainer - INFO - hit_rate@20: 0.090049
2025-12-15 20:14:26 - GraphTrainer - INFO - ndcg@20: 0.037103
2025-12-15 20:14:26 - GraphTrainer - INFO - map@20: 0.023282
2025-12-15 20:14:26 - GraphTrainer - INFO - mrr@20: 0.024360
2025-12-15 20:14:26 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:14:26 - GraphTrainer - INFO - ============================================================
2025-12-15 20:14:26 - GraphTrainer - INFO - 开始第 37/1000 轮训练
2025-12-15 20:14:26 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2246, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2088, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2263, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2148, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2316, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2324, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2239, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2336, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2267, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2265, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2353, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2499, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2409, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2088, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2086, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2137, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2133, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2465, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2327, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2508, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2385, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2211, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2001, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2428, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2184, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2446, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2286, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2321, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2339, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2123, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2368, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2403, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2211, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2508, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2283, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2196, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2292, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2139, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2129, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2176, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2318, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2239, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2230, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2328, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2172, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2158, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2211, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2267, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2325, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2221, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2430, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2258, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2412, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2273, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2349, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2240, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2627, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2162, device='cuda:0', grad_fn=<AddBackward0>)
The 36 training average loss: 0.2278430924333375
2025-12-15 20:14:34 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:14:34 - GraphTrainer - INFO -   precision@5: 0.007169
2025-12-15 20:14:34 - GraphTrainer - INFO -   recall@5: 0.034350
2025-12-15 20:14:34 - GraphTrainer - INFO -   hit_rate@5: 0.035845
2025-12-15 20:14:34 - GraphTrainer - INFO -   ndcg@5: 0.022677
2025-12-15 20:14:34 - GraphTrainer - INFO -   map@5: 0.018598
2025-12-15 20:14:34 - GraphTrainer - INFO -   mrr@5: 0.019420
2025-12-15 20:14:34 - GraphTrainer - INFO -   precision@10: 0.005765
2025-12-15 20:14:34 - GraphTrainer - INFO -   recall@10: 0.054745
2025-12-15 20:14:34 - GraphTrainer - INFO -   hit_rate@10: 0.057547
2025-12-15 20:14:34 - GraphTrainer - INFO -   ndcg@10: 0.029264
2025-12-15 20:14:34 - GraphTrainer - INFO -   map@10: 0.021228
2025-12-15 20:14:34 - GraphTrainer - INFO -   mrr@10: 0.022215
2025-12-15 20:14:34 - GraphTrainer - INFO -   precision@20: 0.004500
2025-12-15 20:14:34 - GraphTrainer - INFO -   recall@20: 0.085295
2025-12-15 20:14:34 - GraphTrainer - INFO -   hit_rate@20: 0.089535
2025-12-15 20:14:34 - GraphTrainer - INFO -   ndcg@20: 0.037003
2025-12-15 20:14:34 - GraphTrainer - INFO -   map@20: 0.023292
2025-12-15 20:14:34 - GraphTrainer - INFO -   mrr@20: 0.024371
2025-12-15 20:14:34 - GraphTrainer - INFO - 第 37 轮训练完成
2025-12-15 20:14:34 - GraphTrainer - INFO - train_loss: 0.223081
2025-12-15 20:14:34 - GraphTrainer - INFO - precision@5: 0.007169
2025-12-15 20:14:34 - GraphTrainer - INFO - recall@5: 0.034350
2025-12-15 20:14:34 - GraphTrainer - INFO - hit_rate@5: 0.035845
2025-12-15 20:14:34 - GraphTrainer - INFO - ndcg@5: 0.022677
2025-12-15 20:14:34 - GraphTrainer - INFO - map@5: 0.018598
2025-12-15 20:14:34 - GraphTrainer - INFO - mrr@5: 0.019420
2025-12-15 20:14:34 - GraphTrainer - INFO - precision@10: 0.005765
2025-12-15 20:14:34 - GraphTrainer - INFO - recall@10: 0.054745
2025-12-15 20:14:34 - GraphTrainer - INFO - hit_rate@10: 0.057547
2025-12-15 20:14:34 - GraphTrainer - INFO - ndcg@10: 0.029264
2025-12-15 20:14:34 - GraphTrainer - INFO - map@10: 0.021228
2025-12-15 20:14:34 - GraphTrainer - INFO - mrr@10: 0.022215
2025-12-15 20:14:34 - GraphTrainer - INFO - precision@20: 0.004500
2025-12-15 20:14:34 - GraphTrainer - INFO - recall@20: 0.085295
2025-12-15 20:14:34 - GraphTrainer - INFO - hit_rate@20: 0.089535
2025-12-15 20:14:34 - GraphTrainer - INFO - ndcg@20: 0.037003
2025-12-15 20:14:34 - GraphTrainer - INFO - map@20: 0.023292
2025-12-15 20:14:34 - GraphTrainer - INFO - mrr@20: 0.024371
2025-12-15 20:14:34 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:14:34 - GraphTrainer - INFO - ============================================================
2025-12-15 20:14:34 - GraphTrainer - INFO - 开始第 38/1000 轮训练
2025-12-15 20:14:34 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2287, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2184, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2028, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2288, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2417, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2268, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2289, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2433, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2085, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2265, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2000, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2281, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2253, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2305, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2275, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2073, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2072, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2366, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2305, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2026, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2220, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2091, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2457, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2316, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.1981, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2088, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2222, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2089, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2316, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2281, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2466, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2010, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2154, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2217, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2265, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2052, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2236, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2121, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2211, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2295, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2235, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2257, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2325, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2326, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2244, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2182, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2300, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2351, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2131, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2227, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2472, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2231, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2287, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2315, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2279, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2153, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2253, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2233, device='cuda:0', grad_fn=<AddBackward0>)
The 37 training average loss: 0.22308054258083476
2025-12-15 20:14:42 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:14:42 - GraphTrainer - INFO -   precision@5: 0.007128
2025-12-15 20:14:42 - GraphTrainer - INFO -   recall@5: 0.033984
2025-12-15 20:14:42 - GraphTrainer - INFO -   hit_rate@5: 0.035588
2025-12-15 20:14:42 - GraphTrainer - INFO -   ndcg@5: 0.022378
2025-12-15 20:14:42 - GraphTrainer - INFO -   map@5: 0.018294
2025-12-15 20:14:42 - GraphTrainer - INFO -   mrr@5: 0.019143
2025-12-15 20:14:42 - GraphTrainer - INFO -   precision@10: 0.005698
2025-12-15 20:14:42 - GraphTrainer - INFO -   recall@10: 0.054067
2025-12-15 20:14:42 - GraphTrainer - INFO -   hit_rate@10: 0.056827
2025-12-15 20:14:42 - GraphTrainer - INFO -   ndcg@10: 0.028889
2025-12-15 20:14:42 - GraphTrainer - INFO -   map@10: 0.020917
2025-12-15 20:14:42 - GraphTrainer - INFO -   mrr@10: 0.021910
2025-12-15 20:14:42 - GraphTrainer - INFO -   precision@20: 0.004492
2025-12-15 20:14:42 - GraphTrainer - INFO -   recall@20: 0.085380
2025-12-15 20:14:42 - GraphTrainer - INFO -   hit_rate@20: 0.089483
2025-12-15 20:14:42 - GraphTrainer - INFO -   ndcg@20: 0.036829
2025-12-15 20:14:42 - GraphTrainer - INFO -   map@20: 0.023049
2025-12-15 20:14:42 - GraphTrainer - INFO -   mrr@20: 0.024134
2025-12-15 20:14:42 - GraphTrainer - INFO - 第 38 轮训练完成
2025-12-15 20:14:42 - GraphTrainer - INFO - train_loss: 0.223892
2025-12-15 20:14:42 - GraphTrainer - INFO - precision@5: 0.007128
2025-12-15 20:14:42 - GraphTrainer - INFO - recall@5: 0.033984
2025-12-15 20:14:42 - GraphTrainer - INFO - hit_rate@5: 0.035588
2025-12-15 20:14:42 - GraphTrainer - INFO - ndcg@5: 0.022378
2025-12-15 20:14:42 - GraphTrainer - INFO - map@5: 0.018294
2025-12-15 20:14:42 - GraphTrainer - INFO - mrr@5: 0.019143
2025-12-15 20:14:42 - GraphTrainer - INFO - precision@10: 0.005698
2025-12-15 20:14:42 - GraphTrainer - INFO - recall@10: 0.054067
2025-12-15 20:14:42 - GraphTrainer - INFO - hit_rate@10: 0.056827
2025-12-15 20:14:42 - GraphTrainer - INFO - ndcg@10: 0.028889
2025-12-15 20:14:42 - GraphTrainer - INFO - map@10: 0.020917
2025-12-15 20:14:42 - GraphTrainer - INFO - mrr@10: 0.021910
2025-12-15 20:14:42 - GraphTrainer - INFO - precision@20: 0.004492
2025-12-15 20:14:42 - GraphTrainer - INFO - recall@20: 0.085380
2025-12-15 20:14:42 - GraphTrainer - INFO - hit_rate@20: 0.089483
2025-12-15 20:14:42 - GraphTrainer - INFO - ndcg@20: 0.036829
2025-12-15 20:14:42 - GraphTrainer - INFO - map@20: 0.023049
2025-12-15 20:14:42 - GraphTrainer - INFO - mrr@20: 0.024134
2025-12-15 20:14:42 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:14:42 - GraphTrainer - INFO - ============================================================
2025-12-15 20:14:42 - GraphTrainer - INFO - 开始第 39/1000 轮训练
2025-12-15 20:14:42 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2180, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2337, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2294, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2279, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2156, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2115, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2214, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2188, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2143, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2199, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2274, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2181, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2142, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2217, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2179, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2186, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2054, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2234, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2247, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2460, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1970, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2451, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2094, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2171, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2185, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2423, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2361, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2336, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2293, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2306, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2195, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2282, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2088, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2357, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2483, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2240, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2253, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2184, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2305, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2112, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2409, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2071, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2257, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2295, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2242, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2173, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2151, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2299, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2345, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2302, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2249, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2125, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2257, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2388, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2206, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2151, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2224, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2343, device='cuda:0', grad_fn=<AddBackward0>)
The 38 training average loss: 0.22389160559095186
2025-12-15 20:14:50 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:14:50 - GraphTrainer - INFO -   precision@5: 0.007025
2025-12-15 20:14:50 - GraphTrainer - INFO -   recall@5: 0.033427
2025-12-15 20:14:50 - GraphTrainer - INFO -   hit_rate@5: 0.035073
2025-12-15 20:14:50 - GraphTrainer - INFO -   ndcg@5: 0.021996
2025-12-15 20:14:50 - GraphTrainer - INFO -   map@5: 0.017966
2025-12-15 20:14:50 - GraphTrainer - INFO -   mrr@5: 0.018797
2025-12-15 20:14:50 - GraphTrainer - INFO -   precision@10: 0.005600
2025-12-15 20:14:50 - GraphTrainer - INFO -   recall@10: 0.053099
2025-12-15 20:14:50 - GraphTrainer - INFO -   hit_rate@10: 0.055850
2025-12-15 20:14:50 - GraphTrainer - INFO -   ndcg@10: 0.028375
2025-12-15 20:14:50 - GraphTrainer - INFO -   map@10: 0.020540
2025-12-15 20:14:50 - GraphTrainer - INFO -   mrr@10: 0.021508
2025-12-15 20:14:50 - GraphTrainer - INFO -   precision@20: 0.004477
2025-12-15 20:14:50 - GraphTrainer - INFO -   recall@20: 0.084800
2025-12-15 20:14:50 - GraphTrainer - INFO -   hit_rate@20: 0.089072
2025-12-15 20:14:50 - GraphTrainer - INFO -   ndcg@20: 0.036425
2025-12-15 20:14:50 - GraphTrainer - INFO -   map@20: 0.022697
2025-12-15 20:14:50 - GraphTrainer - INFO -   mrr@20: 0.023768
2025-12-15 20:14:50 - GraphTrainer - INFO - 第 39 轮训练完成
2025-12-15 20:14:50 - GraphTrainer - INFO - train_loss: 0.223583
2025-12-15 20:14:50 - GraphTrainer - INFO - precision@5: 0.007025
2025-12-15 20:14:50 - GraphTrainer - INFO - recall@5: 0.033427
2025-12-15 20:14:50 - GraphTrainer - INFO - hit_rate@5: 0.035073
2025-12-15 20:14:50 - GraphTrainer - INFO - ndcg@5: 0.021996
2025-12-15 20:14:50 - GraphTrainer - INFO - map@5: 0.017966
2025-12-15 20:14:50 - GraphTrainer - INFO - mrr@5: 0.018797
2025-12-15 20:14:50 - GraphTrainer - INFO - precision@10: 0.005600
2025-12-15 20:14:50 - GraphTrainer - INFO - recall@10: 0.053099
2025-12-15 20:14:50 - GraphTrainer - INFO - hit_rate@10: 0.055850
2025-12-15 20:14:50 - GraphTrainer - INFO - ndcg@10: 0.028375
2025-12-15 20:14:50 - GraphTrainer - INFO - map@10: 0.020540
2025-12-15 20:14:50 - GraphTrainer - INFO - mrr@10: 0.021508
2025-12-15 20:14:50 - GraphTrainer - INFO - precision@20: 0.004477
2025-12-15 20:14:50 - GraphTrainer - INFO - recall@20: 0.084800
2025-12-15 20:14:50 - GraphTrainer - INFO - hit_rate@20: 0.089072
2025-12-15 20:14:50 - GraphTrainer - INFO - ndcg@20: 0.036425
2025-12-15 20:14:50 - GraphTrainer - INFO - map@20: 0.022697
2025-12-15 20:14:50 - GraphTrainer - INFO - mrr@20: 0.023768
2025-12-15 20:14:50 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:14:50 - GraphTrainer - INFO - ============================================================
2025-12-15 20:14:50 - GraphTrainer - INFO - 开始第 40/1000 轮训练
2025-12-15 20:14:50 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2295, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2293, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2145, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2160, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2111, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2357, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2417, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2270, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2283, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2129, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2228, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2208, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2206, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2187, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2115, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2189, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2399, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2409, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2186, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2234, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2328, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2307, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2145, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2045, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2027, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2178, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2160, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2215, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2319, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2380, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2387, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2063, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2157, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2102, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2084, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2335, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2279, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2356, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2182, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2285, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2458, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2444, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2264, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2163, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2209, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2293, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2037, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2349, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2290, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2233, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2069, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2238, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2339, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2394, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2188, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2298, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2222, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2036, device='cuda:0', grad_fn=<AddBackward0>)
The 39 training average loss: 0.22358267882774616
2025-12-15 20:14:58 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:14:58 - GraphTrainer - INFO -   precision@5: 0.007118
2025-12-15 20:14:58 - GraphTrainer - INFO -   recall@5: 0.033956
2025-12-15 20:14:58 - GraphTrainer - INFO -   hit_rate@5: 0.035536
2025-12-15 20:14:58 - GraphTrainer - INFO -   ndcg@5: 0.022488
2025-12-15 20:14:58 - GraphTrainer - INFO -   map@5: 0.018460
2025-12-15 20:14:58 - GraphTrainer - INFO -   mrr@5: 0.019231
2025-12-15 20:14:58 - GraphTrainer - INFO -   precision@10: 0.005791
2025-12-15 20:14:58 - GraphTrainer - INFO -   recall@10: 0.054895
2025-12-15 20:14:58 - GraphTrainer - INFO -   hit_rate@10: 0.057804
2025-12-15 20:14:58 - GraphTrainer - INFO -   ndcg@10: 0.029244
2025-12-15 20:14:58 - GraphTrainer - INFO -   map@10: 0.021154
2025-12-15 20:14:58 - GraphTrainer - INFO -   mrr@10: 0.022097
2025-12-15 20:14:58 - GraphTrainer - INFO -   precision@20: 0.004544
2025-12-15 20:14:58 - GraphTrainer - INFO -   recall@20: 0.085994
2025-12-15 20:14:58 - GraphTrainer - INFO -   hit_rate@20: 0.090357
2025-12-15 20:14:58 - GraphTrainer - INFO -   ndcg@20: 0.037150
2025-12-15 20:14:58 - GraphTrainer - INFO -   map@20: 0.023277
2025-12-15 20:14:58 - GraphTrainer - INFO -   mrr@20: 0.024317
2025-12-15 20:14:58 - GraphTrainer - INFO - 第 40 轮训练完成
2025-12-15 20:14:58 - GraphTrainer - INFO - train_loss: 0.224120
2025-12-15 20:14:58 - GraphTrainer - INFO - precision@5: 0.007118
2025-12-15 20:14:58 - GraphTrainer - INFO - recall@5: 0.033956
2025-12-15 20:14:58 - GraphTrainer - INFO - hit_rate@5: 0.035536
2025-12-15 20:14:58 - GraphTrainer - INFO - ndcg@5: 0.022488
2025-12-15 20:14:58 - GraphTrainer - INFO - map@5: 0.018460
2025-12-15 20:14:58 - GraphTrainer - INFO - mrr@5: 0.019231
2025-12-15 20:14:58 - GraphTrainer - INFO - precision@10: 0.005791
2025-12-15 20:14:58 - GraphTrainer - INFO - recall@10: 0.054895
2025-12-15 20:14:58 - GraphTrainer - INFO - hit_rate@10: 0.057804
2025-12-15 20:14:58 - GraphTrainer - INFO - ndcg@10: 0.029244
2025-12-15 20:14:58 - GraphTrainer - INFO - map@10: 0.021154
2025-12-15 20:14:58 - GraphTrainer - INFO - mrr@10: 0.022097
2025-12-15 20:14:58 - GraphTrainer - INFO - precision@20: 0.004544
2025-12-15 20:14:58 - GraphTrainer - INFO - recall@20: 0.085994
2025-12-15 20:14:58 - GraphTrainer - INFO - hit_rate@20: 0.090357
2025-12-15 20:14:58 - GraphTrainer - INFO - ndcg@20: 0.037150
2025-12-15 20:14:58 - GraphTrainer - INFO - map@20: 0.023277
2025-12-15 20:14:58 - GraphTrainer - INFO - mrr@20: 0.024317
2025-12-15 20:14:58 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:14:58 - GraphTrainer - INFO - 检查点已保存: Epoch 40 -> ./checkpoints/checkpoint_epoch_40.pth
2025-12-15 20:14:58 - GraphTrainer - INFO - ============================================================
2025-12-15 20:14:58 - GraphTrainer - INFO - 开始第 41/1000 轮训练
2025-12-15 20:14:58 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2173, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2286, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2194, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2157, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2289, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2232, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2252, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2062, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2085, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2208, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2318, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2274, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2068, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2304, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2283, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2285, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2477, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2226, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2254, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2324, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2283, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2249, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2122, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2279, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2321, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2500, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2130, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2200, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2066, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2254, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2350, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2233, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2482, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2268, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2302, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2221, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2255, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2076, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2094, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2199, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2329, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2350, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2116, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2429, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2258, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2230, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2226, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2119, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2143, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2416, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2237, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2180, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2072, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2169, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2298, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2247, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2018, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2516, device='cuda:0', grad_fn=<AddBackward0>)
The 40 training average loss: 0.22412036667610036
2025-12-15 20:15:07 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:15:07 - GraphTrainer - INFO -   precision@5: 0.007292
2025-12-15 20:15:07 - GraphTrainer - INFO -   recall@5: 0.034669
2025-12-15 20:15:07 - GraphTrainer - INFO -   hit_rate@5: 0.036410
2025-12-15 20:15:07 - GraphTrainer - INFO -   ndcg@5: 0.022984
2025-12-15 20:15:07 - GraphTrainer - INFO -   map@5: 0.018851
2025-12-15 20:15:07 - GraphTrainer - INFO -   mrr@5: 0.019747
2025-12-15 20:15:07 - GraphTrainer - INFO -   precision@10: 0.005852
2025-12-15 20:15:07 - GraphTrainer - INFO -   recall@10: 0.055491
2025-12-15 20:15:07 - GraphTrainer - INFO -   hit_rate@10: 0.058267
2025-12-15 20:15:07 - GraphTrainer - INFO -   ndcg@10: 0.029711
2025-12-15 20:15:07 - GraphTrainer - INFO -   map@10: 0.021555
2025-12-15 20:15:07 - GraphTrainer - INFO -   mrr@10: 0.022578
2025-12-15 20:15:07 - GraphTrainer - INFO -   precision@20: 0.004608
2025-12-15 20:15:07 - GraphTrainer - INFO -   recall@20: 0.087182
2025-12-15 20:15:07 - GraphTrainer - INFO -   hit_rate@20: 0.091592
2025-12-15 20:15:07 - GraphTrainer - INFO -   ndcg@20: 0.037764
2025-12-15 20:15:07 - GraphTrainer - INFO -   map@20: 0.023711
2025-12-15 20:15:07 - GraphTrainer - INFO -   mrr@20: 0.024846
2025-12-15 20:15:07 - GraphTrainer - INFO - 第 41 轮训练完成
2025-12-15 20:15:07 - GraphTrainer - INFO - train_loss: 0.221662
2025-12-15 20:15:07 - GraphTrainer - INFO - precision@5: 0.007292
2025-12-15 20:15:07 - GraphTrainer - INFO - recall@5: 0.034669
2025-12-15 20:15:07 - GraphTrainer - INFO - hit_rate@5: 0.036410
2025-12-15 20:15:07 - GraphTrainer - INFO - ndcg@5: 0.022984
2025-12-15 20:15:07 - GraphTrainer - INFO - map@5: 0.018851
2025-12-15 20:15:07 - GraphTrainer - INFO - mrr@5: 0.019747
2025-12-15 20:15:07 - GraphTrainer - INFO - precision@10: 0.005852
2025-12-15 20:15:07 - GraphTrainer - INFO - recall@10: 0.055491
2025-12-15 20:15:07 - GraphTrainer - INFO - hit_rate@10: 0.058267
2025-12-15 20:15:07 - GraphTrainer - INFO - ndcg@10: 0.029711
2025-12-15 20:15:07 - GraphTrainer - INFO - map@10: 0.021555
2025-12-15 20:15:07 - GraphTrainer - INFO - mrr@10: 0.022578
2025-12-15 20:15:07 - GraphTrainer - INFO - precision@20: 0.004608
2025-12-15 20:15:07 - GraphTrainer - INFO - recall@20: 0.087182
2025-12-15 20:15:07 - GraphTrainer - INFO - hit_rate@20: 0.091592
2025-12-15 20:15:07 - GraphTrainer - INFO - ndcg@20: 0.037764
2025-12-15 20:15:07 - GraphTrainer - INFO - map@20: 0.023711
2025-12-15 20:15:07 - GraphTrainer - INFO - mrr@20: 0.024846
2025-12-15 20:15:07 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:15:07 - GraphTrainer - INFO - ============================================================
2025-12-15 20:15:07 - GraphTrainer - INFO - 开始第 42/1000 轮训练
2025-12-15 20:15:07 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2142, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2046, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2064, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2278, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2332, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2068, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2209, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2368, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2075, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2253, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2080, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.1956, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2343, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2055, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2169, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2045, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2208, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2268, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2139, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2231, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2157, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2403, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2300, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2302, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2308, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2183, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2179, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2357, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2443, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2065, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2329, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2390, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2280, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2353, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2123, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2262, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2143, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2099, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2131, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2203, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2180, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2404, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2258, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2596, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2352, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2111, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2194, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2293, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2285, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2105, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2087, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2257, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2142, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2109, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2361, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2079, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2023, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2386, device='cuda:0', grad_fn=<AddBackward0>)
The 41 training average loss: 0.22166167071153378
2025-12-15 20:15:15 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:15:15 - GraphTrainer - INFO -   precision@5: 0.007190
2025-12-15 20:15:15 - GraphTrainer - INFO -   recall@5: 0.034492
2025-12-15 20:15:15 - GraphTrainer - INFO -   hit_rate@5: 0.035896
2025-12-15 20:15:15 - GraphTrainer - INFO -   ndcg@5: 0.022638
2025-12-15 20:15:15 - GraphTrainer - INFO -   map@5: 0.018511
2025-12-15 20:15:15 - GraphTrainer - INFO -   mrr@5: 0.019247
2025-12-15 20:15:15 - GraphTrainer - INFO -   precision@10: 0.005837
2025-12-15 20:15:15 - GraphTrainer - INFO -   recall@10: 0.055217
2025-12-15 20:15:15 - GraphTrainer - INFO -   hit_rate@10: 0.058164
2025-12-15 20:15:15 - GraphTrainer - INFO -   ndcg@10: 0.029386
2025-12-15 20:15:15 - GraphTrainer - INFO -   map@10: 0.021224
2025-12-15 20:15:15 - GraphTrainer - INFO -   mrr@10: 0.022163
2025-12-15 20:15:15 - GraphTrainer - INFO -   precision@20: 0.004556
2025-12-15 20:15:15 - GraphTrainer - INFO -   recall@20: 0.086285
2025-12-15 20:15:15 - GraphTrainer - INFO -   hit_rate@20: 0.090615
2025-12-15 20:15:15 - GraphTrainer - INFO -   ndcg@20: 0.037266
2025-12-15 20:15:15 - GraphTrainer - INFO -   map@20: 0.023333
2025-12-15 20:15:15 - GraphTrainer - INFO -   mrr@20: 0.024365
2025-12-15 20:15:15 - GraphTrainer - INFO - 第 42 轮训练完成
2025-12-15 20:15:15 - GraphTrainer - INFO - train_loss: 0.219742
2025-12-15 20:15:15 - GraphTrainer - INFO - precision@5: 0.007190
2025-12-15 20:15:15 - GraphTrainer - INFO - recall@5: 0.034492
2025-12-15 20:15:15 - GraphTrainer - INFO - hit_rate@5: 0.035896
2025-12-15 20:15:15 - GraphTrainer - INFO - ndcg@5: 0.022638
2025-12-15 20:15:15 - GraphTrainer - INFO - map@5: 0.018511
2025-12-15 20:15:15 - GraphTrainer - INFO - mrr@5: 0.019247
2025-12-15 20:15:15 - GraphTrainer - INFO - precision@10: 0.005837
2025-12-15 20:15:15 - GraphTrainer - INFO - recall@10: 0.055217
2025-12-15 20:15:15 - GraphTrainer - INFO - hit_rate@10: 0.058164
2025-12-15 20:15:15 - GraphTrainer - INFO - ndcg@10: 0.029386
2025-12-15 20:15:15 - GraphTrainer - INFO - map@10: 0.021224
2025-12-15 20:15:15 - GraphTrainer - INFO - mrr@10: 0.022163
2025-12-15 20:15:15 - GraphTrainer - INFO - precision@20: 0.004556
2025-12-15 20:15:15 - GraphTrainer - INFO - recall@20: 0.086285
2025-12-15 20:15:15 - GraphTrainer - INFO - hit_rate@20: 0.090615
2025-12-15 20:15:15 - GraphTrainer - INFO - ndcg@20: 0.037266
2025-12-15 20:15:15 - GraphTrainer - INFO - map@20: 0.023333
2025-12-15 20:15:15 - GraphTrainer - INFO - mrr@20: 0.024365
2025-12-15 20:15:15 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:15:15 - GraphTrainer - INFO - ============================================================
2025-12-15 20:15:15 - GraphTrainer - INFO - 开始第 43/1000 轮训练
2025-12-15 20:15:15 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2068, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2355, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2082, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2105, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2305, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2104, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2255, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2121, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2196, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2283, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2375, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2117, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2249, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.1997, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2303, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2206, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2142, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2273, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2054, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2009, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2238, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2186, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2092, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2316, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2061, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.1995, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2333, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2196, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2144, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2078, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2220, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2266, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2374, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2417, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2257, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2530, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1943, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2172, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2276, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2342, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2249, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2080, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2475, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.1944, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2288, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2013, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2230, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2010, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2283, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2115, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2326, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2280, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2207, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2269, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2206, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2162, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2084, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2195, device='cuda:0', grad_fn=<AddBackward0>)
The 42 training average loss: 0.21974225316582055
2025-12-15 20:15:24 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:15:24 - GraphTrainer - INFO -   precision@5: 0.006932
2025-12-15 20:15:24 - GraphTrainer - INFO -   recall@5: 0.033050
2025-12-15 20:15:24 - GraphTrainer - INFO -   hit_rate@5: 0.034610
2025-12-15 20:15:24 - GraphTrainer - INFO -   ndcg@5: 0.021875
2025-12-15 20:15:24 - GraphTrainer - INFO -   map@5: 0.017940
2025-12-15 20:15:24 - GraphTrainer - INFO -   mrr@5: 0.018756
2025-12-15 20:15:24 - GraphTrainer - INFO -   precision@10: 0.005714
2025-12-15 20:15:24 - GraphTrainer - INFO -   recall@10: 0.054196
2025-12-15 20:15:24 - GraphTrainer - INFO -   hit_rate@10: 0.056981
2025-12-15 20:15:24 - GraphTrainer - INFO -   ndcg@10: 0.028736
2025-12-15 20:15:24 - GraphTrainer - INFO -   map@10: 0.020710
2025-12-15 20:15:24 - GraphTrainer - INFO -   mrr@10: 0.021674
2025-12-15 20:15:24 - GraphTrainer - INFO -   precision@20: 0.004595
2025-12-15 20:15:24 - GraphTrainer - INFO -   recall@20: 0.087107
2025-12-15 20:15:24 - GraphTrainer - INFO -   hit_rate@20: 0.091489
2025-12-15 20:15:24 - GraphTrainer - INFO -   ndcg@20: 0.037103
2025-12-15 20:15:24 - GraphTrainer - INFO -   map@20: 0.022956
2025-12-15 20:15:24 - GraphTrainer - INFO -   mrr@20: 0.024026
2025-12-15 20:15:24 - GraphTrainer - INFO - 第 43 轮训练完成
2025-12-15 20:15:24 - GraphTrainer - INFO - train_loss: 0.219461
2025-12-15 20:15:24 - GraphTrainer - INFO - precision@5: 0.006932
2025-12-15 20:15:24 - GraphTrainer - INFO - recall@5: 0.033050
2025-12-15 20:15:24 - GraphTrainer - INFO - hit_rate@5: 0.034610
2025-12-15 20:15:24 - GraphTrainer - INFO - ndcg@5: 0.021875
2025-12-15 20:15:24 - GraphTrainer - INFO - map@5: 0.017940
2025-12-15 20:15:24 - GraphTrainer - INFO - mrr@5: 0.018756
2025-12-15 20:15:24 - GraphTrainer - INFO - precision@10: 0.005714
2025-12-15 20:15:24 - GraphTrainer - INFO - recall@10: 0.054196
2025-12-15 20:15:24 - GraphTrainer - INFO - hit_rate@10: 0.056981
2025-12-15 20:15:24 - GraphTrainer - INFO - ndcg@10: 0.028736
2025-12-15 20:15:24 - GraphTrainer - INFO - map@10: 0.020710
2025-12-15 20:15:24 - GraphTrainer - INFO - mrr@10: 0.021674
2025-12-15 20:15:24 - GraphTrainer - INFO - precision@20: 0.004595
2025-12-15 20:15:24 - GraphTrainer - INFO - recall@20: 0.087107
2025-12-15 20:15:24 - GraphTrainer - INFO - hit_rate@20: 0.091489
2025-12-15 20:15:24 - GraphTrainer - INFO - ndcg@20: 0.037103
2025-12-15 20:15:24 - GraphTrainer - INFO - map@20: 0.022956
2025-12-15 20:15:24 - GraphTrainer - INFO - mrr@20: 0.024026
2025-12-15 20:15:24 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:15:24 - GraphTrainer - INFO - ============================================================
2025-12-15 20:15:24 - GraphTrainer - INFO - 开始第 44/1000 轮训练
2025-12-15 20:15:24 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2091, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2344, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2243, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2245, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2219, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2328, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2147, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2394, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2143, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.1830, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2245, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2214, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2111, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2208, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2096, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1994, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1918, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2149, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2074, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2470, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2295, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2252, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2341, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2185, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2142, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2225, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2255, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2341, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2158, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2226, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2192, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2122, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2158, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2254, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2076, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2231, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2274, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2077, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2220, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2307, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2203, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2180, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2420, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2099, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2315, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2231, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2061, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.1993, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2223, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2355, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2152, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2083, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2113, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2093, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2378, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2269, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2125, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2202, device='cuda:0', grad_fn=<AddBackward0>)
The 43 training average loss: 0.21946059578451618
2025-12-15 20:15:32 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:15:32 - GraphTrainer - INFO -   precision@5: 0.007087
2025-12-15 20:15:32 - GraphTrainer - INFO -   recall@5: 0.033847
2025-12-15 20:15:32 - GraphTrainer - INFO -   hit_rate@5: 0.035382
2025-12-15 20:15:32 - GraphTrainer - INFO -   ndcg@5: 0.022826
2025-12-15 20:15:32 - GraphTrainer - INFO -   map@5: 0.018919
2025-12-15 20:15:32 - GraphTrainer - INFO -   mrr@5: 0.019782
2025-12-15 20:15:32 - GraphTrainer - INFO -   precision@10: 0.005719
2025-12-15 20:15:32 - GraphTrainer - INFO -   recall@10: 0.054436
2025-12-15 20:15:32 - GraphTrainer - INFO -   hit_rate@10: 0.057033
2025-12-15 20:15:32 - GraphTrainer - INFO -   ndcg@10: 0.029483
2025-12-15 20:15:32 - GraphTrainer - INFO -   map@10: 0.021600
2025-12-15 20:15:32 - GraphTrainer - INFO -   mrr@10: 0.022596
2025-12-15 20:15:32 - GraphTrainer - INFO -   precision@20: 0.004556
2025-12-15 20:15:32 - GraphTrainer - INFO -   recall@20: 0.086401
2025-12-15 20:15:32 - GraphTrainer - INFO -   hit_rate@20: 0.090666
2025-12-15 20:15:32 - GraphTrainer - INFO -   ndcg@20: 0.037600
2025-12-15 20:15:32 - GraphTrainer - INFO -   map@20: 0.023768
2025-12-15 20:15:32 - GraphTrainer - INFO -   mrr@20: 0.024878
2025-12-15 20:15:32 - GraphTrainer - INFO - 第 44 轮训练完成
2025-12-15 20:15:32 - GraphTrainer - INFO - train_loss: 0.217371
2025-12-15 20:15:32 - GraphTrainer - INFO - precision@5: 0.007087
2025-12-15 20:15:32 - GraphTrainer - INFO - recall@5: 0.033847
2025-12-15 20:15:32 - GraphTrainer - INFO - hit_rate@5: 0.035382
2025-12-15 20:15:32 - GraphTrainer - INFO - ndcg@5: 0.022826
2025-12-15 20:15:32 - GraphTrainer - INFO - map@5: 0.018919
2025-12-15 20:15:32 - GraphTrainer - INFO - mrr@5: 0.019782
2025-12-15 20:15:32 - GraphTrainer - INFO - precision@10: 0.005719
2025-12-15 20:15:32 - GraphTrainer - INFO - recall@10: 0.054436
2025-12-15 20:15:32 - GraphTrainer - INFO - hit_rate@10: 0.057033
2025-12-15 20:15:32 - GraphTrainer - INFO - ndcg@10: 0.029483
2025-12-15 20:15:32 - GraphTrainer - INFO - map@10: 0.021600
2025-12-15 20:15:32 - GraphTrainer - INFO - mrr@10: 0.022596
2025-12-15 20:15:32 - GraphTrainer - INFO - precision@20: 0.004556
2025-12-15 20:15:32 - GraphTrainer - INFO - recall@20: 0.086401
2025-12-15 20:15:32 - GraphTrainer - INFO - hit_rate@20: 0.090666
2025-12-15 20:15:32 - GraphTrainer - INFO - ndcg@20: 0.037600
2025-12-15 20:15:32 - GraphTrainer - INFO - map@20: 0.023768
2025-12-15 20:15:32 - GraphTrainer - INFO - mrr@20: 0.024878
2025-12-15 20:15:32 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:15:32 - GraphTrainer - INFO - ============================================================
2025-12-15 20:15:32 - GraphTrainer - INFO - 开始第 45/1000 轮训练
2025-12-15 20:15:32 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2126, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2330, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2286, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2115, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2399, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.1996, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2283, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2424, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2135, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2154, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2158, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2325, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2349, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2156, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2212, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2184, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2157, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2037, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2267, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.1999, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2046, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2255, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2388, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2230, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2138, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2371, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2079, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2183, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2347, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.1915, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2429, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2136, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2134, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1993, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2056, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2354, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2015, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2433, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2221, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2139, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1767, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.1919, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2067, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.1875, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2050, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2226, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2155, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2203, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2215, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2217, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2457, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2225, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2104, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2107, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2171, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2050, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.1948, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2367, device='cuda:0', grad_fn=<AddBackward0>)
The 44 training average loss: 0.21737119761006585
2025-12-15 20:15:40 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:15:40 - GraphTrainer - INFO -   precision@5: 0.007272
2025-12-15 20:15:40 - GraphTrainer - INFO -   recall@5: 0.034803
2025-12-15 20:15:40 - GraphTrainer - INFO -   hit_rate@5: 0.036308
2025-12-15 20:15:40 - GraphTrainer - INFO -   ndcg@5: 0.022867
2025-12-15 20:15:40 - GraphTrainer - INFO -   map@5: 0.018688
2025-12-15 20:15:40 - GraphTrainer - INFO -   mrr@5: 0.019541
2025-12-15 20:15:40 - GraphTrainer - INFO -   precision@10: 0.005657
2025-12-15 20:15:40 - GraphTrainer - INFO -   recall@10: 0.053596
2025-12-15 20:15:40 - GraphTrainer - INFO -   hit_rate@10: 0.056416
2025-12-15 20:15:40 - GraphTrainer - INFO -   ndcg@10: 0.028958
2025-12-15 20:15:40 - GraphTrainer - INFO -   map@10: 0.021124
2025-12-15 20:15:40 - GraphTrainer - INFO -   mrr@10: 0.022142
2025-12-15 20:15:40 - GraphTrainer - INFO -   precision@20: 0.004549
2025-12-15 20:15:40 - GraphTrainer - INFO -   recall@20: 0.086273
2025-12-15 20:15:40 - GraphTrainer - INFO -   hit_rate@20: 0.090563
2025-12-15 20:15:40 - GraphTrainer - INFO -   ndcg@20: 0.037265
2025-12-15 20:15:40 - GraphTrainer - INFO -   map@20: 0.023360
2025-12-15 20:15:40 - GraphTrainer - INFO -   mrr@20: 0.024479
2025-12-15 20:15:40 - GraphTrainer - INFO - 第 45 轮训练完成
2025-12-15 20:15:40 - GraphTrainer - INFO - train_loss: 0.218619
2025-12-15 20:15:40 - GraphTrainer - INFO - precision@5: 0.007272
2025-12-15 20:15:40 - GraphTrainer - INFO - recall@5: 0.034803
2025-12-15 20:15:40 - GraphTrainer - INFO - hit_rate@5: 0.036308
2025-12-15 20:15:40 - GraphTrainer - INFO - ndcg@5: 0.022867
2025-12-15 20:15:40 - GraphTrainer - INFO - map@5: 0.018688
2025-12-15 20:15:40 - GraphTrainer - INFO - mrr@5: 0.019541
2025-12-15 20:15:40 - GraphTrainer - INFO - precision@10: 0.005657
2025-12-15 20:15:40 - GraphTrainer - INFO - recall@10: 0.053596
2025-12-15 20:15:40 - GraphTrainer - INFO - hit_rate@10: 0.056416
2025-12-15 20:15:40 - GraphTrainer - INFO - ndcg@10: 0.028958
2025-12-15 20:15:40 - GraphTrainer - INFO - map@10: 0.021124
2025-12-15 20:15:40 - GraphTrainer - INFO - mrr@10: 0.022142
2025-12-15 20:15:40 - GraphTrainer - INFO - precision@20: 0.004549
2025-12-15 20:15:40 - GraphTrainer - INFO - recall@20: 0.086273
2025-12-15 20:15:40 - GraphTrainer - INFO - hit_rate@20: 0.090563
2025-12-15 20:15:40 - GraphTrainer - INFO - ndcg@20: 0.037265
2025-12-15 20:15:40 - GraphTrainer - INFO - map@20: 0.023360
2025-12-15 20:15:40 - GraphTrainer - INFO - mrr@20: 0.024479
2025-12-15 20:15:40 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:15:40 - GraphTrainer - INFO - ============================================================
2025-12-15 20:15:40 - GraphTrainer - INFO - 开始第 46/1000 轮训练
2025-12-15 20:15:40 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1997, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2197, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2172, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2239, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2104, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2282, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2071, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2022, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2311, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.1977, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2118, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2417, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2258, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2238, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2130, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2167, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2278, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2110, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2172, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2156, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2359, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2195, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2154, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2078, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2088, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2130, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2204, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2083, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2152, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2001, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2118, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2312, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2035, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2228, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2132, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2197, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2172, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2078, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2326, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2308, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2188, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2149, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2408, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2118, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2120, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2183, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2173, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2305, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2296, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2488, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2035, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2088, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2375, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2287, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2233, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.1942, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2205, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2441, device='cuda:0', grad_fn=<AddBackward0>)
The 45 training average loss: 0.21861942061062517
2025-12-15 20:15:49 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:15:49 - GraphTrainer - INFO -   precision@5: 0.007035
2025-12-15 20:15:49 - GraphTrainer - INFO -   recall@5: 0.033516
2025-12-15 20:15:49 - GraphTrainer - INFO -   hit_rate@5: 0.035125
2025-12-15 20:15:49 - GraphTrainer - INFO -   ndcg@5: 0.022572
2025-12-15 20:15:49 - GraphTrainer - INFO -   map@5: 0.018699
2025-12-15 20:15:49 - GraphTrainer - INFO -   mrr@5: 0.019575
2025-12-15 20:15:49 - GraphTrainer - INFO -   precision@10: 0.005811
2025-12-15 20:15:49 - GraphTrainer - INFO -   recall@10: 0.055220
2025-12-15 20:15:49 - GraphTrainer - INFO -   hit_rate@10: 0.057958
2025-12-15 20:15:49 - GraphTrainer - INFO -   ndcg@10: 0.029614
2025-12-15 20:15:49 - GraphTrainer - INFO -   map@10: 0.021548
2025-12-15 20:15:49 - GraphTrainer - INFO -   mrr@10: 0.022570
2025-12-15 20:15:49 - GraphTrainer - INFO -   precision@20: 0.004564
2025-12-15 20:15:49 - GraphTrainer - INFO -   recall@20: 0.086649
2025-12-15 20:15:49 - GraphTrainer - INFO -   hit_rate@20: 0.090923
2025-12-15 20:15:49 - GraphTrainer - INFO -   ndcg@20: 0.037575
2025-12-15 20:15:49 - GraphTrainer - INFO -   map@20: 0.023669
2025-12-15 20:15:49 - GraphTrainer - INFO -   mrr@20: 0.024799
2025-12-15 20:15:49 - GraphTrainer - INFO - 第 46 轮训练完成
2025-12-15 20:15:49 - GraphTrainer - INFO - train_loss: 0.217832
2025-12-15 20:15:49 - GraphTrainer - INFO - precision@5: 0.007035
2025-12-15 20:15:49 - GraphTrainer - INFO - recall@5: 0.033516
2025-12-15 20:15:49 - GraphTrainer - INFO - hit_rate@5: 0.035125
2025-12-15 20:15:49 - GraphTrainer - INFO - ndcg@5: 0.022572
2025-12-15 20:15:49 - GraphTrainer - INFO - map@5: 0.018699
2025-12-15 20:15:49 - GraphTrainer - INFO - mrr@5: 0.019575
2025-12-15 20:15:49 - GraphTrainer - INFO - precision@10: 0.005811
2025-12-15 20:15:49 - GraphTrainer - INFO - recall@10: 0.055220
2025-12-15 20:15:49 - GraphTrainer - INFO - hit_rate@10: 0.057958
2025-12-15 20:15:49 - GraphTrainer - INFO - ndcg@10: 0.029614
2025-12-15 20:15:49 - GraphTrainer - INFO - map@10: 0.021548
2025-12-15 20:15:49 - GraphTrainer - INFO - mrr@10: 0.022570
2025-12-15 20:15:49 - GraphTrainer - INFO - precision@20: 0.004564
2025-12-15 20:15:49 - GraphTrainer - INFO - recall@20: 0.086649
2025-12-15 20:15:49 - GraphTrainer - INFO - hit_rate@20: 0.090923
2025-12-15 20:15:49 - GraphTrainer - INFO - ndcg@20: 0.037575
2025-12-15 20:15:49 - GraphTrainer - INFO - map@20: 0.023669
2025-12-15 20:15:49 - GraphTrainer - INFO - mrr@20: 0.024799
2025-12-15 20:15:49 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:15:49 - GraphTrainer - INFO - ============================================================
2025-12-15 20:15:49 - GraphTrainer - INFO - 开始第 47/1000 轮训练
2025-12-15 20:15:49 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2173, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2046, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.1946, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2171, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2305, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2276, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2192, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2312, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2179, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2395, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2317, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2399, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2104, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2057, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2195, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2068, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2297, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2279, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2173, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2374, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2234, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2323, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2256, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2276, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.1936, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2179, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2025, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2067, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2135, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2237, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2038, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2111, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2377, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2071, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2069, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2097, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2136, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2200, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2025, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2423, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2150, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.1961, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2179, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2163, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2277, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2269, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2140, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2369, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2168, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2431, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2004, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2195, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.1920, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2277, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2150, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.1857, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2110, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2248, device='cuda:0', grad_fn=<AddBackward0>)
The 46 training average loss: 0.21783163064512714
2025-12-15 20:15:57 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:15:57 - GraphTrainer - INFO -   precision@5: 0.007179
2025-12-15 20:15:57 - GraphTrainer - INFO -   recall@5: 0.034300
2025-12-15 20:15:57 - GraphTrainer - INFO -   hit_rate@5: 0.035896
2025-12-15 20:15:57 - GraphTrainer - INFO -   ndcg@5: 0.023030
2025-12-15 20:15:57 - GraphTrainer - INFO -   map@5: 0.019055
2025-12-15 20:15:57 - GraphTrainer - INFO -   mrr@5: 0.019949
2025-12-15 20:15:57 - GraphTrainer - INFO -   precision@10: 0.005760
2025-12-15 20:15:57 - GraphTrainer - INFO -   recall@10: 0.054741
2025-12-15 20:15:57 - GraphTrainer - INFO -   hit_rate@10: 0.057547
2025-12-15 20:15:57 - GraphTrainer - INFO -   ndcg@10: 0.029657
2025-12-15 20:15:57 - GraphTrainer - INFO -   map@10: 0.021722
2025-12-15 20:15:57 - GraphTrainer - INFO -   mrr@10: 0.022772
2025-12-15 20:15:57 - GraphTrainer - INFO -   precision@20: 0.004652
2025-12-15 20:15:57 - GraphTrainer - INFO -   recall@20: 0.088283
2025-12-15 20:15:57 - GraphTrainer - INFO -   hit_rate@20: 0.092620
2025-12-15 20:15:57 - GraphTrainer - INFO -   ndcg@20: 0.038164
2025-12-15 20:15:57 - GraphTrainer - INFO -   map@20: 0.023996
2025-12-15 20:15:57 - GraphTrainer - INFO -   mrr@20: 0.025151
2025-12-15 20:15:57 - GraphTrainer - INFO - 第 47 轮训练完成
2025-12-15 20:15:57 - GraphTrainer - INFO - train_loss: 0.213147
2025-12-15 20:15:57 - GraphTrainer - INFO - precision@5: 0.007179
2025-12-15 20:15:57 - GraphTrainer - INFO - recall@5: 0.034300
2025-12-15 20:15:57 - GraphTrainer - INFO - hit_rate@5: 0.035896
2025-12-15 20:15:57 - GraphTrainer - INFO - ndcg@5: 0.023030
2025-12-15 20:15:57 - GraphTrainer - INFO - map@5: 0.019055
2025-12-15 20:15:57 - GraphTrainer - INFO - mrr@5: 0.019949
2025-12-15 20:15:57 - GraphTrainer - INFO - precision@10: 0.005760
2025-12-15 20:15:57 - GraphTrainer - INFO - recall@10: 0.054741
2025-12-15 20:15:57 - GraphTrainer - INFO - hit_rate@10: 0.057547
2025-12-15 20:15:57 - GraphTrainer - INFO - ndcg@10: 0.029657
2025-12-15 20:15:57 - GraphTrainer - INFO - map@10: 0.021722
2025-12-15 20:15:57 - GraphTrainer - INFO - mrr@10: 0.022772
2025-12-15 20:15:57 - GraphTrainer - INFO - precision@20: 0.004652
2025-12-15 20:15:57 - GraphTrainer - INFO - recall@20: 0.088283
2025-12-15 20:15:57 - GraphTrainer - INFO - hit_rate@20: 0.092620
2025-12-15 20:15:57 - GraphTrainer - INFO - ndcg@20: 0.038164
2025-12-15 20:15:57 - GraphTrainer - INFO - map@20: 0.023996
2025-12-15 20:15:57 - GraphTrainer - INFO - mrr@20: 0.025151
2025-12-15 20:15:57 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:15:57 - GraphTrainer - INFO - ============================================================
2025-12-15 20:15:57 - GraphTrainer - INFO - 开始第 48/1000 轮训练
2025-12-15 20:15:57 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2244, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.1985, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2214, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2205, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2119, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2162, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2026, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2160, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2067, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2086, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2045, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2127, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1973, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2022, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2034, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2046, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2296, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2003, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2183, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2195, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2249, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2154, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2388, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2101, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2136, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2272, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.1967, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2066, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2009, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2296, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2147, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2410, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2219, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2145, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2281, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2191, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2093, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2139, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.1983, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2169, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2202, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2023, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2145, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2018, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2091, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.1883, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2283, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2204, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1955, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2153, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2146, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2185, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2179, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1944, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2313, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2044, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2114, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2136, device='cuda:0', grad_fn=<AddBackward0>)
The 47 training average loss: 0.2131474303274319
2025-12-15 20:16:06 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:16:06 - GraphTrainer - INFO -   precision@5: 0.006881
2025-12-15 20:16:06 - GraphTrainer - INFO -   recall@5: 0.032620
2025-12-15 20:16:06 - GraphTrainer - INFO -   hit_rate@5: 0.034353
2025-12-15 20:16:06 - GraphTrainer - INFO -   ndcg@5: 0.022191
2025-12-15 20:16:06 - GraphTrainer - INFO -   map@5: 0.018494
2025-12-15 20:16:06 - GraphTrainer - INFO -   mrr@5: 0.019339
2025-12-15 20:16:06 - GraphTrainer - INFO -   precision@10: 0.005631
2025-12-15 20:16:06 - GraphTrainer - INFO -   recall@10: 0.053346
2025-12-15 20:16:06 - GraphTrainer - INFO -   hit_rate@10: 0.056158
2025-12-15 20:16:06 - GraphTrainer - INFO -   ndcg@10: 0.028881
2025-12-15 20:16:06 - GraphTrainer - INFO -   map@10: 0.021179
2025-12-15 20:16:06 - GraphTrainer - INFO -   mrr@10: 0.022166
2025-12-15 20:16:06 - GraphTrainer - INFO -   precision@20: 0.004510
2025-12-15 20:16:06 - GraphTrainer - INFO -   recall@20: 0.085260
2025-12-15 20:16:06 - GraphTrainer - INFO -   hit_rate@20: 0.089637
2025-12-15 20:16:06 - GraphTrainer - INFO -   ndcg@20: 0.037000
2025-12-15 20:16:06 - GraphTrainer - INFO -   map@20: 0.023359
2025-12-15 20:16:06 - GraphTrainer - INFO -   mrr@20: 0.024449
2025-12-15 20:16:06 - GraphTrainer - INFO - 第 48 轮训练完成
2025-12-15 20:16:06 - GraphTrainer - INFO - train_loss: 0.213836
2025-12-15 20:16:06 - GraphTrainer - INFO - precision@5: 0.006881
2025-12-15 20:16:06 - GraphTrainer - INFO - recall@5: 0.032620
2025-12-15 20:16:06 - GraphTrainer - INFO - hit_rate@5: 0.034353
2025-12-15 20:16:06 - GraphTrainer - INFO - ndcg@5: 0.022191
2025-12-15 20:16:06 - GraphTrainer - INFO - map@5: 0.018494
2025-12-15 20:16:06 - GraphTrainer - INFO - mrr@5: 0.019339
2025-12-15 20:16:06 - GraphTrainer - INFO - precision@10: 0.005631
2025-12-15 20:16:06 - GraphTrainer - INFO - recall@10: 0.053346
2025-12-15 20:16:06 - GraphTrainer - INFO - hit_rate@10: 0.056158
2025-12-15 20:16:06 - GraphTrainer - INFO - ndcg@10: 0.028881
2025-12-15 20:16:06 - GraphTrainer - INFO - map@10: 0.021179
2025-12-15 20:16:06 - GraphTrainer - INFO - mrr@10: 0.022166
2025-12-15 20:16:06 - GraphTrainer - INFO - precision@20: 0.004510
2025-12-15 20:16:06 - GraphTrainer - INFO - recall@20: 0.085260
2025-12-15 20:16:06 - GraphTrainer - INFO - hit_rate@20: 0.089637
2025-12-15 20:16:06 - GraphTrainer - INFO - ndcg@20: 0.037000
2025-12-15 20:16:06 - GraphTrainer - INFO - map@20: 0.023359
2025-12-15 20:16:06 - GraphTrainer - INFO - mrr@20: 0.024449
2025-12-15 20:16:06 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:16:06 - GraphTrainer - INFO - ============================================================
2025-12-15 20:16:06 - GraphTrainer - INFO - 开始第 49/1000 轮训练
2025-12-15 20:16:06 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2368, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2012, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2134, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2074, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2281, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2126, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2057, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2019, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2309, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2121, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1917, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2260, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2199, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2038, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2316, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2083, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2113, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2179, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2199, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2244, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1911, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2005, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2122, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2193, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2276, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2091, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2285, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2195, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2071, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2209, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2229, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2180, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2052, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2141, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2013, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2307, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2135, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2380, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2196, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2094, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2086, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2130, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2135, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2032, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2023, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2015, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2287, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2041, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2042, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2221, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2394, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.1973, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2029, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1954, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2169, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2117, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2153, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2094, device='cuda:0', grad_fn=<AddBackward0>)
The 48 training average loss: 0.21383640427013922
2025-12-15 20:16:14 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:16:14 - GraphTrainer - INFO -   precision@5: 0.007138
2025-12-15 20:16:14 - GraphTrainer - INFO -   recall@5: 0.034002
2025-12-15 20:16:14 - GraphTrainer - INFO -   hit_rate@5: 0.035690
2025-12-15 20:16:14 - GraphTrainer - INFO -   ndcg@5: 0.022787
2025-12-15 20:16:14 - GraphTrainer - INFO -   map@5: 0.018830
2025-12-15 20:16:14 - GraphTrainer - INFO -   mrr@5: 0.019702
2025-12-15 20:16:14 - GraphTrainer - INFO -   precision@10: 0.005672
2025-12-15 20:16:14 - GraphTrainer - INFO -   recall@10: 0.053635
2025-12-15 20:16:14 - GraphTrainer - INFO -   hit_rate@10: 0.056570
2025-12-15 20:16:14 - GraphTrainer - INFO -   ndcg@10: 0.029195
2025-12-15 20:16:14 - GraphTrainer - INFO -   map@10: 0.021430
2025-12-15 20:16:14 - GraphTrainer - INFO -   mrr@10: 0.022459
2025-12-15 20:16:14 - GraphTrainer - INFO -   precision@20: 0.004569
2025-12-15 20:16:14 - GraphTrainer - INFO -   recall@20: 0.086477
2025-12-15 20:16:14 - GraphTrainer - INFO -   hit_rate@20: 0.090975
2025-12-15 20:16:14 - GraphTrainer - INFO -   ndcg@20: 0.037507
2025-12-15 20:16:14 - GraphTrainer - INFO -   map@20: 0.023645
2025-12-15 20:16:14 - GraphTrainer - INFO -   mrr@20: 0.024776
2025-12-15 20:16:14 - GraphTrainer - INFO - 第 49 轮训练完成
2025-12-15 20:16:14 - GraphTrainer - INFO - train_loss: 0.215956
2025-12-15 20:16:14 - GraphTrainer - INFO - precision@5: 0.007138
2025-12-15 20:16:14 - GraphTrainer - INFO - recall@5: 0.034002
2025-12-15 20:16:14 - GraphTrainer - INFO - hit_rate@5: 0.035690
2025-12-15 20:16:14 - GraphTrainer - INFO - ndcg@5: 0.022787
2025-12-15 20:16:14 - GraphTrainer - INFO - map@5: 0.018830
2025-12-15 20:16:14 - GraphTrainer - INFO - mrr@5: 0.019702
2025-12-15 20:16:14 - GraphTrainer - INFO - precision@10: 0.005672
2025-12-15 20:16:14 - GraphTrainer - INFO - recall@10: 0.053635
2025-12-15 20:16:14 - GraphTrainer - INFO - hit_rate@10: 0.056570
2025-12-15 20:16:14 - GraphTrainer - INFO - ndcg@10: 0.029195
2025-12-15 20:16:14 - GraphTrainer - INFO - map@10: 0.021430
2025-12-15 20:16:14 - GraphTrainer - INFO - mrr@10: 0.022459
2025-12-15 20:16:14 - GraphTrainer - INFO - precision@20: 0.004569
2025-12-15 20:16:14 - GraphTrainer - INFO - recall@20: 0.086477
2025-12-15 20:16:14 - GraphTrainer - INFO - hit_rate@20: 0.090975
2025-12-15 20:16:14 - GraphTrainer - INFO - ndcg@20: 0.037507
2025-12-15 20:16:14 - GraphTrainer - INFO - map@20: 0.023645
2025-12-15 20:16:14 - GraphTrainer - INFO - mrr@20: 0.024776
2025-12-15 20:16:14 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:16:14 - GraphTrainer - INFO - ============================================================
2025-12-15 20:16:14 - GraphTrainer - INFO - 开始第 50/1000 轮训练
2025-12-15 20:16:14 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2150, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2098, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2087, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2168, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2257, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.1975, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2156, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2256, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2071, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2066, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2063, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2087, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2364, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2006, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2179, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2109, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2253, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2140, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2251, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.1851, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2199, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2187, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2084, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2294, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2162, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2005, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2008, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2180, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2415, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2236, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2353, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2235, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2406, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2130, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2042, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2037, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1981, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2150, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2347, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2292, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2101, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2179, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2264, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2179, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2280, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2096, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2091, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2273, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2291, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2190, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2221, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2142, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2196, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1971, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2100, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2346, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.1926, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2079, device='cuda:0', grad_fn=<AddBackward0>)
The 49 training average loss: 0.21595634031912375
2025-12-15 20:16:22 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:16:22 - GraphTrainer - INFO -   precision@5: 0.007015
2025-12-15 20:16:22 - GraphTrainer - INFO -   recall@5: 0.033259
2025-12-15 20:16:22 - GraphTrainer - INFO -   hit_rate@5: 0.035022
2025-12-15 20:16:22 - GraphTrainer - INFO -   ndcg@5: 0.022555
2025-12-15 20:16:22 - GraphTrainer - INFO -   map@5: 0.018726
2025-12-15 20:16:22 - GraphTrainer - INFO -   mrr@5: 0.019644
2025-12-15 20:16:22 - GraphTrainer - INFO -   precision@10: 0.005796
2025-12-15 20:16:22 - GraphTrainer - INFO -   recall@10: 0.054950
2025-12-15 20:16:22 - GraphTrainer - INFO -   hit_rate@10: 0.057855
2025-12-15 20:16:22 - GraphTrainer - INFO -   ndcg@10: 0.029579
2025-12-15 20:16:22 - GraphTrainer - INFO -   map@10: 0.021562
2025-12-15 20:16:22 - GraphTrainer - INFO -   mrr@10: 0.022622
2025-12-15 20:16:22 - GraphTrainer - INFO -   precision@20: 0.004605
2025-12-15 20:16:22 - GraphTrainer - INFO -   recall@20: 0.087050
2025-12-15 20:16:22 - GraphTrainer - INFO -   hit_rate@20: 0.091643
2025-12-15 20:16:22 - GraphTrainer - INFO -   ndcg@20: 0.037742
2025-12-15 20:16:22 - GraphTrainer - INFO -   map@20: 0.023746
2025-12-15 20:16:22 - GraphTrainer - INFO -   mrr@20: 0.024915
2025-12-15 20:16:22 - GraphTrainer - INFO - 第 50 轮训练完成
2025-12-15 20:16:22 - GraphTrainer - INFO - train_loss: 0.213318
2025-12-15 20:16:22 - GraphTrainer - INFO - precision@5: 0.007015
2025-12-15 20:16:22 - GraphTrainer - INFO - recall@5: 0.033259
2025-12-15 20:16:22 - GraphTrainer - INFO - hit_rate@5: 0.035022
2025-12-15 20:16:22 - GraphTrainer - INFO - ndcg@5: 0.022555
2025-12-15 20:16:22 - GraphTrainer - INFO - map@5: 0.018726
2025-12-15 20:16:22 - GraphTrainer - INFO - mrr@5: 0.019644
2025-12-15 20:16:22 - GraphTrainer - INFO - precision@10: 0.005796
2025-12-15 20:16:22 - GraphTrainer - INFO - recall@10: 0.054950
2025-12-15 20:16:22 - GraphTrainer - INFO - hit_rate@10: 0.057855
2025-12-15 20:16:22 - GraphTrainer - INFO - ndcg@10: 0.029579
2025-12-15 20:16:22 - GraphTrainer - INFO - map@10: 0.021562
2025-12-15 20:16:22 - GraphTrainer - INFO - mrr@10: 0.022622
2025-12-15 20:16:22 - GraphTrainer - INFO - precision@20: 0.004605
2025-12-15 20:16:22 - GraphTrainer - INFO - recall@20: 0.087050
2025-12-15 20:16:22 - GraphTrainer - INFO - hit_rate@20: 0.091643
2025-12-15 20:16:22 - GraphTrainer - INFO - ndcg@20: 0.037742
2025-12-15 20:16:22 - GraphTrainer - INFO - map@20: 0.023746
2025-12-15 20:16:22 - GraphTrainer - INFO - mrr@20: 0.024915
2025-12-15 20:16:22 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:16:22 - GraphTrainer - INFO - 检查点已保存: Epoch 50 -> ./checkpoints/checkpoint_epoch_50.pth
2025-12-15 20:16:22 - GraphTrainer - INFO - ============================================================
2025-12-15 20:16:22 - GraphTrainer - INFO - 开始第 51/1000 轮训练
2025-12-15 20:16:22 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1931, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2004, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2142, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.1971, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1954, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2356, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.1976, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2245, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2261, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2233, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1830, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2060, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2273, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2159, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.1996, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1941, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2337, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2063, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2048, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2008, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2114, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1979, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2206, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2170, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2105, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2018, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2185, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2253, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2020, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2107, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2149, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2340, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.1974, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1984, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2076, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2220, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2058, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2159, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2140, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2028, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2263, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2045, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2483, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2352, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2257, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.1936, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2035, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2214, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1963, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2180, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2193, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2292, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2222, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2268, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2186, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2421, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2135, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2204, device='cuda:0', grad_fn=<AddBackward0>)
The 50 training average loss: 0.2133175111536322
2025-12-15 20:16:31 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:16:31 - GraphTrainer - INFO -   precision@5: 0.007107
2025-12-15 20:16:31 - GraphTrainer - INFO -   recall@5: 0.033838
2025-12-15 20:16:31 - GraphTrainer - INFO -   hit_rate@5: 0.035485
2025-12-15 20:16:31 - GraphTrainer - INFO -   ndcg@5: 0.022717
2025-12-15 20:16:31 - GraphTrainer - INFO -   map@5: 0.018762
2025-12-15 20:16:31 - GraphTrainer - INFO -   mrr@5: 0.019668
2025-12-15 20:16:31 - GraphTrainer - INFO -   precision@10: 0.005744
2025-12-15 20:16:31 - GraphTrainer - INFO -   recall@10: 0.054358
2025-12-15 20:16:31 - GraphTrainer - INFO -   hit_rate@10: 0.057341
2025-12-15 20:16:31 - GraphTrainer - INFO -   ndcg@10: 0.029393
2025-12-15 20:16:31 - GraphTrainer - INFO -   map@10: 0.021459
2025-12-15 20:16:31 - GraphTrainer - INFO -   mrr@10: 0.022544
2025-12-15 20:16:31 - GraphTrainer - INFO -   precision@20: 0.004623
2025-12-15 20:16:31 - GraphTrainer - INFO -   recall@20: 0.087535
2025-12-15 20:16:31 - GraphTrainer - INFO -   hit_rate@20: 0.092003
2025-12-15 20:16:31 - GraphTrainer - INFO -   ndcg@20: 0.037773
2025-12-15 20:16:31 - GraphTrainer - INFO -   map@20: 0.023682
2025-12-15 20:16:31 - GraphTrainer - INFO -   mrr@20: 0.024860
2025-12-15 20:16:31 - GraphTrainer - INFO - 第 51 轮训练完成
2025-12-15 20:16:31 - GraphTrainer - INFO - train_loss: 0.213869
2025-12-15 20:16:31 - GraphTrainer - INFO - precision@5: 0.007107
2025-12-15 20:16:31 - GraphTrainer - INFO - recall@5: 0.033838
2025-12-15 20:16:31 - GraphTrainer - INFO - hit_rate@5: 0.035485
2025-12-15 20:16:31 - GraphTrainer - INFO - ndcg@5: 0.022717
2025-12-15 20:16:31 - GraphTrainer - INFO - map@5: 0.018762
2025-12-15 20:16:31 - GraphTrainer - INFO - mrr@5: 0.019668
2025-12-15 20:16:31 - GraphTrainer - INFO - precision@10: 0.005744
2025-12-15 20:16:31 - GraphTrainer - INFO - recall@10: 0.054358
2025-12-15 20:16:31 - GraphTrainer - INFO - hit_rate@10: 0.057341
2025-12-15 20:16:31 - GraphTrainer - INFO - ndcg@10: 0.029393
2025-12-15 20:16:31 - GraphTrainer - INFO - map@10: 0.021459
2025-12-15 20:16:31 - GraphTrainer - INFO - mrr@10: 0.022544
2025-12-15 20:16:31 - GraphTrainer - INFO - precision@20: 0.004623
2025-12-15 20:16:31 - GraphTrainer - INFO - recall@20: 0.087535
2025-12-15 20:16:31 - GraphTrainer - INFO - hit_rate@20: 0.092003
2025-12-15 20:16:31 - GraphTrainer - INFO - ndcg@20: 0.037773
2025-12-15 20:16:31 - GraphTrainer - INFO - map@20: 0.023682
2025-12-15 20:16:31 - GraphTrainer - INFO - mrr@20: 0.024860
2025-12-15 20:16:31 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:16:31 - GraphTrainer - INFO - ============================================================
2025-12-15 20:16:31 - GraphTrainer - INFO - 开始第 52/1000 轮训练
2025-12-15 20:16:31 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2118, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2172, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2407, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2089, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2053, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2292, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2115, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2118, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2065, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2073, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2333, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2248, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2015, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.1982, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2241, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2345, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2114, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2057, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2041, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2052, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2067, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2140, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2078, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2229, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2186, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2102, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2307, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2111, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.1964, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2161, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.1957, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2212, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2340, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2272, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2118, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2409, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2114, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2225, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2227, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2048, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2051, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2193, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.1997, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.1990, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2123, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2160, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2205, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2125, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2027, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.1987, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2002, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2238, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2150, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2125, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2029, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2007, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2097, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2342, device='cuda:0', grad_fn=<AddBackward0>)
The 51 training average loss: 0.21386866040270905
2025-12-15 20:16:39 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:16:39 - GraphTrainer - INFO -   precision@5: 0.007169
2025-12-15 20:16:39 - GraphTrainer - INFO -   recall@5: 0.034138
2025-12-15 20:16:39 - GraphTrainer - INFO -   hit_rate@5: 0.035793
2025-12-15 20:16:39 - GraphTrainer - INFO -   ndcg@5: 0.023048
2025-12-15 20:16:39 - GraphTrainer - INFO -   map@5: 0.019119
2025-12-15 20:16:39 - GraphTrainer - INFO -   mrr@5: 0.019996
2025-12-15 20:16:39 - GraphTrainer - INFO -   precision@10: 0.005847
2025-12-15 20:16:39 - GraphTrainer - INFO -   recall@10: 0.055305
2025-12-15 20:16:39 - GraphTrainer - INFO -   hit_rate@10: 0.058318
2025-12-15 20:16:39 - GraphTrainer - INFO -   ndcg@10: 0.029927
2025-12-15 20:16:39 - GraphTrainer - INFO -   map@10: 0.021894
2025-12-15 20:16:39 - GraphTrainer - INFO -   mrr@10: 0.022943
2025-12-15 20:16:39 - GraphTrainer - INFO -   precision@20: 0.004659
2025-12-15 20:16:39 - GraphTrainer - INFO -   recall@20: 0.088060
2025-12-15 20:16:39 - GraphTrainer - INFO -   hit_rate@20: 0.092620
2025-12-15 20:16:39 - GraphTrainer - INFO -   ndcg@20: 0.038254
2025-12-15 20:16:39 - GraphTrainer - INFO -   map@20: 0.024130
2025-12-15 20:16:39 - GraphTrainer - INFO -   mrr@20: 0.025277
2025-12-15 20:16:39 - GraphTrainer - INFO - 第 52 轮训练完成
2025-12-15 20:16:39 - GraphTrainer - INFO - train_loss: 0.207286
2025-12-15 20:16:39 - GraphTrainer - INFO - precision@5: 0.007169
2025-12-15 20:16:39 - GraphTrainer - INFO - recall@5: 0.034138
2025-12-15 20:16:39 - GraphTrainer - INFO - hit_rate@5: 0.035793
2025-12-15 20:16:39 - GraphTrainer - INFO - ndcg@5: 0.023048
2025-12-15 20:16:39 - GraphTrainer - INFO - map@5: 0.019119
2025-12-15 20:16:39 - GraphTrainer - INFO - mrr@5: 0.019996
2025-12-15 20:16:39 - GraphTrainer - INFO - precision@10: 0.005847
2025-12-15 20:16:39 - GraphTrainer - INFO - recall@10: 0.055305
2025-12-15 20:16:39 - GraphTrainer - INFO - hit_rate@10: 0.058318
2025-12-15 20:16:39 - GraphTrainer - INFO - ndcg@10: 0.029927
2025-12-15 20:16:39 - GraphTrainer - INFO - map@10: 0.021894
2025-12-15 20:16:39 - GraphTrainer - INFO - mrr@10: 0.022943
2025-12-15 20:16:39 - GraphTrainer - INFO - precision@20: 0.004659
2025-12-15 20:16:39 - GraphTrainer - INFO - recall@20: 0.088060
2025-12-15 20:16:39 - GraphTrainer - INFO - hit_rate@20: 0.092620
2025-12-15 20:16:39 - GraphTrainer - INFO - ndcg@20: 0.038254
2025-12-15 20:16:39 - GraphTrainer - INFO - map@20: 0.024130
2025-12-15 20:16:39 - GraphTrainer - INFO - mrr@20: 0.025277
2025-12-15 20:16:39 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:16:39 - GraphTrainer - INFO - ============================================================
2025-12-15 20:16:39 - GraphTrainer - INFO - 开始第 53/1000 轮训练
2025-12-15 20:16:39 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2074, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2214, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.1924, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2069, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2085, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2096, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2053, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2139, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1922, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2067, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2174, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2180, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2113, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.1919, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2124, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2022, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1930, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2379, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.1951, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2060, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2229, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2094, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2265, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2267, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2135, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.1816, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2170, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2136, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.1908, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2055, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.1892, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.1960, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.1918, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1953, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1984, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1918, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2026, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2128, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2090, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.1862, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2166, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.1932, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2190, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2051, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2290, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2045, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2165, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2187, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1874, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2098, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.1950, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2006, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2177, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2100, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2191, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2333, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2007, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2166, device='cuda:0', grad_fn=<AddBackward0>)
The 52 training average loss: 0.20728554165568844
2025-12-15 20:16:47 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:16:47 - GraphTrainer - INFO -   precision@5: 0.007200
2025-12-15 20:16:47 - GraphTrainer - INFO -   recall@5: 0.034366
2025-12-15 20:16:47 - GraphTrainer - INFO -   hit_rate@5: 0.035999
2025-12-15 20:16:47 - GraphTrainer - INFO -   ndcg@5: 0.023442
2025-12-15 20:16:47 - GraphTrainer - INFO -   map@5: 0.019563
2025-12-15 20:16:47 - GraphTrainer - INFO -   mrr@5: 0.020467
2025-12-15 20:16:47 - GraphTrainer - INFO -   precision@10: 0.005724
2025-12-15 20:16:47 - GraphTrainer - INFO -   recall@10: 0.054146
2025-12-15 20:16:47 - GraphTrainer - INFO -   hit_rate@10: 0.057033
2025-12-15 20:16:47 - GraphTrainer - INFO -   ndcg@10: 0.029878
2025-12-15 20:16:47 - GraphTrainer - INFO -   map@10: 0.022162
2025-12-15 20:16:47 - GraphTrainer - INFO -   mrr@10: 0.023225
2025-12-15 20:16:47 - GraphTrainer - INFO -   precision@20: 0.004667
2025-12-15 20:16:47 - GraphTrainer - INFO -   recall@20: 0.088318
2025-12-15 20:16:47 - GraphTrainer - INFO -   hit_rate@20: 0.092723
2025-12-15 20:16:47 - GraphTrainer - INFO -   ndcg@20: 0.038554
2025-12-15 20:16:47 - GraphTrainer - INFO -   map@20: 0.024486
2025-12-15 20:16:47 - GraphTrainer - INFO -   mrr@20: 0.025650
2025-12-15 20:16:47 - GraphTrainer - INFO - 第 53 轮训练完成
2025-12-15 20:16:47 - GraphTrainer - INFO - train_loss: 0.210309
2025-12-15 20:16:47 - GraphTrainer - INFO - precision@5: 0.007200
2025-12-15 20:16:47 - GraphTrainer - INFO - recall@5: 0.034366
2025-12-15 20:16:47 - GraphTrainer - INFO - hit_rate@5: 0.035999
2025-12-15 20:16:47 - GraphTrainer - INFO - ndcg@5: 0.023442
2025-12-15 20:16:47 - GraphTrainer - INFO - map@5: 0.019563
2025-12-15 20:16:47 - GraphTrainer - INFO - mrr@5: 0.020467
2025-12-15 20:16:47 - GraphTrainer - INFO - precision@10: 0.005724
2025-12-15 20:16:47 - GraphTrainer - INFO - recall@10: 0.054146
2025-12-15 20:16:47 - GraphTrainer - INFO - hit_rate@10: 0.057033
2025-12-15 20:16:47 - GraphTrainer - INFO - ndcg@10: 0.029878
2025-12-15 20:16:47 - GraphTrainer - INFO - map@10: 0.022162
2025-12-15 20:16:47 - GraphTrainer - INFO - mrr@10: 0.023225
2025-12-15 20:16:47 - GraphTrainer - INFO - precision@20: 0.004667
2025-12-15 20:16:47 - GraphTrainer - INFO - recall@20: 0.088318
2025-12-15 20:16:47 - GraphTrainer - INFO - hit_rate@20: 0.092723
2025-12-15 20:16:47 - GraphTrainer - INFO - ndcg@20: 0.038554
2025-12-15 20:16:47 - GraphTrainer - INFO - map@20: 0.024486
2025-12-15 20:16:47 - GraphTrainer - INFO - mrr@20: 0.025650
2025-12-15 20:16:47 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:16:47 - GraphTrainer - INFO - ============================================================
2025-12-15 20:16:47 - GraphTrainer - INFO - 开始第 54/1000 轮训练
2025-12-15 20:16:47 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2128, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2109, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.1871, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2228, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2072, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2214, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2088, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2365, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1991, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2081, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2171, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2162, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2153, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2087, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.1931, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1941, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2116, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2077, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2082, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2177, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1965, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2489, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2244, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2123, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2280, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2218, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2199, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2034, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.1967, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.1952, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2007, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2147, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2177, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1980, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1932, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1993, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2041, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2182, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2099, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2247, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2279, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2065, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2122, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2108, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.1969, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2088, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2213, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2166, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1951, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2212, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2150, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.1890, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2075, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2206, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1948, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2302, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.1908, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2003, device='cuda:0', grad_fn=<AddBackward0>)
The 53 training average loss: 0.2103087650290851
2025-12-15 20:16:55 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:16:55 - GraphTrainer - INFO -   precision@5: 0.007148
2025-12-15 20:16:55 - GraphTrainer - INFO -   recall@5: 0.033936
2025-12-15 20:16:55 - GraphTrainer - INFO -   hit_rate@5: 0.035690
2025-12-15 20:16:55 - GraphTrainer - INFO -   ndcg@5: 0.023443
2025-12-15 20:16:55 - GraphTrainer - INFO -   map@5: 0.019676
2025-12-15 20:16:55 - GraphTrainer - INFO -   mrr@5: 0.020615
2025-12-15 20:16:55 - GraphTrainer - INFO -   precision@10: 0.005899
2025-12-15 20:16:55 - GraphTrainer - INFO -   recall@10: 0.055858
2025-12-15 20:16:55 - GraphTrainer - INFO -   hit_rate@10: 0.058730
2025-12-15 20:16:55 - GraphTrainer - INFO -   ndcg@10: 0.030531
2025-12-15 20:16:55 - GraphTrainer - INFO -   map@10: 0.022528
2025-12-15 20:16:55 - GraphTrainer - INFO -   mrr@10: 0.023609
2025-12-15 20:16:55 - GraphTrainer - INFO -   precision@20: 0.004634
2025-12-15 20:16:55 - GraphTrainer - INFO -   recall@20: 0.087817
2025-12-15 20:16:55 - GraphTrainer - INFO -   hit_rate@20: 0.092209
2025-12-15 20:16:55 - GraphTrainer - INFO -   ndcg@20: 0.038628
2025-12-15 20:16:55 - GraphTrainer - INFO -   map@20: 0.024690
2025-12-15 20:16:55 - GraphTrainer - INFO -   mrr@20: 0.025873
2025-12-15 20:16:55 - GraphTrainer - INFO - 第 54 轮训练完成
2025-12-15 20:16:55 - GraphTrainer - INFO - train_loss: 0.208527
2025-12-15 20:16:55 - GraphTrainer - INFO - precision@5: 0.007148
2025-12-15 20:16:55 - GraphTrainer - INFO - recall@5: 0.033936
2025-12-15 20:16:55 - GraphTrainer - INFO - hit_rate@5: 0.035690
2025-12-15 20:16:55 - GraphTrainer - INFO - ndcg@5: 0.023443
2025-12-15 20:16:55 - GraphTrainer - INFO - map@5: 0.019676
2025-12-15 20:16:55 - GraphTrainer - INFO - mrr@5: 0.020615
2025-12-15 20:16:55 - GraphTrainer - INFO - precision@10: 0.005899
2025-12-15 20:16:55 - GraphTrainer - INFO - recall@10: 0.055858
2025-12-15 20:16:55 - GraphTrainer - INFO - hit_rate@10: 0.058730
2025-12-15 20:16:55 - GraphTrainer - INFO - ndcg@10: 0.030531
2025-12-15 20:16:55 - GraphTrainer - INFO - map@10: 0.022528
2025-12-15 20:16:55 - GraphTrainer - INFO - mrr@10: 0.023609
2025-12-15 20:16:55 - GraphTrainer - INFO - precision@20: 0.004634
2025-12-15 20:16:55 - GraphTrainer - INFO - recall@20: 0.087817
2025-12-15 20:16:55 - GraphTrainer - INFO - hit_rate@20: 0.092209
2025-12-15 20:16:55 - GraphTrainer - INFO - ndcg@20: 0.038628
2025-12-15 20:16:55 - GraphTrainer - INFO - map@20: 0.024690
2025-12-15 20:16:55 - GraphTrainer - INFO - mrr@20: 0.025873
2025-12-15 20:16:55 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:16:55 - GraphTrainer - INFO - ============================================================
2025-12-15 20:16:55 - GraphTrainer - INFO - 开始第 55/1000 轮训练
2025-12-15 20:16:55 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1836, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2039, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2014, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.1903, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2003, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2123, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2099, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.1987, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2206, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2152, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2295, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2010, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2185, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2193, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.1977, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2013, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2181, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2048, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2172, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2227, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2289, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2315, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.1969, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2091, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2175, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2185, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.1942, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.1961, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2092, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2127, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.1955, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2085, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2043, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2012, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2124, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2327, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2116, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2090, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2159, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.1935, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2241, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2085, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2030, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.1852, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.1994, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2000, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.1972, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2129, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2191, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2025, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2079, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2113, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2098, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2115, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1999, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2252, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.1915, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2198, device='cuda:0', grad_fn=<AddBackward0>)
The 54 training average loss: 0.20852715136675998
2025-12-15 20:17:04 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:17:04 - GraphTrainer - INFO -   precision@5: 0.007159
2025-12-15 20:17:04 - GraphTrainer - INFO -   recall@5: 0.033958
2025-12-15 20:17:04 - GraphTrainer - INFO -   hit_rate@5: 0.035742
2025-12-15 20:17:04 - GraphTrainer - INFO -   ndcg@5: 0.023169
2025-12-15 20:17:04 - GraphTrainer - INFO -   map@5: 0.019302
2025-12-15 20:17:04 - GraphTrainer - INFO -   mrr@5: 0.020273
2025-12-15 20:17:04 - GraphTrainer - INFO -   precision@10: 0.005796
2025-12-15 20:17:04 - GraphTrainer - INFO -   recall@10: 0.055002
2025-12-15 20:17:04 - GraphTrainer - INFO -   hit_rate@10: 0.057753
2025-12-15 20:17:04 - GraphTrainer - INFO -   ndcg@10: 0.029993
2025-12-15 20:17:04 - GraphTrainer - INFO -   map@10: 0.022068
2025-12-15 20:17:04 - GraphTrainer - INFO -   mrr@10: 0.023161
2025-12-15 20:17:04 - GraphTrainer - INFO -   precision@20: 0.004708
2025-12-15 20:17:04 - GraphTrainer - INFO -   recall@20: 0.088994
2025-12-15 20:17:04 - GraphTrainer - INFO -   hit_rate@20: 0.093546
2025-12-15 20:17:04 - GraphTrainer - INFO -   ndcg@20: 0.038608
2025-12-15 20:17:04 - GraphTrainer - INFO -   map@20: 0.024358
2025-12-15 20:17:04 - GraphTrainer - INFO -   mrr@20: 0.025570
2025-12-15 20:17:04 - GraphTrainer - INFO - 第 55 轮训练完成
2025-12-15 20:17:04 - GraphTrainer - INFO - train_loss: 0.209575
2025-12-15 20:17:04 - GraphTrainer - INFO - precision@5: 0.007159
2025-12-15 20:17:04 - GraphTrainer - INFO - recall@5: 0.033958
2025-12-15 20:17:04 - GraphTrainer - INFO - hit_rate@5: 0.035742
2025-12-15 20:17:04 - GraphTrainer - INFO - ndcg@5: 0.023169
2025-12-15 20:17:04 - GraphTrainer - INFO - map@5: 0.019302
2025-12-15 20:17:04 - GraphTrainer - INFO - mrr@5: 0.020273
2025-12-15 20:17:04 - GraphTrainer - INFO - precision@10: 0.005796
2025-12-15 20:17:04 - GraphTrainer - INFO - recall@10: 0.055002
2025-12-15 20:17:04 - GraphTrainer - INFO - hit_rate@10: 0.057753
2025-12-15 20:17:04 - GraphTrainer - INFO - ndcg@10: 0.029993
2025-12-15 20:17:04 - GraphTrainer - INFO - map@10: 0.022068
2025-12-15 20:17:04 - GraphTrainer - INFO - mrr@10: 0.023161
2025-12-15 20:17:04 - GraphTrainer - INFO - precision@20: 0.004708
2025-12-15 20:17:04 - GraphTrainer - INFO - recall@20: 0.088994
2025-12-15 20:17:04 - GraphTrainer - INFO - hit_rate@20: 0.093546
2025-12-15 20:17:04 - GraphTrainer - INFO - ndcg@20: 0.038608
2025-12-15 20:17:04 - GraphTrainer - INFO - map@20: 0.024358
2025-12-15 20:17:04 - GraphTrainer - INFO - mrr@20: 0.025570
2025-12-15 20:17:04 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:17:04 - GraphTrainer - INFO - ============================================================
2025-12-15 20:17:04 - GraphTrainer - INFO - 开始第 56/1000 轮训练
2025-12-15 20:17:04 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2066, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2155, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2146, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2048, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1936, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2094, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2133, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2172, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2284, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2012, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2264, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2001, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1836, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2163, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2138, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2065, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2131, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2288, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2134, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2068, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2149, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2110, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2096, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2151, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2140, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2152, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2173, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.1989, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.1976, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2049, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2131, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2233, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2077, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2197, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2265, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2131, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2071, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2065, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2091, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2007, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1984, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2107, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2070, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2023, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.1983, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2052, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2088, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.1840, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2039, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.1900, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.1929, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2116, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2311, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2235, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1937, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2200, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2053, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2301, device='cuda:0', grad_fn=<AddBackward0>)
The 55 training average loss: 0.20957538331377096
2025-12-15 20:17:12 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:17:12 - GraphTrainer - INFO -   precision@5: 0.007210
2025-12-15 20:17:12 - GraphTrainer - INFO -   recall@5: 0.034139
2025-12-15 20:17:12 - GraphTrainer - INFO -   hit_rate@5: 0.035948
2025-12-15 20:17:12 - GraphTrainer - INFO -   ndcg@5: 0.023026
2025-12-15 20:17:12 - GraphTrainer - INFO -   map@5: 0.019071
2025-12-15 20:17:12 - GraphTrainer - INFO -   mrr@5: 0.020003
2025-12-15 20:17:12 - GraphTrainer - INFO -   precision@10: 0.005786
2025-12-15 20:17:12 - GraphTrainer - INFO -   recall@10: 0.054808
2025-12-15 20:17:12 - GraphTrainer - INFO -   hit_rate@10: 0.057650
2025-12-15 20:17:12 - GraphTrainer - INFO -   ndcg@10: 0.029748
2025-12-15 20:17:12 - GraphTrainer - INFO -   map@10: 0.021804
2025-12-15 20:17:12 - GraphTrainer - INFO -   mrr@10: 0.022867
2025-12-15 20:17:12 - GraphTrainer - INFO -   precision@20: 0.004693
2025-12-15 20:17:12 - GraphTrainer - INFO -   recall@20: 0.088768
2025-12-15 20:17:12 - GraphTrainer - INFO -   hit_rate@20: 0.093134
2025-12-15 20:17:12 - GraphTrainer - INFO -   ndcg@20: 0.038341
2025-12-15 20:17:12 - GraphTrainer - INFO -   map@20: 0.024091
2025-12-15 20:17:12 - GraphTrainer - INFO -   mrr@20: 0.025252
2025-12-15 20:17:12 - GraphTrainer - INFO - 第 56 轮训练完成
2025-12-15 20:17:12 - GraphTrainer - INFO - train_loss: 0.209294
2025-12-15 20:17:12 - GraphTrainer - INFO - precision@5: 0.007210
2025-12-15 20:17:12 - GraphTrainer - INFO - recall@5: 0.034139
2025-12-15 20:17:12 - GraphTrainer - INFO - hit_rate@5: 0.035948
2025-12-15 20:17:12 - GraphTrainer - INFO - ndcg@5: 0.023026
2025-12-15 20:17:12 - GraphTrainer - INFO - map@5: 0.019071
2025-12-15 20:17:12 - GraphTrainer - INFO - mrr@5: 0.020003
2025-12-15 20:17:12 - GraphTrainer - INFO - precision@10: 0.005786
2025-12-15 20:17:12 - GraphTrainer - INFO - recall@10: 0.054808
2025-12-15 20:17:12 - GraphTrainer - INFO - hit_rate@10: 0.057650
2025-12-15 20:17:12 - GraphTrainer - INFO - ndcg@10: 0.029748
2025-12-15 20:17:12 - GraphTrainer - INFO - map@10: 0.021804
2025-12-15 20:17:12 - GraphTrainer - INFO - mrr@10: 0.022867
2025-12-15 20:17:12 - GraphTrainer - INFO - precision@20: 0.004693
2025-12-15 20:17:12 - GraphTrainer - INFO - recall@20: 0.088768
2025-12-15 20:17:12 - GraphTrainer - INFO - hit_rate@20: 0.093134
2025-12-15 20:17:12 - GraphTrainer - INFO - ndcg@20: 0.038341
2025-12-15 20:17:12 - GraphTrainer - INFO - map@20: 0.024091
2025-12-15 20:17:12 - GraphTrainer - INFO - mrr@20: 0.025252
2025-12-15 20:17:12 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:17:12 - GraphTrainer - INFO - ============================================================
2025-12-15 20:17:12 - GraphTrainer - INFO - 开始第 57/1000 轮训练
2025-12-15 20:17:12 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1984, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2299, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.1994, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2123, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2073, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2109, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2094, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2153, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2065, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2025, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2113, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2229, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2206, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2034, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2216, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2057, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2054, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2221, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2130, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2241, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2209, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2093, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.1972, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2110, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2003, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2019, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2156, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2196, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.1865, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2099, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.1988, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2219, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.1941, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2032, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2120, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2056, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2057, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2115, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.1973, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2136, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2299, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2174, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.1971, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2385, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2070, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.1877, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2126, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.1899, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1996, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2021, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2303, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2094, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2079, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2069, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2144, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.1981, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2110, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2012, device='cuda:0', grad_fn=<AddBackward0>)
The 56 training average loss: 0.20929357229635634
2025-12-15 20:17:20 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:17:20 - GraphTrainer - INFO -   precision@5: 0.007262
2025-12-15 20:17:20 - GraphTrainer - INFO -   recall@5: 0.034502
2025-12-15 20:17:20 - GraphTrainer - INFO -   hit_rate@5: 0.036256
2025-12-15 20:17:20 - GraphTrainer - INFO -   ndcg@5: 0.023524
2025-12-15 20:17:20 - GraphTrainer - INFO -   map@5: 0.019604
2025-12-15 20:17:20 - GraphTrainer - INFO -   mrr@5: 0.020511
2025-12-15 20:17:20 - GraphTrainer - INFO -   precision@10: 0.005883
2025-12-15 20:17:20 - GraphTrainer - INFO -   recall@10: 0.055755
2025-12-15 20:17:20 - GraphTrainer - INFO -   hit_rate@10: 0.058678
2025-12-15 20:17:20 - GraphTrainer - INFO -   ndcg@10: 0.030410
2025-12-15 20:17:20 - GraphTrainer - INFO -   map@10: 0.022381
2025-12-15 20:17:20 - GraphTrainer - INFO -   mrr@10: 0.023439
2025-12-15 20:17:20 - GraphTrainer - INFO -   precision@20: 0.004649
2025-12-15 20:17:20 - GraphTrainer - INFO -   recall@20: 0.088225
2025-12-15 20:17:20 - GraphTrainer - INFO -   hit_rate@20: 0.092415
2025-12-15 20:17:20 - GraphTrainer - INFO -   ndcg@20: 0.038640
2025-12-15 20:17:20 - GraphTrainer - INFO -   map@20: 0.024589
2025-12-15 20:17:20 - GraphTrainer - INFO -   mrr@20: 0.025728
2025-12-15 20:17:20 - GraphTrainer - INFO - 第 57 轮训练完成
2025-12-15 20:17:20 - GraphTrainer - INFO - train_loss: 0.204760
2025-12-15 20:17:20 - GraphTrainer - INFO - precision@5: 0.007262
2025-12-15 20:17:20 - GraphTrainer - INFO - recall@5: 0.034502
2025-12-15 20:17:20 - GraphTrainer - INFO - hit_rate@5: 0.036256
2025-12-15 20:17:20 - GraphTrainer - INFO - ndcg@5: 0.023524
2025-12-15 20:17:20 - GraphTrainer - INFO - map@5: 0.019604
2025-12-15 20:17:20 - GraphTrainer - INFO - mrr@5: 0.020511
2025-12-15 20:17:20 - GraphTrainer - INFO - precision@10: 0.005883
2025-12-15 20:17:20 - GraphTrainer - INFO - recall@10: 0.055755
2025-12-15 20:17:20 - GraphTrainer - INFO - hit_rate@10: 0.058678
2025-12-15 20:17:20 - GraphTrainer - INFO - ndcg@10: 0.030410
2025-12-15 20:17:20 - GraphTrainer - INFO - map@10: 0.022381
2025-12-15 20:17:20 - GraphTrainer - INFO - mrr@10: 0.023439
2025-12-15 20:17:20 - GraphTrainer - INFO - precision@20: 0.004649
2025-12-15 20:17:20 - GraphTrainer - INFO - recall@20: 0.088225
2025-12-15 20:17:20 - GraphTrainer - INFO - hit_rate@20: 0.092415
2025-12-15 20:17:20 - GraphTrainer - INFO - ndcg@20: 0.038640
2025-12-15 20:17:20 - GraphTrainer - INFO - map@20: 0.024589
2025-12-15 20:17:20 - GraphTrainer - INFO - mrr@20: 0.025728
2025-12-15 20:17:20 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:17:20 - GraphTrainer - INFO - ============================================================
2025-12-15 20:17:20 - GraphTrainer - INFO - 开始第 58/1000 轮训练
2025-12-15 20:17:20 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1918, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.1911, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.1984, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2098, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2001, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2162, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.1940, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2080, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2019, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2051, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1959, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2093, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1863, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.1817, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.1973, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1994, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2184, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2066, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2013, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2144, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2003, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1971, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2173, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2020, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2064, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2360, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.1959, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2040, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2145, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2089, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2336, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2181, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2007, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2156, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1953, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2107, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2119, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2077, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.1881, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2180, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2012, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2139, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2019, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2152, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2102, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2076, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.1845, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2225, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1985, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.1901, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.1942, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.1976, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2122, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2031, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1979, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2053, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2065, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2049, device='cuda:0', grad_fn=<AddBackward0>)
The 57 training average loss: 0.20475959649373746
2025-12-15 20:17:28 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:17:28 - GraphTrainer - INFO -   precision@5: 0.007364
2025-12-15 20:17:28 - GraphTrainer - INFO -   recall@5: 0.034888
2025-12-15 20:17:28 - GraphTrainer - INFO -   hit_rate@5: 0.036668
2025-12-15 20:17:28 - GraphTrainer - INFO -   ndcg@5: 0.023472
2025-12-15 20:17:28 - GraphTrainer - INFO -   map@5: 0.019423
2025-12-15 20:17:28 - GraphTrainer - INFO -   mrr@5: 0.020303
2025-12-15 20:17:28 - GraphTrainer - INFO -   precision@10: 0.005775
2025-12-15 20:17:28 - GraphTrainer - INFO -   recall@10: 0.054757
2025-12-15 20:17:28 - GraphTrainer - INFO -   hit_rate@10: 0.057598
2025-12-15 20:17:28 - GraphTrainer - INFO -   ndcg@10: 0.029912
2025-12-15 20:17:28 - GraphTrainer - INFO -   map@10: 0.022027
2025-12-15 20:17:28 - GraphTrainer - INFO -   mrr@10: 0.023044
2025-12-15 20:17:28 - GraphTrainer - INFO -   precision@20: 0.004616
2025-12-15 20:17:28 - GraphTrainer - INFO -   recall@20: 0.087287
2025-12-15 20:17:28 - GraphTrainer - INFO -   hit_rate@20: 0.091797
2025-12-15 20:17:28 - GraphTrainer - INFO -   ndcg@20: 0.038159
2025-12-15 20:17:28 - GraphTrainer - INFO -   map@20: 0.024226
2025-12-15 20:17:28 - GraphTrainer - INFO -   mrr@20: 0.025351
2025-12-15 20:17:28 - GraphTrainer - INFO - 第 58 轮训练完成
2025-12-15 20:17:28 - GraphTrainer - INFO - train_loss: 0.205702
2025-12-15 20:17:28 - GraphTrainer - INFO - precision@5: 0.007364
2025-12-15 20:17:28 - GraphTrainer - INFO - recall@5: 0.034888
2025-12-15 20:17:28 - GraphTrainer - INFO - hit_rate@5: 0.036668
2025-12-15 20:17:28 - GraphTrainer - INFO - ndcg@5: 0.023472
2025-12-15 20:17:28 - GraphTrainer - INFO - map@5: 0.019423
2025-12-15 20:17:28 - GraphTrainer - INFO - mrr@5: 0.020303
2025-12-15 20:17:28 - GraphTrainer - INFO - precision@10: 0.005775
2025-12-15 20:17:28 - GraphTrainer - INFO - recall@10: 0.054757
2025-12-15 20:17:28 - GraphTrainer - INFO - hit_rate@10: 0.057598
2025-12-15 20:17:28 - GraphTrainer - INFO - ndcg@10: 0.029912
2025-12-15 20:17:28 - GraphTrainer - INFO - map@10: 0.022027
2025-12-15 20:17:28 - GraphTrainer - INFO - mrr@10: 0.023044
2025-12-15 20:17:28 - GraphTrainer - INFO - precision@20: 0.004616
2025-12-15 20:17:28 - GraphTrainer - INFO - recall@20: 0.087287
2025-12-15 20:17:28 - GraphTrainer - INFO - hit_rate@20: 0.091797
2025-12-15 20:17:28 - GraphTrainer - INFO - ndcg@20: 0.038159
2025-12-15 20:17:28 - GraphTrainer - INFO - map@20: 0.024226
2025-12-15 20:17:28 - GraphTrainer - INFO - mrr@20: 0.025351
2025-12-15 20:17:28 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:17:28 - GraphTrainer - INFO - ============================================================
2025-12-15 20:17:28 - GraphTrainer - INFO - 开始第 59/1000 轮训练
2025-12-15 20:17:28 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1894, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2126, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2222, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2057, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2026, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.1942, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.1996, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2033, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2041, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2070, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1918, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2037, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1933, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2135, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2251, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2049, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2265, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2245, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2001, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2187, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2029, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2191, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.1876, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.1982, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2165, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.1957, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2049, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2012, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2193, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.1964, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.1963, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2252, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.1775, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2198, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1986, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2050, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1911, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2121, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2178, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2146, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1969, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.1914, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2047, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2177, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2123, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2039, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.1883, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2051, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1967, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2009, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2026, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2449, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2126, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1945, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2072, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.1876, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2038, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2171, device='cuda:0', grad_fn=<AddBackward0>)
The 58 training average loss: 0.2057015335765378
2025-12-15 20:17:36 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:17:36 - GraphTrainer - INFO -   precision@5: 0.007046
2025-12-15 20:17:36 - GraphTrainer - INFO -   recall@5: 0.033376
2025-12-15 20:17:36 - GraphTrainer - INFO -   hit_rate@5: 0.035228
2025-12-15 20:17:36 - GraphTrainer - INFO -   ndcg@5: 0.022847
2025-12-15 20:17:36 - GraphTrainer - INFO -   map@5: 0.019084
2025-12-15 20:17:36 - GraphTrainer - INFO -   mrr@5: 0.020034
2025-12-15 20:17:36 - GraphTrainer - INFO -   precision@10: 0.005837
2025-12-15 20:17:36 - GraphTrainer - INFO -   recall@10: 0.054949
2025-12-15 20:17:36 - GraphTrainer - INFO -   hit_rate@10: 0.058267
2025-12-15 20:17:36 - GraphTrainer - INFO -   ndcg@10: 0.029869
2025-12-15 20:17:36 - GraphTrainer - INFO -   map@10: 0.021916
2025-12-15 20:17:36 - GraphTrainer - INFO -   mrr@10: 0.023054
2025-12-15 20:17:36 - GraphTrainer - INFO -   precision@20: 0.004664
2025-12-15 20:17:36 - GraphTrainer - INFO -   recall@20: 0.088328
2025-12-15 20:17:36 - GraphTrainer - INFO -   hit_rate@20: 0.092620
2025-12-15 20:17:36 - GraphTrainer - INFO -   ndcg@20: 0.038305
2025-12-15 20:17:36 - GraphTrainer - INFO -   map@20: 0.024177
2025-12-15 20:17:36 - GraphTrainer - INFO -   mrr@20: 0.025367
2025-12-15 20:17:36 - GraphTrainer - INFO - 第 59 轮训练完成
2025-12-15 20:17:36 - GraphTrainer - INFO - train_loss: 0.204813
2025-12-15 20:17:36 - GraphTrainer - INFO - precision@5: 0.007046
2025-12-15 20:17:36 - GraphTrainer - INFO - recall@5: 0.033376
2025-12-15 20:17:36 - GraphTrainer - INFO - hit_rate@5: 0.035228
2025-12-15 20:17:36 - GraphTrainer - INFO - ndcg@5: 0.022847
2025-12-15 20:17:36 - GraphTrainer - INFO - map@5: 0.019084
2025-12-15 20:17:36 - GraphTrainer - INFO - mrr@5: 0.020034
2025-12-15 20:17:36 - GraphTrainer - INFO - precision@10: 0.005837
2025-12-15 20:17:36 - GraphTrainer - INFO - recall@10: 0.054949
2025-12-15 20:17:36 - GraphTrainer - INFO - hit_rate@10: 0.058267
2025-12-15 20:17:36 - GraphTrainer - INFO - ndcg@10: 0.029869
2025-12-15 20:17:36 - GraphTrainer - INFO - map@10: 0.021916
2025-12-15 20:17:36 - GraphTrainer - INFO - mrr@10: 0.023054
2025-12-15 20:17:36 - GraphTrainer - INFO - precision@20: 0.004664
2025-12-15 20:17:36 - GraphTrainer - INFO - recall@20: 0.088328
2025-12-15 20:17:36 - GraphTrainer - INFO - hit_rate@20: 0.092620
2025-12-15 20:17:36 - GraphTrainer - INFO - ndcg@20: 0.038305
2025-12-15 20:17:36 - GraphTrainer - INFO - map@20: 0.024177
2025-12-15 20:17:36 - GraphTrainer - INFO - mrr@20: 0.025367
2025-12-15 20:17:36 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:17:36 - GraphTrainer - INFO - ============================================================
2025-12-15 20:17:36 - GraphTrainer - INFO - 开始第 60/1000 轮训练
2025-12-15 20:17:36 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2033, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2086, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2131, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2213, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2076, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2007, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2033, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2176, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2031, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2049, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1964, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.1963, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2293, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2084, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.1872, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1765, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2052, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1994, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.1927, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.1888, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2151, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1984, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2389, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2003, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2009, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.1946, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2252, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2148, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2052, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.1851, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2299, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2190, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.1998, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1922, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2136, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2196, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2061, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2046, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.1997, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2007, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2021, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.1940, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2099, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2075, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2072, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2021, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.1972, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2056, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2074, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.1998, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2000, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2005, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2091, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2133, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2037, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2194, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.1866, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.1863, device='cuda:0', grad_fn=<AddBackward0>)
The 59 training average loss: 0.20481270757214776
2025-12-15 20:17:44 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:17:44 - GraphTrainer - INFO -   precision@5: 0.007251
2025-12-15 20:17:44 - GraphTrainer - INFO -   recall@5: 0.034357
2025-12-15 20:17:44 - GraphTrainer - INFO -   hit_rate@5: 0.036256
2025-12-15 20:17:44 - GraphTrainer - INFO -   ndcg@5: 0.023451
2025-12-15 20:17:44 - GraphTrainer - INFO -   map@5: 0.019545
2025-12-15 20:17:44 - GraphTrainer - INFO -   mrr@5: 0.020527
2025-12-15 20:17:44 - GraphTrainer - INFO -   precision@10: 0.006104
2025-12-15 20:17:44 - GraphTrainer - INFO -   recall@10: 0.057773
2025-12-15 20:17:44 - GraphTrainer - INFO -   hit_rate@10: 0.060941
2025-12-15 20:17:44 - GraphTrainer - INFO -   ndcg@10: 0.031062
2025-12-15 20:17:44 - GraphTrainer - INFO -   map@10: 0.022630
2025-12-15 20:17:44 - GraphTrainer - INFO -   mrr@10: 0.023771
2025-12-15 20:17:44 - GraphTrainer - INFO -   precision@20: 0.004600
2025-12-15 20:17:44 - GraphTrainer - INFO -   recall@20: 0.087156
2025-12-15 20:17:44 - GraphTrainer - INFO -   hit_rate@20: 0.091540
2025-12-15 20:17:44 - GraphTrainer - INFO -   ndcg@20: 0.038501
2025-12-15 20:17:44 - GraphTrainer - INFO -   map@20: 0.024616
2025-12-15 20:17:44 - GraphTrainer - INFO -   mrr@20: 0.025835
2025-12-15 20:17:44 - GraphTrainer - INFO - 第 60 轮训练完成
2025-12-15 20:17:44 - GraphTrainer - INFO - train_loss: 0.202239
2025-12-15 20:17:44 - GraphTrainer - INFO - precision@5: 0.007251
2025-12-15 20:17:44 - GraphTrainer - INFO - recall@5: 0.034357
2025-12-15 20:17:44 - GraphTrainer - INFO - hit_rate@5: 0.036256
2025-12-15 20:17:44 - GraphTrainer - INFO - ndcg@5: 0.023451
2025-12-15 20:17:44 - GraphTrainer - INFO - map@5: 0.019545
2025-12-15 20:17:44 - GraphTrainer - INFO - mrr@5: 0.020527
2025-12-15 20:17:44 - GraphTrainer - INFO - precision@10: 0.006104
2025-12-15 20:17:44 - GraphTrainer - INFO - recall@10: 0.057773
2025-12-15 20:17:44 - GraphTrainer - INFO - hit_rate@10: 0.060941
2025-12-15 20:17:44 - GraphTrainer - INFO - ndcg@10: 0.031062
2025-12-15 20:17:44 - GraphTrainer - INFO - map@10: 0.022630
2025-12-15 20:17:44 - GraphTrainer - INFO - mrr@10: 0.023771
2025-12-15 20:17:44 - GraphTrainer - INFO - precision@20: 0.004600
2025-12-15 20:17:44 - GraphTrainer - INFO - recall@20: 0.087156
2025-12-15 20:17:44 - GraphTrainer - INFO - hit_rate@20: 0.091540
2025-12-15 20:17:44 - GraphTrainer - INFO - ndcg@20: 0.038501
2025-12-15 20:17:44 - GraphTrainer - INFO - map@20: 0.024616
2025-12-15 20:17:44 - GraphTrainer - INFO - mrr@20: 0.025835
2025-12-15 20:17:44 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:17:44 - GraphTrainer - INFO - 检查点已保存: Epoch 60 -> ./checkpoints/checkpoint_epoch_60.pth
2025-12-15 20:17:44 - GraphTrainer - INFO - ============================================================
2025-12-15 20:17:44 - GraphTrainer - INFO - 开始第 61/1000 轮训练
2025-12-15 20:17:44 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1901, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2028, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2143, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.1764, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1830, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2082, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2055, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2146, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1955, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2146, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2003, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2089, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2016, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.1962, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2022, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2025, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1990, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2166, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2007, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2175, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2066, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2066, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.1867, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.1936, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.1920, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.1915, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.1955, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2073, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2136, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.1863, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.1866, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2031, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2107, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2196, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1834, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2038, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2154, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2041, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.1986, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2080, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2161, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.1868, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2269, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.1916, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.1939, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2040, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.1950, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.1998, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1951, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2246, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2181, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.1948, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2115, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2127, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2035, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2051, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2069, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.1801, device='cuda:0', grad_fn=<AddBackward0>)
The 60 training average loss: 0.2022389946826573
2025-12-15 20:17:53 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:17:53 - GraphTrainer - INFO -   precision@5: 0.007519
2025-12-15 20:17:53 - GraphTrainer - INFO -   recall@5: 0.035710
2025-12-15 20:17:53 - GraphTrainer - INFO -   hit_rate@5: 0.037542
2025-12-15 20:17:53 - GraphTrainer - INFO -   ndcg@5: 0.023621
2025-12-15 20:17:53 - GraphTrainer - INFO -   map@5: 0.019336
2025-12-15 20:17:53 - GraphTrainer - INFO -   mrr@5: 0.020287
2025-12-15 20:17:53 - GraphTrainer - INFO -   precision@10: 0.005858
2025-12-15 20:17:53 - GraphTrainer - INFO -   recall@10: 0.055578
2025-12-15 20:17:53 - GraphTrainer - INFO -   hit_rate@10: 0.058421
2025-12-15 20:17:53 - GraphTrainer - INFO -   ndcg@10: 0.030069
2025-12-15 20:17:53 - GraphTrainer - INFO -   map@10: 0.021950
2025-12-15 20:17:53 - GraphTrainer - INFO -   mrr@10: 0.023025
2025-12-15 20:17:53 - GraphTrainer - INFO -   precision@20: 0.004595
2025-12-15 20:17:53 - GraphTrainer - INFO -   recall@20: 0.087112
2025-12-15 20:17:53 - GraphTrainer - INFO -   hit_rate@20: 0.091437
2025-12-15 20:17:53 - GraphTrainer - INFO -   ndcg@20: 0.038068
2025-12-15 20:17:53 - GraphTrainer - INFO -   map@20: 0.024089
2025-12-15 20:17:53 - GraphTrainer - INFO -   mrr@20: 0.025261
2025-12-15 20:17:53 - GraphTrainer - INFO - 第 61 轮训练完成
2025-12-15 20:17:53 - GraphTrainer - INFO - train_loss: 0.202597
2025-12-15 20:17:53 - GraphTrainer - INFO - precision@5: 0.007519
2025-12-15 20:17:53 - GraphTrainer - INFO - recall@5: 0.035710
2025-12-15 20:17:53 - GraphTrainer - INFO - hit_rate@5: 0.037542
2025-12-15 20:17:53 - GraphTrainer - INFO - ndcg@5: 0.023621
2025-12-15 20:17:53 - GraphTrainer - INFO - map@5: 0.019336
2025-12-15 20:17:53 - GraphTrainer - INFO - mrr@5: 0.020287
2025-12-15 20:17:53 - GraphTrainer - INFO - precision@10: 0.005858
2025-12-15 20:17:53 - GraphTrainer - INFO - recall@10: 0.055578
2025-12-15 20:17:53 - GraphTrainer - INFO - hit_rate@10: 0.058421
2025-12-15 20:17:53 - GraphTrainer - INFO - ndcg@10: 0.030069
2025-12-15 20:17:53 - GraphTrainer - INFO - map@10: 0.021950
2025-12-15 20:17:53 - GraphTrainer - INFO - mrr@10: 0.023025
2025-12-15 20:17:53 - GraphTrainer - INFO - precision@20: 0.004595
2025-12-15 20:17:53 - GraphTrainer - INFO - recall@20: 0.087112
2025-12-15 20:17:53 - GraphTrainer - INFO - hit_rate@20: 0.091437
2025-12-15 20:17:53 - GraphTrainer - INFO - ndcg@20: 0.038068
2025-12-15 20:17:53 - GraphTrainer - INFO - map@20: 0.024089
2025-12-15 20:17:53 - GraphTrainer - INFO - mrr@20: 0.025261
2025-12-15 20:17:53 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:17:53 - GraphTrainer - INFO - ============================================================
2025-12-15 20:17:53 - GraphTrainer - INFO - 开始第 62/1000 轮训练
2025-12-15 20:17:53 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1864, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2038, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.1929, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2009, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2181, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2117, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2114, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.1970, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2168, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2120, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2144, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.1926, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1958, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.1926, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.1931, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1928, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2169, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2178, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.1818, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.1831, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1924, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2154, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.1915, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2052, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2189, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2140, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2142, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2112, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2057, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.1935, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2005, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.1926, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.1966, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2178, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1893, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1878, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1889, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.1917, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2122, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2072, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2102, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.1997, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.1858, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2089, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2096, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.1964, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2137, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2181, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1983, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2269, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2061, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.1824, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.1917, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2039, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2191, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.1907, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2346, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.1764, device='cuda:0', grad_fn=<AddBackward0>)
The 61 training average loss: 0.2025974107713535
2025-12-15 20:18:01 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:18:01 - GraphTrainer - INFO -   precision@5: 0.007395
2025-12-15 20:18:01 - GraphTrainer - INFO -   recall@5: 0.035119
2025-12-15 20:18:01 - GraphTrainer - INFO -   hit_rate@5: 0.036925
2025-12-15 20:18:01 - GraphTrainer - INFO -   ndcg@5: 0.023250
2025-12-15 20:18:01 - GraphTrainer - INFO -   map@5: 0.019054
2025-12-15 20:18:01 - GraphTrainer - INFO -   mrr@5: 0.019979
2025-12-15 20:18:01 - GraphTrainer - INFO -   precision@10: 0.005822
2025-12-15 20:18:01 - GraphTrainer - INFO -   recall@10: 0.055190
2025-12-15 20:18:01 - GraphTrainer - INFO -   hit_rate@10: 0.058113
2025-12-15 20:18:01 - GraphTrainer - INFO -   ndcg@10: 0.029761
2025-12-15 20:18:01 - GraphTrainer - INFO -   map@10: 0.021685
2025-12-15 20:18:01 - GraphTrainer - INFO -   mrr@10: 0.022755
2025-12-15 20:18:01 - GraphTrainer - INFO -   precision@20: 0.004608
2025-12-15 20:18:01 - GraphTrainer - INFO -   recall@20: 0.087366
2025-12-15 20:18:01 - GraphTrainer - INFO -   hit_rate@20: 0.091643
2025-12-15 20:18:01 - GraphTrainer - INFO -   ndcg@20: 0.037938
2025-12-15 20:18:01 - GraphTrainer - INFO -   map@20: 0.023884
2025-12-15 20:18:01 - GraphTrainer - INFO -   mrr@20: 0.025044
2025-12-15 20:18:01 - GraphTrainer - INFO - 第 62 轮训练完成
2025-12-15 20:18:01 - GraphTrainer - INFO - train_loss: 0.201493
2025-12-15 20:18:01 - GraphTrainer - INFO - precision@5: 0.007395
2025-12-15 20:18:01 - GraphTrainer - INFO - recall@5: 0.035119
2025-12-15 20:18:01 - GraphTrainer - INFO - hit_rate@5: 0.036925
2025-12-15 20:18:01 - GraphTrainer - INFO - ndcg@5: 0.023250
2025-12-15 20:18:01 - GraphTrainer - INFO - map@5: 0.019054
2025-12-15 20:18:01 - GraphTrainer - INFO - mrr@5: 0.019979
2025-12-15 20:18:01 - GraphTrainer - INFO - precision@10: 0.005822
2025-12-15 20:18:01 - GraphTrainer - INFO - recall@10: 0.055190
2025-12-15 20:18:01 - GraphTrainer - INFO - hit_rate@10: 0.058113
2025-12-15 20:18:01 - GraphTrainer - INFO - ndcg@10: 0.029761
2025-12-15 20:18:01 - GraphTrainer - INFO - map@10: 0.021685
2025-12-15 20:18:01 - GraphTrainer - INFO - mrr@10: 0.022755
2025-12-15 20:18:01 - GraphTrainer - INFO - precision@20: 0.004608
2025-12-15 20:18:01 - GraphTrainer - INFO - recall@20: 0.087366
2025-12-15 20:18:01 - GraphTrainer - INFO - hit_rate@20: 0.091643
2025-12-15 20:18:01 - GraphTrainer - INFO - ndcg@20: 0.037938
2025-12-15 20:18:01 - GraphTrainer - INFO - map@20: 0.023884
2025-12-15 20:18:01 - GraphTrainer - INFO - mrr@20: 0.025044
2025-12-15 20:18:01 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:18:01 - GraphTrainer - INFO - ============================================================
2025-12-15 20:18:01 - GraphTrainer - INFO - 开始第 63/1000 轮训练
2025-12-15 20:18:01 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2066, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2070, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2107, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2189, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2024, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.1852, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2174, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2057, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1836, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2035, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1738, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2021, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2027, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2089, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2103, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2269, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1952, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1940, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2099, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.1922, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2189, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2045, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.1993, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2281, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2012, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.1913, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2029, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2031, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2164, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.1967, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2013, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.1952, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.1904, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1960, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2122, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1901, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1876, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2054, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2074, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2045, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1963, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.1996, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.1914, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.1862, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.1950, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2063, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2107, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.1861, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1993, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.1940, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.1953, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2145, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.1965, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1983, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1891, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2130, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.1946, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2109, device='cuda:0', grad_fn=<AddBackward0>)
The 62 training average loss: 0.20149296008307357
2025-12-15 20:18:09 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:18:09 - GraphTrainer - INFO -   precision@5: 0.007179
2025-12-15 20:18:09 - GraphTrainer - INFO -   recall@5: 0.034104
2025-12-15 20:18:09 - GraphTrainer - INFO -   hit_rate@5: 0.035845
2025-12-15 20:18:09 - GraphTrainer - INFO -   ndcg@5: 0.022644
2025-12-15 20:18:09 - GraphTrainer - INFO -   map@5: 0.018571
2025-12-15 20:18:09 - GraphTrainer - INFO -   mrr@5: 0.019537
2025-12-15 20:18:09 - GraphTrainer - INFO -   precision@10: 0.005816
2025-12-15 20:18:09 - GraphTrainer - INFO -   recall@10: 0.055095
2025-12-15 20:18:09 - GraphTrainer - INFO -   hit_rate@10: 0.058010
2025-12-15 20:18:09 - GraphTrainer - INFO -   ndcg@10: 0.029452
2025-12-15 20:18:09 - GraphTrainer - INFO -   map@10: 0.021321
2025-12-15 20:18:09 - GraphTrainer - INFO -   mrr@10: 0.022436
2025-12-15 20:18:09 - GraphTrainer - INFO -   precision@20: 0.004649
2025-12-15 20:18:09 - GraphTrainer - INFO -   recall@20: 0.088108
2025-12-15 20:18:09 - GraphTrainer - INFO -   hit_rate@20: 0.092517
2025-12-15 20:18:09 - GraphTrainer - INFO -   ndcg@20: 0.037834
2025-12-15 20:18:09 - GraphTrainer - INFO -   map@20: 0.023570
2025-12-15 20:18:09 - GraphTrainer - INFO -   mrr@20: 0.024783
2025-12-15 20:18:09 - GraphTrainer - INFO - 第 63 轮训练完成
2025-12-15 20:18:09 - GraphTrainer - INFO - train_loss: 0.201120
2025-12-15 20:18:09 - GraphTrainer - INFO - precision@5: 0.007179
2025-12-15 20:18:09 - GraphTrainer - INFO - recall@5: 0.034104
2025-12-15 20:18:09 - GraphTrainer - INFO - hit_rate@5: 0.035845
2025-12-15 20:18:09 - GraphTrainer - INFO - ndcg@5: 0.022644
2025-12-15 20:18:09 - GraphTrainer - INFO - map@5: 0.018571
2025-12-15 20:18:09 - GraphTrainer - INFO - mrr@5: 0.019537
2025-12-15 20:18:09 - GraphTrainer - INFO - precision@10: 0.005816
2025-12-15 20:18:09 - GraphTrainer - INFO - recall@10: 0.055095
2025-12-15 20:18:09 - GraphTrainer - INFO - hit_rate@10: 0.058010
2025-12-15 20:18:09 - GraphTrainer - INFO - ndcg@10: 0.029452
2025-12-15 20:18:09 - GraphTrainer - INFO - map@10: 0.021321
2025-12-15 20:18:09 - GraphTrainer - INFO - mrr@10: 0.022436
2025-12-15 20:18:09 - GraphTrainer - INFO - precision@20: 0.004649
2025-12-15 20:18:09 - GraphTrainer - INFO - recall@20: 0.088108
2025-12-15 20:18:09 - GraphTrainer - INFO - hit_rate@20: 0.092517
2025-12-15 20:18:09 - GraphTrainer - INFO - ndcg@20: 0.037834
2025-12-15 20:18:09 - GraphTrainer - INFO - map@20: 0.023570
2025-12-15 20:18:09 - GraphTrainer - INFO - mrr@20: 0.024783
2025-12-15 20:18:09 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:18:09 - GraphTrainer - INFO - ============================================================
2025-12-15 20:18:09 - GraphTrainer - INFO - 开始第 64/1000 轮训练
2025-12-15 20:18:09 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1926, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.1823, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2069, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.1941, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2152, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2021, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2058, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2206, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2223, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2187, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2153, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.1935, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2066, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2005, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.1984, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1860, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2145, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1981, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.1959, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.1979, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2112, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2205, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.1982, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.1805, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.1945, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.1864, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.1920, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.1837, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.1918, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.1977, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.1979, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2237, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.1968, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1991, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1892, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1944, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2124, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.2090, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.1892, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2076, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1946, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2031, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2123, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.1905, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2026, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2128, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2020, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.1859, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1976, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2060, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.1967, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.1936, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2074, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2137, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2027, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.1787, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.1895, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2324, device='cuda:0', grad_fn=<AddBackward0>)
The 63 training average loss: 0.20111998427530814
2025-12-15 20:18:17 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:18:17 - GraphTrainer - INFO -   precision@5: 0.007395
2025-12-15 20:18:17 - GraphTrainer - INFO -   recall@5: 0.035132
2025-12-15 20:18:17 - GraphTrainer - INFO -   hit_rate@5: 0.036976
2025-12-15 20:18:17 - GraphTrainer - INFO -   ndcg@5: 0.023839
2025-12-15 20:18:17 - GraphTrainer - INFO -   map@5: 0.019822
2025-12-15 20:18:17 - GraphTrainer - INFO -   mrr@5: 0.020769
2025-12-15 20:18:17 - GraphTrainer - INFO -   precision@10: 0.005842
2025-12-15 20:18:17 - GraphTrainer - INFO -   recall@10: 0.055359
2025-12-15 20:18:17 - GraphTrainer - INFO -   hit_rate@10: 0.058215
2025-12-15 20:18:17 - GraphTrainer - INFO -   ndcg@10: 0.030389
2025-12-15 20:18:17 - GraphTrainer - INFO -   map@10: 0.022469
2025-12-15 20:18:17 - GraphTrainer - INFO -   mrr@10: 0.023542
2025-12-15 20:18:17 - GraphTrainer - INFO -   precision@20: 0.004652
2025-12-15 20:18:17 - GraphTrainer - INFO -   recall@20: 0.087994
2025-12-15 20:18:17 - GraphTrainer - INFO -   hit_rate@20: 0.092466
2025-12-15 20:18:17 - GraphTrainer - INFO -   ndcg@20: 0.038712
2025-12-15 20:18:17 - GraphTrainer - INFO -   map@20: 0.024713
2025-12-15 20:18:17 - GraphTrainer - INFO -   mrr@20: 0.025893
2025-12-15 20:18:17 - GraphTrainer - INFO - 第 64 轮训练完成
2025-12-15 20:18:17 - GraphTrainer - INFO - train_loss: 0.202771
2025-12-15 20:18:17 - GraphTrainer - INFO - precision@5: 0.007395
2025-12-15 20:18:17 - GraphTrainer - INFO - recall@5: 0.035132
2025-12-15 20:18:17 - GraphTrainer - INFO - hit_rate@5: 0.036976
2025-12-15 20:18:17 - GraphTrainer - INFO - ndcg@5: 0.023839
2025-12-15 20:18:17 - GraphTrainer - INFO - map@5: 0.019822
2025-12-15 20:18:17 - GraphTrainer - INFO - mrr@5: 0.020769
2025-12-15 20:18:17 - GraphTrainer - INFO - precision@10: 0.005842
2025-12-15 20:18:17 - GraphTrainer - INFO - recall@10: 0.055359
2025-12-15 20:18:17 - GraphTrainer - INFO - hit_rate@10: 0.058215
2025-12-15 20:18:17 - GraphTrainer - INFO - ndcg@10: 0.030389
2025-12-15 20:18:17 - GraphTrainer - INFO - map@10: 0.022469
2025-12-15 20:18:17 - GraphTrainer - INFO - mrr@10: 0.023542
2025-12-15 20:18:17 - GraphTrainer - INFO - precision@20: 0.004652
2025-12-15 20:18:17 - GraphTrainer - INFO - recall@20: 0.087994
2025-12-15 20:18:17 - GraphTrainer - INFO - hit_rate@20: 0.092466
2025-12-15 20:18:17 - GraphTrainer - INFO - ndcg@20: 0.038712
2025-12-15 20:18:17 - GraphTrainer - INFO - map@20: 0.024713
2025-12-15 20:18:17 - GraphTrainer - INFO - mrr@20: 0.025893
2025-12-15 20:18:17 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:18:17 - GraphTrainer - INFO - ============================================================
2025-12-15 20:18:17 - GraphTrainer - INFO - 开始第 65/1000 轮训练
2025-12-15 20:18:17 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2057, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.1905, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2042, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2028, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2095, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.1937, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.1971, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.1988, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2117, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2072, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.2024, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2008, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1786, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2053, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2127, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.2053, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2183, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1893, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2266, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2138, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1999, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1911, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2055, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.1993, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.1879, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2066, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.1962, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.1914, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2306, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.1959, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2098, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.1912, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2049, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1844, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2217, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1962, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1884, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.1959, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2134, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2047, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1920, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2159, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.1992, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.1982, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2016, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2164, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2178, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.1908, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2220, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2074, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.1943, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2174, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.1944, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1923, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2101, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.1947, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2030, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2041, device='cuda:0', grad_fn=<AddBackward0>)
The 64 training average loss: 0.2027711264532188
2025-12-15 20:18:26 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:18:26 - GraphTrainer - INFO -   precision@5: 0.007539
2025-12-15 20:18:26 - GraphTrainer - INFO -   recall@5: 0.035688
2025-12-15 20:18:26 - GraphTrainer - INFO -   hit_rate@5: 0.037645
2025-12-15 20:18:26 - GraphTrainer - INFO -   ndcg@5: 0.023846
2025-12-15 20:18:26 - GraphTrainer - INFO -   map@5: 0.019653
2025-12-15 20:18:26 - GraphTrainer - INFO -   mrr@5: 0.020591
2025-12-15 20:18:26 - GraphTrainer - INFO -   precision@10: 0.005822
2025-12-15 20:18:26 - GraphTrainer - INFO -   recall@10: 0.055228
2025-12-15 20:18:26 - GraphTrainer - INFO -   hit_rate@10: 0.058113
2025-12-15 20:18:26 - GraphTrainer - INFO -   ndcg@10: 0.030138
2025-12-15 20:18:26 - GraphTrainer - INFO -   map@10: 0.022180
2025-12-15 20:18:26 - GraphTrainer - INFO -   mrr@10: 0.023233
2025-12-15 20:18:26 - GraphTrainer - INFO -   precision@20: 0.004729
2025-12-15 20:18:26 - GraphTrainer - INFO -   recall@20: 0.089486
2025-12-15 20:18:26 - GraphTrainer - INFO -   hit_rate@20: 0.093906
2025-12-15 20:18:26 - GraphTrainer - INFO -   ndcg@20: 0.038815
2025-12-15 20:18:26 - GraphTrainer - INFO -   map@20: 0.024492
2025-12-15 20:18:26 - GraphTrainer - INFO -   mrr@20: 0.025641
2025-12-15 20:18:26 - GraphTrainer - INFO - 第 65 轮训练完成
2025-12-15 20:18:26 - GraphTrainer - INFO - train_loss: 0.198565
2025-12-15 20:18:26 - GraphTrainer - INFO - precision@5: 0.007539
2025-12-15 20:18:26 - GraphTrainer - INFO - recall@5: 0.035688
2025-12-15 20:18:26 - GraphTrainer - INFO - hit_rate@5: 0.037645
2025-12-15 20:18:26 - GraphTrainer - INFO - ndcg@5: 0.023846
2025-12-15 20:18:26 - GraphTrainer - INFO - map@5: 0.019653
2025-12-15 20:18:26 - GraphTrainer - INFO - mrr@5: 0.020591
2025-12-15 20:18:26 - GraphTrainer - INFO - precision@10: 0.005822
2025-12-15 20:18:26 - GraphTrainer - INFO - recall@10: 0.055228
2025-12-15 20:18:26 - GraphTrainer - INFO - hit_rate@10: 0.058113
2025-12-15 20:18:26 - GraphTrainer - INFO - ndcg@10: 0.030138
2025-12-15 20:18:26 - GraphTrainer - INFO - map@10: 0.022180
2025-12-15 20:18:26 - GraphTrainer - INFO - mrr@10: 0.023233
2025-12-15 20:18:26 - GraphTrainer - INFO - precision@20: 0.004729
2025-12-15 20:18:26 - GraphTrainer - INFO - recall@20: 0.089486
2025-12-15 20:18:26 - GraphTrainer - INFO - hit_rate@20: 0.093906
2025-12-15 20:18:26 - GraphTrainer - INFO - ndcg@20: 0.038815
2025-12-15 20:18:26 - GraphTrainer - INFO - map@20: 0.024492
2025-12-15 20:18:26 - GraphTrainer - INFO - mrr@20: 0.025641
2025-12-15 20:18:26 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:18:26 - GraphTrainer - INFO - ============================================================
2025-12-15 20:18:26 - GraphTrainer - INFO - 开始第 66/1000 轮训练
2025-12-15 20:18:26 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2153, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.1922, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.1897, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2014, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2069, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.1937, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2023, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2080, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2123, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2031, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1891, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.1794, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1952, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.1847, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2059, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1893, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2187, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1953, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.1993, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2150, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1791, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1884, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.2024, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.1844, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2103, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.1834, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.1768, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.1947, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2014, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2072, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.1998, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2281, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.1702, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2000, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1859, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1839, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1965, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.1972, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.1944, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2085, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2035, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.1808, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.1932, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2007, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.1953, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2024, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2129, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2150, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1876, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.2210, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2250, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.1957, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2095, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1894, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1998, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.1856, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2063, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2035, device='cuda:0', grad_fn=<AddBackward0>)
The 65 training average loss: 0.19856460572316728
2025-12-15 20:18:34 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:18:34 - GraphTrainer - INFO -   precision@5: 0.007395
2025-12-15 20:18:34 - GraphTrainer - INFO -   recall@5: 0.035080
2025-12-15 20:18:34 - GraphTrainer - INFO -   hit_rate@5: 0.036925
2025-12-15 20:18:34 - GraphTrainer - INFO -   ndcg@5: 0.023368
2025-12-15 20:18:34 - GraphTrainer - INFO -   map@5: 0.019205
2025-12-15 20:18:34 - GraphTrainer - INFO -   mrr@5: 0.020133
2025-12-15 20:18:34 - GraphTrainer - INFO -   precision@10: 0.005914
2025-12-15 20:18:34 - GraphTrainer - INFO -   recall@10: 0.056158
2025-12-15 20:18:34 - GraphTrainer - INFO -   hit_rate@10: 0.058987
2025-12-15 20:18:34 - GraphTrainer - INFO -   ndcg@10: 0.030202
2025-12-15 20:18:34 - GraphTrainer - INFO -   map@10: 0.021977
2025-12-15 20:18:34 - GraphTrainer - INFO -   mrr@10: 0.023027
2025-12-15 20:18:34 - GraphTrainer - INFO -   precision@20: 0.004706
2025-12-15 20:18:34 - GraphTrainer - INFO -   recall@20: 0.089164
2025-12-15 20:18:34 - GraphTrainer - INFO -   hit_rate@20: 0.093546
2025-12-15 20:18:34 - GraphTrainer - INFO -   ndcg@20: 0.038561
2025-12-15 20:18:34 - GraphTrainer - INFO -   map@20: 0.024206
2025-12-15 20:18:34 - GraphTrainer - INFO -   mrr@20: 0.025350
2025-12-15 20:18:34 - GraphTrainer - INFO - 第 66 轮训练完成
2025-12-15 20:18:34 - GraphTrainer - INFO - train_loss: 0.202995
2025-12-15 20:18:34 - GraphTrainer - INFO - precision@5: 0.007395
2025-12-15 20:18:34 - GraphTrainer - INFO - recall@5: 0.035080
2025-12-15 20:18:34 - GraphTrainer - INFO - hit_rate@5: 0.036925
2025-12-15 20:18:34 - GraphTrainer - INFO - ndcg@5: 0.023368
2025-12-15 20:18:34 - GraphTrainer - INFO - map@5: 0.019205
2025-12-15 20:18:34 - GraphTrainer - INFO - mrr@5: 0.020133
2025-12-15 20:18:34 - GraphTrainer - INFO - precision@10: 0.005914
2025-12-15 20:18:34 - GraphTrainer - INFO - recall@10: 0.056158
2025-12-15 20:18:34 - GraphTrainer - INFO - hit_rate@10: 0.058987
2025-12-15 20:18:34 - GraphTrainer - INFO - ndcg@10: 0.030202
2025-12-15 20:18:34 - GraphTrainer - INFO - map@10: 0.021977
2025-12-15 20:18:34 - GraphTrainer - INFO - mrr@10: 0.023027
2025-12-15 20:18:34 - GraphTrainer - INFO - precision@20: 0.004706
2025-12-15 20:18:34 - GraphTrainer - INFO - recall@20: 0.089164
2025-12-15 20:18:34 - GraphTrainer - INFO - hit_rate@20: 0.093546
2025-12-15 20:18:34 - GraphTrainer - INFO - ndcg@20: 0.038561
2025-12-15 20:18:34 - GraphTrainer - INFO - map@20: 0.024206
2025-12-15 20:18:34 - GraphTrainer - INFO - mrr@20: 0.025350
2025-12-15 20:18:34 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:18:34 - GraphTrainer - INFO - ============================================================
2025-12-15 20:18:34 - GraphTrainer - INFO - 开始第 67/1000 轮训练
2025-12-15 20:18:34 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.2090, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2045, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.1956, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.1948, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.2111, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2047, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.1786, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2065, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.2204, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.1953, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1901, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2049, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.2093, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.1953, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2183, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1929, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.1940, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2195, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2089, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2018, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2130, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2110, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.1974, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2083, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.2073, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2092, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.1929, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2060, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.1881, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2134, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2026, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2019, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2220, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2175, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2087, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2237, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2091, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.1872, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2100, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.1804, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1996, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2022, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2019, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.2074, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2031, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.2092, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2060, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.1917, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.2005, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.1956, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2140, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.1884, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.2139, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1857, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.2023, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.1957, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.1866, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.2048, device='cuda:0', grad_fn=<AddBackward0>)
The 66 training average loss: 0.20299485711188153
2025-12-15 20:18:42 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:18:42 - GraphTrainer - INFO -   precision@5: 0.007385
2025-12-15 20:18:42 - GraphTrainer - INFO -   recall@5: 0.035192
2025-12-15 20:18:42 - GraphTrainer - INFO -   hit_rate@5: 0.036873
2025-12-15 20:18:42 - GraphTrainer - INFO -   ndcg@5: 0.023819
2025-12-15 20:18:42 - GraphTrainer - INFO -   map@5: 0.019792
2025-12-15 20:18:42 - GraphTrainer - INFO -   mrr@5: 0.020731
2025-12-15 20:18:42 - GraphTrainer - INFO -   precision@10: 0.005780
2025-12-15 20:18:42 - GraphTrainer - INFO -   recall@10: 0.054606
2025-12-15 20:18:42 - GraphTrainer - INFO -   hit_rate@10: 0.057598
2025-12-15 20:18:42 - GraphTrainer - INFO -   ndcg@10: 0.030131
2025-12-15 20:18:42 - GraphTrainer - INFO -   map@10: 0.022334
2025-12-15 20:18:42 - GraphTrainer - INFO -   mrr@10: 0.023441
2025-12-15 20:18:42 - GraphTrainer - INFO -   precision@20: 0.004685
2025-12-15 20:18:42 - GraphTrainer - INFO -   recall@20: 0.088573
2025-12-15 20:18:42 - GraphTrainer - INFO -   hit_rate@20: 0.093032
2025-12-15 20:18:42 - GraphTrainer - INFO -   ndcg@20: 0.038783
2025-12-15 20:18:42 - GraphTrainer - INFO -   map@20: 0.024671
2025-12-15 20:18:42 - GraphTrainer - INFO -   mrr@20: 0.025868
2025-12-15 20:18:42 - GraphTrainer - INFO - 第 67 轮训练完成
2025-12-15 20:18:42 - GraphTrainer - INFO - train_loss: 0.198792
2025-12-15 20:18:42 - GraphTrainer - INFO - precision@5: 0.007385
2025-12-15 20:18:42 - GraphTrainer - INFO - recall@5: 0.035192
2025-12-15 20:18:42 - GraphTrainer - INFO - hit_rate@5: 0.036873
2025-12-15 20:18:42 - GraphTrainer - INFO - ndcg@5: 0.023819
2025-12-15 20:18:42 - GraphTrainer - INFO - map@5: 0.019792
2025-12-15 20:18:42 - GraphTrainer - INFO - mrr@5: 0.020731
2025-12-15 20:18:42 - GraphTrainer - INFO - precision@10: 0.005780
2025-12-15 20:18:42 - GraphTrainer - INFO - recall@10: 0.054606
2025-12-15 20:18:42 - GraphTrainer - INFO - hit_rate@10: 0.057598
2025-12-15 20:18:42 - GraphTrainer - INFO - ndcg@10: 0.030131
2025-12-15 20:18:42 - GraphTrainer - INFO - map@10: 0.022334
2025-12-15 20:18:42 - GraphTrainer - INFO - mrr@10: 0.023441
2025-12-15 20:18:42 - GraphTrainer - INFO - precision@20: 0.004685
2025-12-15 20:18:42 - GraphTrainer - INFO - recall@20: 0.088573
2025-12-15 20:18:42 - GraphTrainer - INFO - hit_rate@20: 0.093032
2025-12-15 20:18:42 - GraphTrainer - INFO - ndcg@20: 0.038783
2025-12-15 20:18:42 - GraphTrainer - INFO - map@20: 0.024671
2025-12-15 20:18:42 - GraphTrainer - INFO - mrr@20: 0.025868
2025-12-15 20:18:42 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:18:42 - GraphTrainer - INFO - ============================================================
2025-12-15 20:18:42 - GraphTrainer - INFO - 开始第 68/1000 轮训练
2025-12-15 20:18:42 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1950, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.2065, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2061, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.2132, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1975, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.2113, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.1939, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.1959, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1975, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2003, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1930, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.1904, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1988, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2063, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.1949, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1810, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2018, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2134, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.2052, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2058, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1981, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2173, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.1931, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2010, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.1997, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2151, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2061, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.1938, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.1931, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.1914, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.1885, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2097, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.2190, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.2102, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1915, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.2010, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2176, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.1841, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.1948, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.1719, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1900, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.1780, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.1921, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.1957, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.1958, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.1936, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.1888, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.2006, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1899, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.1901, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2096, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.2066, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.1936, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.2113, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1921, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2000, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.1984, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.1986, device='cuda:0', grad_fn=<AddBackward0>)
The 67 training average loss: 0.19879168349093404
2025-12-15 20:18:50 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:18:50 - GraphTrainer - INFO -   precision@5: 0.007200
2025-12-15 20:18:50 - GraphTrainer - INFO -   recall@5: 0.034283
2025-12-15 20:18:50 - GraphTrainer - INFO -   hit_rate@5: 0.035948
2025-12-15 20:18:50 - GraphTrainer - INFO -   ndcg@5: 0.022783
2025-12-15 20:18:50 - GraphTrainer - INFO -   map@5: 0.018723
2025-12-15 20:18:50 - GraphTrainer - INFO -   mrr@5: 0.019618
2025-12-15 20:18:50 - GraphTrainer - INFO -   precision@10: 0.005883
2025-12-15 20:18:50 - GraphTrainer - INFO -   recall@10: 0.055849
2025-12-15 20:18:50 - GraphTrainer - INFO -   hit_rate@10: 0.058730
2025-12-15 20:18:50 - GraphTrainer - INFO -   ndcg@10: 0.029773
2025-12-15 20:18:50 - GraphTrainer - INFO -   map@10: 0.021543
2025-12-15 20:18:50 - GraphTrainer - INFO -   mrr@10: 0.022599
2025-12-15 20:18:50 - GraphTrainer - INFO -   precision@20: 0.004659
2025-12-15 20:18:50 - GraphTrainer - INFO -   recall@20: 0.088262
2025-12-15 20:18:50 - GraphTrainer - INFO -   hit_rate@20: 0.092672
2025-12-15 20:18:50 - GraphTrainer - INFO -   ndcg@20: 0.038051
2025-12-15 20:18:50 - GraphTrainer - INFO -   map@20: 0.023787
2025-12-15 20:18:50 - GraphTrainer - INFO -   mrr@20: 0.024936
2025-12-15 20:18:50 - GraphTrainer - INFO - 第 68 轮训练完成
2025-12-15 20:18:50 - GraphTrainer - INFO - train_loss: 0.197833
2025-12-15 20:18:50 - GraphTrainer - INFO - precision@5: 0.007200
2025-12-15 20:18:50 - GraphTrainer - INFO - recall@5: 0.034283
2025-12-15 20:18:50 - GraphTrainer - INFO - hit_rate@5: 0.035948
2025-12-15 20:18:50 - GraphTrainer - INFO - ndcg@5: 0.022783
2025-12-15 20:18:50 - GraphTrainer - INFO - map@5: 0.018723
2025-12-15 20:18:50 - GraphTrainer - INFO - mrr@5: 0.019618
2025-12-15 20:18:50 - GraphTrainer - INFO - precision@10: 0.005883
2025-12-15 20:18:50 - GraphTrainer - INFO - recall@10: 0.055849
2025-12-15 20:18:50 - GraphTrainer - INFO - hit_rate@10: 0.058730
2025-12-15 20:18:50 - GraphTrainer - INFO - ndcg@10: 0.029773
2025-12-15 20:18:50 - GraphTrainer - INFO - map@10: 0.021543
2025-12-15 20:18:50 - GraphTrainer - INFO - mrr@10: 0.022599
2025-12-15 20:18:50 - GraphTrainer - INFO - precision@20: 0.004659
2025-12-15 20:18:50 - GraphTrainer - INFO - recall@20: 0.088262
2025-12-15 20:18:50 - GraphTrainer - INFO - hit_rate@20: 0.092672
2025-12-15 20:18:50 - GraphTrainer - INFO - ndcg@20: 0.038051
2025-12-15 20:18:50 - GraphTrainer - INFO - map@20: 0.023787
2025-12-15 20:18:50 - GraphTrainer - INFO - mrr@20: 0.024936
2025-12-15 20:18:50 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:18:50 - GraphTrainer - INFO - ============================================================
2025-12-15 20:18:50 - GraphTrainer - INFO - 开始第 69/1000 轮训练
2025-12-15 20:18:50 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1885, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.1865, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2149, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.1693, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1980, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.1943, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.1964, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.1905, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1850, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.2064, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1970, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2202, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1995, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.2012, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.2172, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1972, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2044, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.1924, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.1886, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.1947, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.2169, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.1953, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.1977, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.2070, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.1959, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.1945, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.1965, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.2056, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2025, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2021, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2101, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.2029, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.1928, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1956, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.1908, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1910, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.2148, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.1882, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.1857, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.2103, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.2015, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.2232, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2054, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.1920, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.2247, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.1885, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.1946, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.1906, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1804, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.1981, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.1876, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.1908, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.1879, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1887, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1918, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2123, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.1849, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.1928, device='cuda:0', grad_fn=<AddBackward0>)
The 68 training average loss: 0.19783334639565697
2025-12-15 20:18:58 - GraphTrainer - INFO - 验证结果:
2025-12-15 20:18:58 - GraphTrainer - INFO -   precision@5: 0.007436
2025-12-15 20:18:58 - GraphTrainer - INFO -   recall@5: 0.035454
2025-12-15 20:18:58 - GraphTrainer - INFO -   hit_rate@5: 0.037130
2025-12-15 20:18:58 - GraphTrainer - INFO -   ndcg@5: 0.023673
2025-12-15 20:18:58 - GraphTrainer - INFO -   map@5: 0.019527
2025-12-15 20:18:58 - GraphTrainer - INFO -   mrr@5: 0.020433
2025-12-15 20:18:58 - GraphTrainer - INFO -   precision@10: 0.005847
2025-12-15 20:18:58 - GraphTrainer - INFO -   recall@10: 0.055657
2025-12-15 20:18:58 - GraphTrainer - INFO -   hit_rate@10: 0.058370
2025-12-15 20:18:58 - GraphTrainer - INFO -   ndcg@10: 0.030246
2025-12-15 20:18:58 - GraphTrainer - INFO -   map@10: 0.022199
2025-12-15 20:18:58 - GraphTrainer - INFO -   mrr@10: 0.023236
2025-12-15 20:18:58 - GraphTrainer - INFO -   precision@20: 0.004672
2025-12-15 20:18:58 - GraphTrainer - INFO -   recall@20: 0.088512
2025-12-15 20:18:58 - GraphTrainer - INFO -   hit_rate@20: 0.092877
2025-12-15 20:18:58 - GraphTrainer - INFO -   ndcg@20: 0.038585
2025-12-15 20:18:58 - GraphTrainer - INFO -   map@20: 0.024425
2025-12-15 20:18:58 - GraphTrainer - INFO -   mrr@20: 0.025572
2025-12-15 20:18:58 - GraphTrainer - INFO - 第 69 轮训练完成
2025-12-15 20:18:58 - GraphTrainer - INFO - train_loss: 0.196984
2025-12-15 20:18:58 - GraphTrainer - INFO - precision@5: 0.007436
2025-12-15 20:18:58 - GraphTrainer - INFO - recall@5: 0.035454
2025-12-15 20:18:58 - GraphTrainer - INFO - hit_rate@5: 0.037130
2025-12-15 20:18:58 - GraphTrainer - INFO - ndcg@5: 0.023673
2025-12-15 20:18:58 - GraphTrainer - INFO - map@5: 0.019527
2025-12-15 20:18:58 - GraphTrainer - INFO - mrr@5: 0.020433
2025-12-15 20:18:58 - GraphTrainer - INFO - precision@10: 0.005847
2025-12-15 20:18:58 - GraphTrainer - INFO - recall@10: 0.055657
2025-12-15 20:18:58 - GraphTrainer - INFO - hit_rate@10: 0.058370
2025-12-15 20:18:58 - GraphTrainer - INFO - ndcg@10: 0.030246
2025-12-15 20:18:58 - GraphTrainer - INFO - map@10: 0.022199
2025-12-15 20:18:58 - GraphTrainer - INFO - mrr@10: 0.023236
2025-12-15 20:18:58 - GraphTrainer - INFO - precision@20: 0.004672
2025-12-15 20:18:58 - GraphTrainer - INFO - recall@20: 0.088512
2025-12-15 20:18:58 - GraphTrainer - INFO - hit_rate@20: 0.092877
2025-12-15 20:18:58 - GraphTrainer - INFO - ndcg@20: 0.038585
2025-12-15 20:18:58 - GraphTrainer - INFO - map@20: 0.024425
2025-12-15 20:18:58 - GraphTrainer - INFO - mrr@20: 0.025572
2025-12-15 20:18:58 - GraphTrainer - INFO - ------------------------------------------------------------
2025-12-15 20:18:58 - GraphTrainer - INFO - ============================================================
2025-12-15 20:18:58 - GraphTrainer - INFO - 开始第 70/1000 轮训练
2025-12-15 20:18:58 - GraphTrainer - INFO - ============================================================
0 train_loss tensor(0.1829, device='cuda:0', grad_fn=<AddBackward0>)
1 train_loss tensor(0.1848, device='cuda:0', grad_fn=<AddBackward0>)
2 train_loss tensor(0.2013, device='cuda:0', grad_fn=<AddBackward0>)
3 train_loss tensor(0.1902, device='cuda:0', grad_fn=<AddBackward0>)
4 train_loss tensor(0.1986, device='cuda:0', grad_fn=<AddBackward0>)
5 train_loss tensor(0.1630, device='cuda:0', grad_fn=<AddBackward0>)
6 train_loss tensor(0.2083, device='cuda:0', grad_fn=<AddBackward0>)
7 train_loss tensor(0.2007, device='cuda:0', grad_fn=<AddBackward0>)
8 train_loss tensor(0.1996, device='cuda:0', grad_fn=<AddBackward0>)
9 train_loss tensor(0.1936, device='cuda:0', grad_fn=<AddBackward0>)
10 train_loss tensor(0.1768, device='cuda:0', grad_fn=<AddBackward0>)
11 train_loss tensor(0.2013, device='cuda:0', grad_fn=<AddBackward0>)
12 train_loss tensor(0.1959, device='cuda:0', grad_fn=<AddBackward0>)
13 train_loss tensor(0.1924, device='cuda:0', grad_fn=<AddBackward0>)
14 train_loss tensor(0.1726, device='cuda:0', grad_fn=<AddBackward0>)
15 train_loss tensor(0.1831, device='cuda:0', grad_fn=<AddBackward0>)
16 train_loss tensor(0.2264, device='cuda:0', grad_fn=<AddBackward0>)
17 train_loss tensor(0.2040, device='cuda:0', grad_fn=<AddBackward0>)
18 train_loss tensor(0.1895, device='cuda:0', grad_fn=<AddBackward0>)
19 train_loss tensor(0.2059, device='cuda:0', grad_fn=<AddBackward0>)
20 train_loss tensor(0.1984, device='cuda:0', grad_fn=<AddBackward0>)
21 train_loss tensor(0.2115, device='cuda:0', grad_fn=<AddBackward0>)
22 train_loss tensor(0.1950, device='cuda:0', grad_fn=<AddBackward0>)
23 train_loss tensor(0.1871, device='cuda:0', grad_fn=<AddBackward0>)
24 train_loss tensor(0.1950, device='cuda:0', grad_fn=<AddBackward0>)
25 train_loss tensor(0.2062, device='cuda:0', grad_fn=<AddBackward0>)
26 train_loss tensor(0.2011, device='cuda:0', grad_fn=<AddBackward0>)
27 train_loss tensor(0.1941, device='cuda:0', grad_fn=<AddBackward0>)
28 train_loss tensor(0.2136, device='cuda:0', grad_fn=<AddBackward0>)
29 train_loss tensor(0.2069, device='cuda:0', grad_fn=<AddBackward0>)
30 train_loss tensor(0.2094, device='cuda:0', grad_fn=<AddBackward0>)
31 train_loss tensor(0.1945, device='cuda:0', grad_fn=<AddBackward0>)
32 train_loss tensor(0.1934, device='cuda:0', grad_fn=<AddBackward0>)
33 train_loss tensor(0.1797, device='cuda:0', grad_fn=<AddBackward0>)
34 train_loss tensor(0.2333, device='cuda:0', grad_fn=<AddBackward0>)
35 train_loss tensor(0.1960, device='cuda:0', grad_fn=<AddBackward0>)
36 train_loss tensor(0.1995, device='cuda:0', grad_fn=<AddBackward0>)
37 train_loss tensor(0.1936, device='cuda:0', grad_fn=<AddBackward0>)
38 train_loss tensor(0.2003, device='cuda:0', grad_fn=<AddBackward0>)
39 train_loss tensor(0.1785, device='cuda:0', grad_fn=<AddBackward0>)
40 train_loss tensor(0.1936, device='cuda:0', grad_fn=<AddBackward0>)
41 train_loss tensor(0.1888, device='cuda:0', grad_fn=<AddBackward0>)
42 train_loss tensor(0.2126, device='cuda:0', grad_fn=<AddBackward0>)
43 train_loss tensor(0.1944, device='cuda:0', grad_fn=<AddBackward0>)
44 train_loss tensor(0.1957, device='cuda:0', grad_fn=<AddBackward0>)
45 train_loss tensor(0.1881, device='cuda:0', grad_fn=<AddBackward0>)
46 train_loss tensor(0.2025, device='cuda:0', grad_fn=<AddBackward0>)
47 train_loss tensor(0.1910, device='cuda:0', grad_fn=<AddBackward0>)
48 train_loss tensor(0.1974, device='cuda:0', grad_fn=<AddBackward0>)
49 train_loss tensor(0.1972, device='cuda:0', grad_fn=<AddBackward0>)
50 train_loss tensor(0.2086, device='cuda:0', grad_fn=<AddBackward0>)
51 train_loss tensor(0.1884, device='cuda:0', grad_fn=<AddBackward0>)
52 train_loss tensor(0.1905, device='cuda:0', grad_fn=<AddBackward0>)
53 train_loss tensor(0.1889, device='cuda:0', grad_fn=<AddBackward0>)
54 train_loss tensor(0.1998, device='cuda:0', grad_fn=<AddBackward0>)
55 train_loss tensor(0.2266, device='cuda:0', grad_fn=<AddBackward0>)
56 train_loss tensor(0.2039, device='cuda:0', grad_fn=<AddBackward0>)
57 train_loss tensor(0.1988, device='cuda:0', grad_fn=<AddBackward0>)
The 69 training average loss: 0.19698439512787194
